# server.R — SARIMA Scientific Writing Lab (v2)
# FIX v2: Manual SARIMA validation forecast aligns with test horizon (h = test length).

library(shiny)
library(ggplot2)
library(forecast)
library(lubridate)
library(zoo)
library(tseries)
library(urca)
library(gridExtra)
library(colourpicker)
library(patchwork)
library(scales)
library(DT)
# library(DiagrammeR)
# library(bootstrap)

has_pkg <- function(pkg) requireNamespace(pkg, quietly = TRUE)





# ---------- Safety helpers (add once) ----------

is_finite_vec <- function(x) {
  x <- suppressWarnings(as.numeric(x))
  length(x) > 0 && any(is.finite(x))
}

safe_range <- function(x) {
  x <- suppressWarnings(as.numeric(x))
  if (length(x) == 0) return(NULL)
  r <- suppressWarnings(range(x, na.rm = TRUE, finite = TRUE))
  if (length(r) != 2 || any(!is.finite(r))) return(NULL)
  if (diff(r) == 0) return(NULL)
  r
}

# Safely extract and standardize coefficient table from MANY model types
coef_table_safe <- function(fit) {
  sm <- tryCatch(summary(fit), error = function(e) NULL)
  if (is.null(sm)) return(data.frame())
  
  # try common places:
  co <- NULL
  if (!is.null(sm$coef)) co <- sm$coef
  if (is.null(co) && !is.null(sm$coefficients)) co <- sm$coefficients
  if (is.null(co)) return(data.frame())
  
  co <- as.data.frame(co)
  co$term <- rownames(co)
  rownames(co) <- NULL
  
  # normalize column names
  nm <- names(co)
  nm0 <- tolower(gsub("[^a-z]+", "", nm))
  
  # Attempt to find estimate/se/t/p columns flexibly
  pick <- function(keys) {
    idx <- which(nm0 %in% keys)
    if (length(idx) == 0) NA_integer_ else idx[1]
  }
  
  i_est <- pick(c("estimate", "est", "coef", "value"))
  i_se  <- pick(c("se", "stderror", "stderr", "sestd"))
  i_t   <- pick(c("tvalue", "tstat", "zvalue", "zstat", "statistic"))
  i_p   <- pick(c("prtz", "prgtz", "prgt", "prtt", "prgtz", "pvalue", "pr", "prt"))
  
  out <- data.frame(
    term = co$term,
    est  = if (!is.na(i_est)) suppressWarnings(as.numeric(co[[i_est]])) else NA_real_,
    se   = if (!is.na(i_se))  suppressWarnings(as.numeric(co[[i_se]]))  else NA_real_,
    stat = if (!is.na(i_t))   suppressWarnings(as.numeric(co[[i_t]]))   else NA_real_,
    p    = if (!is.na(i_p))   suppressWarnings(as.numeric(co[[i_p]]))   else NA_real_,
    stringsAsFactors = FALSE
  )
  
  out
}

sig_stars <- function(p) {
  if (!is.finite(p)) return("")
  if (p < 0.001) "***" else if (p < 0.01) "**" else if (p < 0.05) "*" else if (p < 0.1) "." else ""
}






build_xreg_split <- function(df, cols, train_n, test_n, scale_x = FALSE) {
  if (length(cols) == 0) return(list(x_train = NULL, x_test = NULL, x_all = NULL))
  
  X <- df[, cols, drop = FALSE]
  
  # keep numeric columns only (convert logical to numeric)
  for (nm in names(X)) {
    if (is.logical(X[[nm]])) X[[nm]] <- as.numeric(X[[nm]])
  }
  # force numeric
  X <- data.frame(lapply(X, function(z) suppressWarnings(as.numeric(z))), check.names = FALSE)
  
  # handle missing values in xreg (simple: linear interpolation + LOCF fallback)
  for (j in seq_along(X)) {
    v <- X[[j]]
    idx <- which(is.finite(v))
    if (length(idx) >= 2) {
      v[!is.finite(v)] <- approx(x = idx, y = v[idx], xout = which(!is.finite(v)), method = "linear", rule = 2)$y
    }
    # if still NA (all missing), set 0
    v[!is.finite(v)] <- 0
    X[[j]] <- v
  }
  
  if (isTRUE(scale_x)) {
    X <- as.data.frame(scale(X), check.names = FALSE)
  }
  
  X_mat <- as.matrix(X)
  x_train <- X_mat[seq_len(train_n), , drop = FALSE]
  x_test  <- if (test_n > 0) X_mat[(train_n + 1):(train_n + test_n), , drop = FALSE] else NULL
  
  list(x_train = x_train, x_test = x_test, x_all = X_mat)
}



# ============================================================
# --- MOD: Robust date parsing (R Date / POSIX / Excel serial / text) ---
# ============================================================
parse_dates <- function(x) {
  if (inherits(x, "Date")) return(x)
  if (inherits(x, "POSIXt")) return(as.Date(x))
  
  if (is.numeric(x)) {
    # MOD: heuristic to distinguish R Date numeric vs Excel serial
    # - R Date numeric typically around [-60000, 60000] (days since 1970-01-01)
    # - Excel serial is typically large positive (days since 1899-12-30)
    med <- suppressWarnings(stats::median(x, na.rm = TRUE))
    if (is.finite(med) && med > -60000 && med < 60000) {
      return(as.Date(x, origin = "1970-01-01"))
    }
    return(as.Date(x, origin = "1899-12-30"))
  }
  
  x_chr <- as.character(x)
  
  d <- suppressWarnings(as.Date(zoo::as.yearmon(x_chr)))
  if (all(is.na(d))) {
    d <- suppressWarnings(lubridate::parse_date_time(
      x_chr,
      orders = c(
        "ymd", "dmy", "mdy", "Ymd", "Y-m-d", "d-m-Y", "m/d/Y",
        "Y", "ym", "my", "bY", "Y-b", "any"
      )
    ))
    d <- as.Date(d)
  }
  
  d
}




# ---------------- APA helpers ----------------

fmt_p <- function(p) {
  if (is.na(p)) return("p = NA")
  if (p < 0.001) return("p < .001")
  s <- format(p, digits = 3, nsmall = 3)
  s <- sub("^0\\.", ".", s)
  paste0("p = ", s)
}



fmt_num <- function(x, digits = 4, trim = TRUE) {
  x <- suppressWarnings(as.numeric(x))
  if (length(x) == 0 || !is.finite(x)) return("NA")
  format(round(x, digits), nsmall = digits, trim = trim)
}

# fmt_num <- function(x, digits = 2) {
#   if (is.na(x)) return("NA")
#   format(round(x, digits), nsmall = digits, trim = TRUE)
# }




fmt_pct <- function(x, digits = 1) {
  if (is.na(x)) return("NA")
  paste0(fmt_num(100 * x, digits), "%")
}

# ---------------- Dates & time grid ----------------

# parse_dates <- function(x) {
#   if (inherits(x, "Date")) return(x)
#   if (is.numeric(x)) return(as.Date(x, origin = "1899-12-30"))
#   x_chr <- as.character(x)
# 
#   d <- suppressWarnings(as.Date(zoo::as.yearmon(x_chr)))
#   if (all(is.na(d))) {
#     d <- suppressWarnings(lubridate::parse_date_time(
#       x_chr,
#       orders = c("ymd", "dmy", "mdy", "Ymd", "Y-m-d", "d-m-Y", "m/d/Y", "Y", "ym", "my", "bY", "Y-b", "any")
#     ))
#     d <- as.Date(d)
#   }
#   d
# }

freq_value <- function(input) {
  if (identical(input$frequency, "other")) as.numeric(input$customFrequency) else as.numeric(input$frequency)
}

freq_to_by <- function(freq) {
  switch(
    as.character(freq),
    "12" = "month",
    "4" = "quarter",
    "52" = "week",
    "365" = "day",
    "7" = "day",
    NULL
  )
}

make_regular_grid <- function(dates, by) {
  if (is.null(by)) return(sort(unique(dates)))
  seq.Date(from = min(dates), to = max(dates), by = by)
}

extend_grid <- function(last_x, h, by) {
  if (inherits(last_x, "Date") && !is.null(by)) {
    seq.Date(from = last_x, by = by, length.out = h + 1)[-1]
  } else {
    (as.numeric(last_x) + seq_len(h))
  }
}

# ---------------- Missing values & transforms ----------------

fill_missing <- function(y, policy, freq) {
  if (policy == "drop") return(y)
  if (policy == "locf") {
    y <- zoo::na.locf(y, na.rm = FALSE)
    y <- zoo::na.locf(y, fromLast = TRUE, na.rm = FALSE)
    return(y)
  }
  if (policy == "linear") return(zoo::na.approx(y, na.rm = FALSE))
  if (policy == "seasonal") return(as.numeric(forecast::na.interp(ts(y, frequency = freq))))
  y
}

apply_transform <- function(y, transform, lambda) {
  if (transform == "none") return(y)
  if (any(y <= 0, na.rm = TRUE)) stop("Chosen transformation requires strictly positive values.")
  if (transform == "log") return(log(y))
  if (transform == "boxcox") {
    lam <- if (!is.na(lambda)) lambda else forecast::BoxCox.lambda(y, lower = 0)
    return(forecast::BoxCox(y, lam))
  }
  y
}

# ---------------- Descriptives & diagnostics ----------------

basic_stats_df <- function(y) {
  y <- as.numeric(y)
  y_ok <- y[is.finite(y)]
  n <- length(y)
  n_ok <- length(y_ok)
  miss <- n - n_ok
  if (n_ok == 0) {
    return(data.frame(Metric = c("N", "Missing"), Value = c(n, miss), stringsAsFactors = FALSE))
  }
  mu <- mean(y_ok)
  sdv <- sd(y_ok)
  med <- median(y_ok)
  mn <- min(y_ok); mx <- max(y_ok)
  cv <- if (mu != 0) sdv / mu else NA_real_
  m3 <- mean((y_ok - mu)^3)
  m4 <- mean((y_ok - mu)^4)
  skew <- if (sdv > 0) m3 / (sdv^3) else NA_real_
  kurt <- if (sdv > 0) m4 / (sdv^4) else NA_real_
  data.frame(
    Metric = c("N", "Valid", "Missing", "Mean", "Median", "SD", "Min", "Max", "CV", "Skewness", "Kurtosis"),
    Value = c(n, n_ok, miss, mu, med, sdv, mn, mx, cv, skew, kurt),
    stringsAsFactors = FALSE
  )
}

z_outliers <- function(y, z_cut = 3) {
  y <- as.numeric(y)
  ok <- is.finite(y)
  mu <- mean(y[ok])
  sdv <- sd(y[ok])
  if (!is.finite(sdv) || sdv == 0) return(integer(0))
  which(abs((y - mu) / sdv) >= z_cut)
}

coef_table <- function(fit) {
  s <- tryCatch(summary(fit), error = function(e) NULL)
  if (is.null(s) || is.null(s$coef)) return(data.frame())
  cf <- as.data.frame(s$coef)
  cf$term <- rownames(cf)
  rownames(cf) <- NULL
  names(cf) <- sub("Pr\\(>\\|t\\|\\)", "p_value", names(cf))
  names(cf) <- sub("Pr\\(>\\|z\\|\\)", "p_value", names(cf))
  cf
}

diag_tests_text <- function(resid, lag, fitdf = 0) {
  r <- as.numeric(na.omit(resid))
  out <- c("Residual diagnostics")

  lb <- tryCatch(Box.test(r, lag = lag, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
  if (!is.null(lb)) out <- c(out, paste0("- Ljung-Box: Q(", lag, ") = ", fmt_num(lb$statistic, 2), ", ", fmt_p(lb$p.value)))

  jb <- tryCatch(tseries::jarque.bera.test(r), error = function(e) NULL)
  if (!is.null(jb)) out <- c(out, paste0("- Jarque–Bera: JB = ", fmt_num(jb$statistic, 2), ", ", fmt_p(jb$p.value)))

  sh <- tryCatch(stats::shapiro.test(if (length(r) > 5000) sample(r, 5000) else r), error = function(e) NULL)
  if (!is.null(sh)) out <- c(out, paste0("- Shapiro–Wilk: W = ", fmt_num(sh$statistic, 3), ", ", fmt_p(sh$p.value)))

  if (has_pkg("nortest")) {
    ad <- tryCatch(nortest::ad.test(r), error = function(e) NULL)
    if (!is.null(ad)) out <- c(out, paste0("- Anderson–Darling: A = ", fmt_num(ad$statistic, 2), ", ", fmt_p(ad$p.value)))
  }

  if (has_pkg("FinTS")) {
    arch <- tryCatch(FinTS::ArchTest(r, lags = min(12, max(1, floor(lag / 2)))), error = function(e) NULL)
    if (!is.null(arch)) out <- c(out, paste0("- ARCH LM: TR^2 = ", fmt_num(arch$statistic, 2), ", ", fmt_p(arch$p.value)))
  }

  out <- c(out, "", "Interpretation (typical): Ljung-Box p > .05 suggests residuals are approximately white noise.")
  paste(out, collapse = "\n")
}

accuracy_df <- function(actual, forecast_mean) {
  a <- as.numeric(actual)
  f <- as.numeric(forecast_mean)
  n <- min(length(a), length(f))
  a <- a[seq_len(n)]
  f <- f[seq_len(n)]
  e <- a - f

  rmse <- sqrt(mean(e^2, na.rm = TRUE))
  mae <- mean(abs(e), na.rm = TRUE)
  mape <- mean(abs(e / a), na.rm = TRUE)
  smape <- mean(2 * abs(e) / (abs(a) + abs(f)), na.rm = TRUE)

  data.frame(
    Metric = c("RMSE", "MAE", "MAPE", "sMAPE"),
    Value = c(rmse, mae, mape, smape),
    stringsAsFactors = FALSE
  )
}

forecast_table <- function(fc) {
  out <- data.frame(step = seq_along(fc$mean), mean = as.numeric(fc$mean))
  if (!is.null(fc$lower)) {
    out$lo80 <- as.numeric(fc$lower[, 1])
    out$hi80 <- as.numeric(fc$upper[, 1])
    if (ncol(fc$lower) >= 2) {
      out$lo95 <- as.numeric(fc$lower[, 2])
      out$hi95 <- as.numeric(fc$upper[, 2])
    }
  }
  out
}

# ---------------- Plot helpers (Date-safe) ----------------

plot_series_df <- function(df, train_n) {
  df$set <- ifelse(seq_len(nrow(df)) <= train_n, "Train", "Test/Future")
  df
}

plot_forecast_df <- function(obs_df, train_n, fc, by) {
  n_obs <- nrow(obs_df)
  test_n <- n_obs - train_n
  h <- length(fc$mean)

  # FIX v2:
  # If a test set exists, align the forecast x values with the test period.
  # Only extend beyond the observed sample if h > test length.
  if (test_n > 0) {
    x_test <- obs_df$x[(train_n + 1):n_obs]
    n_align <- min(h, length(x_test))
    x_fc <- x_test[seq_len(n_align)]
    if (h > n_align) {
      x_extra <- extend_grid(obs_df$x[n_obs], h - n_align, by)
      x_fc <- c(x_fc, x_extra)
    }
  } else {
    x_fc <- extend_grid(obs_df$x[n_obs], h, by)
  }

  fc_tab <- forecast_table(fc)
  fc_tab$x <- x_fc
  fc_tab
}

gg_forecast_plot <- function(obs_df, train_n, fc_df, title) {
  p <- ggplot() +
    geom_line(data = obs_df[seq_len(train_n), ], aes(x = x, y = y, color = "Train")) +
    theme_minimal() +
    labs(title = title, x = "Time", y = "Value", color = NULL) +
    theme(legend.position = "bottom")

  if (nrow(obs_df) > train_n) {
    p <- p + geom_line(data = obs_df[(train_n + 1):nrow(obs_df), ], aes(x = x, y = y, color = "Test"))
  }

  if ("lo95" %in% names(fc_df)) p <- p + geom_ribbon(data = fc_df, aes(x = x, ymin = lo95, ymax = hi95), alpha = 0.15)
  if ("lo80" %in% names(fc_df)) p <- p + geom_ribbon(data = fc_df, aes(x = x, ymin = lo80, ymax = hi80), alpha = 0.25)

  p + geom_line(data = fc_df, aes(x = x, y = mean, color = "Forecast"), linewidth = 1)
}





apply_smart_date_axis <- function(g, ddf) {
  if (!(inherits(ddf$t, "Date") || inherits(ddf$t, "POSIXct") || inherits(ddf$t, "POSIXt"))) return(g)
  
  span_days <- as.numeric(max(ddf$t, na.rm = TRUE) - min(ddf$t, na.rm = TRUE))
  
  # choose break spacing
  brks <- if (!is.finite(span_days) || span_days <= 0) {
    "1 year"
  } else if (span_days <= 90) {
    "1 week"
  } else if (span_days <= 365) {
    "1 month"
  } else if (span_days <= 3 * 365) {
    "3 months"
  } else if (span_days <= 10 * 365) {
    "1 year"
  } else {
    "2 years"
  }
  
  # choose label format by zoom level
  fmt <- if (!is.finite(span_days)) {
    "%Y"
  } else if (span_days <= 90) {
    "%d/%m/%y"   # short span → day/month/year
  } else if (span_days <= 3 * 365) {
    "%m/%y"      # medium span → month/year
  } else {
    "%Y"         # long span → year only
  }
  
  if (inherits(ddf$t, "POSIXct") || inherits(ddf$t, "POSIXt")) {
    g + ggplot2::scale_x_datetime(date_breaks = brks, date_labels = fmt)
  } else {
    g + ggplot2::scale_x_date(date_breaks = brks, date_labels = fmt)
  }
}














#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================






#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================




pkg_status_li <- function(pkg) {
  ok <- has_pkg(pkg)
  tags$li(
    if (ok) "✅" else "❌",
    tags$span(
      paste0(" ", pkg),
      style = if (ok) "color: #2e7d32;" else "color: #b71c1c;"
    )
  )
}



# ---------------- Shiny server ----------------

server <- function(input, output, session) {

  # ---- Roadmap & teaching notes ----

  
  # Required packages (UI-style environment check)
  output$package_status <- renderUI({
    
    required_pkgs <- c(
      "shiny",        # app framework
      "ggplot2",      # all plotting
      "forecast",     # SARIMA, ACF/PACF, decomposition, BoxCox
      "lubridate",    # date parsing
      "zoo",          # na.locf, na.approx, as.yearmon
      "tseries",      # ADF, Jarque-Bera
      "urca",         # unit root tests
      "DT",           # data tables
      "scales"        # plot scales
    )
    
    optional_pkgs <- c(
      "readxl",       # only needed for XLS/XLSX upload
      "colourpicker", # S(t) plot color pickers
      "patchwork",    # combined plots
      "gridExtra",    # plot layouts
      "shinythemes",  # UI theme
      "shinyjs",      # JS helpers (disable/enable UI)
      "nortest",      # Anderson–Darling normality test
      "FinTS"         # ARCH LM test
    )
    
    tags$div(
      style = "background:#eef5ff;padding:12px;border-radius:8px;",
      tags$h4("R environment check"),
      tags$p(
        style = "margin-top:-6px; font-size: 13px; color:#34495e;",
        "✅ installed  •  ❌ missing"
      ),
      
      tags$br(),
      
      fluidRow(
        column(
          width = 6,
          tags$b("Required packages"),
          tags$ul(lapply(required_pkgs, pkg_status_li))
        ),
        column(
          width = 6,
          tags$b("Optional packages"),
          tags$ul(lapply(optional_pkgs, pkg_status_li))
        )
      ),
      
      if (any(!vapply(required_pkgs, has_pkg, logical(1)))) {
        tags$div(
          style = "margin-top:10px; color:#b71c1c; font-size:13px;",
          tags$b("Some required packages are missing."),
          tags$div("Install with:"),
          tags$pre(
            style = "background:white; padding:8px; border-radius:6px;",
            paste0(
              "install.packages(c(",
              paste0('"', required_pkgs, '"', collapse = ", "),
              "))"
            )
          )
        )
      } else {
        tags$div(
          style = "margin-top:10px; color:#2e7d32; font-size:13px;",
          tags$b("All required packages are installed.")
        )
      }
    )
  })
  
  
  
  output$roadmap_ui <- renderUI({
    
    required_pkgs <- c(
      "shiny", "ggplot2", "forecast", "lubridate", "zoo",
      "tseries", "urca", "DT", "scales"
    )
    
    optional_pkgs <- c(
      "readxl", "colourpicker", "patchwork", "gridExtra",
      "shinythemes", "shinyjs", "nortest", "FinTS"
    )
    
    # Helper for roadmap items with icons
    step_li <- function(ic, title_bold, rest_text) {
      tags$li(
        tags$span(icon(ic), style = "margin-right:8px; color:#2c3e50;"),
        tags$b(title_bold),
        HTML(paste0(": ", rest_text))
      )
    }
    
    tags$div(
      
      # =========================
      # Box 1: Roadmap steps
      # =========================
      tags$div(
        style = "background:#f7f7f7;padding:12px;border-radius:8px;margin-bottom:10px;",
        tags$h4("Roadmap (what students do, what they write)"),
        tags$ol(
          step_li("database",      "Describe the data",   "sample size, missing values, descriptive statistics."),
          step_li("chart-line",    "Explore visually",    "trend/seasonality/outliers; report observations."),
          step_li("layer-group",   "Decompose",           "justify additive vs multiplicative; use STL when robust needed."),
          step_li("check-circle",  "Check stationarity",  "ADF/KPSS/PP; justify differencing (d and D)."),
          step_li("robot",         "Fit a baseline model","Auto-ARIMA to obtain a strong starting SARIMA."),
          step_li("sliders-h",     "Fit a theory-driven model","Manual SARIMA using ACF/PACF + tests."),
          step_li("stethoscope",   "Diagnose & compare",  "residual tests + forecast accuracy; choose final model."),
          step_li("file-alt",      "Write your paper",    "use APA paragraphs in each step; assemble Methods/Results.")
        ),
        tags$br(),
      ),
      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Diagramme complet — analyse SARIMA (workflow)")),
        grVizOutput("sarima_workflow", height = "2500px")
      ),
      
      # =========================
      # Box 2: Package status (below roadmap)
      # =========================
      # tags$div(
      #   style = "background:#eef5ff;padding:12px;border-radius:8px;",
      #   tags$h4("R environment check"),
      #   tags$p(
      #     style = "margin-top:-6px; font-size: 13px; color:#34495e;",
      #     "✅ installed  •  ❌ missing"
      #   ),
      # 
      #   tags$br(),
      # 
      #   fluidRow(
      # 
      #     # =========================
      #     # LEFT: Required packages
      #     # =========================
      #     column(
      #       width = 2,
      #       tags$b("Required packages"),
      #       tags$ul(lapply(required_pkgs, pkg_status_li))
      #     ),
      # 
      #     # =========================
      #     # RIGHT: Optional packages
      #     # =========================
      #     column(
      #       width = 2,
      #       tags$b("Optional packages"),
      #       tags$ul(lapply(optional_pkgs, pkg_status_li))
      #     )
      #   ),
      # 
      #   # Optional warning if required packages missing
      #   if (any(!vapply(required_pkgs, has_pkg, logical(1)))) {
      #     tags$div(
      #       style = "margin-top:10px; color:#b71c1c; font-size:13px;",
      #       tags$b("Some required packages are missing."),
      #       tags$div("Install with:"),
      #       tags$pre(
      #         style = "background:white; padding:8px; border-radius:6px;",
      #         paste0(
      #           "install.packages(c(",
      #           paste0('"', required_pkgs, '"', collapse = ", "),
      #           "))"
      #         )
      #       )
      #     )
      #   } else NULL
      # )
      
      
      
      # tags$div(
      #   style = "background:#eef5ff;padding:12px;border-radius:8px;",
      #   tags$h4("R environment check"),
      #   tags$p(
      #     style = "margin-top:-6px; font-size: 13px; color:#34495e;",
      #     "✅ installed  •  ❌ missing"
      #   ),
      #   
      #   tags$b("Required packages"),
      #   tags$ul(lapply(required_pkgs, pkg_status_li)),
      #   
      #   tags$b("Optional packages"),
      #   tags$ul(lapply(optional_pkgs, pkg_status_li)),
      #   
      #   # Optional install hint (only if required missing)
      #   if (any(!vapply(required_pkgs, has_pkg, logical(1)))) {
      #     tags$div(
      #       style = "margin-top:10px; color:#b71c1c; font-size: 13px;",
      #       tags$b("Some required packages are missing."),
      #       tags$div("Install with:"),
      #       tags$pre(
      #         style = "background:white; padding:8px; border-radius:6px;",
      #         paste0(
      #           "install.packages(c(",
      #           paste0('"', required_pkgs, '"', collapse = ", "),
      #           "))"
      #         )
      #       )
      #     )
      #   } else NULL
      # )
    )
  })
  
  
  
  note_box <- function(items) {
    if (!isTRUE(input$show_teaching_notes)) return(NULL)
    tags$div(
      style = "background:#eef5ff;padding:10px;border-radius:6px;margin-bottom:10px;",
      tags$b("What to do:"),
      tags$ul(lapply(items, tags$li))
    )
  }

  output$step1_notes <- renderUI({ note_box(list(
    "Check the data preview; confirm correct date/value columns.",
    "Describe missingness and how you handled it.",
    "Report mean/SD and distribution shape (skewness/kurtosis)."
  ))})

  output$step2_notes <- renderUI({ note_box(list(
    "Inspect trend and seasonality in the time series plot.",
    "Use seasonal/subseries plots to justify seasonality.",
    "Use ACF/PACF to propose candidate SARIMA orders."
  ))})

  output$step3_notes <- renderUI({ note_box(list(
    "Compare additive vs multiplicative decomposition.",
    "Use STL (robust) if you suspect outliers or changing seasonality.",
    "Interpret trend/seasonal/remainder components."
  ))})

  output$step4_notes <- renderUI({ note_box(list(
    "Run stationarity tests (ADF/KPSS/PP).",
    "Use suggested differencing as hints, not rules.",
    "Preview differenced series to confirm stationarity visually."
  ))})

  output$step5_notes <- renderUI({ note_box(list(
    "Fit Auto-ARIMA as a baseline.",
    "Report selected (p,d,q)(P,D,Q)[s] and key diagnostics.",
    "Evaluate forecast accuracy on the test set (if available)."
  ))})

  output$step6_notes <- renderUI({ note_box(list(
    "Select orders guided by ACF/PACF and differencing evidence.",
    "Check residual diagnostics: white-noise residuals are expected.",
    "Compare with Auto-ARIMA to justify your final choice.",
    "IMPORTANT: With a test set, the validation forecast is forced to h = test length (overlays the test period)."
  ))})

  output$step7_notes <- renderUI({ note_box(list(
    "Compare models using AICc/BIC and test-set accuracy (if available).",
    "Use Methods/Results drafts as a starting point; edit for your dataset.",
    "Use the Checklist to avoid common reporting omissions."
  ))})

  output$paper_checklist_ui <- renderUI({
    tags$div(
      tags$h4("Paper checklist (SARIMA reporting essentials)"),
      tags$ul(
        tags$li("Data: variable, unit, frequency, time range, N."),
        tags$li("Missing values: amount and handling approach."),
        tags$li("Exploration: plots + seasonality indicators + ACF/PACF rationale."),
        tags$li("Stationarity: ADF/KPSS/PP results and differencing decisions."),
        tags$li("Model: (p,d,q)(P,D,Q)[s], software, estimation method."),
        tags$li("Diagnostics: Ljung-Box (+ normality/ARCH if reported)."),
        tags$li("Forecast evaluation: horizon, metrics, interpretation.")
      )
    )
  })

  # ---- Data ingest ----

  raw_data <- reactive({
    req(input$fileData)
    ext <- tolower(tools::file_ext(input$fileData$name))
    if (ext == "csv") {
      read.csv(input$fileData$datapath, stringsAsFactors = FALSE, check.names = FALSE)
    } else if (ext %in% c("xls", "xlsx")) {
      validate(need(has_pkg("readxl"), "Install package 'readxl' to read Excel files."))
      readxl::read_excel(input$fileData$datapath)
    } else {
      validate("Unsupported file type. Use CSV or XLSX.")
    }
  })

  output$dateColUI <- renderUI({
    req(raw_data())
    cols <- names(raw_data())
    selectInput("dateCol", "Date column", choices = cols, selected = cols[1])
  })

  output$valueColUI <- renderUI({
    req(raw_data())
    cols <- names(raw_data())
    selectInput("valueCol", "Value column", choices = cols, selected = cols[min(2, length(cols))])
  })

  
  # ============================================================
  # --- MOD: Use robust date parsing inside prepared() ---
  # ============================================================
  prepared <- reactive({
    req(raw_data(), input$dateCol, input$valueCol)
    
    f <- freq_value(input)
    by <- freq_to_by(f)
    
    df <- raw_data()
    
    # MOD: robust conversion to Date
    d <- parse_dates(df[[input$dateCol]])
    
    y <- suppressWarnings(as.numeric(df[[input$valueCol]]))
    
    keep <- !is.na(d)
    df2 <- data.frame(date = as.Date(d[keep]), y_raw = y[keep])
    df2 <- df2[order(df2$date), , drop = FALSE]
    
    if (isTRUE(input$align_regular) && !is.null(by)) {
      grid <- make_regular_grid(df2$date, by = by)
      df2 <- merge(data.frame(date = grid), df2, by = "date", all.x = TRUE, sort = TRUE)
    }
    
    df2$y_filled <- fill_missing(df2$y_raw, input$missing_policy, f)
    
    df2$y_trans <- tryCatch(
      apply_transform(df2$y_filled, input$transform, input$lambda),
      error = function(e) { validate(e$message); df2$y_filled }
    )
    
    # MOD: If we have a Date-based grid, use Date on x
    if (!is.null(by)) {
      df2$x <- df2$date
      x_label <- "Date"
    } else {
      df2$x <- seq_len(nrow(df2))
      x_label <- "Index"
    }
    
    list(df = df2, freq = f, by = by, x_label = x_label)
  })
  
  

  # ============================================================
  # --- MOD: Fix Train split = 100% (no test set) bug in ts_train_test() ---
  # Reason: ts(numeric(0)) is invalid in R ("ts must have at least one observation")
  # Fix: store ts_test = NULL when there is no test set, and guard all downstream uses.
  # ============================================================
  ts_train_test <- reactive({
    p <- prepared()
    df <- p$df
    
    ok <- is.finite(df$y_trans)
    dfm <- df[ok, , drop = FALSE]
    validate(need(nrow(dfm) >= 10, "Not enough valid observations after cleaning."))
    
    train_n <- max(2, floor(nrow(dfm) * as.numeric(input$train_prop)))
    train_n <- min(train_n, nrow(dfm)) # MOD: hard cap so train_n never exceeds n
    
    y_tr <- dfm$y_trans[seq_len(train_n)]
    y_te <- if (train_n < nrow(dfm)) dfm$y_trans[(train_n + 1):nrow(dfm)] else numeric(0)
    
    list(
      dfm = dfm,
      train_n = train_n,
      test_n = length(y_te),
      ts_train = ts(y_tr, start = 1, frequency = p$freq),
      
      # --- MOD: when test is empty, keep it NULL (do NOT create ts(numeric(0))) ---
      ts_test = if (length(y_te) > 0) {
        ts(y_te, start = train_n + 1, frequency = p$freq)
      } else {
        NULL
      }
    )
  })
  
  # ============================================================
  # --- MOD: Helper to safely reconstruct the full series (train + test) ---
  # Used in plots requiring the full observed sample.
  # ============================================================
  full_ts <- function(s) {
    if (!is.null(s$ts_test) && length(s$ts_test) > 0) {
      ts(
        c(as.numeric(s$ts_train), as.numeric(s$ts_test)),
        start = 1,
        frequency = frequency(s$ts_train)
      )
    } else {
      s$ts_train
    }
  }
  
  # ============================================================
  # --- MOD: Replace all "ts(c(train, test))" calls by full_ts(s) ---
  # This prevents errors when train_prop = 1 (test set absent).
  # ============================================================
  
  output$season_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Seasonal plots need frequency >= 2."))
    forecast::seasonplot(x, s = frequency(x))
  })
  
  output$subseries_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Subseries plot needs frequency >= 2."))
    forecast::ggsubseriesplot(x) + theme_minimal()
  })
  
  output$decomp_add <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    plot(decompose(x, type = "additive"))
  })
  
  output$decomp_mult <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    validate(need(all(x > 0, na.rm = TRUE), "Multiplicative decomposition requires strictly positive values."))
    plot(decompose(x, type = "multiplicative"))
  })
  
  output$diff_suggestion <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    d_rec <- tryCatch(forecast::ndiffs(x), error = function(e) NA_integer_)
    D_rec <- tryCatch(forecast::nsdiffs(x), error = function(e) NA_integer_)
    cat("Suggested differencing (heuristics):\n")
    cat("- ndiffs (d):", d_rec, "\n")
    cat("- nsdiffs (D):", D_rec, "\n")
  })
  
  
  
  # ---- Step 1 outputs ----
  
  
  # ============================================================
  # --- MOD: display Date columns as readable strings in the preview table ---
  # ============================================================
  
  # output$full_data_table <- DT::renderDataTable({
  #   req(raw_data())
  #   
  #   df <- raw_data()
  #   
  #   # optional: make Date/POSIX columns print nicely
  #   for (nm in names(df)) {
  #     if (inherits(df[[nm]], "Date")) df[[nm]] <- format(df[[nm]], "%Y-%m-%d")
  #     if (inherits(df[[nm]], "POSIXt")) df[[nm]] <- format(df[[nm]], "%Y-%m-%d %H:%M:%S")
  #   }
  #   
  #   DT::datatable(
  #     df,
  #     rownames = FALSE,
  #     filter = "top",
  #     extensions = c("Scroller"),
  #     options = list(
  #       deferRender = TRUE,
  #       scrollX = TRUE,
  #       scrollY = 520,
  #       scroller = TRUE,
  #       pageLength = 25,
  #       lengthMenu = list(c(10, 25, 50, 100, -1), c("10", "25", "50", "100", "All"))
  #     )
  #   )
  # })
  
  output$full_data_table <- DT::renderDataTable({
    req(raw_data())
    
    df <- raw_data()
    
    # ✅ Force Date & POSIX columns to Day-Month-Year
    for (nm in names(df)) {
      if (inherits(df[[nm]], "Date")) {
        df[[nm]] <- format(df[[nm]], "%d-%m-%Y")
      }
      if (inherits(df[[nm]], "POSIXt")) {
        df[[nm]] <- format(df[[nm]], "%d-%m-%Y %H:%M:%S")
      }
    }
    
    DT::datatable(
      df,
      rownames = FALSE,
      filter = "top",
      extensions = "Scroller",
      options = list(
        deferRender = TRUE,
        scrollX = TRUE,
        scrollY = 520,
        scroller = TRUE,
        pageLength = 25,
        lengthMenu = list(
          c(10, 25, 50, 100, -1),
          c("10", "25", "50", "100", "All")
        )
      )
    )
  })
  
  
  
  output$data_preview <- renderTable({
    req(prepared())
    # df <- head(prepared()$df, 12)
    df <- prepared()$df
    
    # MOD: ensure Date columns print nicely (Shiny sometimes prints Date as numeric)
    for (nm in intersect(c("date", "x"), names(df))) {
      if (inherits(df[[nm]], "Date")) df[[nm]] <- format(df[[nm]], "%Y-%m-%d")
    }
    
    df
  }, rownames = FALSE)
  
  output$basic_stats <- renderTable({
    req(prepared())
    basic_stats_df(prepared()$df$y_filled)
  }, rownames = FALSE)
  
  output$hist_plot <- renderPlot({
    req(prepared())
    df <- prepared()$df
    
    ggplot(df, aes(x = y_filled)) +
      geom_histogram(bins = 30) +
      theme_minimal() +
      labs(title = "Distribution (filled values)", x = "Value", y = "Count")
  })
  

  # output$data_preview <- renderTable({ req(prepared()); head(prepared()$df, 12) }, rownames = FALSE)
  
  
  # output$basic_stats <- renderTable({ req(prepared()); basic_stats_df(prepared()$df$y_filled) }, rownames = FALSE)

  # output$hist_plot <- renderPlot({
  #   req(prepared())
  #   df <- prepared()$df
  #   ggplot(df, aes(x = y_filled)) +
  #     geom_histogram(bins = 30) +
  #     theme_minimal() +
  #     labs(title = "Distribution (filled values)", x = "Value", y = "Count")
  # })

  output$missing_text <- renderPrint({
    req(prepared())
    p <- prepared()
    df <- p$df
    n <- nrow(df)
    miss_raw <- sum(is.na(df$y_raw))
    cat("Missing values\n")
    cat("- N rows:", n, "\n")
    cat("- Missing in raw y:", miss_raw, " (", fmt_pct(miss_raw / n), ")\n", sep = "")
    cat("- Handling method:", input$missing_policy, "\n")
    cat("- Date range:", format(min(df$date)), "to", format(max(df$date)), "\n")
  })

  output$outlier_table <- renderTable({
    req(prepared())
    df <- prepared()$df
    idx <- z_outliers(df$y_filled, z_cut = 3)
    if (length(idx) == 0) return(data.frame(message = "No |z| ≥ 3 outliers detected (filled values)."))
    data.frame(index = idx, date = df$date[idx], value = df$y_filled[idx], stringsAsFactors = FALSE)
  }, rownames = FALSE)

  output$apa_data_paragraph <- renderPrint({
    req(prepared())
    p <- prepared()
    df <- p$df
    n <- nrow(df)
    miss_raw <- sum(is.na(df$y_raw))
    miss_pct <- miss_raw / n
    trans <- switch(input$transform, none = "no transformation", log = "a log transformation", boxcox = "a Box–Cox transformation")
    cat(
      "APA-ready paragraph (edit variable names/unit as needed):\n\n",
      "The dataset comprised ", n, " observations collected from ", format(min(df$date)), " to ", format(max(df$date)), ". ",
      "Missing values were present in ", miss_raw, " observations (", fmt_pct(miss_pct), "). ",
      "Missingness was handled using the ", input$missing_policy, " approach. ",
      "Prior to modeling, ", trans, " was applied to the series when appropriate.\n",
      sep = ""
    )
  })

  # ---- Step 2 outputs ----
  
  output$plot_series <- renderPlot(
    {
      req(prepared(), ts_train_test())
      p <- prepared()
      s <- ts_train_test()
      df <- s$dfm
      df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test/Future")
      
      ggplot(df, aes(x = x, y = y_trans, color = set)) +
        geom_line(linewidth = 0.9) +
        theme_minimal() +
        labs(
          title = "Time series (transformed)",
          x = p$x_label,
          y = "Value",
          color = NULL
        ) +
        theme(legend.position = "bottom")
    },
    width = 1000,
    height = 650
  )

  # output$plot_series <- renderPlot({
  #   req(prepared(), ts_train_test())
  #   p <- prepared()
  #   s <- ts_train_test()
  #   df <- s$dfm
  #   df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test/Future")
  #   ggplot(df, aes(x = x, y = y_trans, color = set)) +
  #     geom_line(linewidth = 0.9) +
  #     theme_minimal() +
  #     labs(title = "Time series (transformed)", x = p$x_label, y = "Value", color = NULL) +
  #     theme(legend.position = "bottom")
  # })

  # output$season_plot <- renderPlot({
  #   req(ts_train_test())
  #   s <- ts_train_test()
  #   x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
  #   validate(need(frequency(x) >= 2, "Seasonal plots need frequency >= 2."))
  #   forecast::seasonplot(x, s = frequency(x))
  # })

  # output$subseries_plot <- renderPlot({
  #   req(ts_train_test())
  #   s <- ts_train_test()
  #   x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
  #   validate(need(frequency(x) >= 2, "Subseries plot needs frequency >= 2."))
  #   forecast::ggsubseriesplot(x) + theme_minimal()
  # })

  output$acf_plot <- renderPlot({ req(ts_train_test()); x <- ts_train_test()$ts_train; plot(acf(x, lag.max = min(60, length(x) - 1)), main = "ACF (training)") })
  output$pacf_plot <- renderPlot({ req(ts_train_test()); x <- ts_train_test()$ts_train; plot(pacf(x, lag.max = min(60, length(x) - 1)), main = "PACF (training)") })

  output$apa_explore_paragraph <- renderPrint({
    req(prepared())
    p <- prepared()
    cat(
      "APA-ready paragraph (edit based on what you observed):\n\n",
      "Visual inspection of the time series suggested the presence of trend and/or seasonal patterns. ",
      "Seasonal and subseries plots were examined to evaluate recurring periodic behavior (s = ", p$freq, "). ",
      "Autocorrelation (ACF) and partial autocorrelation (PACF) plots were inspected to inform candidate ARIMA and seasonal ARIMA orders.\n",
      sep = ""
    )
  })

  
  
  
  
  
  
  
  
  
  
  
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  
  
  
  
  
  # server.R
  # library(DiagrammeR)  # ou utiliser DiagrammeR:: partout
  
  
  output$sarima_workflow <- renderGrViz({
    grViz("
          digraph sarima_workflow {
          
            graph [rankdir=TB, bgcolor='white', fontname='Helvetica'];
            node  [shape=box, style='rounded,filled', color='#2c3e50', fillcolor='#f7f9fb',
                   fontname='Helvetica', fontsize=11];
            edge  [color='#34495e', fontname='Helvetica', fontsize=10];
          
            // =======================
            // 0) Départ
            // =======================
            start [label='DÉPART\\nObjectif : prévoir y_t avec un SARIMA interprétable\\n+ diagnostics OK + performance > benchmark', fillcolor='#ecf0f1'];
          
            // =======================
            // 1) Données & index
            // =======================
            data [label='1) Données\\n- Définir y_t (unité, source)\\n- Vérifier période & fréquence (s)\\n- Index temporel : régulier, doublons, ordre\\n- Horizon de prévision (h)', fillcolor='#e8f8f5'];
            miss [label='2) Manquants & qualité\\n- Quantifier k et k/n\\n- Choisir traitement (drop/linéaire/saisonnier/Kalman)\\n- Documenter', fillcolor='#e8f8f5'];
            outliers [label='3) Outliers & ruptures\\n- Repérage visuel\\n- Hypothèse (réel vs erreur)\\n- Décision (garder/corriger/imputer)\\n- Impact sur modèle', fillcolor='#e8f8f5'];
          
            // =======================
            // 2) EDA
            // =======================
            eda [label='4) EDA (exploration)\\n- Courbe y_t\\n- Seasonal plot / subseries\\n- Boxplots par saison\\n- Variance vs niveau\\n- ACF/PACF brutes (indicatif)', fillcolor='#fdebd0'];
          
            // =======================
            // 3) Transformations
            // =======================
            q_transform [label='Variance augmente avec le niveau ?\\n(erreur relative, saison multiplicative)', fillcolor='#fef9e7'];
            transform [label='5) Transformation\\n- Niveaux\\n- Log\\n- Box-Cox (λ)\\nObjectif : stabiliser variance, rendre additif', fillcolor='#fdebd0'];
          
            // =======================
            // 4) Stationnarité & différenciation
            // =======================
            station_tests [label='6) Stationnarité\\n- Tests : ADF + PP + KPSS\\n- Saison : HEGY (si besoin)\\n- Rupture : Zivot–Andrews (si suspectée)', fillcolor='#fdebd0'];
          
            q_need_diff [label='Non-stationnaire ?\\n(ADF/PP ne rejettent pas ET KPSS rejette)', fillcolor='#fef9e7'];
            diff_d [label='7) Différenciation non saisonnière\\nAppliquer d (souvent 0 ou 1)\\n(1-B)^d', fillcolor='#fdebd0'];
            diff_D [label='8) Différenciation saisonnière\\nAppliquer D (souvent 0 ou 1)\\n(1-B^s)^D', fillcolor='#fdebd0'];
          
            q_overdiff [label='Sur-différenciation ?\\nACF lag1 très négative\\nvariance gonflée, prévisions erratiques', fillcolor='#f5eef8'];
            backtrack [label='Revenir en arrière\\nRéduire d ou D\\n(chercher différenciation minimale)', fillcolor='#f5eef8'];
          
            // =======================
            // 5) Identification (p,q,P,Q)
            // =======================
            identify [label='9) Identification (p,q,P,Q)\\n- ACF/PACF sur série différenciée\\n- Repérer coupures / décroissances\\n- Saison : pics aux lags multiples de s\\n- Proposer candidats', fillcolor='#d6eaf8'];
          
            auto [label='10) Modèle baseline\\nAuto-ARIMA (benchmark SARIMA)\\nComparer AICc/BIC + diagnostics', fillcolor='#d6eaf8'];
          
            // =======================
            // 6) Estimation
            // =======================
            estimate [label='11) Estimation\\n- MLE (ou CSS+MLE)\\n- Coefficients ± SE, z, p\\n- Vérifier contraintes (stationnarité/inversibilité)', fillcolor='#d6eaf8'];
          
            // =======================
            // 7) Diagnostics
            // =======================
            diag [label='12) Diagnostics résiduels\\n- Résidus ~ bruit blanc\\n- ACF résidus\\n- Ljung–Box\\n- Normalité (optionnel)\\n- ARCH/variance (optionnel)', fillcolor='#fadbd8'];
          
            q_diag_ok [label='Diagnostics OK ?\\n(Ljung–Box non sig., pas de structure)', fillcolor='#fef9e7'];
            refine [label='Ajuster le modèle\\n- Revoir p,q,P,Q\\n- Revoir d/D (si sous/sur-diff)\\n- Revoir transformation\\n- Ajouter dummies (rupture/outliers)', fillcolor='#fadbd8'];
          
            // =======================
            // 8) Validation & choix final
            // =======================
            validate [label='13) Validation hors-échantillon\\n- Train/Test ou rolling-origin\\n- Comparer à benchmark (naïf/snaïve/drift)\\n- Métriques : MAE, RMSE (+ MASE/WAPE)', fillcolor='#e8f8f5'];
          
            q_beats_benchmark [label='Meilleur que benchmark ?\\n(et parcimonieux)', fillcolor='#fef9e7'];
            choose [label='14) Choix final\\n- Modèle le plus simple\\n- Performance comparable ou meilleure\\n- Diagnostics satisfaisants', fillcolor='#e8f8f5'];
          
            // =======================
            // 9) Prévisions & reporting
            // =======================
            forecast [label='15) Prévision\\n- Horizon h\\n- Point + intervalles (80/95%)\\n- Visualisation + table\\n- Interprétation métier', fillcolor='#ecf0f1'];
          
            report [label='16) Reporting (papier / APA)\\n- Données (n, période, s, manquants)\\n- Transformations & différences (d,D)\\n- Modèle (p,d,q)(P,D,Q)[s]\\n- Diagnostics\\n- Validation + métriques\\n- Conclusion', fillcolor='#ecf0f1'];
          
            end [label='FIN\\nSARIMA validé + justifié', fillcolor='#ecf0f1'];
          
            // =======================
            // Flow
            // =======================
            start -> data -> miss -> outliers -> eda -> q_transform;
            q_transform -> transform [label='Oui'];
            q_transform -> station_tests [label='Non / variance stable'];
            transform -> station_tests;
          
            station_tests -> q_need_diff;
          
            q_need_diff -> diff_d [label='Oui (non saisonnier)'];
            q_need_diff -> diff_D [label='Oui (saisonnier)'];
            q_need_diff -> identify [label='Non (stationnaire)'];
          
            diff_d -> diff_D [label='si saisonnalité'];
            diff_D -> q_overdiff;
          
            q_overdiff -> backtrack [label='Oui'];
            q_overdiff -> identify [label='Non'];
            backtrack -> station_tests;
          
            identify -> auto -> estimate -> diag -> q_diag_ok;
          
            q_diag_ok -> refine [label='Non'];
            q_diag_ok -> validate [label='Oui'];
          
            refine -> estimate;
          
            validate -> q_beats_benchmark;
            q_beats_benchmark -> choose [label='Oui'];
            q_beats_benchmark -> refine [label='Non (améliorer)'];
          
            choose -> forecast -> report -> end;
          
          }
      ")
  })

  output$pdqpDQ_tree <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
                digraph pdqpDQ_tree {

                  graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                         label = 'Choisir p, d, q, P, D, Q : workflow SARIMA (critères → actions)',
                         fontname = Helvetica, bgcolor = 'transparent',
                         nodesep = 0.35, ranksep = 0.45]

                  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                         fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                  edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]

                  start [shape = circle, label = 'Départ', fillcolor = '#d6eaf8']
                  end   [shape = doublecircle, label = 'Modèle final\\n(parcimonieux + valide)', fillcolor = '#d5f5e3']

                  s0 [label = '0) Fixer la saisonnalité s\\n(à partir du contexte + EDA)']

                  d0 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                      label = '1) Choisir d et D\\n(stationnarité : ADF/KPSS/PP\\n+ ACF aux multiples de s)']
                  actd [label = 'Action :\\n• appliquer la différenciation minimale\\n• vérifier sur-diff (ACF lag1 très négative)\\n• retester si besoin']

                  acf0 [label = '2) Tracer ACF/PACF\\nSUR la série différenciée\\n(après d et D)\\n+ regarder aux lags 1.. et s,2s,…']

                  d1 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                      label = '3) Motifs ACF/PACF suggèrent\\nAR vs MA ?\\n(non-saisonnier et saisonnier)']

                  hint [label = 'Rappels (heuristiques) :\\n• AR(p) : PACF coupure, ACF décroît\\n• MA(q) : ACF coupure, PACF décroît\\n• Saison : pics à s,2s,…\\n  PACF → P ; ACF → Q']

                  cand [label = '4) Proposer un petit ensemble de candidats\\n(3 à 8 modèles)\\njustifier p,q,P,Q\\n(y compris aux multiples de s)']

                  fit [label = '5) Ajuster chaque candidat\\n(p,d,q)(P,D,Q)[s]\\n+ relever AICc/BIC\\n+ vérifier stabilité/inversibilité si possible']

                  d2 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                      label = '6) Problèmes numériques ?\\n(non-inversible / non-stationnaire\\nconvergence instable)']
                  act2 [label = 'Actions :\\n• simplifier p/q/P/Q\\n• revoir d/D (sur-diff ?)\\n• transformer (log/Box–Cox)\\n• traiter outliers/manquants\\n• changer méthode/initialisation']

                  diag [label = '7) Diagnostics résiduels\\nACF résidus + Ljung–Box\\n+ normalité/ARCH (secondaire)']

                  d3 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                      label = '8) Résidus ~ bruit blanc ?\\n(Ljung–Box OK + ACF résidus ≈ 0)']
                  act3 [label = 'Actions :\\n• ajuster p/q/P/Q\\n• ajouter saison si pics à s\\n• revoir d/D\\n• re-EDA (rupture/outliers)']

                  perf [label = '9) Évaluation prévisionnelle\\nSplit temporel / rolling-origin\\nMAE/RMSE/MASE\\nvs benchmark (naïf/SNAIVE)']

                  d4 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                      label = '10) Bat le benchmark\\nET performance stable ?']
                  act4 [label = 'Actions :\\n• simplifier / régulariser\\n• revoir candidats\\n• si aucun gain : garder benchmark\\n• ajuster horizon h / fenêtre']

                  choose [label = '11) Choix final\\n• retenir le plus simple\\n  qui passe diagnostics\\n  ET bat le benchmark\\n• comparer AICc/BIC à performance comparable\\n• documenter justification']

                  start -> s0 -> d0
                  d0 -> actd [label = 'itérer si besoin', color = '#34495e', fontcolor = '#34495e']
                  actd -> acf0
                  d0 -> acf0 [label = 'd & D fixés', color = '#1e8449', fontcolor = '#1e8449']

                  acf0 -> d1 -> hint -> cand -> fit -> d2
                  d2 -> act2 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                  act2 -> cand
                  d2 -> diag [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

                  diag -> d3
                  d3 -> act3 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
                  act3 -> cand
                  d3 -> perf [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']

                  perf -> d4
                  d4 -> act4 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
                  act4 -> cand
                  d4 -> choose [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']

                  choose -> end
                }
              ")
  }) 
  
  output$stationarity_tree <- renderGrViz({
    grViz("
          digraph stationarity_tree {
          
            graph [rankdir=TB, bgcolor='white', fontname='Helvetica'];
            node  [shape=box, style='rounded,filled', color='#2c3e50', fillcolor='#f7f9fb',
                   fontname='Helvetica', fontsize=11];
            edge  [color='#34495e', fontname='Helvetica', fontsize=10];
          
            start [label='Départ\\n(EDA + contexte + ACF/PACF)'];
          
            q_season [label='Saisonnalité marquée\\net possiblement stochastique ?'];
            hegy [label='Faire HEGY\\n(racines unitaires saisonnières)'];
            hegy_yes [label='HEGY indique racine\\nunitaire saisonnière'];
            act_D1 [label='Action : appliquer\\nDiff saisonnière D = 1\\nPuis retester ADF/PP/KPSS'];
            hegy_no [label='Pas de racine\\nunitaire saisonnière claire'];
          
            q_break [label='Rupture structurelle\\nvisible/suspectée ?\\n(crise, réforme, choc)'];
            za [label='Faire Zivot–Andrews\\n(racine unitaire + rupture endogène)'];
            za_reject [label='ZA rejette H0\\n=> stationnarité avec rupture'];
            act_dummy [label='Action : d = 0\\n+ dummy(s) de rupture\\n(ou modèle avec tendance déterministe)'];
            za_noreject [label='ZA ne rejette pas\\n=> racine unitaire possible'];
          
            tests [label='Lancer ADF + PP + KPSS\\n(sur la série actuelle)'];
          
            case_stationary [label='ADF rejette & PP rejette\\nET KPSS ne rejette pas', fillcolor='#e8f8f5'];
            act_d0 [label='Conclusion : stationnaire\\nAction : d = 0', fillcolor='#e8f8f5'];
          
            case_i1 [label='ADF ne rejette pas & PP ne rejette pas\\nET KPSS rejette', fillcolor='#fdebd0'];
            act_d1 [label='Conclusion : I(1) probable\\nAction : d = 1\\nPuis retester', fillcolor='#fdebd0'];
          
            case_conflict1 [label='ADF/PP rejettent\\nmais KPSS rejette aussi\\n(ou résultats mixtes)', fillcolor='#fef9e7'];
            act_conflict1 [label='Action :\\n- vérifier spécification (constante/tendance)\\n- regarder ACF + plots\\n- tester après d=1\\n- choisir parcimonie', fillcolor='#fef9e7'];
          
            case_conflict2 [label='ADF/PP ne rejettent pas\\nmais KPSS ne rejette pas\\n(test peu informatif)', fillcolor='#fef9e7'];
            act_conflict2 [label='Action :\\n- EDA + ACF\\n- essayer d=1 puis retester\\n- privilégier solution minimale', fillcolor='#fef9e7'];
          
            q_overdiff [label='Après différenciation\\nACF lag 1 très négative\\nou prévisions erratiques ?', fillcolor='#f5eef8'];
            act_overdiff [label='Sur-différenciation probable\\nAction : revenir en arrière\\n(d ou D trop grand)', fillcolor='#f5eef8'];
          
            end [label='Fin\\n(choix final d, D justifiés\\n+ diagnostics résiduels)', fillcolor='#ecf0f1'];
          
            // Flow
            start -> q_season;
            q_season -> hegy [label='Oui'];
            q_season -> q_break [label='Non'];
          
            hegy -> hegy_yes [label='Détectée'];
            hegy -> hegy_no  [label='Non détectée'];
            hegy_yes -> act_D1 -> q_break;
            hegy_no  -> q_break;
          
            q_break -> za [label='Oui'];
            q_break -> tests [label='Non'];
          
            za -> za_reject [label='Rejet H0'];
            za -> za_noreject [label='Non-rejet H0'];
            za_reject -> act_dummy -> tests;
            za_noreject -> tests;
          
            tests -> case_stationary;
            tests -> case_i1;
            tests -> case_conflict1;
            tests -> case_conflict2;
          
            case_stationary -> act_d0 -> q_overdiff;
            case_i1 -> act_d1 -> q_overdiff;
            case_conflict1 -> act_conflict1 -> q_overdiff;
            case_conflict2 -> act_conflict2 -> q_overdiff;
          
            q_overdiff -> act_overdiff [label='Oui'];
            q_overdiff -> end [label='Non'];
            act_overdiff -> tests;
          
          }
      ")
  })
  
  output$stationarity_tree2 <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
                digraph stationarity_tree2 {

                  graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                         label = 'Stationnarité & différenciation : ADF / KPSS / PP → choix de d et D',
                         fontname = Helvetica, bgcolor = 'transparent',
                         nodesep = 0.35, ranksep = 0.45]

                  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                         fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                  edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]

                  start [shape = circle, label = 'Départ', fillcolor = '#d6eaf8']
                  end   [shape = doublecircle, label = 'Décision\\n(d, D) validée', fillcolor = '#d5f5e3']

                  prep [label = 'Préparer la série\\n• fréquence s définie\\n• manquants traités\\n• transformation (log/Box–Cox) si besoin\\n• EDA (tendance / saisonnalité)']

                  spec [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                        label = 'Choisir spécification des tests\\n(constante ? tendance ?)']

                  noteSpec [label = 'Règle :\\n• si tendance visible → inclure tendance (trend)\\n• sinon drift / constante\\n• éviter ‘none’ sauf justification']

                  test0 [label = 'Tester sur la série brute\\nADF + PP (H0 : racine unitaire)\\nKPSS (H0 : stationnaire)']

                  dStrongS [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                            label = 'Stationnarité forte ?\\nADF/PP rejettent (p petit)\\nET KPSS ne rejette pas (p grand)']

                  actS [label = 'Action :\\n• d = 0\\n• vérifier saisonnalité (D ?)\\n• passer au test saisonnier']

                  dStrongNS [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                             label = 'Non-stationnarité forte ?\\nADF/PP ne rejettent pas (p grand)\\nET KPSS rejette (p petit)']

                  actNS [label = 'Action :\\n• essayer d = 1\\n• retester ADF / PP / KPSS\\n• surveiller sur-diff (ACF lag 1 très négative)']

                  dConflict [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                             label = 'Conflit / cas ambigu ?\\n(ex. ADF rejette mais KPSS rejette aussi\\nou tous non significatifs)']

                  actConflict [label = 'Actions :\\n• reconsidérer trend vs drift\\n• examiner graphiques + ACF\\n• tester après d = 1 puis comparer\\n• suspecter rupture (Zivot–Andrews)\\n• documenter (convergence d’indices)']

                  retest [label = 'Retester après d choisi\\nADF + PP + KPSS\\n(d doit être minimal)']

                  seasCheck [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                             label = 'Racine saisonnière ?\\nIndices : pics ACF à s, 2s…\\n+ KPSS / ADF sur série saisonnière\\n(ou HEGY en annexe)']

                  actSeas [label = 'Action :\\n• essayer D = 1 (diff. saisonnière)\\n• retester stationnarité\\n• D = 2 rarement justifié']

                  overdiff [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
                            label = 'Sur-différenciation suspectée ?\\nACF lag 1 très négative\\nvariance gonflée\\nprévisions erratiques']

                  actOver [label = 'Action :\\n• revenir en arrière (d ou D trop élevé)\\n• préférer tendance déterministe\\n• vérifier spécification des tests']

                  stop [label = 'Stop quand stationnarité raisonnable\\n+ parcimonie\\n(d ∈ {0,1} le plus souvent\\n D ∈ {0,1})']

                  start -> prep -> spec
                  spec -> noteSpec -> test0

                  test0 -> dStrongS
                  dStrongS -> actS      [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                  dStrongS -> dStrongNS [label = 'Non']

                  dStrongNS -> actNS    [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                  dStrongNS -> dConflict[label = 'Non']

                  dConflict -> actConflict [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                  actConflict -> actNS     [label = 'tester d = 1 (prudence)', color = '#7d3c98', fontcolor = '#7d3c98']

                  actNS -> retest
                  actS  -> seasCheck
                  retest -> seasCheck

                  seasCheck -> actSeas [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                  seasCheck -> stop    [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

                  actSeas -> overdiff
                  overdiff -> actOver [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
                  overdiff -> stop    [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

                  actOver -> retest
                  stop -> end
                }
        ")
  })
  
  output$diag_tree <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
              digraph diag_tree {
              
                graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                       label = 'Arbre décisionnel : diagnostics résiduels → actions (SARIMA)',
                       fontname = Helvetica, bgcolor = 'transparent',
                       nodesep = 0.35, ranksep = 0.45]
              
                node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                       fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
              
                start [shape = circle, label = 'Départ', fillcolor = '#d6eaf8']
                end   [shape = doublecircle, label = 'Modèle final\\n(OK)', fillcolor = '#d5f5e3']
              
                fit  [label = 'Ajuster un modèle SARIMA candidat\\n(p,d,q)(P,D,Q)[s]']
                pre  [label = 'Fixer protocole prévision\\nSplit temporel ou rolling-origin\\n+ métriques (MAE/RMSE/MASE) + benchmark']
              
                d1 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = '1) Autocorrélation résiduelle ?\\nACF(res) + Ljung–Box OK']
                a1 [label = 'Actions si échec :\\n• revoir p,q,P,Q\\n• ajuster d/D (sous/sur-diff)\\n• transformation (log/Box–Cox)\\n• outliers / manquants\\n• saisonnalité (s)']
              
                d2 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = '2) Bat le benchmark hors-échantillon ?\\nMAE/RMSE/MASE meilleurs']
                a2 [label = 'Actions si échec :\\n• simplifier (parcimonie)\\n• revoir spécification\\n• si aucun gain : garder benchmark']
              
                d3 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = '3) Performance stable (rolling-origin) ?']
                a3 [label = 'Actions si instable :\\n• réduire complexité\\n• expansive vs glissante\\n• vérifier ruptures/régimes\\n• réévaluer horizon h']
              
                d4 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                    label = '4) Normalité résiduelle problématique ?\\nQQ-plot / Jarque–Bera']
                a4 [label = 'Si objectif = point forecast :\\n• souvent secondaire\\nSi IC/tests importants :\\n• transformation\\n• robustesse / discussion\\n• traiter outliers']
              
                d5 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                    label = '5) Hétéroscédasticité / ARCH forte ?\\nACF(ε²) / test ARCH']
                a5 [label = 'Actions :\\n• discuter variance conditionnelle\\n• transformation\\n• (annexe) GARCH\\n• attention calibration des IC']
              
                d6 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                    label = '6) Coefficients non significatifs ?\\n(est, SE, z, p)']
                a6 [label = 'Actions :\\n• rapporter est ± SE, z, p\\n• supprimer termes non signif\\n  seulement si diagnostics + OOS inchangés\\n• comparer AICc/BIC + nb paramètres']
              
                start -> pre -> fit -> d1
              
                d1 -> a1 [label = 'Non (échec)', color = '#c0392b', fontcolor = '#c0392b']
                a1 -> fit
              
                d1 -> d2 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                d2 -> a2 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
                a2 -> fit
              
                d2 -> d3 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                d3 -> a3 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
                a3 -> fit
              
                d3 -> d4 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
              
                d4 -> a4 [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                a4 -> d5
                d4 -> d5 [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
                d5 -> a5 [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                a5 -> d6
                d5 -> d6 [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
                d6 -> a6 [label = 'Oui', color = '#2471a3', fontcolor = '#2471a3']
                a6 -> end
                d6 -> end [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
              }
        ")
  })
  
  
  output$adf_kpss_pp_tree <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
              digraph adf_kpss_pp_tree {
              
                graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                       label = 'Comment conclure en combinant ADF / KPSS / PP (diagramme pédagogique)',
                       fontname = Helvetica, bgcolor = 'transparent',
                       nodesep = 0.35, ranksep = 0.45]
              
                node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                       fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
              
                start [shape = circle, label = 'Départ', fillcolor = '#d6eaf8']
              
                tests [label = 'Appliquer les tests sur la série brute\\nADF + PP (H0 : racine unitaire)\\nKPSS (H0 : stationnaire)']
              
                d1 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                    label = 'ADF/PP rejettent\\nET KPSS ne rejette pas ?']
                s1 [label = 'Interprétation :\\nConvergence forte\\n→ stationnarité confirmée']
                a1 [label = 'Décision :\\nd = 0\\n(ne pas différencier)']
              
                d2 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = 'ADF/PP ne rejettent pas\\nET KPSS rejette ?']
                s2 [label = 'Interprétation :\\nConvergence forte\\n→ racine unitaire probable']
                a2 [label = 'Décision :\\nEssayer d = 1\\n(puis retester)']
              
                d3 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                    label = 'ADF/PP rejettent\\nET KPSS rejette aussi ?']
                s3 [label = 'Interprétation :\\nStationnarité autour\\nd’une tendance déterministe']
                a3 [label = 'Décision :\\nd = 0 + tendance\\n(éviter différenciation)']
              
                d4 [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
                    label = 'ADF/PP ne rejettent pas\\nET KPSS ne rejette pas ?']
                s4 [label = 'Interprétation :\\nManque de puissance\\nou série très bruitée']
                a4 [label = 'Décision :\\nS’appuyer sur EDA, ACF, contexte\\n(décision argumentée)']
              
                d5 [shape = diamond, style = 'rounded,filled', fillcolor = '#fadbd8',
                    label = 'Résultats instables\\nselon spécification\\n(constante / tendance) ?']
                s5 [label = 'Interprétation :\\nSensibilité au modèle\\nde test']
                a5 [label = 'Décision :\\nComparer plusieurs specs\\n+ documenter le choix']
              
                afterd [label = 'Après d = 1 (si appliqué) :\\nretester ADF / PP / KPSS']
              
                d6 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                    label = 'ADF/PP rejettent\\nET KPSS ne rejette plus ?']
                a6 [label = 'Conclusion finale :\\nSérie I(1) confirmée\\n→ conserver d = 1']
              
                d7 [shape = diamond, style = 'rounded,filled', fillcolor = '#f1948a',
                    label = 'ADF/PP et KPSS\\nrejettent fortement ?']
                a7 [label = 'Interprétation :\\nRupture structurelle probable\\n→ tester Zivot–Andrews']
              
                end [shape = doublecircle, label = 'Décision argumentée\\n(et justifiée)', fillcolor = '#d5f5e3']
              
                start -> tests
              
                tests -> d1
                d1 -> s1 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                s1 -> a1 -> end
              
                d1 -> d2 [label = 'Non']
                d2 -> s2 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                s2 -> a2 -> afterd
              
                d2 -> d3 [label = 'Non']
                d3 -> s3 [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                s3 -> a3 -> end
              
                d3 -> d4 [label = 'Non']
                d4 -> s4 [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
                s4 -> a4 -> end
              
                afterd -> d6
                d6 -> a6 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                a6 -> end
              
                d6 -> d7 [label = 'Non']
                d7 -> a7 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                a7 -> end
              
                d7 -> a4 [label = 'Non']
              }
      ")
  })
  
 
  
  
#   output$pdqpDQ_tree <- DiagrammeR::renderGrViz({
#     DiagrammeR::grViz("
# digraph pdqpDQ_tree {
# 
#   graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
#          label = 'Choisir p, d, q, P, D, Q : workflow SARIMA (critères → actions)',
#          fontname = Helvetica, bgcolor = 'transparent',
#          nodesep = 0.35, ranksep = 0.45]
# 
#   node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
#          fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
#   edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
# 
#   start [shape = circle, label = 'Départ', fillcolor = '#d6eaf8']
#   end   [shape = doublecircle, label = 'Modèle final\\n(parcimonieux + valide)', fillcolor = '#d5f5e3']
# 
#   s0 [label = '0) Fixer la saisonnalité s\\n(à partir du contexte + EDA)']
# 
#   d0 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
#       label = '1) Choisir d et D\\n(stationnarité : ADF/KPSS/PP\\n+ ACF aux multiples de s)']
#   actd [label = 'Action :\\n• appliquer la différenciation minimale\\n• vérifier sur-diff (ACF lag1 très négative)\\n• retester si besoin']
# 
#   acf0 [label = '2) Tracer ACF/PACF\\nSUR la série différenciée\\n(après d et D)\\n+ regarder aux lags 1.. et s,2s,…']
# 
#   d1 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
#       label = '3) Motifs ACF/PACF suggèrent\\nAR vs MA ?\\n(non-saisonnier et saisonnier)']
# 
#   hint [label = 'Rappels (heuristiques) :\\n• AR(p) : PACF coupure, ACF décroît\\n• MA(q) : ACF coupure, PACF décroît\\n• Saison : pics à s,2s,…\\n  PACF → P ; ACF → Q']
# 
#   cand [label = '4) Proposer un petit ensemble de candidats\\n(3 à 8 modèles)\\njustifier p,q,P,Q\\n(y compris aux multiples de s)']
# 
#   fit [label = '5) Ajuster chaque candidat\\n(p,d,q)(P,D,Q)[s]\\n+ relever AICc/BIC\\n+ vérifier stabilité/inversibilité si possible']
# 
#   d2 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
#       label = '6) Problèmes numériques ?\\n(non-inversible / non-stationnaire\\nconvergence instable)']
#   act2 [label = 'Actions :\\n• simplifier p/q/P/Q\\n• revoir d/D (sur-diff ?)\\n• transformer (log/Box–Cox)\\n• traiter outliers/manquants\\n• changer méthode/initialisation']
# 
#   diag [label = '7) Diagnostics résiduels\\nACF résidus + Ljung–Box\\n+ normalité/ARCH (secondaire)']
# 
#   d3 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
#       label = '8) Résidus ~ bruit blanc ?\\n(Ljung–Box OK + ACF résidus ≈ 0)']
#   act3 [label = 'Actions :\\n• ajuster p/q/P/Q\\n• ajouter saison si pics à s\\n• revoir d/D\\n• re-EDA (rupture/outliers)']
# 
#   perf [label = '9) Évaluation prévisionnelle\\nSplit temporel / rolling-origin\\nMAE/RMSE/MASE\\nvs benchmark (naïf/SNAIVE)']
# 
#   d4 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
#       label = '10) Bat le benchmark\\nET performance stable ?']
#   act4 [label = 'Actions :\\n• simplifier / régulariser\\n• revoir candidats\\n• si aucun gain : garder benchmark\\n• ajuster horizon h / fenêtre']
# 
#   choose [label = '11) Choix final\\n• retenir le plus simple\\n  qui passe diagnostics\\n  ET bat le benchmark\\n• comparer AICc/BIC à performance comparable\\n• documenter justification']
# 
#   start -> s0 -> d0
#   d0 -> actd [label = 'itérer si besoin', color = '#34495e', fontcolor = '#34495e']
#   actd -> acf0
#   d0 -> acf0 [label = 'd & D fixés', color = '#1e8449', fontcolor = '#1e8449']
# 
#   acf0 -> d1 -> hint -> cand -> fit -> d2
#   d2 -> act2 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
#   act2 -> cand
#   d2 -> diag [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
# 
#   diag -> d3
#   d3 -> act3 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
#   act3 -> cand
#   d3 -> perf [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
# 
#   perf -> d4
#   d4 -> act4 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
#   act4 -> cand
#   d4 -> choose [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
# 
#   choose -> end
# }
#   ")
#   })
  
  
  
  
  
  
  
  # server.R
  # library(DiagrammeR)  # ou utiliser DiagrammeR:: partout
  
  # output$stationarity_tree2 <- DiagrammeR::renderGrViz({
  #   DiagrammeR::grViz("
  #             digraph stationarity_tree2 {
  #             
  #               graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
  #                      label = 'Stationnarité & différenciation : ADF / KPSS / PP → choix de d et D',
  #                      fontname = Helvetica, bgcolor = 'transparent',
  #                      nodesep = 0.35, ranksep = 0.45]
  #             
  #               node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
  #                      fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
  #               edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
  #             
  #               start [shape = circle, label = 'Départ', fillcolor = '#d6eaf8']
  #               end   [shape = doublecircle, label = 'Décision\\n(d, D) validée', fillcolor = '#d5f5e3']
  #             
  #               prep [label = 'Préparer la série\\n• fréquence s définie\\n• manquants traités\\n• transformation (log/Box–Cox) si besoin\\n• EDA (tendance / saisonnalité)']
  #             
  #               spec [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
  #                     label = 'Choisir spécification des tests\\n(constante ? tendance ?)']
  #             
  #               noteSpec [label = 'Règle :\\n• si tendance visible → inclure tendance (trend)\\n• sinon drift / constante\\n• éviter ‘none’ sauf justification']
  #             
  #               test0 [label = 'Tester sur la série brute\\nADF + PP (H0 : racine unitaire)\\nKPSS (H0 : stationnaire)']
  #             
  #               dStrongS [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
  #                         label = 'Stationnarité forte ?\\nADF/PP rejettent (p petit)\\nET KPSS ne rejette pas (p grand)']
  #             
  #               actS [label = 'Action :\\n• d = 0\\n• vérifier saisonnalité (D ?)\\n• passer au test saisonnier']
  #             
  #               dStrongNS [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
  #                          label = 'Non-stationnarité forte ?\\nADF/PP ne rejettent pas (p grand)\\nET KPSS rejette (p petit)']
  #             
  #               actNS [label = 'Action :\\n• essayer d = 1\\n• retester ADF / PP / KPSS\\n• surveiller sur-diff (ACF lag 1 très négative)']
  #             
  #               dConflict [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
  #                          label = 'Conflit / cas ambigu ?\\n(ex. ADF rejette mais KPSS rejette aussi\\nou tous non significatifs)']
  #             
  #               actConflict [label = 'Actions :\\n• reconsidérer trend vs drift\\n• examiner graphiques + ACF\\n• tester après d = 1 puis comparer\\n• suspecter rupture (Zivot–Andrews)\\n• documenter (convergence d’indices)']
  #             
  #               retest [label = 'Retester après d choisi\\nADF + PP + KPSS\\n(d doit être minimal)']
  #             
  #               seasCheck [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
  #                          label = 'Racine saisonnière ?\\nIndices : pics ACF à s, 2s…\\n+ KPSS / ADF sur série saisonnière\\n(ou HEGY en annexe)']
  #             
  #               actSeas [label = 'Action :\\n• essayer D = 1 (diff. saisonnière)\\n• retester stationnarité\\n• D = 2 rarement justifié']
  #             
  #               overdiff [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
  #                         label = 'Sur-différenciation suspectée ?\\nACF lag 1 très négative\\nvariance gonflée\\nprévisions erratiques']
  #             
  #               actOver [label = 'Action :\\n• revenir en arrière (d ou D trop élevé)\\n• préférer tendance déterministe\\n• vérifier spécification des tests']
  #             
  #               stop [label = 'Stop quand stationnarité raisonnable\\n+ parcimonie\\n(d ∈ {0,1} le plus souvent\\n D ∈ {0,1})']
  #             
  #               start -> prep -> spec
  #               spec -> noteSpec -> test0
  #             
  #               test0 -> dStrongS
  #               dStrongS -> actS      [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
  #               dStrongS -> dStrongNS [label = 'Non']
  #             
  #               dStrongNS -> actNS    [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
  #               dStrongNS -> dConflict[label = 'Non']
  #             
  #               dConflict -> actConflict [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
  #               actConflict -> actNS     [label = 'tester d = 1 (prudence)', color = '#7d3c98', fontcolor = '#7d3c98']
  #             
  #               actNS -> retest
  #               actS  -> seasCheck
  #               retest -> seasCheck
  #             
  #               seasCheck -> actSeas [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
  #               seasCheck -> stop    [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
  #             
  #               actSeas -> overdiff
  #               overdiff -> actOver [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
  #               overdiff -> stop    [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
  #             
  #               actOver -> retest
  #               stop -> end
  #             }
  #     ")
  # })
  
  
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  
  
  
  

  
  
  # ============================================================
  # S(t) plots tab (SERVER) — paste INSIDE server()
  # ============================================================
  
  # ---- helpers ----
  to_num <- function(x, d = NA_real_) {
    y <- suppressWarnings(as.numeric(x))
    ifelse(is.finite(y), y, d)
  }
  
  # fmt_num <- function(x, d = 4) {
  #   if (!is.finite(x)) return("NA")
  #   format(round(x, d), nsmall = d)
  # }
  
  # S_Lag <- suppressWarnings(as.integer(input$stp_corr_lag))
  # if (!is.finite(S_Lag) || S_Lag < 1) S_Lag <- 40L
  # S_Lag <- max(1L, min(S_Lag, length(ts_obj) - 1L))
  
  
  # ============================================================
  # 0) Scope control: prevent "Training only" when train_prop == 1.00
  # ============================================================
  output$stp_scope_ui <- renderUI({
    tp <- to_num(input$train_prop, 1)
    has_test <- isTRUE(tp < 1)
    
    if (!has_test) {
      radioButtons(
        "stp_scope",
        label = NULL,
        choices = c("Full series" = "full"),
        selected = "full"
      )
    } else {
      radioButtons(
        "stp_scope",
        label = NULL,
        choices = c("Full series" = "full", "Training only" = "train"),
        selected = input$stp_scope %||% "full"
      )
    }
  })
  
  output$stp_scope_warning <- renderUI({
    tp <- to_num(input$train_prop, 1)
    if (isTRUE(tp >= 1)) {
      tags$div(
        style = "color:#b22222; font-size:12px; margin-top:-6px;",
        "No test set → training = full series"
      )
    } else NULL
  })
  
  observeEvent(input$train_prop, {
    tp <- to_num(input$train_prop, 1)
    if (isTRUE(tp >= 1) && identical(input$stp_scope, "train")) {
      updateRadioButtons(session, "stp_scope", selected = "full")
    }
  }, ignoreInit = TRUE)
  
  # ============================================================
  # 1) Global transform info (read-only)
  # ============================================================
  output$stp_transform_info <- renderPrint({
    tr <- input$transform %||% "none"
    if (tr == "boxcox") {
      lam <- input$lambda
      cat("Transformation:", "Box-Cox", "\n")
      cat("λ:", if (is.null(lam) || (length(lam) == 1 && is.na(lam))) "auto (estimated)" else as.character(lam), "\n")
    } else if (tr == "log") {
      cat("Transformation:", "Log (ln y)", "\n")
    } else {
      cat("Transformation:", "None", "\n")
    }
  })
  
  output$stp_transform_note <- renderUI({
    tr <- input$transform %||% "none"
    lam <- input$lambda
    
    tr_lbl <- switch(tr,
                     "none" = "None",
                     "log" = "Log (ln y)",
                     "boxcox" = "Box-Cox",
                     tr)
    
    if (identical(tr, "boxcox")) {
      tags$div(
        style = "font-size:12px;",
        tags$b("Transformation (global): "), tr_lbl, " — ",
        tags$b("λ: "), if (is.null(lam) || is.na(lam)) "auto" else as.character(lam)
      )
    } else {
      tags$div(
        style = "font-size:12px;",
        tags$b("Transformation (global): "), tr_lbl
      )
    }
  })
  
  # ============================================================
  # 2) Theme/palette helpers  (IMPORTANT: rotation is controlled here)
  # ============================================================
  stp_theme_picker <- function(key) {
    switch(
      key,
      "Minimal" = ggplot2::theme_minimal(),
      "Classic" = ggplot2::theme_classic(),
      "Light"   = ggplot2::theme_light(),
      "Dark"    = ggplot2::theme_dark(),
      "BW"      = ggplot2::theme_bw(),
      "Void"    = ggplot2::theme_void(),
      ggplot2::theme_gray()
    )
  }
  
  stp_apply_theme <- function(g) {
    ang <- to_num(input$stp_x_angle, 30)
    rot <- isTRUE(input$stp_x_rotate %||% TRUE)
    
    g +
      stp_theme_picker(input$stp_theme %||% "Minimal") +
      ggplot2::theme(
        text = ggplot2::element_text(size = to_num(input$stp_base_size, 12)),
        plot.title = ggplot2::element_text(hjust = 0.5),
        
        # ✅ rotation is applied HERE so it always wins over the theme preset
        axis.text.x = ggplot2::element_text(
          angle = if (rot) ang else 0,
          hjust = if (!rot || ang == 0) 0.5 else 1,
          vjust = if (!rot || ang == 0) 0.5 else 1
        )
      )
  }
  
  stp_apply_palette <- function(g) {
    pal <- input$stp_palette %||% "Paired (brewer)"
    rev <- isTRUE(input$stp_palette_rev)
    
    if (pal == "Viridis") {
      g +
        ggplot2::scale_color_viridis_d(direction = ifelse(rev, -1, 1)) +
        ggplot2::scale_fill_viridis_d(direction = ifelse(rev, -1, 1))
    } else {
      brewer_name <- sub(" \\(brewer\\)$", "", pal)
      g +
        ggplot2::scale_color_brewer(palette = brewer_name, direction = ifelse(rev, -1, 1)) +
        ggplot2::scale_fill_brewer(palette = brewer_name, direction = ifelse(rev, -1, 1))
    }
  }
  
  # ============================================================
  # 3) Conditional style UI (COLOUR PICKERS)
  # ============================================================
  output$stp_style_ui <- renderUI({
    req(input$stp_plot_type)
    pt <- input$stp_plot_type
    
    if (!requireNamespace("colourpicker", quietly = TRUE)) {
      return(tags$div(
        style = "color:#b22222; font-size:12px;",
        "Package 'colourpicker' is required for color pickers. Install it: install.packages('colourpicker')"
      ))
    }
    
    is_liney <- pt %in% c("Line", "Line + Points", "Smoothed (LOESS)", "Moving average",
                          "Cumulative sum", "Seasonal plot", "Seasonal subseries",
                          "Polar seasonal", "Periodogram",
                          "Classical decomposition (additive)", "Classical decomposition (multiplicative)",
                          "STL decomposition")
    
    is_pointy <- pt %in% c("Points", "Line + Points", "Smoothed (LOESS)",
                           "Lag-1 scatter", "Lag plot (1..m)", "QQ plot")
    
    is_filly  <- pt %in% c("Histogram", "Density", "Seasonal boxplot")
    
    tagList(
      if (is_liney) tagList(
        colourpicker::colourInput("stp_line_color", "Line color", value = "#2C7FB8", allowTransparent = FALSE),
        sliderInput("stp_line_width", "Line width", min = 0.1, max = 5, value = 0.9, step = 0.1)
      ),
      if (is_pointy) tagList(
        colourpicker::colourInput("stp_point_color", "Point color", value = "#2C7FB8", allowTransparent = FALSE),
        sliderInput("stp_point_size", "Point size", min = 0.5, max = 8, value = 2, step = 0.5)
      ),
      if (is_filly) tagList(
        colourpicker::colourInput("stp_fill_color", "Fill color", value = "#2C7FB8", allowTransparent = FALSE)
      )
    )
  })
  
  # ============================================================
  # 4) Data reactive: choose scope + apply GLOBAL transform
  # ============================================================
  stp_data <- reactive({
    req(prepared(), ts_train_test())
    p <- prepared()
    s <- ts_train_test()
    
    df_all <- p$df
    req(df_all)
    
    validate(need("y_filled" %in% names(df_all), "prepared()$df must contain column y_filled."))
    
    if (!("x" %in% names(df_all))) df_all$x <- seq_len(nrow(df_all))
    
    df_all <- df_all[is.finite(df_all$y_filled), , drop = FALSE]
    validate(need(nrow(df_all) >= 5, "Not enough data to plot."))
    
    train_n <- s$train_n %||% floor(nrow(df_all) * to_num(input$train_prop, 1))
    train_n <- max(2, min(as.integer(train_n), nrow(df_all)))
    
    has_test <- isTRUE(to_num(input$train_prop, 1) < 1)
    scope_in <- input$stp_scope %||% "full"
    scope <- if (!has_test) "full" else scope_in
    
    df_use <- if (identical(scope, "train")) df_all[seq_len(train_n), , drop = FALSE] else df_all
    
    tr <- input$transform %||% "none"
    y <- df_use$y_filled
    y_plot <- y
    lambda_used <- NA_real_
    
    if (tr == "log") {
      validate(need(all(y > 0, na.rm = TRUE), "Log transform requires strictly positive values."))
      y_plot <- log(y)
    } else if (tr == "boxcox") {
      validate(need(all(y > 0, na.rm = TRUE), "Box-Cox transform requires strictly positive values."))
      lam <- input$lambda
      if (is.null(lam) || (length(lam) == 1 && is.na(lam))) {
        lam <- forecast::BoxCox.lambda(y, method = "guerrero")
      } else {
        lam <- as.numeric(lam)
      }
      lambda_used <- lam
      y_plot <- forecast::BoxCox(y, lam)
    }
    
    df_use$y_plot <- as.numeric(y_plot)
    
    freq_use <- p$freq %||% 1
    ts_use <- stats::ts(df_use$y_plot, start = 1, frequency = freq_use)
    
    list(
      df = df_use,
      ts = ts_use,
      freq = freq_use,
      scope = scope,
      train_n = train_n,
      n_total = nrow(df_all),
      transform = tr,
      lambda_used = lambda_used,
      x_is_date = inherits(df_use$x, "Date"),
      x_is_dt   = inherits(df_use$x, "POSIXct") || inherits(df_use$x, "POSIXt")
    )
  })
  
  # ============================================================
  # 5) Labels helper (teaching subtitle)
  # ============================================================
  stp_labels <- function(d, default_title = "S(t)", default_y = "Value") {
    title_in <- input$stp_title %||% ""
    sub_in   <- input$stp_subtitle %||% ""
    x_in     <- input$stp_xlab %||% ""
    y_in     <- input$stp_ylab %||% ""
    
    scope_txt <- if (identical(d$scope, "train")) "training" else "full"
    n_txt <- paste0("n=", nrow(d$df))
    s_txt <- paste0("s=", d$freq)
    
    tr_txt <- switch(
      d$transform,
      "log" = "transform=log",
      "boxcox" = paste0("transform=BoxCox(λ=", ifelse(is.finite(d$lambda_used), fmt_num(d$lambda_used, 3), "auto"), ")"),
      "none" = "transform=none",
      "transform=none"
    )
    
    teaching_sub <- paste(scope_txt, n_txt, s_txt, tr_txt, sep = " • ")
    
    list(
      title = if (nzchar(title_in)) title_in else default_title,
      subtitle = if (nzchar(sub_in)) sub_in else teaching_sub,
      x = if (nzchar(x_in)) x_in else "Time",
      y = if (nzchar(y_in)) y_in else default_y
    )
  }
  
  # ============================================================
  # 6) Smart date axis (NO ROTATION here)
  # ============================================================
  # stp_apply_x_scale <- function(g, d) {
  #   if (!isTRUE(d$x_is_date) && !isTRUE(d$x_is_dt)) return(g)
  #   
  #   n_ticks <- as.integer(to_num(input$stp_x_ticks, 8))
  #   
  #   fmt_choice <- input$stp_date_format %||% "auto"
  #   fmt_custom <- input$stp_date_format_custom %||% "%Y-%m"
  #   fmt <- if (identical(fmt_choice, "custom")) fmt_custom else fmt_choice
  #   
  #   if (identical(fmt, "auto")) {
  #     n <- nrow(d$df)
  #     if (n <= 24) fmt <- "%b %Y"
  #     else if (n <= 120) fmt <- "%Y-%m"
  #     else fmt <- "%Y"
  #   }
  #   
  #   if (isTRUE(d$x_is_date)) {
  #     g + ggplot2::scale_x_date(
  #       labels = scales::date_format(fmt),
  #       breaks = scales::pretty_breaks(n = n_ticks)
  #     )
  #   } else {
  #     g + ggplot2::scale_x_datetime(
  #       labels = scales::date_format(fmt),
  #       breaks = scales::pretty_breaks(n = n_ticks)
  #     )
  #   }
  # }
  
  # stp_apply_x_scale <- function(g, d) {
  #   if (!isTRUE(d$x_is_date) && !isTRUE(d$x_is_dt)) return(g)
  #   
  #   n_ticks <- as.integer(to_num(input$stp_x_ticks, 8))
  #   
  #   fmt_choice <- input$stp_date_format %||% "auto"
  #   fmt_custom <- input$stp_date_format_custom %||% "%Y-%m"
  #   lang <- input$stp_date_lang %||% "en"
  #   
  #   # ---- format selection ----
  #   fmt <- if (identical(fmt_choice, "custom")) fmt_custom else fmt_choice
  #   
  #   if (identical(fmt, "auto")) {
  #     n <- nrow(d$df)
  #     if (n <= 24) fmt <- "%b %Y"
  #     else if (n <= 120) fmt <- "%Y-%m"
  #     else fmt <- "%Y"
  #   }
  #   
  #   # ---- locale mapping ----
  #   locale_map <- c(
  #     "en" = "en",
  #     "fr" = "fr",
  #     "ar" = "ar"
  #   )
  #   locale_use <- locale_map[[lang]] %||% "en"
  #   
  #   label_fun <- scales::label_date(
  #     format = fmt,
  #     locale = locale_use
  #   )
  #   
  #   if (isTRUE(d$x_is_date)) {
  #     g + ggplot2::scale_x_date(
  #       labels = label_fun,
  #       breaks = scales::pretty_breaks(n = n_ticks)
  #     )
  #   } else {
  #     g + ggplot2::scale_x_datetime(
  #       labels = label_fun,
  #       breaks = scales::pretty_breaks(n = n_ticks)
  #     )
  #   }
  # }
  
  
  stp_apply_x_scale <- function(g, d) {
    if (!isTRUE(d$x_is_date) && !isTRUE(d$x_is_dt)) return(g)
    
    n_ticks <- as.integer(to_num(input$stp_x_ticks, 8))
    
    fmt_choice <- input$stp_date_format %||% "auto"
    fmt_custom <- input$stp_date_format_custom %||% "%Y-%m"
    lang <- input$stp_date_lang %||% "en"
    
    # ---- format selection ----
    fmt <- if (identical(fmt_choice, "custom")) fmt_custom else fmt_choice
    
    if (identical(fmt, "auto")) {
      n <- nrow(d$df)
      if (n <= 24) fmt <- "%b %Y"
      else if (n <= 120) fmt <- "%Y-%m"
      else fmt <- "%Y"
    }
    
    # ---- locale mapping ----
    locale_map <- c(
      "en" = "en",
      "fr" = "fr",
      "ar" = "ar"
    )
    locale_use <- locale_map[[lang]] %||% "en"
    
    # ---- label function (locale-aware) ----
    base_label_fun <- scales::label_date(
      format = fmt,
      locale = locale_use
    )
    
    # ---- force Western digits for Arabic labels only ----
    label_fun <- function(x) {
      lab <- base_label_fun(x)
      
      if (identical(lang, "ar")) {
        # Arabic-Indic: ٠١٢٣٤٥٦٧٨٩
        arabic_indic <- c("٠","١","٢","٣","٤","٥","٦","٧","٨","٩")
        # Eastern Arabic-Indic (Persian): ۰۱۲۳۴۵۶۷۸۹
        eastern_arabic_indic <- c("۰","۱","۲","۳","۴","۵","۶","۷","۸","۹")
        western <- as.character(0:9)
        
        lab <- as.character(lab)
        for (i in 0:9) {
          lab <- gsub(arabic_indic[i + 1], western[i + 1], lab, fixed = TRUE)
          lab <- gsub(eastern_arabic_indic[i + 1], western[i + 1], lab, fixed = TRUE)
        }
      }
      
      lab
    }
    
    if (isTRUE(d$x_is_date)) {
      g + ggplot2::scale_x_date(
        labels = label_fun,
        breaks = scales::pretty_breaks(n = n_ticks)
      )
    } else {
      g + ggplot2::scale_x_datetime(
        labels = label_fun,
        breaks = scales::pretty_breaks(n = n_ticks)
      )
    }
  }
  
  
  
  # ============================================================
  # 7) UI dispatcher for multi-panel plot types
  # ============================================================
  # output$stp_plot_ui <- renderUI({
  #   req(input$stp_plot_type)
  #   pt <- input$stp_plot_type
  #   h <- to_num(input$stp_plot_height_px, 520)
  #   
  #   if (pt == "ACF+PACF") {
  #     fluidRow(
  #       column(6, plotOutput("stp_acf",  width = "100%", height = h)),
  #       column(6, plotOutput("stp_pacf", width = "100%", height = h))
  #     )
  #   } else if (pt == "Time + ACF+PACF") {
  #     tagList(
  #       plotOutput("stp_main", width = "100%", height = round(h * 0.9)),
  #       fluidRow(
  #         column(6, plotOutput("stp_acf",  width = "100%", height = round(h * 0.8))),
  #         column(6, plotOutput("stp_pacf", width = "100%", height = round(h * 0.8)))
  #       )
  #     )
  #   } else if (pt == "Lag plot (1..m)") {
  #     plotOutput("stp_lag_grid", width = "100%", height = round(h * 1.2))
  #   } else if (pt == "ACF") {
  #     plotOutput("stp_acf", width = "100%", height = h)
  #   } else if (pt == "PACF") {
  #     plotOutput("stp_pacf", width = "100%", height = h)
  #   } else {
  #     plotOutput("stp_main", width = "100%", height = h)
  #   }
  # })
  
  # output$stp_plot_ui <- renderUI({
  #   req(input$stp_plot_type)
  #   pt <- input$stp_plot_type
  #   h  <- to_num(input$stp_plot_height_px, 520)
  #   
  #   if (pt == "ACF+PACF") {
  #     
  #     fluidRow(
  #       column(6, plotOutput("stp_acf",  width = "100%", height = h)),
  #       column(6, plotOutput("stp_pacf", width = "100%", height = h))
  #     )
  #     
  #   } else if (pt == "Time + ACF+PACF") {
  #     
  #     fluidRow(
  #       column(
  #         12,
  #         
  #         # TOP: same container width as bottom
  #         plotOutput("stp_main", width = "100%", height = round(h * 0.9)),
  #         
  #         # BOTTOM: ACF + PACF inside SAME column(12)
  #         fluidRow(
  #           column(6, plotOutput("stp_acf",  width = "100%", height = round(h * 0.8))),
  #           column(6, plotOutput("stp_pacf", width = "100%", height = round(h * 0.8)))
  #         )
  #       )
  #     )
  #     
  #   } else if (pt == "Lag plot (1..m)") {
  #     
  #     plotOutput("stp_lag_grid", width = "100%", height = round(h * 1.2))
  #     
  #   } else if (pt == "ACF") {
  #     
  #     plotOutput("stp_acf", width = "100%", height = h)
  #     
  #   } else if (pt == "PACF") {
  #     
  #     plotOutput("stp_pacf", width = "100%", height = h)
  #     
  #   } else {
  #     
  #     plotOutput("stp_main", width = "100%", height = h)
  #     
  #   }
  # })
  
  
  
  output$stp_plot_ui <- renderUI({
    req(input$stp_plot_type)
    pt <- input$stp_plot_type
    h  <- to_num(input$stp_plot_height_px, 520)
    
    if (pt == "ACF+PACF") {
      
      fluidRow(
        column(6, plotOutput("stp_acf",  width = "100%", height = h)),
        column(6, plotOutput("stp_pacf", width = "100%", height = h))
      )
      
    } else if (pt == "Time + ACF+PACF") {
      
      gap_px <- round(h * 0.12)  # height of empty middle row
      
      fluidRow(
        column(
          12,
          
          # ── Row 1: Time plot ──
          plotOutput("stp_main", width = "100%", height = round(h * 0.9)),
          
          # ── Row 2: empty spacer row ──
          fluidRow(
            column(
              12,
              div(style = paste0("height:", gap_px, "px;"))
            )
          ),
          
          # ── Row 3: ACF (left-indented) + PACF (right-indented) ──
          fluidRow(
            column(
              6,
              div(
                style = "padding-left: 24px;",
                plotOutput("stp_acf", width = "100%", height = round(h * 0.6))
              )
            ),
            column(
              6,
              div(
                style = "padding-right: 24px;",
                plotOutput("stp_pacf", width = "100%", height = round(h * 0.6))
              )
            )
          )
        )
      )
      
    } else if (pt == "Lag plot (1..m)") {
      
      plotOutput("stp_lag_grid", width = "100%", height = round(h * 1.2))
      
    } else if (pt == "ACF") {
      
      plotOutput("stp_acf", width = "100%", height = h)
      
    } else if (pt == "PACF") {
      
      plotOutput("stp_pacf", width = "100%", height = h)
      
    } else {
      
      plotOutput("stp_main", width = "100%", height = h)
      
    }
  })
  
  
  
  
  # ============================================================
  # 8) Main plot  (FIXED ORDER: theme first, x-scale last)
  # ============================================================
  output$stp_main <- renderPlot({
    d <- stp_data()
    df <- d$df
    pt <- input$stp_plot_type %||% "Line"
    
    line_col <- input$stp_line_color %||% "#2C7FB8"
    lw       <- to_num(input$stp_line_width, 1)
    pt_col   <- input$stp_point_color %||% line_col
    ps       <- to_num(input$stp_point_size, 2)
    fill_col <- input$stp_fill_color %||% line_col
    a        <- to_num(input$stp_alpha, 1)
    
    labs0 <- stp_labels(d, default_title = "S(t)", default_y = "Value")
    
    base <- ggplot2::ggplot(df, ggplot2::aes(x = x, y = y_plot)) +
      ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$x, y = labs0$y)
    
    # ---- plot switch ----
    if (pt == "Line") {
      g <- base + ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Points") {
      g <- base + ggplot2::geom_point(color = pt_col, size = ps, alpha = a)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Line + Points") {
      g <- base +
        ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a) +
        ggplot2::geom_point(color = pt_col, size = ps, alpha = a)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Smoothed (LOESS)") {
      span <- to_num(input$stp_loess_span, 0.4)
      g <- base +
        ggplot2::geom_point(color = pt_col, size = ps, alpha = a) +
        ggplot2::geom_smooth(method = "loess", span = span, se = TRUE,
                             color = line_col, linewidth = lw, alpha = 0.2)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Moving average") {
      k <- as.integer(to_num(input$stp_ma_k, 5))
      show_raw <- isTRUE(input$stp_ma_show_raw)
      
      df2 <- df
      df2$ma <- zoo::rollmean(df2$y_plot, k = k, fill = NA, align = "center")
      
      g <- ggplot2::ggplot(df2, ggplot2::aes(x = x)) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$x, y = labs0$y)
      
      if (show_raw) {
        g <- g + ggplot2::geom_line(ggplot2::aes(y = y_plot), color = "gray60", linewidth = 0.6, alpha = 0.7)
      }
      g <- g + ggplot2::geom_line(ggplot2::aes(y = ma), color = line_col, linewidth = lw, alpha = a)
      
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Cumulative sum") {
      df2 <- df
      df2$cs <- cumsum(df2$y_plot)
      
      g <- ggplot2::ggplot(df2, ggplot2::aes(x = x, y = cs)) +
        ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$x, y = "Cumsum")
      
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    
    # ---- Seasonal plots ----
    if (pt %in% c("Seasonal plot", "Seasonal subseries", "Polar seasonal", "Seasonal boxplot")) {
      validate(need(is.finite(d$freq) && d$freq >= 2, "Seasonal plots require frequency >= 2."))
      
      x_ts <- d$ts  # ts object built from y_plot + frequency
      
      if (pt == "Seasonal plot") {
        g <- forecast::ggseasonplot(x_ts, polar = FALSE) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
        g <- stp_apply_palette(g)
        g <- stp_apply_theme(g)
        return(g)
      }
      
      if (pt == "Polar seasonal") {
        g <- forecast::ggseasonplot(x_ts, polar = TRUE) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
        g <- stp_apply_palette(g)
        g <- stp_apply_theme(g)
        return(g)
      }
      
      if (pt == "Seasonal subseries") {
        g <- forecast::ggsubseriesplot(x_ts) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
        g <- stp_apply_theme(g)
        return(g)
      }
      
      if (pt == "Seasonal boxplot") {
        df2 <- data.frame(season = factor(stats::cycle(x_ts)), y = as.numeric(x_ts))
        g <- ggplot2::ggplot(df2, ggplot2::aes(x = season, y = y, fill = season)) +
          ggplot2::geom_boxplot(alpha = 0.6) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = "Season", y = labs0$y)
        g <- stp_apply_palette(g)
        g <- stp_apply_theme(g)
        return(g)
      }
    }
    
    # ---- Decomposition plots ----
    if (pt %in% c("Classical decomposition (additive)", "Classical decomposition (multiplicative)")) {
      validate(need(is.finite(d$freq) && d$freq >= 2, "Decomposition requires frequency >= 2."))
      
      x_ts <- d$ts
      type <- if (pt == "Classical decomposition (multiplicative)") "multiplicative" else "additive"
      
      # multiplicative requires strictly positive values
      if (type == "multiplicative") {
        validate(need(all(as.numeric(x_ts) > 0), "Multiplicative decomposition requires strictly positive values."))
      }
      
      dc <- stats::decompose(x_ts, type = type)
      g <- forecast::autoplot(dc) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
      g <- stp_apply_theme(g)
      return(g)
    }
    
    if (pt == "STL decomposition") {
      validate(need(is.finite(d$freq) && d$freq >= 2, "STL requires frequency >= 2."))
      
      x_ts <- d$ts
      fit <- stats::stl(x_ts, s.window = "periodic", robust = TRUE)
      
      g <- forecast::autoplot(fit) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
      g <- stp_apply_theme(g)
      return(g)
    }
    
    
    
    
    if (pt == "Histogram") {
      bins <- as.integer(to_num(input$stp_hist_bins, 30))
      g <- ggplot2::ggplot(df, ggplot2::aes(x = y_plot)) +
        ggplot2::geom_histogram(bins = bins, fill = fill_col, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$y, y = "Count")
      return(stp_apply_theme(g))
    }
    
    if (pt == "Density") {
      bw_adj <- to_num(input$stp_bw_adj, 1)
      g <- ggplot2::ggplot(df, ggplot2::aes(x = y_plot)) +
        ggplot2::geom_density(adjust = bw_adj, fill = fill_col, alpha = 0.25) +
        ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$y, y = "Density")
      return(stp_apply_theme(g))
    }
    
    if (pt == "QQ plot") {
      g <- ggplot2::ggplot(df, ggplot2::aes(sample = y_plot)) +
        ggplot2::stat_qq(color = pt_col, alpha = a) +
        ggplot2::stat_qq_line(color = line_col, linewidth = lw) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = "Theoretical", y = "Sample")
      return(stp_apply_theme(g))
    }
    
    if (pt == "Lag-1 scatter") {
      y <- df$y_plot
      validate(need(length(y) >= 3, "Not enough observations for lag scatter."))
      dfl <- data.frame(x = y[-length(y)], y = y[-1])
      g <- ggplot2::ggplot(dfl, ggplot2::aes(x = x, y = y)) +
        ggplot2::geom_point(color = pt_col, size = ps, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = "S(t-1)", y = "S(t)")
      return(stp_apply_theme(g))
    }
    
    # (seasonal/decomposition/periodogram parts unchanged...)
    stp_apply_theme(base + ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a))
    
  }, width  = function() to_num(input$stp_plot_width_px, 980),
  height = function() to_num(input$stp_plot_height_px, 520))
  
  # ============================================================
  # 9) ACF/PACF panels
  # ============================================================
  output$stp_acf <- renderPlot({
    d <- stp_data()
    x_ts <- d$ts
    
    # --- slider-driven lag (robust + capped) ---
    S_Lag <- suppressWarnings(as.integer(input$stp_corr_lag))
    if (!is.finite(S_Lag) || S_Lag < 1) S_Lag <- 40L   # default = UI value
    S_Lag <- max(1L, min(S_Lag, length(x_ts) - 1L))
    
    g <- forecast::ggAcf(x_ts, lag.max = S_Lag) +
      ggplot2::labs(title = "ACF", subtitle = stp_labels(d)$subtitle)
    
    stp_apply_theme(g)
  })
  
  output$stp_pacf <- renderPlot({
    d <- stp_data()
    x_ts <- d$ts
    
    # --- slider-driven lag (robust + capped) ---
    S_Lag <- suppressWarnings(as.integer(input$stp_corr_lag))
    if (!is.finite(S_Lag) || S_Lag < 1) S_Lag <- 40L
    S_Lag <- max(1L, min(S_Lag, length(x_ts) - 1L))
    
    g <- forecast::ggPacf(x_ts, lag.max = S_Lag) +
      ggplot2::labs(title = "PACF", subtitle = stp_labels(d)$subtitle)
    
    stp_apply_theme(g)
  })
  
  
  
  
  # output$stp_acf <- renderPlot({
  #   d <- stp_data()
  #   x_ts <- d$ts
  #   L <- min(60, length(x_ts) - 1)
  #   g <- forecast::ggAcf(x_ts, lag.max = L) +
  #     ggplot2::labs(title = "ACF", subtitle = stp_labels(d)$subtitle)
  #   stp_apply_theme(g)
  # })
  # 
  # output$stp_pacf <- renderPlot({
  #   d <- stp_data()
  #   x_ts <- d$ts
  #   L <- min(60, length(x_ts) - 1)
  #   g <- forecast::ggPacf(x_ts, lag.max = L) +
  #     ggplot2::labs(title = "PACF", subtitle = stp_labels(d)$subtitle)
  #   stp_apply_theme(g)
  # })
  
  # ============================================================
  # 10) Lag grid (1..m)
  # ============================================================
  output$stp_lag_grid <- renderPlot({
    d <- stp_data()
    df <- d$df
    
    m <- as.integer(to_num(input$stp_lag_m, 12))
    validate(need(m >= 1, "m must be >= 1."))
    
    y <- df$y_plot
    validate(need(length(y) >= (m + 2), "Not enough observations for requested lag grid."))
    
    out <- lapply(1:m, function(k) {
      data.frame(
        lag = paste0("Lag ", k),
        x = y[seq_len(length(y) - k)],
        y = y[(k + 1):length(y)]
      )
    })
    dfl <- do.call(rbind, out)
    
    pt_col <- input$stp_point_color %||% "#2C7FB8"
    ps <- to_num(input$stp_point_size, 2)
    a  <- to_num(input$stp_alpha, 1)
    
    g <- ggplot2::ggplot(dfl, ggplot2::aes(x = x, y = y)) +
      ggplot2::geom_point(color = pt_col, size = ps, alpha = a) +
      ggplot2::facet_wrap(~ lag, scales = "free", ncol = 3) +
      ggplot2::labs(title = "Lag plots (1..m)", subtitle = stp_labels(d)$subtitle, x = "S(t-k)", y = "S(t)")
    
    stp_apply_theme(g)
    
  }, width  = function() to_num(input$stp_plot_width_px, 980),
  height = function() round(to_num(input$stp_plot_height_px, 520) * 1.2))
  
  
  
  
  
  
  
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  # ============================================================
  
  
  
  
  
  
  # ---- Step 3 outputs ----

  output$decomp_add <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    plot(decompose(x, type = "additive"))
  })

  output$decomp_mul <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    validate(need(all(as.numeric(x) > 0), "Multiplicative decomposition requires strictly positive values."))
    plot(decompose(x, type = "multiplicative"))
  })

  output$stl_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    validate(need(frequency(x) >= 2, "STL needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    fit <- stl(x, s.window = "periodic", robust = TRUE)
    plot(fit, main = "STL decomposition (robust)")
  })

  output$apa_decomp_paragraph <- renderPrint({
    cat(
      "APA-ready paragraph (edit based on which decomposition you used):\n\n",
      "Decomposition methods were used to separate the series into trend, seasonal, and remainder components. ",
      "Classical decomposition was evaluated under additive and multiplicative assumptions, and robust STL decomposition ",
      "was also examined to reduce the influence of potential outliers. ",
      "The decomposition results provided evidence regarding the stability of seasonality and the magnitude of irregular variation.\n",
      sep = ""
    )
  })

  # ---- Step 4 outputs ----

  output$diff_suggestion <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    d_rec <- tryCatch(forecast::ndiffs(x), error = function(e) NA_integer_)
    D_rec <- tryCatch(forecast::nsdiffs(x), error = function(e) NA_integer_)
    cat("Suggested differencing (heuristics):\n")
    cat("- ndiffs (d):", d_rec, "\n")
    cat("- nsdiffs (D):", D_rec, "\n")
  })
  
 
  
  stationarity <- eventReactive(input$run_tests, {
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0) a else b
    to_int <- function(x, d = 0L) { v <- suppressWarnings(as.integer(x)); if (!is.finite(v)) d else v }
    
    s <- ts_train_test()
    x <- as.numeric(stats::na.omit(s$ts_train))
    x <- x[is.finite(x)]
    
    k <- max(0L, to_int(input$adf_lags, 10L))
    
    # single source of truth for the deterministic type
    type_used <- tolower(as.character(input$adf_type %||% input$adfTypeSt2 %||% "drift"))
    type_used <- if (type_used %in% c("none", "drift", "trend")) type_used else "drift"
    
    alpha_used <- suppressWarnings(as.numeric(input$alphaSt2 %||% 0.05))
    if (!is.finite(alpha_used)) alpha_used <- 0.05
    
    out <- list(
      type_used  = type_used,
      alpha_used = alpha_used,
      k_used     = k,
      series     = x
    )
    
    # run tests (keep errors if any)
    out$adf <- tryCatch(
      tseries::adf.test(x, k = k, alternative = input$alternd2St %||% "stationary"),
      error = function(e) { out$adf_error <<- e$message; NULL }
    )
    
    out$kpss <- tryCatch({
      null_kpss <- if (identical(type_used, "trend")) "Trend" else "Level"
      tseries::kpss.test(x, null = null_kpss)
    }, error = function(e) { out$kpss_error <<- e$message; NULL })
    
    out$pp <- tryCatch(
      tseries::pp.test(x),
      error = function(e) { out$pp_error <<- e$message; NULL }
    )
    
    out$ur <- tryCatch(
      urca::ur.df(x, type = type_used, lags = k),
      error = function(e) { out$ur_error <<- e$message; NULL }
    )
    
    # NEW: Auto-lag ADF (AIC)
    out$ur_auto <- tryCatch(
      urca::ur.df(x, type = type_used, selectlags = "AIC"),
      error = function(e) { out$ur_auto_error <<- e$message; NULL }
    )
    
    # Infer chosen k from regression terms: number of z.diff* terms ~= k
    out$k_auto <- tryCatch({
      if (is.null(out$ur_auto)) return(NA_integer_)
      sm <- summary(out$ur_auto)
      rn <- rownames(sm@testreg$coefficients)
      as.integer(sum(grepl("^z\\.diff", rn)))
    }, error = function(e) NA_integer_)
    
    out
  })
  
  
 
  
  alpha_to_col <- function(a) {
    if (!is.finite(a)) return("5pct")
    if (abs(a - 0.01) < 1e-8) return("1pct")
    if (abs(a - 0.05) < 1e-8) return("5pct")
    if (abs(a - 0.10) < 1e-8 || abs(a - 0.1) < 1e-8) return("10pct")
    "5pct"
  }
  
  extract_tau_urdf <- function(ur_obj, alpha_used = 0.05, type_used = NULL) {
    out <- list(tau_obs = NA_real_, tau_crit = NA_real_, tau_row = NA_character_, alpha_col = NA_character_)
    if (is.null(ur_obj)) return(out)
    
    # tau observed: first entry whose name starts with "tau" (fallback: first element)
    ts_vec <- tryCatch(ur_obj@teststat, error = function(e) NULL)
    if (!is.null(ts_vec)) {
      nms <- names(ts_vec)
      if (!is.null(nms)) {
        idx <- grep("^tau", nms)
        out$tau_obs <- suppressWarnings(as.numeric(ts_vec[ if (length(idx)) idx[1] else 1 ]))
      } else {
        out$tau_obs <- suppressWarnings(as.numeric(ts_vec[1]))
      }
    }
    
    cv <- tryCatch(ur_obj@cval, error = function(e) NULL)
    if (is.null(cv)) return(out)
    
    # Work with matrix cval (usual case)
    if (is.matrix(cv)) {
      rnames <- rownames(cv); cnames <- colnames(cv)
      
      # preferred tau row from declared type
      tau_pref <- switch(tolower(type_used %||% ""), "none" = "tau1", "drift" = "tau2", "trend" = "tau3", NA_character_)
      tau_rows <- grep("^tau", rnames, value = TRUE)
      
      row_pick <- if (!is.na(tau_pref) && tau_pref %in% rnames) tau_pref else if (length(tau_rows)) tau_rows[1] else NA_character_
      out$tau_row <- row_pick
      
      col_pick <- alpha_to_col(alpha_used)
      if (!is.null(cnames) && !(col_pick %in% cnames)) {
        # choose the nearest available alpha column
        pct <- suppressWarnings(as.numeric(gsub("pct", "", cnames)))/100
        if (any(is.finite(pct))) col_pick <- cnames[ which.min(abs(pct - alpha_used)) ] else col_pick <- cnames[1]
      }
      out$alpha_col <- col_pick
      
      if (!is.na(row_pick) && !is.null(col_pick) && row_pick %in% rnames && col_pick %in% cnames) {
        out$tau_crit <- suppressWarnings(as.numeric(cv[row_pick, col_pick]))
      }
      return(out)
    }
    
    # Named vector fallback (rare)
    col_pick <- alpha_to_col(alpha_used)
    out$alpha_col <- col_pick
    if (!is.null(names(cv)) && col_pick %in% names(cv)) {
      out$tau_crit <- suppressWarnings(as.numeric(cv[[col_pick]]))
    }
    out
  }
  
  
  
 
  
  
  
  
  output$stationarity_results <- renderPrint({
    req(stationarity())
    st <- stationarity()
    
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0) a else b
    to_num <- function(x, d = NA_real_) {
      y <- suppressWarnings(as.numeric(x))
      if (length(y) == 0 || all(is.na(y)) || !is.finite(y[1])) d else y[1]
    }
    fmt_p   <- if (exists("fmt_p", inherits = TRUE)) get("fmt_p") else function(p) if (!is.finite(p)) "NA" else format.pval(p, digits = 4, eps = .Machine$double.eps)
    fmt_num <- if (exists("fmt_num", inherits = TRUE)) get("fmt_num") else function(x, d = 4) if (!is.finite(x)) "NA" else format(round(x, d), nsmall = d)
    
    adf_type_ui  <- input$adfTypeSt2 %||% "trend"
    k_lags       <- to_num(input$LagOrderADFd2St, 10)
    alpha        <- to_num(input$alphaSt2, 0.05)
    kpss_null_ui <- if (identical(adf_type_ui, "trend")) "tau" else "mu"
    
    tau_row   <- switch(adf_type_ui, "none"="tau1", "drift"="tau2", "trend"="tau3", "tau3")
    alpha_col <- switch(as.character(alpha), "0.01"="1pct", "0.05"="5pct", "0.1"="10pct", "0.10"="10pct", "5pct")
    
    adf_p     <- if (!is.null(st$adf))  to_num(st$adf$p.value)    else NA_real_
    adf_stat  <- if (!is.null(st$adf))  to_num(st$adf$statistic)  else NA_real_
    kpss_p    <- if (!is.null(st$kpss)) to_num(st$kpss$p.value)   else NA_real_
    kpss_stat <- if (!is.null(st$kpss)) to_num(st$kpss$statistic) else NA_real_
    pp_p      <- if (!is.null(st$pp))   to_num(st$pp$p.value)     else NA_real_
    pp_stat   <- if (!is.null(st$pp))   to_num(st$pp$statistic)   else NA_real_
    
    tau_obs  <- NA_real_
    tau_crit <- NA_real_
    if (!is.null(st$ur)) {
      tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[tau_row]))
      if (!is.finite(tau_obs)) tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[1]))
      cv <- tryCatch(st$ur@cval, error = function(e) NULL)
      if (!is.null(cv) && is.matrix(cv) && !is.null(rownames(cv)) && !is.null(colnames(cv)) &&
          tau_row %in% rownames(cv) && alpha_col %in% colnames(cv)) {
        tau_crit <- suppressWarnings(as.numeric(cv[tau_row, alpha_col]))
      } else if (!is.null(cv) && !is.matrix(cv) && !is.null(names(cv)) && alpha_col %in% names(cv)) {
        tau_crit <- suppressWarnings(as.numeric(cv[[alpha_col]]))
      }
    }
    
    adf_dec_ts  <- if (is.finite(adf_p))  (adf_p  < alpha) else NA
    adf_dec_ur  <- if (is.finite(tau_obs) && is.finite(tau_crit)) (tau_obs < tau_crit) else NA
    kpss_reject <- if (is.finite(kpss_p)) (kpss_p < alpha) else NA
    pp_reject   <- if (is.finite(pp_p))   (pp_p   < alpha) else NA
    
    cat("==========================================================================\n")
    cat("           ACADEMIC REPORT: STATIONARITY TESTS (TRAINING SERIES)          \n")
    cat("==========================================================================\n")
    cat(sprintf(" Significance Level (α): %.2f\n", alpha))
    cat("--------------------------------------------------------------------------\n")
    
    # 1) ADF (tseries)
    cat(" 1) AUGMENTED DICKEY–FULLER — tseries::adf.test\n")
    if (is.null(st$adf)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  • Parametric unit-root test with lagged differences (need for differencing d).\n")
      cat(" HYPOTHESES:\n")
      cat("  • H0: Unit root (non-stationary)\n")
      cat("  • Ha: Stationary\n")
      cat(sprintf(" DECISION RULE (α=%.2f): Reject H0 if P-value < α.\n", alpha))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  • Proper lag length k; low power near unit root.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  • DF statistic : %s\n", fmt_num(adf_stat, 4)))
      cat(sprintf("  • P-value      : %s\n\n", fmt_p(adf_p)))
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ts)) {
        cat("  → P-value < α ⇒ REJECT H0 ⇒ Stationarity suggested.\n")
      } else if (identical(adf_dec_ts, FALSE)) {
        cat("  → P-value ≥ α ⇒ FAIL TO REJECT H0 ⇒ Possible unit root.\n")
      } else cat("  → Inconclusive (p-value NA/Inf).\n")
      cat(" SUGGESTIONS:\n")
      cat("  • If ADF fails but KPSS rejects, prefer d=1 and re-test.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # 2) ADF (ur.df)
    cat(" 2) ADF — urca::ur.df (tau vs. critical)\n")
    if (is.null(st$ur)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  • ADF with explicit deterministic component and chosen lag order.\n")
      cat(" HYPOTHESES:\n")
      cat("  • H0: Unit root (non-stationary)\n")
      cat("  • Ha: Stationary\n")
      cat(sprintf(" DECISION RULE (α=%.2f, %s): Reject H0 if Tau-Obs < Tau-Crit.\n", alpha, alpha_col))
      cat(" SPECIFICATION:\n")
      cat(sprintf("  • Model type : %s   • Lags (k): %s\n", adf_type_ui, as.character(k_lags)))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  • Wrong type (none/drift/trend) or too-small k can bias inference.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  • Tau-Obs    : %s\n", fmt_num(tau_obs, 4)))
      cat(sprintf("  • Tau-Crit   : %s (%s)\n\n", fmt_num(tau_crit, 4), alpha_col))
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ur)) {
        cat("  → Tau-Obs < Tau-Crit ⇒ REJECT H0 ⇒ Stationarity supported.\n")
      } else if (identical(adf_dec_ur, FALSE)) {
        cat("  → Tau-Obs ≥ Tau-Crit ⇒ FAIL TO REJECT H0 ⇒ Possible unit root.\n")
      } else cat("  → Inconclusive (tau/critical NA).\n")
      cat(" SUGGESTIONS:\n")
      cat("  • If residuals autocorrelate (Ljung–Box), increase k or difference the series.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # 3) KPSS
    cat(" 3) KPSS — tseries::kpss.test\n")
    if (is.null(st$kpss)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  • Tests null of stationarity (level or trend); complements ADF/PP.\n")
      cat(" HYPOTHESES:\n")
      cat(sprintf("  • H0: Stationary around a %s\n", ifelse(kpss_null_ui == "tau", "trend", "level")))
      cat("  • Ha: Non-stationary (unit root)\n")
      cat(sprintf(" DECISION RULE (α=%.2f): Reject H0 if P-value < α.\n", alpha))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  • Sensitive to unremoved trend/seasonality; small-sample distortions.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  • KPSS η     : %s\n", fmt_num(kpss_stat, 4)))
      cat(sprintf("  • P-value    : %s\n\n", fmt_p(kpss_p)))
      cat(" DECISION:\n")
      if (isTRUE(kpss_reject)) {
        cat("  → P-value < α ⇒ REJECT H0 ⇒ Evidence of NON-STATIONARITY.\n")
      } else if (identical(kpss_reject, FALSE)) {
        cat("  → P-value ≥ α ⇒ FAIL TO REJECT H0 ⇒ Stationarity is plausible.\n")
      } else cat("  → Inconclusive (p-value NA/Inf).\n")
      cat(" SUGGESTIONS:\n")
      cat("  • If KPSS rejects and ADF/PP don’t, set d=1 (and D=1 if seasonal), then re-test.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # 4) PP
    cat(" 4) PHILLIPS–PERRON — tseries::pp.test\n")
    if (is.null(st$pp)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  • Unit-root test with nonparametric correction (robust to serial correlation/heteroskedasticity).\n")
      cat(" HYPOTHESES:\n")
      cat("  • H0: Unit root (non-stationary)\n")
      cat("  • Ha: Stationary\n")
      cat(sprintf(" DECISION RULE (α=%.2f): Reject H0 if P-value < α.\n", alpha))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  • Low power near unit root; interpret with KPSS.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  • PP statistic : %s\n", fmt_num(pp_stat, 4)))
      cat(sprintf("  • P-value      : %s\n\n", fmt_p(pp_p)))
      cat(" DECISION:\n")
      if (isTRUE(pp_reject)) {
        cat("  → P-value < α ⇒ REJECT H0 ⇒ Stationarity suggested.\n")
      } else if (identical(pp_reject, FALSE)) {
        cat("  → P-value ≥ α ⇒ FAIL TO REJECT H0 ⇒ Possible unit root.\n")
      } else cat("  → Inconclusive (p-value NA/Inf).\n")
      cat(" SUGGESTIONS:\n")
      cat("  • If PP & ADF fail but KPSS rejects, difference (d=1; D=1 if seasonal) and re-test.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # Synthesis
    cat(" SYNTHESIS & PRACTICAL RECOMMENDATIONS\n")
    if ((isTRUE(adf_dec_ts) || isTRUE(adf_dec_ur) || isTRUE(pp_reject)) && !isTRUE(kpss_reject)) {
      cat(" • Convergent STATIONARITY: use d=0; if seasonal, model with SARIMA terms rather than differencing more.\n")
    } else if ((identical(adf_dec_ts, FALSE) || identical(adf_dec_ur, FALSE) || identical(pp_reject, FALSE)) && isTRUE(kpss_reject)) {
      cat(" • Convergent UNIT ROOT: set d=1 (and D=1 if seasonal), then re-test before identification.\n")
    } else {
      cat(" • Mixed results: align deterministic spec (none/drift/trend), tune ADF lag k (check Ljung–Box),\n")
      cat("   treat seasonality first (D=1 if needed), consider log/Box–Cox for variance, and check for breaks.\n")
    }
    cat("\n==========================================================================\n\n")
  })
  
  
  
 
  
  
  
  
  
  
  
  output$stationarity_interpretation <- renderPrint({
    req(stationarity())
    st <- stationarity()
    
    # ---- helpers ----
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0) a else b
    to_num <- function(x, d = NA_real_) {
      y <- suppressWarnings(as.numeric(x))
      ifelse(is.finite(y), y, d)
    }
    to_int <- function(x, d = NA_integer_) {
      y <- suppressWarnings(as.integer(x))
      ifelse(is.finite(y), y, d)
    }
    
    fmt_p <- if (exists("fmt_p", inherits = TRUE)) get("fmt_p") else function(p) {
      if (!is.finite(p)) return("NA")
      format.pval(p, digits = 4, eps = .Machine$double.eps)
    }
    fmt_num <- if (exists("fmt_num", inherits = TRUE)) get("fmt_num") else function(x, d = 4) {
      if (!is.finite(x)) return("NA")
      format(round(x, d), nsmall = d)
    }
    
    # ---- series used ----
    n_used <- if (!is.null(st$series)) length(st$series) else NA_integer_
    
    # Prefer stationarity() metadata when available
    adf_type_ui <- st$type_used %||% (input$adfTypeSt2 %||% "drift")
    alpha <- to_num(st$alpha_used, to_num(input$alphaSt2, 0.05))
    
    # fixed-lag (user-provided) metadata
    k_lags <- as.integer(to_num(st$k_used, to_num(input$LagOrderADFd2St, 10)))
    
    # auto-lag metadata (AIC among 0..Kmax)
    k_auto <- as.integer(to_num(st$k_auto, NA_real_))
    max_lag_auto <- as.integer(to_num(st$max_lag_auto, NA_real_))
    
    # KPSS null pairing (informational)
    kpss_null_ui <- if (adf_type_ui == "trend") "tau" else "mu"
    
    # Map for ur.df critical values
    tau_row <- switch(adf_type_ui, "none" = "tau1", "drift" = "tau2", "trend" = "tau3", "tau3")
    alpha_col <- switch(
      as.character(alpha),
      "0.01" = "1pct",
      "0.05" = "5pct",
      "0.1"  = "10pct",
      "0.10" = "10pct",
      "5pct"
    )
    
    # =========================
    # NEW: Python-like ADF (no k specified) + report chosen lag
    # tseries::adf.test default lag rule:
    #   k_default = trunc((n - 1)^(1/3))
    # =========================
    k_default_adf <- NA_integer_
    if (is.finite(n_used) && n_used >= 2) {
      k_default_adf <- as.integer(trunc((n_used - 1)^(1/3)))
      if (!is.finite(k_default_adf) || k_default_adf < 0L) k_default_adf <- NA_integer_
    }
    
    adf_auto_obj  <- NULL
    adf_auto_p    <- NA_real_
    adf_auto_stat <- NA_real_
    adf_auto_err  <- NULL
    
    # Run WITHOUT specifying k (Python-like)
    if (!is.null(st$series) && length(st$series) >= 10) {
      adf_auto_obj <- tryCatch(
        tseries::adf.test(st$series, alternative = input$alternd2St %||% "stationary"),
        error = function(e) { adf_auto_err <<- e$message; NULL }
      )
      if (!is.null(adf_auto_obj)) {
        adf_auto_p    <- to_num(adf_auto_obj$p.value)
        adf_auto_stat <- to_num(adf_auto_obj$statistic)
      }
    }
    
    # ---- fixed-lag ur.df tau & crit ----
    tau_obs <- NA_real_
    tau_crit <- NA_real_
    if (!is.null(st$ur)) {
      tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[tau_row]))
      if (!is.finite(tau_obs)) tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[1]))
      
      cv <- tryCatch(st$ur@cval, error = function(e) NULL)
      if (!is.null(cv) && is.matrix(cv) &&
          tau_row %in% rownames(cv) && alpha_col %in% colnames(cv)) {
        tau_crit <- suppressWarnings(as.numeric(cv[tau_row, alpha_col]))
      }
    }
    
    # ---- auto-lag ur.df tau & crit ----
    tau_obs_auto <- NA_real_
    tau_crit_auto <- NA_real_
    if (!is.null(st$ur_auto)) {
      tau_obs_auto <- suppressWarnings(as.numeric(st$ur_auto@teststat[tau_row]))
      if (!is.finite(tau_obs_auto)) tau_obs_auto <- suppressWarnings(as.numeric(st$ur_auto@teststat[1]))
      
      cv2 <- tryCatch(st$ur_auto@cval, error = function(e) NULL)
      if (!is.null(cv2) && is.matrix(cv2) &&
          tau_row %in% rownames(cv2) && alpha_col %in% colnames(cv2)) {
        tau_crit_auto <- suppressWarnings(as.numeric(cv2[tau_row, alpha_col]))
      }
    }
    
    # ---- tseries numbers (your existing fixed-k ADF) ----
    adf_p    <- if (!is.null(st$adf))  to_num(st$adf$p.value)    else NA_real_
    adf_stat <- if (!is.null(st$adf))  to_num(st$adf$statistic)  else NA_real_
    
    kpss_p    <- if (!is.null(st$kpss)) to_num(st$kpss$p.value)   else NA_real_
    kpss_stat <- if (!is.null(st$kpss)) to_num(st$kpss$statistic) else NA_real_
    
    pp_p    <- if (!is.null(st$pp)) to_num(st$pp$p.value) else NA_real_
    pp_stat <- if (!is.null(st$pp)) to_num(st$pp$statistic) else NA_real_
    
    # ---- lags used by tests (best effort) ----
    adf_lags_used <- k_lags
    kpss_lags_used <- if (!is.null(st$kpss) && !is.null(st$kpss$parameter)) as.integer(to_num(st$kpss$parameter)) else NA_integer_
    pp_lags_used   <- if (!is.null(st$pp)   && !is.null(st$pp$parameter))   as.integer(to_num(st$pp$parameter))   else NA_integer_
    
    # ---- decisions ----
    adf_auto_dec_ts <- if (is.finite(adf_auto_p)) (adf_auto_p < alpha) else NA
    
    adf_dec_ts      <- if (is.finite(adf_p)) (adf_p < alpha) else NA
    adf_dec_ur      <- if (is.finite(tau_obs) && is.finite(tau_crit)) (tau_obs < tau_crit) else NA
    adf_dec_ur_auto <- if (is.finite(tau_obs_auto) && is.finite(tau_crit_auto)) (tau_obs_auto < tau_crit_auto) else NA
    
    kpss_reject <- if (is.finite(kpss_p)) (kpss_p < alpha) else NA
    pp_reject   <- if (is.finite(pp_p)) (pp_p < alpha) else NA
    
    # ---- HEADER ----
    cat("==========================================================================\n")
    cat("                 ACADEMIC REPORT: STATIONARITY ANALYSIS                   \n")
    cat("==========================================================================\n")
    cat(" Number of Observations Used: ", ifelse(is.finite(n_used), n_used, "NA"), "\n", sep = "")
    cat(" Significance Level (α): ", format(alpha, nsmall = 2), "\n", sep = "")
    cat("--------------------------------------------------------------------------\n")
    
    # ---- TEACHING NOTES: overview ----
    cat(" STATIONARITY ANALYSIS (overview):\n")
    cat(" • Stationarity in SARIMA usually means: mean/variance roughly stable over time and autocorrelation decays.\n")
    cat(" • ADF / PP: H0 = unit root (non-stationary). KPSS: H0 = stationary. They complement each other.\n")
    cat(" • Differencing guidance:\n")
    cat("    - Use d for non-seasonal trend; use D for seasonal unit roots.\n")
    cat("    - Avoid over-differencing: it can induce negative autocorrelation and inflate forecast variance.\n")
    cat(" • Deterministic terms (ur.df type):\n")
    cat("    - none: no intercept/trend; drift: intercept; trend: intercept + deterministic trend.\n")
    cat(" • Caution: structural breaks/outliers can make unit-root tests misleading. Always check plots.\n")
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 1A) Python-like ADF (tseries::adf.test with automatic k) ----
    cat(" 1A. ADF — tseries::adf.test (AUTO Lag : k)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(adf_auto_obj)) {
      cat("    Not available.\n")
      if (!is.null(adf_auto_err)) cat("    Reason: ", adf_auto_err, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" • H0: the series has a unit root (non-stationary)\n")
      cat(" • Ha: the series is stationary\n")
      cat(" • Reject H0 if P-value < α.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - Lag selection       : automatic (no k provided)\n")
      cat("    - Default lag formula : k = trunc((n - 1)^(1/3))\n")
      cat("    - n used              : ", ifelse(is.finite(n_used), n_used, "NA"), "\n", sep = "")
      cat("    - #Lags chosen (k)    : ", ifelse(is.finite(k_default_adf), k_default_adf, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic (DF) : ", fmt_num(adf_auto_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(adf_auto_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_auto_dec_ts)) {
        cat("  P-value < α ⇒ REJECT H0: Evidence suggests STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  This result mirrors common Python workflows: the ADF lag length is chosen automatically based on sample size.\n")
        cat("  Rejecting H0 suggests the series does not behave like a unit-root process under this default lag choice.\n")
        cat("  In SARIMA practice, this reduces the need for non-seasonal differencing (d), but you should still check seasonal\n")
        cat("  patterns (possibly D) and confirm with KPSS/PP plus ACF/PACF.\n")
      } else if (identical(adf_auto_dec_ts, FALSE)) {
        cat("  P-value ≥ α ⇒ FAIL TO REJECT H0: Evidence suggests NON-STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  With automatic lag choice, failing to reject H0 indicates a unit root remains plausible, so differencing is typically\n")
        cat("  justified (often d = 1). After differencing, re-run tests: if results flip to stationarity and residual diagnostics look\n")
        cat("  white-noise-like, you have a good basis for ARIMA modeling.\n")
      } else {
        cat("  ADF p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  When p-values are unavailable/non-finite, rely more on the ur.df tau/critical approach, KPSS/PP, and especially the time\n")
        cat("  plot + ACF/PACF. Also verify the series isn’t constant and has enough variation after cleaning.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 1) ADF (tseries::adf.test) fixed k (your existing one) ----
    cat(" 1B. ADF — tseries::adf.test (FIXED k)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$adf)) {
      cat("    Not available.\n")
      if (!is.null(st$adf_error)) cat("    Reason: ", st$adf_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" • H0: the series has a unit root (non-stationary)\n")
      cat(" • Ha: the series is stationary\n")
      cat(" • Reject H0 if P-value < α.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - #Lags Used (k)      : ", ifelse(is.finite(adf_lags_used), adf_lags_used, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic (DF) : ", fmt_num(adf_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(adf_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ts)) {
        cat("  P-value < α ⇒ REJECT H0: Evidence suggests STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Under the chosen fixed lag k, the unit-root null is rejected. This supports treating the series as stationary after\n")
        cat("  accounting for autocorrelation up to k lags. If this disagrees with KPSS, treat evidence as mixed and validate with\n")
        cat("  residual diagnostics and forecast performance.\n")
      } else if (identical(adf_dec_ts, FALSE)) {
        cat("  P-value ≥ α ⇒ FAIL TO REJECT H0: Evidence suggests NON-STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  With the selected fixed lag, a unit root cannot be ruled out. Consider differencing (d) and then re-check ACF/PACF.\n")
        cat("  If the ACF still shows seasonal spikes at multiples of s, consider seasonal differencing (D).\n")
      } else {
        cat("  ADF p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  When ADF is inconclusive, rely on ur.df tau/critical, PP, and KPSS along with plots. In teaching settings, it helps to\n")
        cat("  compare fixed-k vs auto-k to show sensitivity to lag choice.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 2) ADF (urca::ur.df) fixed lag ----
    cat(" 2A. ADF — urca::ur.df (FIXED lags; tau vs. critical)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$ur)) {
      cat("    Not available.\n")
      if (!is.null(st$ur_error)) cat("    Reason: ", st$ur_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" • H0: the series has a unit root (non-stationary)\n")
      cat(" • Ha: the series is stationary\n")
      cat(" • Reject H0 if Tau-Observed < Tau-Critical.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - Model type          : ", adf_type_ui, "  (none/drift/trend)\n", sep = "")
      cat("    - #Lags Used (k)      : ", ifelse(is.finite(k_lags), k_lags, "NA"), "\n", sep = "")
      
      cat(" CRITICAL VALUE:\n")
      cat("    - Tau Critical        : ", fmt_num(tau_crit, 4), " (", alpha_col, ")\n\n", sep = "")
      
      cat(" STATISTICS:\n")
      cat("    - Tau Observed        : ", fmt_num(tau_obs, 4), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ur)) {
        cat("  Tau-Obs < Tau-Crit ⇒ REJECT H0: Stationarity supported.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  The ur.df version is useful for teaching because it explicitly shows the deterministic component and uses a tau statistic\n")
        cat("  compared to critical values. Rejection strengthens the case for d = 0, but always check if seasonality implies D > 0.\n")
      } else if (identical(adf_dec_ur, FALSE)) {
        cat("  Tau-Obs ≥ Tau-Crit ⇒ FAIL TO REJECT H0: Possible unit root.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Failing to reject here suggests non-stationarity under the chosen deterministic component and lag order. In practice, try\n")
        cat("  differencing and re-run tests; in teaching, compare type=drift vs type=trend to show how assumptions change conclusions.\n")
      } else {
        cat("  Tau or critical value missing; cannot form a decision.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If critical values are missing (package/version issues), use PP + KPSS and emphasize plot-based diagnostics.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 2A) ADF (urca::ur.df) automatic lag selection ----
    cat(" 2B. ADF — urca::ur.df (AUTOMATIC lags via AIC; tau vs. critical)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$ur_auto)) {
      cat("    Not available.\n")
      if (!is.null(st$ur_auto_error)) cat("    Reason: ", st$ur_auto_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" • H0: the series has a unit root (non-stationary)\n")
      cat(" • Ha: the series is stationary\n")
      cat(" • Lags are selected automatically using AIC within 0..Kmax.\n")
      cat(" • Reject H0 if Tau-Observed < Tau-Critical.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - Model type          : ", adf_type_ui, "\n", sep = "")
      cat("    - Kmax searched       : ", ifelse(is.finite(max_lag_auto), max_lag_auto, "NA"), "\n", sep = "")
      cat("    - #Lags chosen (auto) : ", ifelse(is.finite(k_auto), k_auto, "NA"), "\n", sep = "")
      
      cat(" CRITICAL VALUE:\n")
      cat("    - Tau Critical        : ", fmt_num(tau_crit_auto, 4), " (", alpha_col, ")\n\n", sep = "")
      
      cat(" STATISTICS:\n")
      cat("    - Tau Observed        : ", fmt_num(tau_obs_auto, 4), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ur_auto)) {
        cat("  Tau-Obs < Tau-Crit ⇒ REJECT H0: Stationarity supported.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  This is the most teachable/defensible ADF workflow: you set a maximum lag (Kmax) and let AIC pick the lag that best\n")
        cat("  explains autocorrelation without overfitting. Agreement with PP (reject unit root) and KPSS (do not reject stationarity)\n")
        cat("  is strong evidence for d = 0, subject to seasonal structure.\n")
      } else if (identical(adf_dec_ur_auto, FALSE)) {
        cat("  Tau-Obs ≥ Tau-Crit ⇒ FAIL TO REJECT H0: Possible unit root.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Even with AIC-selected lag, the unit-root null remains plausible. This supports differencing. In teaching, highlight that\n")
        cat("  lag choice matters because too few lags leave autocorrelation in errors; too many reduce power.\n")
      } else {
        cat("  Tau or critical value missing; cannot form a decision.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If tau/critical values can’t be extracted, treat as supportive context and rely on the other tests + plots.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 3) KPSS ----
    cat(" 3. KPSS — tseries::kpss.test\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$kpss)) {
      cat("    Not available.\n")
      if (!is.null(st$kpss_error)) cat("    Reason: ", st$kpss_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" • H0: the series is stationary around a ", ifelse(kpss_null_ui == "tau", "trend", "level"), "\n", sep = "")
      cat(" • Ha: the series is non-stationary\n")
      cat(" • Reject H0 if P-value < α.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - #Lags Used          : ", ifelse(is.finite(kpss_lags_used), kpss_lags_used, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic (η)  : ", fmt_num(kpss_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(kpss_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(kpss_reject)) {
        cat("  P-value < α ⇒ REJECT H0: Evidence of NON-STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  KPSS is the mirror-image of ADF/PP: it rejects stationarity. If ADF/PP fail to reject unit root AND KPSS rejects\n")
        cat("  stationarity, that’s convergent evidence for differencing. If KPSS conflicts with ADF, emphasize mixed evidence and\n")
        cat("  validate with residual diagnostics and forecast accuracy.\n")
      } else if (identical(kpss_reject, FALSE)) {
        cat("  P-value ≥ α ⇒ FAIL TO REJECT H0: Stationarity is plausible.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Non-rejection supports stationarity around level/trend. In teaching, KPSS is great to show why ‘fail to reject’ is not\n")
        cat("  ‘prove stationarity’, but combined with ADF/PP it builds a coherent story.\n")
      } else {
        cat("  KPSS p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If KPSS is unavailable/inconclusive, rely more on ADF/PP + plots and consider using multiple transformations.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 4) Phillips–Perron ----
    cat(" 4. PHILLIPS–PERRON — tseries::pp.test\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$pp)) {
      cat("    Not available.\n")
      if (!is.null(st$pp_error)) cat("    Reason: ", st$pp_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" • H0: the series has a unit root (non-stationary)\n")
      cat(" • Ha: the series is stationary\n")
      cat(" • Reject H0 if P-value < α.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - #Lags Used          : ", ifelse(is.finite(pp_lags_used), pp_lags_used, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic      : ", fmt_num(pp_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(pp_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(pp_reject)) {
        cat("  P-value < α ⇒ REJECT H0: Stationarity suggested.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  PP is a robust alternative to ADF that corrects for serial correlation/heteroskedasticity nonparametrically.\n")
        cat("  In teaching, it’s useful to show that agreement between PP and ADF strengthens inference, while disagreement suggests\n")
        cat("  sensitivity to assumptions and motivates a conservative workflow.\n")
      } else if (identical(pp_reject, FALSE)) {
        cat("  P-value ≥ α ⇒ FAIL TO REJECT H0: Possible unit root.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  PP does not reject a unit root, supporting differencing. Re-test after differencing and check residual whiteness.\n")
      } else {
        cat("  PP p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If PP is inconclusive, rely on the other tests + plots, and consider transformations (log/Box-Cox) before differencing.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- Final synthesis ----
    cat(" RECOMMENDATION (practical SARIMA workflow):\n")
    cat("--------------------------------------------------------------------------\n")
    
    cat(" • Step 1: Inspect time plot + ACF/PACF (look for slow decay and seasonal spikes).\n")
    cat(" • Step 2: Use evidence from ADF/PP (unit root) + KPSS (stationarity null) to decide d and D.\n")
    cat(" • Step 3: Apply minimal differencing; re-check tests and plots.\n")
    cat(" • Step 4: Fit SARIMA; verify residuals ~ white noise (Ljung-Box, residual ACF).\n")
    cat(" • Step 5: Prefer the model that passes diagnostics and forecasts well (not just lowest AIC).\n\n")
    
    # teaching: show how to interpret convergence
    if ((isTRUE(adf_auto_dec_ts) || isTRUE(adf_dec_ts) || isTRUE(adf_dec_ur) || isTRUE(adf_dec_ur_auto) || isTRUE(pp_reject)) && !isTRUE(kpss_reject)) {
      cat(" • Convergent evidence: STATIONARITY likely (consider d = 0; then evaluate seasonal differencing D).\n")
    } else if ((identical(adf_auto_dec_ts, FALSE) || identical(adf_dec_ts, FALSE) || identical(adf_dec_ur, FALSE) || identical(adf_dec_ur_auto, FALSE) || identical(pp_reject, FALSE)) && isTRUE(kpss_reject)) {
      cat(" • Convergent evidence: NON-STATIONARITY likely (difference: d and/or D; then re-test).\n")
    } else {
      cat(" • Mixed evidence: be conservative — try minimal differencing and validate using residual diagnostics + forecast accuracy.\n")
    }
    
    cat("\n==========================================================================\n\n")
  })
  
  
  
 
  diff_preview <- eventReactive(input$preview_diff, {
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    d <- as.numeric(input$d_preview)
    D <- as.numeric(input$D_preview)
    x2 <- x
    if (d > 0) x2 <- diff(x2, differences = d)
    if (D > 0) x2 <- diff(x2, lag = frequency(x), differences = D)
    x2
  })

  
  
  
  output$diff_plot <- renderPlot(
    {
      # =======================
      # Layout knobs (EDIT ME)
      # =======================
      LAG_MAX <- 40
      
      # When SPLIT (top + middle + (acf|pacf))
      # ↓↓↓ Reduce TOP, increase BOTTOM so ACF/PACF are readable
      H_TOP <- 0.7   # top: original series with split line
      H_MID <- 1.0   # middle: train-differenced series
      H_BOT <- 1.6   # bottom: ACF/PACF row
      
      # Width split between ACF and PACF
      W_LEFT  <- 1.0
      W_RIGHT <- 1.0
      
      # Panel styling knobs (teaching-friendly)
      TOP_TITLE_SIZE <- 11
      MID_TITLE_SIZE <- 12
      BOT_TITLE_SIZE <- 12
      
      TOP_MARGIN <- ggplot2::margin(t = 2, r = 6, b = 2, l = 6)
      MID_MARGIN <- ggplot2::margin(t = 6, r = 6, b = 6, l = 6)
      BOT_MARGIN <- ggplot2::margin(t = 6, r = 6, b = 6, l = 6)
      
      s <- ts_train_test()
      req(s$ts_train)
      
      d <- as.numeric(input$d_preview)
      D <- as.numeric(input$D_preview)
      
      has_test <- isTRUE(input$train_prop < 1) && length(s$ts_test) > 0
      
      # Full ORIGINAL series (no differencing)
      x_full_orig <- ts(
        c(as.numeric(s$ts_train), as.numeric(s$ts_test)),
        start = 1,
        frequency = frequency(s$ts_train)
      )
      
      # Differencing helper
      do_diff <- function(x) {
        x2 <- x
        if (d > 0) x2 <- diff(x2, differences = d)
        if (D > 0) x2 <- diff(x2, lag = frequency(x), differences = D)
        x2
      }
      
      # =========================
      # NO SPLIT: top reflects d,D
      # =========================
      if (!has_test) {
        x_full_diff <- do_diff(x_full_orig)
        
        p_top <- autoplot(x_full_diff) +
          ggtitle(paste0("Series preview (full), differenced (d=", d, ", D=", D, ")")) +
          xlab("Time") + ylab("Value") +
          theme(
            plot.title = element_text(size = MID_TITLE_SIZE),
            plot.margin = MID_MARGIN
          )
        
        p_acf  <- ggAcf(x_full_diff, lag.max = LAG_MAX) +
          ggtitle("ACF (full series, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        p_pacf <- ggPacf(x_full_diff, lag.max = LAG_MAX) +
          ggtitle("PACF (full series, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        (p_top / (p_acf | p_pacf)) +
          patchwork::plot_layout(heights = c(1.1, 1.0), widths = c(W_LEFT, W_RIGHT))
      } else {
        
        # =========================
        # SPLIT: top original + split line
        # =========================
        p_top <- autoplot(x_full_orig) +
          ggtitle("Original time series (no transformation) with Train/Test split") +
          xlab("Time") + ylab("Value") +
          theme(
            plot.title = element_text(size = TOP_TITLE_SIZE),
            plot.margin = TOP_MARGIN
          )
        
        split_time <- time(x_full_orig)[length(s$ts_train)]
        p_top <- p_top +
          geom_vline(xintercept = split_time, linetype = "dashed", color = "red") +
          annotate(
            "text",
            x = split_time,
            y = max(as.numeric(x_full_orig), na.rm = TRUE),
            label = "Train/Test split",
            vjust = -0.5, hjust = 0,
            color = "red",
            size = 3
          )
        
        # Middle: TRAIN-only differenced
        x_train_diff <- do_diff(s$ts_train)
        
        p_mid <- autoplot(x_train_diff) +
          ggtitle(paste0("Training portion only, differenced (d=", d, ", D=", D, ")")) +
          xlab("Time") + ylab("Differenced value") +
          theme(
            plot.title = element_text(size = MID_TITLE_SIZE),
            plot.margin = MID_MARGIN
          )
        
        # Bottom: ACF/PACF on TRAIN-diff
        p_acf <- ggAcf(x_train_diff, lag.max = LAG_MAX) +
          ggtitle("ACF (train only, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        p_pacf <- ggPacf(x_train_diff, lag.max = LAG_MAX) +
          ggtitle("PACF (train only, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        bottom_row <- (p_acf | p_pacf) +
          patchwork::plot_layout(widths = c(W_LEFT, W_RIGHT))
        
        # IMPORTANT: Force row heights so top is NOT huge
        (p_top / p_mid / bottom_row) +
          patchwork::plot_layout(heights = c(H_TOP, H_MID, H_BOT))
      }
    },
    
    # =======================
    # Output device sizing
    # =======================
    width = local({
      W_PX <- 990   # overall width (EDIT ME)
      W_PX
    }),
    
    height = local({
      H_NO_SPLIT_PX <- 750   # overall height without split (EDIT ME)
      H_SPLIT_PX    <- 950   # overall height with split (EDIT ME)
      function() {
        s <- ts_train_test()
        has_test <- isTRUE(input$train_prop < 1) &&
          !is.null(s$ts_test) &&
          length(s$ts_test) > 0
        if (has_test) H_SPLIT_PX else H_NO_SPLIT_PX
      }
    })
  )
  
  
  
 
  
  output$diff_plot <- renderPlot(
    {
      s <- ts_train_test()
      req(s$ts_train)
      
      d <- as.numeric(input$d_preview)
      D <- as.numeric(input$D_preview)
      
      has_test <- isTRUE(input$train_prop < 1) && length(s$ts_test) > 0
      
      # Build full ORIGINAL series (no differencing)
      x_full_orig <- ts(
        c(as.numeric(s$ts_train), as.numeric(s$ts_test)),
        start = 1,
        frequency = frequency(s$ts_train)
      )
      
      # Differencing helper (applies to any ts)
      do_diff <- function(x) {
        x2 <- x
        if (d > 0) x2 <- diff(x2, differences = d)
        if (D > 0) x2 <- diff(x2, lag = frequency(x), differences = D)
        x2
      }
      
      # ===== If NO SPLIT: upper plot should reflect parameters (d, D) =====
      if (!has_test) {
        x_full_diff <- do_diff(x_full_orig)
        
        p_top <- autoplot(x_full_diff) +
          ggtitle(paste0("Series preview (full), differenced (d=", d, ", D=", D, ")")) +
          xlab("Time") + ylab("Value")
        
        p_acf  <- ggAcf(x_full_diff, lag.max = 40) +
          ggtitle("ACF (full series, after differencing)")
        
        p_pacf <- ggPacf(x_full_diff, lag.max = 40) +
          ggtitle("PACF (full series, after differencing)")
        
        return(p_top / (p_acf | p_pacf))
      }
      
      # ===== If SPLIT: keep top ORIGINAL + split, then show TRAIN-diff + ACF/PACF =====
      p_top <- autoplot(x_full_orig) +
        ggtitle("Original time series (no transformation) with Train/Test split") +
        xlab("Time") + ylab("Value")
      
      split_time <- time(x_full_orig)[length(s$ts_train)]
      p_top <- p_top +
        geom_vline(xintercept = split_time, linetype = "dashed", color = "red") +
        annotate(
          "text",
          x = split_time,
          y = max(as.numeric(x_full_orig), na.rm = TRUE),
          label = "Train/Test split",
          vjust = -0.5, hjust = 0,
          color = "red",
          size = 3
        )
      
      # TRAIN-only after differencing
      x_train_diff <- do_diff(s$ts_train)
      
      p_train <- autoplot(x_train_diff) +
        ggtitle(paste0("Training portion only, differenced (d=", d, ", D=", D, ")")) +
        xlab("Time") + ylab("Differenced value")
      
      p_acf <- ggAcf(x_train_diff, lag.max = 40) +
        ggtitle("ACF (train only, after differencing)")
      
      p_pacf <- ggPacf(x_train_diff, lag.max = 40) +
        ggtitle("PACF (train only, after differencing)")
      
      p_top / (p_train / (p_acf | p_pacf))
    },
    width  = 990,
    height = function() {
      s <- ts_train_test()
      has_test <- isTRUE(input$train_prop < 1) && !is.null(s$ts_test) && length(s$ts_test) > 0
      if (has_test) 1050 else 750
    }
  )
  
 
  
  
  
  
  output$apa_stationarity_paragraph <- renderPrint({
    req(stationarity(), prepared())
    st <- stationarity()
    s_per <- prepared()$freq
    adf_txt <- if (!is.null(st$adf)) paste0("An Augmented Dickey–Fuller test indicated ", ifelse(st$adf$p.value < 0.05, "stationarity", "non-stationarity"), ", ", fmt_p(st$adf$p.value), ". ") else ""
    kpss_txt <- if (!is.null(st$kpss)) paste0("A KPSS test suggested ", ifelse(st$kpss$p.value < 0.05, "non-stationarity", "stationarity"), ", ", fmt_p(st$kpss$p.value), ". ") else ""
    pp_txt <- if (!is.null(st$pp)) paste0("A Phillips–Perron test suggested ", ifelse(st$pp$p.value < 0.05, "stationarity", "non-stationarity"), ", ", fmt_p(st$pp$p.value), ". ") else ""
    cat(
      "APA-ready paragraph (edit differencing decisions as needed):\n\n",
      adf_txt, kpss_txt, pp_txt,
      "Based on combined evidence and inspection of differenced series plots, appropriate non-seasonal (d) and seasonal (D) differencing ",
      "were selected prior to fitting SARIMA models (season length s = ", s_per, ").\n",
      sep = ""
    )
  })

  # ---- Step 5 Auto-ARIMA ----

  auto_fit <- eventReactive(input$fit_auto, {
    s <- ts_train_test()
    forecast::auto.arima(
      s$ts_train,
      seasonal = isTRUE(input$auto_seasonal),
      stepwise = isTRUE(input$auto_stepwise),
      approximation = isTRUE(input$auto_approx),
      allowmean = isTRUE(input$auto_allow_mean),
      allowdrift = isTRUE(input$auto_allow_mean),
      max.order = as.numeric(input$auto_max_order)
    )
  })

  auto_fc <- reactive({
    req(auto_fit(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    user_h <- if (!is.na(input$auto_h) && input$auto_h > 0) as.numeric(input$auto_h) else NA_real_
    if (s$test_n > 0) {
      h <- s$test_n
    } else {
      h <- if (!is.na(user_h)) user_h else max(1, frequency(s$ts_train))
    }
    fc <- forecast::forecast(auto_fit(), h = h)
    list(fc = fc, h = h, by = p$by)
  })

  output$auto_horizon_note <- renderPrint({
    req(ts_train_test(), auto_fc())
    s <- ts_train_test()
    if (s$test_n > 0) {
      cat("Validation mode: forecast horizon is forced to the test length (h =", s$test_n, ") to overlay the test period.\n")
    } else {
      cat("Future mode: no test set. Forecast horizon uses your 'Future horizon h' setting (or defaults to one seasonal cycle).\n")
    }
  })

  output$auto_model_spec <- renderPrint({
    req(auto_fit(), prepared())
    fit <- auto_fit()
    p <- prepared()
    cat("Auto-ARIMA selected model:\n")
    cat("- Specification:", as.character(fit), "\n")
    cat("- Seasonal period (s):", p$freq, "\n")
    cat("- Information criteria: AICc =", fmt_num(fit$aicc, 2), ", BIC =", fmt_num(fit$bic, 2), "\n")
  })

  output$auto_coef_table <- renderTable({ req(auto_fit()); coef_table(auto_fit()) }, rownames = FALSE)
  output$auto_resid_ts <- renderPlot({ req(auto_fit()); plot(residuals(auto_fit()), main = "Residuals (Auto-ARIMA)", ylab = "Residual", xlab = "Time") })
  output$auto_resid_acf <- renderPlot({ req(auto_fit()); plot(acf(residuals(auto_fit()), plot = FALSE), main = "Residual ACF (Auto-ARIMA)") })
  output$auto_resid_hist <- renderPlot({ req(auto_fit()); hist(residuals(auto_fit()), breaks = 30, main = "Residual histogram", xlab = "Residual") })
  output$auto_resid_qq <- renderPlot({ req(auto_fit()); qqnorm(residuals(auto_fit())); qqline(residuals(auto_fit())) })
  
  # Ljung–Box p-values across lags (Auto-ARIMA)
  output$auto_resid_lb_pvals <- renderPlot({
    req(auto_fit())
    
    res <- residuals(auto_fit())
    res <- as.numeric(res)[is.finite(res)]
    
    # Use the same controls you already expose for diagnostics
    L_input <- suppressWarnings(as.integer(input$diag_lag))
    L       <- if (is.finite(L_input) && L_input > 0) L_input else 12L
    fitdf   <- length(coef(auto_fit()))
    alpha   <- suppressWarnings(as.numeric(input$alphaSt2)); if (!is.finite(alpha)) alpha <- 0.05
    
    N <- length(res)
    validate(need(N >= 8, "Too few residuals (N < 8) to compute Ljung–Box p-values."))
    L <- max(1L, min(L, N - 1L))
    
    # Compute p-values at cumulative lags 1..L (omit k <= fitdf where df<=0)
    pvals <- rep(NA_real_, L)
    for (k in seq_len(L)) {
      if (k > fitdf) {
        bt <- tryCatch(stats::Box.test(res, lag = k, type = "Ljung-Box", fitdf = fitdf),
                       error = function(e) NULL)
        pvals[k] <- if (!is.null(bt)) as.numeric(bt$p.value) else NA_real_
      }
    }
    
    # Base R plotting to match your existing diagnostics
    plot(seq_len(L), pvals,
         type = "h", lwd = 2,
         xlab = "Lag (k)",
         ylab = "p-value  (Ljung–Box up to lag k)",
         main = "Ljung–Box p-values by lag (Auto-ARIMA)",
         ylim = c(0, 1))
    points(seq_len(L), pvals, pch = 16)
    abline(h = alpha, lty = 2)
    mtext(sprintf("alpha = %.3f,   fitdf = %d", alpha, fitdf), side = 3, line = 0.2, cex = 0.8)
    
    if (fitdf >= 1 && fitdf < L) {
      rect(xleft = 0.5, ybottom = -0.02, xright = fitdf + 0.5, ytop = 1.02,
           border = NA, col = grDevices::adjustcolor("gray", alpha.f = 0.15))
      text(x = (fitdf + 1) / 2, y = 0.95, labels = "df ≤ 0 (omitted)", cex = 0.8)
    }
  })
  
  
  
  
  
  
  
  
  #===============================================================
  #===============================================================
  #===============================================================
  
  
  
  # ============================================================
  # --- FIXED: Auto-ARIMA equation renderer (MathJax-safe) ---
  # ============================================================
  
  auto_equations <- reactive({
    req(auto_fit())
    fit <- auto_fit()
    
    # --- Orders from forecast::Arima (arma = c(p, q, P, Q, m, d, D)) ---
    arma <- fit$arma
    p <- arma[1]; q <- arma[2]; P <- arma[3]; Q <- arma[4]
    s <- ifelse(isTRUE(arma[5] > 0), arma[5], 1L)
    d <- arma[6]; D <- arma[7]
    
    coefs <- stats::coef(fit)
    nm    <- names(coefs)
    
    ip <- if (p > 0) seq_len(p) else integer(0)
    iq <- if (q > 0) seq_len(q) else integer(0)
    iP <- if (P > 0) seq_len(P) else integer(0)
    iQ <- if (Q > 0) seq_len(Q) else integer(0)
    
    # Intercept/mean (show only when meaningful)
    intercept_name <- intersect(c("intercept", "mean"), nm)
    intercept_val  <- if (length(intercept_name) > 0) unname(coefs[intercept_name[1]]) else NA_real_
    show_intercept <- is.finite(intercept_val) && abs(intercept_val) > 1e-8 && d == 0 && D == 0
    intercept_num  <- if (show_intercept) sprintf("%.3f", intercept_val) else ""
    
    # Drift (present only when differencing is used and auto.arima included it)
    drift_val <- if ("drift" %in% nm) unname(coefs["drift"]) else NA_real_
    show_drift <- is.finite(drift_val) && abs(drift_val) > 1e-8 && (d > 0 || D > 0)
    
    # MathJax wrappers
    tex_display <- function(x) paste0("\\[", x, "\\]")
    
    # Cosmetic cleanup for numeric line
    simplify_tex <- function(x) {
      x <- gsub("\\(1\\)", "", x)
      x <- gsub("\\s+", " ", x)
      x <- gsub("\\+\\s*\\+", "+", x)
      x <- gsub("\\+\\s*-", "-", x)
      x <- gsub("-\\s*\\+", "-", x)
      x <- gsub("-\\s*-", "+", x)
      x <- gsub("\\s*\\+\\s*0\\.000\\b", "", x)
      trimws(x)
    }
    
    # ---- Parameter-polynomial strings (symbolic) ----
    poly_param_ar  <- function() if (p == 0) "1" else paste0("1", paste0(" - \\phi_{", ip, "}L^{", ip, "}", collapse = ""))
    poly_param_sar <- function() if (P == 0) "1" else paste0("1", paste0(" - \\Phi_{", iP, "}L^{", s * iP, "}", collapse = ""))
    poly_param_ma  <- function() if (q == 0) "1" else paste0("1", paste0(" + \\theta_{", iq, "}L^{", iq, "}", collapse = ""))
    poly_param_sma <- function() if (Q == 0) "1" else paste0("1", paste0(" + \\Theta_{", iQ, "}L^{", s * iQ, "}", collapse = ""))
    
    # ---- Numeric polynomials (use estimated coefficients) ----
    poly_num_ar <- function() {
      if (p == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("ar", ip)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], ip[keep]), collapse = ""))
    }
    poly_num_sar <- function() {
      if (P == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("sar", iP)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iP
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], lags[keep]), collapse = ""))
    }
    poly_num_ma <- function() {
      if (q == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("ma", iq)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], iq[keep]), collapse = ""))
    }
    poly_num_sma <- function() {
      if (Q == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("sma", iQ)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iQ
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], lags[keep]), collapse = ""))
    }
    
    # Differencing operators (omit if exponent is zero)
    diff_part  <- if (d > 0) paste0("(1-L)^{", d, "}") else ""
    sdiff_part <- if (D > 0) paste0("(1-L^{", s, "})^{", D, "}") else ""
    
    # ---------- Line 1: General operator form ----------
    # \phi_p(L)\Phi_P(L^S)(1-L)^d(1-L^S)^D Y_t = c + \theta_q(L)\Theta_Q(L^S)\varepsilon_t (+ drift when appropriate)
    line1 <- paste0(
      "\\phi_p(L)\\,\\Phi_P(L^{S})\\,(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + \\theta_q(L)\\,\\Theta_Q(L^{S})\\varepsilon_t",
      if (show_drift) " + \\delta t" else ""
    )
    
    # ---------- Line 2: Expanded operator (summation) ----------
    line2 <- paste0(
      "\\left(1-\\sum_{i=1}^{p}\\phi_i L^{i}\\right)",
      "\\left(1-\\sum_{j=1}^{P}\\Phi_j L^{jS}\\right)",
      "(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + ",
      "\\left(1+\\sum_{i=1}^{q}\\theta_i L^{i}\\right)",
      "\\left(1+\\sum_{j=1}^{Q}\\Theta_j L^{jS}\\right)",
      "\\varepsilon_t",
      if (show_drift) " + \\delta t" else ""
    )
    
    # ---------- Line 3: Parameter-expanded polynomials ----------
    line3 <- paste0(
      "(", poly_param_ar(), ")",
      "(", poly_param_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = c + ",
      "(", poly_param_ma(), ")",
      "(", poly_param_sma(), ")\\varepsilon_t",
      if (show_drift) " + \\delta t" else ""
    )
    
    # ---------- Line 4: Numeric-expanded polynomials ----------
    rhs_intercept <- if (show_intercept) paste0(intercept_num, " + ") else ""
    line4 <- paste0(
      "(", poly_num_ar(), ")",
      "(", poly_num_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = ",
      rhs_intercept,
      "(", poly_num_ma(), ")",
      "(", poly_num_sma(), ")\\varepsilon_t",
      if (show_drift) paste0(" + ", sprintf("%.3f", drift_val), "t") else ""
    )
    line4 <- simplify_tex(line4)
    
    # ---------- Coefficient legend ----------
    coef_lines <- c()
    if (show_intercept) coef_lines <- c(coef_lines, paste0("c (intercept/mean) = ", sprintf("%.4f", intercept_val)))
    if (show_drift)     coef_lines <- c(coef_lines, paste0("drift (\\(\\delta\\)) = ", sprintf("%.4f", drift_val)))
    
    if (p > 0) {
      for (i in ip) {
        nm_i <- paste0("ar", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\phi_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (q > 0) {
      for (i in iq) {
        nm_i <- paste0("ma", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\theta_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (P > 0) {
      for (i in iP) {
        nm_i <- paste0("sar", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\Phi_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (Q > 0) {
      for (i in iQ) {
        nm_i <- paste0("sma", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\Theta_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (length(coef_lines) == 0) coef_lines <- "No coefficients available."
    
    list(
      p = p, d = d, q = q, P = P, D = D, Q = Q, s = s,
      eq_general      = tex_display(line1),
      eq_expanded     = tex_display(line2),
      eq_line3        = tex_display(line3),
      eq_line4        = tex_display(line4),
      coef_lines      = coef_lines
    )
  })
  
  output$auto_model_equation <- renderUI({
    req(auto_equations())
    eq <- auto_equations()
    
    tagList(
      tags$div(
        style = "text-align:left;",
        tags$h4("Auto-ARIMA model"),
        tags$p(sprintf("ARIMA(%d,%d,%d)%s",
                       eq$p, eq$d, eq$q,
                       if (eq$s > 1) sprintf(" × (%d,%d,%d)[%d]", eq$P, eq$D, eq$Q, eq$s) else "")),
        
        tags$h5("Estimated coefficients"),
        tags$ul(lapply(eq$coef_lines, function(x) tags$li(HTML(x)))),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h4("General SARIMA formulation"),
        HTML(eq$eq_general),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h4("Expanded operator form"),
        HTML(eq$eq_expanded),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h4("Numerical model"),
        HTML(eq$eq_line3),
        
        tags$br(),
        tags$hr(),
        tags$hr(),,
        
        # HTML("\\[\\text{------------}\\]"),
        HTML(eq$eq_line4),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
      ),
      
      # Force MathJax typesetting for dynamically injected content
      tags$script(HTML("
      if (window.MathJax) {
        if (window.MathJax.Hub) { MathJax.Hub.Queue(['Typeset', MathJax.Hub]); }
        else if (window.MathJax.typesetPromise) { MathJax.typesetPromise(); }
      }
    "))
    )
  })
  
  
  
  
  
  
  
  
  #===============================================================
  #===============================================================
  #===============================================================
  
  
  # output$auto_diag_tests <- renderText({ req(auto_fit()); diag_tests_text(residuals(auto_fit()), lag = as.numeric(input$diag_lag), fitdf = length(coef(auto_fit()))) })

  
  output$auto_diag_tests <- renderText({
    req(auto_fit())
    res   <- residuals(auto_fit())
    L     <- as.integer(input$diag_lag %||% 12L)
    fitdf <- length(coef(auto_fit()))
    alpha <- to_num_safe(input$alphaSt2 %||% 0.05, 0.05)
    residual_diagnostics_report(res, L = L, fitdf = fitdf, alpha = alpha)
  })
  
  

  
  
  residual_diagnostics_report <- function(res, L = 12L, fitdf = 0L, alpha = 0.05) {
    # ---- Safe helpers (use local fallbacks if not already defined globally) ----
    if (!exists("fmt_p", inherits = TRUE)) {
      fmt_p <- function(p) {
        if (!is.finite(p)) return("NA")
        if (p < .001) "<0.001" else sprintf("%.6f", p)
      }
    }
    if (!exists("fmt_num", inherits = TRUE)) {
      fmt_num <- function(z, d = 6) ifelse(is.finite(z), sprintf(paste0("%.", d, "f"), z), "NA")
    }
    
    # ---- Sanitize inputs ----
    res   <- as.numeric(res)
    res   <- res[is.finite(res)]
    N     <- length(res)
    L     <- max(1L, as.integer(L))
    fitdf <- max(0L, as.integer(fitdf))
    alpha <- suppressWarnings(as.numeric(alpha)); if (!is.finite(alpha)) alpha <- 0.05
    if (N < 8) {
      return(
        "==========================================================================\n" %+%
          "                     RESIDUAL DIAGNOSTIC BATTERY                          \n" %+%
          "==========================================================================\n" %+%
          "Too few residuals (N < 8) to run the requested tests."
      )
    }
    
    # Convenience
    `%+%` <- function(a, b) paste0(a, b)
    df_lb <- max(L - fitdf, 1L)             # Ljung–Box / Box–Pierce df after parameter adjustment
    cv_lb <- stats::qchisq(1 - alpha, df = df_lb)
    
    # ---- 1) Ljung–Box (portmanteau for autocorrelation) ----
    lb <- tryCatch(stats::Box.test(res, lag = L, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
    lb_stat <- if (!is.null(lb)) as.numeric(lb$statistic) else NA_real_
    lb_p    <- if (!is.null(lb)) as.numeric(lb$p.value)   else NA_real_
    
    # ---- 2) Box–Pierce (classic portmanteau) ----
    bp <- tryCatch(stats::Box.test(res, lag = L, type = "Box-Pierce", fitdf = fitdf), error = function(e) NULL)
    bp_stat <- if (!is.null(bp)) as.numeric(bp$statistic) else NA_real_
    bp_p    <- if (!is.null(bp)) as.numeric(bp$p.value)   else NA_real_
    
    # ---- 3) Jarque–Bera (normality of residuals; large-sample χ^2_2) ----
    jb <- if (requireNamespace("tseries", quietly = TRUE))
      tryCatch(tseries::jarque.bera.test(res), error = function(e) NULL) else NULL
    jb_stat <- if (!is.null(jb)) as.numeric(jb$statistic) else NA_real_
    jb_p    <- if (!is.null(jb)) as.numeric(jb$p.value)   else NA_real_
    cv_jb   <- stats::qchisq(1 - alpha, df = 2)  # asymptotic
    
    # ---- 4) Shapiro–Wilk (normality; exact test for N in [3, 5000]) ----
    sw <- if (N >= 3 && N <= 5000)
      tryCatch(stats::shapiro.test(res), error = function(e) NULL) else NULL
    sw_W <- if (!is.null(sw)) as.numeric(sw$statistic) else NA_real_
    sw_p <- if (!is.null(sw)) as.numeric(sw$p.value)   else NA_real_
    
    # ---- 5) Engle’s ARCH LM (conditional heteroskedasticity) ----
    arch_lags <- min(L, max(1L, floor(N/10)))
    arch <- if (requireNamespace("FinTS", quietly = TRUE))
      tryCatch(FinTS::ArchTest(res, lags = arch_lags), error = function(e) NULL) else NULL
    arch_stat <- if (!is.null(arch)) as.numeric(arch$statistic) else NA_real_
    arch_p    <- if (!is.null(arch)) as.numeric(arch$p.value)   else NA_real_
    cv_arch   <- stats::qchisq(1 - alpha, df = arch_lags)
    
    # ---- 6) Runs test (randomness / independence of signs) ----
    run <- if (requireNamespace("tseries", quietly = TRUE))
      tryCatch(tseries::runs.test(res), error = function(e) NULL) else NULL
    run_Z <- if (!is.null(run)) as.numeric(run$statistic) else NA_real_
    run_p <- if (!is.null(run)) as.numeric(run$p.value)   else NA_real_
    zcrit <- stats::qnorm(1 - alpha/2)  # two-sided
    
    # ---- 7) Anderson–Darling for normality (tail-sensitive; optional) ----
    ad <- if (requireNamespace("nortest", quietly = TRUE))
      tryCatch(nortest::ad.test(res), error = function(e) NULL) else NULL
    ad_A2 <- if (!is.null(ad)) as.numeric(ad$statistic) else NA_real_
    ad_p  <- if (!is.null(ad)) as.numeric(ad$p.value)   else NA_real_
    
    # ---- 8) KPSS on residuals (should be stationary if model is adequate; optional) ----
    kpss_res <- if (requireNamespace("tseries", quietly = TRUE))
      tryCatch(tseries::kpss.test(res, null = "Level"), error = function(e) NULL) else NULL
    kpss_stat <- if (!is.null(kpss_res)) as.numeric(kpss_res$statistic) else NA_real_
    kpss_p    <- if (!is.null(kpss_res)) as.numeric(kpss_res$p.value)   else NA_real_
    
    # ---- Compose the academic-friendly text ----
    out <- c(
      "==========================================================================",
      "                     RESIDUAL DIAGNOSTIC BATTERY                          ",
      "==========================================================================",
      sprintf(" SAMPLE SIZE (residuals used): %d   |   α: %s   |   Lag (L): %d   |   fitdf: %d",
              N, fmt_num(alpha, 4), L, fitdf),
      "--------------------------------------------------------------------------",
      
      # Ljung–Box
      "TEST 1: Ljung–Box Portmanteau (autocorrelation)",
      " Purpose     : To determine whether any linear autocorrelation remains in the residuals up to lag L after fitting the SARIMA model.",
      "               Passing this test supports the idea that the model has successfully captured the serial dependence in the training data.",
      " Description : The Ljung–Box statistic aggregates squared sample autocorrelations of the residuals across lags 1..L,",
      "               with a small-sample correction. Under the null hypothesis that residuals are white noise, Q follows",
      "               approximately a chi-square distribution with degrees of freedom equal to max(L − fitdf, 1).",
      sprintf(" Statistic   : Q(LB) = %s  |  df = %d  |  p-value = %s", fmt_num(lb_stat, 4), df_lb, fmt_p(lb_p)),
      sprintf(" Critical    : χ^2_(%d, 1-α) = %s", df_lb, fmt_num(cv_lb, 4)),
      sprintf(" Decision    : Reject H0 (white noise) if Q(LB) > χ^2_(%d, 1-α) (equivalently, p < α).", df_lb),
      sprintf(" Result      : %s",
              if (!is.finite(lb_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (lb_p < alpha) {
                "Reject H0 → residual autocorrelation detected."
              } else {
                "Fail to reject H0 → residuals consistent with white noise."
              }),
      sprintf(" Conclusion  : %s",
              if (!is.finite(lb_p)) {
                "Because the test could not be evaluated, do not draw conclusions about left-over autocorrelation. Recheck model estimation and sample size."
              } else if (lb_p < alpha) {
                "There is statistical evidence of remaining serial correlation up to the chosen lag. This suggests the SARIMA orders may be underspecified (e.g., too few AR/MA or seasonal terms) or that differencing/seasonality was not fully addressed. Consider revisiting (p,d,q)(P,D,Q)m, increasing L modestly, or examining ACF/PACF of residuals to guide refinement."
              } else {
                "No material linear autocorrelation is detected at the examined lags. This supports the adequacy of the fitted orders for the training data and increases confidence that forecast errors are not biased by serial dependence left in the residuals."
              }),
      "--------------------------------------------------------------------------",
      
      # Box–Pierce
      "TEST 2: Box–Pierce Portmanteau (autocorrelation, classic)",
      " Purpose     : Same goal as Ljung–Box—screen for any left-over autocorrelation up to lag L—using the original Box–Pierce statistic.",
      " Description : The Box–Pierce statistic is the uncorrected sum of squared residual autocorrelations over lags 1..L.",
      "               Under the white-noise null, it is approximately χ^2 with df = max(L − fitdf, 1).",
      sprintf(" Statistic   : Q(BP) = %s  |  df = %d  |  p-value = %s", fmt_num(bp_stat, 4), df_lb, fmt_p(bp_p)),
      sprintf(" Critical    : χ^2_(%d, 1-α) = %s", df_lb, fmt_num(cv_lb, 4)),
      sprintf(" Decision    : Reject H0 if Q(BP) > χ^2_(%d, 1-α) (equivalently, p < α).", df_lb),
      sprintf(" Result      : %s",
              if (!is.finite(bp_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (bp_p < alpha) {
                "Reject H0 → residual autocorrelation detected (classic statistic)."
              } else {
                "Fail to reject H0 → no strong evidence of residual autocorrelation."
              }),
      sprintf(" Conclusion  : %s",
              if (!is.finite(bp_p)) {
                "Since the test could not be computed, rely on Ljung–Box and graphical diagnostics. If both are inconclusive, try a different L or expand the sample."
              } else if (bp_p < alpha) {
                "Autocorrelation persists by the Box–Pierce criterion. In practice, prioritize Ljung–Box; if both agree, refine the model orders or differencing. If they disagree, prefer Ljung–Box due to its small-sample correction."
              } else {
                "Results align with white-noise residuals by the Box–Pierce criterion. Together with Ljung–Box, this strengthens the case that the fitted SARIMA captured the main serial structure."
              }),
      "--------------------------------------------------------------------------",
      
      # Jarque–Bera
      "TEST 3: Jarque–Bera (normality, large-sample χ^2)",
      " Purpose     : Assess whether residuals are approximately normal—important when using normal-based prediction intervals and likelihood-based inference.",
      " Description : The statistic combines squared residual skewness and excess kurtosis. Under normality (large N), JB ~ χ^2 with 2 degrees of freedom.",
      sprintf(" Statistic   : JB = %s  |  df = 2  |  p-value = %s", fmt_num(jb_stat, 4), fmt_p(jb_p)),
      sprintf(" Critical    : χ^2_(2, 1-α) = %s", fmt_num(cv_jb, 4)),
      " Decision    : Reject H0 (normality) if JB > χ^2_(2, 1-α) (equivalently, p < α).",
      sprintf(" Result      : %s",
              if (!is.finite(jb_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (jb_p < alpha) {
                "Reject H0 → residuals deviate from normality."
              } else {
                "Fail to reject H0 → residual normality is plausible."
              }),
      sprintf(" Conclusion  : %s",
              if (!is.finite(jb_p)) {
                "Because the test could not be evaluated, rely on the QQ-plot and Shapiro–Wilk (if available) to judge normality. Normality mainly affects interval calibration rather than point forecasts."
              } else if (jb_p < alpha) {
                "Non-normal residuals indicate skewness and/or heavy tails. Point forecasts remain unbiased if the mean is correctly specified, but nominal prediction intervals may undercover or overcover. Consider variance-stabilizing transforms (e.g., log/Box–Cox), robust inference, or heavier-tailed error models if tails matter."
              } else {
                "Residuals are consistent with normality at the chosen α. This supports the use of standard Gaussian prediction intervals and likelihood-based comparisons for competing SARIMA specifications."
              }),
      "--------------------------------------------------------------------------",
      
      # Shapiro–Wilk
      "TEST 4: Shapiro–Wilk (normality, small/medium samples)",
      " Purpose     : Provide a powerful small-sample test of normality when N ≤ 5000.",
      " Description : The W statistic compares ordered residuals to expected normal order statistics. Lower W indicates departure from normality.",
      sprintf(" Statistic   : W = %s  |  p-value = %s  |  Range: N ∈ [3, 5000]",
              fmt_num(sw_W, 4), if (N > 5000) "n/a (N>5000)" else fmt_p(sw_p)),
      " Critical    : R relies on p-value; explicit critical values are not printed.",
      " Decision    : Reject H0 (normality) if p < α.",
      sprintf(" Result      : %s",
              if (N > 5000) {
                "Omitted (Shapiro–Wilk is defined for N ≤ 5000)."
              } else if (!is.finite(sw_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (sw_p < alpha) {
                "Reject H0 → residuals deviate from normality."
              } else {
                "Fail to reject H0 → residual normality is plausible."
              }),
      sprintf(" Conclusion  : %s",
              if (N > 5000) {
                "For large samples, rely on Jarque–Bera and visual diagnostics (histogram, QQ-plot)."
              } else if (!is.finite(sw_p)) {
                "Unable to conclude about normality from Shapiro–Wilk. Cross-check with QQ-plot and Jarque–Bera before changing the model."
              } else if (sw_p < alpha) {
                "Evidence against normality in smaller samples warrants caution with Gaussian intervals. Inspect QQ-plots for systematic S-shapes (tails) or asymmetry (skew). Consider transformations or alternative error distributions if interval accuracy is a goal."
              } else {
                "Normality appears adequate by Shapiro–Wilk. Combined with QQ-plot and JB, this supports the standard Gaussian assumptions used in SARIMA teaching examples."
              }),
      "--------------------------------------------------------------------------",
      
      # ARCH LM
      "TEST 5: Engle’s ARCH LM (conditional heteroskedasticity)",
      sprintf(" Purpose     : Check whether residual variance changes over time (ARCH effects) up to %d lags—important when volatility clustering is present.", arch_lags),
      " Description : Regress squared residuals on their own lags and test whether lag coefficients are jointly zero. Under H0 (no ARCH), LM ~ χ^2 with df equal to the lag count.",
      sprintf(" Statistic   : LM = %s  |  df = %d  |  p-value = %s", fmt_num(arch_stat, 4), arch_lags, fmt_p(arch_p)),
      sprintf(" Critical    : χ^2_(%d, 1-α) = %s", arch_lags, fmt_num(cv_arch, 4)),
      " Decision    : Reject H0 (no ARCH) if LM > χ^2_(lags, 1-α) (equivalently, p < α).",
      sprintf(" Result      : %s",
              if (is.null(arch)) {
                "Skipped (package 'FinTS' not installed)."
              } else if (!is.finite(arch_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (arch_p < alpha) {
                "Reject H0 → ARCH present."
              } else {
                "Fail to reject H0 → no strong evidence of ARCH."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(arch)) {
                "Install the 'FinTS' package to assess time-varying volatility rigorously. In the meantime, inspect a rolling variance plot; volatility clustering can bias interval calibration."
              } else if (!is.finite(arch_p)) {
                "ARCH could not be assessed; consider re-running with a different lag count or larger sample. Visual checks of squared residuals may still reveal volatility clusters."
              } else if (arch_p < alpha) {
                "Time-varying variance is indicated. If volatility matters (finance, energy), consider augmenting the mean model with a GARCH-type variance model or using heteroskedasticity-robust intervals. If mean forecasts are the sole target, point forecasts can still be useful but intervals should be treated with caution."
              } else {
                "No strong evidence of ARCH effects. Constant-variance assumptions used in basic SARIMA are reasonable for these residuals, improving confidence in prediction interval calibration."
              }),
      "--------------------------------------------------------------------------",
      
      # Runs test
      "TEST 6: Runs Test (randomness of signs)",
      " Purpose     : Evaluate whether positive and negative residuals occur in a random order.",
      "               Systematic alternation or clustering of signs may indicate remaining structure (e.g., nonlinearity or omitted seasonal effects).",
      " Description : Counts runs of consecutive positive/negative residuals. Under independence, the standardized count Z is approximately N(0,1).",
      sprintf(" Statistic   : Z = %s  |  p-value = %s  |  Two-sided z-crit = ±%s",
              fmt_num(run_Z, 4), fmt_p(run_p), fmt_num(zcrit, 3)),
      " Critical    : Reject H0 if |Z| > z_crit (equivalently, p < α).",
      sprintf(" Result      : %s",
              if (is.null(run)) {
                "Skipped (package 'tseries' not installed)."
              } else if (!is.finite(run_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (run_p < alpha) {
                "Reject H0 → residual signs are not random."
              } else {
                "Fail to reject H0 → residual signs appear random."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(run)) {
                "Install 'tseries' to include the runs test in your diagnostic battery. Without it, rely on the residual time plot to spot sign clustering."
              } else if (!is.finite(run_p)) {
                "Because the statistic could not be computed, defer to visual checks. Persistent runs may point to nonlinearity or missing seasonal terms."
              } else if (run_p < alpha) {
                "Non-random sign patterns suggest unresolved structure (e.g., threshold dynamics or seasonal mismatches). Inspect seasonal plots and consider adding nonlinearity or revisiting seasonal differencing."
              } else {
                "Signs occur in a pattern consistent with randomness, which complements portmanteau tests by checking a simple, intuitive notion of independence."
              }),
      "--------------------------------------------------------------------------",
      
      # Anderson–Darling (optional)
      "TEST 7: Anderson–Darling (normality, tail-sensitive) [optional]",
      " Purpose     : Detect departures from normality with particular emphasis on the tails—useful when extremes matter for risk or service-level planning.",
      " Description : The A² statistic compares the empirical CDF of residuals to the normal CDF, weighting discrepancies more heavily in the tails.",
      sprintf(" Statistic   : A² = %s  |  p-value = %s", fmt_num(ad_A2, 4), if (!is.null(ad)) fmt_p(ad_p) else "n/a (package 'nortest' not installed)"),
      " Critical    : Decision by p-value (package provides the calibration).",
      sprintf(" Result      : %s",
              if (is.null(ad)) {
                "Skipped (package 'nortest' not installed)."
              } else if (!is.finite(ad_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (ad_p < alpha) {
                "Reject H0 → tail behavior not normal."
              } else {
                "Fail to reject H0 → tails are consistent with normality."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(ad)) {
                "If tail accuracy matters, consider installing 'nortest' or inspecting extreme quantiles in the QQ-plot. Heavy tails call for robust or heavy-tailed error models."
              } else if (!is.finite(ad_p)) {
                "Unable to assess tail behavior quantitatively. Rely on QQ-plots focusing on the extremes before modifying the model."
              } else if (ad_p < alpha) {
                "Evidence of tail non-normality suggests Gaussian prediction intervals may under- or over-cover in the extremes. Consider transformations, t-errors, or bootstrapped intervals if extreme events are decision-critical."
              } else {
                "Tail behavior looks compatible with normality, supporting standard Gaussian intervals for planning purposes."
              }),
      "--------------------------------------------------------------------------",
      
      # KPSS on residuals (optional)
      "TEST 8: KPSS on Residuals (level-stationarity) [optional]",
      " Purpose     : Verify that residuals are stationary around a fixed level (no unit root), as expected from a well-specified SARIMA model.",
      " Description : The KPSS statistic accumulates partial sums of residuals; large values indicate non-stationarity. The test is run with the 'Level' null.",
      sprintf(" Statistic   : KPSS = %s  |  p-value = %s", fmt_num(kpss_stat, 5),
              if (!is.null(kpss_res)) fmt_p(kpss_p) else "n/a (package 'tseries' not installed)"),
      " Critical    : Decision by p-value or package-reported thresholds.",
      sprintf(" Result      : %s",
              if (is.null(kpss_res)) {
                "Skipped (package 'tseries' not installed)."
              } else if (!is.finite(kpss_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (kpss_p < alpha) {
                "Reject H0 → residuals may contain non-stationary structure."
              } else {
                "Fail to reject H0 → residuals behave as stationary noise."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(kpss_res)) {
                "Install 'tseries' to include KPSS on residuals. In its absence, rely on the residual ACF and time plot to confirm stationarity."
              } else if (!is.finite(kpss_p)) {
                "Stationarity of residuals could not be certified statistically. Check for slow drifts or level shifts; if present, revisit differencing or break handling."
              } else if (kpss_p < alpha) {
                "Some non-stationary behavior remains in the residuals, which can undermine the white-noise assumption and degrade forecast uncertainty estimates. Consider additional differencing, seasonal adjustments, or modeling identified breaks."
              } else {
                "Residuals appear stationary around a fixed mean, consistent with a correctly differenced and seasonally specified SARIMA model."
              }),
      
      "==========================================================================",
      "INTERPRETATION GUIDE",
      " • Good SARIMA residuals typically: (i) pass Ljung–Box/Box–Pierce (no linear autocorrelation),",
      "   (ii) show no strong ARCH unless volatility modeling is intended, and (iii) are roughly normal",
      "   if you rely on Gaussian prediction intervals. When diagnostics fail, prefer changing the model",
      "   (orders, differencing, seasonality) rather than over-fitting residuals with ad-hoc fixes."
    )
    
    paste(out, collapse = "\n")
  }
  
  
 
  
  
  
  
  
  #===============================================================
  #===============================================================
  #===============================================================
  #===============================================================
  
  
  output$auto_forecast_plot <- renderPlot({
    req(auto_fc(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    fc <- auto_fc()$fc

    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")

    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    gg_forecast_plot(obs_df, s$train_n, fc_df, title = "Auto-ARIMA forecast (train/test + intervals)")
  })

  output$auto_forecast_table <- renderTable({ req(auto_fc()); head(forecast_table(auto_fc()$fc), 25) }, rownames = FALSE)

  output$auto_accuracy_table <- renderTable({
    req(auto_fc(), ts_train_test())
    s <- ts_train_test()
    if (s$test_n == 0) return(data.frame(message = "No test set (training = 100%). Reduce training to compute accuracy."))
    accuracy_df(s$ts_test, auto_fc()$fc$mean)
  }, rownames = FALSE)

  output$apa_auto_paragraph <- renderPrint({
    req(auto_fit(), auto_fc(), ts_train_test())
    fit <- auto_fit()
    s <- ts_train_test()
    fc <- auto_fc()$fc
    lag <- as.numeric(input$diag_lag)
    lb <- tryCatch(Box.test(residuals(fit), lag = lag, type = "Ljung-Box", fitdf = length(coef(fit))), error = function(e) NULL)
    acc_line <- ""
    if (s$test_n > 0) {
      acc <- accuracy_df(s$ts_test, fc$mean)
      rmse <- acc$Value[acc$Metric == "RMSE"]
      mae <- acc$Value[acc$Metric == "MAE"]
      acc_line <- paste0("Forecast accuracy on the holdout set was RMSE = ", fmt_num(rmse, 2), " and MAE = ", fmt_num(mae, 2), ". ")
    }
    lb_line <- if (!is.null(lb)) paste0("The Ljung–Box test suggested ", ifelse(lb$p.value > 0.05, "no strong residual autocorrelation", "residual autocorrelation"), " (", fmt_p(lb$p.value), "). ") else ""
    cat(
      "APA-ready paragraph:\n\n",
      "An Auto-ARIMA procedure selected a seasonal ARIMA model (", as.character(fit), "). ",
      lb_line, acc_line,
      "Forecasts were generated with prediction intervals to quantify uncertainty.\n",
      sep = ""
    )
  })
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  
  

  # ---- Auto-ARIMA: academic conclusion (cached on Fit click) ----
  auto_conclusion_full_obj <- eventReactive(input$fit_auto, {
    req(auto_fit(), auto_fc(), auto_equations(), ts_train_test(), prepared())
    
    fit <- auto_fit()
    fc0 <- auto_fc()
    fc  <- fc0$fc
    eq  <- auto_equations()
    s   <- ts_train_test()
    p0  <- prepared()
    
    # ---- safe values
    n_train <- suppressWarnings(as.integer(s$train_n)); if (!is.finite(n_train)) n_train <- length(residuals(fit))
    n_test  <- suppressWarnings(as.integer(s$test_n));  if (!is.finite(n_test))  n_test  <- 0L
    N <- n_train + n_test
    
    L_in <- suppressWarnings(as.integer(input$diag_lag))
    L <- if (is.finite(L_in) && L_in > 0) L_in else 12L
    fitdf <- length(coef(fit))
    
    # ---- key stats
    AICc_val <- suppressWarnings(as.numeric(fit$aicc))
    BIC_val  <- suppressWarnings(as.numeric(fit$bic))
    AIC_val  <- suppressWarnings(as.numeric(fit$aic))
    
    # ---- residual tests (minimal, fast)
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    lb <- tryCatch(Box.test(res, lag = min(L, max(1L, floor(length(res) / 3))), type = "Ljung-Box", fitdf = fitdf),
                   error = function(e) NULL)
    
    # ---- accuracy (only if test exists)
    acc_line <- NULL
    if (n_test > 0) {
      acc <- tryCatch(accuracy_df(s$ts_test, fc$mean), error = function(e) NULL)
      if (!is.null(acc) && all(c("Metric", "Value") %in% names(acc))) {
        rmse <- acc$Value[acc$Metric == "RMSE"][1]
        mae  <- acc$Value[acc$Metric == "MAE"][1]
        mape <- acc$Value[acc$Metric == "MAPE"][1]
        acc_line <- tags$p(
          tags$b("Forecast accuracy (test set). "),
          HTML(paste0(
            "Over the holdout period (n = ", n_test, "), performance was RMSE = ",
            fmt_num(rmse, 3), ", MAE = ", fmt_num(mae, 3),
            if (is.finite(mape)) paste0(", MAPE = ", fmt_num(100 * mape, 2), "%") else "",
            "."
          ))
        )
      }
    }
    if (is.null(acc_line)) {
      acc_line <- tags$p(tags$b("Forecast accuracy. "),
                         "No holdout test set was detected; therefore, out-of-sample accuracy was not computed.")
    }
    
    # ---- horizon narrative (align with your Step 5 logic)
    horizon_txt <- if (n_test > 0) {
      paste0("Validation mode was used: the forecast horizon was forced to match the test length (h = ", n_test, ").")
    } else {
      paste0("Future mode was used: forecasts were produced beyond the training sample (h = ", fc0$h, ").")
    }
    
    # ---- “model string” consistent with your equation panel
    s_term <- if (is.finite(eq$s) && eq$s > 1) sprintf(" × (%d,%d,%d)[%d]", eq$P, eq$D, eq$Q, eq$s) else ""
    model_str <- sprintf("ARIMA(%d,%d,%d)%s", eq$p, eq$d, eq$q, s_term)
    
    # ---- build tag UI (fast + correct MathJax)
    tagList(
      tags$h3("Auto-ARIMA: Full academic conclusion"),
      
      tags$h4("1. Objective and modelling context"),
      tags$p(
        "An automated ARIMA procedure was used to establish a reproducible baseline for linear time-series dynamics. ",
        "Auto-ARIMA searches across candidate ARIMA/SARIMA structures and selects a parsimonious specification based on information criteria, ",
        "subject to the user-defined search settings (e.g., stepwise/approximation and seasonal allowance)."
      ),
      
      tags$h4("2. Sample design"),
      tags$p(
        HTML(paste0(
          "The analysis used <b>N = ", N, "</b> observations (training <b>n = ", n_train,
          "</b>", if (n_test > 0) paste0(", test <b>n = ", n_test, "</b>") else "",
          "). The seasonal period used in the workflow was <b>s = ", p0$freq, "</b>."
        ))
      ),
      tags$p(tags$b("Forecast design. "), horizon_txt),
      
      tags$h4("3. Selected specification and fit"),
      tags$p(HTML(paste0("The selected model was <b>", as.character(fit), "</b> (reported as <b>", model_str, "</b> in order notation)."))),
      tags$ul(
        tags$li(HTML(paste0("AIC = <b>", fmt_num(AIC_val, 2), "</b>"))),
        tags$li(HTML(paste0("AICc = <b>", fmt_num(AICc_val, 2), "</b>"))),
        tags$li(HTML(paste0("BIC = <b>", fmt_num(BIC_val, 2), "</b>")))
      ),
      tags$p(
        "In academic reporting, these criteria support relative comparison among candidate models; lower values indicate improved parsimony-adjusted fit."
      ),
      
      tags$h4("4. Model equations (reporting-ready)"),
      tags$p(
        "For documentation and replication, the fitted model is expressed in standard SARIMA operator notation, followed by an expanded form ",
        "and a numerical representation using the estimated coefficients."
      ),
      tags$div(
        style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;text-align:left;",
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h5("General SARIMA formulation:"),
        HTML(eq$eq_general),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h5("Expanded operator form:"),
        HTML(eq$eq_expanded),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h5("Numerical model:"),
        HTML(eq$eq_line3),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        HTML(eq$eq_line4),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
      ),
      
      tags$h4("5. Residual diagnostics (adequacy of linear dynamics)"),
      tags$p(
        "Adequacy was evaluated using graphical diagnostics (residual series, ACF, histogram, Q–Q plot) and formal residual tests. ",
        "A key criterion for ARIMA adequacy is that residuals approximate white noise (no remaining autocorrelation)."
      ),
      if (!is.null(lb)) {
        tags$p(HTML(paste0(
          "<b>Ljung–Box test:</b> Q(", lb$parameter, ") = ", fmt_num(lb$statistic, 3),
          ", p ", fmt_p(lb$p.value), "."
        )))
      } else {
        tags$p(tags$b("Ljung–Box test:"), " unavailable (insufficient residuals or test error).")
      },
      
      tags$h4("6. Forecasting and predictive performance"),
      acc_line,
      
      tags$h4("7. Overall conclusion and recommended next steps"),
      tags$p(
        "Overall, the Auto-ARIMA baseline provides a defensible benchmark for forecasting and for comparison against theory-guided manual SARIMA candidates. ",
        "If diagnostics suggest residual autocorrelation, a refined manual specification (guided by ACF/PACF after differencing) is recommended. ",
        "If volatility clustering is present (e.g., significant ARCH effects), ARIMA may be complemented by conditional variance modelling (e.g., GARCH)."
      )
    )
  })
  
  output$auto_conclusion_full <- renderUI({
    # Show a helpful message if user hasn't clicked Fit yet
    validate(need(input$fit_auto > 0, "Click “Fit Auto-ARIMA” to generate the full academic conclusion."))
    req(auto_conclusion_full_obj())
    
    # Force MathJax typesetting in the conclusion container
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "auto_conclusion_box")
    }, once = TRUE)
    
    auto_conclusion_full_obj()
  })
  
  
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  

  # ---- Step 6 Manual SARIMA ----

  output$manual_split_text <- renderPrint({
    req(ts_train_test(), prepared())
    s <- ts_train_test()
    df <- s$dfm
    train_n <- s$train_n
    test_n <- s$test_n
    x <- df$x

    cat("Train/Test split (Manual SARIMA)\n")
    cat("- Training proportion:", fmt_pct(as.numeric(input$train_prop)), "\n")
    cat("- Training size (n):", train_n, "\n")
    cat("- Test size (n):", test_n, "\n")
    if (test_n > 0) {
      cat("- Validation forecast horizon (h):", test_n, "(forced)\n\n")
    } else {
      cat("- Validation forecast horizon (h): none (future mode)\n\n")
    }

    cat("- Training range:", as.character(x[1]), "to", as.character(x[train_n]), "\n")
    if (test_n > 0) cat("- Test range:", as.character(x[train_n + 1]), "to", as.character(x[length(x)]), "\n")
  })

  output$manual_split_plot <- renderPlot({
    req(ts_train_test(), prepared())
    p <- prepared()
    s <- ts_train_test()
    df <- s$dfm
    df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test")
    split_df <- data.frame(xint = df$x[s$train_n])

    ggplot(df, aes(x = x, y = y_trans, color = set)) +
      geom_line(linewidth = 0.9) +
      geom_vline(data = split_df, aes(xintercept = xint), linetype = "dashed") +
      theme_minimal() +
      labs(title = "Train/Test split used for Manual SARIMA", x = p$x_label, y = "Value", color = NULL) +
      theme(legend.position = "bottom")
  })

  manual_fit <- eventReactive(input$fit_manual, {
    s <- ts_train_test()
    p <- prepared()
    period <- if (!is.na(input$s) && input$s >= 1) as.numeric(input$s) else p$freq
    forecast::Arima(
      s$ts_train,
      order = c(as.numeric(input$p), as.numeric(input$d), as.numeric(input$q)),
      seasonal = list(order = c(as.numeric(input$P), as.numeric(input$D), as.numeric(input$Q)), period = period),
      include.drift = isTRUE(input$manual_drift),
      include.mean = isTRUE(input$manual_drift)
    )
  })

  manual_fc <- reactive({
    req(manual_fit(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()

    # FIX v2 (core issue):
    # When a test set exists, we forecast exactly h = test_n so forecasts overlay the test period.
    user_h <- if (!is.na(input$manual_h) && input$manual_h > 0) as.numeric(input$manual_h) else NA_real_
    if (s$test_n > 0) {
      h <- s$test_n
    } else {
      h <- if (!is.na(user_h)) user_h else max(1, frequency(s$ts_train))
    }

    fc <- forecast::forecast(manual_fit(), h = h)
    list(fc = fc, h = h, by = p$by)
  })

  output$manual_horizon_note <- renderPrint({
    req(ts_train_test(), manual_fc())
    s <- ts_train_test()
    if (s$test_n > 0) {
      cat("Validation mode: forecast horizon is forced to the test length (h =", s$test_n, ") so the forecast overlays the test period.\n")
    } else {
      cat("Future mode: no test set. Horizon uses your 'Future horizon h' input (or defaults to one seasonal cycle).\n")
    }
  })

  output$manual_model_spec <- renderPrint({
    req(manual_fit(), prepared())
    p <- prepared()
    cat("Manual SARIMA model:\n")
    cat("- Non-seasonal (p,d,q): (", input$p, ",", input$d, ",", input$q, ")\n", sep = "")
    cat("- Seasonal (P,D,Q)[s]: (", input$P, ",", input$D, ",", input$Q, ")[", ifelse(is.na(input$s), p$freq, input$s), "]\n", sep = "")
    cat("- Drift/mean included:", isTRUE(input$manual_drift), "\n")
    cat("- AICc =", fmt_num(manual_fit()$aicc, 2), ", BIC =", fmt_num(manual_fit()$bic, 2), "\n")
  })

  output$manual_coef_table <- renderTable({ req(manual_fit()); coef_table(manual_fit()) }, rownames = FALSE)
  
  output$manual_resid_ts <- renderPlot({ req(manual_fit()); plot(residuals(manual_fit()), main = "Residuals (Manual SARIMA)", ylab = "Residual", xlab = "Time") })
  output$manual_resid_acf <- renderPlot({ req(manual_fit()); plot(acf(residuals(manual_fit()), plot = FALSE), main = "Residual ACF (Manual SARIMA)") })
  output$manual_resid_hist <- renderPlot({ req(manual_fit()); hist(residuals(manual_fit()), breaks = 30, main = "Residual histogram", xlab = "Residual") })
  output$manual_resid_qq <- renderPlot({ req(manual_fit()); qqnorm(residuals(manual_fit())); qqline(residuals(manual_fit())) })
  
  
  
  
  
  
  # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # --------------------------------------------- 
  
  
  
  
  
  # ============================================================
  # ✅ DIAGNOSTICS (COPY/PASTE COMPLETE SERVER CODE)
  # Fixes:
  # - NO more "valeur manquante là où TRUE/FALSE est requis"
  # - safe handling for NULL inputs (fit_manual, preset, sliders)
  # - Diagnostics-only Ljung–Box p-values plot: manual_resid_lb_pvals_diag2
  # - Keeps Academic conclusion plot name unchanged: manual_resid_lb_pvals
  # - Only TWO plot sliders used: diag_plot_width, diag_plot_height
  # - Container width slider: diag_container_width_px controls the flex width
  #
  # REQUIRED UI:
  # - tabPanel("Diagnostics", uiOutput("diag_container_ui"))
  # - plus: tags$head(tags$style(HTML("body { overflow-x: auto; }")))
  # ============================================================
  
  `%||%` <- function(a, b) if (!is.null(a)) a else b
  
  # ---------- SAFE helpers (prevent logical(0) / NA in if/need) ----------
  safe_chr1 <- function(x, default) {
    if (is.null(x) || length(x) == 0 || is.na(x[1])) return(default)
    as.character(x[1])
  }
  
  safe_int1 <- function(x, default) {
    y <- suppressWarnings(as.integer(x))
    if (is.null(y) || length(y) == 0 || !is.finite(y[1])) return(default)
    y[1]
  }
  
  fit_manual_clicked <- function(input) {
    fm <- input$fit_manual
    isTRUE(!is.null(fm) && length(fm) > 0 && is.finite(fm) && fm > 0)
  }
  
  nice_par <- function() {
    par(mar = c(4, 4, 2.2, 1), mgp = c(2.2, 0.7, 0), las = 1)
  }
  
  # ---- Shared helpers ----
  get_diag_controls <- function(input) {
    L_input <- suppressWarnings(as.integer(input$diag_lag))
    L <- if (is.finite(L_input) && L_input > 0) L_input else 12L
    
    alpha <- suppressWarnings(as.numeric(input$alphaSt2))
    if (!is.finite(alpha) || alpha <= 0 || alpha >= 1) alpha <- 0.05
    
    list(L = L, alpha = alpha)
  }
  
  compute_lb_pvals <- function(res, L, fitdf) {
    res <- as.numeric(res)
    res <- res[is.finite(res)]
    
    N <- length(res)
    if (N < 8) return(list(pvals = numeric(0), L = 0L, N = N))
    
    L <- as.integer(L)
    L <- max(1L, min(L, N - 1L))
    
    pvals <- rep(NA_real_, L)
    for (k in seq_len(L)) {
      if (k > fitdf) {
        bt <- tryCatch(
          stats::Box.test(res, lag = k, type = "Ljung-Box", fitdf = fitdf),
          error = function(e) NULL
        )
        pvals[k] <- if (!is.null(bt)) as.numeric(bt$p.value) else NA_real_
      }
    }
    list(pvals = pvals, L = L, N = N)
  }
  
  plot_lb_pvals <- function(pvals, L, alpha, fitdf, main_title) {
    plot(seq_len(L), pvals,
         type = "h", lwd = 2,
         xlab = "Lag (k)",
         ylab = "p-value (Ljung–Box up to lag k)",
         main = main_title,
         ylim = c(0, 1))
    points(seq_len(L), pvals, pch = 16)
    abline(h = alpha, lty = 2, col = "gray40")
    mtext(sprintf("alpha = %.3f, fitdf = %d", alpha, fitdf),
          side = 3, line = 0.2, cex = 0.85)
    
    if (is.finite(fitdf) && fitdf >= 1 && fitdf < L) {
      rect(xleft = 0.5, ybottom = -0.02, xright = fitdf + 0.5, ytop = 1.02,
           border = NA, col = grDevices::adjustcolor("gray", alpha.f = 0.15))
      text(x = (fitdf + 1) / 2, y = 0.95, labels = "df ≤ 0 (omitted)", cex = 0.8)
    }
  }
  
  # ============================================================
  # Diagnostics plots (independent outputs)
  # ============================================================
  
  output$manual_resid_ts_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 3, "Not enough residuals to plot."))
    
    plot(res, type = "l",
         main = "Residuals over time",
         xlab = "Time", ylab = "Residual")
    abline(h = 0, col = "gray40", lty = 2)
  })
  
  output$manual_resid_acf_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for ACF."))
    
    plot(acf(res, plot = FALSE), main = "Residual ACF")
  })
  
  # output$manual_resid_pacf_diag <- renderPlot({
  #   validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
  #   req(manual_fit())
  #   fit <- manual_fit()
  #   nice_par()
  #   
  #   res <- as.numeric(residuals(fit))
  #   res <- res[is.finite(res)]
  #   validate(need(length(res) >= 5, "Not enough residuals for PACF."))
  #   
  #   plot(pacf(res, plot = FALSE), main = "Residual PACF")
  # })
  
  output$manual_resid_pacf_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for PACF."))
    
    plot(pacf(res, plot = FALSE), main = "Residual PACF")
  })
  
  
  output$manual_resid_hist_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for histogram."))
    
    hist(res, breaks = 30, col = "gray85", border = "white",
         main = "Residual histogram", xlab = "Residual")
  })
  
  output$manual_resid_qq_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for Q–Q plot."))
    
    qqnorm(res, main = "Normal Q–Q")
    qqline(res, col = "red", lwd = 2)
  })
  
  output$manual_resid_fitted_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    fv  <- as.numeric(fitted(fit))
    ok  <- is.finite(res) & is.finite(fv)
    validate(need(sum(ok) >= 10, "Not enough valid points for residuals vs fitted."))
    
    plot(fv[ok], res[ok],
         pch = 16, cex = 0.7,
         col = grDevices::adjustcolor("steelblue", alpha.f = 0.7),
         main = "Residuals vs fitted",
         xlab = "Fitted values", ylab = "Residual")
    abline(h = 0, col = "gray40", lty = 2)
    if (sum(ok) > 20) {
      lines(stats::lowess(fv[ok], res[ok], f = 2/3), col = "tomato", lwd = 2)
    }
  })
  
  output$manual_resid_scale_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    fv  <- as.numeric(fitted(fit))
    ok  <- is.finite(res) & is.finite(fv)
    y   <- sqrt(abs(res))
    ok2 <- ok & is.finite(y)
    validate(need(sum(ok2) >= 10, "Not enough valid points for scale-location plot."))
    
    plot(fv[ok2], y[ok2],
         pch = 16, cex = 0.7,
         col = grDevices::adjustcolor("darkgreen", alpha.f = 0.65),
         main = "Scale-location (sqrt(|res|) vs fitted)",
         xlab = "Fitted values", ylab = expression(sqrt("|Residual|")))
    if (sum(ok2) > 20) {
      lines(stats::lowess(fv[ok2], y[ok2], f = 2/3), col = "tomato", lwd = 2)
    }
  })
  
  # ------------------------------------------------------------
  # NEW: Ljung–Box p-values by lag (Diagnostics ONLY)
  # ------------------------------------------------------------
  output$manual_resid_lb_pvals_diag2 <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res   <- residuals(fit)
    fitdf <- length(coef(fit))
    
    ctrl <- get_diag_controls(input)
    out  <- compute_lb_pvals(res, L = ctrl$L, fitdf = fitdf)
    
    validate(need(out$N >= 8, "Too few residuals (N < 8) to compute Ljung–Box p-values."))
    validate(need(out$L >= 1, "No valid lags available for Ljung–Box p-values."))
    
    plot_lb_pvals(out$pvals, out$L, ctrl$alpha, fitdf,
                  main_title = "Ljung–Box p-values by lag (Diagnostics)")
  })
  
  # ------------------------------------------------------------
  # Commentary (Diagnostics tab)
  # ------------------------------------------------------------
  output$manual_diag_commentary_diag <- renderPrint({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    N   <- length(res)
    
    ctrl  <- get_diag_controls(input)
    fitdf <- length(coef(fit))
    
    if (N < 8) {
      cat("Diagnostics summary (Manual SARIMA)\n",
          "------------------------------------------------------------\n",
          "- Too few residuals to run diagnostics.\n", sep = "")
      return(invisible())
    }
    
    L2 <- max(1L, min(as.integer(ctrl$L), N - 1L))
    lb <- tryCatch(
      stats::Box.test(res, lag = L2, type = "Ljung-Box", fitdf = fitdf),
      error = function(e) NULL
    )
    
    cat("Diagnostics summary (Manual SARIMA)\n")
    cat("------------------------------------------------------------\n")
    if (!is.null(lb) && is.finite(lb$p.value)) {
      cat("Ljung–Box (lag ", L2, ") p = ", signif(lb$p.value, 3),
          if (lb$p.value > ctrl$alpha) " -> no strong evidence of autocorrelation.\n"
          else " -> remaining autocorrelation; revise orders/differencing.\n",
          sep = "")
    } else {
      cat("Ljung–Box unavailable.\n")
    }
    
    cat("\nNotes:\n")
    cat("- Use Residual ACF + Ljung–Box together: spikes + small p-values suggest underfitting.\n")
    cat("- If Q–Q shows heavy tails: intervals/inference may be optimistic.\n")
  })
  
  # ============================================================
  # KEEP: Academic conclusion plot output unchanged
  # ============================================================
  output$manual_resid_lb_pvals <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res   <- residuals(fit)
    fitdf <- length(coef(fit))
    
    ctrl <- get_diag_controls(input)
    out  <- compute_lb_pvals(res, L = ctrl$L, fitdf = fitdf)
    
    validate(need(out$N >= 8, "Too few residuals (N < 8) to compute Ljung–Box p-values."))
    validate(need(out$L >= 1, "No valid lags available for Ljung–Box p-values."))
    
    plot_lb_pvals(out$pvals, out$L, ctrl$alpha, fitdf,
                  main_title = "Ljung–Box p-values by lag (Manual SARIMA)")
  })
  
  # ============================================================
  # Layout builder + auto canvas sizing from ONLY plot width/height
  # ============================================================
  
  manual_diag_plot_map <- list(
    ts     = list(id = "manual_resid_ts_diag",        title = "Residuals over time"),
    acf    = list(id = "manual_resid_acf_diag",       title = "Residual ACF"),
    pacf   = list(id = "manual_resid_pacf_diag",      title = "Residual PACF"),
    hist   = list(id = "manual_resid_hist_diag",      title = "Residual histogram"),
    qq     = list(id = "manual_resid_qq_diag",        title = "Normal Q–Q"),
    fitted = list(id = "manual_resid_fitted_diag",    title = "Residuals vs fitted"),
    scale  = list(id = "manual_resid_scale_diag",     title = "Scale-location"),
    lb     = list(id = "manual_resid_lb_pvals_diag2", title = "Ljung–Box p-values by lag (Diagnostics)")
  )
  
  get_diag_plot_order <- reactive({
    sel <- input$diag_plots_selected
    if (is.null(sel) || length(sel) == 0) return(character(0))
    
    preset <- safe_chr1(input$diag_layout_preset, "preset_current")
    
    if (!identical(preset, "preset_custom")) {
      # default_order <- c("ts", "acf", "hist", "qq", "fitted", "scale", "lb")
      default_order <- c("ts", "acf", "pacf", "hist", "qq", "fitted", "scale", "lb")
      
      return(default_order[default_order %in% sel])
    }
    
    pos <- c(
      ts     = input$pos_ts,
      acf    = input$pos_acf,
      pacf   = input$pos_pacf,
      hist   = input$pos_hist,
      qq     = input$pos_qq,
      fitted = input$pos_fitted,
      scale  = input$pos_scale,
      lb     = input$pos_lb
    )
    pos <- pos[names(pos) %in% sel]
    pos_num <- suppressWarnings(as.numeric(pos))
    pos_num[!is.finite(pos_num)] <- 999
    ord <- order(pos_num, names(pos_num))
    names(pos_num)[ord]
  })
  
  diag_canvas_dims <- reactive({
    keys   <- get_diag_plot_order()
    preset <- safe_chr1(input$diag_layout_preset, "preset_current")
    
    pw <- safe_int1(input$diag_plot_width, 650L)
    ph <- safe_int1(input$diag_plot_height, 320L)
    
    # If you want to allow "auto width", set slider min >=300; we keep px always.
    if (pw < 300) pw <- 300L
    if (ph < 200) ph <- 200L
    
    ncol <- if (identical(preset, "preset_one_col") || identical(preset, "preset_custom")) 1L else 2L
    n <- length(keys)
    nrow <- if (n == 0) 1L else ceiling(n / ncol)
    
    pad_w <- 60L
    pad_h <- 110L
    
    canvas_w <- ncol * (pw + pad_w) + 40L
    canvas_h <- nrow * (ph + pad_h) + 40L
    
    list(w = canvas_w, h = canvas_h, pw = pw, ph = ph)
  })
  
  make_diag_plot_output <- function(plot_key, pw, ph) {
    info <- manual_diag_plot_map[[plot_key]]
    if (is.null(info)) return(NULL)
    
    tags$div(
      style = sprintf(
        "margin-bottom:14px; padding:10px; border:1px solid #eee; border-radius:10px; background:#fff; width:%dpx;",
        pw + 30
      ),
      tags$h5(info$title),
      plotOutput(info$id, width = pw, height = ph)
    )
  }
  
  output$manual_diag_plots_ui <- renderUI({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) first, then diagnostics will appear."))
    
    keys <- get_diag_plot_order()
    if (length(keys) == 0) {
      return(tags$div(
        style = "padding:10px;border:1px dashed #ccc;border-radius:10px;background:#fff;",
        tags$strong("No plots selected."),
        tags$p("Use the left panel to select plots.")
      ))
    }
    
    dims <- diag_canvas_dims()
    pw <- dims$pw
    ph <- dims$ph
    preset <- safe_chr1(input$diag_layout_preset, "preset_current")
    
    if (identical(preset, "preset_one_col") || identical(preset, "preset_custom")) {
      return(tagList(lapply(keys, function(k) make_diag_plot_output(k, pw, ph))))
    }
    
    left  <- keys[seq(1, length(keys), by = 2)]
    right <- keys[seq(2, length(keys), by = 2)]
    fluidRow(
      column(6, lapply(left,  function(k) make_diag_plot_output(k, pw, ph))),
      column(6, lapply(right, function(k) make_diag_plot_output(k, pw, ph)))
    )
  })
  
  output$manual_diag_canvas_ui <- renderUI({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) first, then diagnostics will appear."))
    
    dims <- diag_canvas_dims()
    keys <- get_diag_plot_order()
    if (length(keys) == 0) return(NULL)
    
    tags$div(
      style = sprintf("width:%dpx; min-height:%dpx; background:#fcfcfc;", dims$w, dims$h),
      uiOutput("manual_diag_plots_ui")
    )
  })
  
  # ============================================================
  # FULL Diagnostics container UI (slider-driven width)
  # ============================================================
  
  output$diag_container_ui <- renderUI({
    container_w <- safe_int1(input$diag_container_width_px, 1600L)
    if (container_w < 900) container_w <- 900L
    
    # keep selected values stable even if UI rebuilds
    preset_now <- safe_chr1(input$diag_layout_preset, "preset_current")
    sel_now    <- input$diag_plots_selected %||% c("ts","acf", "pacf", "hist","qq","lb","fitted","scale")
    pw_now     <- safe_int1(input$diag_plot_width, 450L)
    ph_now     <- safe_int1(input$diag_plot_height, 320L)
    show_conc  <- isTRUE(input$diag_show_conclusion %||% TRUE)
    
    tags$div(
      style = sprintf("
      display:flex;
      gap:12px;
      align-items:flex-start;
      width:%dpx;
      max-width:none;
    ", container_w),
      
      # Sidebar
      tags$div(
        style = "
        flex:0 0 220px;
        max-width:320px;
        border:1px solid #e5e5e5;
        border-radius:10px;
        padding:10px;
        background:#fff;
        max-height:85vh;
        overflow-y:auto;
      ",
        
        tags$h4("Diagnostics layout builder"),
        
        selectInput(
          "diag_layout_preset",
          "Layout preset",
          choices = c(
            "Current layout" = "preset_current",
            "Two columns"    = "preset_two_col",
            "Single column"  = "preset_one_col",
            "Custom order"   = "preset_custom"
          ),
          selected = preset_now
        ),
        
        tags$hr(),
        
        checkboxGroupInput(
          "diag_plots_selected",
          "Plots to display",
          choices = c(
            "Residuals over time"                          = "ts",
            "Residual ACF"                                 = "acf",
            "Residual PACF"                                = "pacf",
            "Residual histogram"                           = "hist",
            "Normal Q-Q"                                   = "qq",
            "Residuals vs fitted"                          = "fitted",
            "Scale-location (sqrt(|res|) vs fitted)"       = "scale",
            "Ljung–Box p-values by lag"                    = "lb"
          ),
          selected = sel_now
        ),
        
        tags$hr(),
        
        sliderInput(
          "diag_container_width_px",
          "Container width (px)",
          min = 1000, max = 5000, value = container_w, step = 50
        ),
        # helpText("Controls the whole Diagnostics width (was width:100%). Scroll horizontally if needed."),
        
        tags$hr(),
        
        # ONLY TWO plot sliders
        sliderInput(
          "diag_plot_width",
          "Plot width (px)",
          min = 300, max = 2500, value = pw_now, step = 25
        ),
        sliderInput(
          "diag_plot_height",
          "Plot height (px)",
          min = 200, max = 1400, value = ph_now, step = 10
        ),
        
        tags$hr(),
        
        checkboxInput("diag_show_conclusion", "Show academic conclusion panel", value = show_conc),
        
        conditionalPanel(
          condition = "input.diag_layout_preset == 'preset_custom'",
          tags$h5("Custom positions (1 = first)"),
          helpText("Give each enabled plot a position. Ties are broken by name."),
          numericInput("pos_ts",     "Residuals over time position", value = safe_int1(input$pos_ts, 1L), min = 1, step = 1),
          numericInput("pos_acf",    "Residual ACF position",        value = safe_int1(input$pos_acf, 2L), min = 1, step = 1),
          numericInput("pos_hist",   "Histogram position",           value = safe_int1(input$pos_hist, 3L), min = 1, step = 1),
          numericInput("pos_qq",     "Q-Q position",                 value = safe_int1(input$pos_qq, 4L), min = 1, step = 1),
          numericInput("pos_fitted", "Residuals vs fitted position", value = safe_int1(input$pos_fitted, 5L), min = 1, step = 1),
          numericInput("pos_scale",  "Scale-location position",      value = safe_int1(input$pos_scale, 6L), min = 1, step = 1),
          numericInput("pos_lb",     "Ljung–Box p-values position",  value = safe_int1(input$pos_lb, 7L), min = 1, step = 1)
        )
      ),
      
      # Right panel
      tags$div(
        style = "
        flex:1 1 auto;
        border:1px solid #e5e5e5;
        border-radius:10px;
        background:#fcfcfc;
        padding:10px;
        overflow:auto;
        max-height:85vh;
      ",
        
        tags$div(
          style = "margin-bottom:12px;",
          tags$h4("Residual diagnostics (Manual SARIMA)"),
          tags$p("Use container width + plot width/height. Scroll right/down to see everything.")
        ),
        
        uiOutput("manual_diag_canvas_ui"),
        
        conditionalPanel(
          condition = "input.diag_show_conclusion == true",
          tags$h4("Academic conclusion (Diagnostics)"),
          tags$div(
            style = "padding:10px;border:1px solid #e5e5e5;border-radius:10px;background:#ffffff;",
            verbatimTextOutput("manual_diag_commentary_diag")
          )
        )
      )
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # --------------------------------------------- 
  
  # output$manual_diag_tests <- renderText({ req(manual_fit()); diag_tests_text(residuals(manual_fit()), lag = as.numeric(input$diag_lag), fitdf = length(coef(manual_fit()))) })

  # Manual SARIMA residual tests (formatted)
  output$manual_diag_tests <- renderPrint({
    req(manual_fit())
    cat(
      residual_diagnostics_report_full(
        res   = residuals(manual_fit()),
        L     = suppressWarnings(as.integer(input$diag_lag %||% 12)),
        fitdf = length(coef(manual_fit())),
        alpha = to_num_safe(input$alphaSt2 %||% 0.05, 0.05)
      )
    )
  })
  
  
  residual_diagnostics_report_full <- function(res, L = 12L, fitdf = 0L, alpha = 0.05) {
    # sanitize
    res   <- as.numeric(res); res <- res[is.finite(res)]
    N     <- length(res)
    L     <- max(1L, as.integer(L))
    fitdf <- max(0L, as.integer(fitdf))
    alpha <- to_num_safe(alpha, 0.05)
    
    if (N < 8) {
      return(paste(
        "==========================================================================",
        "                    RESIDUAL DIAGNOSTIC BATTERY                           ",
        "==========================================================================",
        " Too few residuals (N < 8) to run the requested tests.",
        sep = "\n"
      ))
    }
    
    # convenience numbers
    df_lb  <- max(L - fitdf, 1L)
    cv_lb  <- stats::qchisq(1 - alpha, df = df_lb)
    cv_jb  <- stats::qchisq(1 - alpha, df = 2)
    arch_m <- min(L, max(1L, floor(N / 10)))
    zcrit  <- stats::qnorm(1 - alpha/2)
    
    # tests
    lb   <- tryCatch(stats::Box.test(res, lag = L, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
    bp   <- tryCatch(stats::Box.test(res, lag = L, type = "Box-Pierce", fitdf = fitdf), error = function(e) NULL)
    jb   <- if (requireNamespace("tseries", quietly = TRUE)) tryCatch(tseries::jarque.bera.test(res), error = function(e) NULL) else NULL
    sw   <- if (N >= 3 && N <= 5000) tryCatch(stats::shapiro.test(res), error = function(e) NULL) else NULL
    arch <- if (requireNamespace("FinTS", quietly = TRUE)) tryCatch(FinTS::ArchTest(res, lags = arch_m), error = function(e) NULL) else NULL
    run  <- if (requireNamespace("tseries", quietly = TRUE)) tryCatch(tseries::runs.test(res), error = function(e) NULL) else NULL
    ad   <- if (requireNamespace("nortest", quietly = TRUE)) tryCatch(nortest::ad.test(res), error = function(e) NULL) else NULL
    
    # pull numbers safely
    lb_stat  <- if (!is.null(lb))  as.numeric(lb$statistic) else NA_real_
    lb_p     <- if (!is.null(lb))  as.numeric(lb$p.value)   else NA_real_
    bp_stat  <- if (!is.null(bp))  as.numeric(bp$statistic) else NA_real_
    bp_p     <- if (!is.null(bp))  as.numeric(bp$p.value)   else NA_real_
    jb_stat  <- if (!is.null(jb))  as.numeric(jb$statistic) else NA_real_
    jb_p     <- if (!is.null(jb))  as.numeric(jb$p.value)   else NA_real_
    sw_W     <- if (!is.null(sw))  as.numeric(sw$statistic) else NA_real_
    sw_p     <- if (!is.null(sw))  as.numeric(sw$p.value)   else NA_real_
    arch_stat<- if (!is.null(arch))as.numeric(arch$statistic) else NA_real_
    arch_p   <- if (!is.null(arch))as.numeric(arch$p.value)    else NA_real_
    run_Z    <- if (!is.null(run)) as.numeric(run$statistic)  else NA_real_
    run_p    <- if (!is.null(run)) as.numeric(run$p.value)    else NA_real_
    ad_A2    <- if (!is.null(ad))  as.numeric(ad$statistic)   else NA_real_
    ad_p     <- if (!is.null(ad))  as.numeric(ad$p.value)     else NA_real_
    
    # flags for the overall conclusion
    lb_ok   <- is.finite(lb_p)   && lb_p   >= alpha
    bp_ok   <- is.finite(bp_p)   && bp_p   >= alpha
    norm_ok <- (is.finite(jb_p) && jb_p >= alpha) || (is.finite(sw_p) && sw_p >= alpha) || (is.finite(ad_p) && ad_p >= alpha)
    arch_ok <- is.null(arch) || (is.finite(arch_p) && arch_p >= alpha)
    runs_ok <- is.null(run)  || (is.finite(run_p)  && run_p  >= alpha)
    
    out <- c(
      "==========================================================================",
      "                     RESIDUAL DIAGNOSTIC BATTERY                          ",
      "==========================================================================",
      sprintf(" SAMPLE SIZE (residuals): %d   |   α: %s   |   Lag (L): %d   |   fitdf: %d",
              N, fmt_num(alpha, 4), L, fitdf),
      "--------------------------------------------------------------------------",
      
      # TEST 1: Ljung–Box
      "TEST 1 — LJUNG–BOX PORTMANTEAU (AUTOCORRELATION)",
      " Purpose: Detect remaining serial correlation up to lag L in the residuals of the fitted model.",
      " Description: The Ljung–Box statistic sums squared sample autocorrelations with a small-sample",
      "  correction. After estimating ARMA/SARIMA parameters, the degrees of freedom are reduced by the",
      "  number of fitted coefficients (fitdf). Well-specified residuals should resemble white noise.",
      " • H0: Residuals are white noise (no serial correlation up to lag L).",
      " • Ha: Residuals are autocorrelated (model may be underspecified).",
      sprintf(" → CRITERIA: Reject H0 if Q(LB) > χ^2_(%d,1-α)  (equivalently p-value < α).", df_lb),
      " RESULT:",
      sprintf("  - Q(LB)          : %s", fmt_num(lb_stat, 4)),
      sprintf("  - df (L - fitdf) : %d", df_lb),
      sprintf("  - χ^2 crit       : %s", fmt_num(cv_lb, 4)),
      sprintf("  - p-value        : %s", fmt_p(lb_p)),
      " DECISION & INTERPRETATION:",
      if (!is.finite(lb_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (lb_p < alpha) {
        "  Reject H0. The residuals still contain autocorrelation up to lag L. This suggests the model may be\n  missing AR/MA or seasonal terms, or that differencing is insufficient. Review ACF/PACF of residuals and\n  consider adjusting orders, seasonal components, or transformations."
      } else {
        "  Fail to reject H0. Residuals behave like white noise up to lag L. This supports the adequacy of the model’s\n  dynamic specification (orders), which is desirable before interpreting parameters or forecasting."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 2: Box–Pierce
      "TEST 2 — BOX–PIERCE PORTMANTEAU (CLASSIC AUTOCORRELATION)",
      " Purpose: Older portmanteau test for residual autocorrelation; conceptually similar to Ljung–Box.",
      " Description: Uses a simpler large-sample approximation without the Ljung–Box small-sample correction.",
      "  It is less accurate in small samples but should broadly agree with Ljung–Box when N is moderate/large.",
      " • H0: Residuals are white noise.",
      " • Ha: Residuals are autocorrelated.",
      sprintf(" → CRITERIA: Reject H0 if Q(BP) > χ^2_(%d,1-α)  (equivalently p-value < α).", df_lb),
      " RESULT:",
      sprintf("  - Q(BP)    : %s", fmt_num(bp_stat, 4)),
      sprintf("  - df       : %d", df_lb),
      sprintf("  - χ^2 crit : %s", fmt_num(cv_lb, 4)),
      sprintf("  - p-value  : %s", fmt_p(bp_p)),
      " DECISION & INTERPRETATION:",
      if (!is.finite(bp_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (bp_p < alpha) {
        "  Reject H0. Autocorrelation remains. Combined with Ljung–Box, this strengthens the case for revising the model."
      } else {
        "  Fail to reject H0. No strong evidence of residual autocorrelation by Box–Pierce."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 3: Jarque–Bera
      "TEST 3 — JARQUE–BERA (NORMALITY: SKEWNESS & KURTOSIS)",
      " Purpose: Evaluate whether residuals are approximately normally distributed by combining deviations in skewness",
      "  and kurtosis. Normal residuals help ensure well-calibrated prediction intervals and valid t-statistics in",
      "  regression-type outputs.",
      " Description: Asymptotically follows χ^2 with 2 df. Sensitive to heavy tails and skew.",
      " • H0: Residuals are normally distributed.",
      " • Ha: Residuals are not normal (skewed and/or heavy/light tails).",
      " → CRITERIA: Reject H0 if JB > χ^2_(2,1-α) (equivalently p-value < α).",
      " RESULT:",
      sprintf("  - JB statistic : %s", fmt_num(jb_stat, 4)),
      sprintf("  - χ^2 crit    : %s", fmt_num(cv_jb, 4)),
      sprintf("  - p-value     : %s", fmt_p(jb_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(jb)) {
        "  Skipped: package 'tseries' not installed."
      } else if (!is.finite(jb_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (jb_p < alpha) {
        "  Reject H0. Residuals deviate from normality. Forecast means are still unbiased if the model is correct, but\n  interval forecasts may be miscalibrated. Consider transformations (e.g., log/Box–Cox), robust modeling, or\n  heavy-tailed error models (e.g., t innovations) if this materially affects your goals."
      } else {
        "  Fail to reject H0. Normality is plausible by JB, supporting standard interval calibration."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 4: Shapiro–Wilk
      "TEST 4 — SHAPIRO–WILK (NORMALITY: SMALL/MEDIUM N)",
      " Purpose: Sensitive test for normality, recommended when sample size is small to moderate.",
      " Description: Based on correlation between ordered sample values and corresponding normal scores. Does not print a simple",
      "  critical value in base R; decisions are p-value based. Defined for 3 ≤ N ≤ 5000.",
      " • H0: Residuals come from a normal distribution.",
      " • Ha: Residuals are non-normal.",
      " → CRITERIA: Reject H0 if p-value < α.",
      " RESULT:",
      sprintf("  - W statistic : %s", fmt_num(sw_W, 4)),
      sprintf("  - p-value     : %s", if (N > 5000) "n/a (N > 5000)" else fmt_p(sw_p)),
      " DECISION & INTERPRETATION:",
      if (N > 5000) {
        "  Omitted: Shapiro–Wilk is defined only up to N = 5000. For large N, prefer visual tools (QQ plot) and JB."
      } else if (is.null(sw)) {
        "  Inconclusive: Shapiro–Wilk did not run."
      } else if (!is.finite(sw_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (sw_p < alpha) {
        "  Reject H0. Residuals depart from normality. Inspect QQ plot to see whether tails or skew drive the result; the remedy\n  depends on whether the distribution is heavy-tailed, skewed, or affected by outliers/level shifts."
      } else {
        "  Fail to reject H0. Shapiro–Wilk supports approximate normality."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 5: Engle ARCH LM
      "TEST 5 — ENGLE'S ARCH LM (TIME-VARYING VARIANCE)",
      sprintf(" Purpose: Detect ARCH effects (conditional heteroskedasticity) up to %d lags. If present, variance clusters over time,", arch_m),
      "  which violates the constant-variance assumption and can distort interval forecasts.",
      " Description: Regress squared residuals on their own lags; under H0, the LM statistic ~ χ^2 with degrees of freedom equal",
      "  to the number of lags. Often used to motivate GARCH-type extensions.",
      " • H0: No ARCH effects (variance is constant over time).",
      " • Ha: ARCH effects present (variance changes with time).",
      sprintf(" → CRITERIA: Reject H0 if LM > χ^2_(%d,1-α) (equivalently p-value < α).", arch_m),
      " RESULT:",
      sprintf("  - LM statistic : %s", fmt_num(arch_stat, 4)),
      sprintf("  - df (lags)    : %d", arch_m),
      sprintf("  - χ^2 crit     : %s", fmt_num(stats::qchisq(1 - alpha, df = arch_m), 4)),
      sprintf("  - p-value      : %s", fmt_p(arch_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(arch)) {
        "  Skipped: package 'FinTS' not installed. If volatility clustering is suspected (e.g., financial data), consider installing it."
      } else if (!is.finite(arch_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (arch_p < alpha) {
        "  Reject H0. Evidence of time-varying variance. Consider SARIMA + GARCH (or other conditional variance models) if volatility matters\n  for your application; otherwise, robust intervals or transformations can help."
      } else {
        "  Fail to reject H0. No strong evidence of ARCH effects; the constant variance assumption is reasonable."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 6: Runs test
      "TEST 6 — RUNS TEST (RANDOMNESS OF SIGNS)",
      " Purpose: Check whether residual signs (+/−) appear in random order. Non-random runs can indicate leftover structure",
      "  (e.g., bias, level shifts) even when autocorrelations are small.",
      " Description: Based on the number of sign runs compared with its expectation under randomness; large |Z| rejects randomness.",
      " • H0: Residual signs occur in random order (independent signs).",
      " • Ha: Residual signs are not random (patterns/clustering of signs).",
      sprintf(" → CRITERIA: Reject H0 if |Z| > %s  (equivalently p-value < α).", fmt_num(zcrit, 3)),
      " RESULT:",
      sprintf("  - Z statistic : %s", fmt_num(run_Z, 4)),
      sprintf("  - p-value     : %s", fmt_p(run_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(run)) {
        "  Skipped: package 'tseries' not installed."
      } else if (!is.finite(run_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (run_p < alpha) {
        "  Reject H0. Residual signs are not random, hinting at systematic under- or over-prediction or structural change.\n  Inspect fitted vs. actual plots and consider adding trend/seasonal terms or handling breaks/outliers."
      } else {
        "  Fail to reject H0. Residual signs appear random, which is consistent with an unbiased model."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 7: Anderson–Darling
      "TEST 7 — ANDERSON–DARLING (NORMALITY, TAIL-SENSITIVE)",
      " Purpose: Additional normality check that gives more weight to the tails than Shapiro–Wilk/Jarque–Bera.",
      " Description: Often more sensitive to deviations in the extremes; useful when tail behavior matters for prediction intervals.",
      " • H0: Residuals are normally distributed.",
      " • Ha: Residuals are not normal.",
      " → CRITERIA: Reject H0 if p-value < α.",
      " RESULT:",
      sprintf("  - A^2 statistic : %s", fmt_num(ad_A2, 4)),
      sprintf("  - p-value       : %s", fmt_p(ad_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(ad)) {
        "  Skipped: package 'nortest' not installed."
      } else if (!is.finite(ad_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (ad_p < alpha) {
        "  Reject H0. Tail behavior deviates from normality; extreme forecast errors may be more common than normal theory predicts."
      } else {
        "  Fail to reject H0. Normal tails are plausible by Anderson–Darling."
      },
      
      "==========================================================================",
      "OVERALL CONCLUSION (HOW TO READ THESE TESTS TOGETHER)",
      if (!lb_ok || !bp_ok) {
        " Serial correlation is still present (one or both portmanteau tests rejected). Before relying on forecasts or coefficients,\n refine the SARIMA specification: check ACF/PACF of residuals, reconsider differencing (d/D), and try alternative AR/MA and\n seasonal orders until residual autocorrelation is removed."
      } else if (!arch_ok) {
        " Autocorrelation is under control, but variance likely varies over time (ARCH). For applications where interval accuracy matters,\n consider augmenting SARIMA with a volatility model (e.g., GARCH)."
      } else if (!norm_ok) {
        " Dynamics look adequate, but residuals deviate from normality. Forecast means remain useful; however, prediction intervals may\n need robust/bootstrapped methods, transformations, or heavy-tailed innovations."
      } else if (!runs_ok) {
        " No strong autocorrelation and variance looks stable, yet residual signs are not random. This can indicate bias or a structural\n feature not captured by the model. Inspect time plots/level shifts and consider adding trend/seasonal regressors or break handling."
      } else {
        " All core checks pass (no autocorrelation, no clear ARCH, normality plausible, signs random). Residual behavior is consistent with\n a well-specified SARIMA. Proceed to forecasting and keep monitoring residuals after re-estimation on new data."
      }
    )
    
    paste(out, collapse = "\n")
  }
  
  
  # --------------------------------------------- 
  # --------------------------------------------- 
  
  
  
  # ============================================================
  # --- MOD: Manual SARIMA equation renderer (FULL code) ---
  # ============================================================
  
  
  
  manual_equations <- reactive({
    req(manual_fit(), ts_train_test())
    
    fit   <- manual_fit()
    coefs <- coef(fit)
    
    # Orders
    p <- as.integer(input$p); d <- as.integer(input$d); q <- as.integer(input$q)
    P <- as.integer(input$P); D <- as.integer(input$D); Q <- as.integer(input$Q)
    
    # Seasonal period (never NA)
    s <- if (!is.na(input$s) && input$s >= 1) {
      as.integer(input$s)
    } else {
      f <- frequency(ts_train_test()$ts_train)
      if (is.na(f) || f < 1) 1L else as.integer(f)
    }
    
    ip <- if (p > 0) seq_len(p) else integer(0)
    iq <- if (q > 0) seq_len(q) else integer(0)
    iP <- if (P > 0) seq_len(P) else integer(0)
    iQ <- if (Q > 0) seq_len(Q) else integer(0)
    
    # Intercept/mean (show only if not ~0)
    intercept_name <- intersect(c("intercept", "mean"), names(coefs))
    intercept_val  <- if (length(intercept_name) > 0) unname(coefs[intercept_name[1]]) else 0
    show_intercept <- is.finite(intercept_val) && abs(intercept_val) > 1e-8
    intercept_num  <- if (show_intercept) sprintf("%.3f", intercept_val) else ""
    
    # Drift
    drift_sym <- if (isTRUE(input$manual_drift)) " + \\delta t" else ""
    drift_val <- if (isTRUE(input$manual_drift) && "drift" %in% names(coefs)) unname(coefs["drift"]) else NA_real_
    drift_num <- if (isTRUE(input$manual_drift) && is.finite(drift_val) && abs(drift_val) > 1e-8) {
      paste0(" + ", sprintf("%.3f", drift_val), "t")
    } else if (isTRUE(input$manual_drift)) {
      " + \\delta t"
    } else ""
    
    # MathJax display wrapper
    tex_display <- function(x) paste0("\\[", x, "\\]")
    
    # Cleanup for numeric line
    simplify_tex <- function(x) {
      x <- gsub("\\(1\\)", "", x)
      x <- gsub("\\s+", " ", x)
      x <- gsub("\\+\\s*\\+", "+", x)
      x <- gsub("\\+\\s*-", "-", x)
      x <- gsub("-\\s*\\+", "-", x)
      x <- gsub("-\\s*-", "+", x)
      x <- gsub("\\s*\\+\\s*0\\.000\\b", "", x)
      trimws(x)
    }
    
    # Parameter-polynomial strings (symbolic)
    poly_param_ar  <- function() if (p == 0) "1" else paste0("1", paste0(" - \\phi_{", ip, "}L^{", ip, "}", collapse = ""))
    poly_param_sar <- function() if (P == 0) "1" else paste0("1", paste0(" - \\Phi_{", iP, "}L^{", s * iP, "}", collapse = ""))
    poly_param_ma  <- function() if (q == 0) "1" else paste0("1", paste0(" + \\theta_{", iq, "}L^{", iq, "}", collapse = ""))
    poly_param_sma <- function() if (Q == 0) "1" else paste0("1", paste0(" + \\Theta_{", iQ, "}L^{", s * iQ, "}", collapse = ""))
    
    # Numeric-polynomial strings (from estimates)
    poly_num_ar <- function() {
      if (p == 0) return("1")
      nms <- paste0("ar", ip)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], ip[keep]), collapse = ""))
    }
    poly_num_sar <- function() {
      if (P == 0) return("1")
      nms <- paste0("sar", iP)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iP
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], lags[keep]), collapse = ""))
    }
    poly_num_ma <- function() {
      if (q == 0) return("1")
      nms <- paste0("ma", iq)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], iq[keep]), collapse = ""))
    }
    poly_num_sma <- function() {
      if (Q == 0) return("1")
      nms <- paste0("sma", iQ)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iQ
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], lags[keep]), collapse = ""))
    }
    
    # Differencing operators
    diff_part  <- if (d > 0) paste0("(1-L)^{", d, "}") else ""
    sdiff_part <- if (D > 0) paste0("(1-L^{", s, "})^{", D, "}") else ""
    
    # Line 1: General operator form
    line1 <- paste0(
      "\\phi_p(L)\\,\\Phi_P(L^{S})\\,(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + \\theta_q(L)\\,\\Theta_Q(L^{S})\\varepsilon_t", drift_sym
    )
    
    # Line 2: Expanded operator (summation)
    line2 <- paste0(
      "\\left(1-\\sum_{i=1}^{p}\\phi_i L^{i}\\right)",
      "\\left(1-\\sum_{j=1}^{P}\\Phi_j L^{jS}\\right)",
      "(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + ",
      "\\left(1+\\sum_{i=1}^{q}\\theta_i L^{i}\\right)",
      "\\left(1+\\sum_{j=1}^{Q}\\Theta_j L^{jS}\\right)",
      "\\varepsilon_t", drift_sym
    )
    
    # Line 3: parameter-expanded polynomials
    line3 <- paste0(
      "(", poly_param_ar(), ")",
      "(", poly_param_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = c + ",
      "(", poly_param_ma(), ")",
      "(", poly_param_sma(), ")\\varepsilon_t",
      drift_sym
    )
    
    # Line 4: numeric-expanded polynomials
    rhs_intercept <- if (show_intercept) paste0(intercept_num, " + ") else ""
    line4 <- paste0(
      "(", poly_num_ar(), ")",
      "(", poly_num_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = ",
      rhs_intercept,
      "(", poly_num_ma(), ")",
      "(", poly_num_sma(), ")\\varepsilon_t",
      drift_num
    )
    line4 <- simplify_tex(line4)
    
    # Time-domain (teaching form)
    ar_vals  <- if (p > 0) suppressWarnings(unname(coefs[paste0("ar", ip)])) else numeric(0)
    sar_vals <- if (P > 0) suppressWarnings(unname(coefs[paste0("sar", iP)])) else numeric(0)
    ma_vals  <- if (q > 0) suppressWarnings(unname(coefs[paste0("ma", iq)])) else numeric(0)
    sma_vals <- if (Q > 0) suppressWarnings(unname(coefs[paste0("sma", iQ)])) else numeric(0)
    
    keep_ar  <- is.finite(ar_vals)
    keep_sar <- is.finite(sar_vals)
    keep_ma  <- is.finite(ma_vals)
    keep_sma <- is.finite(sma_vals)
    
    td <- paste0(
      "Y_t = ",
      if (show_intercept) intercept_num else "0",
      if (p > 0 && any(keep_ar))  paste0(paste(sprintf(" %+.3fY_{t-%d}", ar_vals[keep_ar], ip[keep_ar]), collapse = "")) else "",
      if (P > 0 && any(keep_sar)) paste0(paste(sprintf(" %+.3fY_{t-%d}", sar_vals[keep_sar], (s * iP)[keep_sar]), collapse = "")) else "",
      if (q > 0 && any(keep_ma))  paste0(paste(sprintf(" %+.3f\\varepsilon_{t-%d}", ma_vals[keep_ma], iq[keep_ma]), collapse = "")) else "",
      if (Q > 0 && any(keep_sma)) paste0(paste(sprintf(" %+.3f\\varepsilon_{t-%d}", sma_vals[keep_sma], (s * iQ)[keep_sma]), collapse = "")) else "",
      " + \\varepsilon_t",
      if (d > 0 || D > 0) paste0(" \\\\ \\text{(with differencing: }(1-L)^{", d, "}(1-L^{", s, "})^{", D, "}\\text{)}") else ""
    )
    td <- simplify_tex(td)
    
    # ---------- Estimated coefficients (MathJax-friendly) ----------
    coef_lines <- c()
    
    if (show_intercept) {
      coef_lines <- c(coef_lines, paste0("\\(c\\) (intercept/mean) = ", sprintf("%.4f", intercept_val)))
    }
    if (isTRUE(input$manual_drift)) {
      if (is.finite(drift_val)) {
        coef_lines <- c(coef_lines, paste0("drift \\((\\delta)\\) = ", sprintf("%.4f", drift_val)))
      } else {
        coef_lines <- c(coef_lines, "drift \\((\\delta)\\) included (value not estimated explicitly)")
      }
    }
    
    if (p > 0) {
      for (i in ip) {
        nm <- paste0("ar", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("ar", i, ": \\(\\phi_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    if (q > 0) {
      for (i in iq) {
        nm <- paste0("ma", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("ma", i, ": \\(\\theta_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    if (P > 0) {
      for (i in iP) {
        nm <- paste0("sar", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("sar", i, ": \\(\\Phi_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    if (Q > 0) {
      for (i in iQ) {
        nm <- paste0("sma", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("sma", i, ": \\(\\Theta_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    
    if (length(coef_lines) == 0) coef_lines <- "No coefficients available."
    
    list(
      p = p, d = d, q = q, P = P, D = D, Q = Q, s = s,
      coef_lines   = coef_lines,
      eq_general   = tex_display(line1),
      eq_expanded  = tex_display(line2),
      eq_line3     = tex_display(line3),
      eq_line4     = tex_display(line4),
      eq_time_domain = tex_display(td)
    )
  })
  
  
  
  
  
 
  
  # ============================================================
  # --- MOD: Render the equation panel with LEFT alignment (CSS) and headings ---
  #   NOTE: Left alignment is done via an HTML wrapper div.
  # ============================================================
  
  # --- helper: scientific formatting (uppercase E), preserves NA ---
  fmt_sci <- function(x, digits = 4) {
    ifelse(is.na(x),
           NA_character_,
           toupper(formatC(x, format = "e", digits = digits)))
  }
  
  # --- helper: show scientific only when needed (tiny/huge), else fixed ---
  fmt_auto <- function(x, digits_fixed = 6, digits_sci = 4) {
    ifelse(
      is.na(x),
      NA_character_,
      ifelse(abs(x) > 0 & (abs(x) < 1e-4 | abs(x) >= 1e5),
             toupper(formatC(x, format = "e", digits = digits_sci)),
             formatC(x, format = "fg", digits = digits_fixed, flag = "#"))
    )
  }
  
  # Parameter significance table for Manual SARIMA (robust to tiny numbers)
  output$manual_param_table <- renderTable({
    req(manual_fit())
    fit <- manual_fit()
    
    # 1) Coefficients
    est <- tryCatch(stats::coef(fit), error = function(e) NULL)
    validate(need(!is.null(est) && length(est) > 0, "No estimated parameters available."))
    
    # 2) Covariance → SE (robust fallbacks)
    V <- tryCatch(stats::vcov(fit), error = function(e) NULL)
    if (is.null(V)) V <- tryCatch(fit$var.coef, error = function(e) NULL)  # forecast::Arima stores var.coef
    se <- if (!is.null(V)) sqrt(diag(V)) else rep(NA_real_, length(est))
    
    # 3) Test stats and p-values (normal/Z approx)
    tst <- est / se
    pvl <- 2 * stats::pnorm(abs(tst), lower.tail = FALSE)
    
    # 4) Nice names (optional)
    s <- suppressWarnings(tryCatch(manual_equations()$s, error = function(e) NA_integer_))
    map_name <- function(nm) {
      nm <- gsub("^ar(\\d+)$", "AR{\\1}", nm, ignore.case = TRUE)
      nm <- gsub("^ma(\\d+)$", "MA{\\1}", nm, ignore.case = TRUE)
      if (isTRUE(!is.na(s))) {
        nm <- gsub("^sar\\d+$", paste0("SAR{", s, "}"), nm, ignore.case = TRUE)
        nm <- gsub("^sma\\d+$", paste0("SMA{", s, "}"), nm, ignore.case = TRUE)
      } else {
        nm <- gsub("^sar\\d+$", "SAR", nm, ignore.case = TRUE)
        nm <- gsub("^sma\\d+$", "SMA", nm, ignore.case = TRUE)
      }
      nm <- gsub("^intercept$", "Constant", nm, ignore.case = TRUE)
      nm <- gsub("^mean$",      "Constant", nm, ignore.case = TRUE)
      nm <- gsub("^drift$",     "Drift",    nm, ignore.case = TRUE)
      nm
    }
    
    df_num <- data.frame(
      Parameter        = vapply(names(est), map_name, character(1)),
      Value            = as.numeric(est),
      `Standard Error` = as.numeric(se),
      `t Statistic`    = as.numeric(tst),
      `P-Value`        = as.numeric(pvl),
      check.names = FALSE
    )
    
    # 5) Append variance (no significance test)
    sigma2 <- suppressWarnings(as.numeric(fit$sigma2))
    if (is.finite(sigma2)) {
      df_num <- rbind(
        df_num,
        data.frame(Parameter = "Variance",
                   Value = sigma2,
                   `Standard Error` = NA_real_,
                   `t Statistic` = NA_real_,
                   `P-Value` = NA_real_,
                   check.names = FALSE)
      )
    }
    
    # 6) FORMAT: keep numbers that need scientific notation in E form (e.g., 5.2E-12)
    df_out <- transform(
      df_num,
      Value            = fmt_auto(Value),
      `Standard Error` = fmt_auto(`Standard Error`),
      `t Statistic`    = fmt_auto(`t Statistic`),
      `P-Value`        = fmt_sci(`P-Value`, digits = 3)  # always scientific for p-values
    )
    
    df_out
  }, rownames = FALSE)
  
  
  
  # Goodness-of-fit table for Manual SARIMA
  output$manual_gof_table <- renderTable({
    req(manual_fit())
    
    fit <- manual_fit()
    
    # sample size and parameter count
    n <- tryCatch(length(residuals(fit)), error = function(e) NA_integer_)
    k <- tryCatch(length(coef(fit)),      error = function(e) NA_integer_)
    
    # AIC
    AIC_val <- suppressWarnings(tryCatch(stats::AIC(fit), error = function(e) NA_real_))
    
    # BIC (use generic first; if unavailable, compute from logLik)
    BIC_val <- suppressWarnings(tryCatch(stats::BIC(fit), error = function(e) NA_real_))
    if (!is.finite(BIC_val)) {
      ll <- suppressWarnings(tryCatch(as.numeric(logLik(fit)), error = function(e) NA_real_))
      if (is.finite(ll) && is.finite(k) && is.finite(n) && n > 0) {
        BIC_val <- (-2 * ll) + k * log(n)
      }
    }
    
    # AICc (use forecast::AICc if available; otherwise use formula)
    AICc_val <- suppressWarnings(tryCatch(forecast::AICc(fit), error = function(e) NA_real_))
    if (!is.finite(AICc_val) && is.finite(AIC_val) && is.finite(k) && is.finite(n) && (n - k - 1) > 0) {
      AICc_val <- AIC_val + (2 * k * (k + 1)) / (n - k - 1)
    }
    
    # Assemble table
    out <- data.frame(
      Metric = c("AIC", "AICc", "BIC"),
      Value  = c(AIC_val, AICc_val, BIC_val),
      check.names = FALSE
    )
    
    # Numeric formatting
    out$Value <- ifelse(is.na(out$Value), NA, signif(out$Value, 6))
    out
  }, rownames = FALSE)
  
  
  
  output$manual_model_equation <- renderUI({
    req(manual_equations())
    eq <- manual_equations()
    
    tagList(
      tags$div(
        style = "text-align:left;",
        
        tags$h4("Manual SARIMA model"),
        tags$p(sprintf("SARIMA(%d,%d,%d)(%d,%d,%d)[%d]", eq$p, eq$d, eq$q, eq$P, eq$D, eq$Q, eq$s)),
        
        tags$h5("Estimated coefficients"),
        tags$ul(lapply(eq$coef_lines, function(x) tags$li(HTML(x)))),
        
        ## parameter significance table
        tags$hr(),
        tags$h4("Table: Estimation Results"),
        tableOutput("manual_param_table"), 
        
        
        tags$hr(),
        tags$h4("Table: Goodness of Fit"),
        tableOutput("manual_gof_table"),
        
        tags$hr(),
        tags$h4("General SARIMA formulation"),
        HTML(eq$eq_general),
        
        tags$hr(),
        
        tags$h4("Expanded operator form"),
        HTML(eq$eq_expanded),
        
        tags$hr(),
        
        tags$h4("Numerical model"),
        HTML(eq$eq_line3),
        tags$hr(),
        HTML(eq$eq_line4),
        
        tags$hr(),
        
  
      ),
      
      # keep MathJax refresh
      tags$script(HTML("if (window.MathJax && MathJax.Hub) MathJax.Hub.Queue(['Typeset', MathJax.Hub]);"))
    )
  })
  
  
  
  
  
  # --- MOD: helper used above inside renderUI (place near other helpers or above output block) ---
  tex_display <- function(x) paste0("\\[", x, "\\]")
  
  
  

  # --------------------------------------------- 
  # --------------------------------------------- 
  
  output$manual_forecast_plot <- renderPlot({
    req(manual_fc(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    fc <- manual_fc()$fc

    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")

    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    gg_forecast_plot(obs_df, s$train_n, fc_df, title = "Manual SARIMA forecast (train/test + intervals)")
  })
  
  
  # ---- Manual SARIMA: Original-scale plot (observed + forecast + CIs) ----
  output$manual_forecast_plot_original <- renderPlot({
    req(manual_fc(), ts_train_test(), prepared())
    
    s <- ts_train_test()
    p <- prepared()
    fc <- manual_fc()$fc
    
    # observed series on ORIGINAL scale
    validate(need("y_filled" %in% names(s$dfm), "Column y_filled not found in ts_train_test()$dfm."))
    obs_df <- s$dfm[, c("x", "y_filled")]
    names(obs_df) <- c("x", "y")
    
    # build forecast df (x alignment) from existing helper, then back-transform values
    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    
    # inverse transform helper (must match your global transform choice)
    inv <- function(z) {
      tr <- input$transform %||% "none"
      z <- as.numeric(z)
      
      if (tr == "none") return(z)
      
      if (tr == "log") {
        return(exp(z))
      }
      
      if (tr == "boxcox") {
        y0 <- prepared()$df$y_filled
        validate(need(all(y0 > 0, na.rm = TRUE), "Box-Cox inverse requires strictly positive original values."))
        
        lam <- input$lambda
        if (is.null(lam) || (length(lam) == 1 && is.na(lam))) {
          lam <- forecast::BoxCox.lambda(y0, method = "guerrero")
        } else {
          lam <- as.numeric(lam)
        }
        return(forecast::InvBoxCox(z, lam))
      }
      
      z
    }
    
    # back-transform forecast mean + intervals
    fc_df$mean <- inv(fc_df$mean)
    if ("lo80" %in% names(fc_df)) fc_df$lo80 <- inv(fc_df$lo80)
    if ("hi80" %in% names(fc_df)) fc_df$hi80 <- inv(fc_df$hi80)
    if ("lo95" %in% names(fc_df)) fc_df$lo95 <- inv(fc_df$lo95)
    if ("hi95" %in% names(fc_df)) fc_df$hi95 <- inv(fc_df$hi95)
    
    gg_forecast_plot(
      obs_df, s$train_n, fc_df,
      title = "Manual SARIMA forecast (original scale)"
    )
  })
  
  

  output$manual_forecast_table <- renderTable({ req(manual_fc()); head(forecast_table(manual_fc()$fc), 25) }, rownames = FALSE)

  
  
  output$manual_accuracy_table <- renderTable({
    req(manual_fc(), ts_train_test())
    s <- ts_train_test()
    if (s$test_n == 0) return(data.frame(message = "No test set (training = 100%). Reduce training to compute accuracy."))
    accuracy_df(s$ts_test, manual_fc()$fc$mean)
  }, rownames = FALSE)

  output$apa_manual_paragraph <- renderPrint({
    req(manual_fit(), manual_fc(), ts_train_test())
    fit <- manual_fit()
    s <- ts_train_test()
    fc <- manual_fc()$fc
    lag <- as.numeric(input$diag_lag)
    lb <- tryCatch(Box.test(residuals(fit), lag = lag, type = "Ljung-Box", fitdf = length(coef(fit))), error = function(e) NULL)
    acc_line <- ""
    if (s$test_n > 0) {
      acc <- accuracy_df(s$ts_test, fc$mean)
      rmse <- acc$Value[acc$Metric == "RMSE"]
      mae <- acc$Value[acc$Metric == "MAE"]
      acc_line <- paste0("Forecast accuracy on the holdout set was RMSE = ", fmt_num(rmse, 2), " and MAE = ", fmt_num(mae, 2), ". ")
    }
    lb_line <- if (!is.null(lb)) paste0("The Ljung–Box test suggested ", ifelse(lb$p.value > 0.05, "no strong residual autocorrelation", "residual autocorrelation"), " (", fmt_p(lb$p.value), "). ") else ""
    cat(
      "APA-ready paragraph:\n\n",
      "A manual seasonal ARIMA model was specified as (", input$p, ",", input$d, ",", input$q, ")(",
      input$P, ",", input$D, ",", input$Q, ")[", ifelse(is.na(input$s), frequency(s$ts_train), input$s), "]. ",
      lb_line, acc_line,
      "Forecasts were produced with prediction intervals to quantify uncertainty.\n",
      sep = ""
    )
  })
  
  
  
  
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  
  
  # ---- Manual SARIMA: academic conclusion (cached on Fit click) ----
  
  # =========================
  # Manual SARIMA: FULL academic conclusion object (robust + detailed)
  # =========================
  
 
  
  
  
  
  
  # ============================================================
  # CORRECTED STRUCTURE
  #   1) Define ALL report outputs ONCE (outside eventReactive)
  #   2) manual_conclusion_full_obj ONLY computes + returns tagList UI
  # ============================================================
  
  
  # ------------------------------------------------------------
  # (A) REPORT OUTPUTS (define ONCE, outside manual_conclusion_full_obj)
  # ------------------------------------------------------------
  
  # ---- A) Time series plot (dates + dashed split) ----
  output$manual_report_ts_plot <- renderPlot({
    req(manual_conclusion_full_obj())     # ensures this is shown after Fit Manual
    req(ts_train_test(), prepared())
    
    s <- ts_train_test()
    p <- prepared()
    
    df <- s$dfm
    validate(need(nrow(df) >= 3, "Not enough observations to plot the time series."))
    
    df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test/Future")
    
    has_test <- isTRUE(s$test_n > 0)
    x_split  <- if (has_test) df$x[s$train_n] else NA
    
    g <- ggplot(df, aes(x = x, y = y_trans, color = set)) +
      geom_line(linewidth = 0.9) +
      theme_minimal() +
      labs(
        title = "Observed time series (transformed)",
        x = p$x_label,
        y = "Value",
        color = NULL
      ) +
      theme(legend.position = "bottom")
    
    if (has_test && !is.na(x_split)) {
      g <- g + geom_vline(
        xintercept = as.numeric(x_split),
        linetype = "dashed",
        linewidth = 0.7,
        color = "gray40"
      )
    }
    
    if (inherits(df$x, "Date")) {
      g <- g + scale_x_date(labels = scales::date_format("%Y-%m"),
                            breaks = scales::pretty_breaks(n = 8))
    } else if (inherits(df$x, "POSIXt")) {
      g <- g + scale_x_datetime(labels = scales::date_format("%Y-%m"),
                                breaks = scales::pretty_breaks(n = 8))
    }
    
    g
  })
  
  
  # ---- NEW: Stationarity tests (ADF + PP + KPSS) + conclusion paragraph ----
  output$manual_report_stationarity <- renderUI({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    validate(need(requireNamespace("tseries", quietly = TRUE),
                  "Package 'tseries' is required for stationarity tests (ADF/PP/KPSS)."))
    
    s_obj <- ts_train_test()
    
    # Use training series for stationarity assessment
    x <- as.numeric(s_obj$ts_train)
    x <- x[is.finite(x)]
    validate(need(length(x) >= 10, "Not enough training observations to run stationarity tests (need ≥ 10)."))
    
    fmt_num <- function(z, d = 3) {
      z <- suppressWarnings(as.numeric(z))
      if (length(z) == 0 || !is.finite(z[1])) return("NA")
      formatC(z[1], format = "f", digits = d)
    }
    fmt_p <- function(p) {
      p <- suppressWarnings(as.numeric(p))
      if (length(p) == 0 || !is.finite(p[1])) return("NA")
      if (p[1] < .001) "p < .001" else paste0("p = ", sub("^0\\.", ".", sprintf("%.3f", p[1])))
    }
    
    # safe lag choice for ADF
    k_adf <- max(0, min(12, floor((length(x) - 1)^(1/3))))
    
    adf <- tryCatch(tseries::adf.test(x, k = k_adf), error = function(e) NULL)
    pp  <- tryCatch(tseries::pp.test(x, lshort = TRUE), error = function(e) NULL)
    kpss_level <- tryCatch(tseries::kpss.test(x, null = "Level", lshort = TRUE), error = function(e) NULL)
    kpss_trend <- tryCatch(tseries::kpss.test(x, null = "Trend", lshort = TRUE), error = function(e) NULL)
    
    rows <- list()
    add_row <- function(test, null_h, stat, pval, decision) {
      rows[[length(rows) + 1L]] <<- data.frame(
        Test = test,
        `H0 (null)` = null_h,
        Statistic = stat,
        `p-value` = pval,
        Decision = decision,
        check.names = FALSE
      )
    }
    
    # ADF: H0 = unit root (non-stationary); reject => stationarity evidence
    if (!is.null(adf)) {
      p <- adf$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 → evidence for stationarity"
      else "Fail to reject H0 → unit root plausible"
      add_row("ADF (Augmented Dickey–Fuller)", "Unit root (non-stationary)",
              fmt_num(unname(adf$statistic)), fmt_p(p), dec)
    } else {
      add_row("ADF (Augmented Dickey–Fuller)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # PP: H0 = unit root (non-stationary); reject => stationarity evidence
    if (!is.null(pp)) {
      p <- pp$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 → evidence for stationarity"
      else "Fail to reject H0 → unit root plausible"
      add_row("PP (Phillips–Perron)", "Unit root (non-stationary)",
              fmt_num(unname(pp$statistic)), fmt_p(p), dec)
    } else {
      add_row("PP (Phillips–Perron)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # KPSS(Level): H0 = level-stationary; reject => non-stationarity evidence
    if (!is.null(kpss_level)) {
      p <- kpss_level$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 → evidence against stationarity"
      else "Fail to reject H0 → stationarity plausible"
      add_row("KPSS (Level)", "Level-stationary",
              fmt_num(unname(kpss_level$statistic)), fmt_p(p), dec)
    } else {
      add_row("KPSS (Level)", "Level-stationary", "NA", "NA", "Not available")
    }
    
    # KPSS(Trend): H0 = trend-stationary
    if (!is.null(kpss_trend)) {
      p <- kpss_trend$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 → evidence against trend-stationarity"
      else "Fail to reject H0 → trend-stationarity plausible"
      add_row("KPSS (Trend)", "Trend-stationary",
              fmt_num(unname(kpss_trend$statistic)), fmt_p(p), dec)
    } else {
      add_row("KPSS (Trend)", "Trend-stationary", "NA", "NA", "Not available")
    }
    
    st_df <- do.call(rbind, rows)
    
    # synthesis
    adf_p <- if (!is.null(adf)) adf$p.value else NA_real_
    pp_p  <- if (!is.null(pp))  pp$p.value  else NA_real_
    kL_p  <- if (!is.null(kpss_level)) kpss_level$p.value else NA_real_
    
    unit_root_rejected <- any(c(adf_p, pp_p) < 0.05, na.rm = TRUE)
    kpss_ok <- is.finite(kL_p) && kL_p >= 0.05
    
    conclusion <- if (unit_root_rejected && kpss_ok) {
      "Across tests, ADF/PP reject the unit-root null (p < .05) while KPSS(Level) does not reject stationarity (p ≥ .05), which is consistent with a stationary series (given the current transformation)."
    } else if (!unit_root_rejected && !kpss_ok) {
      "ADF/PP do not reject the unit-root null (p ≥ .05) while KPSS(Level) rejects stationarity (p < .05), providing convergent evidence of non-stationarity and supporting the need for differencing (d and/or D)."
    } else if (unit_root_rejected && !kpss_ok) {
      "Evidence is mixed: ADF/PP suggest stationarity but KPSS(Level) rejects it. This can occur under breaks, strong seasonality, or test sensitivity; complement these results with differencing checks and ACF/PACF."
    } else {
      "Evidence is inconclusive: ADF/PP do not reject a unit root while KPSS(Level) does not reject stationarity. Because power can be limited, complement these tests with differencing diagnostics and ACF/PACF."
    }
    
    # table renderer (HTML)
    html_tbl <- tags$table(
      class = "table table-striped table-condensed",
      tags$thead(tags$tr(lapply(names(st_df), tags$th))),
      tags$tbody(lapply(seq_len(nrow(st_df)), function(i) {
        tags$tr(lapply(st_df[i, , drop = FALSE], function(cell) tags$td(HTML(as.character(cell)))))
      }))
    )
    
    tagList(
      # tags$h4(tags$strong("3. Stationarity assessment (ADF, KPSS, and Phillips–Perron)")),
      # tags$p("Stationarity tests were applied to the training series to evaluate whether differencing is required before SARIMA identification and estimation."),
      html_tbl,
      tags$p(tags$b("Conclusion. "), conclusion)
    )
  })
  
  
  # ---- helper used by multiple outputs (define ONCE) ----
  apply_sarima_diffs_report <- function(y, d = 0L, D = 0L, s = 1L) {
    y <- as.numeric(y)
    y <- y[is.finite(y)]
    if (length(y) < 3) return(y)
    
    d <- as.integer(d); if (!is.finite(d) || d < 0) d <- 0L
    D <- as.integer(D); if (!is.finite(D) || D < 0) D <- 0L
    s <- as.integer(s); if (!is.finite(s) || s < 1) s <- 1L
    
    yy <- y
    
    if (D > 0 && s > 1) {
      for (i in seq_len(D)) {
        if (length(yy) <= s + 1) break
        yy <- diff(yy, lag = s)
      }
    }
    if (d > 0) {
      for (i in seq_len(d)) {
        if (length(yy) <= 2) break
        yy <- diff(yy, lag = 1)
      }
    }
    yy
  }
  
  
  # ---- B) Transformed training series vs differenced (d,D,s) ----
  output$manual_report_ts_trans_and_diff <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    df <- s_obj$dfm
    validate(need(nrow(df) >= 5, "Not enough observations to plot."))
    
    train_n <- s_obj$train_n
    has_test <- isTRUE(s_obj$test_n > 0)
    df_train <- if (has_test) df[seq_len(train_n), , drop = FALSE] else df
    
    validate(need(nrow(df_train) >= 5, "Not enough training observations to plot."))
    
    x_train <- df_train$x
    y_train <- df_train$y_trans
    
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y_train, d = input$d, D = input$D, s = s_use)
    validate(need(length(y_mod) >= 3, "Differencing left too few observations to plot."))
    
    x_mod <- tail(x_train, length(y_mod))
    
    plot_df <- rbind(
      data.frame(x = x_train, y = y_train, series = "Transformed (train)"),
      data.frame(x = x_mod,   y = y_mod,   series = paste0("Differenced (d=", input$d, ", D=", input$D, ", s=", s_use, ")"))
    )
    
    g <- ggplot(plot_df, aes(x = x, y = y, color = series)) +
      geom_line(linewidth = 0.9) +
      theme_minimal() +
      labs(
        title = "Training series: transformed vs differenced",
        x = p$x_label,
        y = "Value",
        color = NULL
      ) +
      theme(legend.position = "bottom")
    
    if (inherits(plot_df$x, "Date")) {
      g <- g + scale_x_date(labels = scales::date_format("%Y-%m"),
                            breaks = scales::pretty_breaks(n = 8))
    } else if (inherits(plot_df$x, "POSIXt")) {
      g <- g + scale_x_datetime(labels = scales::date_format("%Y-%m"),
                                breaks = scales::pretty_breaks(n = 8))
    }
    
    g
  })
  
  
  # ---- C) Seasonal subseries (full observed) ----
  # output$manual_report_subseries <- renderPlot({
  #   req(manual_conclusion_full_obj())
  #   req(ts_train_test())
  #   
  #   s_obj <- ts_train_test()
  #   
  #   x_full <- ts(
  #     c(as.numeric(s_obj$ts_train),
  #       if (!is.null(s_obj$ts_test) && length(s_obj$ts_test) > 0) as.numeric(s_obj$ts_test) else numeric(0)),
  #     start = 1,
  #     frequency = frequency(s_obj$ts_train)
  #   )
  #   
  #   validate(need(frequency(x_full) >= 2, "Seasonal subseries plot requires seasonal frequency (s) >= 2."))
  #   validate(need(length(x_full) >= 2 * frequency(x_full), "Need at least 2 seasonal cycles for a subseries plot."))
  #   
  #   forecast::ggsubseriesplot(x_full) +
  #     theme_minimal() +
  #     labs(title = "Seasonal subseries (observed series)", x = "Seasonal period", y = "Value")
  # })
  
  
  # ---- D) Seasonal box-plot (full observed) ----
  # output$manual_report_seasonal_box <- renderPlot({
  #   req(manual_conclusion_full_obj())
  #   req(ts_train_test())
  #   
  #   s_obj <- ts_train_test()
  #   
  #   x_full <- ts(
  #     c(as.numeric(s_obj$ts_train),
  #       if (!is.null(s_obj$ts_test) && length(s_obj$ts_test) > 0) as.numeric(s_obj$ts_test) else numeric(0)),
  #     start = 1,
  #     frequency = frequency(s_obj$ts_train)
  #   )
  #   
  #   validate(need(frequency(x_full) >= 2, "Seasonal box-plot requires seasonal frequency (s) >= 2."))
  #   validate(need(length(x_full) >= frequency(x_full), "Need at least 1 seasonal cycle for a box-plot."))
  #   
  #   df <- data.frame(
  #     value  = as.numeric(x_full),
  #     season = factor(cycle(x_full), ordered = TRUE)
  #   )
  #   df <- df[is.finite(df$value), , drop = FALSE]
  #   validate(need(nrow(df) >= 5, "Not enough valid observations for seasonal box-plot."))
  #   
  #   ggplot(df, aes(x = season, y = value)) +
  #     geom_boxplot(fill = "#2C7FB8", alpha = 0.45, outlier.alpha = 0.4) +
  #     theme_minimal() +
  #     labs(title = "Seasonal box-plot (observed series)", x = "Seasonal period", y = "Value")
  # })
  
  
  # ---- C) Seasonal subseries (TRAINING ONLY) ----
  output$manual_report_subseries <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    s_obj <- ts_train_test()
    
    x_train <- s_obj$ts_train
    validate(need(inherits(x_train, "ts"), "Training series is not a 'ts' object."))
    validate(need(stats::frequency(x_train) >= 2, "Seasonal subseries plot requires seasonal frequency (s) >= 2."))
    validate(need(length(x_train) >= 2 * stats::frequency(x_train),
                  "Need at least 2 seasonal cycles in the TRAINING set for a subseries plot."))
    
    forecast::ggsubseriesplot(x_train) +
      theme_minimal() +
      labs(title = "Seasonal subseries (training series)", x = "Seasonal period", y = "Value")
  })
  
  
  # ---- D) Seasonal box-plot (TRAINING ONLY) ----
  output$manual_report_seasonal_box <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    s_obj <- ts_train_test()
    
    x_train <- s_obj$ts_train
    validate(need(inherits(x_train, "ts"), "Training series is not a 'ts' object."))
    validate(need(stats::frequency(x_train) >= 2, "Seasonal box-plot requires seasonal frequency (s) >= 2."))
    validate(need(length(x_train) >= stats::frequency(x_train),
                  "Need at least 1 seasonal cycle in the TRAINING set for a box-plot."))
    
    df <- data.frame(
      value  = as.numeric(x_train),
      season = factor(stats::cycle(x_train), ordered = TRUE)
    )
    df <- df[is.finite(df$value), , drop = FALSE]
    validate(need(nrow(df) >= 5, "Not enough valid training observations for seasonal box-plot."))
    
    ggplot(df, aes(x = season, y = value)) +
      geom_boxplot(fill = "#2C7FB8", alpha = 0.45, outlier.alpha = 0.4) +
      theme_minimal() +
      labs(title = "Seasonal box-plot (training series)", x = "Seasonal period", y = "Value")
  })
  
  
  # ---- E) ACF / PACF of training series ----
  output$manual_report_acf <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    x <- ts_train_test()$ts_train
    validate(need(length(x) >= 5, "Not enough training observations for ACF."))
    
    forecast::ggAcf(x, lag.max = min(60, length(x) - 1)) +
      theme_minimal() +
      labs(title = "ACF (training)")
  })
  
  output$manual_report_pacf <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    x <- ts_train_test()$ts_train
    validate(need(length(x) >= 5, "Not enough training observations for PACF."))
    
    forecast::ggPacf(x, lag.max = min(60, length(x) - 1)) +
      theme_minimal() +
      labs(title = "PACF (training)")
  })
  
  
  # ---- F) ACF / PACF of differenced series ----
  output$manual_report_acf_mod <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    y <- as.numeric(s_obj$ts_train)
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    
    validate(need(length(y_mod) >= 5, "Differencing left too few observations for ACF."))
    
    ts_mod <- ts(y_mod, frequency = p$freq)
    
    forecast::ggAcf(ts_mod, lag.max = min(60, length(ts_mod) - 1)) +
      theme_minimal() +
      labs(title = paste0("ACF (d=", input$d, ", D=", input$D, ", s=", s_use, ")"))
  })
  
  output$manual_report_pacf_mod <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    y <- as.numeric(s_obj$ts_train)
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    
    validate(need(length(y_mod) >= 5, "Differencing left too few observations for PACF."))
    
    ts_mod <- ts(y_mod, frequency = p$freq)
    
    forecast::ggPacf(ts_mod, lag.max = min(60, length(ts_mod) - 1)) +
      theme_minimal() +
      labs(title = paste0("PACF (d=", input$d, ", D=", input$D, ", s=", s_use, ")"))
  })
  
  
  
  # ---- NEW: Stationarity tests on differenced/transformed series (d, D, s) ----
  output$manual_report_stationarity_mod <- renderUI({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    validate(need(requireNamespace("tseries", quietly = TRUE),
                  "Package 'tseries' is required for stationarity tests (ADF/PP/KPSS)."))
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    # training series
    y <- as.numeric(s_obj$ts_train)
    y <- y[is.finite(y)]
    
    # apply differencing implied by current d, D, s
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    y_mod <- as.numeric(y_mod)
    y_mod <- y_mod[is.finite(y_mod)]
    
    validate(need(length(y_mod) >= 10,
                  "Not enough observations after differencing (d, D, s) to run stationarity tests (need ≥ 10)."))
    
    fmt_num <- function(z, d = 3) {
      z <- suppressWarnings(as.numeric(z))
      if (length(z) == 0 || !is.finite(z[1])) return("NA")
      formatC(z[1], format = "f", digits = d)
    }
    fmt_p <- function(pv) {
      pv <- suppressWarnings(as.numeric(pv))
      if (length(pv) == 0 || !is.finite(pv[1])) return("NA")
      if (pv[1] < .001) "p < .001" else paste0("p = ", sub("^0\\.", ".", sprintf("%.3f", pv[1])))
    }
    
    # safe lag choice for ADF (based on effective sample)
    k_adf <- max(0, min(12, floor((length(y_mod) - 1)^(1/3))))
    
    adf <- tryCatch(tseries::adf.test(y_mod, k = k_adf), error = function(e) NULL)
    pp  <- tryCatch(tseries::pp.test(y_mod, lshort = TRUE), error = function(e) NULL)
    kpss_level <- tryCatch(tseries::kpss.test(y_mod, null = "Level", lshort = TRUE), error = function(e) NULL)
    kpss_trend <- tryCatch(tseries::kpss.test(y_mod, null = "Trend", lshort = TRUE), error = function(e) NULL)
    
    rows <- list()
    add_row <- function(test, null_h, stat, pval, decision) {
      rows[[length(rows) + 1L]] <<- data.frame(
        Test = test,
        `H0 (null)` = null_h,
        Statistic = stat,
        `p-value` = pval,
        Decision = decision,
        check.names = FALSE
      )
    }
    
    # ADF
    if (!is.null(adf)) {
      pv <- adf$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 → evidence for stationarity"
      else "Fail to reject H0 → unit root plausible"
      add_row("ADF (Augmented Dickey–Fuller)", "Unit root (non-stationary)",
              fmt_num(unname(adf$statistic)), fmt_p(pv), dec)
    } else {
      add_row("ADF (Augmented Dickey–Fuller)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # PP
    if (!is.null(pp)) {
      pv <- pp$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 → evidence for stationarity"
      else "Fail to reject H0 → unit root plausible"
      add_row("PP (Phillips–Perron)", "Unit root (non-stationary)",
              fmt_num(unname(pp$statistic)), fmt_p(pv), dec)
    } else {
      add_row("PP (Phillips–Perron)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # KPSS Level
    if (!is.null(kpss_level)) {
      pv <- kpss_level$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 → evidence against stationarity"
      else "Fail to reject H0 → stationarity plausible"
      add_row("KPSS (Level)", "Level-stationary",
              fmt_num(unname(kpss_level$statistic)), fmt_p(pv), dec)
    } else {
      add_row("KPSS (Level)", "Level-stationary", "NA", "NA", "Not available")
    }
    
    # KPSS Trend
    if (!is.null(kpss_trend)) {
      pv <- kpss_trend$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 → evidence against trend-stationarity"
      else "Fail to reject H0 → trend-stationarity plausible"
      add_row("KPSS (Trend)", "Trend-stationary",
              fmt_num(unname(kpss_trend$statistic)), fmt_p(pv), dec)
    } else {
      add_row("KPSS (Trend)", "Trend-stationary", "NA", "NA", "Not available")
    }
    
    st_df <- do.call(rbind, rows)
    
    # synthesis
    adf_p <- if (!is.null(adf)) adf$p.value else NA_real_
    pp_p  <- if (!is.null(pp))  pp$p.value  else NA_real_
    kL_p  <- if (!is.null(kpss_level)) kpss_level$p.value else NA_real_
    
    unit_root_rejected <- any(c(adf_p, pp_p) < 0.05, na.rm = TRUE)
    kpss_ok <- is.finite(kL_p) && kL_p >= 0.05
    
    conclusion <- if (unit_root_rejected && kpss_ok) {
      paste0(
        "After applying differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), ",
        "ADF/PP reject the unit-root null (p < .05) while KPSS(Level) does not reject stationarity (p ≥ .05). ",
        "This pattern is consistent with a stationary series after differencing."
      )
    } else if (!unit_root_rejected && !kpss_ok) {
      paste0(
        "After differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), ",
        "ADF/PP do not reject a unit root (p ≥ .05) and KPSS(Level) rejects stationarity (p < .05). ",
        "This suggests the series may still be non-stationary (consider revising d/D or checking breaks/seasonality)."
      )
    } else if (unit_root_rejected && !kpss_ok) {
      paste0(
        "After differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), evidence is mixed: ",
        "ADF/PP suggest stationarity but KPSS(Level) rejects it. This can happen with breaks, strong seasonal effects, ",
        "or finite-sample sensitivity; complement with diagnostics/visual checks."
      )
    } else {
      paste0(
        "After differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), evidence is inconclusive: ",
        "ADF/PP do not reject a unit root while KPSS(Level) does not reject stationarity. ",
        "Use ACF/PACF of the differenced series and consider alternative lag choices or structural breaks."
      )
    }
    
    html_tbl <- tags$table(
      class = "table table-striped table-condensed",
      tags$thead(tags$tr(lapply(names(st_df), tags$th))),
      tags$tbody(lapply(seq_len(nrow(st_df)), function(i) {
        tags$tr(lapply(st_df[i, , drop = FALSE], function(cell) tags$td(HTML(as.character(cell)))))
      }))
    )
    
    tagList(
      tags$h4(tags$strong(paste0(
        "Stationarity assessment after differencing (d=", input$d,
        ", D=", input$D, ", s=", s_use, ")"
      ))),
      tags$p("The same stationarity tests were re-applied to the training series after applying the current differencing settings to verify that the working series is stationary."),
      tags$br(),
      html_tbl,
      tags$p(tags$b("Conclusion. "), conclusion)
    )
  })
  
  
  
  
  
  # ------------------------------------------------------------
  # (B) manual_conclusion_full_obj (eventReactive) — UI builder ONLY
  # ------------------------------------------------------------
  manual_conclusion_full_obj <- eventReactive(input$fit_manual, {
    req(manual_fit(), manual_fc(), manual_equations(), ts_train_test())
    
    fit <- manual_fit()
    fc0 <- manual_fc()
    fc  <- fc0$fc
    eq  <- manual_equations()
    s   <- ts_train_test()
    
    # ---------- helpers (local + safe)
    `%||%` <- function(x, y) {
      if (is.null(x) || length(x) == 0 || all(is.na(x))) y else x
    }
    
    fmt_num_local <- function(x, d = 3) {
      if (length(x) == 0 || all(is.na(x))) return("NA")
      x <- suppressWarnings(as.numeric(x[1]))
      if (!is.finite(x)) return("NA")
      formatC(x, format = "f", digits = d)
    }
    fmt_p_local <- function(p) {
      if (length(p) == 0 || all(is.na(p))) return("NA")
      p <- suppressWarnings(as.numeric(p[1]))
      if (!is.finite(p)) return("NA")
      if (p < .001) "&lt; .001" else sprintf("= %.3f", p)
    }
    sig_stars <- function(p) {
      p <- suppressWarnings(as.numeric(p))
      if (!is.finite(p)) return("")
      if (p < .001) "***" else if (p < .01) "**" else if (p < .05) "*" else if (p < .10) "†" else ""
    }
    safe_len <- function(x) if (is.null(x)) 0L else length(x)
    
    html_table <- function(df) {
      if (is.null(df) || !is.data.frame(df) || nrow(df) == 0) {
        return(tags$em("Table unavailable."))
      }
      tags$table(
        class = "table table-striped table-condensed",
        tags$thead(tags$tr(lapply(names(df), function(nm) tags$th(nm)))),
        tags$tbody(
          lapply(seq_len(nrow(df)), function(i) {
            tags$tr(lapply(df[i, , drop = FALSE], function(cell) tags$td(HTML(as.character(cell)))))
          })
        )
      )
    }
    
    # ---------- sample sizes (safe)
    n_train <- suppressWarnings(as.integer(s$train_n))
    if (!is.finite(n_train) || n_train < 1) n_train <- tryCatch(length(residuals(fit)), error = function(e) 0L)
    
    n_test <- suppressWarnings(as.integer(s$test_n))
    if (!is.finite(n_test) || n_test < 0) n_test <- 0L
    
    N <- n_train + n_test
    
    # ---------- lag choice (safe)
    L_in <- suppressWarnings(as.integer(input$diag_lag))
    L <- if (is.finite(L_in) && L_in > 0) L_in else 12L
    
    # ============================================================
    # ---------- IC (safe + robust AICc fallback)
    # ============================================================
    AIC_val <- suppressWarnings(tryCatch(as.numeric(stats::AIC(fit)), error = function(e) NA_real_))
    BIC_val <- suppressWarnings(tryCatch(as.numeric(stats::BIC(fit)), error = function(e) NA_real_))
    
    AICc_val <- suppressWarnings(tryCatch(as.numeric(forecast::AICc(fit)), error = function(e) NA_real_))
    
    if (!is.finite(AICc_val) && is.finite(AIC_val)) {
      n_fit <- suppressWarnings(tryCatch(stats::nobs(fit), error = function(e) NA_integer_))
      if (!is.finite(n_fit) || n_fit <= 0) {
        r <- suppressWarnings(tryCatch(as.numeric(residuals(fit)), error = function(e) numeric(0)))
        n_fit <- sum(is.finite(r))
      }
      if (!is.finite(n_fit) || n_fit <= 0) n_fit <- n_train
      
      k <- suppressWarnings(tryCatch(length(stats::coef(fit)), error = function(e) NA_integer_))
      if (!is.finite(k) || k < 0) k <- 0L
      k <- k + 1L
      
      if (is.finite(n_fit) && n_fit > (k + 1)) {
        AICc_val <- AIC_val + (2 * k * (k + 1)) / (n_fit - k - 1)
      } else {
        AICc_val <- NA_real_
      }
    }
    
    ic_df <- data.frame(
      Criterion = c("AIC", "AICc", "BIC"),
      Value     = c(fmt_num_local(AIC_val, 2), fmt_num_local(AICc_val, 2), fmt_num_local(BIC_val, 2)),
      check.names = FALSE
    )
    
    # ---------- coefficients + significance (robust)
    est <- suppressWarnings(tryCatch(stats::coef(fit), error = function(e) NULL))
    V   <- suppressWarnings(tryCatch(stats::vcov(fit), error = function(e) NULL))
    if (is.null(V)) V <- suppressWarnings(tryCatch(fit$var.coef, error = function(e) NULL))
    
    coef_df <- NULL
    if (!is.null(est) && length(est) > 0) {
      est <- as.numeric(est)
      nm  <- names(stats::coef(fit))
      if (is.null(nm)) nm <- paste0("param_", seq_along(est))
      
      se <- rep(NA_real_, length(est))
      if (!is.null(V)) {
        dV <- tryCatch(diag(V), error = function(e) rep(NA_real_, length(est)))
        if (length(dV) == length(est)) se <- sqrt(pmax(dV, 0))
      }
      z  <- est / se
      p  <- 2 * stats::pnorm(-abs(z))
      
      coef_df <- data.frame(
        Term     = nm,
        Estimate = sprintf("%.6f", est),
        SE       = ifelse(is.finite(se), sprintf("%.6f", se), "NA"),
        `z/t`    = ifelse(is.finite(z),  sprintf("%.3f",  z),  "NA"),
        `p`      = ifelse(is.finite(p),  sprintf("%.3f",  p),  "NA"),
        Sig      = vapply(p, sig_stars, character(1)),
        check.names = FALSE
      )
    }
    
    n_sig <- if (!is.null(coef_df)) sum(suppressWarnings(as.numeric(coef_df$p)) < 0.05, na.rm = TRUE) else 0L
    
    # ---------- residuals (safe)
    res <- suppressWarnings(tryCatch(as.numeric(residuals(fit)), error = function(e) numeric(0)))
    res <- res[is.finite(res)]
    n_res <- length(res)
    
    fitdf <- if (!is.null(est)) length(est) else 0L
    
    lb_lag <- min(L, max(1L, floor(n_res / 3)))
    lb <- if (n_res >= 5) {
      tryCatch(stats::Box.test(res, lag = lb_lag, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
    } else NULL
    
    bp <- if (n_res >= 5) {
      tryCatch(stats::Box.test(res, lag = lb_lag, type = "Box-Pierce", fitdf = fitdf), error = function(e) NULL)
    } else NULL
    
    jb <- if (requireNamespace("tseries", quietly = TRUE) && n_res >= 5) {
      tryCatch(tseries::jarque.bera.test(res), error = function(e) NULL)
    } else NULL
    
    sw <- if (n_res >= 3 && n_res <= 5000) {
      tryCatch(stats::shapiro.test(res), error = function(e) NULL)
    } else NULL
    
    arch <- if (requireNamespace("FinTS", quietly = TRUE) && n_res >= 10) {
      tryCatch(FinTS::ArchTest(res, lags = min(12L, max(1L, floor(L / 2)))), error = function(e) NULL)
    } else NULL
    
    runs <- if (requireNamespace("tseries", quietly = TRUE) && n_res >= 10) {
      tryCatch(tseries::runs.test(res), error = function(e) NULL)
    } else NULL
    
    ad <- if (requireNamespace("nortest", quietly = TRUE) && n_res >= 8) {
      tryCatch(nortest::ad.test(res), error = function(e) NULL)
    } else NULL
    
    test_rows <- list()
    add_test <- function(name, stat, pval, note = "") {
      test_rows[[length(test_rows) + 1L]] <<- data.frame(
        Test = name,
        Statistic = if (is.null(stat)) "NA" else fmt_num_local(stat, 3),
        `p-value` = if (is.null(pval)) "NA" else fmt_p_local(pval),
        Interpretation = note,
        check.names = FALSE
      )
    }
    
    add_test(
      "Ljung–Box (residuals)",
      if (!is.null(lb)) unname(lb$statistic) else NULL,
      if (!is.null(lb)) unname(lb$p.value) else NULL,
      if (!is.null(lb)) {
        if (is.finite(lb$p.value) && lb$p.value >= 0.05) "No evidence of remaining autocorrelation (white-noise compatible)."
        else "Evidence of remaining autocorrelation (model may be under-specified)."
      } else "Not available."
    )
    
    add_test(
      "Box–Pierce (residuals)",
      if (!is.null(bp)) unname(bp$statistic) else NULL,
      if (!is.null(bp)) unname(bp$p.value) else NULL,
      if (!is.null(bp)) {
        if (is.finite(bp$p.value) && bp$p.value >= 0.05) "Consistent with uncorrelated residuals."
        else "Suggests residual autocorrelation."
      } else "Not available."
    )
    
    add_test(
      "Jarque–Bera (normality)",
      if (!is.null(jb)) unname(jb$statistic) else NULL,
      if (!is.null(jb)) unname(jb$p.value) else NULL,
      if (!is.null(jb)) {
        if (is.finite(jb$p.value) && jb$p.value >= 0.05) "No evidence against normality."
        else "Residuals deviate from normality (common in real series)."
      } else "Package 'tseries' missing or test unavailable."
    )
    
    add_test(
      "Shapiro–Wilk (normality)",
      if (!is.null(sw)) unname(sw$statistic) else NULL,
      if (!is.null(sw)) unname(sw$p.value) else NULL,
      if (!is.null(sw)) {
        if (is.finite(sw$p.value) && sw$p.value >= 0.05) "No evidence against normality."
        else "Evidence against normality."
      } else if (n_res > 5000) "Not computed (n > 5000)." else "Not available."
    )
    
    add_test(
      "ARCH LM (heteroskedasticity)",
      if (!is.null(arch)) unname(arch$statistic) else NULL,
      if (!is.null(arch)) unname(arch$p.value) else NULL,
      if (!is.null(arch)) {
        if (is.finite(arch$p.value) && arch$p.value >= 0.05) "No evidence of remaining ARCH effects."
        else "Evidence of ARCH effects → consider GARCH for variance."
      } else "Package 'FinTS' missing or test unavailable."
    )
    
    add_test(
      "Runs test (randomness)",
      if (!is.null(runs)) unname(runs$statistic) else NULL,
      if (!is.null(runs)) unname(runs$p.value) else NULL,
      if (!is.null(runs)) {
        if (is.finite(runs$p.value) && runs$p.value >= 0.05) "No evidence against randomness."
        else "Evidence of non-randomness (structure may remain)."
      } else "Package 'tseries' missing or test unavailable."
    )
    
    add_test(
      "Anderson–Darling (normality)",
      if (!is.null(ad)) unname(ad$statistic) else NULL,
      if (!is.null(ad)) unname(ad$p.value) else NULL,
      if (!is.null(ad)) {
        if (is.finite(ad$p.value) && ad$p.value >= 0.05) "No evidence against normality."
        else "Evidence against normality (sensitive in tails)."
      } else "Package 'nortest' missing or test unavailable."
    )
    
    tests_df <- if (length(test_rows)) do.call(rbind, test_rows) else data.frame()
    
    # ---------- forecast accuracy (safe)  [NOTE: this is on the model scale]
    acc_df <- NULL
    acc_sentence <- "No holdout test set was detected; therefore, out-of-sample accuracy was not computed."
    
    y_test <- s$ts_test
    has_test <- !is.null(y_test) && safe_len(y_test) > 0 && n_test > 0
    
    if (has_test) {
      y_test_num <- as.numeric(y_test)
      y_hat_num  <- suppressWarnings(tryCatch(as.numeric(fc$mean), error = function(e) rep(NA_real_, length(y_test_num))))
      h <- min(length(y_test_num), length(y_hat_num))
      if (h >= 1) {
        e <- y_test_num[seq_len(h)] - y_hat_num[seq_len(h)]
        rmse <- sqrt(mean(e^2, na.rm = TRUE))
        mae  <- mean(abs(e), na.rm = TRUE)
        mape <- mean(abs(e) / pmax(abs(y_test_num[seq_len(h)]), .Machine$double.eps), na.rm = TRUE)
        
        acc_df <- data.frame(
          Metric = c("RMSE", "MAE", "MAPE"),
          Value  = c(fmt_num_local(rmse, 3), fmt_num_local(mae, 3), paste0(fmt_num_local(100*mape, 2), "%")),
          check.names = FALSE
        )
        
        acc_sentence <- paste0(
          "Over the holdout period (test n = ", h, "), forecast performance was ",
          "RMSE = ", fmt_num_local(rmse, 3), ", ",
          "MAE = ", fmt_num_local(mae, 3), ", ",
          "MAPE = ", fmt_num_local(100*mape, 2), "%."
        )
      }
    }
    
    # ---------- horizon narrative
    horizon_txt <- if (has_test) {
      paste0("Validation mode was used: the forecast horizon was forced to match the test length (h = ", n_test, ").")
    } else {
      paste0("Future mode was used: forecasts were produced beyond the training sample (h = ", fc0$h, ").")
    }
    
    # ---------- model string
    season_txt <- suppressWarnings(as.integer(eq$s))
    s_txt <- if (is.finite(season_txt) && season_txt > 0) as.character(season_txt) else "s"
    
    model_str <- sprintf(
      "SARIMA(%d,%d,%d)(%d,%d,%d)[%s]",
      eq$p, eq$d, eq$q, eq$P, eq$D, eq$Q, s_txt
    )
    
    # ---------- diagnostic verdict
    lb_ok <- !is.null(lb) && is.finite(lb$p.value) && lb$p.value >= 0.05
    arch_ok <- is.null(arch) || (is.finite(arch$p.value) && arch$p.value >= 0.05)
    diag_verdict <- paste0(
      if (lb_ok) "Residual autocorrelation was not statistically detected (Ljung–Box p ≥ .05). "
      else "Residual autocorrelation may remain (Ljung–Box p < .05). ",
      if (arch_ok) "No clear evidence of residual ARCH effects was found (or test unavailable)."
      else "Residual ARCH effects were detected → a GARCH extension is recommended."
    )
    
    # ============================================================
    # ---------- Inverse transform equation + bias-adjusted back-forecasts
    # ============================================================
    tr_global <- input$transform %||% "none"
    
    # lambda consistent with your transform step:
    # apply_transform() uses forecast::BoxCox.lambda(y, lower=0) when input$lambda is NA
    lambda_used <- NA_real_
    if (identical(tr_global, "boxcox")) {
      p_obj <- tryCatch(prepared(), error = function(e) NULL)
      lam_in <- input$lambda
      if (is.null(lam_in) || (length(lam_in) == 1 && is.na(lam_in))) {
        lambda_used <- tryCatch(
          forecast::BoxCox.lambda(p_obj$df$y_filled, lower = 0),
          error = function(e) NA_real_
        )
      } else {
        lambda_used <- suppressWarnings(as.numeric(lam_in))
      }
    }
    
    # Forecasts are on TRANSFORMED scale:
    mu_t <- suppressWarnings(as.numeric(fc$mean))
    
    # se can be NULL / missing; handle safely
    se_t <- tryCatch(as.numeric(fc$se), error = function(e) rep(NA_real_, length(mu_t)))
    if (length(se_t) != length(mu_t)) se_t <- rep(NA_real_, length(mu_t))
    var_t <- se_t^2  # forecast variance on transformed scale (when available)
    
    lo_t <- tryCatch(fc$lower, error = function(e) NULL)
    hi_t <- tryCatch(fc$upper, error = function(e) NULL)
    lvl_names <- tryCatch(colnames(fc$lower), error = function(e) NULL)
    
    inv_equation_html <- NULL
    inv_note_html <- NULL
    
    inv_mean <- mu_t
    inv_lo   <- lo_t
    inv_hi   <- hi_t
    
    tex_or_plain <- function(tex, plain) {
      if (exists("tex_display", mode = "function")) HTML(tex_display(tex)) else HTML(plain)
    }
    
    if (identical(tr_global, "log")) {
      
      # Always-available back-transform (median)
      inv_mean <- exp(mu_t)
      
      # Bias-adjusted mean where variance is available
      ok <- is.finite(var_t)
      inv_mean[ok] <- exp(mu_t[ok] + 0.5 * var_t[ok])
      
      # Interval bounds: back-transform quantiles
      if (!is.null(lo_t) && !is.null(hi_t)) {
        inv_lo <- exp(lo_t)
        inv_hi <- exp(hi_t)
      }
      
      inv_equation_html <- tex_or_plain(
        "y = \\exp(z) \\quad \\text{where } z = \\ln(y)",
        "y = exp(z), where z = log(y)"
      )
      inv_note_html <- HTML(
        "<span style='font-size:12px;color:#444;'>
        Point forecasts use <b>exp(μ + 0.5·σ²)</b> when σ² is available; otherwise they fall back to <b>exp(μ)</b>.
        Interval bounds are back-transformed using <b>exp()</b>.
      </span>"
      )
      
    } else if (identical(tr_global, "boxcox")) {
      
      validate(need(is.finite(lambda_used), "Box–Cox lambda is missing/invalid; cannot compute inverse forecasts."))
      lam <- lambda_used
      
      # Always-available back-transform (median)
      inv_mean <- forecast::InvBoxCox(mu_t, lam)
      
      # Bias-adjusted mean where variance is available
      ok <- is.finite(var_t)
      inv_mean[ok] <- forecast::InvBoxCox(mu_t, lam)                              # forecast::InvBoxCox(mu_t[ok], lam, biasadj = TRUE, var = var_t[ok])
      
      if (!is.null(lo_t) && !is.null(hi_t)) {
        inv_lo <- tryCatch(forecast::InvBoxCox(lo_t, lam), error = function(e) lo_t)
        inv_hi <- tryCatch(forecast::InvBoxCox(hi_t, lam), error = function(e) hi_t)
      }

      
      if (is.finite(lam) && abs(lam) < 1e-6) {
        inv_equation_html <- tex_or_plain(
          "y = \\exp(z) \\quad (\\lambda \\approx 0)",
          "y = exp(z)  (lambda ≈ 0)"
        )
      } else {
        inv_equation_html <- tex_or_plain(
          "y = (\\lambda z + 1)^{1/\\lambda}",
          "y = (lambda*z + 1)^(1/lambda)"
        )
      }
      
      inv_note_html <- HTML(paste0(
        "<span style='font-size:12px;color:#444;'>
        λ used = <b>", if (is.finite(lambda_used)) formatC(lambda_used, digits = 4, format = "f") else "NA", "</b>.
        Point forecasts use <b>InvBoxCox(μ, λ, biasadj=TRUE, var=se²)</b> when se² is available; otherwise they fall back to <b>InvBoxCox(μ, λ)</b>.
        Interval bounds are back-transformed using <b>InvBoxCox()</b>.
      </span>"
      ))
    }
    
    

    # Build an ORIGINAL-SCALE forecast table (bias-adjusted mean + back-transformed intervals)
    fc_orig_df <- data.frame(
      # Horizon = seq_along(inv_mean),
      Horizon = as.integer(seq_along(inv_mean)),
      Mean_original = as.numeric(inv_mean),
      stringsAsFactors = FALSE
    )
    
    if (!is.null(inv_lo) && !is.null(inv_hi) && !is.null(lvl_names)) {
      for (j in seq_along(lvl_names)) {
        lvl <- lvl_names[j]
        fc_orig_df[[paste0("Lo_", lvl)]] <- as.numeric(inv_lo[, j])
        fc_orig_df[[paste0("Hi_", lvl)]] <- as.numeric(inv_hi[, j])
      }
    }
    
    # format numeric columns for HTML display
    fc_orig_df_fmt <- fc_orig_df
    for (nm in names(fc_orig_df_fmt)) {
      if (is.numeric(fc_orig_df_fmt[[nm]])) {
        fc_orig_df_fmt[[nm]] <- ifelse(
          is.finite(fc_orig_df_fmt[[nm]]),
          sprintf("%.6f", fc_orig_df_fmt[[nm]]),
          "NA"
        )
      }
    }
    
    
    fc_orig_df_fmt <- fc_orig_df
    # ✅ force integer display for Horizon
    fc_orig_df_fmt$Horizon <- as.character(as.integer(fc_orig_df_fmt$Horizon))
    
    # format OTHER numeric columns to 6 decimals
    for (nm in setdiff(names(fc_orig_df_fmt), "Horizon")) {
      if (is.numeric(fc_orig_df_fmt[[nm]])) {
        fc_orig_df_fmt[[nm]] <- ifelse(
          is.finite(fc_orig_df_fmt[[nm]]),
          sprintf("%.6f", fc_orig_df_fmt[[nm]]),
          "NA"
        )
      }
    }
    
    # ---------- build report UI (NO output$ definitions here)
    tagList(
      tags$h3("Manual SARIMA: Full academic conclusion (report-ready)"),
      
      # 1. Objective and modelling rationale
      tags$hr(), tags$br(),
      tags$h4(tags$strong("1. Objective and modelling rationale")),
      tags$p(
        "A manually specified seasonal ARIMA (SARIMA) model was estimated to represent linear temporal dependence,",
        " including seasonal structure, and to provide an interpretable baseline for forecasting."
      ),
      
      # 2. Data design and sample split
      tags$hr(), tags$br(),
      tags$h4(tags$strong("2. Data design and sample split")),
      tags$p(HTML(paste0(
        "The analysis used <b>N = ", N, "</b> observations (training <b>n = ", n_train, "</b>",
        if (has_test) paste0(", test <b>n = ", n_test, "</b>") else "",
        ")."
      ))),
      tags$p(tags$b("Forecast design. "), horizon_txt),
      
      # 3. Identification visuals (time series + ACF/PACF)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("3. Identification visuals (time series + ACF/PACF)")),
      tags$p(
        "The plots below summarize the observed series (with the train/test split, if applicable), ",
        "followed by ACF/PACF for the training series and for the differenced series implied by the chosen (d, D, s)."
      ),
      
      tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure A. Time series with split marker")),
      plotOutput("manual_report_ts_plot", height = 360),
      
      # 4. Stationarity assessment (ADF, KPSS, and Phillips–Perron)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("4. Stationarity assessment (ADF, KPSS, and Phillips–Perron)")),
      tags$p("Stationarity tests were applied to the training series to evaluate whether differencing is required before SARIMA identification and estimation."),
      tags$hr(),
      uiOutput("manual_report_stationarity"),
      
      # 5. Transformed series: differencing and seasonality
      tags$hr(), tags$br(),
      tags$h4(tags$strong("5. Transformed series: differencing and seasonality")),
      
      tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure B. Seasonal subseries")),
      plotOutput("manual_report_subseries", height = 360),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure C. Seasonal box-plot")),
      plotOutput("manual_report_seasonal_box", height = 360),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure D. Transformed training series and differenced (d, D, s) series")),
      plotOutput("manual_report_ts_trans_and_diff", height = 360),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure E. ACF and PACF (training series)")),
      fluidRow(
        column(6, plotOutput("manual_report_acf",  height = 280)),
        column(6, plotOutput("manual_report_pacf", height = 280))
      ),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure F. ACF and PACF (modified / differenced series using current d, D, s)")),
      fluidRow(
        column(6, plotOutput("manual_report_acf_mod",  height = 280)),
        column(6, plotOutput("manual_report_pacf_mod", height = 280))
      ),
      
      tags$hr(), tags$br(),
      uiOutput("manual_report_stationarity_mod"),
      
      # 6. Final model specification and fit quality
      tags$hr(), tags$br(),
      tags$h4(tags$strong("6. Final model specification and fit quality")),
      tags$p(HTML(paste0(
        "The final manual specification was <b>", model_str, "</b>",
        if (isTRUE(input$manual_drift)) " including drift/mean." else " without drift/mean.",
        " Model adequacy was assessed using information criteria, coefficient inference, residual diagnostics, and forecast performance."
      ))),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Table A. Goodness-of-fit (information criteria)")),
      html_table(ic_df),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Table B. Parameter estimates and significance (approx. z/t tests)")),
      if (!is.null(coef_df)) html_table(coef_df) else tags$em("No coefficients available."),
      tags$p(HTML(paste0(
        "In total, <b>", n_sig, "</b> parameter(s) were significant at α = .05 (marked by *, **, ***)."
      ))),
      
      # 7. Model equations (replication-ready)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("7. Model equations (replication-ready)")),
      tags$p(
        "The fitted model is reported below in operator notation (general form), expanded form, and the numerical equation",
        " based on the estimated parameters."
      ),
      tags$div(
        style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;",
        
        tags$br(), tags$hr(), tags$hr(),
        tags$h5("General SARIMA formulation"),
        HTML(eq$eq_general),
        
        tags$br(), tags$hr(), tags$hr(),
        tags$h5("Expanded operator form"),
        HTML(eq$eq_expanded),
        
        tags$br(), tags$hr(), tags$hr(),
        tags$h5("Numerical model"),
        HTML(eq$eq_line3),
        
        tags$br(), tags$hr(), tags$hr(),
        HTML(eq$eq_line4),
        
        tags$br(), tags$hr(), tags$hr()
      ),
      
      # 8. Residual diagnostics (graphical evidence)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("8. Residual diagnostics (graphical evidence)")),
      tags$p(
        "Graphical diagnostics evaluate whether residuals resemble white noise (no systematic autocorrelation),",
        " approximate normality (Q–Q and histogram), and stable variance."
      ),
      
      fluidRow(
        column(6, plotOutput("manual_resid_ts",   height = 220)),
        column(6, plotOutput("manual_resid_acf",  height = 220))
      ),
      fluidRow(
        column(6, plotOutput("manual_resid_hist", height = 220)),
        column(6, plotOutput("manual_resid_qq",   height = 220))
      ),
      
      tags$h5("Ljung–Box p-values by lag"),
      plotOutput("manual_resid_lb_pvals", height = 260),
      
      # 9. Residual tests (formal inference)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("9. Residual tests (formal inference)")),
      tags$p(
        "Formal tests complement the plots: Ljung–Box/Box–Pierce assess remaining autocorrelation;",
        " Jarque–Bera/Shapiro–Wilk/Anderson–Darling assess normality;",
        " ARCH LM tests conditional heteroskedasticity; the runs test checks randomness."
      ),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Table C. Residual test summary")),
      html_table(tests_df),
      tags$p(tags$b("Diagnostic synthesis. "), diag_verdict),
      
      # 10. Forecasting results and predictive performance
      tags$hr(), tags$br(),
      tags$h4(tags$strong("10. Forecasting results and predictive performance")),
      tags$p(acc_sentence),
      
      if (!is.null(acc_df)) tagList(
        tags$h5("Table D. Holdout accuracy (test set)"),
        html_table(acc_df)
      ) else NULL,
      
      tags$hr(),  tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Forecast plot")),
      plotOutput("manual_forecast_plot", height = 420),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Forecast table")),
      tableOutput("manual_forecast_table"),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Accuracy table (your app output)")),
      tableOutput("manual_accuracy_table"),
      
      # ---------- Back-transformed forecasts (original scale) + plot placeholder
      tags$hr(), tags$br(),
      tags$h4(tags$strong("10.B Back-transformed forecasts (original scale)")),
      if (!identical(tr_global, "none")) tagList(
        tags$p("Because the model was estimated on the transformed series, forecasts are reported below on the original measurement scale using an appropriate bias adjustment for the point forecasts."),
        tags$div(
          style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;",
          tags$h5("Inverse transform equation (simple form)"),
          inv_equation_html,
          tags$br(),
          inv_note_html
        ),
        
        tags$hr(), tags$br(),
        tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Original-scale plot (observed + forecast + CIs)")),
        # NOTE: you must define output$manual_forecast_plot_original <- renderPlot(...) elsewhere in server
        plotOutput("manual_forecast_plot_original", height = 420),
        
        tags$hr(), tags$br(),
        tags$h5("Back-transformed forecast table (original scale)"),
        html_table(fc_orig_df_fmt)
      ) else tags$em("No transformation was applied; forecasts are already on the original scale."),
      
      # 11. Final conclusion (academic)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("11. Final conclusion")),
      tags$p(
        "Overall, the manually specified SARIMA model provides a coherent and interpretable representation of seasonal linear dynamics,",
        " supported by information criteria, statistically interpretable parameters, and diagnostic checks.",
        " When diagnostics indicate remaining autocorrelation, refinement should prioritize revising differencing (d, D) and AR/MA orders guided by ACF/PACF and Ljung–Box.",
        " When conditional heteroskedasticity is detected (ARCH LM), a volatility model (e.g., GARCH) should be added to the mean equation to better represent time-varying variance."
      ),
      tags$p(
        "For reporting, the results above provide the full chain of evidence typically expected in academic manuscripts:",
        " (i) specification + IC, (ii) parameter inference, (iii) equation reporting, (iv) residual validation with plots and tests, and (v) forecasting with accuracy assessment."
      ),
      
      tags$br(), tags$hr(), tags$br(), tags$br()
    )
  })
  
  
  
  
  
  
  
  
  # IMPORTANT: renderUI wrapper + MathJax re-typeset (this is what makes equations show correctly)
  output$manual_conclusion_full <- renderUI({
    ui <- manual_conclusion_full_obj()
    
    # Re-typeset MathJax after the UI is inserted into the DOM
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "manual_conclusion_box")
    }, once = TRUE)
    
    ui
  })
  
  
  
  
  
  # manual_conclusion_full_obj <- eventReactive(input$fit_manual, {
  #   req(manual_fit(), manual_fc(), manual_equations(), ts_train_test())
  #   
  #   fit <- manual_fit()
  #   fc0 <- manual_fc()
  #   fc  <- fc0$fc
  #   eq  <- manual_equations()
  #   s   <- ts_train_test()
  #   
  #   # ---- safe values
  #   n_train <- suppressWarnings(as.integer(s$train_n)); if (!is.finite(n_train)) n_train <- length(residuals(fit))
  #   n_test  <- suppressWarnings(as.integer(s$test_n));  if (!is.finite(n_test))  n_test  <- 0L
  #   N <- n_train + n_test
  #   
  #   L_in <- suppressWarnings(as.integer(input$diag_lag))
  #   L <- if (is.finite(L_in) && L_in > 0) L_in else 12L
  #   fitdf <- length(coef(fit))
  #   
  #   # ---- IC
  #   AIC_val  <- suppressWarnings(as.numeric(fit$aic))
  #   AICc_val <- suppressWarnings(as.numeric(fit$aicc))
  #   BIC_val  <- suppressWarnings(as.numeric(fit$bic))
  #   
  #   # ---- residual test (minimal)
  #   res <- as.numeric(residuals(fit))
  #   res <- res[is.finite(res)]
  #   lb <- tryCatch(Box.test(res, lag = min(L, max(1L, floor(length(res) / 3))), type = "Ljung-Box", fitdf = fitdf),
  #                  error = function(e) NULL)
  #   
  #   # ---- accuracy
  #   acc_line <- NULL
  #   if (n_test > 0) {
  #     acc <- tryCatch(accuracy_df(s$ts_test, fc$mean), error = function(e) NULL)
  #     if (!is.null(acc) && all(c("Metric", "Value") %in% names(acc))) {
  #       rmse <- acc$Value[acc$Metric == "RMSE"][1]
  #       mae  <- acc$Value[acc$Metric == "MAE"][1]
  #       mape <- acc$Value[acc$Metric == "MAPE"][1]
  #       acc_line <- tags$p(
  #         tags$b("Forecast accuracy (test set). "),
  #         HTML(paste0(
  #           "Over the holdout period (n = ", n_test, "), performance was RMSE = ",
  #           fmt_num(rmse, 3), ", MAE = ", fmt_num(mae, 3),
  #           if (is.finite(mape)) paste0(", MAPE = ", fmt_num(100 * mape, 2), "%") else "",
  #           "."
  #         ))
  #       )
  #     }
  #   }
  #   if (is.null(acc_line)) {
  #     acc_line <- tags$p(tags$b("Forecast accuracy. "),
  #                        "No holdout test set was detected; therefore, out-of-sample accuracy was not computed.")
  #   }
  #   
  #   # ---- horizon narrative
  #   horizon_txt <- if (n_test > 0) {
  #     paste0("Validation mode was used: the forecast horizon was forced to match the test length (h = ", n_test, ").")
  #   } else {
  #     paste0("Future mode was used: forecasts were produced beyond the training sample (h = ", fc0$h, ").")
  #   }
  #   
  #   # ---- model text (manual)
  #   season_txt <- if (is.finite(eq$s)) eq$s else NA_integer_
  #   model_str <- sprintf("SARIMA(%d,%d,%d)(%d,%d,%d)[%s]",
  #                        eq$p, eq$d, eq$q, eq$P, eq$D, eq$Q,
  #                        if (is.finite(season_txt)) as.character(season_txt) else "s")
  #   
  #   tagList(
  #     tags$h3("Manual SARIMA: Full academic conclusion"),
  #     
  #     tags$h4("1. Rationale and modelling objective"),
  #     tags$p(
  #       "A manually specified seasonal ARIMA (SARIMA) model was estimated to provide explicit control over non-seasonal and seasonal dynamics. ",
  #       "This approach is appropriate when domain knowledge and diagnostic patterns (ACF/PACF after differencing) motivate targeted structure beyond automated search."
  #     ),
  #     
  #     tags$h4("2. Sample design"),
  #     tags$p(HTML(paste0(
  #       "The analysis used <b>N = ", N, "</b> observations (training <b>n = ", n_train, "</b>",
  #       if (n_test > 0) paste0(", test <b>n = ", n_test, "</b>") else "",
  #       ")."
  #     ))),
  #     tags$p(tags$b("Forecast design. "), horizon_txt),
  #     
  #     tags$h4("3. Final specification and fit"),
  #     tags$p(HTML(paste0(
  #       "The fitted manual specification was <b>", model_str, "</b>",
  #       if (isTRUE(input$manual_drift)) " with drift/mean." else " without drift/mean.",
  #       " The corresponding fitted object was reported as <b>", as.character(fit), "</b>."
  #     ))),
  #     tags$ul(
  #       tags$li(HTML(paste0("AIC = <b>", fmt_num(AIC_val, 2), "</b>"))),
  #       tags$li(HTML(paste0("AICc = <b>", fmt_num(AICc_val, 2), "</b>"))),
  #       tags$li(HTML(paste0("BIC = <b>", fmt_num(BIC_val, 2), "</b>")))
  #     ),
  #     
  #     tags$h4("4. Model equations (reporting-ready)"),
  #     tags$p(
  #       "For academic reporting and replication, the fitted model is expressed in standard operator notation, followed by an expanded form ",
  #       "and a numerical representation using the estimated coefficients."
  #     ),
  #     tags$div(
  #       style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;text-align:left;",
  #       tags$h5("General SARIMA formulation"),
  #       HTML(eq$eq_general),
  #       tags$hr(),
  #       tags$h5("Expanded operator form"),
  #       HTML(eq$eq_expanded),
  #       tags$hr(),
  #       tags$h5("Numerical model"),
  #       HTML(eq$eq_line3),
  #       tags$hr(),
  #       HTML(eq$eq_line4)
  #     ),
  #     
  #     tags$h4("5. Residual diagnostics (adequacy of linear dynamics)"),
  #     tags$p(
  #       "Adequacy was evaluated using residual plots and formal tests. A key criterion is that residuals resemble white noise, ",
  #       "indicating that the model has captured the systematic linear dependence."
  #     ),
  #     if (!is.null(lb)) {
  #       tags$p(HTML(paste0(
  #         "<b>Ljung–Box test:</b> Q(", lb$parameter, ") = ", fmt_num(lb$statistic, 3),
  #         ", p ", fmt_p(lb$p.value), "."
  #       )))
  #     } else {
  #       tags$p(tags$b("Ljung–Box test:"), " unavailable (insufficient residuals or test error).")
  #     },
  #     
  #     tags$h4("6. Forecasting and predictive performance"),
  #     acc_line,
  #     
  #     tags$h4("7. Overall conclusion and recommended next steps"),
  #     tags$p(
  #       "In sum, the manual SARIMA specification provides an interpretable representation of linear dependence, contingent on residual whiteness. ",
  #       "If residual autocorrelation persists, revise differencing (d, D) or adjust AR/MA orders guided by diagnostics. ",
  #       "If volatility clustering is evident, consider modelling conditional variance (e.g., GARCH) alongside the SARIMA mean equation."
  #     )
  #   )
  # })
  
  output$manual_conclusion_full <- renderUI({
    validate(need(input$fit_manual > 0, "Click “Fit” in the Manual tab to generate the full academic conclusion."))
    req(manual_conclusion_full_obj())
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "manual_conclusion_box")
    }, once = TRUE)
    
    manual_conclusion_full_obj()
  })
  
  
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  
  
  
  
  
  

  # ---- Step 7 Comparison & Paper builder ----

  comparison <- reactive({
    s <- ts_train_test()
    out <- data.frame(Model = character(0), AICc = numeric(0), BIC = numeric(0), Test_RMSE = numeric(0), Test_MAE = numeric(0), stringsAsFactors = FALSE)

    if (!is.null(input$fit_auto)) {
      fit <- tryCatch(auto_fit(), error = function(e) NULL)
      if (!is.null(fit)) {
        rmse <- NA_real_; mae <- NA_real_
        if (s$test_n > 0) {
          acc <- accuracy_df(s$ts_test, auto_fc()$fc$mean)
          rmse <- acc$Value[acc$Metric == "RMSE"]
          mae <- acc$Value[acc$Metric == "MAE"]
        }
        out <- rbind(out, data.frame(Model = "Auto-ARIMA", AICc = fit$aicc, BIC = fit$bic, Test_RMSE = rmse, Test_MAE = mae))
      }
    }

    if (!is.null(input$fit_manual)) {
      fit <- tryCatch(manual_fit(), error = function(e) NULL)
      if (!is.null(fit)) {
        rmse <- NA_real_; mae <- NA_real_
        if (s$test_n > 0) {
          acc <- accuracy_df(s$ts_test, manual_fc()$fc$mean)
          rmse <- acc$Value[acc$Metric == "RMSE"]
          mae <- acc$Value[acc$Metric == "MAE"]
        }
        out <- rbind(out, data.frame(Model = "Manual SARIMA", AICc = fit$aicc, BIC = fit$bic, Test_RMSE = rmse, Test_MAE = mae))
      }
    }
    out
  })

  output$comparison_table <- renderTable({
    df <- comparison()
    if (nrow(df) == 0) return(data.frame(message = "Fit Auto-ARIMA and/or Manual SARIMA to compare models."))
    df
  }, rownames = FALSE)

  output$comparison_interpretation <- renderPrint({
    df <- comparison()
    if (nrow(df) == 0) { cat("Fit models first to generate comparison interpretation.\n"); return() }
    cat("Interpretation guide:\n")
    cat("- Lower AICc/BIC indicates better in-sample trade-off (fit vs complexity).\n")
    cat("- Lower RMSE/MAE indicates better holdout forecast accuracy.\n\n")
    best <- df[order(df$Test_RMSE, df$AICc, na.last = TRUE), , drop = FALSE]
    cat("Top-ranked (by RMSE then AICc):", best$Model[1], "\n")
  })

  output$apa_methods_draft <- renderPrint({
    req(prepared())
    p <- prepared()
    df <- p$df
    n <- nrow(df)
    cat(
      "Methods (APA draft — edit names/unit and add study context):\n\n",
      "Time series analyses were conducted using R. The series consisted of ", n, " observations spanning ",
      format(min(df$date)), " to ", format(max(df$date)), " with a seasonal period of s = ", p$freq, ". ",
      "Missing values were handled using the ", input$missing_policy, " method. ",
      "Stationarity was assessed using the Augmented Dickey–Fuller (ADF), KPSS, and Phillips–Perron tests, and differencing decisions were informed by these tests alongside visual inspection of differenced series plots. ",
      "Seasonal ARIMA models were estimated using maximum likelihood as implemented in the forecast package.\n",
      sep = ""
    )
  })

  output$apa_results_draft <- renderPrint({
    cat(
      "Results (APA draft — refine after you finalize the model):\n\n",
      "Exploratory analysis suggested trend and seasonal dynamics in the series, motivating the evaluation of seasonal ARIMA models. ",
      "Model adequacy was evaluated via residual diagnostics, including the Ljung–Box test for residual autocorrelation and additional normality and heteroskedasticity checks when available. ",
      "Forecast performance was evaluated using holdout accuracy metrics (e.g., RMSE and MAE) when a test set was available. ",
      "The final model specification, diagnostics, and forecast results are reported in the corresponding panels.\n",
      sep = ""
    )
  })

  observeEvent(input$refresh_all, { invisible(NULL) })
  
  
  
  
  
  
  
  
  
  
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  #
  #                          - D?d?log? -
  #
  # ====================================================================
  # ====================================================================
  # ==================================================================== 
  
  
  
  # helper used below (safe defaulting)
  # `%||%` <- function(a, b) if (is.null(a) || is.na(a) || identical(a, "")) b else a
  
  
  # ============================================================================
  # 0) SMALL HELPERS (safe input fallback + safe numeric)
  # ============================================================================
  `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0 && !all(is.na(a))) a else b
  to_num_safe <- function(v, default = NA_real_) {
    out <- suppressWarnings(as.numeric(v))
    if (length(out) == 0 || all(is.na(out)) || !is.finite(out[1])) default else out[1]
  }
  
  getPlotDim <- function(x, default = "100%") {
    if (is.null(x) || is.na(x) || identical(x, "")) return(default)
    if (is.numeric(x)) return(paste0(x, "px"))
    # accept strings like "800" or "100%" or "800px"
    xs <- as.character(x)
    if (grepl("^[0-9]+$", xs)) return(paste0(xs, "px"))
    xs
  }
  
  
  # # ---- helpers.R (or at the top of server.R) ----
  # # Convert numeric -> "Npx"; pass through "100%" or "auto"; provide a default.
  # getPlotDim <- function(x, default = "100%") {
  #   if (is.null(x)) return(default)
  #   if (is.na(x))   return(default)
  #   if (is.numeric(x)) return(paste0(x, "px"))
  #   # if it's already a character like "100%" or "450px", just return it
  #   as.character(x)
  # }
  
  
  # helper: map input$plot_theme -> a ggplot2 theme object
  theme_picker <- function(key = "Minimal") {
    switch(key,
           "Minimal" = ggplot2::theme_minimal(),
           "Classic" = ggplot2::theme_classic(),
           "Light"   = ggplot2::theme_light(),
           "Dark"    = ggplot2::theme_dark(),
           "BW"      = ggplot2::theme_bw(),
           "Void"    = ggplot2::theme_void(),
           # default
           ggplot2::theme_gray()
    )
  }
  
  # common theming applied to ggplot objects
  add_theme <- function(g) {
    g +
      theme_picker(input$plot_theme) +
      ggplot2::theme(
        axis.text  = ggplot2::element_text(size = input$tickSize),
        axis.title = ggplot2::element_text(size = input$tickSize + 2),
        plot.title = ggplot2::element_text(hjust = 0.5)
      )
  }
  
  
  
  
  # Map the log checkbox to a simple flag
  values <- reactiveValues(islog = "No")
  observe({
    values$islog <- if (isTRUE(input$check_box)) "Yes" else "No"
  })
  
  # Core transformation helper (log, then D, then d)
  getMyData <- function(tsData, frequency, islog = "No", d_n = 0, DS_n = 0) {
    shiny::req(tsData)
    freq <- as.numeric(frequency)
    d_n  <- as.numeric(d_n)
    DS_n <- as.numeric(DS_n)
    
    working_ts <- if (identical(islog, "Yes")) log(tsData) else tsData
    
    # Seasonal differencing (D)
    if (!is.na(DS_n) && DS_n > 0 && !is.na(freq) && freq > 1) {
      working_ts <- diff(working_ts, lag = freq, differences = DS_n)
    }
    
    # Non-seasonal differencing (d)
    if (!is.na(d_n) && d_n > 0) {
      working_ts <- diff(working_ts, lag = 1, differences = d_n)
    }
    
    working_ts
  }
  
  # Base ts comes from your prepared() reactive
  # prepared() returns list(df=..., freq=..., by=..., x_label=...)
  # We'll use the filled values (before transform) to let the playground own the transforms
  ts_base <- reactive({
    p <- prepared()                                   # df/freq are defined here
    ts(p$df$y_filled, start = 1, frequency = p$freq)  # build a ts from the cleaned series
  })
  
  # Central reactive used by all (*) panels in this tab
  # ========= replace the whole myData_Choice() reactive with this =========
  myData_Choice <- reactive({
    req(prepared())
    base_ts <- ts_base()                 # full, cleaned & regularly spaced series (y_filled)
    
    # Figure out how many observations belong to the training window
    s <- ts_train_test()                 # has $train_n computed from input$train_prop
    train_n <- s$train_n
    
    # Choose full vs. training window based on the new checkbox
    if (isTRUE(input$use_train_explore) && is.finite(train_n) && train_n >= 2) {
      # keep start and frequency; truncate by index
      base_vec <- as.numeric(base_ts)
      base_vec <- base_vec[seq_len(min(train_n, length(base_vec)))]
      base_ts  <- ts(base_vec, start = start(base_ts), frequency = frequency(base_ts))
    }
    
    # Apply the Exploration controls (log / d / D) consistently to whatever window we chose
    getMyData(
      tsData    = base_ts,
      frequency = frequency(base_ts),
      islog     = values$islog,          # this already mirrors input$check_box via your observeEvent
      d_n       = input$d_n,
      DS_n      = input$DS_n
    )
  })
  
  
  

  # UI wrapper: uses textInput("plot_width"), textInput("plot_height")
  
  output$d_D_Log_ts_Choice_UI <- renderUI({
    plotOutput(
      "d_D_Log_ts_Choice",
      width  = getPlotDim(input$plot_width  %||% "800"),
      height = getPlotDim(input$plot_height %||% "500")
    )
  })
  
  # output$d_D_Log_ts_Choice <- renderPlot({
  #   req(myData_Choice(), prepared())
  #   
  #   ts_obj <- myData_Choice()
  #   p <- prepared()
  #   
  #   # build a date-aware df for the current transformed series
  #   ddf <- df_ts(ts_obj)   # <-- reuse the same df_ts() you already use in tsPlot_Choice
  #   
  #   g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #     ggplot2::geom_line(size = 0.9) +
  #     ggplot2::labs(
  #       title = "Series after d / D / log choices",
  #       x = p$x_label,
  #       y = "Value"
  #     )
  #   
  #   g <- apply_smart_date_axis(g, ddf)  # ✅ fixes the date labels / too many ticks
  #   add_theme(g)
  # })
  
  
  
  # --- ggtsdisplay of the transformed series (time plot + ACF + PACF) ---
  output$d_D_Log_ts_Choice <- renderPlot({
    req(myData_Choice())
    p <- prepared()
    forecast::ggtsdisplay(
      myData_Choice(),
      main = "Diagnostics of transformed series (d/D/log)",
      xlab = p$x_label,
      ylab = "Transformed value"
    )
  }, res = 96)



  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  
  
  
  # map input$plot_theme to a ggplot theme
  theme_picker <- function(key = "Minimal") {
    switch(key,
           "Minimal" = ggplot2::theme_minimal(),
           "Classic" = ggplot2::theme_classic(),
           "Light"   = ggplot2::theme_light(),
           "Dark"    = ggplot2::theme_dark(),
           "BW"      = ggplot2::theme_bw(),
           "Void"    = ggplot2::theme_void(),
           ggplot2::theme_gray()  # default "Gray"
    )
  }
  
  # apply selected theme + common text sizes
  add_theme <- function(g) {
    g +
      theme_picker(input$plot_theme) +
      ggplot2::theme(
        axis.text  = ggplot2::element_text(size = input$tickSize),
        axis.title = ggplot2::element_text(size = input$tickSize + 2),
        plot.title = ggplot2::element_text(hjust = 0.5)
      )
  }
  
  # ---- UI wrapper so the plot can size dynamically ----
  output$tsPlot_Choice_UI <- renderUI({
    plotOutput(
      "tsPlot_Choice",
      width  = getPlotDim(input$plot_width  %||% "800"),
      height = getPlotDim(input$plot_height %||% "500")
    )
  })
  
  # ---- Color picker UI (already in your sidebar) ----
  output$ts_color_ui <- renderUI({
    tagList(
      tags$input(type = "color", id = "ts_line_color", value = "#2C7FB8"),
      tags$label("Series color", style = "color: #2C7FB8;"),
      br(), br(),
      tags$script(HTML("
      $(document).ready(function() {
        var el = document.getElementById('ts_line_color');
        if (el) Shiny.setInputValue('ts_line_color', el.value);
        $(document).on('input', '#ts_line_color', function() {
          Shiny.setInputValue(this.id, this.value);
        });
      });
    "))
    )
  })
  
  # ---- Plot router for the Plot (*) tab (uses theme) ----
  # output$tsPlot_Choice <- renderPlot({
  #   req(myData_Choice())
  #   req(input$plot_type_choice)
  #   
  #   ts_obj <- myData_Choice()
  #   p      <- prepared()  # for x-axis label
  #   freq   <- tryCatch(stats::frequency(ts_obj), error = function(e) NA_real_)
  #   
  #   df_ts <- function(z) {
  #     if (inherits(z, "ts")) {
  #       data.frame(t = as.numeric(stats::time(z)), y = as.numeric(z))
  #     } else {
  #       data.frame(t = seq_along(z), y = as.numeric(z))
  #     }
  #   }
  #   
  #   k_ma  <- max(2L, as.integer(input$ma_k %||% 5))
  #   lag_m <- max(1L, as.integer(input$lag_m %||% 12))
  #   
  #   plt <- switch(
  #     input$plot_type_choice,
  #     
  #     "Line" = {
  #       forecast::autoplot(
  #         ts_obj,
  #         size   = 1,
  #         colour = input$ts_line_color %||% "#2C7FB8"
  #       ) +
  #         ggplot2::labs(title = "Transformed series", x = p$x_label, y = "Transformed value")
  #     },
  #     
  #     "Points" = {
  #       d <- df_ts(ts_obj)
  #       ggplot2::ggplot(d, ggplot2::aes(t, y)) +
  #         ggplot2::geom_point(size = 1) +
  #         ggplot2::labs(title = "Points", x = p$x_label, y = "Transformed value")
  #     },
  #     
  #     "Line + Points" = {
  #       d <- df_ts(ts_obj)
  #       ggplot2::ggplot(d, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line() +
  #         ggplot2::geom_point(size = 0.9, alpha = 0.8) +
  #         ggplot2::labs(title = "Line + Points", x = p$x_label, y = "Transformed value")
  #     },
  #     
  #     "Smoothed (LOESS)" = {
  #       d <- df_ts(ts_obj)
  #       ggplot2::ggplot(d, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line(alpha = 0.4) +
  #         ggplot2::geom_smooth(method = "loess", se = FALSE, span = 0.2) +
  #         ggplot2::labs(title = "LOESS smooth", x = p$x_label, y = "Transformed value")
  #     },
  #     
  #     "Moving average" = {
  #       d <- df_ts(ts_obj)
  #       ma <- stats::filter(d$y, rep(1/k_ma, k_ma), sides = 2)
  #       d$ma <- as.numeric(ma)
  #       ggplot2::ggplot(d, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line(alpha = 0.4) +
  #         ggplot2::geom_line(ggplot2::aes(y = ma), size = 1) +
  #         ggplot2::labs(title = sprintf("Moving average (k = %d)", k_ma), x = p$x_label, y = "Transformed value")
  #     },
  #     
  #     "Cumulative sum" = {
  #       d <- df_ts(ts_obj); d$cum <- cumsum(d$y)
  #       ggplot2::ggplot(d, ggplot2::aes(t, cum)) +
  #         ggplot2::geom_line() +
  #         ggplot2::labs(title = "Cumulative sum", x = p$x_label, y = "Cumulative value")
  #     },
  #     
  #     "Seasonal plot" = {
  #       validate(need(is.finite(freq) && freq > 1, "Seasonal plot requires frequency > 1."))
  #       forecast::ggseasonplot(ts_obj, year.labels = TRUE) +
  #         ggplot2::labs(title = "Seasonal plot", x = p$x_label, y = "Value")
  #     },
  #     
  #     "Seasonal subseries" = {
  #       validate(need(is.finite(freq) && freq > 1, "Seasonal subseries requires frequency > 1."))
  #       forecast::ggsubseriesplot(ts_obj) +
  #         ggplot2::labs(title = "Seasonal subseries", x = p$x_label, y = "Value")
  #     },
  #     
  #     "Polar seasonal" = {
  #       validate(need(is.finite(freq) && freq > 1, "Polar seasonal requires frequency > 1."))
  #       forecast::ggseasonplot(ts_obj, polar = TRUE) +
  #         ggplot2::labs(title = "Polar seasonal plot", x = p$x_label, y = "Value")
  #     },
  #     
  #     "Seasonal boxplot" = {
  #       validate(need(is.finite(freq) && freq > 1, "Seasonal boxplot requires frequency > 1."))
  #       d <- if (inherits(ts_obj, "ts")) data.frame(season = stats::cycle(ts_obj), y = as.numeric(ts_obj))
  #       else data.frame(season = factor(1), y = as.numeric(ts_obj))
  #       ggplot2::ggplot(d, ggplot2::aes(x = factor(season), y = y)) +
  #         ggplot2::geom_boxplot() +
  #         ggplot2::labs(title = "Seasonal boxplot", x = "Season", y = "Value")
  #     },
  #     
  #     "Classical decomposition (additive)" = {
  #       validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
  #       dc <- stats::decompose(ts_obj, type = "additive")
  #       forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (additive)")
  #     },
  #     
  #     "Classical decomposition (multiplicative)" = {
  #       validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
  #       dc <- stats::decompose(ts_obj, type = "multiplicative")
  #       forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (multiplicative)")
  #     },
  #     
  #     "STL decomposition" = {
  #       validate(need(is.finite(freq) && freq > 1, "STL decomposition requires frequency > 1."))
  #       decomp <- stats::stl(ts_obj, s.window = "periodic")
  #       forecast::autoplot(decomp) + ggplot2::labs(title = "STL decomposition")
  #     },
  #     
  #     "Histogram" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
  #         ggplot2::geom_histogram(bins = 30) +
  #         ggplot2::labs(title = "Histogram", x = "Value", y = "Count")
  #     },
  #     
  #     "Density" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
  #         ggplot2::geom_density() +
  #         ggplot2::labs(title = "Density", x = "Value", y = "Density")
  #     },
  #     
  #     "QQ plot" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(sample = x)) +
  #         ggplot2::stat_qq() +
  #         ggplot2::stat_qq_line() +
  #         ggplot2::labs(title = "Normal Q-Q plot", x = "Theoretical quantiles", y = "Sample quantiles")
  #     },
  #     
  #     "Lag-1 scatter" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       validate(need(length(xx) >= 2, "Not enough data for lag-1 scatter."))
  #       d <- data.frame(x = xx[-length(xx)], y = xx[-1])
  #       ggplot2::ggplot(d, ggplot2::aes(x, y)) +
  #         ggplot2::geom_point() +
  #         ggplot2::geom_smooth(method = "lm", se = FALSE) +
  #         ggplot2::labs(title = "Lag-1 scatter", x = "y(t-1)", y = "y(t)")
  #     },
  #     
  #     "Lag plot (1..m)" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       validate(need(length(xx) > (lag_m + 1), "Increase data or reduce m for lag plots."))
  #       forecast::gglagplot(ts_obj, lags = lag_m) +
  #         ggplot2::labs(title = sprintf("Lag plot (1..%d)", lag_m))
  #     },
  #     
  #     "ACF" = {
  #       forecast::ggAcf(ts_obj) + ggplot2::labs(title = "ACF")
  #     },
  #     
  #     "PACF" = {
  #       forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF")
  #     },
  #     
  # 
  #     # inside your switch(input$plot_type_choice, ...)
  #     "ACF+PACF" = {
  #       # ACF (top) & PACF (bottom)
  #       p_acf  <- forecast::ggAcf(ts_obj)  + ggplot2::labs(title = "ACF")
  #       p_pacf <- forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF")
  #       
  #       # Apply your theme helper
  #       p_acf  <- add_theme(p_acf)
  #       p_pacf <- add_theme(p_pacf)
  #       
  #       # Vertical layout: ACF on top, PACF below
  #       gridExtra::grid.arrange(p_acf, p_pacf, ncol = 1, heights = c(1, 1))
  #     },
  #     
  #   
  # 
  #     # library(gridExtra)
  #     
  #     "Time + ACF+PACF" = {
  #       # Time plot (top)
  #       p_time <- forecast::autoplot(
  #         ts_obj,
  #         size   = 1,
  #         colour = input$ts_line_color %||% "#2C7FB8"
  #       ) +
  #         ggplot2::labs(
  #           title = "Time plot",
  #           x = p$x_label,
  #           y = "Transformed value"
  #         )
  # 
  #       # ACF (bottom-left) & PACF (bottom-right)
  #       p_acf  <- forecast::ggAcf(ts_obj)  + ggplot2::labs(title = "ACF")
  #       p_pacf <- forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF")
  # 
  #       # Apply your selected theme to each plot
  #       p_time <- add_theme(p_time)
  #       p_acf  <- add_theme(p_acf)
  #       p_pacf <- add_theme(p_pacf)
  # 
  #       # Bottom row: ACF (left) | PACF (right)
  #       bottom_row <- gridExtra::arrangeGrob(p_acf, p_pacf, ncol = 2)
  # 
  #       # Final layout: Time on top; ACF+PACF in one row at bottom
  #       gridExtra::grid.arrange(p_time, bottom_row, ncol = 1, heights = c(1.3, 1))
  #     }
  #     
  #     
  # 
  #     "Periodogram" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       validate(need(length(xx) > 5, "More data needed for periodogram."))
  #       sp <- stats::spec.pgram(xx, detrend = TRUE, taper = 0.1, plot = FALSE)
  #       d  <- data.frame(freq = sp$freq, spec = sp$spec)
  #       ggplot2::ggplot(d, ggplot2::aes(freq, spec)) +
  #         ggplot2::geom_line() +
  #         ggplot2::labs(title = "Periodogram", x = "Frequency", y = "Spectral density")
  #     }
  #   )
  #   
  #   # apply theme (for ggplot outputs)
  #   if (inherits(plt, "ggplot")) {
  #     plt <- add_theme(plt)
  #   }
  #   plt
  # }, res = 96)
  # 
  
  
  
  
  output$tsPlot_Choice <- renderPlot({
    req(myData_Choice())
    req(input$plot_type_choice)
    
    ts_obj <- myData_Choice()
    p      <- prepared()  # for x-axis label
    freq   <- tryCatch(stats::frequency(ts_obj), error = function(e) NA_real_)
    
    # ------------------------------------------------------------
    # ACF/PACF lag control (numericInput: St_Lag) → S_Lag2
    # ------------------------------------------------------------
    S_Lag2 <- suppressWarnings(as.integer(input$St_Lag))
    if (!is.finite(S_Lag2) || S_Lag2 < 1) S_Lag2 <- 40L
    S_Lag2 <- max(1L, min(S_Lag2, length(ts_obj) - 1L))
    
    # ------------------------------------------------------------
    # ✅ DATE-AWARE helper: build plotting df using prepared()$df$x
    # and align it after differencing (d and D).
    # ------------------------------------------------------------
    df_ts <- function(z) {
      
      # base date/index from prepared()
      x_all <- p$df$x
      has_dates <- !is.null(x_all) &&
        (inherits(x_all, "Date") || inherits(x_all, "POSIXct") || inherits(x_all, "POSIXt"))
      
      # match the scope used by myData_Choice(): full vs train
      s <- ts_train_test()
      train_n <- s$train_n
      
      if (isTRUE(input$use_train_explore) && is.finite(train_n) && train_n >= 2) {
        x0 <- x_all[seq_len(min(train_n, length(x_all)))]
      } else {
        x0 <- x_all
      }
      
      # how many rows were dropped by differencing in getMyData()
      f0 <- as.numeric(p$freq)
      if (!is.finite(f0) || f0 < 1) f0 <- 1
      
      D <- suppressWarnings(as.integer(input$DS_n))
      d <- suppressWarnings(as.integer(input$d_n))
      if (!is.finite(D) || D < 0) D <- 0
      if (!is.finite(d) || d < 0) d <- 0
      
      drop_n <- 0L
      if (D > 0 && f0 > 1) drop_n <- drop_n + as.integer(D * f0)
      if (d > 0)           drop_n <- drop_n + as.integer(d)
      
      y <- as.numeric(z)
      
      if (has_dates) {
        # align x to differenced series
        if (length(x0) > drop_n) {
          x_use <- x0[(drop_n + 1L):length(x0)]
        } else {
          x_use <- x0
        }
        
        n <- min(length(x_use), length(y))
        data.frame(t = x_use[seq_len(n)], y = y[seq_len(n)])
      } else {
        data.frame(t = seq_along(y), y = y)
      }
    }
    
    k_ma  <- max(2L, as.integer(input$ma_k %||% 5))
    lag_m <- max(1L, as.integer(input$lag_m %||% 12))
    
    plt <- switch(
      input$plot_type_choice,
      
      "Line" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(
            size   = 0.9,
            colour = input$ts_line_color %||% "#2C7FB8"
          ) +
          ggplot2::labs(
            title = "Transformed series",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Points" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_point(size = 1) +
          ggplot2::labs(title = "Points", x = p$x_label, y = "Transformed value")
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Line + Points" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line() +
          ggplot2::geom_point(size = 0.9, alpha = 0.8) +
          ggplot2::labs(
            title = "Line + Points",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Smoothed (LOESS)" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(alpha = 0.4) +
          ggplot2::geom_smooth(method = "loess", se = FALSE, span = 0.2) +
          ggplot2::labs(
            title = "LOESS smooth",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Moving average" = {
        ddf <- df_ts(ts_obj)
        
        ma <- stats::filter(ddf$y, rep(1 / k_ma, k_ma), sides = 2)
        ddf$ma <- as.numeric(ma)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(alpha = 0.4) +
          ggplot2::geom_line(ggplot2::aes(y = ma), size = 1) +
          ggplot2::labs(
            title = sprintf("Moving average (k = %d)", k_ma),
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Cumulative sum" = {
        d <- df_ts(ts_obj); d$cum <- cumsum(d$y)
        ggplot2::ggplot(d, ggplot2::aes(t, cum)) +
          ggplot2::geom_line() +
          ggplot2::labs(title = "Cumulative sum", x = p$x_label, y = "Cumulative value")
      },
      
      "Seasonal plot" = {
        validate(need(is.finite(freq) && freq > 1, "Seasonal plot requires frequency > 1."))
        forecast::ggseasonplot(ts_obj, year.labels = TRUE) +
          ggplot2::labs(title = "Seasonal plot", x = p$x_label, y = "Value")
      },
      
      "Seasonal subseries" = {
        validate(need(is.finite(freq) && freq > 1, "Seasonal subseries requires frequency > 1."))
        forecast::ggsubseriesplot(ts_obj) +
          ggplot2::labs(title = "Seasonal subseries", x = p$x_label, y = "Value")
      },
      
      "Polar seasonal" = {
        validate(need(is.finite(freq) && freq > 1, "Polar seasonal requires frequency > 1."))
        forecast::ggseasonplot(ts_obj, polar = TRUE) +
          ggplot2::labs(title = "Polar seasonal plot", x = p$x_label, y = "Value")
      },
      
      "Seasonal boxplot" = {
        validate(need(is.finite(freq) && freq > 1, "Seasonal boxplot requires frequency > 1."))
        d <- if (inherits(ts_obj, "ts")) data.frame(season = stats::cycle(ts_obj), y = as.numeric(ts_obj))
        else data.frame(season = factor(1), y = as.numeric(ts_obj))
        ggplot2::ggplot(d, ggplot2::aes(x = factor(season), y = y)) +
          ggplot2::geom_boxplot() +
          ggplot2::labs(title = "Seasonal boxplot", x = "Season", y = "Value")
      },
      
      "Classical decomposition (additive)" = {
        validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
        dc <- stats::decompose(ts_obj, type = "additive")
        forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (additive)")
      },
      
      "Classical decomposition (multiplicative)" = {
        validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
        dc <- stats::decompose(ts_obj, type = "multiplicative")
        forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (multiplicative)")
      },
      
      "STL decomposition" = {
        validate(need(is.finite(freq) && freq > 1, "STL decomposition requires frequency > 1."))
        decomp <- stats::stl(ts_obj, s.window = "periodic")
        forecast::autoplot(decomp) + ggplot2::labs(title = "STL decomposition")
      },
      
      "Histogram" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
          ggplot2::geom_histogram(bins = 30) +
          ggplot2::labs(title = "Histogram", x = "Value", y = "Count")
      },
      
      "Density" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
          ggplot2::geom_density() +
          ggplot2::labs(title = "Density", x = "Value", y = "Density")
      },
      
      "QQ plot" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(sample = x)) +
          ggplot2::stat_qq() +
          ggplot2::stat_qq_line() +
          ggplot2::labs(title = "Normal Q-Q plot", x = "Theoretical quantiles", y = "Sample quantiles")
      },
      
      "Lag-1 scatter" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        validate(need(length(xx) >= 2, "Not enough data for lag-1 scatter."))
        d <- data.frame(x = xx[-length(xx)], y = xx[-1])
        ggplot2::ggplot(d, ggplot2::aes(x, y)) +
          ggplot2::geom_point() +
          ggplot2::geom_smooth(method = "lm", se = FALSE) +
          ggplot2::labs(title = "Lag-1 scatter", x = "y(t-1)", y = "y(t)")
      },
      
      "Lag plot (1..m)" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        validate(need(length(xx) > (lag_m + 1), "Increase data or reduce m for lag plots."))
        forecast::gglagplot(ts_obj, lags = lag_m) +
          ggplot2::labs(title = sprintf("Lag plot (1..%d)", lag_m))
      },
      
      # ======================
      # ACF/PACF (uses S_Lag2)
      # ======================
      "ACF" = {
        forecast::ggAcf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "ACF")
      },
      
      "PACF" = {
        forecast::ggPacf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "PACF")
      },
      
      "ACF+PACF" = {
        p_acf  <- add_theme(forecast::ggAcf(ts_obj,  lag.max = S_Lag2) + ggplot2::labs(title = "ACF"))
        p_pacf <- add_theme(forecast::ggPacf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "PACF"))
        (p_acf / p_pacf) + patchwork::plot_layout(heights = c(1, 1))
      },
      
      "Time + ACF+PACF" = {
        
        ddf <- df_ts(ts_obj)
        
        p_time <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(
            size   = 1,
            colour = input$ts_line_color %||% "#2C7FB8"
          ) +
          ggplot2::labs(
            title = "Time plot",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        p_time <- apply_smart_date_axis(p_time, ddf)
        
        p_acf  <- forecast::ggAcf(ts_obj,  lag.max = S_Lag2) + ggplot2::labs(title = "ACF")
        p_pacf <- forecast::ggPacf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "PACF")
        
        p_time <- add_theme(p_time)
        p_acf  <- add_theme(p_acf)
        p_pacf <- add_theme(p_pacf)
        
        (p_time / (p_acf | p_pacf)) +
          patchwork::plot_layout(heights = c(1.3, 1))
      },
      
      "Periodogram" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        validate(need(length(xx) >= 8, "Need at least 8 observations for a periodogram."))
        
        taper <- suppressWarnings(as.numeric(input$stp_spec_taper %||% 0.1))
        if (!is.finite(taper)) taper <- 0.1
        
        sp <- tryCatch(
          stats::spec.pgram(xx, detrend = TRUE, taper = taper, plot = FALSE),
          error = function(e) e
        )
        validate(need(!inherits(sp, "error"), paste("spec.pgram failed:", sp$message)))
        
        d <- data.frame(freq = sp$freq, spec = as.numeric(sp$spec))
        d <- d[is.finite(d$freq) & is.finite(d$spec), , drop = FALSE]
        validate(need(nrow(d) > 1, "Periodogram returned no finite values (check data/transform)."))
        
        ggplot2::ggplot(d, ggplot2::aes(freq, spec)) +
          ggplot2::geom_line(linewidth = 1, colour = input$ts_line_color %||% "#2C7FB8") +
          ggplot2::labs(title = "Periodogram", x = "Frequency", y = "Spectral density") +
          ggplot2::scale_x_continuous()
      }
    )
    
    # apply theme (for plain ggplot outputs only)
    if (inherits(plt, "ggplot")) {
      plt <- add_theme(plt)
    }
    
    print(plt)
  }, res = 96)
  
  
 
  # output$tsPlot_Choice <- renderPlot({
  #   req(myData_Choice())
  #   req(input$plot_type_choice)
  #   
  #   ts_obj <- myData_Choice()
  #   p      <- prepared()  # for x-axis label
  #   freq   <- tryCatch(stats::frequency(ts_obj), error = function(e) NA_real_)
  #   
  #   # df_ts <- function(z) {
  #   #   if (inherits(z, "ts")) {
  #   #     data.frame(t = as.numeric(stats::time(z)), y = as.numeric(z))
  #   #   } else {
  #   #     data.frame(t = seq_along(z), y = as.numeric(z))
  #   #   }
  #   # }
  #   
  #   
  #   # apply_smart_date_axis <- function(g, ddf) {
  #   #   if (!(inherits(ddf$t, "Date") || inherits(ddf$t, "POSIXct") || inherits(ddf$t, "POSIXt"))) return(g)
  #   #   
  #   #   span_days <- as.numeric(max(ddf$t, na.rm = TRUE) - min(ddf$t, na.rm = TRUE))
  #   #   
  #   #   brks <- if (!is.finite(span_days) || span_days <= 0) {
  #   #     "1 year"
  #   #   } else if (span_days <= 90) {
  #   #     "1 week"
  #   #   } else if (span_days <= 365) {
  #   #     "1 month"
  #   #   } else if (span_days <= 3 * 365) {
  #   #     "3 months"
  #   #   } else if (span_days <= 10 * 365) {
  #   #     "1 year"
  #   #   } else {
  #   #     "2 years"
  #   #   }
  #   #   
  #   #   fmt <- if (span_days <= 365) "%d-%m-%Y" else "%d-%Y"
  #   #   
  #   #   if (inherits(ddf$t, "POSIXct") || inherits(ddf$t, "POSIXt")) {
  #   #     g + ggplot2::scale_x_datetime(date_breaks = brks, date_labels = fmt)
  #   #   } else {
  #   #     g + ggplot2::scale_x_date(date_breaks = brks, date_labels = fmt)
  #   #   }
  #   # }
  #   
  #   
  # 
  #   
  #   
  #   
  #   ts_obj <- myData_Choice()
  #   p      <- prepared()  # for x-axis label
  #   freq   <- tryCatch(stats::frequency(ts_obj), error = function(e) NA_real_)
  #   
  #   
  #   S_Lag2 <- suppressWarnings(as.integer(input$St_Lag))
  #   if (!is.finite(S_Lag2) || S_Lag2 < 1) S_Lag2 <- 40L
  #   S_Lag2 <- min(S_Lag2, length(x_ts) - 1L)
  #   
  #   # ------------------------------------------------------------
  #   # ✅ DATE-AWARE helper: build plotting df using prepared()$df$x
  #   # and align it after differencing (d and D).
  #   # ------------------------------------------------------------
  #   df_ts <- function(z) {
  #     
  #     # base date/index from prepared()
  #     x_all <- p$df$x
  #     has_dates <- !is.null(x_all) &&
  #       (inherits(x_all, "Date") || inherits(x_all, "POSIXct") || inherits(x_all, "POSIXt"))
  #     
  #     # match the scope used by myData_Choice(): full vs train
  #     s <- ts_train_test()
  #     train_n <- s$train_n
  #     
  #     if (isTRUE(input$use_train_explore) && is.finite(train_n) && train_n >= 2) {
  #       x0 <- x_all[seq_len(min(train_n, length(x_all)))]
  #     } else {
  #       x0 <- x_all
  #     }
  #     
  #     # how many rows were dropped by differencing in getMyData()
  #     f0 <- as.numeric(p$freq)
  #     if (!is.finite(f0) || f0 < 1) f0 <- 1
  #     
  #     D <- suppressWarnings(as.integer(input$DS_n))
  #     d <- suppressWarnings(as.integer(input$d_n))
  #     if (!is.finite(D) || D < 0) D <- 0
  #     if (!is.finite(d) || d < 0) d <- 0
  #     
  #     drop_n <- 0L
  #     if (D > 0 && f0 > 1) drop_n <- drop_n + as.integer(D * f0)
  #     if (d > 0)           drop_n <- drop_n + as.integer(d)
  #     
  #     y <- as.numeric(z)
  #     
  #     if (has_dates) {
  #       # align x to differenced series
  #       if (length(x0) > drop_n) {
  #         x_use <- x0[(drop_n + 1L):length(x0)]
  #       } else {
  #         x_use <- x0
  #       }
  #       
  #       n <- min(length(x_use), length(y))
  #       data.frame(t = x_use[seq_len(n)], y = y[seq_len(n)])
  #     } else {
  #       data.frame(t = seq_along(y), y = y)
  #     }
  #   }
  #   
  #   k_ma  <- max(2L, as.integer(input$ma_k %||% 5))
  #   lag_m <- max(1L, as.integer(input$lag_m %||% 12))
  #   
  #   plt <- switch(
  #     input$plot_type_choice,
  #     
  #     # ==========================================================
  #     # ✅ FIXED "Line": use ggplot on date-aware df + smart thinning
  #     # ==========================================================
  # 
  # 
  #     "Line" = {
  #       ddf <- df_ts(ts_obj)
  #       
  #       g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line(
  #           size   = 0.9,
  #           colour = input$ts_line_color %||% "#2C7FB8"
  #         ) +
  #         ggplot2::labs(
  #           title = "Transformed series",
  #           x     = p$x_label,
  #           y     = "Transformed value"
  #         )
  #       
  #       # ✅ Apply the same smart date axis logic used everywhere else
  #       apply_smart_date_axis(g, ddf)
  #     },
  #     
  # 
  #     
  #     "Points" = {
  #       ddf <- df_ts(ts_obj)
  #       
  #       g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #         ggplot2::geom_point(size = 1) +
  #         ggplot2::labs(title = "Points", x = p$x_label, y = "Transformed value")
  #       
  #       apply_smart_date_axis(g, ddf)
  #     },
  #     
  #     
  #     
  # 
  #     "Line + Points" = {
  #       ddf <- df_ts(ts_obj)
  #       
  #       g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line() +
  #         ggplot2::geom_point(size = 0.9, alpha = 0.8) +
  #         ggplot2::labs(
  #           title = "Line + Points",
  #           x     = p$x_label,
  #           y     = "Transformed value"
  #         )
  #       
  #       # ✅ Apply smart date thinning + formatting
  #       apply_smart_date_axis(g, ddf)
  #     },
  #     
  #     
  # 
  #     
  #     "Smoothed (LOESS)" = {
  #       ddf <- df_ts(ts_obj)
  #       
  #       g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line(alpha = 0.4) +
  #         ggplot2::geom_smooth(method = "loess", se = FALSE, span = 0.2) +
  #         ggplot2::labs(
  #           title = "LOESS smooth",
  #           x     = p$x_label,
  #           y     = "Transformed value"
  #         )
  #       
  #       # ✅ Smart date axis (same logic as Line/Points)
  #       apply_smart_date_axis(g, ddf)
  #     },
  #     
  #     
  #     
  #  
  #     "Moving average" = {
  #       ddf <- df_ts(ts_obj)
  #       
  #       ma <- stats::filter(ddf$y, rep(1 / k_ma, k_ma), sides = 2)
  #       ddf$ma <- as.numeric(ma)
  #       
  #       g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line(alpha = 0.4) +
  #         ggplot2::geom_line(ggplot2::aes(y = ma), size = 1) +
  #         ggplot2::labs(
  #           title = sprintf("Moving average (k = %d)", k_ma),
  #           x     = p$x_label,
  #           y     = "Transformed value"
  #         )
  #       
  #       # ✅ Keep dates readable
  #       apply_smart_date_axis(g, ddf)
  #     },
  #     
  #     
  #     
  #     "Cumulative sum" = {
  #       d <- df_ts(ts_obj); d$cum <- cumsum(d$y)
  #       ggplot2::ggplot(d, ggplot2::aes(t, cum)) +
  #         ggplot2::geom_line() +
  #         ggplot2::labs(title = "Cumulative sum", x = p$x_label, y = "Cumulative value")
  #     },
  #     
  #     "Seasonal plot" = {
  #       validate(need(is.finite(freq) && freq > 1, "Seasonal plot requires frequency > 1."))
  #       forecast::ggseasonplot(ts_obj, year.labels = TRUE) +
  #         ggplot2::labs(title = "Seasonal plot", x = p$x_label, y = "Value")
  #     },
  #     
  #     "Seasonal subseries" = {
  #       validate(need(is.finite(freq) && freq > 1, "Seasonal subseries requires frequency > 1."))
  #       forecast::ggsubseriesplot(ts_obj) +
  #         ggplot2::labs(title = "Seasonal subseries", x = p$x_label, y = "Value")
  #     },
  #     
  #     "Polar seasonal" = {
  #       validate(need(is.finite(freq) && freq > 1, "Polar seasonal requires frequency > 1."))
  #       forecast::ggseasonplot(ts_obj, polar = TRUE) +
  #         ggplot2::labs(title = "Polar seasonal plot", x = p$x_label, y = "Value")
  #     },
  #     
  #     "Seasonal boxplot" = {
  #       validate(need(is.finite(freq) && freq > 1, "Seasonal boxplot requires frequency > 1."))
  #       d <- if (inherits(ts_obj, "ts")) data.frame(season = stats::cycle(ts_obj), y = as.numeric(ts_obj))
  #       else data.frame(season = factor(1), y = as.numeric(ts_obj))
  #       ggplot2::ggplot(d, ggplot2::aes(x = factor(season), y = y)) +
  #         ggplot2::geom_boxplot() +
  #         ggplot2::labs(title = "Seasonal boxplot", x = "Season", y = "Value")
  #     },
  #     
  #     "Classical decomposition (additive)" = {
  #       validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
  #       dc <- stats::decompose(ts_obj, type = "additive")
  #       forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (additive)")
  #     },
  #     
  #     "Classical decomposition (multiplicative)" = {
  #       validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
  #       dc <- stats::decompose(ts_obj, type = "multiplicative")
  #       forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (multiplicative)")
  #     },
  #     
  #     "STL decomposition" = {
  #       validate(need(is.finite(freq) && freq > 1, "STL decomposition requires frequency > 1."))
  #       decomp <- stats::stl(ts_obj, s.window = "periodic")
  #       forecast::autoplot(decomp) + ggplot2::labs(title = "STL decomposition")
  #     },
  #     
  #     "Histogram" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
  #         ggplot2::geom_histogram(bins = 30) +
  #         ggplot2::labs(title = "Histogram", x = "Value", y = "Count")
  #     },
  #     
  #     "Density" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
  #         ggplot2::geom_density() +
  #         ggplot2::labs(title = "Density", x = "Value", y = "Density")
  #     },
  #     
  #     "QQ plot" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(sample = x)) +
  #         ggplot2::stat_qq() +
  #         ggplot2::stat_qq_line() +
  #         ggplot2::labs(title = "Normal Q-Q plot", x = "Theoretical quantiles", y = "Sample quantiles")
  #     },
  #     
  #     "Lag-1 scatter" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       validate(need(length(xx) >= 2, "Not enough data for lag-1 scatter."))
  #       d <- data.frame(x = xx[-length(xx)], y = xx[-1])
  #       ggplot2::ggplot(d, ggplot2::aes(x, y)) +
  #         ggplot2::geom_point() +
  #         ggplot2::geom_smooth(method = "lm", se = FALSE) +
  #         ggplot2::labs(title = "Lag-1 scatter", x = "y(t-1)", y = "y(t)")
  #     },
  #     
  #     "Lag plot (1..m)" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       validate(need(length(xx) > (lag_m + 1), "Increase data or reduce m for lag plots."))
  #       forecast::gglagplot(ts_obj, lags = lag_m) +
  #         ggplot2::labs(title = sprintf("Lag plot (1..%d)", lag_m))
  #     },
  #     
  #     # "ACF" = {
  #     #   forecast::ggAcf(ts_obj) + ggplot2::labs(title = "ACF")
  #     # },
  #     # 
  #     # "PACF" = {
  #     #   forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF")
  #     # },
  #     # 
  #     # "ACF+PACF" = {
  #     #   p_acf  <- add_theme(forecast::ggAcf(ts_obj)  + ggplot2::labs(title = "ACF"))
  #     #   p_pacf <- add_theme(forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF"))
  #     #   
  #     #   # patchwork vertical
  #     #   (p_acf / p_pacf) + patchwork::plot_layout(heights = c(1, 1))
  #     # },
  #     
  #     "ACF" = {
  #       forecast::ggAcf(ts_obj, lag.max = S_Lag2) +
  #         ggplot2::labs(title = "ACF")
  #     },
  #     
  #     "PACF" = {
  #       forecast::ggPacf(ts_obj, lag.max = S_Lag2) +
  #         ggplot2::labs(title = "PACF")
  #     },
  #     
  #     "ACF+PACF" = {
  #       p_acf  <- add_theme(
  #         forecast::ggAcf(ts_obj,  lag.max = S_Lag2) +
  #           ggplot2::labs(title = "ACF")
  #       )
  #       p_pacf <- add_theme(
  #         forecast::ggPacf(ts_obj, lag.max = S_Lag2) +
  #           ggplot2::labs(title = "PACF")
  #       )
  #       
  #       # patchwork vertical
  #       (p_acf / p_pacf) + patchwork::plot_layout(heights = c(1, 1))
  #     },
  #     
  # 
  #     # "Time + ACF+PACF" = {
  #     #   # Top: time plot
  #     #   p_time <- forecast::autoplot(
  #     #     ts_obj,
  #     #     size   = 1,
  #     #     colour = input$ts_line_color %||% "#2C7FB8"
  #     #   ) +
  #     #     ggplot2::labs(
  #     #       title = "Time plot",
  #     #       x = p$x_label,
  #     #       y = "Transformed value"
  #     #     )
  #     # 
  #     #   # Bottom: ACF + PACF
  #     #   p_acf  <- forecast::ggAcf(ts_obj)  + ggplot2::labs(title = "ACF")
  #     #   p_pacf <- forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF")
  #     # 
  #     #   # Apply theme
  #     #   p_time <- add_theme(p_time)
  #     #   p_acf  <- add_theme(p_acf)
  #     #   p_pacf <- add_theme(p_pacf)
  #     # 
  #     #   # Patchwork layout (resizes correctly, no overlap)
  #     #   (p_time / (p_acf | p_pacf)) +
  #     #     patchwork::plot_layout(heights = c(1.3, 1))
  #     # },
  #     
  #     
  #     "Time + ACF+PACF" = {
  #       
  #       # --- Top: time plot (DATE-AWARE) ---
  #       ddf <- df_ts(ts_obj)
  #       
  #       p_time <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
  #         ggplot2::geom_line(
  #           size   = 1,
  #           colour = input$ts_line_color %||% "#2C7FB8"
  #         ) +
  #         ggplot2::labs(
  #           title = "Time plot",
  #           x     = p$x_label,
  #           y     = "Transformed value"
  #         )
  #       
  #       # ✅ Apply smart date axis thinning (only affects the time plot)
  #       p_time <- apply_smart_date_axis(p_time, ddf)
  #       
  #       # --- Bottom: ACF + PACF (keep as-is) ---
  #       p_acf  <- forecast::ggAcf(ts_obj)  + ggplot2::labs(title = "ACF")
  #       p_pacf <- forecast::ggPacf(ts_obj) + ggplot2::labs(title = "PACF")
  #       
  #       # Apply theme
  #       p_time <- add_theme(p_time)
  #       p_acf  <- add_theme(p_acf)
  #       p_pacf <- add_theme(p_pacf)
  #       
  #       # Patchwork layout
  #       (p_time / (p_acf | p_pacf)) +
  #         patchwork::plot_layout(heights = c(1.3, 1))
  #     },
  #     
  #     
  #     
  #     
  #     
  #     "Periodogram" = {
  #       xx <- as.numeric(stats::na.omit(ts_obj))
  #       validate(need(length(xx) >= 8, "Need at least 8 observations for a periodogram."))
  #       
  #       # use your UI taper slider if it exists; otherwise 0.1
  #       taper <- suppressWarnings(as.numeric(input$stp_spec_taper %||% 0.1))
  #       if (!is.finite(taper)) taper <- 0.1
  #       
  #       sp <- tryCatch(
  #         stats::spec.pgram(xx, detrend = TRUE, taper = taper, plot = FALSE),
  #         error = function(e) e
  #       )
  #       validate(need(!inherits(sp, "error"), paste("spec.pgram failed:", sp$message)))
  #       
  #       d <- data.frame(freq = sp$freq, spec = as.numeric(sp$spec))
  #       d <- d[is.finite(d$freq) & is.finite(d$spec), , drop = FALSE]
  #       validate(need(nrow(d) > 1, "Periodogram returned no finite values (check data/transform)."))
  #       
  #       ggplot2::ggplot(d, ggplot2::aes(freq, spec)) +
  #         ggplot2::geom_line(linewidth = 1, colour = input$ts_line_color %||% "#2C7FB8") +
  #         ggplot2::labs(title = "Periodogram", x = "Frequency", y = "Spectral density") +
  #         ggplot2::scale_x_continuous()
  #     }
  #   )
  #   
  #   # apply theme (for plain ggplot outputs only)
  #   if (inherits(plt, "ggplot")) {
  #     plt <- add_theme(plt)
  #   }
  #   plt
  # }, res = 96)
  
  
  
  
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  

    # ---- UI wrapper (dynamic size) ----
  output$difference2ACFPACF_UI <- renderUI({
    plotOutput(
      "difference2ACFPACF",
      width  = getPlotDim(input$plot_width  %||% 900),
      height = getPlotDim(input$plot_height %||% 700)
    )
  })
  
  # # ---- UI wrapper (dynamic size) ----
  # output$difference2ACFPACF_UI <- renderUI({
  #   plotOutput(
  #     "difference2ACFPACF",
  #     width  = getPlotDim(input$plot_width  %||% 800),
  #     height = getPlotDim(input$plot_height %||% 700)
  #   )
  # })
  
  # ---- Combined ACF + PACF (stacked) ----
  
  
  plot_pylike_corr <- function(x, type = c("acf", "pacf"), lag.max = 50, tickSize = 11) {
    type <- match.arg(type)
    x <- as.numeric(na.omit(x))
    n <- length(x)
    stopifnot(n > 3)
    
    # compute acf/pacf without plotting
    obj <- if (type == "acf") stats::acf(x, lag.max = lag.max, plot = FALSE)
    else               stats::pacf(x, lag.max = lag.max, plot = FALSE)
    
    vals <- as.numeric(obj$acf)
    lags <- as.numeric(obj$lag)
    
    # statsmodels-style: usually start at lag 1 for ACF
    if (type == "acf") {
      keep <- lags > 0
      lags <- lags[keep]
      vals <- vals[keep]
    }
    
    df <- data.frame(lag = lags, val = vals)
    
    # common CI band (very similar visually to Python defaults)
    ci <- 1.96 / sqrt(n)
    
    ggplot(df, aes(x = lag, y = val)) +
      geom_hline(yintercept = 0, linewidth = 0.4) +
      geom_ribbon(aes(ymin = -ci, ymax = ci), alpha = 0.2) +
      geom_segment(aes(xend = lag, yend = 0), linewidth = 0.8) +
      geom_point(size = 2) +
      coord_cartesian(ylim = c(-1, 1)) +
      labs(
        title = if (type == "acf") "Autocorrelation" else "Partial Autocorrelation",
        x = "Lag",
        y = toupper(type)
      ) +
      theme_classic(base_size = tickSize) +
      theme(
        plot.title = element_text(hjust = 0.5, face = "bold"),
        panel.border = element_rect(fill = NA, linewidth = 0.4)
      )
  }
  
  # output$difference2ACFPACF <- renderPlot({
  #   req(myData_Choice())
  #   tick <- as.numeric(input$tickSize %||% 11)
  #   
  #   p1 <- plot_pylike_corr(myData_Choice(), "acf",  lag.max = 50, tickSize = tick) +
  #     labs(title = "Autocorrelation of Sales")
  #   
  #   p2 <- plot_pylike_corr(myData_Choice(), "pacf", lag.max = 50, tickSize = tick) +
  #     labs(title = "Partial Autocorrelation of Sales")
  #   
  #   gridExtra::grid.arrange(p1, p2, ncol = 1, top = "ACF & PACF of transformed series")
  # }, res = 96)
  
  output$difference2ACFPACF <- renderPlot({
    req(myData_Choice())
    
    tick <- as.numeric(input$tickSize %||% 11)
    ts_obj <- myData_Choice()
    
    # --- lag control (numericInput: St_Lag) -> S_Lag2 ---
    S_Lag2 <- suppressWarnings(as.integer(input$St_Lag))
    if (!is.finite(S_Lag2) || S_Lag2 < 1) S_Lag2 <- 40L
    S_Lag2 <- max(1L, min(S_Lag2, length(ts_obj) - 1L))
    
    p1 <- plot_pylike_corr(ts_obj, "acf",  lag.max = S_Lag2, tickSize = tick) +
      ggplot2::labs(title = "Autocorrelation of Sales")
    
    p2 <- plot_pylike_corr(ts_obj, "pacf", lag.max = S_Lag2, tickSize = tick) +
      ggplot2::labs(title = "Partial Autocorrelation of Sales")
    
    gridExtra::grid.arrange(p1, p2, ncol = 1, top = "ACF & PACF of transformed series")
  }, res = 96)
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  output$teststationarited3St <- renderPrint({
    # ---------- Helpers ----------
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0 && !all(is.na(a))) a else b
    to_num_safe <- function(v, default = NA_real_) {
      out <- suppressWarnings(as.numeric(v))
      if (length(out) == 0 || all(is.na(out)) || !is.finite(out[1])) default else out[1]
    }
    to_int_safe <- function(v, default = 0L) {
      out <- suppressWarnings(as.integer(v))
      if (length(out) == 0 || is.na(out[1]) || !is.finite(out[1])) default else out[1]
    }
    safe_head_tail <- function(x, n = 5) {
      x <- as.numeric(x); x <- x[is.finite(x)]
      if (length(x) == 0) return(list(head = numeric(0), tail = numeric(0)))
      list(head = head(x, n), tail = tail(x, n))
    }
    tau_row_for <- function(type_in) switch(type_in, "none"="tau1", "drift"="tau2", "trend"="tau3", "tau3")
    cval_pick_safe <- function(cval_obj, row, col) {
      if (is.null(cval_obj)) return(NA_real_)
      ans <- NA_real_
      if (is.matrix(cval_obj)) {
        if (!missing(row) && !missing(col) && row %in% rownames(cval_obj) && col %in% colnames(cval_obj)) {
          ans <- suppressWarnings(as.numeric(cval_obj[row, col]))
        } else if (!missing(col) && col %in% colnames(cval_obj)) {
          ans <- suppressWarnings(as.numeric(cval_obj[1, col]))
        } else {
          ans <- suppressWarnings(as.numeric(cval_obj[1, 1]))
        }
      } else {
        nm <- names(cval_obj)
        if (!is.null(nm) && col %in% nm) ans <- suppressWarnings(as.numeric(cval_obj[[col]]))
        if (!is.finite(ans) && length(cval_obj) >= 3) {
          if (identical(col, "10pct")) ans <- suppressWarnings(as.numeric(cval_obj[1]))
          if (identical(col, "5pct"))  ans <- suppressWarnings(as.numeric(cval_obj[2]))
          if (identical(col, "1pct"))  ans <- suppressWarnings(as.numeric(cval_obj[3]))
        }
        if (!is.finite(ans)) ans <- suppressWarnings(as.numeric(cval_obj[1]))
      }
      ans
    }
    fmt_p <- function(p) {
      if (!is.finite(p)) return("NA")
      if (p < .001) "<0.001" else sprintf("%.6f", p)
    }
    fmt_num <- function(z, d=6) ifelse(is.finite(z), sprintf(paste0("%.", d ,"f"), z), "NA")
    tick <- function(ok) if (isTRUE(ok)) "[✓]" else "[X]"
    warn <- function(ok) if (isTRUE(ok)) "[✓]" else "[!]"
    qmark <- function(ok) if (isTRUE(ok)) "[✓]" else "[?]"
    
    # ---------- Inputs (from your UI) ----------
    alt_in  <- input$alternd2St %||% input$alternSt       # "stationary", "explosive", "regression"
    lag_in  <- input$LagOrderADFd2St %||% input$LagOrderADFSt
    a_in    <- input$alphaSt2
    type_in <- input$adfTypeSt2                            # "none", "drift", "trend"
    
    # Transformation flags (provenance)
    d_in   <- input$d_n  %||% NA
    D_in   <- input$DS_n %||% NA
    log_in <- input$check_box %||% FALSE
    
    # ---------- Data ----------
    req(myData_Choice())
    x_raw <- myData_Choice()
    na_before <- sum(is.na(x_raw))
    x_class <- paste(class(x_raw), collapse = ", ")
    x_freq  <- if (inherits(x_raw, "ts")) tryCatch(stats::frequency(x_raw), error = function(e) NA_integer_) else NA_integer_
    x <- as.numeric(stats::na.omit(x_raw))
    N <- length(x)
    
    # ---------- Hyper-parameters ----------
    k <- to_int_safe(lag_in, default = 0L); if (!is.finite(k) || k < 0) k <- 0L
    alpha_raw <- as.character(a_in)
    alpha_val <- to_num_safe(alpha_raw, default = 0.05)
    alpha_col <- switch(alpha_raw, "0.01"="1pct", "0.05"="5pct", "0.1"="10pct", "0.10"="10pct",
                        "1pct"="1pct", "5pct"="5pct", "10pct"="10pct", "5pct")
    tau_row <- tau_row_for(type_in)
    
    # ---------- Sanity checks ----------
    if (N < 5) {
      cat("==========================================================================\n")
      cat("                         ADF UNIT ROOT DIAGNOSTIC                         \n")
      cat("==========================================================================\n")
      cat("CRITICAL ERROR: Too few observations (N < 5). Provide more data.\n")
      return(invisible(NULL))
    }
    if (!is.finite(stats::sd(x)) || stats::sd(x) == 0) {
      cat("==========================================================================\n")
      cat("                         ADF UNIT ROOT DIAGNOSTIC                         \n")
      cat("==========================================================================\n")
      cat("CRITICAL ERROR: Series is constant/invalid (sd = 0 or NA). Check transforms.\n")
      return(invisible(NULL))
    }
    
    # ---------- Package check ----------
    if (!requireNamespace("urca", quietly = TRUE) || !requireNamespace("tseries", quietly = TRUE)) {
      cat("==========================================================================\n")
      cat("                         ADF UNIT ROOT DIAGNOSTIC                         \n")
      cat("==========================================================================\n")
      cat("ERROR: Please install.packages(c('urca','tseries')) to run ADF/KPSS.\n")
      return(invisible(NULL))
    }
    
    # ---------- Common quantities ----------
    m_mean <- mean(x, na.rm = TRUE)
    m_sd   <- stats::sd(x, na.rm = TRUE)
    lb_lag <- max(1L, min(10L, floor(N / 5)))
    
    # ---------- Core ADF (urca) for chosen type & k ----------
    ur  <- tryCatch(urca::ur.df(x, type = type_in, lags = k), error = function(e) NULL)
    tau_obs  <- if (!is.null(ur)) suppressWarnings(as.numeric(ur@teststat[tau_row])) else NA_real_
    if (!is.finite(tau_obs) && !is.null(ur)) tau_obs <- suppressWarnings(as.numeric(ur@teststat[1]))
    tau_crit <- if (!is.null(ur)) cval_pick_safe(ur@cval, tau_row, alpha_col) else NA_real_
    adf_ts <- if (N > (k + 10)) tryCatch(tseries::adf.test(x, alternative = alt_in, k = k),
                                         error = function(e) NULL) else NULL
    adf_p  <- if (!is.null(adf_ts)) to_num_safe(adf_ts$p.value) else NA_real_
    lb_main <- if (!is.null(ur)) stats::Box.test(ur@res, lag = lb_lag, type = "Ljung-Box") else NULL
    lb_stat<- if (!is.null(lb_main)) to_num_safe(lb_main$statistic) else NA_real_
    lb_p   <- if (!is.null(lb_main)) to_num_safe(lb_main$p.value) else NA_real_
    
    adf_ok_vals <- is.finite(tau_obs) && is.finite(tau_crit)
    adf_stationary <- adf_ok_vals && (tau_obs < tau_crit)
    
    # ---------- KPSS (full sample) ----------
    kpss_type <- if (type_in == "trend") "Trend" else "Level"
    kpss_ts   <- tryCatch(tseries::kpss.test(x, null = kpss_type), error = function(e) NULL)
    kpss_p    <- if (!is.null(kpss_ts)) to_num_safe(kpss_ts$p.value) else NA_real_
    kpss_uc   <- tryCatch(urca::ur.kpss(x, type = if (type_in == "trend") "tau" else "mu"),
                          error = function(e) NULL)
    eta_obs_uc  <- if (!is.null(kpss_uc)) to_num_safe(kpss_uc@teststat) else NA_real_
    eta_col     <- if (alpha_val <= 0.01) "1pct" else if (alpha_val <= 0.05) "5pct" else "10pct"
    eta_crit_uc <- if (!is.null(kpss_uc)) cval_pick_safe(kpss_uc@cval, 1, eta_col) else NA_real_
    kpss_by_p   <- is.finite(kpss_p)     && (kpss_p < alpha_val)
    kpss_by_eta <- is.finite(eta_obs_uc) && is.finite(eta_crit_uc) && (eta_obs_uc > eta_crit_uc)
    kpss_stationary <- !(kpss_by_p || kpss_by_eta)
    
    # ---------- Structural break (Pettitt) ----------
    pett_U <- pett_p <- NA_real_; pett_cp <- NA_integer_
    if (requireNamespace("trend", quietly = TRUE)) {
      pet <- tryCatch(trend::pettitt.test(x), error = function(e) NULL)
      if (!is.null(pet)) {
        pett_U <- to_num_safe(pet$statistic)
        pett_p <- to_num_safe(pet$p.value)
        # trend::pettitt.test typically returns estimate (break index); guard for NA
        pett_cp <- to_int_safe(pet$estimate[1], default = NA_integer_)
        if (!is.finite(pett_cp)) {
          # conservative fallback: midpoint (only if needed)
          pett_cp <- as.integer(floor(N/2))
        }
        if (pett_cp < 2L || pett_cp > (N - 2L)) pett_cp <- NA_integer_  # unusable splits
      }
    }
    
    # ---------- KPSS by segments (if break usable) ----------
    seg1_p <- seg2_p <- NA_real_
    if (is.finite(pett_cp)) {
      if (pett_cp >= 8 && (N - pett_cp) >= 8) {
        seg1 <- tryCatch(tseries::kpss.test(x[seq_len(pett_cp)], null = kpss_type), error = function(e) NULL)
        seg2 <- tryCatch(tseries::kpss.test(x[(pett_cp + 1L):N], null = kpss_type), error = function(e) NULL)
        if (!is.null(seg1)) seg1_p <- to_num_safe(seg1$p.value)
        if (!is.null(seg2)) seg2_p <- to_num_safe(seg2$p.value)
      }
    }
    
    # ---------- Phase 0: k* scan & spec sensitivity ----------
    # k* = smallest k such that Ljung–Box p-value on ADF residuals > alpha, for the user-chosen type_in
    k_grid <- 0L:min(12L, max(1L, floor(N/10)))
    lbp_by_k <- rep(NA_real_, length(k_grid))
    for (i in seq_along(k_grid)) {
      kk <- k_grid[i]
      ur_i <- tryCatch(urca::ur.df(x, type = type_in, lags = kk), error = function(e) NULL)
      lb_i <- if (!is.null(ur_i)) tryCatch(stats::Box.test(ur_i@res, lag = lb_lag, type = "Ljung-Box"), error = function(e) NULL) else NULL
      lbp_by_k[i] <- if (!is.null(lb_i)) to_num_safe(lb_i$p.value) else NA_real_
    }
    k_suggest <- NA_integer_
    idx_ok <- which(is.finite(lbp_by_k) & lbp_by_k > alpha_val)
    if (length(idx_ok) > 0) k_suggest <- k_grid[min(idx_ok)] else k_suggest <- k
    
    # Spec sensitivity across types for k = selected and k = k_suggest
    types <- c("none","drift","trend")
    spec_line <- function(kk) {
      for (tp in types) {
        tau_row_tp <- tau_row_for(tp)
        ur_tp <- tryCatch(urca::ur.df(x, type = tp, lags = kk), error = function(e) NULL)
        tau_tp  <- if (!is.null(ur_tp)) suppressWarnings(as.numeric(ur_tp@teststat[tau_row_tp])) else NA_real_
        if (!is.finite(tau_tp) && !is.null(ur_tp)) tau_tp <- suppressWarnings(as.numeric(ur_tp@teststat[1]))
        crit_tp <- if (!is.null(ur_tp)) cval_pick_safe(ur_tp@cval, tau_row_tp, alpha_col) else NA_real_
        lb_tp   <- if (!is.null(ur_tp)) tryCatch(stats::Box.test(ur_tp@res, lag = lb_lag, type = "Ljung-Box"), error = function(e) NULL) else NULL
        lbp_tp  <- if (!is.null(lb_tp)) to_num_safe(lb_tp$p.value) else NA_real_
        adf_dec <- if (is.finite(tau_tp) && is.finite(crit_tp) && (tau_tp < crit_tp)) "ADF=STATIONARY" else "ADF=NON-STATIONARY"
        cat(sprintf("     %s type=%-5s | tau=%s | crit=%s | %s | LB p=%s\n",
                    tick(is.finite(lbp_tp) && lbp_tp > alpha_val),
                    tp,
                    fmt_num(tau_tp, 4),
                    fmt_num(crit_tp, 4),
                    adf_dec,
                    fmt_num(lbp_tp, 4)))
      }
    }
    
    # ---------- Agreement & flags ----------
    agreement <- (adf_stationary && kpss_stationary) || (!adf_stationary && !kpss_stationary)
    
    # ---------- HEADER ----------
    cat("==========================================================================\n")
    cat("                        ADF UNIT ROOT DIAGNOSTIC                          \n")
    cat("==========================================================================\n")
    cat(sprintf(" MODEL TYPE : %-10s | SAMPLE SIZE (N) : %s\n", toupper(type_in), N))
    cat(sprintf(" LAG ORDER  : %-10s | SIGNIFICANCE (α) : %s\n", k, fmt_num(alpha_val, 4)))
    cat(sprintf(" MOMENTS    : Mean: %s | Std.Dev: %s\n",
                fmt_num(m_mean, 4), fmt_num(m_sd, 4)))
    cat("--------------------------------------------------------------------------\n")
    cat(" TRANSFORMATION PROVENANCE (what ALL tests use):\n")
    cat(sprintf(" [ ] Source object class           : %s\n", x_class))
    cat(sprintf(" [ ] Frequency (if ts)             : %s\n", ifelse(is.finite(x_freq), x_freq, "NA")))
    cat(sprintf(" [ ] NA count before na.omit       : %s\n", na_before))
    cat(sprintf(" [ ] Transformation inputs (UI)    : log=%s | d=%s | D=%s\n",
                ifelse(isTRUE(log_in),"ON","OFF"), as.character(d_in), as.character(D_in)))
    ht <- safe_head_tail(x, 5)
    cat(sprintf(" [ ] First 5 values used in tests  : %s\n", paste(round(ht$head, 4), collapse = ", ")))
    cat(sprintf(" [ ] Last  5 values used in tests  : %s\n\n", paste(round(ht$tail, 4), collapse = ", ")))
    
    # ---------- PHASE 0 ----------
    cat("==========================================================================\n")
    cat("PHASE 0: DECISION AID (Lag + Spec Sensitivity)\n")
    cat("==========================================================================\n")
    cat(sprintf(" • Ljung-Box reference lag used in scan : %d  ; (LB lag = min(10, floor(N/5))\n", lb_lag))
    cat(sprintf(" [!] Suggested k* (scan)                : %s  (smallest k with Ljung-Box p-value > alpha (whiter residuals))\n",
                ifelse(is.finite(k_suggest), k_suggest, "NA")))
    if (is.finite(k_suggest) && k_suggest != k) {
      cat(sprintf(" [!] You selected k=%d. Consider trying k=%d and re-running.\n", k, k_suggest))
    } else {
      cat(sprintf(" [✓] You selected k=%d. This already meets the LB>α rule-of-thumb.\n", k))
    }
    cat("--------------------------------------------------------------------------\n")
    cat(" ADF SPEC SENSITIVITY (ur.df):\n")
    cat("   (Prefer: LB ok + stable decision across types)\n")
    cat(sprintf("  • k=%d\n", k)); spec_line(k)
    if (is.finite(k_suggest) && k_suggest != k) {
      cat(sprintf("  • k=%d\n", k_suggest)); spec_line(k_suggest)
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---------- PHASE 1 ----------
    cat("==========================================================================\n")
    cat("PHASE 1: ADF UNIT ROOT TEST\n")
    cat("==========================================================================\n")
    cat(" • H0: The series has a Unit Root (Non-Stationary).\n")
    cat(" • Ha: The series is Stationary (Mean Reverting).\n")
    cat(sprintf(" -> CRITERIA: Reject H0 if Tau-Obs (%s) < Tau-Crit (%s)\n",
                fmt_num(tau_obs, 4), fmt_num(tau_crit, 4)))
    cat("\n RESULT:\n")
    cat(sprintf("  - Tau Observed : %s \n", fmt_num(tau_obs, 6)))
    cat(sprintf("  - Tau Critical : %s \n", fmt_num(tau_crit, 2)))
    cat(sprintf("  - P-Value (Ref): %s \n", ifelse(is.finite(adf_p), fmt_p(adf_p), "NA")))
    cat("\n DECISION:\n")
    if (adf_ok_vals && adf_stationary) {
      cat("  -> REJECT H0: Evidence suggests the series is STATIONARY.\n")
    } else if (adf_ok_vals && !adf_stationary) {
      cat("  -> FAIL TO REJECT H0: Evidence suggests the series is NON-STATIONARY.\n")
    } else {
      cat("  -> INCONCLUSIVE: Missing statistic/critical value; regression may be ill-conditioned.\n")
    }
    
    # ---------- PHASE 2 ----------
    cat("\n==========================================================================\n")
    cat("PHASE 2: RESIDUAL DIAGNOSTICS (LJUNG-BOX)\n")
    cat("==========================================================================\n")
    cat(" • H0: Residuals are White Noise (No Autocorrelation).\n")
    cat(" • Ha: Residuals are Correlated (Lags are insufficient).\n")
    cat(sprintf(" -> CRITERIA: Reject H0 if P-Value (%s) < α (%s)\n", fmt_num(lb_p, 6), fmt_num(alpha_val, 4)))
    cat("\n RESULT:\n")
    cat(sprintf("  - LB Statistic : %s \n", fmt_num(lb_stat, 6)))
    cat(sprintf("  - LB P-Value   : %s \n", fmt_num(lb_p, 6)))
    cat(sprintf("  - LB Lag used  : %d \n", lb_lag))
    cat("    it’s normal to choose LB lag by a rule-of-thumb (like min(10, floor(N/5)) \n")
    cat("\n DECISION:\n")
    if (is.finite(lb_p)) {
      if (lb_p > alpha_val) cat("  -> FAIL TO REJECT H0: Residuals are White Noise. [ADF more reliable]\n")
      else                  cat("  -> REJECT H0: Residual autocorrelation remains; increase k or difference.\n")
    } else {
      cat("  -> INCONCLUSIVE: Ljung–Box p-value is NA.\n")
    }
    
    # ---------- PHASE 3A ----------
    cat("\n==========================================================================\n")
    cat("PHASE 3: KPSS + STRUCTURAL BREAK (Pettitt) + KPSS SEGMENTS\n")
    cat("==========================================================================\n\n")
    cat("PHASE 3A: KPSS (Stationarity Confirmation)\n")
    cat(sprintf(" • H0: The series is Stationary around a %s.\n", if (kpss_type=="Trend") "Trend" else "Level"))
    cat(" • Ha: The series is Non-Stationary.\n")
    cat(sprintf(" • CRITERIA (p-value) : Reject H0 if p-value (%s) < α (%s)\n",
                ifelse(is.finite(kpss_p), fmt_num(kpss_p, 6), "NA"), fmt_num(alpha_val,4)))
    cat(sprintf(" • CRITERIA (eta)     : Reject H0 if Eta-Obs (%s) > Eta-Crit (%s)  [urca]\n",
                fmt_num(eta_obs_uc, 6), fmt_num(eta_crit_uc, 6)))
    cat("\n RESULT:\n")
    cat(sprintf("  - Eta (Observed value) [urca]   : %s \n", fmt_num(eta_obs_uc, 5)))
    cat(sprintf("  - Eta (Critical value) [urca]   : %s \n", fmt_num(eta_crit_uc, 3)))
    cat(sprintf("  - p-value (one-tailed) [tseries]: %s \n", ifelse(is.finite(kpss_p), fmt_num(kpss_p, 6), "NA")))
    cat(sprintf("  - Eta (Observed) [tseries, FYI] : %s \n", fmt_num(eta_obs_uc, 5)))
    cat("\n DECISION:\n")
    if (kpss_stationary) cat("  -> FAIL TO REJECT H0: Stationarity supported by KPSS.\n")
    else                 cat("  -> REJECT H0: Non-stationarity indicated by KPSS.\n")
    
    # ---------- PHASE 3B ----------
    cat("--------------------------------------------------------------------------\n")
    cat("PHASE 3B: STRUCTURAL BREAK CHECK (Pettitt) + KPSS SEGMENT CHECK\n")
    cat(" • Goal: Detect a single change-point (median shift) that can distort KPSS.\n")
    cat(" • If a break exists, we re-run KPSS before/after the break.\n")
    cat(sprintf(" • Pettitt p-value: %s | α: %s\n\n", ifelse(is.finite(pett_p), fmt_num(pett_p, 6), "NA"), fmt_num(alpha_val, 4)))
    cat(" RESULT:\n")
    cat(sprintf("  - Break index (estimate): %s \n", ifelse(is.finite(pett_cp), pett_cp, "NA")))
    cat(sprintf("  - Pettitt statistic     : %s \n", fmt_num(pett_U, 0)))
    cat(sprintf("  - Pettitt p-value       : %s \n", ifelse(is.finite(pett_p), fmt_num(pett_p, 6), "NA")))
    cat("\n DECISION:\n")
    if (is.finite(pett_p)) {
      if (pett_p < alpha_val) cat("  -> REJECT H0: Break detected. Full-sample KPSS/ADF may be contaminated.\n")
      else                    cat("  -> FAIL TO REJECT H0: No strong single break detected.\n")
    } else {
      cat("  -> INCONCLUSIVE: Pettitt p-value NA.\n")
    }
    
    # ---------- PHASE 3C ----------
    cat("--------------------------------------------------------------------------\n")
    cat("PHASE 3C: KPSS RE-CHECK BY SEGMENTS\n")
    cat("  • Segment 1 = [1 .. break]\n")
    cat("  • Segment 2 = [break+1 .. N]\n")
    cat(sprintf("  - KPSS p-value (Segment 1): %s\n", ifelse(is.finite(seg1_p), fmt_num(seg1_p, 6), "NA")))
    cat(sprintf("  - KPSS p-value (Segment 2): %s\n", ifelse(is.finite(seg2_p), fmt_num(seg2_p, 6), "NA")))
    cat("\n INTERPRETATION:\n")
    if (is.finite(seg1_p) && is.finite(seg2_p)) {
      if (seg1_p >= alpha_val && seg2_p >= alpha_val)
        cat("  [✓] Both segments look stationary by KPSS.\n      -> Full-sample non-stationarity may be break-driven.\n")
      else if (seg1_p < alpha_val && seg2_p < alpha_val)
        cat("  [X] Both segments look non-stationary by KPSS.\n")
      else
        cat("  [?] Mixed evidence: one segment stationary, the other not.\n")
    } else {
      cat("  [?] Segment KPSS not available (short segments or missing package).\n")
    }
    
    # ---------- PHASE 4: Final verdict & advice ----------
    cat("\n==========================================================================\n")
    cat("PHASE 4: FINAL ACADEMIC VERDICT & ADVICE\n")
    cat("==========================================================================\n")
    if (adf_stationary && kpss_stationary) {
      cat(" [✓] VERDICT: CONVERGENT STATIONARITY (ADF & KPSS agree; residuals likely white).\n")
      cat("     ADVICE: Proceed with SARIMA identification with d=0 (choose D via seasonality), then residual checks.\n")
    } else if (!adf_stationary && !kpss_stationary) {
      cat(" [X] VERDICT: CONVERGENT NON-STATIONARITY (ADF & KPSS agree).\n")
      cat("     ADVICE: Difference the series (d=1). If seasonal (m≥2), consider D=1, then re-run tests.\n")
    } else {
      cat(" [?] VERDICT: CONFLICTING RESULTS (ADF vs KPSS).\n")
      cat("     ADVICE: Near-unit-root, trend-vs-drift mismatch, or break contamination are common causes.\n")
      cat("             Use PHASE 0 to pick k/type with LB ok and stable decisions; consider seasonal differencing and break handling.\n")
    }
    
    # ---------- Technical appendix: ADF regression coefficients ----------
    cat("\n TECHNICAL APPENDIX (ADF Regression Coefficients):\n")
    if (!is.null(ur) && !is.null(ur@testreg)) {
      cf <- tryCatch(coef(summary(ur@testreg)), error = function(e) NULL)
      if (!is.null(cf)) {
        printCoefmat(cf, digits = 7, signif.stars = FALSE, P.values = TRUE, has.Pvalue = TRUE)
      } else {
        cat("  (coefficients unavailable)\n")
      }
    } else {
      cat("  (ADF regression unavailable)\n")
    }
    
    # ---------- PHASE 5: Evidence snapshot & checklist ----------
    cat("\n==========================================================================\n")
    cat("PHASE 5: POST-SUMMARY (Academic-quality snapshot)\n")
    cat("==========================================================================\n")
    cat(" EVIDENCE SNAPSHOT (All key outcomes in one place):\n")
    cat(sprintf(" [ ] N (effective sample size)              : %s\n", N))
    cat(sprintf(" [ ] Model type (ADF)                       : %s  (tau row: %s)\n", tolower(type_in), tau_row))
    cat(sprintf(" [ ] Lag order (k)                          : %s\n", k))
    cat(sprintf(" [ ] Alpha (α)                              : %s\n", fmt_num(alpha_val, 4)))
    cat(sprintf(" [ ] Tau-Observed (urca)                    : %s\n", fmt_num(tau_obs, 6)))
    cat(sprintf(" [ ] Tau-Critical (urca, %s)                  : %s\n", alpha_col, fmt_num(tau_crit, 6)))
    cat(sprintf(" [ ] ADF p-value (tseries reference)        : %s\n", ifelse(is.finite(adf_p), fmt_num(adf_p, 6), "NA")))
    cat(sprintf(" [ ] Ljung-Box p-value (residuals)          : %s\n", fmt_num(lb_p, 6)))
    cat(sprintf(" [ ] KPSS Eta observed (urca)               : %s\n", fmt_num(eta_obs_uc, 6)))
    cat(sprintf(" [ ] KPSS Eta critical (urca, %s)             : %s\n", eta_col, fmt_num(eta_crit_uc, 6)))
    cat(sprintf(" [ ] KPSS p-value (one-tailed, tseries)     : %s\n", ifelse(is.finite(kpss_p), fmt_num(kpss_p, 6), "NA")))
    cat(sprintf(" [!] Suggested k* (scan)                     : %s\n", ifelse(is.finite(k_suggest), k_suggest, "NA")))
    cat("--------------------------------------------------------------------------\n")
    cat(" CHECKLIST (Academic-quality acceptance criteria):\n")
    cat(sprintf(" [ ] Tests run on transformed series (x=myData_Choice) : %s YES (same x used everywhere)\n", tick(TRUE)))
    cat(sprintf(" [ ] Variance usable (sd>0)                          : %s SATISFIED\n", tick(TRUE)))
    cat(sprintf(" [ ] Tau is finite and usable                        : %s %s\n", tick(is.finite(tau_obs)), ifelse(is.finite(tau_obs),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] Tau critical value extracted                    : %s %s\n", tick(is.finite(tau_crit)), ifelse(is.finite(tau_crit),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] Residuals pass Ljung-Box (white noise)          : %s %s\n", tick(is.finite(lb_p) && lb_p > alpha_val), ifelse(is.finite(lb_p) && lb_p > alpha_val,"SATISFIED","CHECK")))
    cat(sprintf(" [ ] KPSS Eta observed & critical are usable         : %s %s\n", tick(is.finite(eta_obs_uc) && is.finite(eta_crit_uc)), ifelse(is.finite(eta_obs_uc) && is.finite(eta_crit_uc),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] KPSS p-value is usable                          : %s %s\n", tick(is.finite(kpss_p)), ifelse(is.finite(kpss_p),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] Sample size adequacy                            : %s STRONG\n", tick(N >= 50)))
    cat(sprintf(" [ ] Lag order reasonable relative to N              : %s %s\n", tick(k <= max(12L, floor(N/10))), ifelse(k <= max(12L, floor(N/10)),"OK","LARGE")))
    cat(sprintf(" [ ] Seasonal differencing indicated (UI D>0)         : %s %s\n", warn(isTRUE(to_int_safe(D_in,0L) > 0)), ifelse(isTRUE(to_int_safe(D_in,0L) > 0),"YES","NO / UNKNOWN")))
    cat(sprintf(" [ ] ADF alternative mode (Stationary/Explosive)      : %s\n", paste0(ifelse(is.null(alt_in),"NA",alt_in))))
    cat(sprintf(" [ ] ADF & KPSS agreement                             : %s %s\n",
                qmark(agreement), ifelse(agreement,"AGREEMENT","CONFLICT")))
    cat("     [?] NOTE: conflicts are common with near-unit-root series, trend vs drift mismatch,\n")
    cat("         structural breaks (Pettitt), or missing seasonal differencing.\n")
    cat("--------------------------------------------------------------------------\n")
    cat(" STRUCTURAL BREAK SUMMARY (Pettitt):\n")
    cat(sprintf(" [ ] Pettitt p-value : %s  (Reject H0 if < α)\n", ifelse(is.finite(pett_p), fmt_num(pett_p, 6), "NA")))
    cat("--------------------------------------------------------------------------\n")
    cat("==========================================================================\n")
    cat(" ACTIONABLE NEXT STEPS (What to do now):\n")
    cat("==========================================================================\n")
    cat(sprintf(" %s [1] RESIDUAL AUTOCORRELATION CHECK\n", tick(is.finite(lb_p) && lb_p > alpha_val)))
    cat("     • Ljung-Box is acceptable → ADF regression is less likely biased.\n")
    cat(" [?] [2] RESOLVE ADF vs KPSS CONFLICT\n")
    cat("     • Use PHASE 0 'ADF SPEC SENSITIVITY' to pick the type with LB ok and stable decision.\n")
    cat("     • Try ADF model type variants: none / drift / trend (match KPSS Level vs Trend).\n")
    cat("     • If Pettitt indicates a break: split sample and re-test.\n")
    cat("     • If series is seasonal: test after seasonal differencing (D=1) + maybe log.\n")
    cat("     • Consider variance stabilization: log or Box-Cox (if positive data).\n")
    cat(" [!] [3] SEASONALITY SANITY (especially for AirPassengers-like series)\n")
    if (is.finite(x_freq) && x_freq >= 2) {
      cat(sprintf("     • Detected frequency=%d → seasonality is plausible.\n", x_freq))
    } else {
      cat("     • Frequency unknown → inspect ACF/PACF for seasonal spikes.\n")
    }
    cat(" [✓] [4] EXPLOSIVE MODE NOTE\n")
    cat(sprintf("     • %s\n", ifelse(identical(alt_in,"explosive"),
                                      "Explosive alternative was requested; interpret ADF accordingly.",
                                      "Not in explosive mode → standard stationarity workflow applies.")))
    cat("\n PRACTICAL MODELING PATH (for your Shiny workflow):\n")
    if (!adf_stationary || !kpss_stationary) {
      cat(" [X] Apply differencing (d and/or D) → re-run ADF/KPSS → then identify ARMA.\n")
    } else {
      cat(" [✓] Keep d=0 (and decide D via seasonality) → SARIMA identification and residual diagnostics.\n")
    }
    cat("--------------------------------------------------------------------------\n")
  })
  
  
 
  
  
  
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  
  
  output$CHECKLIST <- renderPrint({
    
    # ============================================================================
    # 0) SMALL HELPERS
    # ============================================================================
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0 && !all(is.na(a))) a else b
    
    to_num_safe <- function(v, default = NA_real_) {
      out <- suppressWarnings(as.numeric(v))
      if (length(out) == 0 || all(is.na(out)) || !is.finite(out[1])) default else out[1]
    }
    
    to_int_safe <- function(v, default = 0L) {
      out <- suppressWarnings(as.integer(v))
      if (length(out) == 0 || is.na(out[1]) || !is.finite(out[1])) default else out[1]
    }
    
    safe_head_tail <- function(x, n = 5) {
      x <- as.numeric(x)
      x <- x[is.finite(x)]
      if (length(x) == 0) return(list(head = numeric(0), tail = numeric(0)))
      list(head = head(x, n), tail = tail(x, n))
    }
    
    # Robust extractor for urca @cval (vector OR matrix; row/col name variations)
    get_uc_cval <- function(cv, key) {
      if (is.null(cv) || is.null(key) || !nzchar(key)) return(NA_real_)
      
      if (is.matrix(cv)) {
        if (!is.null(colnames(cv)) && key %in% colnames(cv)) return(as.numeric(cv[1, key]))
        if (!is.null(rownames(cv)) && key %in% rownames(cv)) return(as.numeric(cv[key, 1]))
        
        if (!is.null(colnames(cv))) {
          m <- which(grepl(key, colnames(cv), fixed = TRUE))
          if (length(m) > 0) return(as.numeric(cv[1, m[1]]))
        }
        if (!is.null(rownames(cv))) {
          m <- which(grepl(key, rownames(cv), fixed = TRUE))
          if (length(m) > 0) return(as.numeric(cv[m[1], 1]))
        }
        return(NA_real_)
      }
      
      nm <- names(cv)
      if (!is.null(nm) && key %in% nm) return(as.numeric(cv[[key]]))
      if (!is.null(nm)) {
        m <- which(grepl(key, nm, fixed = TRUE))
        if (length(m) > 0) return(as.numeric(cv[[m[1]]]))
      }
      NA_real_
    }
    
    # ============================================================================
    # 1) INPUT COLLECTION (supports either naming convention in your UI)
    # ============================================================================
    alt_in  <- input$alternd2St %||% input$alternSt
    lag_in  <- input$LagOrderADFd2St %||% input$LagOrderADFSt
    a_in    <- input$alphaSt2
    type_in <- input$adfTypeSt2
    
    # Optional transformation UI inputs (informational only)
    d_in   <- input$d_n  %||% input$d  %||% NA
    D_in   <- input$DS_n %||% input$D  %||% NA
    log_in <- input$check_box %||% input$islog %||% FALSE
    
    req(myData_Choice())
    
    if (is.null(alt_in) || is.null(lag_in) || is.null(a_in) || is.null(type_in)) {
      cat("==========================================================================\n")
      cat(" [!] INPUT ERROR: One or more inputs are NULL (likely UI/server ID mismatch)\n")
      cat("     Needed inputs:\n")
      cat("       - alternative : input$alternd2St OR input$alternSt\n")
      cat("       - lag         : input$LagOrderADFd2St OR input$LagOrderADFSt\n")
      cat("       - alpha       : input$alphaSt2\n")
      cat("       - adf type    : input$adfTypeSt2\n")
      cat("==========================================================================\n")
      return(invisible(NULL))
    }
    
    # ============================================================================
    # 2) DATA PREP
    # ============================================================================
    x_raw <- myData_Choice()
    na_before <- sum(is.na(x_raw))
    
    x_class <- paste(class(x_raw), collapse = ", ")
    x_freq  <- NA_integer_
    if (inherits(x_raw, "ts")) x_freq <- tryCatch(stats::frequency(x_raw), error = function(e) NA_integer_)
    
    x <- as.numeric(stats::na.omit(x_raw))
    valid_N <- length(x)
    
    k <- to_int_safe(lag_in, default = 0L)
    if (!is.finite(k) || k < 0) k <- 0L
    
    alpha_raw <- as.character(a_in)
    alpha_val <- to_num_safe(alpha_raw, default = 0.05)
    
    alpha_col <- switch(alpha_raw,
                        "0.01" = "1pct",
                        "0.05" = "5pct",
                        "0.1"  = "10pct",
                        "0.10" = "10pct",
                        "1pct" = "1pct",
                        "5pct" = "5pct",
                        "10pct"= "10pct",
                        "5pct")
    
    tau_row <- switch(type_in,
                      "none"  = "tau1",
                      "drift" = "tau2",
                      "trend" = "tau3",
                      "tau3")
    
    D_ui <- to_int_safe(D_in, default = 0L)
    seasonality_resolved <- isTRUE(D_ui > 0L)
    
    # Quick sanity exits (still only printing the 3 sections)
    if (valid_N < 5 || !is.finite(stats::sd(x)) || stats::sd(x) == 0) {
      cat("==========================================================================\n")
      cat(" CHECKLIST\n")
      cat("==========================================================================\n\n")
      cat(sprintf(" [ ] N (effective)                    : %d\n", valid_N))
      cat(sprintf(" [ ] Variance usable (sd>0)           : %s\n",
                  ifelse(is.finite(stats::sd(x)) && stats::sd(x) > 0, "[✓]", "[!]")))
      cat("--------------------------------------------------------------------------\n")
      cat(" FINAL ACADEMIC ADVICE\n")
      cat("--------------------------------------------------------------------------\n\n")
      if (valid_N < 5) {
        cat(" [!] Too few observations after transformation. Provide more data points.\n")
      } else {
        cat(" [!] Series is constant/invalid after transformation (sd=0/NA).\n")
        cat("     Fix data quality or transformation pipeline in myData_Choice().\n")
      }
      cat("--------------------------------------------------------------------------\n")
      cat(" ACTIONABLE NEXT STEPS\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" [!] [1] Verify myData_Choice() returns the transformed series (log/d/D).\n")
      cat(" [!] [2] Print/plot the transformed series to confirm it is not constant.\n")
      cat(" [!] [3] Re-run tests after fixing the above.\n")
      cat("==========================================================================\n")
      return(invisible(NULL))
    }
    
    # ============================================================================
    # 3) PREDECLARE OUTPUTS
    # ============================================================================
    res_urca <- NULL
    res_tseries <- list(p.value = NA_real_)
    lb_test <- list(statistic = NA_real_, p.value = NA_real_)
    lb_lag <- NA_integer_
    
    res_kpss_ts <- list(statistic = NA_real_, p.value = NA_real_)
    res_kpss_uc <- NULL
    
    tau_obs <- NA_real_
    tau_crit <- NA_real_
    
    eta_obs_uc <- NA_real_
    eta_crit_uc <- NA_real_
    eta_obs_ts <- NA_real_
    eta_p_one <- NA_real_
    eta_col <- NA_character_
    
    pettitt_res <- list(statistic = NA_real_, p.value = NA_real_, estimate = NULL)
    
    is_stationary <- FALSE
    kpss_stationary <- FALSE
    agreement_safe <- FALSE
    lb_white_safe <- FALSE
    
    # ============================================================================
    # 4) COMPUTE TESTS (no verbose phases; we only use results for the 3 outputs)
    # ============================================================================
    tryCatch({
      
      if (!requireNamespace("urca", quietly = TRUE)) stop("Package 'urca' missing. install.packages('urca')")
      if (!requireNamespace("tseries", quietly = TRUE)) stop("Package 'tseries' missing. install.packages('tseries')")
      
      # ADF (urca)
      res_urca <- urca::ur.df(x, type = type_in, lags = k)
      
      tau_obs <- suppressWarnings(as.numeric(res_urca@teststat[tau_row]))
      if (!is.finite(tau_obs)) {
        tau_obs_fallback <- suppressWarnings(as.numeric(res_urca@teststat[1]))
        if (is.finite(tau_obs_fallback)) tau_obs <- tau_obs_fallback
      }
      tau_crit <- suppressWarnings(as.numeric(res_urca@cval[tau_row, alpha_col]))
      
      # ADF p-value reference (tseries)
      if (valid_N > (k + 10)) {
        res_tseries <- tseries::adf.test(x, alternative = alt_in, k = k)
      }
      
      # Ljung-Box on ADF residuals
      lb_lag <- max(1L, min(10L, floor(valid_N / 5)))
      lb_test <- Box.test(res_urca@res, lag = lb_lag, type = "Ljung-Box")
      
      # KPSS (tseries p-value, urca cvals)
      kpss_type <- if (type_in == "trend") "Trend" else "Level"
      res_kpss_ts <- tseries::kpss.test(x, null = kpss_type)
      eta_obs_ts  <- to_num_safe(res_kpss_ts$statistic)
      eta_p_one   <- to_num_safe(res_kpss_ts$p.value)
      
      kpss_type_urca <- if (type_in == "trend") "tau" else "mu"
      res_kpss_uc    <- urca::ur.kpss(x, type = kpss_type_urca)
      
      eta_obs_uc <- suppressWarnings(as.numeric(res_kpss_uc@teststat))
      
      eta_col <- switch(alpha_raw,
                        "0.01" = "1pct",
                        "0.05" = "5pct",
                        "0.1"  = "10pct",
                        "0.10" = "10pct",
                        "1pct" = "1pct",
                        "5pct" = "5pct",
                        "10pct"= "10pct",
                        "5pct")
      
      eta_crit_uc <- suppressWarnings(get_uc_cval(res_kpss_uc@cval, eta_col))
      
      # Optional Pettitt
      if (requireNamespace("trend", quietly = TRUE)) {
        pettitt_res <- tryCatch(trend::pettitt.test(x),
                                error = function(e) list(statistic = NA_real_, p.value = NA_real_, estimate = NULL))
      }
      
      # Decisions
      tau_ok <- is.finite(tau_obs) && is.finite(tau_crit)
      lb_p   <- to_num_safe(lb_test$p.value)
      lb_ok  <- is.finite(lb_p)
      
      is_stationary <- isTRUE(tau_ok) && (tau_obs < tau_crit)
      
      # KPSS rejects stationarity if p<alpha OR eta_obs>eta_crit (when available)
      kpss_reject_by_p   <- is.finite(eta_p_one) && (eta_p_one < alpha_val)
      kpss_reject_by_eta <- is.finite(eta_obs_uc) && is.finite(eta_crit_uc) && (eta_obs_uc > eta_crit_uc)
      kpss_stationary <- !(kpss_reject_by_p || kpss_reject_by_eta)
      
      lb_white_safe <- lb_ok && (lb_p > alpha_val)
      
      agreement_safe <- (isTRUE(is_stationary) && isTRUE(kpss_stationary)) ||
        (isTRUE(!is_stationary) && isTRUE(!kpss_stationary))
      
    }, error = function(e) {
      cat("==========================================================================\n")
      cat(" CHECKLIST\n")
      cat("==========================================================================\n")
      cat(" [!] Execution error while computing tests:\n")
      cat("     ", e$message, "\n", sep = "")
      cat("--------------------------------------------------------------------------\n")
      cat(" FINAL ACADEMIC ADVICE\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" [!] Install/enable required packages and re-run.\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" ACTIONABLE NEXT STEPS\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" [!] [1] install.packages('urca') and install.packages('tseries')\n")
      cat(" [!] [2] Re-run after verifying myData_Choice() returns a numeric/ts vector.\n")
      cat("==========================================================================\n")
      return(invisible(NULL))
    })
    
    # ============================================================================
    # 5) OUTPUT ONLY: CHECKLIST, FINAL ACADEMIC ADVICE, ACTIONABLE NEXT STEPS
    # ============================================================================
    lb_p <- to_num_safe(lb_test$p.value)
    adf_p <- to_num_safe(res_tseries$p.value)
    pett_p <- to_num_safe(pettitt_res$p.value)
    
    # --------------------
    # CHECKLIST
    # --------------------
    cat("==========================================================================\n")
    cat(" CHECKLIST\n")
    cat("==========================================================================\n")
    
    # ht <- safe_head_tail(x, 5)
    
    # cat(sprintf(" [ ] N (effective)                              : %d\n", valid_N))
    # cat(sprintf(" [ ] ADF model type (none/drift/trend)          : %s\n", as.character(type_in)))
    # cat(sprintf(" [ ] Lag k                                      : %d\n", k))
    # cat(sprintf(" [ ] Alpha (α)                                  : %.4f\n", alpha_val))
    # cat(sprintf(" [ ] Data class                                 : %s\n", x_class))
    # cat(sprintf(" [ ] Frequency (if ts)                          : %s\n", ifelse(is.finite(x_freq), as.character(x_freq), "NA / not ts")))
    # cat(sprintf(" [ ] NA count before na.omit                     : %d\n", na_before))
    # cat(sprintf(" [ ] UI transform flags                          : log=%s | d=%s | D=%s\n",
    #             ifelse(isTRUE(log_in), "ON", "OFF"),
    #             ifelse(is.na(d_in), "NA", as.character(d_in)),
    #             ifelse(is.na(D_in), "NA", as.character(D_in))))
    # cat(sprintf(" [ ] First 5 values tested                       : %s\n", paste(round(ht$head, 4), collapse = ", ")))
    # cat(sprintf(" [ ] Last  5 values tested                       : %s\n", paste(round(ht$tail, 4), collapse = ", ")))
    # cat("--------------------------------------------------------------------------\n")
    
    # cat(sprintf(" [ ] ADF Tau observed is finite                  : %s\n", ifelse(is.finite(tau_obs), "[✓]", "[!]")))
    # cat(sprintf(" [ ] ADF Tau critical is finite                  : %s\n", ifelse(is.finite(tau_crit), "[✓]", "[!]")))
    # cat(sprintf(" [ ] Ljung-Box p-value is finite                 : %s\n", ifelse(is.finite(lb_p), "[✓]", "[!]")))
    # cat(sprintf(" [ ] KPSS Eta observed (urca) is finite          : %s\n", ifelse(is.finite(eta_obs_uc), "[✓]", "[!]")))
    # cat(sprintf(" [ ] KPSS Eta critical (urca) is finite          : %s\n", ifelse(is.finite(eta_crit_uc), "[✓]", "[!]" )))
    # cat(sprintf(" [ ] KPSS p-value (tseries) is finite            : %s\n", ifelse(is.finite(eta_p_one), "[✓]", "[!]" )))
    # cat("--------------------------------------------------------------------------\n")
    
    # Key decisions summary (compact)
    cat(sprintf(" [ ] ADF decision (reject unit root => stationary) : %s\n",
                ifelse(isTRUE(is_stationary), "[✓] STATIONARY", "[X] NON-STATIONARY")))
    cat(sprintf(" [ ] KPSS decision (fail reject => stationary)     : %s\n",
                ifelse(isTRUE(kpss_stationary), "[✓] STATIONARY", "[X] NON-STATIONARY")))
    cat(sprintf(" [ ] ADF vs KPSS agreement                         : %s\n",
                ifelse(isTRUE(agreement_safe), "[✓] AGREEMENT", "[?] CONFLICT")))
    cat(sprintf(" [ ] Residual whiteness (LB (Ljung–Box) p>α)       : %s\n",
                ifelse(is.finite(lb_p) && lb_p > alpha_val, "[✓] OK", ifelse(is.finite(lb_p), "[X] FAIL", "[?] UNKNOWN"))))
    cat(sprintf(" [ ] Seasonal differencing indicated (UI D>0)      : %s\n",
                ifelse(isTRUE(seasonality_resolved), "[✓] YES", "[!] NO / UNKNOWN")))
    cat(sprintf(" [ ] Pettitt break check available                 : %s\n",
                ifelse(requireNamespace("trend", quietly = TRUE), "[✓] YES", "[!] NO (trend pkg missing)")))
    # if (requireNamespace("trend", quietly = TRUE)) {
    #   cat(sprintf(" [ ] Pettitt p-value                               : %.6f\n", pett_p))
    # }
    
    cat("\n")
    
    # --------------------
    # FINAL ACADEMIC ADVICE
    # --------------------
    cat("==========================================================================\n")
    cat(" FINAL ACADEMIC ADVICE\n")
    cat("==========================================================================\n")
    cat("\n")
    # Explain conflict in a compact, decision-useful way
    if (isTRUE(agreement_safe) && isTRUE(is_stationary) && isTRUE(kpss_stationary)) {
      cat(" [✓] Strong evidence of stationarity (I(0)) from BOTH ADF and KPSS.\n")
      if (!(is.finite(lb_p) && lb_p > alpha_val)) {
        cat(" [!] But residual autocorrelation suggests your ADF lag may be too small.\n")
        cat("     Treat the ADF conclusion as less reliable until LB passes.\n")
      } else {
        cat(" [✓] Residuals are consistent with a well-specified ADF regression.\n")
      }
      cat("     Academic implication: proceed with ARMA/ARIMA using d=0 (and D as already applied).\n")
      
    } else if (isTRUE(agreement_safe) && !isTRUE(is_stationary) && !isTRUE(kpss_stationary)) {
      cat(" [X] Strong evidence of a unit root (non-stationarity) from BOTH tests.\n")
      cat("     Academic implication: apply differencing (d=1) and re-test.\n")
      if (is.finite(x_freq) && x_freq > 1 && !isTRUE(seasonality_resolved)) {
        cat(" [!] Seasonal frequency detected; consider seasonal differencing (D=1) before increasing k.\n")
      }
      
    } else {
      cat(" [?] ADF and KPSS are in conflict.\n")
      cat("     This is common when the series is near-unit-root, trend-stationary vs difference-stationary,\n")
      cat("     has structural breaks, seasonality not properly removed, or lag k is mis-specified.\n")
      
      if (requireNamespace("trend", quietly = TRUE) && is.finite(pett_p) && pett_p < alpha_val) {
        cat(" [!] Pettitt suggests a structural break (p < α). Breaks often cause ADF/KPSS disagreement.\n")
      }
      
      if (is.finite(x_freq) && x_freq > 1 && !isTRUE(seasonality_resolved)) {
        cat(" [!] Seasonal frequency detected but seasonal differencing is NOT indicated (D=0).\n")
        cat("     Unremoved seasonality often triggers KPSS non-stationarity while ADF looks borderline.\n")
      }
      
      if (is.finite(lb_p) && lb_p <= alpha_val) {
        cat(" [!] Ljung-Box fails => ADF regression residuals are autocorrelated; your ADF decision is less trustworthy.\n")
      }
      
      cat("     Academic implication: be conservative—prefer differencing (and/or D=1 if seasonal), then re-test.\n")
    }
    
    cat(sprintf("\n (Numbers) ADF tau=%.6f | tau_crit=%.6f | ADF p(ref)=%.6f\n", tau_obs, tau_crit, adf_p))
    cat(sprintf("           KPSS eta_obs=%.6f | eta_crit=%.6f | KPSS p=%.6f\n", eta_obs_uc, eta_crit_uc, eta_p_one))
    cat(sprintf("           LB (the Ljung–Box Q test) p=%.6f (lag=%s)\n", lb_p, ifelse(is.finite(lb_lag), as.character(lb_lag), "NA")))
    cat("            |__ it’s normal to choose LB lag by a rule-of-thumb (like min(10, floor(N/5)) \n")
    cat("\n")
    
    # --------------------
    # ACTIONABLE NEXT STEPS
    # --------------------
    cat("==========================================================================\n")
    cat(" ACTIONABLE NEXT STEPS\n")
    cat("==========================================================================\n")
    
    
    # [1] Residual autocorrelation
    cat("\n")
    if (is.finite(lb_p) && lb_p <= alpha_val) {
      cat(" [X] [1] FIX RESIDUAL AUTOCORRELATION (LB failed)\n")
      cat("     • Increase k gradually (k+1, k+2) and re-run.\n")
      cat("     • If k becomes large vs N, prefer (d=1) and/or (D=1 if seasonal) instead of pushing k.\n")
    } else if (is.finite(lb_p) && lb_p > alpha_val) {
      cat(" [✓] [1] RESIDUALS LOOK OK (LB passed)\n")
      cat("     • Your ADF regression is less likely biased by autocorrelation.\n")
    } else {
      cat(" [?] [1] RESIDUAL DIAGNOSTICS INCONCLUSIVE\n")
      cat("     • LB p-value is NA/Inf. Reduce k and re-run; verify x is not pathological.\n")
    }
    
    # [2] Agreement vs conflict
    cat("\n")
    if (!isTRUE(agreement_safe)) {
      cat(" [?] [2] RESOLVE THE ADF vs KPSS CONFLICT\n")
      cat("     • Re-test ADF with model types: none / drift / trend (choose what your plot suggests).\n")
      cat("     • If seasonal frequency exists, try D=1 (seasonal differencing) before debating k.\n")
      cat("     • If series is strictly positive, try log or Box-Cox for variance stabilization.\n")
      if (requireNamespace("trend", quietly = TRUE)) {
        if (is.finite(pett_p) && pett_p < alpha_val) {
          cat("     • Break detected: split sample around the break and re-run KPSS/ADF on each segment.\n")
        } else {
          cat("     • No strong break evidence at α: focus on model type (trend/drift) + seasonality + k.\n")
        }
      } else {
        cat("     • Install 'trend' to check breaks: install.packages('trend')\n")
      }
    } else {
      cat(" [✓] [2] TESTS AGREE — MOVE FORWARD\n")
      cat("     • Use this decision to pick d (and D if seasonal) for ARIMA/SARIMA modeling.\n")
    }
    
    # [3] Seasonality sanity with required rule: [✓] if resolved, else [!]
    cat("\n")
    season_tag <- if (isTRUE(seasonality_resolved)) "[✓]" else "[!]"
    cat(sprintf(" %s [3] SEASONALITY SANITY\n", season_tag))
    if (is.finite(x_freq) && x_freq > 1) {
      cat(sprintf("     • Frequency=%d detected.\n", x_freq))
      if (isTRUE(seasonality_resolved)) {
        cat("     • D>0 in UI indicates seasonality treatment is ON (as long as myData_Choice() applies it).\n")
      } else {
        cat("     • Consider D=1 if ACF shows seasonal spikes at lag = frequency, 2*frequency, ...\n")
      }
    } else {
      cat("     • Frequency not available: rely on plot/ACF to decide if seasonal differencing is needed.\n")
    }
    
    # [4] Explosive note
    cat("\n")
    if (identical(as.character(alt_in), "explosive")) {
      cat(" [!] [4] EXPLOSIVE MODE NOTE\n")
      cat("     • KPSS is not an explosive test. Use tseries ADF p-value + plots.\n")
    } else {
      cat(" [✓] [4] EXPLOSIVE MODE NOTE\n")
      cat("     • Standard stationarity workflow applies.\n")
    }
    
    
    
    # --------------------------------------------------------------------------
    # EXTRA ACTIONABLE NEXT STEPS (more complete workflow)
    # --------------------------------------------------------------------------
    
    # [5] Choose ADF model type systematically (avoid random picking)
    cat("\n")
    cat(" [!] [5] CHOOSE ADF MODEL TYPE SYSTEMATICALLY (avoid mis-specification)\n")
    cat("     • Use your time plot:\n")
    cat("       - Clear deterministic trend  → set type='trend'\n")
    cat("       - No clear trend, non-zero mean → set type='drift'\n")
    cat("       - Mean around ~0 (rare)      → set type='none'\n")
    cat("     • Wrong type_in is a top cause of ADF vs KPSS conflict.\n")
    
    # [6] Lag strategy: use Ljung-Box as your guardrail
    cat("\n")
    cat(" [!] [6] USE LB AS A LAG-SELECTION GUARDRAIL\n")
    cat("     • Increase k until LB p-value > α (residuals approx. white).\n")
    cat("     • Stop increasing k if N becomes too small relative to k (risk: N <= k+10).\n")
    cat("     • If you hit that risk, prefer differencing (d or D) instead of more k.\n")
    
    # [7] Seasonality protocol (if frequency known)
    cat("\n")
    if (is.finite(x_freq) && x_freq > 1) {
      cat(" [!] [7] SEASONALITY PROTOCOL (freq detected)\n")
      cat("     • Check ACF for spikes at seasonal lags: freq, 2*freq, ...\n")
      if (isTRUE(seasonality_resolved)) {
        cat("     [✓] D>0 indicated → ensure myData_Choice() truly applied seasonal differencing.\n")
      } else {
        cat("     [X] D=0 indicated → if seasonal spikes exist, set D=1 and re-test.\n")
      }
    }
    
    # [8] Break protocol (if Pettitt available)
    cat("\n")
    if (requireNamespace("trend", quietly = TRUE)) {
      cat(" [!] [8] BREAK PROTOCOL (Pettitt)\n")
      if (is.finite(pett_p) && (pett_p < alpha_val)) {
        cat("     [!] Break detected → do this:\n")
        cat("       1) Split the series around the estimated break index.\n")
        cat("       2) Re-run KPSS/ADF on each segment.\n")
        cat("       3) If segments are stationary but full sample is not → break-driven non-stationarity.\n")
      } else {
        cat("     [✓] No strong single-break evidence at α.\n")
        cat("     • If conflict persists, consider multiple breaks or gradual regime changes.\n")
      }
    } else {
      cat(" [!] [8] BREAK PROTOCOL (Pettitt)\n")
      cat("     [!] trend package not installed → install.packages('trend') to enable break diagnostics.\n")
    }
    
    # [9] Conservative “default safe choice” rule (useful in teaching apps)
    cat("\n")
    cat(" [!] [9] DEFAULT SAFE CHOICE (when unsure)\n")
    cat("     • If ADF/KPSS conflict persists after fixing seasonality + lag:\n")
    cat("       - Prefer differencing (d=1) (and D=1 if seasonal) then re-test.\n")
    cat("     • This reduces the chance of building ARMA on a near-integrated series.\n")
    
    # [10] Sanity check transformations inside myData_Choice()
    cat("\n")
    cat(" [!] [10] TRANSFORMATION SANITY INSIDE myData_Choice()\n")
    cat("     • Ensure the same transformed object is returned for ALL downstream tests.\n")
    cat("     • Avoid mixing ts and numeric conversions before applying frequency-based operations.\n")
    cat("     • After log, verify positivity and handle zeros (e.g., log1p) if needed.\n")
    
    
    cat("==========================================================================\n\n")
    
    # --------------------------------------------------------------------------
    # EXTRA FINAL ACADEMIC ADVICE (more complete decision logic)
    # --------------------------------------------------------------------------
    
    # Power / sample size warnings (high impact)
    if (valid_N < 30) {
      cat(" [!] Power warning: with N < 30, ADF/KPSS can be unstable (low power / size distortions).\n")
      if (valid_N < 15) {
        cat("     [X] N < 15 is very weak for reliable inference; treat conclusions as provisional.\n")
      } else {
        cat("     [?] N is borderline; combine with plots + conservative transformations.\n")
      }
    } else {
      cat(" [✓] Sample size is generally adequate for classical stationarity tests.\n")
    }
    
    # Lag-vs-N safety
    if (valid_N <= (k + 10)) {
      cat(" [!] Lag risk: k is large relative to N (N <= k+10). Regression-based tests may misbehave.\n")
      cat("     Action: reduce k OR increase N, and prefer differencing/seasonal differencing over huge k.\n")
    } else {
      cat(" [✓] Lag order looks safe relative to N.\n")
    }
    
    # Model-type specification advice (none/drift/trend)
    cat(" [!] Model-type (none/drift/trend) matters:\n")
    cat("     • If the series has a visible non-zero mean but no deterministic trend → prefer 'drift'.\n")
    cat("     • If the series has a clear deterministic trend → prefer 'trend'.\n")
    cat("     • If the series oscillates around zero (rare in real data) → 'none'.\n")
    
    # Seasonality: warn if frequency exists but D not indicated
    if (is.finite(x_freq) && x_freq > 1 && !isTRUE(seasonality_resolved)) {
      cat(" [!] Seasonality risk: frequency suggests seasonality, but D=0 in UI.\n")
      cat("     Missing seasonal differencing can cause KPSS to reject stationarity and/or ADF to look borderline.\n")
    } else if (is.finite(x_freq) && x_freq > 1 && isTRUE(seasonality_resolved)) {
      cat(" [✓] Seasonality flag: D>0 in UI indicates seasonal treatment is intended.\n")
    }
    
    # Structural break contamination (Pettitt)
    if (requireNamespace("trend", quietly = TRUE) && is.finite(pett_p) && (pett_p < alpha_val)) {
      cat(" [!] Structural break contamination: Pettitt indicates a change-point (p < α).\n")
      cat("     ADF/KPSS disagreements are common under breaks; consider segment tests or break-aware models.\n")
    }
    
    # Near-unit-root / borderline zone heuristic
    # (We don't have direct 'borderline' threshold universally, so we use agreement + p-values)
    if (!isTRUE(agreement_safe) && is.finite(adf_p) && is.finite(eta_p_one)) {
      if (adf_p > 0.01 && adf_p < 0.10 && eta_p_one > 0.01 && eta_p_one < 0.10) {
        cat(" [?] Near-unit-root zone: both tests are near typical cutoffs.\n")
        cat("     Treat the series as highly persistent; prefer conservative differencing and validate by forecasting performance.\n")
      }
    }
    
    # Explosive alternative caveat (important correctness note)
    if (identical(as.character(alt_in), "explosive")) {
      cat(" [!] Explosive caveat: urca tau critical values are for the usual left-tail unit-root framework.\n")
      cat("     For explosive detection, rely primarily on tseries::adf.test p-value (right-tail) + plots.\n")
    }
    
    
    cat("==========================================================================\n\n")
    
    # Practical path
    cat(" PRACTICAL MODELING PATH:\n")
    if (isTRUE(is_stationary) && is.finite(lb_p) && (lb_p > alpha_val)) {
      cat(" [✓] Treat as I(0): identify ARMA on current series → fit → residual analysis.\n")
    } else if (!isTRUE(is_stationary)) {
      cat(" [X] Treat as I(1): apply differencing (d and/or D) → re-test → then identify ARMA.\n")
    } else {
      cat(" [?] Borderline/mixed: prefer conservative differencing and validate with residual diagnostics.\n")
    }
    
    cat("==========================================================================\n\n")
    
    
    
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  #
  #                          - HELP -
  #
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  
  
  # ---- Roadmap Detailed & teaching notes ----
  
  
  output$roadmap_Detailed_Ang_ui <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      tags$hr(),
      
      tags$p(
        "Below is a ",
        tags$b("practical, SARIMA Modeling roadmap"),
      ),
      
      tags$hr(),
      
      tags$h4("[0] - Set the stage: define the modeling problem"),
      
      tags$h5("What students do"),
      tags$ul(
        tags$li("Define the ", tags$b("response series"), " (y_t) (what you forecast)."),
        tags$li("Define the ", tags$b("time index"), " (daily/weekly/monthly), and confirm it’s consistent."),
        tags$li(
          "Define the ", tags$b("forecast task"), ":",
          tags$ul(
            tags$li("horizon (e.g., 12 months ahead),"),
            tags$li("evaluation scheme (rolling-origin or simple train/test split),"),
            tags$li("loss metric (MAE/RMSE/MAPE/sMAPE).")
          )
        ),
        tags$li(
          "Decide whether you’ll model in:",
          tags$ul(
            tags$li(tags$b("levels"), " (raw data),"),
            tags$li(tags$b("log-levels"), " (common if variance grows with level),"),
            tags$li(tags$b("Box–Cox"), " transformed space (more general).")
          )
        )
      ),
      
      tags$h5("What they write (paper)"),
      tags$p(
        tags$b("Methods (Data & Objective). "),
        "“We modeled the univariate time series (y_t) observed at a [monthly] frequency from [start] to [end] (n=...). ",
        "The objective was to forecast (h=...) steps ahead. Model performance was evaluated using [metric(s)] under a ",
        "[train/test or rolling-origin] evaluation design.”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("SARIMA assumes ", tags$b("regular spacing"), "; irregular timestamps need fixing before anything else."),
        tags$li("SARIMA models ", tags$b("one series"), " (no predictors). If you have external regressors, that’s SARIMAX.")
      ),
      
      tags$hr(),
      
      tags$h4("[1] - Describe the data: sample size, missing values, descriptive statistics"),
      
      tags$h5("What students do"),
      tags$ol(
        tags$li(
          "Report:",
          tags$ul(
            tags$li("sample size (n),"),
            tags$li("start/end dates,"),
            tags$li("frequency,"),
            tags$li("number/percent missing values.")
          )
        ),
        tags$li(
          "Handle missingness:",
          tags$ul(
            tags$li("If rare and random: impute (linear interpolation, seasonal interpolation)."),
            tags$li("If many: reconsider the series, frequency, or data source.")
          )
        ),
        tags$li(
          "Descriptive stats:",
          tags$ul(
            tags$li("mean, median, sd, min/max,"),
            tags$li("maybe skewness/kurtosis,"),
            tags$li("and seasonal summaries (e.g., average by month).")
          )
        )
      ),
      
      tags$h5("What they write (APA-style)"),
      tags$p(
        tags$b("Results (Data description). "),
        "“The series contained (n=...) observations spanning [dates] at a [frequency] frequency. ",
        "Missing values accounted for (...%) of observations (k=... points). Missing observations were handled using ",
        "[method], selected because [reason]. The distribution of (y_t) showed a mean of (...) (SD=(...)), median (...), ",
        "and range ([...,...]).”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("Don’t “silently” impute—", tags$b("always justify"), " it."),
        tags$li("If you log-transform, describe the transformed series stats too.")
      ),
      
      tags$hr(),
      
      tags$h4("[2] - Explore visually: trend/seasonality/outliers; report observations"),
      
      tags$h5("What students do"),
      tags$p("Make plots and annotate:"),
      tags$ul(
        tags$li(tags$b("Line plot"), " of (y_t)."),
        tags$li(tags$b("Seasonal plot"), " (e.g., month-of-year lines)."),
        tags$li(tags$b("Boxplot by season"), " (month/quarter/week)."),
        tags$li(
          tags$b("Outlier check"), ":",
          tags$ul(
            tags$li("z-scores, IQR rule, or robust methods,"),
            tags$li("but also context (holidays, policy changes, measurement glitches).")
          )
        )
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Results (Exploratory analysis). "),
        "“Visual inspection indicated [an upward/downward] trend and recurring seasonal fluctuations with period (s=...). ",
        "Variability appeared [constant/increasing with level], suggesting [no transformation / log transformation]. ",
        "Several potential outliers were observed around [dates], likely associated with [context], and were ",
        "[retained/adjusted] because [reason].”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("Outliers aren’t automatically “bad”—they might be real events that your forecast must respect."),
        tags$li("If variance grows with level, SARIMA often behaves better after a ", tags$b("log"), " or ", tags$b("Box–Cox"), " transform.")
      ),
      
      tags$hr(),
      
      tags$h4("[3] - Decompose: justify additive vs multiplicative; use STL when robust needed"),
      
      tags$h5("What students do"),
      tags$p("Perform decomposition to separate:"),
      tags$ul(
        tags$li("trend,"),
        tags$li("seasonality,"),
        tags$li("remainder.")
      ),
      
      tags$p(tags$b("Choose model form:")),
      tags$ul(
        tags$li(tags$b("Additive:"), " (y_t = T_t + S_t + e_t). Use when seasonal amplitude is roughly constant."),
        tags$li(tags$b("Multiplicative:"), " (y_t = T_t × S_t × e_t). Use when seasonal amplitude grows with the level (often solved by log transform → additive in log space).")
      ),
      
      tags$p(tags$b("Use STL decomposition when:")),
      tags$ul(
        tags$li("seasonality changes slowly over time,"),
        tags$li("you want robustness to outliers.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Decomposition). "),
        "“We assessed additive versus multiplicative structure by examining whether seasonal amplitude scaled with the series level. ",
        "Because [seasonal variation was approximately constant / increased with level], we used an [additive model / log transformation] ",
        "and decomposed the series using [classical decomposition / STL]. STL was selected due to its robustness to outliers and its flexibility ",
        "in modeling evolving seasonality.”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("“Multiplicative seasonality” and “log transform” are basically best friends."),
        tags$li("STL decomposition is descriptive; SARIMA fitting still needs stationarity checks.")
      ),
      
      tags$hr(),
      
      tags$h4("[4] - Check stationarity: ADF/KPSS/PP; justify differencing (d and D)"),
      tags$p("SARIMA needs stationarity ", tags$b("after differencing"), "."),
      
      tags$h5("What students do"),
      tags$ol(
        tags$li("Define seasonal period (s) (e.g., 12 for monthly, 7 for daily-with-weekly seasonality)."),
        tags$li(
          "Test stationarity on:",
          tags$ul(
            tags$li("original series,"),
            tags$li("after ", tags$b("regular differencing"), " ((1-B)^d),"),
            tags$li("after ", tags$b("seasonal differencing"), " ((1-B^s)^D),"),
            tags$li("and sometimes after both.")
          )
        )
      ),
      
      tags$h5("Stationarity tests: what they do, H0/Ha, and how to conclude"),
      tags$ul(
        
        tags$li(
          tags$b("ADF test (Augmented Dickey–Fuller)"),
          tags$ul(
            tags$li(tags$b("What it does:"), " tests whether the series behaves like it has a ", tags$b("unit root"),
                    " (a stochastic trend), which implies non-stationarity; the test estimates a regression where lagged differences are added to handle autocorrelation."),
            tags$li(tags$b("H0:"), " the series has a unit root (non-stationary; shocks have permanent effects)."),
            tags$li(tags$b("Ha:"), " the series does not have a unit root (stationary around a mean or around a deterministic trend, depending on the ADF specification)."),
            tags$li(tags$b("Conclusion sentence template:"), " “The ADF test yielded p = [p-value]; therefore, at α = [alpha] we ",
                    tags$b("[reject / fail to reject]"), " H0 that the series contains a unit root. This implies the series is ",
                    tags$b("[stationary / non-stationary]"), " under the ADF framework, so we ",
                    tags$b("[did not apply additional differencing / applied]"), " [d=…] regular and/or [D=…] seasonal differencing to obtain an approximately stationary series suitable for SARIMA estimation.”")
          )
        ),
        
        tags$li(
          tags$b("KPSS test (Kwiatkowski–Phillips–Schmidt–Shin)"),
          tags$ul(
            tags$li(tags$b("What it does:"), " tests stationarity by examining whether the cumulative sum of residuals (from a level or trend regression) is too large; it is designed as a complement to ADF by flipping the null hypothesis."),
            tags$li(tags$b("H0:"), " the series is stationary (level-stationary, or trend-stationary if a trend is included)."),
            tags$li(tags$b("Ha:"), " the series is non-stationary (contains a unit root or otherwise violates stationarity)."),
            tags$li(tags$b("Conclusion sentence template:"), " “The KPSS test produced p = [p-value]; thus, at α = [alpha] we ",
                    tags$b("[reject / fail to reject]"), " H0 of stationarity. This indicates the series is ",
                    tags$b("[not stationary / consistent with stationarity]"), " in the KPSS sense, which ",
                    tags$b("[supports applying / does not require]"), " additional differencing; we therefore selected differencing orders [d=…] and [D=…] and rechecked stationarity on the transformed series.”")
          )
        ),
        
        tags$li(
          tags$b("PP test (Phillips–Perron)"),
          tags$ul(
            tags$li(tags$b("What it does:"), " tests for a unit root like ADF, but uses a nonparametric correction for autocorrelation and heteroskedasticity in the errors (instead of adding many lagged difference terms)."),
            tags$li(tags$b("H0:"), " the series has a unit root (non-stationary)."),
            tags$li(tags$b("Ha:"), " the series does not have a unit root (stationary)."),
            tags$li(tags$b("Conclusion sentence template:"), " “The PP test returned p = [p-value]; accordingly, at α = [alpha] we ",
                    tags$b("[reject / fail to reject]"), " H0 of a unit root. Interpreted alongside ADF and KPSS results, this suggests the series is ",
                    tags$b("[stationary / non-stationary]"), " after applying [d=…] regular and [D=…] seasonal differences, supporting the use of SARIMA on the differenced series.”")
          )
        )
      ),
      
      tags$p(
        tags$b("How to interpret ADF/KPSS/PP together (the logic students should write).")
      ),
      tags$ul(
        tags$li(tags$b("Best-case agreement:"), " ADF/PP reject unit root (small p) and KPSS fails to reject stationarity (large p) → strong evidence of stationarity."),
        tags$li(tags$b("Clear non-stationarity:"), " ADF/PP fail to reject unit root (large p) and KPSS rejects stationarity (small p) → strong evidence you need differencing."),
        tags$li(tags$b("Conflicts happen:"), " when tests disagree, prioritize the combination of evidence: plots + ACF behavior + results after differencing, and report that conclusions were based on the converging pattern rather than a single p-value.")
      ),
      
      tags$p(tags$b("Differencing logic:")),
      tags$ul(
        tags$li("Choose ", tags$b("d"), " to remove trend / unit root."),
        tags$li("Choose ", tags$b("D"), " to remove seasonal unit root."),
        tags$li("Stop as soon as stationarity is reasonable; avoid over-differencing.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Stationarity and differencing). "),
        "“Stationarity was assessed using ADF, KPSS, and PP tests to triangulate evidence because the tests use different null hypotheses. ",
        "Based on the combined results and visual diagnostics, we selected [d=...] regular differences and [D=...] seasonal differences with seasonal period (s=...). ",
        "This differencing order was chosen to remove [trend/seasonal unit root] while avoiding over-differencing, and stationarity was re-evaluated on the transformed series before fitting SARIMA models.”"
      ),
      
      tags$h5("Pitfalls (classic)"),
      tags$ul(
        tags$li(
          tags$b("Over-differencing"),
          " causes:",
          tags$ul(
            tags$li("strong negative lag-1 autocorrelation,"),
            tags$li("inflated variance,"),
            tags$li("messier forecasts.")
          )
        ),
        tags$li("D is usually ", tags$b("0 or 1"), " in real life. If you need (D=2), the series may be weird or the seasonal period is wrong.")
      ),
      
      tags$hr(),
      
      tags$h4("[5] - Fit a baseline model: Auto-ARIMA to obtain a strong starting SARIMA"),
      
      tags$h5("What students do"),
      tags$ul(
        tags$li("Use an ", tags$b("auto-ARIMA"), " procedure (AICc-based or similar) to propose: ((p,d,q)(P,D,Q)_s)."),
        tags$li(
          "Keep track of:",
          tags$ul(
            tags$li("transformations used,"),
            tags$li("constraints (max p/q etc.),"),
            tags$li("whether stepwise search was used.")
          )
        ),
        tags$li(tags$b("Important:"), " Auto-ARIMA gives a baseline, not truth carved into granite.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Baseline model). "),
        "“A baseline SARIMA model was selected using an automated information-criterion approach (minimizing AICc) over candidate orders ((p,q,P,Q)) ",
        "subject to [bounds]. The chosen baseline specification was SARIMA((p,d,q)(P,D,Q)_s), which served as the reference model for subsequent theory-driven refinement.”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("Auto-ARIMA can pick models that are statistically fine but ", tags$b("hard to interpret"), " or slightly unstable."),
        tags$li("If your evaluation is forecast-focused, it’s okay to prefer ", tags$b("simpler"), " models with similar accuracy.")
      ),
      
      tags$hr(),
      
      tags$h4("[6] - Fit a theory-driven model: Manual SARIMA using ACF/PACF + tests"),
      
      tags$h5("What students do"),
      tags$p("Using the differenced series (after chosen (d, D)):"),
      tags$ol(
        tags$li("Plot ", tags$b("ACF/PACF"), "."),
        tags$li(
          "Propose candidate structures:",
          tags$ul(
            tags$li(
              "Nonseasonal:",
              tags$ul(
                tags$li("AR(p): PACF cuts off around p; ACF tails."),
                tags$li("MA(q): ACF cuts off around q; PACF tails.")
              )
            ),
            tags$li(
              "Seasonal:",
              tags$ul(
                tags$li("seasonal AR(P): PACF spikes at lags (s, 2s, ...)."),
                tags$li("seasonal MA(Q): ACF spikes at lags (s, 2s, ...).")
              )
            )
          )
        ),
        tags$li("Fit a ", tags$b("small set"), " of plausible candidates (e.g., 3–8 models)."),
        tags$li(
          "Use tests/criteria:",
          tags$ul(
            tags$li("AICc/BIC,"),
            tags$li("parameter significance (with caution),"),
            tags$li("stability/invertibility checks.")
          )
        )
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Theory-driven model building). "),
        "“Candidate SARIMA structures were proposed based on ACF/PACF behavior of the differenced series. Spikes at [lags] suggested nonseasonal [AR/MA] components, ",
        "while prominent autocorrelation at multiples of (s) indicated seasonal [AR/MA] terms. Several candidate models were fitted and compared using [AICc/BIC], with final selection also considering parsimony and diagnostic adequacy.”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("ACF/PACF heuristics are ", tags$b("guides"), ", not commandments."),
        tags$li("Don’t brute-force 200 models and pretend it’s “theory-driven.” Pick a ", tags$b("small, reasoned set"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[7] - Diagnose & compare: residual tests + forecast accuracy; choose final model"),
      
      tags$h5("What students do"),
      tags$p(tags$b("Residual diagnostics (must-do):")),
      tags$ul(
        tags$li("Residual time plot (should look like noise)."),
        tags$li("Residual ACF (no big spikes)."),
        tags$li(tags$b("Ljung–Box test"), " for residual autocorrelation."),
        tags$li("Normality checks (QQ plot; Shapiro-Wilk is too sensitive for big n)."),
        tags$li("Check heteroskedasticity (variance changing over time).")
      ),
      
      tags$p(tags$b("Forecast evaluation (must-do):")),
      tags$ul(
        tags$li("Holdout or rolling cross-validation."),
        tags$li("Metrics: MAE/RMSE; MAPE only if data never near zero."),
        tags$li(
          "Compare:",
          tags$ul(
            tags$li("baseline auto-ARIMA,"),
            tags$li("manual SARIMA candidates,"),
            tags$li("maybe a simple benchmark (seasonal naive).")
          )
        )
      ),
      
      tags$p(tags$b("Model choice rule (healthy):")),
      tags$ul(
        tags$li("Must pass diagnostics reasonably well."),
        tags$li("Must beat naive benchmark."),
        tags$li("Prefer simpler model if accuracy is essentially tied.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Results (Model diagnostics and performance). "),
        "“Residual diagnostics indicated approximate white-noise behavior: residual autocorrelations were small and the Ljung–Box test was [non-significant/significant] at (α=...). ",
        "Forecast performance over the evaluation window showed MAE=(...) and RMSE=(...), outperforming the baseline and benchmark models. Based on diagnostic adequacy and predictive performance, the final selected model was SARIMA((p,d,q)(P,D,Q)_s).”"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("A model with great AIC but autocorrelated residuals is basically ", tags$i("lying to you politely"), "."),
        tags$li("If residuals are non-normal, forecasts can still be good; the bigger issue is ", tags$b("autocorrelation"), " left in residuals.")
      ),
      
      tags$hr(),
      
      tags$h4("[8] - Write your paper: use APA paragraphs in each step; assemble Methods/Results"),
      
      tags$h5("What students do (assembly checklist)"),
      tags$p(tags$b("Methods section")),
      tags$ul(
        tags$li("Data (source, frequency, missing handling, transformation)."),
        tags$li("Exploratory approach (plots used, decomposition method)."),
        tags$li("Stationarity tests and differencing decisions."),
        tags$li("Baseline (auto-ARIMA settings)."),
        tags$li("Manual model selection rationale (ACF/PACF + candidates)."),
        tags$li("Diagnostics and evaluation scheme.")
      ),
      
      tags$p(tags$b("Results section")),
      tags$ul(
        tags$li("Data summary + key visual observations."),
        tags$li("Decomposition findings (trend/seasonality statements)."),
        tags$li("Stationarity test outcomes and chosen (d, D)."),
        tags$li("Final model parameters."),
        tags$li("Diagnostics results and accuracy results."),
        tags$li("Forecast plot + table of errors.")
      ),
      
      tags$h5("What they write (APA structure guidance)"),
      tags$ul(
        tags$li("Keep each subsection as: ", tags$b("What we did → Why → What we found → What we concluded"), "."),
        tags$li("Use past tense for Methods, results-oriented past tense for Results."),
        tags$li("Put the math in-line sparingly; put full model spec once, clearly.")
      ),
      
      tags$hr(),
      
      tags$h4("A clean “deliverable package” students should submit"),
      tags$ul(
        tags$li(
          "A notebook/script that:",
          tags$ul(
            tags$li("loads data,"),
            tags$li("handles missingness,"),
            tags$li("performs EDA plots,"),
            tags$li("decomposition,"),
            tags$li("stationarity tests,"),
            tags$li("baseline auto-ARIMA,"),
            tags$li("manual candidates,"),
            tags$li("diagnostics,"),
            tags$li("evaluation,"),
            tags$li("and final forecast.")
          )
        ),
        tags$li(
          "A short paper with:",
          tags$ul(
            tags$li("Methods + Results sections aligned to steps 1–7,"),
            tags$li("figures: time plot, decomposition, ACF/PACF, residual ACF, forecast plot,"),
            tags$li("a table comparing candidate models (AICc + metrics).")
          )
        )
      ),
      
      tags$hr(),
      
    )
  })
  
  
  
  
  #=============================================================================
  #=============================================================================
  #=============================================================================
  
  
  
  output$roadmap_Detailed_Fr_ui <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      tags$hr(),
      
      tags$p(
        "Ci-dessous, une ",
        tags$b("feuille de route pratique de modélisation SARIMA"),
        "."
      ),
      
      tags$hr(),
      
      tags$h4("[0] - Préparer le terrain : définir le problème de modélisation"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ul(
        tags$li("Définir la ", tags$b("série réponse"), " (y_t) (ce que l’on prévoit)."),
        tags$li("Définir l’", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vérifier qu’il est cohérent."),
        tags$li(
          "Définir la ", tags$b("tâche de prévision"), " :",
          tags$ul(
            tags$li("horizon (ex. : 12 mois à l’avance),"),
            tags$li("schéma d’évaluation (origine glissante / rolling-origin ou simple découpage apprentissage/test),"),
            tags$li("métrique de perte (MAE/RMSE/MAPE/sMAPE).")
          )
        ),
        tags$li(
          "Décider si l’on modélise en :",
          tags$ul(
            tags$li(tags$b("niveaux"), " (données brutes),"),
            tags$li(tags$b("log-niveaux"), " (fréquent si la variance augmente avec le niveau),"),
            tags$li("espace transformé ", tags$b("Box–Cox"), " (plus général).")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent (papier)"),
      tags$p(
        tags$b("Méthodes (Données & Objectif). "),
        "« Nous avons modélisé la série temporelle univariée (y_t) observée à une fréquence [mensuelle] de [début] à [fin] (n=...). ",
        "L’objectif était de prévoir à un horizon de (h=...) pas. La performance du modèle a été évaluée à l’aide de [métrique(s)] selon un protocole ",
        "[apprentissage/test ou origine glissante]. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("SARIMA suppose un ", tags$b("espacement régulier"), " ; des timestamps irréguliers doivent être corrigés avant toute chose."),
        tags$li("SARIMA modélise ", tags$b("une seule série"), " (sans prédicteurs). Avec des variables explicatives, on parle plutôt de SARIMAX.")
      ),
      
      tags$hr(),
      
      tags$h4("[1] - Décrire les données : taille d’échantillon, valeurs manquantes, statistiques descriptives"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ol(
        tags$li(
          "Rapporter :",
          tags$ul(
            tags$li("taille d’échantillon (n),"),
            tags$li("dates de début/fin,"),
            tags$li("fréquence,"),
            tags$li("nombre/pourcentage de valeurs manquantes.")
          )
        ),
        tags$li(
          "Gérer le manque :",
          tags$ul(
            tags$li("S’il est rare et aléatoire : imputer (interpolation linéaire, interpolation saisonnière)."),
            tags$li("S’il est important : reconsidérer la série, la fréquence ou la source de données.")
          )
        ),
        tags$li(
          "Statistiques descriptives :",
          tags$ul(
            tags$li("moyenne, médiane, écart-type, min/max,"),
            tags$li("éventuellement asymétrie (skewness) / kurtosis,"),
            tags$li("et résumés saisonniers (ex. : moyenne par mois).")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent (style APA)"),
      tags$p(
        tags$b("Résultats (Description des données). "),
        "« La série contient (n=...) observations couvrant [dates] à une fréquence [fréquence]. ",
        "Les valeurs manquantes représentaient (...%) des observations (k=... points). Les observations manquantes ont été traitées par ",
        "[méthode], choisie car [raison]. La distribution de (y_t) présentait une moyenne de (...) (ET=(...)), une médiane (...), ",
        "et un intervalle ([...,...]). »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Ne pas imputer « silencieusement » — ", tags$b("toujours justifier"), "."),
        tags$li("Si une transformation logarithmique est appliquée, décrire aussi les statistiques de la série transformée.")
      ),
      
      tags$hr(),
      
      tags$h4("[2] - Explorer visuellement : tendance/saisonnalité/valeurs aberrantes ; rapporter les observations"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("Produire des graphiques et les commenter :"),
      tags$ul(
        tags$li(tags$b("Courbe"), " de (y_t)."),
        tags$li(tags$b("Graphique saisonnier"), " (ex. : lignes par mois de l’année)."),
        tags$li(tags$b("Boîte à moustaches par saison"), " (mois/trimestre/semaine)."),
        tags$li(
          tags$b("Détection d’outliers"), " :",
          tags$ul(
            tags$li("z-scores, règle IQR, ou méthodes robustes,"),
            tags$li("mais aussi le contexte (fêtes, changements de politique, erreurs de mesure).")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Résultats (Analyse exploratoire). "),
        "« L’inspection visuelle a indiqué une tendance [haussière/baissière] et des fluctuations saisonnières récurrentes de période (s=...). ",
        "La variabilité semblait [constante/augmenter avec le niveau], suggérant [aucune transformation / une transformation logarithmique]. ",
        "Plusieurs valeurs potentiellement aberrantes ont été observées autour de [dates], probablement liées à [contexte], et ont été ",
        "[conservées/ajustées] car [raison]. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Les outliers ne sont pas automatiquement « mauvais » : ils peuvent correspondre à des événements réels que la prévision doit respecter."),
        tags$li("Si la variance augmente avec le niveau, SARIMA se comporte souvent mieux après une transformation ", tags$b("log"), " ou ", tags$b("Box–Cox"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[3] - Décomposer : justifier additif vs multiplicatif ; utiliser STL si robustesse nécessaire"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("Réaliser une décomposition pour séparer :"),
      tags$ul(
        tags$li("tendance,"),
        tags$li("saisonnalité,"),
        tags$li("reste (bruit).")
      ),
      
      tags$p(tags$b("Choisir la forme du modèle :")),
      tags$ul(
        tags$li(tags$b("Additive :"), " (y_t = T_t + S_t + e_t). À utiliser lorsque l’amplitude saisonnière est à peu près constante."),
        tags$li(tags$b("Multiplicative :"), " (y_t = T_t × S_t × e_t). À utiliser lorsque l’amplitude saisonnière augmente avec le niveau (souvent résolu par log → additif en espace log).")
      ),
      
      tags$p(tags$b("Utiliser la décomposition STL lorsque :")),
      tags$ul(
        tags$li("la saisonnalité évolue lentement au fil du temps,"),
        tags$li("on souhaite une robustesse aux outliers.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Décomposition). "),
        "« Nous avons évalué une structure additive versus multiplicative en examinant si l’amplitude saisonnière évoluait avec le niveau de la série. ",
        "Comme [la variation saisonnière était approximativement constante / augmentait avec le niveau], nous avons utilisé [un modèle additif / une transformation logarithmique] ",
        "et décomposé la série via [décomposition classique / STL]. STL a été retenue pour sa robustesse aux valeurs aberrantes et sa flexibilité ",
        "dans la modélisation d’une saisonnalité évolutive. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("« Saison multiplicative » et « transformation log » sont pratiquement meilleurs amis."),
        tags$li("La décomposition STL est descriptive ; l’estimation SARIMA nécessite toujours des vérifications de stationnarité.")
      ),
      
      tags$hr(),
      
      tags$h4("[4] - Vérifier la stationnarité : ADF/KPSS/PP ; justifier la différenciation (d et D)"),
      tags$p("SARIMA requiert la stationnarité ", tags$b("après différenciation"), "."),
      
      tags$h5("Ce que les étudiants font"),
      tags$ol(
        tags$li("Définir la période saisonnière (s) (ex. : 12 pour des données mensuelles, 7 pour des données quotidiennes avec saisonnalité hebdomadaire)."),
        tags$li(
          "Tester la stationnarité sur :",
          tags$ul(
            tags$li("la série originale,"),
            tags$li("après ", tags$b("différenciation ordinaire"), " ((1-B)^d),"),
            tags$li("après ", tags$b("différenciation saisonnière"), " ((1-B^s)^D),"),
            tags$li("et parfois après les deux.")
          )
        )
      ),
      
      tags$h5("Tests de stationnarité : rôle, H0/Ha, et conclusion"),
      tags$ul(
        tags$li(
          tags$b("Test ADF (Augmented Dickey–Fuller)"),
          tags$ul(
            tags$li(tags$b("Rôle :"), " tester si la série se comporte comme si elle avait une ", tags$b("racine unitaire"),
                    " (tendance stochastique), impliquant la non-stationnarité ; le test estime une régression où des différences retardées sont ajoutées pour gérer l’autocorrélation."),
            tags$li(tags$b("H0 :"), " la série a une racine unitaire (non-stationnaire ; les chocs ont des effets permanents)."),
            tags$li(tags$b("Ha :"), " la série n’a pas de racine unitaire (stationnaire autour d’une moyenne ou autour d’une tendance déterministe, selon la spécification ADF)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " « Le test ADF a donné p = [p-value] ; ainsi, au seuil α = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 (racine unitaire). Cela implique que la série est ",
                    tags$b("[stationnaire / non-stationnaire]"), " selon l’ADF ; nous ",
                    tags$b("[n’avons pas appliqué de différenciation supplémentaire / avons appliqué]"), " une différenciation ordinaire [d=…] et/ou saisonnière [D=…] afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA. »")
          )
        ),
        tags$li(
          tags$b("Test KPSS (Kwiatkowski–Phillips–Schmidt–Shin)"),
          tags$ul(
            tags$li(tags$b("Rôle :"), " tester la stationnarité en examinant si la somme cumulée des résidus (d’une régression de niveau ou de tendance) est trop importante ; c’est un complément à l’ADF en inversant l’hypothèse nulle."),
            tags$li(tags$b("H0 :"), " la série est stationnaire (stationnaire en niveau, ou stationnaire en tendance si une tendance est incluse)."),
            tags$li(tags$b("Ha :"), " la série est non-stationnaire (contient une racine unitaire ou viole la stationnarité)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " « Le test KPSS a donné p = [p-value] ; au seuil α = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 de stationnarité. Cela indique que la série est ",
                    tags$b("[non stationnaire / compatible avec la stationnarité]"), " au sens KPSS ; cela ",
                    tags$b("[soutient l’application / ne nécessite pas]"), " d’une différenciation additionnelle. Nous avons donc retenu [d=…] et [D=…] puis revérifié la stationnarité sur la série transformée. »")
          )
        ),
        tags$li(
          tags$b("Test PP (Phillips–Perron)"),
          tags$ul(
            tags$li(tags$b("Rôle :"), " tester une racine unitaire comme l’ADF, mais en utilisant une correction non paramétrique de l’autocorrélation et de l’hétéroscédasticité (au lieu d’ajouter de nombreux retards)."),
            tags$li(tags$b("H0 :"), " la série a une racine unitaire (non-stationnaire)."),
            tags$li(tags$b("Ha :"), " la série n’a pas de racine unitaire (stationnaire)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " « Le test PP a donné p = [p-value] ; ainsi, au seuil α = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 de racine unitaire. Interprété avec l’ADF et le KPSS, cela suggère que la série est ",
                    tags$b("[stationnaire / non-stationnaire]"), " après application de [d=…] différenciations ordinaires et [D=…] différenciations saisonnières ; cela soutient l’usage d’un SARIMA sur la série différenciée. »")
          )
        )
      ),
      
      tags$p(tags$b("Interpréter ADF/KPSS/PP ensemble (logique à écrire).")),
      tags$ul(
        tags$li(tags$b("Accord idéal :"), " ADF/PP rejettent la racine unitaire (p petit) et KPSS ne rejette pas la stationnarité (p grand) → forte évidence de stationnarité."),
        tags$li(tags$b("Non-stationnarité claire :"), " ADF/PP ne rejettent pas la racine unitaire (p grand) et KPSS rejette la stationnarité (p petit) → forte évidence qu’une différenciation est nécessaire."),
        tags$li(tags$b("Conflits :"), " lorsque les tests divergent, s’appuyer sur l’ensemble des preuves : graphiques + comportement de l’ACF + résultats après différenciation, et indiquer que la conclusion repose sur la convergence des indices plutôt que sur une seule p-value.")
      ),
      
      tags$p(tags$b("Logique de différenciation :")),
      tags$ul(
        tags$li("Choisir ", tags$b("d"), " pour éliminer la tendance / racine unitaire."),
        tags$li("Choisir ", tags$b("D"), " pour éliminer la racine unitaire saisonnière."),
        tags$li("S’arrêter dès que la stationnarité est raisonnable ; éviter la sur-différenciation.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Stationnarité et différenciation). "),
        "« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
        "Sur la base des résultats combinés et des diagnostics visuels, nous avons retenu [d=...] différenciations ordinaires et [D=...] différenciations saisonnières avec une période saisonnière (s=...). ",
        "Ce choix visait à supprimer [tendance/racine unitaire saisonnière] tout en évitant la sur-différenciation ; la stationnarité a ensuite été réévaluée sur la série transformée avant d’ajuster les modèles SARIMA. »"
      ),
      
      tags$h5("Pièges (classiques)"),
      tags$ul(
        tags$li(
          tags$b("Sur-différenciation"),
          " provoque :",
          tags$ul(
            tags$li("forte autocorrélation négative au retard 1,"),
            tags$li("variance gonflée,"),
            tags$li("prévisions plus instables.")
          )
        ),
        tags$li("En pratique, D vaut souvent ", tags$b("0 ou 1"), ". Si (D=2) est nécessaire, la série est atypique ou la période saisonnière est mal spécifiée.")
      ),
      
      tags$hr(),
      
      tags$h4("[5] - Ajuster un modèle de référence : Auto-ARIMA pour obtenir un bon point de départ SARIMA"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ul(
        tags$li("Utiliser une procédure ", tags$b("auto-ARIMA"), " (AICc ou similaire) pour proposer : ((p,d,q)(P,D,Q)_s)."),
        tags$li(
          "Documenter :",
          tags$ul(
            tags$li("les transformations utilisées,"),
            tags$li("les contraintes (max p/q, etc.),"),
            tags$li("si une recherche stepwise a été utilisée.")
          )
        ),
        tags$li(tags$b("Important :"), " Auto-ARIMA donne une base solide, pas une vérité gravée dans le marbre.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Modèle de référence). "),
        "« Un modèle SARIMA de référence a été sélectionné via une procédure automatisée basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats ((p,q,P,Q)) ",
        "sous contraintes [bornes]. La spécification retenue était SARIMA((p,d,q)(P,D,Q)_s), utilisée comme modèle de référence pour des ajustements ultérieurs guidés par la théorie. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Auto-ARIMA peut sélectionner des modèles statistiquement corrects mais ", tags$b("difficiles à interpréter"), " ou légèrement instables."),
        tags$li("Si l’objectif est la prévision, il est acceptable de préférer des modèles ", tags$b("plus simples"), " à précision comparable.")
      ),
      
      tags$hr(),
      
      tags$h4("[6] - Ajuster un modèle guidé par la théorie : SARIMA manuel via ACF/PACF + tests"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("À partir de la série différenciée (après choix de (d, D)) :"),
      tags$ol(
        tags$li("Tracer ", tags$b("ACF/PACF"), "."),
        tags$li(
          "Proposer des structures candidates :",
          tags$ul(
            tags$li(
              "Non saisonnier :",
              tags$ul(
                tags$li("AR(p) : la PACF se coupe autour de p ; l’ACF décroît."),
                tags$li("MA(q) : l’ACF se coupe autour de q ; la PACF décroît.")
              )
            ),
            tags$li(
              "Saisonnier :",
              tags$ul(
                tags$li("AR saisonnier (P) : pics PACF aux retards (s, 2s, ...)."),
                tags$li("MA saisonnier (Q) : pics ACF aux retards (s, 2s, ...).")
              )
            )
          )
        ),
        tags$li("Ajuster un ", tags$b("petit ensemble"), " de candidats plausibles (ex. : 3–8 modèles)."),
        tags$li(
          "Comparer via :",
          tags$ul(
            tags$li("AICc/BIC,"),
            tags$li("significativité des paramètres (avec prudence),"),
            tags$li("stabilité / inversibilité.")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Construction guidée par la théorie). "),
        "« Les structures SARIMA candidates ont été proposées d’après le comportement ACF/PACF de la série différenciée. Des pics aux retards [lags] suggéraient des composantes non saisonnières [AR/MA], ",
        "tandis que des autocorrélations aux multiples de (s) indiquaient des termes saisonniers [AR/MA]. Plusieurs modèles ont été ajustés et comparés via [AICc/BIC], la sélection finale tenant compte de la parcimonie et de l’adéquation diagnostique. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Les heuristiques ACF/PACF sont des ", tags$b("guides"), ", pas des commandements."),
        tags$li("Éviter de brute-forcer 200 modèles puis d’appeler ça « théorie ». Préférer un ", tags$b("petit ensemble raisonné"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[7] - Diagnostiquer & comparer : tests des résidus + précision de prévision ; choisir le modèle final"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p(tags$b("Diagnostics des résidus (indispensable) :")),
      tags$ul(
        tags$li("Courbe des résidus (doit ressembler à du bruit)."),
        tags$li("ACF des résidus (pas de gros pics)."),
        tags$li(tags$b("Test de Ljung–Box"), " pour l’autocorrélation des résidus."),
        tags$li("Vérification de normalité (QQ-plot ; Shapiro-Wilk est trop sensible pour grands n)."),
        tags$li("Vérifier l’hétéroscédasticité (variance changeante).")
      ),
      
      tags$p(tags$b("Évaluation de la prévision (indispensable) :")),
      tags$ul(
        tags$li("Échantillon test ou validation croisée rolling."),
        tags$li("Métriques : MAE/RMSE ; MAPE seulement si la série n’est jamais proche de zéro."),
        tags$li(
          "Comparer :",
          tags$ul(
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats SARIMA manuels,"),
            tags$li("éventuellement un benchmark simple (naïf saisonnier).")
          )
        )
      ),
      
      tags$p(tags$b("Règle de choix (saine) :")),
      tags$ul(
        tags$li("Doit passer les diagnostics de façon raisonnable."),
        tags$li("Doit battre le benchmark naïf."),
        tags$li("Préférer le modèle le plus simple si la précision est quasi identique.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Résultats (Diagnostics et performance). "),
        "« Les diagnostics des résidus indiquaient un comportement proche du bruit blanc : les autocorrélations résiduelles étaient faibles et le test de Ljung–Box était [non significatif/significatif] au seuil (α=...). ",
        "La performance de prévision sur la fenêtre d’évaluation donnait MAE=(...) et RMSE=(...), surpassant les modèles de référence et de benchmark. Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Un modèle avec un excellent AIC mais des résidus autocorrélés te ", tags$i("raconte une belle histoire"), " — mais fausse."),
        tags$li("Des résidus non normaux peuvent encore donner de bonnes prévisions ; le problème majeur est l’", tags$b("autocorrélation"), " résiduelle.")
      ),
      
      tags$hr(),
      
      tags$h4("[8] - Rédiger le rapport : paragraphes APA à chaque étape ; assembler Méthodes/Résultats"),
      
      tags$h5("Ce que les étudiants font (checklist d’assemblage)"),
      tags$p(tags$b("Section Méthodes")),
      tags$ul(
        tags$li("Données (source, fréquence, traitement du manque, transformation)."),
        tags$li("Approche exploratoire (graphiques, décomposition)."),
        tags$li("Tests de stationnarité et choix de différenciation."),
        tags$li("Baseline (paramètres auto-ARIMA)."),
        tags$li("Justification de la sélection manuelle (ACF/PACF + candidats)."),
        tags$li("Diagnostics et protocole d’évaluation.")
      ),
      
      tags$p(tags$b("Section Résultats")),
      tags$ul(
        tags$li("Résumé des données + observations visuelles clés."),
        tags$li("Résultats de décomposition (tendance/saisonnalité)."),
        tags$li("Résultats des tests de stationnarité et choix (d, D)."),
        tags$li("Paramètres du modèle final."),
        tags$li("Diagnostics et métriques de précision."),
        tags$li("Graphique de prévision + tableau d’erreurs.")
      ),
      
      tags$h5("Guidance (structure APA)"),
      tags$ul(
        tags$li("Pour chaque sous-section : ", tags$b("Ce qu’on a fait → Pourquoi → Ce qu’on a observé → Conclusion"), "."),
        tags$li("Passé pour Méthodes ; passé orienté résultats pour Résultats."),
        tags$li("Écrire les maths avec parcimonie ; donner la spécification complète du modèle une seule fois, clairement.")
      ),
      
      tags$hr(),
      
      tags$h4("Un « pack livrable » propre que les étudiants doivent rendre"),
      tags$ul(
        tags$li(
          "Un notebook/script qui :",
          tags$ul(
            tags$li("charge les données,"),
            tags$li("traite les valeurs manquantes,"),
            tags$li("réalise l’EDA (graphiques),"),
            tags$li("décomposition,"),
            tags$li("tests de stationnarité,"),
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats manuels,"),
            tags$li("diagnostics,"),
            tags$li("évaluation,"),
            tags$li("prévision finale.")
          )
        ),
        tags$li(
          "Un court rapport avec :",
          tags$ul(
            tags$li("Méthodes + Résultats alignés aux étapes 1–7,"),
            tags$li("figures : courbe temporelle, décomposition, ACF/PACF, ACF des résidus, graphique de prévision,"),
            tags$li("tableau comparatif des modèles candidats (AICc + métriques).")
          )
        )
      ),
      
      tags$hr()
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  #=============================================================================
  #=============================================================================
  #=============================================================================
  
  
  
  
  output$roadmap_Detailed_Fr_ui2 <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      # --- Minimal styling for callouts & details ---
      tags$style(HTML("
      .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:6px; margin:10px 0;}
      .callout.warn {border-left-color:#E45756; background:#fff7f7;}
      .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
      details {background:#ffffff;border:1px solid #e5e5e5;border-radius:8px;padding:8px 12px;margin:12px 0;}
      details > summary {cursor:pointer;font-weight:600;}
      code, kbd {background:#f3f3f3; padding:0 3px; border-radius:3px;}
      .tiny {font-size: 90%;}
    ")),
      
      tags$hr(),
      tags$p(
        "Ci-dessous, une ",
        tags$b("feuille de route pratique de modélisation SARIMA"),
        " — enrichie de définitions simples, exemples et règles pratiques."
      ),
      tags$hr(),
      
      # ===================== [0] =====================
      tags$h4("[0] - Préparer le terrain : définir le problème de modélisation"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ul(
        tags$li("Définir la ", tags$b("série réponse"), " ", tags$code("y_t"), " (ce que l’on prévoit)."),
        tags$li("Définir l’", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vérifier sa régularité."),
        tags$li(
          "Définir la ", tags$b("tâche de prévision"), " :",
          tags$ul(
            tags$li(tags$b("horizon h"), " (ex. : 12 mois à l’avance)"),
            tags$li("schéma d’évaluation (", tags$b("origine glissante"), " / rolling-origin ou split apprentissage/test)"),
            tags$li("métrique de perte (", tags$b("MAE / RMSE / MAPE / sMAPE"), ").")
          )
        ),
        tags$li(
          "Décider l’échelle de modélisation :",
          tags$ul(
            tags$li(tags$b("niveaux"), " (données brutes)"),
            tags$li(tags$b("log-niveaux"), " (si la variance augmente avec le niveau)"),
            tags$li("espace transformé ", tags$b("Box–Cox"), " (plus général).")
          )
        )
      ),
      
      tags$details(
        tags$summary("Définitions clés (simples)"),
        tags$ul(
          tags$li(tags$b("Série univariée :"), " une seule valeur par date (ex. ventes mensuelles)."),
          tags$li(tags$b("Fréquence :"), " espacement des observations (jour, semaine, mois, trimestre…)."),
          tags$li(tags$b("Horizon h :"), " combien de pas dans le futur on prévoit (ex. h=12 ⇒ 12 mois)."),
          tags$li(tags$b("Rolling-origin :"), " on décale le point de départ, on re-fit à chaque fois et on moyenne les erreurs."),
          tags$li(tags$b("SARIMA :"), " ARIMA avec composantes saisonnières. Notation ", tags$code("SARIMA((p,d,q)(P,D,Q)_s)"), ".")
        ),
        tags$div(class="callout ok",
                 tags$b("En clair :"),
                 " posez clairement ", tags$em("quoi"), " prévoir, ", tags$em("sur quelle échelle"), " et ", tags$em("comment juger la qualité"), ".")
      ),
      
      tags$h5("Ce qu’ils écrivent (papier)"),
      tags$p(
        tags$b("Méthodes (Données & Objectif). "),
        "« Nous avons modélisé la série temporelle univariée (", tags$code("y_t"), ") observée à une fréquence [mensuelle] de [début] à [fin] (n=...). ",
        "L’objectif était de prévoir à un horizon (h=...) pas. La performance a été évaluée via [métrique(s)] selon un protocole ",
        "[apprentissage/test ou origine glissante]. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("SARIMA suppose un ", tags$b("espacement régulier"), " ; corriger toute irrégularité avant tout."),
        tags$li("SARIMA modélise ", tags$b("une seule série"), " (sans prédicteurs). Avec des variables explicatives → SARIMAX.")
      ),
      
      tags$hr(),
      
      # ===================== [1] =====================
      tags$h4("[1] - Décrire les données : taille d’échantillon, manque, descriptives"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ol(
        tags$li(
          "Rapporter :",
          tags$ul(
            tags$li("taille d’échantillon (n)"),
            tags$li("dates de début/fin"),
            tags$li("fréquence"),
            tags$li("nombre / pourcentage de valeurs manquantes")
          )
        ),
        tags$li(
          "Gérer le manque :",
          tags$ul(
            tags$li("Peu et aléatoire : imputer (interpolation linéaire ou saisonnière)."),
            tags$li("Beaucoup : envisager autre fréquence, autre source ou expliquer les limites.")
          )
        ),
        tags$li(
          "Statistiques descriptives :",
          tags$ul(
            tags$li("moyenne, médiane, écart-type, min/max"),
            tags$li("asymétrie (skewness) / kurtosis (si utile)"),
            tags$li("résumés saisonniers (ex. moyenne par mois).")
          )
        )
      ),
      
      tags$details(
        tags$summary("Définitions manque & interprétations"),
        tags$ul(
          tags$li(tags$b("MCAR :"), " manquants complètement aléatoires — l’imputation simple est OK."),
          tags$li(tags$b("MAR :"), " manquants dépendant d’autres variables observées — justifier la méthode."),
          tags$li(tags$b("MNAR :"), " manquants dépendant de la valeur elle-même — signaler le biais potentiel.")
        ),
        tags$div(class="callout warn",
                 tags$b("Règle pratique :"),
                 " documentez l’imputation et testez la sensibilité (avec/sans imputation).")
      ),
      
      tags$h5("Ce qu’ils écrivent (style APA)"),
      tags$p(
        tags$b("Résultats (Description des données). "),
        "« La série contient (n=...) observations couvrant [dates] à une fréquence [fréquence]. ",
        "Les valeurs manquantes représentaient (...%) (k=...). Elles ont été traitées par [méthode], choisie car [raison]. ",
        "La distribution de ", tags$code("y_t"), " présentait une moyenne (...) (ET (...)), une médiane (...), et un intervalle ([...,...]). »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Ne pas imputer « silencieusement » — ", tags$b("toujours justifier"), "."),
        tags$li("Si log-transformée, rapporter aussi les statistiques sur l’échelle transformée.")
      ),
      
      tags$hr(),
      
      # ===================== [2] =====================
      tags$h4("[2] - Explorer visuellement : tendance, saisonnalité, outliers"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("Produire et commenter :"),
      tags$ul(
        tags$li(tags$b("Courbe"), " de ", tags$code("y_t"), "."),
        tags$li(tags$b("Graphique saisonnier"), " (ex. lignes par mois)."),
        tags$li(tags$b("Boîte à moustaches par saison"), " (mois/trimestre/semaine)."),
        tags$li(
          tags$b("Détection d’outliers :"),
          tags$ul(
            tags$li("règle IQR, z-scores, méthodes robustes"),
            tags$li("contexte (fêtes, ruptures de politique, erreurs de mesure)")
          )
        )
      ),
      
      tags$details(
        tags$summary("Outliers : types & conduite"),
        tags$ul(
          tags$li(tags$b("AO (Additive Outlier) :"), " un pic isolé."),
          tags$li(tags$b("LS (Level Shift) :"), " changement de niveau persistant."),
          tags$li(tags$b("TC (Temporary Change) :"), " choc transitoire s’éteignant progressivement.")
        ),
        tags$div(class="callout ok",
                 tags$b("En clair :"),
                 " un outlier n’est pas « faux » par défaut. S’il reflète un évènement réel à reproduire, on ", tags$em("le garde"), ". Sinon, on l’ajuste et on documente.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Résultats (Analyse exploratoire). "),
        "« L’inspection visuelle a indiqué une tendance [haussière/baissière] et des fluctuations saisonnières de période (s=...). ",
        "La variabilité semblait [constante/augmenter avec le niveau], suggérant [aucune transformation / log]. ",
        "Des valeurs potentiellement aberrantes autour de [dates], liées à [contexte], ont été ",
        "[conservées/ajustées] car [raison]. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Les outliers réels doivent souvent être conservés (la prévision doit les anticiper)."),
        tags$li("Si la variance augmente avec le niveau : essayer ", tags$b("log"), " ou ", tags$b("Box–Cox"), ".")
      ),
      
      tags$hr(),
      
      # ===================== [3] =====================
      tags$h4("[3] - Décomposer : additif vs multiplicatif ; STL si robustesse"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("Décomposer pour séparer : tendance, saisonnalité, bruit."),
      
      tags$p(tags$b("Choisir la forme :")),
      tags$ul(
        tags$li(tags$b("Additive :"), " ", tags$code("y_t = T_t + S_t + e_t"), " si l’amplitude saisonnière est à peu près constante."),
        tags$li(tags$b("Multiplicative :"), " ", tags$code("y_t = T_t × S_t × e_t"), " si l’amplitude augmente avec le niveau (devenir additif après log).")
      ),
      
      tags$p(tags$b("Utiliser STL lorsque :")),
      tags$ul(
        tags$li("la saisonnalité évolue lentement"),
        tags$li("on souhaite une robustesse aux outliers")
      ),
      
      tags$details(
        tags$summary("En clair & exemples"),
        tags$div(class="callout ok",
                 tags$b("Exemple :"),
                 " ventes mensuelles qui doublent en décembre chaque année → amplitude saisonnière croît avec le niveau → ", tags$em("log + additif en espace log"), ".")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Décomposition). "),
        "« Nous avons comparé structure additive vs multiplicative selon l’amplitude saisonnière. ",
        "Comme [constante / croissante], nous avons utilisé [additif / log] et décomposé via [classique / STL]. STL retenue pour robustesse et flexibilité. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Multiplicatif ↔ log : bons amis."),
        tags$li("STL est descriptive ; SARIMA exige encore la stationnarité.")
      ),
      
      tags$hr(),
      
      # ===================== [4] =====================
      tags$h4("[4] - Stationnarité : ADF / KPSS / PP ; justifier d et D"),
      tags$p("SARIMA requiert la stationnarité ", tags$b("après différenciation"), "."),
      
      tags$h5("Ce que les étudiants font"),
      tags$ol(
        tags$li("Fixer la période saisonnière ", tags$code("s"), " (12 mensuel, 4 trimestriel, 7 quotidien avec hebdo, etc.)."),
        tags$li("Tester sur : série brute → après ", tags$b("différence ordinaire"), " ", tags$code("(1-B)^d"), " → après ", tags$b("différence saisonnière"), " ", tags$code("(1-B^s)^D"), " → (éventuellement) les deux.")
      ),
      
      tags$details(
        tags$summary("Tests (version accessible)"),
        tags$ul(
          tags$li(tags$b("ADF (Augmented Dickey–Fuller)"),
                  ": H0 = racine unitaire (non-stationnaire). ",
                  "Rejeter H0 ⇒ stationnarité plausible."),
          tags$li(tags$b("KPSS (Kwiatkowski–Phillips–Schmidt–Shin)"),
                  ": H0 = stationnarité. ",
                  "Rejeter H0 ⇒ non-stationnaire."),
          tags$li(tags$b("PP (Phillips–Perron)"),
                  ": comme ADF (H0 racine unitaire) mais corrige l’autocorrélation/hétéroscédasticité différemment.")
        ),
        tags$div(class="callout ok",
                 tags$b("Lecture combinée :"),
                 " ADF/PP rejettent & KPSS ne rejette pas → stationnaire. ",
                 "ADF/PP ne rejettent pas & KPSS rejette → différencier.")
      ),
      
      tags$h5("Logique de différenciation"),
      tags$ul(
        tags$li("Choisir ", tags$b("d"), " pour supprimer tendance/racine unitaire."),
        tags$li("Choisir ", tags$b("D"), " pour supprimer racine unitaire saisonnière."),
        tags$li("S’arrêter dès que la stationnarité est raisonnable (éviter la sur-différenciation).")
      ),
      
      tags$details(
        tags$summary("Arbre décisionnel rapide (d, D)"),
        tags$ul(
          tags$li(tags$b("Étape 1 :"), " si forte saisonnalité → essayer ", tags$code("D=1"), " (", tags$code("∇_s"), "), retester."),
          tags$li(tags$b("Étape 2 :"), " si tendance résiduelle → ", tags$code("d=1"), ", retester."),
          tags$li(tags$b("Étape 3 :"), " si ACF lag 1 très négatif → probable sur-différenciation (réduire d/D).")
        ),
        tags$div(class="callout warn",
                 tags$b("Pratique :"),
                 " en applications courantes, ", tags$code("D ∈ {0,1}"), " suffit. Si ", tags$code("D=2"), " semble nécessaire, re-vérifier ", tags$code("s"), ".")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Stationnarité et différenciation). "),
        "« La stationnarité a été évaluée via ADF, KPSS et PP. ",
        "Selon l’ensemble des preuves (tests + graphiques), nous avons retenu [d=...] et [D=...] avec ", tags$code("s=..."), 
        ". Nous avons évité la sur-différenciation et re-testé la stationnarité avant l’ajustement SARIMA. »"
      ),
      
      tags$hr(),
      
      # ===================== [5] =====================
      tags$h4("[5] - Modèle de référence : Auto-ARIMA pour un bon départ"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ul(
        tags$li("Utiliser ", tags$b("auto-ARIMA"), " (AICc/BIC) pour proposer ", tags$code("((p,d,q)(P,D,Q)_s)"), "."),
        tags$li("Documenter : transformations (log/Box–Cox), bornes (max p/q/P/Q), option ", tags$em("stepwise"), ", etc."),
        tags$li(tags$b("Important :"), " auto-ARIMA donne une base, pas un verdict.")
      ),
      
      tags$details(
        tags$summary("Notes utiles"),
        tags$ul(
          tags$li("Si la variance est instable, estimer avec ", tags$code("lambda"), " (Box–Cox) et prévoir sur l’échelle d’origine."),
          tags$li("Comparer avec des benchmarks (naïf, SNAIVE, drift).")
        )
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Modèle de référence). "),
        "« Un SARIMA de référence a été choisi par minimisation de l’AICc parmi des ordres candidats, ",
        "avec contraintes [bornes]. La spécification retenue : ", tags$code("SARIMA((p,d,q)(P,D,Q)_s)"), ". »"
      ),
      
      tags$hr(),
      
      # ===================== [6] =====================
      tags$h4("[6] - Modèle guidé par la théorie : ACF/PACF + tests"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("À partir de la série différenciée (", tags$code("d, D"), ") :"),
      tags$ol(
        tags$li("Tracer ", tags$b("ACF/PACF"), "."),
        tags$li("Proposer 3–8 modèles plausibles (non saisonniers et saisonniers)."),
        tags$li("Comparer : AICc/BIC, significativité (avec prudence), stabilité/inversibilité.")
      ),
      
      tags$details(
        tags$summary("Cheat-sheet ACF/PACF"),
        tags$ul(
          tags$li(tags$b("AR(p) :"), " PACF se coupe ≈ p ; ACF décroît."),
          tags$li(tags$b("MA(q) :"), " ACF se coupe ≈ q ; PACF décroît."),
          tags$li(tags$b("Saisonnier AR(P) :"), " pics PACF aux ", tags$code("s, 2s, ..."), "."),
          tags$li(tags$b("Saisonnier MA(Q) :"), " pics ACF aux ", tags$code("s, 2s, ..."), ".")
        ),
        tags$div(class="callout ok",
                 tags$b("Astuce :"),
                 " privilégier les modèles ", tags$em("parcimonieux"), " qui passent les diagnostics.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Construction guidée par la théorie). "),
        "« Les structures SARIMA candidates ont été proposées à partir de l’ACF/PACF de la série différenciée. ",
        "Plusieurs modèles ont été ajustés et comparés via [AICc/BIC], la sélection finale tenant compte de la parcimonie et de l’adéquation diagnostique. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("ACF/PACF sont des guides, pas des commandements."),
        tags$li("Éviter de brute-forcer des centaines de modèles : rester dans un petit ensemble raisonné.")
      ),
      
      tags$hr(),
      
      # ===================== [7] =====================
      tags$h4("[7] - Diagnostiquer & comparer : résidus + précision ; choisir le final"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p(tags$b("Diagnostics des résidus :")),
      tags$ul(
        tags$li("Courbe des résidus (doit ressembler à du bruit)."),
        tags$li("ACF des résidus (pas de gros pics)."),
        tags$li(tags$b("Ljung–Box"), " (H0 : pas d’autocorrélation globale)."),
        tags$li("QQ-plot (normalité : utile mais non cruciale pour la prévision)."),
        tags$li("Hétéroscédasticité (variance changeante).")
      ),
      
      tags$details(
        tags$summary("Paramétrer Ljung–Box & lire les résultats"),
        tags$ul(
          tags$li(tags$b("Choix du lag m :"), " souvent ", tags$code("m ≈ 2s") , " (s saison) ou ", tags$code("m ≈ 10*log10(n)"), " pour non saisonnier."),
          tags$li(tags$b("Lecture :"), " p-value grande ⇒ OK ; p-value petite ⇒ spécification incomplète (ajouter AR/MA, revoir d/D).")
        )
      ),
      
      tags$p(tags$b("Évaluation de la prévision :")),
      tags$ul(
        tags$li("Split test ou validation croisée rolling."),
        tags$li("Métriques : ", tags$b("MAE / RMSE"), " (MAPE seulement si la série n’est jamais proche de zéro)."),
        tags$li("Comparer : baseline auto-ARIMA, candidats manuels, benchmark naïf (souvent SNAIVE).")
      ),
      
      tags$p(tags$b("Règle de choix :")),
      tags$ul(
        tags$li("Diagnostics raisonnablement passés."),
        tags$li("Batte le benchmark naïf."),
        tags$li("À précision proche, préférer le plus simple.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Résultats (Diagnostics et performance). "),
        "« Les résidus se comportent comme un bruit blanc (ACF sans pics) et le test de Ljung–Box est [non significatif/significatif] à (α=...). ",
        "Sur l’échantillon d’évaluation : MAE=(...) et RMSE=(...), meilleurs que les benchmarks. ",
        "Le modèle final retenu : ", tags$code("SARIMA((p,d,q)(P,D,Q)_s)"), ". »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Un AIC excellent avec des résidus autocorrélés ", tags$i("raconte une belle histoire… fausse"), "."),
        tags$li("Des résidus non normaux peuvent quand même bien prévoir ; l’autocorrélation résiduelle est le vrai problème.")
      ),
      
      tags$hr(),
      
      # ===================== [8] =====================
      tags$h4("[8] - Rédiger : paragraphes APA & structure"),
      
      tags$h5("Checklist d’assemblage"),
      tags$p(tags$b("Section Méthodes")),
      tags$ul(
        tags$li("Données (source, fréquence, manque, transformation)"),
        tags$li("EDA (graphiques), décomposition"),
        tags$li("Tests de stationnarité et choix d/D"),
        tags$li("Baseline auto-ARIMA"),
        tags$li("Sélection guidée par ACF/PACF"),
        tags$li("Diagnostics & protocole d’évaluation (rolling/split)")
      ),
      tags$p(tags$b("Section Résultats")),
      tags$ul(
        tags$li("Résumé des données + points visuels clés"),
        tags$li("Décomposition (tendance/saisonnalité)"),
        tags$li("Tests de stationnarité + choix (d, D)"),
        tags$li("Paramètres du modèle final"),
        tags$li("Diagnostics + métriques (MAE, RMSE, etc.)"),
        tags$li("Graphique de prévision + tableau d’erreurs")
      ),
      tags$h5("Guidance (APA)"),
      tags$ul(
        tags$li("Pour chaque sous-section : ", tags$b("Ce qu’on a fait → Pourquoi → Ce qu’on a observé → Conclusion"), "."),
        tags$li("Passé pour Méthodes ; passé orienté résultats pour Résultats."),
        tags$li("Donner la spécification complète une seule fois, clairement.")
      ),
      
      tags$hr(),
      
      # ===================== Livrables =====================
      tags$h4("Livrables attendus (pack propre)"),
      tags$ul(
        tags$li(
          "Notebook/script :",
          tags$ul(
            tags$li("chargement & manque"),
            tags$li("EDA (graphiques)"),
            tags$li("décomposition"),
            tags$li("tests de stationnarité"),
            tags$li("baseline auto-ARIMA"),
            tags$li("candidats manuels"),
            tags$li("diagnostics"),
            tags$li("évaluation"),
            tags$li("prévision finale")
          )
        ),
        tags$li(
          "Court rapport :",
          tags$ul(
            tags$li("Méthodes + Résultats (étapes 1–7)"),
            tags$li("Figures : courbe, décomposition, ACF/PACF, ACF résidus, prévision"),
            tags$li("Tableau comparatif (AICc + métriques)")
          )
        )
      ),
      
      tags$hr(),
      
      # ===================== Annexes pédagogiques =====================
      tags$h3("Annexes — mini-cours & définitions"),
      
      tags$details(
        tags$summary("[A] Notation & rappel SARIMA (sans douleur)"),
        tags$div(
          class="callout",
          tags$p(tags$b("Opérateurs & différences")),
          tags$ul(
            tags$li(tags$code("B"), ": opérateur de retard (", tags$code("B y_t = y_{t-1}"), ")."),
            tags$li(tags$code("∇ = 1 - B"), " : différence ordinaire (", tags$code("∇ y_t = y_t - y_{t-1}"), ")."),
            tags$li(tags$code("∇_s = 1 - B^s"), " : différence saisonnière (période ", tags$code("s"), ").")
          ),
          tags$p(tags$b("Modèle SARIMA((p,d,q)(P,D,Q)", tags$sub("s"), ")")),
          tags$ul(
            tags$li(tags$code("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), " (AR non saisonnier)"),
            tags$li(tags$code("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), " (MA non saisonnier)"),
            tags$li(tags$code("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), " (AR saisonnier)"),
            tags$li(tags$code("Θ(B^s) = 1 + Θ_1 B^s - ... - Θ_Q B^{Qs}"), " (MA saisonnier)")
          ),
          tags$p(class="tiny", "Écriture compacte : ",
                 tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t,  ε_t ~ w.n.(0, σ^2)"))
        )
      ),
      
      tags$details(
        tags$summary("[B] Transformations (log, Box–Cox) & inverse"),
        tags$ul(
          tags$li(tags$b("Log :"), " utile si la variabilité croît avec le niveau ; gérer les zéros avec ", tags$code("log(y + c)"), "."),
          tags$li(tags$b("Box–Cox :"), " ", tags$code("y^(λ) = (y^λ - 1)/λ"), " si ", tags$code("λ ≠ 0"), " ; ", tags$code("log(y)"), " si ", tags$code("λ = 0"), ".")
        ),
        tags$p(tags$b("Inverse Box–Cox :")),
        tags$ul(
          tags$li(tags$code("y = (λ * y^(λ) + 1)^(1/λ)"), " si ", tags$code("λ ≠ 0")),
          tags$li(tags$code("y = exp(y^(λ))"), " si ", tags$code("λ = 0"))
        ),
        tags$div(class="callout warn",
                 tags$b("Comparer les erreurs sur l’échelle d’origine"),
                 " (après transformation inverse).")
      ),
      
      tags$details(
        tags$summary("[C] Benchmarks & métriques (quand et pourquoi)"),
        tags$ul(
          tags$li(tags$b("Naïf :"), " ", tags$code("ŷ_{t+1|t} = y_t"), " — base absolue."),
          tags$li(tags$b("Drift :"), " ", tags$code("ŷ_{t+h|t} = y_t + h*(y_t - y_1)/(t-1)"), " — tendance linéaire."),
          tags$li(tags$b("SNAIVE :"), " ", tags$code("ŷ_{t+h|t} = y_{t+h-s}"), " — saisonnalité récurrente.")
        ),
        tags$ul(
          tags$li(tags$b("MAE :"), " robuste, lisible en unités de la série."),
          tags$li(tags$b("RMSE :"), " punit fort les grosses erreurs (utile si coût convexe)."),
          tags$li(tags$b("MAPE :"), " éviter si valeurs proches de 0."),
          tags$li(tags$b("sMAPE :"), " alternative symétrique, prudence si faible signal.")
        ),
        tags$div(class="callout ok",
                 tags$b("Bon réflexe :"),
                 " toujours comparer au moins au SNAIVE + rapporter MAE & RMSE.")
      ),
      
      tags$details(
        tags$summary("[D] Validation par origine glissante (schéma)"),
        tags$ol(
          tags$li("Choisir origine ", tags$code("T0"), " et horizon ", tags$code("h")),
          tags$li("Ajuster sur [1..T0], prévoir [T0+1..T0+h], mesurer l’erreur"),
          tags$li("Avancer l’origine et répéter"),
          tags$li("Aggréger les erreurs (MAE/RMSE) sur les folds")
        ),
        tags$pre("
for (origin in origins) {
  fit <- Arima(y[1:origin], order=c(p,d,q), seasonal=c(P,D,Q), lambda=lambda)
  fc  <- forecast(fit, h=h)
  err <- accuracy(fc, y[(origin+1):(origin+h)])
  collect(err)
}
summary_errors <- aggregate_metrics(...)
")
      ),
      
      tags$details(
        tags$summary("[E] Erreurs fréquentes & anti-patterns"),
        tags$ul(
          tags$li("Laisser auto-ARIMA choisir d/D sans réflexion préalable."),
          tags$li("Ignorer les benchmarks → impossible de qualifier « bon »."),
          tags$li("Comparer des AIC sur échelles différentes (log vs niveau) sans précaution."),
          tags$li("Évaluer uniquement in-sample (optimisme)."),
          tags$li("Tester trop de modèles (data snooping).")
        )
      ),
      
      tags$details(
        tags$summary("[F] Mini-FAQ"),
        tags$ul(
          tags$li(tags$b("Trous longs ?"), " Envisager fréquence plus faible, autre source, ou modéliser une rupture (intervention)."),
          tags$li(tags$b("Plusieurs saisonnalités ?"), " SARIMA gère une saisonnalité ; voir TBATS/ETS-complexe/état espace."),
          tags$li(tags$b("Variables explicatives ?"), " Passer à SARIMAX ou modèles d’état (régressions avec erreurs ARIMA).")
        )
      ),
      
      tags$hr()
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
 
  output$roadmap_Detailed_Fr_ui3 <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      tags$hr(),
      
      tags$p(
        "Ci-dessous, une ",
        tags$b("feuille de route pratique de modélisation SARIMA"),
        "."
      ),
      
      tags$hr(),
      
      # Encadré: définitions/notations (collapsible)
      tags$details(
        tags$summary(tags$b("Encadré — Définitions, notations et rappels utiles")),
        tags$ul(
          tags$li(
            tags$b("Notation SARIMA : "), 
            tags$code("SARIMA((p,d,q)(P,D,Q))"),
            " avec saisonnalité de période ",
            tags$code("s"),
            "."
          ),
          tags$li(
            tags$b("Forme opérateur (backshift B) :")
          ),
          tags$ul(
            tags$li(
              tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
              " avec innovations ",
              tags$code("ε_t ~ w.n.(0, σ^2)")
            ),
            tags$li(
              tags$code("φ(B) = 1 - φ1 B - ... - φp B^p"),
              "; ",
              tags$code("θ(B) = 1 + θ1 B + ... + θq B^q")
            ),
            tags$li(
              tags$code("Φ(B^s) = 1 - Φ1 B^s - ... - ΦP B^{Ps}"),
              "; ",
              tags$code("Θ(B^s) = 1 + Θ1 B^s + ... + ΘQ B^{Qs}")
            ),
            tags$li(
              tags$code("∇^d = (1 - B)^d"),
              " ; ",
              tags$code("∇_s^D = (1 - B^s)^D")
            )
          ),
          tags$li(
            tags$b("Stationnarité/inversibilité : "),
            "racinaires de ",
            tags$code("φ(B)"),
            " et ",
            tags$code("Φ(B^s)"),
            " hors du cercle unité ; idem pour ",
            tags$code("θ(B)"),
            " et ",
            tags$code("Θ(B^s)"),
            " (invertibilité)."
          ),
          tags$li(
            tags$b("ACF/PACF : "),
            "ACF tronquée ≈ MA ; PACF tronquée ≈ AR ; pics aux multiples de ",
            tags$code("s"),
            " → composantes saisonnières."
          ),
          tags$li(
            tags$b("Critères d’info : "),
            tags$code("AIC = -2ℓ + 2k"),
            ", ",
            tags$code("BIC = -2ℓ + k ln(n)"),
            ", ",
            tags$code("AICc = AIC + (2k(k+1))/(n-k-1)"),
            " (préférer plus petit)."
          ),
          tags$li(
            tags$b("Métriques d’erreur : "),
            tags$code("MAE"),
            ", ",
            tags$code("RMSE"),
            ", ",
            tags$code("MAPE/sMAPE"),
            " (éviter MAPE près de zéro)."
          ),
          tags$li(
            tags$b("Transformations : "),
            tags$code("log"),
            " (stabilise variance, multiplicatif → additif), ",
            tags$code("Box–Cox"),
            " (paramètre ",
            tags$code("λ"),
            ", inclut log si ",
            tags$code("λ = 0"),
            ")."
          ),
          tags$li(
            tags$b("Sur-/sous-différenciation : "),
            "viser le minimum de ",
            tags$code("d"),
            " et ",
            tags$code("D"),
            " assurant une stationnarité raisonnable (éviter ",
            tags$code("ACF"),
            " très négative au lag 1)."
          )
        )
      ),
      
      tags$h4("[0] - Préparer le terrain : définir le problème de modélisation"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ul(
        tags$li("Définir la ", tags$b("série réponse"), " (y_t) (ce que l’on prévoit)."),
        tags$li("Définir l’", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vérifier qu’il est cohérent."),
        tags$li(
          "Définir la ", tags$b("tâche de prévision"), " :",
          tags$ul(
            tags$li("horizon (ex. : 12 mois à l’avance),"),
            tags$li("schéma d’évaluation (origine glissante / rolling-origin ou simple découpage apprentissage/test),"),
            tags$li("métrique de perte (MAE/RMSE/MAPE/sMAPE).")
          )
        ),
        tags$li(
          "Décider si l’on modélise en :",
          tags$ul(
            tags$li(tags$b("niveaux"), " (données brutes),"),
            tags$li(tags$b("log-niveaux"), " (fréquent si la variance augmente avec le niveau),"),
            tags$li("espace transformé ", tags$b("Box–Cox"), " (plus général).")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent (papier)"),
      tags$p(
        tags$b("Méthodes (Données & Objectif). "),
        "« Nous avons modélisé la série temporelle univariée (y_t) observée à une fréquence [mensuelle] de [début] à [fin] (n=...). ",
        "L’objectif était de prévoir à un horizon de (h=...) pas. La performance du modèle a été évaluée à l’aide de [métrique(s)] selon un protocole ",
        "[apprentissage/test ou origine glissante]. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("SARIMA suppose un ", tags$b("espacement régulier"), " ; des timestamps irréguliers doivent être corrigés avant toute chose."),
        tags$li("SARIMA modélise ", tags$b("une seule série"), " (sans prédicteurs). Avec des variables explicatives, on parle plutôt de SARIMAX.")
      ),
      
      tags$hr(),
      
      tags$h4("[1] - Décrire les données : taille d’échantillon, valeurs manquantes, statistiques descriptives"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ol(
        tags$li(
          "Rapporter :",
          tags$ul(
            tags$li("taille d’échantillon (n),"),
            tags$li("dates de début/fin,"),
            tags$li("fréquence,"),
            tags$li("nombre/pourcentage de valeurs manquantes.")
          )
        ),
        tags$li(
          "Gérer le manque :",
          tags$ul(
            tags$li("S’il est rare et aléatoire : imputer (interpolation linéaire, interpolation saisonnière)."),
            tags$li("S’il est important : reconsidérer la série, la fréquence ou la source de données.")
          )
        ),
        tags$li(
          "Statistiques descriptives :",
          tags$ul(
            tags$li("moyenne, médiane, écart-type, min/max,"),
            tags$li("éventuellement asymétrie (skewness) / kurtosis,"),
            tags$li("et résumés saisonniers (ex. : moyenne par mois).")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent (style APA)"),
      tags$p(
        tags$b("Résultats (Description des données). "),
        "« La série contient (n=...) observations couvrant [dates] à une fréquence [fréquence]. ",
        "Les valeurs manquantes représentaient (...%) des observations (k=... points). Les observations manquantes ont été traitées par ",
        "[méthode], choisie car [raison]. La distribution de (y_t) présentait une moyenne de (...) (ET=(...)), une médiane (...), ",
        "et un intervalle ([...,...]). »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Ne pas imputer « silencieusement » — ", tags$b("toujours justifier"), "."),
        tags$li("Si une transformation logarithmique est appliquée, décrire aussi les statistiques de la série transformée.")
      ),
      
      tags$hr(),
      
      tags$h4("[2] - Explorer visuellement : tendance/saisonnalité/valeurs aberrantes ; rapporter les observations"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("Produire des graphiques et les commenter :"),
      tags$ul(
        tags$li(tags$b("Courbe"), " de (y_t)."),
        tags$li(tags$b("Graphique saisonnier"), " (ex. : lignes par mois de l’année)."),
        tags$li(tags$b("Boîte à moustaches par saison"), " (mois/trimestre/semaine)."),
        tags$li(
          tags$b("Détection d’outliers"), " :",
          tags$ul(
            tags$li("z-scores, règle IQR, ou méthodes robustes,"),
            tags$li("mais aussi le contexte (fêtes, changements de politique, erreurs de mesure).")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Résultats (Analyse exploratoire). "),
        "« L’inspection visuelle a indiqué une tendance [haussière/baissière] et des fluctuations saisonnières récurrentes de période (s=...). ",
        "La variabilité semblait [constante/augmenter avec le niveau], suggérant [aucune transformation / une transformation logarithmique]. ",
        "Plusieurs valeurs potentiellement aberrantes ont été observées autour de [dates], probablement liées à [contexte], et ont été ",
        "[conservées/ajustées] car [raison]. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Les outliers ne sont pas automatiquement « mauvais » : ils peuvent correspondre à des événements réels que la prévision doit respecter."),
        tags$li("Si la variance augmente avec le niveau, SARIMA se comporte souvent mieux après une transformation ", tags$b("log"), " ou ", tags$b("Box–Cox"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[3] - Décomposer : justifier additif vs multiplicatif ; utiliser STL si robustesse nécessaire"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("Réaliser une décomposition pour séparer :"),
      tags$ul(
        tags$li("tendance,"),
        tags$li("saisonnalité,"),
        tags$li("reste (bruit).")
      ),
      
      tags$p(tags$b("Choisir la forme du modèle :")),
      tags$ul(
        tags$li(tags$b("Additive :"), " (y_t = T_t + S_t + e_t). À utiliser lorsque l’amplitude saisonnière est à peu près constante."),
        tags$li(tags$b("Multiplicative :"), " (y_t = T_t × S_t × e_t). À utiliser lorsque l’amplitude saisonnière augmente avec le niveau (souvent résolu par log → additif en espace log).")
      ),
      
      tags$p(tags$b("Utiliser la décomposition STL lorsque :")),
      tags$ul(
        tags$li("la saisonnalité évolue lentement au fil du temps,"),
        tags$li("on souhaite une robustesse aux outliers.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Décomposition). "),
        "« Nous avons évalué une structure additive versus multiplicative en examinant si l’amplitude saisonnière évoluait avec le niveau de la série. ",
        "Comme [la variation saisonnière était approximativement constante / augmentait avec le niveau], nous avons utilisé [un modèle additif / une transformation logarithmique] ",
        "et décomposé la série via [décomposition classique / STL]. STL a été retenue pour sa robustesse aux valeurs aberrantes et sa flexibilité ",
        "dans la modélisation d’une saisonnalité évolutive. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("« Saison multiplicative » et « transformation log » sont pratiquement meilleurs amis."),
        tags$li("La décomposition STL est descriptive ; l’estimation SARIMA nécessite toujours des vérifications de stationnarité.")
      ),
      
      tags$hr(),
      
      tags$h4("[4] - Vérifier la stationnarité : ADF/KPSS/PP ; justifier la différenciation (d et D)"),
      tags$p("SARIMA requiert la stationnarité ", tags$b("après différenciation"), "."),
      
      tags$h5("Ce que les étudiants font"),
      tags$ol(
        tags$li("Définir la période saisonnière (s) (ex. : 12 pour des données mensuelles, 7 pour des données quotidiennes avec saisonnalité hebdomadaire)."),
        tags$li(
          "Tester la stationnarité sur :",
          tags$ul(
            tags$li("la série originale,"),
            tags$li("après ", tags$b("différenciation ordinaire"), " ((1-B)^d),"),
            tags$li("après ", tags$b("différenciation saisonnière"), " ((1-B^s)^D),"),
            tags$li("et parfois après les deux.")
          )
        )
      ),
      
      tags$h5("Tests de stationnarité : rôle, H0/Ha, et conclusion"),
      tags$ul(
        tags$li(
          tags$b("Test ADF (Augmented Dickey–Fuller)"),
          tags$ul(
            tags$li(tags$b("Rôle :"), " tester si la série se comporte comme si elle avait une ", tags$b("racine unitaire"),
                    " (tendance stochastique), impliquant la non-stationnarité ; le test estime une régression où des différences retardées sont ajoutées pour gérer l’autocorrélation."),
            tags$li(tags$b("H0 :"), " la série a une racine unitaire (non-stationnaire ; les chocs ont des effets permanents)."),
            tags$li(tags$b("Ha :"), " la série n’a pas de racine unitaire (stationnaire autour d’une moyenne ou autour d’une tendance déterministe, selon la spécification ADF)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " « Le test ADF a donné p = [p-value] ; ainsi, au seuil α = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 (racine unitaire). Cela implique que la série est ",
                    tags$b("[stationnaire / non-stationnaire]"), " selon l’ADF ; nous ",
                    tags$b("[n’avons pas appliqué de différenciation supplémentaire / avons appliqué]"),
                    " une différenciation ordinaire [d=…] et/ou saisonnière [D=…] afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA. »")
          )
        ),
        tags$li(
          tags$b("Test KPSS (Kwiatkowski–Phillips–Schmidt–Shin)"),
          tags$ul(
            tags$li(tags$b("Rôle :"), " tester la stationnarité en examinant si la somme cumulée des résidus (d’une régression de niveau ou de tendance) est trop importante ; complément à l’ADF (H0 inversée)."),
            tags$li(tags$b("H0 :"), " la série est stationnaire (niveau, ou tendance si incluse)."),
            tags$li(tags$b("Ha :"), " la série est non-stationnaire."),
            tags$li(tags$b("Phrase-type :"), " « Le test KPSS a donné p = [p-value] ; au seuil α = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0. Cela indique que la série est ",
                    tags$b("[non stationnaire / compatible avec la stationnarité]"),
                    " ; cela ",
                    tags$b("[soutient / ne nécessite pas]"),
                    " une différenciation additionnelle. »")
          )
        ),
        tags$li(
          tags$b("Test PP (Phillips–Perron)"),
          tags$ul(
            tags$li(tags$b("Rôle :"), " racine unitaire comme l’ADF, correction non paramétrique de l’autocorrélation/hétéroscédasticité."),
            tags$li(tags$b("H0 :"), " racine unitaire (non-stationnaire)."),
            tags$li(tags$b("Ha :"), " stationnarité."),
            tags$li(tags$b("Phrase-type :"), " « Le test PP a donné p = [p-value] ; au seuil α = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"),
                    " H0. Interprété avec l’ADF et le KPSS, cela suggère que la série est ",
                    tags$b("[stationnaire / non-stationnaire]"),
                    " après application de [d=…] et [D=…]. »")
          )
        )
      ),
      
      tags$p(tags$b("Interpréter ADF/KPSS/PP ensemble (logique à écrire).")),
      tags$ul(
        tags$li(tags$b("Accord idéal :"), " ADF/PP rejettent (p petit) et KPSS ne rejette pas (p grand) → forte évidence de stationnarité."),
        tags$li(tags$b("Non-stationnarité claire :"), " ADF/PP ne rejettent pas (p grand) et KPSS rejette (p petit) → différenciation nécessaire."),
        tags$li(tags$b("Conflits :"), " s’appuyer sur graphiques + ACF + tests après différenciation ; éviter de se baser sur une seule p-value.")
      ),
      
      tags$p(tags$b("Logique de différenciation :")),
      tags$ul(
        tags$li("Choisir ", tags$b("d"), " pour éliminer la tendance."),
        tags$li("Choisir ", tags$b("D"), " pour éliminer la saisonnalité stochastique (racine unitaire saisonnière)."),
        tags$li("S’arrêter dès que la stationnarité est raisonnable ; éviter la sur-différenciation.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Stationnarité et différenciation). "),
        "« La stationnarité a été évaluée via ADF, KPSS et PP. Sur la base des résultats combinés et des diagnostics visuels, ",
        "nous avons retenu [d=...] et [D=...] avec période saisonnière (s=...). La stationnarité a été revérifiée sur la série transformée avant ajustement SARIMA. »"
      ),
      
      tags$h5("Pièges (classiques)"),
      tags$ul(
        tags$li(
          tags$b("Sur-différenciation"),
          " → forte autocorrélation négative au lag 1, variance gonflée, prévisions instables."
        ),
        tags$li("En pratique, D vaut souvent ", tags$b("0 ou 1"), ". Si (D=2) est nécessaire, questionner la période saisonnière ou la série.")
      ),
      
      tags$hr(),
      
      tags$h4("[5] - Ajuster un modèle de référence : Auto-ARIMA pour obtenir un bon point de départ SARIMA"),
      
      tags$h5("Ce que les étudiants font"),
      tags$ul(
        tags$li("Utiliser une procédure ", tags$b("auto-ARIMA"), " (AICc ou similaire) pour proposer : ((p,d,q)(P,D,Q)_s)."),
        tags$li(
          "Documenter :",
          tags$ul(
            tags$li("les transformations utilisées,"),
            tags$li("les contraintes (max p/q, etc.),"),
            tags$li("si une recherche stepwise a été utilisée.")
          )
        ),
        tags$li(tags$b("Important :"), " Auto-ARIMA donne une base solide, pas une vérité gravée dans le marbre.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Modèle de référence). "),
        "« Un SARIMA de référence a été sélectionné via minimisation de l’AICc parmi des ordres ((p,q,P,Q)) sous contraintes. ",
        "La spécification retenue était SARIMA((p,d,q)(P,D,Q)_s), utilisée comme base pour des ajustements guidés par la théorie. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Auto-ARIMA peut sélectionner des modèles ", tags$b("difficiles à interpréter"), " ou légèrement instables."),
        tags$li("Pour la prévision, privilégier des modèles ", tags$b("plus simples"), " à précision comparable.")
      ),
      
      tags$hr(),
      
      tags$h4("[6] - Ajuster un modèle guidé par la théorie : SARIMA manuel via ACF/PACF + tests"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p("À partir de la série différenciée (après choix de (d, D)) :"),
      tags$ol(
        tags$li("Tracer ", tags$b("ACF/PACF"), "."),
        tags$li(
          "Proposer des structures candidates :",
          tags$ul(
            tags$li(
              "Non saisonnier :",
              tags$ul(
                tags$li("AR(p) : la PACF se coupe autour de p ; l’ACF décroît."),
                tags$li("MA(q) : l’ACF se coupe autour de q ; la PACF décroît.")
              )
            ),
            tags$li(
              "Saisonnier :",
              tags$ul(
                tags$li("AR saisonnier (P) : pics PACF aux retards (s, 2s, ...)."),
                tags$li("MA saisonnier (Q) : pics ACF aux retards (s, 2s, ...).")
              )
            )
          )
        ),
        tags$li("Ajuster un ", tags$b("petit ensemble"), " de candidats plausibles (ex. : 3–8 modèles)."),
        tags$li(
          "Comparer via :",
          tags$ul(
            tags$li("AICc/BIC,"),
            tags$li("significativité des paramètres (avec prudence),"),
            tags$li("stabilité / inversibilité.")
          )
        )
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Méthodes (Construction guidée par la théorie). "),
        "« Les structures SARIMA candidates ont été proposées d’après le comportement ACF/PACF de la série différenciée. Des pics aux retards [lags] suggéraient des composantes non saisonnières [AR/MA], ",
        "tandis que des autocorrélations aux multiples de (s) indiquaient des termes saisonniers [AR/MA]. Plusieurs modèles ont été ajustés et comparés via [AICc/BIC], la sélection finale tenant compte de la parcimonie et de l’adéquation diagnostique. »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Les heuristiques ACF/PACF sont des ", tags$b("guides"), ", pas des commandements."),
        tags$li("Éviter de brute-forcer 200 modèles puis d’appeler ça « théorie ». Préférer un ", tags$b("petit ensemble raisonné"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[7] - Diagnostiquer & comparer : tests des résidus + précision de prévision ; choisir le modèle final"),
      
      tags$h5("Ce que les étudiants font"),
      tags$p(tags$b("Diagnostics des résidus (indispensable) :")),
      tags$ul(
        tags$li("Courbe des résidus (doit ressembler à du bruit)."),
        tags$li("ACF des résidus (pas de gros pics)."),
        tags$li(tags$b("Test de Ljung–Box"), " pour l’autocorrélation des résidus."),
        tags$li("Vérification de normalité (QQ-plot ; Shapiro-Wilk est trop sensible pour grands n)."),
        tags$li("Vérifier l’hétéroscédasticité (variance changeante).")
      ),
      
      tags$p(tags$b("Évaluation de la prévision (indispensable) :")),
      tags$ul(
        tags$li("Échantillon test ou validation croisée rolling."),
        tags$li("Métriques : MAE/RMSE ; MAPE seulement si la série n’est jamais proche de zéro."),
        tags$li(
          "Comparer :",
          tags$ul(
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats SARIMA manuels,"),
            tags$li("éventuellement un benchmark simple (naïf saisonnier).")
          )
        )
      ),
      
      tags$p(tags$b("Règle de choix (saine) :")),
      tags$ul(
        tags$li("Doit passer les diagnostics de façon raisonnable."),
        tags$li("Doit battre le benchmark naïf."),
        tags$li("Préférer le modèle le plus simple si la précision est quasi identique.")
      ),
      
      tags$h5("Ce qu’ils écrivent"),
      tags$p(
        tags$b("Résultats (Diagnostics et performance). "),
        "« Les diagnostics des résidus indiquaient un comportement proche du bruit blanc : les autocorrélations résiduelles étaient faibles et le test de Ljung–Box était [non significatif/significatif] au seuil (α=...). ",
        "La performance de prévision sur la fenêtre d’évaluation donnait MAE=(...) et RMSE=(...), surpassant les modèles de référence et de benchmark. Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). »"
      ),
      
      tags$h5("Pièges"),
      tags$ul(
        tags$li("Un modèle avec un excellent AIC mais des résidus autocorrélés te ", tags$i("raconte une belle histoire"), " — mais fausse."),
        tags$li("Des résidus non normaux peuvent encore donner de bonnes prévisions ; le problème majeur est l’", tags$b("autocorrélation"), " résiduelle.")
      ),
      
      tags$hr(),
      
      tags$h4("[8] - Rédiger le rapport : paragraphes APA à chaque étape ; assembler Méthodes/Résultats"),
      
      tags$h5("Ce que les étudiants font (checklist d’assemblage)"),
      tags$p(tags$b("Section Méthodes")),
      tags$ul(
        tags$li("Données (source, fréquence, traitement du manque, transformation)."),
        tags$li("Approche exploratoire (graphiques, décomposition)."),
        tags$li("Tests de stationnarité et choix de différenciation."),
        tags$li("Baseline (paramètres auto-ARIMA)."),
        tags$li("Justification de la sélection manuelle (ACF/PACF + candidats)."),
        tags$li("Diagnostics et protocole d’évaluation.")
      ),
      
      tags$p(tags$b("Section Résultats")),
      tags$ul(
        tags$li("Résumé des données + observations visuelles clés."),
        tags$li("Résultats de décomposition (tendance/saisonnalité)."),
        tags$li("Résultats des tests de stationnarité et choix (d, D)."),
        tags$li("Paramètres du modèle final."),
        tags$li("Diagnostics et métriques de précision."),
        tags$li("Graphique de prévision + tableau d’erreurs.")
      ),
      
      tags$h5("Guidance (structure APA)"),
      tags$ul(
        tags$li("Pour chaque sous-section : ", tags$b("Ce qu’on a fait → Pourquoi → Ce qu’on a observé → Conclusion"), "."),
        tags$li("Passé pour Méthodes ; passé orienté résultats pour Résultats."),
        tags$li("Écrire les maths avec parcimonie ; donner la spécification complète du modèle une seule fois, clairement.")
      ),
      
      tags$hr(),
      
      tags$h4("Un « pack livrable » propre que les étudiants doivent rendre"),
      tags$ul(
        tags$li(
          "Un notebook/script qui :",
          tags$ul(
            tags$li("charge les données,"),
            tags$li("traite les valeurs manquantes,"),
            tags$li("réalise l’EDA (graphiques),"),
            tags$li("décomposition,"),
            tags$li("tests de stationnarité,"),
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats manuels,"),
            tags$li("diagnostics,"),
            tags$li("évaluation,"),
            tags$li("prévision finale.")
          )
        ),
        tags$li(
          "Un court rapport avec :",
          tags$ul(
            tags$li("Méthodes + Résultats alignés aux étapes 1–7,"),
            tags$li("figures : courbe temporelle, décomposition, ACF/PACF, ACF des résidus, graphique de prévision,"),
            tags$li("tableau comparatif des modèles candidats (AICc + métriques).")
          )
        )
      ),
      
      tags$hr()
    )
  })
  
  
  
  
  
  
  
  
  
  #=============================================================================
  #=============================================================================
  #=============================================================================
  
  
 
  # # --- Roadmap slider navigation (Prev/Next) ---
  # observeEvent(input$road_prev, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  # }, ignoreInit = TRUE)
  # 
  # observeEvent(input$road_next, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  # }, ignoreInit = TRUE)
  
  
  

  # =========================
  # Roadmap UI (controls)
  # =========================
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  #   
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  #     
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:600;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #   ")),
  #     
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
  #     tags$p(class="road-sub",
  #            "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
  #     
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput(
  #         "roadmap_step", label = NULL,
  #         min = 0, max = 10, value = 0, step = 1, width = "520px"
  #       ),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
  #     ),
  #     
  #     # Progress bar (pure UI, updated via re-render of content)
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  
  
  # =========================
  # Roadmap UI (content)
  # =========================
  # output$roadmap_step_content <- renderUI({
  #   
  #   # Helpers (local)
  #   D <- function(title, ...) tags$details(tags$summary(title), ...)
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   
  #   cur <- input$roadmap_step
  #   if (is.null(cur) || !is.finite(cur)) cur <- 0
  #   cur <- as.integer(cur)
  #   
  #   step_names <- c(
  #     "Aperçu & notations",
  #     "Étape 0 — Préparer le terrain",
  #     "Étape 1 — Décrire les données",
  #     "Étape 2 — Explorer visuellement (EDA)",
  #     "Étape 3 — Décomposer (tendance/saison)",
  #     "Étape 4 — Stationnarité & différenciation (d, D)",
  #     "Étape 5 — Baseline Auto-ARIMA",
  #     "Étape 6 — SARIMA manuel guidé (ACF/PACF)",
  #     "Étape 7 — Diagnostics & comparaison",
  #     "Étape 8 — Rédaction & livrables",
  #     "Annexes — formules, benchmarks, checklists"
  #   )
  #   
  #   # Progress (%)
  #   pct <- round(100 * cur / 10)
  #   progress_ui <- tags$div(
  #     class="progress",
  #     tags$div(
  #       class="progress-bar",
  #       role="progressbar",
  #       `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #       style = paste0("width:", pct, "%;")
  #     )
  #   )
  #   
  #   # --- Pages (one per step) ---
  #   pages <- vector("list", length = 11)
  #   
  #   # 0) Aperçu & notations
  #   pages[[1]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[1]),
  #     tags$div(class="callout ok",
  #              tags$b("Objectif : "), "produire une prévision fiable + un rapport reproductible, en battant un benchmark simple."),
  #     D("Notation SARIMA (à citer dans le rapport)",
  #       UL(
  #         tags$li(tags$b("SARIMA((p,d,q)(P,D,Q))"), " avec période saisonnière ", tags$code("s"), "."),
  #         tags$li("Opérateurs : ", tags$code("B y_t = y_{t-1}"), ", ", tags$code("∇ = 1-B"), ", ", tags$code("∇_s = 1-B^s"), "."),
  #         tags$li(tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"), " avec ", tags$code("ε_t ~ w.n.(0, σ^2)"), ".")
  #       )
  #     ),
  #     D("Roadmap (résumé en 8 étapes)",
  #       OL(
  #         tags$li("Définir série, fréquence, horizon, métrique, protocole test."),
  #         tags$li("Contrôler données (manquants, anomalies), stats descriptives."),
  #         tags$li("EDA : tendance/saison/outliers (graphiques)."),
  #         tags$li("Décomposition (additif vs multiplicatif; STL)."),
  #         tags$li("Stationnarité : ADF/KPSS/PP → choisir d et D."),
  #         tags$li("Baseline auto-ARIMA (point de départ)."),
  #         tags$li("SARIMA manuel (ACF/PACF) : 3–8 candidats raisonnés."),
  #         tags$li("Diagnostics + évaluation (benchmarks) → modèle final + prévision.")
  #       )
  #     ),
  #     D("Phrase APA prête à l’emploi (méthodes)",
  #       tags$p("« Nous avons modélisé la série temporelle univariée ", tags$code("y_t"),
  #              " observée à une fréquence [..] sur [..]. Un modèle SARIMA((p,d,q)(P,D,Q)_s) a été sélectionné par comparaison de candidats ",
  #              "via [AICc/BIC] et par validation temporelle [split/rolling-origin], avec évaluation par [MAE/RMSE]. »")
  #     )
  #   )
  #   
  #   # Étape 0
  #   pages[[2]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[2]),
  #     D("Actions (à faire)",
  #       UL(
  #         tags$li("Définir ", tags$b("y_t"), ", l’index temps, la fréquence (s), l’horizon h."),
  #         tags$li("Choisir protocole : split train/test ou origine glissante."),
  #         tags$li("Choisir métriques : MAE + RMSE (MAPE seulement si y>0 et loin de 0)."),
  #         tags$li("Décider transformation : aucune / log / Box–Cox.")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« L’objectif était de prévoir à horizon ", tags$code("h"), " selon un protocole [..]. ",
  #              "Les performances ont été mesurées via [MAE/RMSE]. Une transformation [..] a été appliquée pour [stabiliser la variance / rendre le modèle additif]. »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Fréquence incohérente → SARIMA devient fragile (régulariser avant)."),
  #         tags$li("Choisir MAPE alors que y≈0 → métrique trompeuse.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 1
  #   pages[[3]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[3]),
  #     D("Actions (à faire)",
  #       OL(
  #         tags$li("Rapporter n, dates début/fin, fréquence, % manquants."),
  #         tags$li("Traiter manquants : interpolation (rare) ou stratégie plus robuste (si nombreux)."),
  #         tags$li("Résumés : moyenne, médiane, ET, min/max + résumés saisonniers (par mois/semaine).")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« La série contient ", tags$code("n"), " observations de [..] à [..]. ",
  #              "Les valeurs manquantes représentaient [..]% et ont été traitées par [..] car [..]. ",
  #              "La moyenne était [..] (ET=[..]). »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Imputation non documentée (à éviter)."),
  #         tags$li("Confondre outlier et erreur : demander le contexte.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 2
  #   pages[[4]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[4]),
  #     D("Actions (à faire)",
  #       UL(
  #         tags$li("Tracer y_t (niveau ou transformé)."),
  #         tags$li("Graphiques saisonniers (par mois/semaine) + boxplots saisonniers."),
  #         tags$li("Repérer ruptures, outliers, changements de variance.")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« L’analyse exploratoire suggère une tendance [..] et une saisonnalité de période ", tags$code("s"),
  #              ". La variance semblait [..], motivant [..]. Des valeurs atypiques près de [..] ont été [conservées/traitées] car [..]. »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Supprimer des points “bizarres” sans justification."),
  #         tags$li("Ignorer une rupture structurelle → diagnostics résiduels échouent ensuite.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 3
  #   pages[[5]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[5]),
  #     D("Actions (à faire)",
  #       UL(
  #         tags$li("Décomposition pour séparer tendance / saison / résidu."),
  #         tags$li("Décider additif vs multiplicatif (souvent log si multiplicatif)."),
  #         tags$li("STL si saisonnalité évolutive ou besoin robustesse.")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« Nous avons comparé une structure additive vs multiplicative. ",
  #              "Comme l’amplitude saisonnière [était constante / croissait avec le niveau], nous avons retenu [additif / log] ",
  #              "et décomposé via [classique/STL]. »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Utiliser STL comme “modèle final” : STL décrit, SARIMA modélise."),
  #         tags$li("Oublier de discuter l’évolution de l’amplitude saisonnière.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 4
  #   pages[[6]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[6]),
  #     tags$div(class="callout",
  #              tags$b("Idée clé : "), "ADF/PP testent racine unitaire (H0=non-stationnaire), KPSS inverse (H0=stationnaire)."),
  #     D("Actions (à faire)",
  #       OL(
  #         tags$li("Fixer la période s (ex. 12 mensuel, 7 quotidien-hebdo)."),
  #         tags$li("Tester ADF + KPSS (+ PP si dispo) sur série brute puis après différences."),
  #         tags$li("Choisir d et D minimums rendant la série raisonnablement stationnaire."),
  #         tags$li("Vérifier ACF/PACF après différenciation (éviter sur-différenciation).")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« La stationnarité a été évaluée via ADF, KPSS (et PP). ",
  #              "Les résultats combinés suggéraient une différenciation ordinaire ", tags$code("d"),
  #              " = [..] et saisonnière ", tags$code("D"), " = [..] avec ", tags$code("s"), " = [..]. ",
  #              "La stationnarité a été revérifiée sur la série transformée. »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Sur-différenciation → ACF lag 1 fortement négative, prévisions instables."),
  #         tags$li("Mettre D=2 sans questionner s ou la source de données.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 5
  #   pages[[7]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[7]),
  #     D("Actions (à faire)",
  #       UL(
  #         tags$li("Lancer auto-ARIMA pour une baseline (AICc)."),
  #         tags$li("Documenter : transformations, contraintes (max p/q/P/Q), stepwise ou recherche exhaustive."),
  #         tags$li("Garder la baseline comme comparateur (pas comme dogme).")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« Un modèle de référence a été sélectionné par minimisation de l’AICc parmi des ordres candidats sous contraintes. ",
  #              "La spécification obtenue, SARIMA((p,d,q)(P,D,Q)_s), a servi de point de départ pour des ajustements guidés par les diagnostics. »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Comparer des AIC entre séries sur des échelles différentes (ex. log vs niveau) sans prudence."),
  #         tags$li("Choisir le plus petit AICc sans vérifier les résidus.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 6
  #   pages[[8]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[8]),
  #     D("Actions (à faire)",
  #       OL(
  #         tags$li("Sur la série différenciée : examiner ACF/PACF (non-saisonnier + saisonnier)."),
  #         tags$li("Proposer 3–8 candidats plausibles (parcimonie)."),
  #         tags$li("Ajuster, vérifier stabilité/inversibilité + significativité (secondaire)."),
  #         tags$li("Comparer (AICc/BIC) + diagnostics.")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« Les candidats ont été proposés à partir des schémas ACF/PACF. ",
  #              "Des pics aux multiples de ", tags$code("s"), " ont motivé des termes saisonniers. ",
  #              "La sélection finale a privilégié la parcimonie sous contraintes diagnostiques satisfaisantes. »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Tester trop de modèles → sur-sélection (data snooping)."),
  #         tags$li("Se focaliser sur p-values : priorité = résidus ~ bruit blanc + performance out-of-sample.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 7
  #   pages[[9]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[9]),
  #     D("Actions (à faire)",
  #       UL(
  #         tags$li("Diagnostics résidus : série, ACF résidus, Ljung–Box (pas d’autocorrélation résiduelle)."),
  #         tags$li("Contrôler variance (ARCH) si besoin ; normalité utile mais secondaire pour la prévision."),
  #         tags$li("Évaluer prévision sur test/rolling-origin ; comparer au benchmark (naïf / SNAIVE).")
  #       )
  #     ),
  #     D("À écrire (APA)",
  #       tags$p("« Les résidus étaient compatibles avec un bruit blanc (Ljung–Box p = [..]). ",
  #              "La performance prédictive sur [test/rolling-origin] donnait MAE = [..], RMSE = [..], ",
  #              "surpassant le benchmark [naïf/SNAIVE]. Le modèle retenu est SARIMA((p,d,q)(P,D,Q)_s). »")
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Bon AIC mais Ljung–Box significatif → modèle mal spécifié."),
  #         tags$li("Évaluer uniquement in-sample → illusion de performance.")
  #       )
  #     )
  #   )
  #   
  #   # Étape 8
  #   pages[[10]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[10]),
  #     D("Livrables minimaux (ce que l’étudiant rend)",
  #       UL(
  #         tags$li("Script/notebook reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
  #         tags$li("Rapport Méthodes/Résultats : 6–10 pages max, figures + tableau comparatif des modèles."),
  #         tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC.")
  #       )
  #     ),
  #     D("Tableau recommandé (modèles candidats)",
  #       UL(
  #         tags$li("Colonnes : (p,d,q)(P,D,Q)[s], AICc, BIC, Ljung–Box p, MAE, RMSE, benchmark battu ?"),
  #         tags$li("Choisir le modèle le plus simple qui passe diagnostics et bat le benchmark.")
  #       )
  #     ),
  #     D("Pièges",
  #       UL(
  #         tags$li("Pas de protocole d’évaluation clair → résultats non comparables."),
  #         tags$li("Pas de benchmark → impossible de juger si “bon”.")
  #       )
  #     )
  #   )
  #   
  #   # Annexes
  #   pages[[11]] <- tags$div(
  #     class="road-card",
  #     tags$h4(step_names[11]),
  #     D("Benchmarks (à toujours inclure)",
  #       UL(
  #         tags$li(tags$b("Naïf : "), tags$code("ŷ_{t+1|t} = y_t")),
  #         tags$li(tags$b("Drift : "), tags$code("ŷ_{t+h|t} = y_t + h * (y_t - y_1)/(t-1)")),
  #         tags$li(tags$b("SNAIVE : "), tags$code("ŷ_{t+h|t} = y_{t+h-s}"))
  #       )
  #     ),
  #     D("Métriques (rappel)",
  #       UL(
  #         tags$li(tags$b("MAE : "), tags$code("mean(|e_t|)")),
  #         tags$li(tags$b("RMSE : "), tags$code("sqrt(mean(e_t^2))")),
  #         tags$li(tags$b("MAPE : "), tags$code("mean(|e_t / y_t|)"), " (éviter si y≈0)."),
  #         tags$li(tags$b("sMAPE : "), tags$code("mean( 2|e_t| / (|y_t|+|ŷ_t|) )"))
  #       )
  #     ),
  #     D("Critères d’information (rappel)",
  #       UL(
  #         tags$li(tags$code("AIC = -2ℓ + 2k")),
  #         tags$li(tags$code("BIC = -2ℓ + k ln(n)")),
  #         tags$li(tags$code("AICc = AIC + 2k(k+1)/(n-k-1)"))
  #       )
  #     ),
  #     D("Rolling-origin (pseudo)",
  #       tags$pre("
  #       for (origin in origins) {
  #         fit <- Arima(y[1:origin], order=c(p,d,q), seasonal=c(P,D,Q))
  #         fc  <- forecast(fit, h=h)
  #         err <- accuracy(fc, y[(origin+1):(origin+h)])
  #       }
  #       ")
  #     ),
  #     tags$div(class="callout warn",
  #              tags$b("Règle d’or : "),
  #              "si le modèle ne bat pas SNAIVE à l’horizon cible, il faut le remettre en question.")
  #   )
  #   
  #   # Final assembly
  #   tagList(
  #     tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
  #     progress_ui,
  #     pages[[cur + 1L]]
  #   )
  # })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  #=============================================================================
  #======================  Good Code =======================================================
  #=============================================================================
  
  
  
  
  # # =========================
  # # SARIMA Roadmap v4 — long-form explanations (pliable), no copy buttons
  # # =========================
  # 
  # # --- Step titles (unchanged) ---
  # step_titles <- c(
  #   "Aperçu & notations (glossaire + lecture du modèle)",
  #   "Étape 0 — Définir le problème de modélisation",
  #   "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
  #   "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
  #   "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
  #   "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (+ avancés)",
  #   "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
  #   "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
  #   "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
  #   "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
  #   "Annexes — Formules, checklists, templates, interprétations rapides"
  # )
  # .road_max <- length(step_titles) - 1L
  # 
  # # --- Prev/Next (unchanged) ---
  # observeEvent(input$road_prev, {
  #   cur <- as.integer(if (is.null(input$roadmap_step)) 0L else input$roadmap_step)
  #   updateSliderInput(session, "roadmap_step", value = max(0L, cur - 1L))
  # }, ignoreInit = TRUE)
  # observeEvent(input$road_next, {
  #   cur <- as.integer(if (is.null(input$roadmap_step)) 0L else input$roadmap_step)
  #   updateSliderInput(session, "roadmap_step", value = min(.road_max, cur + 1L))
  # }, ignoreInit = TRUE)
  # 
  # # --- Controls UI (unchanged) ---
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:700;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     .road-scroll {max-height:62vh; overflow-y:auto; padding-right:10px;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #     .road-toolbar {display:flex; gap:8px; flex-wrap:wrap; align-items:center;}
  #     mark.road-hit {background:#fff2ac;}
  #   ")),
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique v4)"),
  #     tags$p(class="road-sub",
  #            "Navigation ←/→ (clavier). Chaque carte suit : Objectifs → Définitions (pliables, phrases complètes) → Actions → APA (pliable) → Évaluation → Pièges."
  #     ),
  #     
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput("roadmap_step", label = NULL,
  #                   min = 0, max = .road_max, value = 0, step = 1, width = "520px"),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : repliez les blocs pour garder une lecture compacte.")
  #     ),
  #     
  #     tags$div(class="road-toolbar",
  #              actionButton("road_expand", "Tout déplier"),
  #              actionButton("road_collapse", "Tout replier"),
  #              textInput("road_find", NULL, placeholder = "Rechercher (page courante)…", width = "260px")
  #     ),
  #     
  #     # Keyboard + expand/collapse + search
  #     tags$script(HTML("
  #     document.addEventListener('keydown', function(e){
  #       if(e.key==='ArrowLeft'){Shiny.setInputValue('road_prev', Math.random());}
  #       if(e.key==='ArrowRight'){Shiny.setInputValue('road_next', Math.random());}
  #     });
  #     Shiny.addCustomMessageHandler('road_toggle_details', function(open){
  #       document.querySelectorAll('#road_container details').forEach(d => d.open = open);
  #     });
  #     Shiny.addCustomMessageHandler('road_find', function(q){
  #       const root = document.getElementById('road_container');
  #       if(!root) return;
  #       root.querySelectorAll('mark.road-hit').forEach(m=>{ const t=document.createTextNode(m.textContent); m.replaceWith(t); });
  #       if(!q){ return; }
  #       const rx = new RegExp(q.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&'), 'gi');
  #       root.querySelectorAll('.road-scroll').forEach(box=>{
  #         const walker = document.createTreeWalker(box, NodeFilter.SHOW_TEXT);
  #         const nodes = [];
  #         while(walker.nextNode()) nodes.push(walker.currentNode);
  #         nodes.forEach(n=>{
  #           const s = n.nodeValue; if(!s) return;
  #           const frag = document.createDocumentFragment();
  #           let last = 0; s.replace(rx, (m, idx) => {
  #             frag.appendChild(document.createTextNode(s.slice(last, idx)));
  #             const mk = document.createElement('mark'); mk.className='road-hit'; mk.textContent=m;
  #             frag.appendChild(mk); last = idx + m.length;
  #           });
  #           if(last){ frag.appendChild(document.createTextNode(s.slice(last))); n.replaceWith(frag); }
  #         });
  #       });
  #     });
  #   ")),
  #     
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  # observeEvent(input$road_expand,  { session$sendCustomMessage("road_toggle_details", TRUE) })
  # observeEvent(input$road_collapse,{ session$sendCustomMessage("road_toggle_details", FALSE) })
  # observeEvent(input$road_find,    { session$sendCustomMessage("road_find", input$road_find %||% "") })
  # `%||%` <- function(a,b) if (is.null(a) || length(a)==0) b else a
  # 
  # # --- CONTENT RENDERER (long-form) --------------------------------------------
  # output$roadmap_step_content <- renderUI({
  #   # Helpers
  #   D  <- function(title, ...) tags$details(tags$summary(title), tags$div(class="road-scroll", ...))
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   P  <- function(...) tags$p(...)
  #   B  <- function(...) tags$b(...)
  #   C  <- function(...) tags$code(...)
  #   H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
  #   
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  #   
  #   # Long-form Concept (pliable)
  #   Concept <- function(title, ...) {
  #     tags$details(tags$summary(title), tags$div(..., style="margin-top:6px;"))
  #   }
  #   
  #   # Exhaustive Test card (pliable)
  #   TestCard <- function(id, name, def, why, H0, Ha, stat, decision, concl, notes=NULL) {
  #     tags$details(
  #       id = id,
  #       tags$summary(name),
  #       tags$div(
  #         H5("Définition"), P(def),
  #         H5("Pourquoi on l’utilise"), P(why),
  #         H5("Hypothèses"),
  #         UL(tags$li(B("H0 : "), H0), tags$li(B("Ha : "), Ha)),
  #         H5("Formulation / Statistique de test"), stat,
  #         H5("Règle de décision"), decision,
  #         H5("Conclusion-type à rapporter"), concl,
  #         if (!is.null(notes)) tagList(H5("Notes & bonnes pratiques"), notes)
  #       )
  #     )
  #   }
  #   
  #   make_step <- function(title, objectifs, defs, actions, apa, evals, pitfalls, extras = NULL) {
  #     tags$div(
  #       class = "road-card",
  #       tags$h4(title),
  #       D("Objectifs (ce qui doit être démontré)", objectifs),
  #       D("Définitions détaillées (cliquer pour développer)", defs),
  #       D("Actions (procédure pas à pas)", actions),
  #       D("Texte APA (cliquer pour développer)", apa),
  #       D("Évaluation & critères de validation", evals),
  #       D("Pièges & comment les éviter", pitfalls),
  #       if (!is.null(extras)) D("Annexes & cartes de tests (cliquer pour développer)", extras)
  #     )
  #   }
  #   
  #   css <- tags$style(HTML("
  #   .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #   details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #   details > summary {cursor:pointer;font-weight:700;}
  #   .road-scroll {max-height:62vh; overflow-y:auto; padding-right:10px;}
  #   .progress {height:10px; margin:10px 0 0 0;}
  # "))
  #   
  #   cur <- as.integer(input$roadmap_step %||% 0L)
  #   cur <- max(0L, min(.road_max, cur))
  #   pct <- round(100 * cur / .road_max)
  #   
  #   progress_ui <- tags$div(class="progress",
  #                           tags$div(class="progress-bar", role="progressbar",
  #                                    `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #                                    style = paste0("width:", pct, "%;"))
  #   )
  #   
  #   pages <- list()
  #   
  #   # ========== Page 0 — Aperçu & notations ==========
  #   pages[[1]] <- make_step(
  #     step_titles[1],
  #     objectifs = tagList(
  #       P("L’étudiant doit comprendre la structure algébrique du modèle SARIMA et ce que chaque bloc apporte à l’explication de la dynamique temporelle. ",
  #         "L’objectif n’est pas d’obtenir un AIC minimal à tout prix, mais d’aboutir à un modèle capable de produire des prévisions fiables, ",
  #         "dont les résidus sont compatibles avec un bruit blanc et dont la complexité reste raisonnable au regard des gains de performance."),
  #       P("L’étudiant doit également savoir relier les écritures polynomiales en ", C("B"), " (opérateur de retard) aux idées de causalité/stabilité pour la partie auto-régressive, ",
  #         "et d’inversibilité pour la partie moyenne mobile, car ces propriétés conditionnent le comportement de long terme et la validité des prévisions.")
  #     ),
  #     defs = tagList(
  #       Concept("Backshift et différenciations : ce que l’on « retire » à la série",
  #               P("L’opérateur de retard ", C("B"), " décale la série d’un pas : ", C("B y_t = y_{t-1}"), ". ",
  #                 "Les opérateurs de différence ", C("∇=(1-B)"), " et ", C("∇_s=(1-B^s)"), " calculent respectivement la variation d’un pas ",
  #                 "et la variation d’une saison. Les puissances ", C("∇^d"), " et ", C("∇_s^D"), " répètent l’opération autant de fois que nécessaire. ",
  #                 "Différencier une série revient à éliminer des tendances stochastiques : la différence ordinaire vise les racines unitaires non saisonnières, ",
  #                 "alors que la différence saisonnière vise des racines unitaires aux fréquences saisonnières. Un bon choix de ", C("d"), " et ", C("D"), " ",
  #                 "rend la série suffisamment stationnaire pour que les composantes AR et MA capturent la dépendance restante.")
  #       ),
  #       Concept("Polynômes AR/MA, stabilité et inversibilité : pourquoi ces contraintes existent",
  #               P(
  #                 "Les composantes auto-régressives et moyenne mobile sont définies par des polynômes en ", C("B"), " : ",
  #                 C("φ(B)=1-φ_1 B-...-φ_p B^p"), " pour l’AR et ", C("θ(B)=1+θ_1 B+...+θ_q B^q"), " pour la MA; leurs versions saisonnières utilisent ", C("B^s"), ". ",
  #                 "La ", B("stabilité/causalité"), " exige que toutes les racines de ", C("φ(z)=0"), " et ", C("Φ(z^s)=0"), " se situent en dehors du cercle unité. ",
  #                 "Cette condition garantit que les chocs s’éteignent à long terme et que le processus ne diverge pas. ",
  #                 "L’", B("inversibilité"), " impose la même contrainte sur ", C("θ(z)"), " et ", C("Θ(z^s)"), " afin que le modèle puisse être ré-écrit comme un AR(∞) ",
  #                 "et que l’identification des paramètres soit possible. Dans l’enseignement, on insiste sur ces idées, car un modèle qui viole ces conditions ",
  #                 "peut afficher un AIC flatteur tout en produisant des prévisions instables ou non interprétables."
  #               )
  #       ),
  #       Concept("Constante et drift : comment lire une tendance moyenne dans un ARIMA",
  #               P("Dans un ARIMA avec ", C("d=0"), ", une constante représente un niveau moyen autour duquel la série fluctue. ",
  #                 "Dans un ARIMA avec ", C("d=1"), ", la présence d’une constante se traduit par un ", B("drift"), ", c’est-à-dire une pente moyenne ",
  #                 "sur l’échelle des niveaux. En pratique, inclure ou exclure ce terme doit être justifié empiriquement (diagnostics et performance), ",
  #                 "et expliqué conceptuellement aux étudiants : le drift formalise une progression moyenne qui n’est pas entièrement capturée par la dynamique ARMA.")
  #       ),
  #       Concept("Bruit blanc et innovations : ce que « résidus ~ bruit blanc » signifie vraiment",
  #               P("Dire que les résidus « ressemblent à un bruit blanc » signifie qu’ils n’exhibent pas de structure temporelle exploitable : ",
  #                 "leur moyenne est proche de zéro, leur variance est stable et leurs autocorrélations ne sont pas significatives. ",
  #                 "Cette propriété ne garantit pas l’indépendance complète, mais elle indique que le modèle a capturé l’essentiel de la dépendance en série. ",
  #                 "Dans un cadre pédagogique, il faut insister sur le fait que des résidus non blancs conduisent en général à des intervalles de prévision trop optimistes.")
  #       ),
  #       Concept("Formulation état–espace et filtre de Kalman : pourquoi c’est utile même si l’on n’approfondit pas",
  #               P("Tout ARIMA/SARIMA peut être réécrit dans une forme état–espace qui sépare l’évolution d’états latents et l’équation d’observation. ",
  #                 "Le filtre de Kalman fournit alors un cadre rigoureux pour traiter des valeurs manquantes, produire des lissages, et calculer des vraisemblances. ",
  #                 "Même sans entrer dans les détails mathématiques, présenter ce lien aide à comprendre pourquoi certains logiciels gèrent les manquants « nativement ». ")
  #       ),
  #       Concept("Types de prévisions : point, intervalles et distributions prédictives",
  #               P("Une ", B("prévision ponctuelle"), " résume la distribution future par un seul nombre (moyenne ou médiane). ",
  #                 "Un ", B("intervalle de prévision"), " exprime l’incertitude autour de cette prévision pour un niveau de couverture (par exemple 80 % ou 95 %). ",
  #                 "Une ", B("prévision en densité"), " modélise toute la distribution. D’un point de vue pédagogique, il est précieux de montrer que de bons points ",
  #                 "ne suffisent pas : un modèle doit aussi proposer des intervalles bien calibrés, ni trop larges (peu informatifs) ni trop étroits (trompeurs).")
  #       ),
  #       Concept("Critères d’information : comment lire AIC, AICc et BIC sans les absolutiser",
  #               P("Les critères d’information comparent des modèles en pondérant l’adéquation (via la log-vraisemblance) par une pénalité liée au nombre de paramètres. ",
  #                 "L’", B("AIC"), " vise la bonne généralisation prédictive, l’", B("AICc"), " corrige l’optimisme en petit échantillon, et le ", B("BIC"),
  #                 " pénalise plus fortement la complexité. Ces critères sont pertinents si l’on compare des modèles estimés sur la même série, au même échantillon, ",
  #                 "et avec la même transformation. Ils ne remplacent jamais les diagnostics résiduels ni les évaluations hors-échantillon.")
  #       )
  #     ),
  #     actions = tagList(
  #       P("1) Fixez la fréquence de la série et la période saisonnière ", C("s"), " en vous appuyant sur le contexte métier et une inspection visuelle. ",
  #         "2) Décidez si une transformation (log, Box–Cox, Yeo–Johnson) est nécessaire pour stabiliser la variance; ",
  #         "expliquez clairement ce choix aux étudiants. 3) Définissez des benchmarks simples (Naïf, Drift, SNAIVE) : ils fourniront une référence ",
  #         "indispensable pour juger l’intérêt réel d’un SARIMA.")
  #     ),
  #     apa = tags$details(
  #       tags$summary("Phrase APA (cliquer pour développer)"),
  #       P("« Nous modélisons la série ", C("y_t"), " observée à une fréquence [..] (période saisonnière s = [..]) à l’aide d’un modèle SARIMA ",
  #         C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"), ". L’objectif de l’analyse est résolument prédictif : la sélection finale du modèle ",
  #         "s’appuie conjointement sur des diagnostics résiduels (notamment l’absence d’autocorrélation) et sur des comparaisons de performance ",
  #         "hors échantillon vis-à-vis de benchmarks simples. »")
  #     ),
  #     evals = tagList(
  #       P("Le modèle est considéré comme adéquat si les résidus ne présentent pas d’autocorrélations significatives (au sens de l’ACF et du Ljung–Box) ",
  #         "et si ses prévisions battent des repères simples selon des métriques transparentes (MAE, RMSE, MASE). ",
  #         "À performance comparable, on privilégie systématiquement la spécification la plus parcimonieuse.")
  #     ),
  #     pitfalls = tagList(
  #       P("Une erreur fréquente consiste à confondre « meilleur AIC » et « meilleur modèle ». Un critère d’information favorable n’a de sens ",
  #         "qu’accompagné de diagnostics satisfaisants et d’un gain prédictif tangible sur un futur réellement non observé.")
  #     )
  #   )
  #   
  #   # ========== Page 1 — Étape 0 (problème) ==========
  #   pages[[2]] <- make_step(
  #     step_titles[2],
  #     objectifs = tagList(
  #       P("L’objectif est de formuler le problème de prévision avec suffisamment de précision pour rendre toute comparaison de modèles juste et reproductible. ",
  #         "Cela implique de fixer l’horizon ", C("h"), ", d’expliciter le protocole d’évaluation temporelle (split unique ou rolling-origin) et ",
  #         "de justifier les métriques retenues, tout en exposant clairement la transformation appliquée à la série si celle-ci est nécessaire.")
  #     ),
  #     defs = tagList(
  #       Concept("Origine de prévision et fenêtres d’évaluation",
  #               P("L’", B("origine de prévision"), " est la dernière date observée à partir de laquelle on génère les prédictions. ",
  #                 "Dans une ", B("validation rolling-origin"), ", on répète cette opération à plusieurs origines, ce qui fournit une estimation plus robuste ",
  #                 "de la performance que celle obtenue à une seule coupure temporelle. La fenêtre d’entraînement peut être expansive (on conserve tout le passé) ",
  #                 "ou glissante (on garde une longueur fixe) ; ce choix doit être motivé par la stabilité supposée de la relation temporelle et par les contraintes de calcul.")
  #       ),
  #       Concept("Métriques de précision : ce qu’elles mesurent et comment les expliquer aux étudiants",
  #               P("La ", B("MAE"), " exprime l’erreur moyenne en unités de la série et se lit facilement comme une grandeur tangible. ",
  #                 "La ", B("RMSE"), " pénalise davantage les grosses erreurs, ce qui peut être approprié si l’usage tolère mal les écarts extrêmes. ",
  #                 "La ", B("MASE"), " normalise l’erreur par celle d’un benchmark saisonnier, rendant les scores comparables entre séries ou entre périodes. ",
  #                 "La ", B("WAPE"), " agrège l’erreur absolue en pourcentage du total observé, utile pour raisonner en parts relatives. ",
  #                 "On évitera la ", B("MAPE"), " si la série prend des valeurs proches de zéro, car la métrique devient explosive et trompeuse.")
  #       ),
  #       Concept("Transformations (log, Box–Cox, Yeo–Johnson) : quand et comment les justifier",
  #               P("Lorsqu’une série présente une variance qui croît avec son niveau, une transformation peut améliorer la stabilité et la lisibilité du modèle. ",
  #                 "Le ", B("log"), " est simple et interprétable mais requiert des valeurs strictement positives. ",
  #                 "La ", B("Box–Cox"), " ajuste un paramètre ", C("λ"), " pour moduler la concavité et inclut le log comme cas limite (", C("λ=0"), "). ",
  #                 "La transformation de ", B("Yeo–Johnson"), " est une alternative qui gère les valeurs négatives. ",
  #                 "Dans un cours, insistez sur la nécessité de documenter le choix de ", C("λ"), " et sur la reconversion des prévisions sur l’échelle d’origine.")
  #       )
  #     ),
  #     actions = tagList(
  #       P("Définissez précisément l’horizon cible ", C("h"), " et la manière dont il sera évalué (split unique réaliste ou rolling-origin). ",
  #         "Choisissez des métriques adaptées au contexte et explicitez leur signification opérationnelle. ",
  #         "Décidez enfin si une transformation est requise, en montrant aux étudiants l’argument empirique (relation niveau–variance) qui motive ce choix.")
  #     ),
  #     apa = tags$details(
  #       tags$summary("Méthodes (APA) — cliquer pour développer"),
  #       P("« Nous visons des prévisions à horizon ", C("h"), "=[..], évaluées selon un protocole [split temporel / rolling-origin]. ",
  #         "La précision est mesurée par [MAE, RMSE, MASE], choisies pour leur interprétabilité et leur robustesse. ",
  #         "Nous appliquons une transformation [aucune/log/Box–Cox/Yeo–Johnson] afin de [stabiliser la variance / améliorer la normalité], ",
  #         "tout en documentant la reconversion vers l’échelle d’origine. »")
  #     ),
  #     evals = P("Toutes les comparaisons de modèles doivent respecter le même horizon, le même protocole et les mêmes métriques. ",
  #               "En horizon multi-pas, il est utile de rapporter les scores séparément par pas de prévision."),
  #     pitfalls = P("La fuite temporelle (utiliser, même par inadvertance, des informations futures pour entraîner ou ajuster des hyper-paramètres) ",
  #                  "fausse gravement l’évaluation et doit être systématiquement évitée et expliquée.")
  #   )
  #   
  #   # ========== Page 2 — Étape 1 (données) ==========
  #   pages[[3]] <- make_step(
  #     step_titles[3],
  #     objectifs = P("Avant toute modélisation, la série doit être décrite avec précision : taille, période couverte, régularité de l’index temporel, ",
  #                   "nombre et mécanisme des valeurs manquantes, et statistiques descriptives globales et saisonnières. ",
  #                   "Cette étape vise la transparence et la reproductibilité."),
  #     defs = tagList(
  #       Concept("Régularité de l’index temporel et alignement des horodatages",
  #               P("Les modèles SARIMA supposent des pas de temps réguliers. Il faut donc vérifier qu’il n’existe ni doublons ni lacunes ",
  #                 "dans l’index, et que l’ordre temporel est strictement croissant. Pour des données horaires, les changements d’heure ",
  #                 "(DST) introduisent des heures manquantes ou dupliquées, qui doivent être traitées explicitement pour éviter des artefacts dans l’ACF.")
  #       ),
  #       Concept("Valeurs manquantes : MCAR, MAR, MNAR et conséquences pour l’imputation",
  #               P("Les manquants peuvent être complètement au hasard (MCAR), dépendre d’autres informations observées (MAR), ",
  #                 "ou dépendre de la valeur latente elle-même (MNAR). La crédibilité d’une imputation diminue à mesure que l’on s’éloigne de MCAR. ",
  #                 "Dans un cadre SARIMA, l’interpolation saisonnière ou les approches basées sur un modèle d’état (Kalman) sont souvent pertinentes, ",
  #                 "mais elles doivent être justifiées et documentées.")
  #       )
  #     ),
  #     actions = P("Quantifiez la taille (", C("n"), "), les dates de début et de fin, et la fréquence. ",
  #                 "Identifiez les manquants (nombre et pourcentage) et expliquez le choix de traitement retenu. ",
  #                 "Fournissez des statistiques de base et un résumé saisonnier (par exemple, moyennes mensuelles) pour ancrer la discussion."),
  #     apa = tags$details(
  #       tags$summary("Résultats (APA) — cliquer"),
  #       P("« La série comprend ", C("n"), "=[..] observations s’étendant de [..] à [..] à une fréquence [..]. ",
  #         "Les valeurs manquantes représentent [..]% (k=[..]) et ont été traitées par [méthode], choix motivé par [raison]. ",
  #         "Les statistiques descriptives indiquent une moyenne de [..] (écart-type [..]) et une médiane de [..], ",
  #         "avec des profils saisonniers qui suggèrent [caractéristiques]. »")
  #     ),
  #     evals = P("L’index temporel doit être strictement régulier avant tout calcul d’ACF/PACF. ",
  #               "Toute imputation doit être traçable et motivée, de façon à ce qu’un tiers puisse reproduire les résultats."),
  #     pitfalls = P("Ne jamais imputer « silencieusement ». Les conversions d’unités, changements de définition ou ruptures administratives ",
  #                  "doivent être repérés et décrits, car ils conditionnent la stationnarité.")
  #   )
  #   
  #   # ========== Page 3 — Étape 2 (EDA) ==========
  #   pages[[4]] <- make_step(
  #     step_titles[4],
  #     objectifs = P("L’exploration visuelle doit identifier la présence d’une tendance, d’une ou plusieurs saisonnalités, de ruptures structurelles et d’outliers, ",
  #                   "et proposer une hypothèse cohérente pour chacun de ces phénomènes. Cette lecture guide directement le choix des transformations et des différenciations."),
  #     defs = tagList(
  #       Concept("Tendance, saisonnalité, ruptures et outliers : distinguer le structurel de l’accidentel",
  #               P("La ", B("tendance"), " décrit l’évolution de long terme, qui peut être déterministe (une pente stable) ou stochastique (un random walk). ",
  #                 "La ", B("saisonnalité"), " correspond à des motifs récurrents de période ", C("s"), " (p. ex. 12 pour du mensuel). ",
  #                 "Une ", B("rupture structurelle"), " traduit un changement durable de niveau ou de variance (choc réglementaire, crise). ",
  #                 "Les ", B("outliers"), " peuvent être ponctuels (AO), diffuser au fil du temps (IO), décaler le niveau (LS) ou produire un changement transitoire (TC). ",
  #                 "Chaque cas appelle un traitement spécifique et une justification claire.")
  #       ),
  #       Concept("ACF/PACF et périodogramme : ce que ces outils montrent et ce qu’ils ne montrent pas",
  #               P("L’ACF mesure la corrélation entre la série et ses versions décalées; la PACF isole la contribution d’un lag donné ",
  #                 "après contrôle des lags plus courts. Des pics aux multiples de ", C("s"), " signalent souvent une saisonnalité. ",
  #                 "Le périodogramme met en évidence des fréquences dominantes. Ces outils sont des guides : ils n’imposent pas une structure unique et doivent être lus ",
  #                 "avec prudence, en tenant compte du bruit d’échantillonnage et des effets de bord.")
  #       )
  #     ),
  #     actions = P("Tracez la série dans le temps, un graphique saisonnier (par année) et des boxplots par saison pour mettre en évidence la forme saisonnière et les outliers. ",
  #                 "Complétez par l’ACF brute et un périodogramme pour repérer d’éventuelles fréquences dominantes. ",
  #                 "Dressez une liste des dates atypiques et indiquez pour chacune s’il s’agit d’un événement réel à conserver ou d’une erreur à corriger."),
  #     apa = tags$details(
  #       tags$summary("Résultats (APA) — cliquer"),
  #       P("« L’exploration visuelle met en évidence une tendance [..] et une saisonnalité de période s=[..] dont l’amplitude semble [stable/proportionnelle au niveau]. ",
  #         "La relation entre niveau et variance suggère [aucune transformation / une transformation log / Box–Cox]. ",
  #         "Des valeurs atypiques observées autour de [dates] ont été [conservées/traitées] en raison de [explication]. »")
  #     ),
  #     evals = P("Le choix d’une transformation doit s’appuyer sur des éléments visibles (par exemple, une variance qui croît avec le niveau). ",
  #               "Les outliers représentant des phénomènes réels récurrents ne doivent pas être supprimés, sous peine de fausser l’estimation de la saison."),
  #     pitfalls = P("Confondre tendance et saisonnalité mène souvent à des différenciations inutiles. ",
  #                  "Ignorer une rupture conduit le modèle à « moyenner » deux régimes incompatibles, au détriment des prévisions.")
  #   )
  #   
  #   # ========== Page 4 — Étape 3 (décomposition) ==========
  #   pages[[5]] <- make_step(
  #     step_titles[5],
  #     objectifs = P("La décomposition vise à séparer la série en tendance, saison et bruit de façon lisible, afin de décider si l’échelle additive suffit ",
  #                   "ou si une transformation (souvent log) est préférable. Elle ne remplace pas les tests de stationnarité."),
  #     defs = tagList(
  #       Concept("Additif vs multiplicatif : un diagnostic d’échelle",
  #               P("Lorsque l’amplitude saisonnière reste globalement constante quel que soit le niveau, un schéma additif est adapté. ",
  #                 "Si l’amplitude croît avec le niveau, une représentation multiplicative puis une transformation log permettent souvent de revenir à l’additif. ",
  #                 "Ce choix impacte la stabilité des résidus et la crédibilité des intervalles de prévision.")
  #       ),
  #       Concept("Décomposition STL : réglages et intérêt pédagogique",
  #               P("STL (Seasonal-Trend via LOESS) sépare la série en composantes flexible de saison et de tendance. ",
  #                 "Le paramètre ", C("s.window"), " contrôle la rigidité de la saison (", C("periodic"), " impose une saison constante; un entier autorise une lente évolution), ",
  #                 "tandis que ", C("t.window"), " règle la douceur de la tendance. Le mode ", C("robust=TRUE"), " limite l’influence des outliers. ",
  #                 "STL est particulièrement pédagogique car elle rend visibles des éléments que l’on invoque ensuite lors de la modélisation SARIMA.")
  #       )
  #     ),
  #     actions = P("Examinez la relation entre amplitude saisonnière et niveau pour choisir l’échelle appropriée (niveaux ou log). ",
  #                 "Réalisez une STL en expliquant les paramètres choisis et interprétez séparément la tendance, la saison et le résidu."),
  #     apa = tags$details(
  #       tags$summary("Méthodes (APA) — cliquer"),
  #       P("« L’amplitude saisonnière variant [peu/fortement] avec le niveau, nous retenons un schéma [additif/log-additif]. ",
  #         "Nous effectuons une décomposition STL [robuste / non robuste] dont les composantes confirment [points saillants], ",
  #         "ce qui motive les choix d’échelle et de différenciation pour le modèle SARIMA. »")
  #     ),
  #     evals = P("On s’assure que le résidu de la décomposition ne laisse pas apparaître de motifs persistants évidents. ",
  #               "Le choix d’échelle doit être cohérent avec l’EDA initiale."),
  #     pitfalls = P("La décomposition ne prouve pas la stationnarité. ",
  #                  "Si l’on modélise en log, il faut documenter la reconversion et le biais éventuel sur l’échelle d’origine.")
  #   )
  #   
  #   # ========== Page 5 — Étape 4 (stationnarité & tests) ==========
  #   pages[[6]] <- make_step(
  #     step_titles[6],
  #     objectifs = P("On cherche un couple de différenciations ", C("d, D"), " suffisant pour éliminer les racines unitaires non saisonnières et saisonnières, ",
  #                   "sans aller jusqu’à sur-différencier la série. Cette décision s’appuie sur une triangulation entre tests formels (ADF, PP, KPSS) ",
  #                   "et diagnostics graphiques (ACF/PACF, évolution des écarts)."),
  #     defs = tagList(
  #       Concept("Stationnarité faible : ce que l’on exige réellement d’un SARIMA",
  #               P("La stationnarité faible impose une moyenne et une variance constantes au cours du temps, ",
  #                 "et des autocovariances qui dépendent du seul décalage. Elle est suffisante pour les méthodes linéaires usuelles. ",
  #                 "Une série non stationnaire peut résulter d’une racine unitaire (random walk), d’une saisonnalité stochastique, ou d’une variance changeante. ",
  #                 "Différencier vise à retrouver cette stationnarité faible sur laquelle les composantes AR et MA sont estimées.")
  #       ),
  #       Concept("Sur-différenciation : symptômes et conséquences",
  #               P("Différencier au-delà du nécessaire introduit des artefacts : une autocorrélation fortement négative au premier retard, ",
  #                 "une variance gonflée et des prévisions qui deviennent erratiques. Pédagogiquement, il faut montrer qu’une bonne ACF après différenciation ",
  #                 "se caractérise par une décroissance raisonnable sans motif oscillatoire artificiel.")
  #       )
  #     ),
  #     actions = P("Appliquez les tests ADF/PP/KPSS sur la série brute, puis après une différence ordinaire et/ou saisonnière lorsque cela s’impose. ",
  #                 "Arrêtez-vous dès qu’un niveau raisonnable de stationnarité est atteint, en vous appuyant simultanément sur les p-values, les graphes et l’ACF."),
  #     apa = tags$details(
  #       tags$summary("Méthodes (APA) — cliquer"),
  #       P("« La stationnarité a été évaluée à l’aide des tests ADF, PP et KPSS qui posent des hypothèses nulles complémentaires. ",
  #         "Les tests ont été conduits sur la série originale puis après différenciations ordinaires et saisonnières. ",
  #         "En agrégeant les indices (tests et diagnostics visuels), nous avons retenu d = [..] et D = [..] (s = [..]) ",
  #         "afin d’obtenir une série approximativement stationnaire tout en évitant la sur-différenciation. »")
  #     ),
  #     evals = P("On privilégie une lecture conjointe des tests : ADF/PP qui rejettent la racine unitaire et KPSS qui ne rejette pas la stationnarité ",
  #               "fournissent une preuve convergente. En cas de conflit, on documente précisément l’arbitrage."),
  #     pitfalls = P("Choisir ", C("d, D"), " par habitude sans vérifier les graphes et l’ACF conduit souvent à des modèles inutiles ou instables."),
  #     extras = tagList(
  #       TestCard("tc_adf", "ADF — Augmented Dickey–Fuller",
  #                def = "Le test ADF examine si la série possède une racine unitaire, ce qui la rendrait non stationnaire, tout en tenant compte de l’autocorrélation résiduelle par l’ajout de lags de la différence.",
  #                why = "Il permet de décider si une différenciation ordinaire (d) est nécessaire avant d’estimer des composantes AR et MA, de manière à éviter de modéliser une tendance stochastique.",
  #                H0  = "La série contient une racine unitaire (elle n’est pas stationnaire).",
  #                Ha  = "La série est stationnaire (autour d’un niveau constant ou d’une tendance déterministe, selon la spécification).",
  #                stat= tagList(
  #                  P("On estime une régression en différences dont la forme dépend de la présence d’une constante et d’une tendance déterministe :"),
  #                  UL(
  #                    tags$li(C("Δy_t = α + γ y_{t-1} + Σ_{i=1}^k ψ_i Δy_{t-i} + u_t"), " (avec constante)"),
  #                    tags$li(C("Δy_t = α + β t + γ y_{t-1} + Σ_{i=1}^k ψ_i Δy_{t-i} + u_t"), " (avec constante et tendance)")
  #                  ),
  #                  P("La statistique de test est la statistique t associée à ", C("γ"), ". Les valeurs critiques ne suivent pas la loi t habituelle et ",
  #                    "doivent être lues dans des tables spécifiques. Le nombre de lags ", C("k"), " sert à absorber l’autocorrélation; il peut être choisi via AIC/BIC.")
  #                ),
  #                decision = P("Si la p-value est inférieure au seuil (par exemple 5 %), on rejette l’hypothèse de racine unitaire et l’on conclut à la stationnarité (au sens ADF). ",
  #                             "Si elle est plus grande, on ne rejette pas H0 et une différenciation ordinaire est probablement nécessaire."),
  #                concl = P("« ADF (spécification [constante / constante+tendance]) : τ = [..], p = [..]. ",
  #                          "Nous [rejetons/ne rejetons pas] H0, ce qui indique que la série est [stationnaire / non stationnaire] avant différenciation. »"),
  #                notes = UL(
  #                  tags$li("Le choix d’inclure une tendance déterministe doit être guidé par l’EDA; un mauvais choix réduit la puissance du test."),
  #                  tags$li("En petit échantillon, les conclusions doivent être triangulées avec l’ACF et les graphes.")
  #                )
  #       ),
  #       TestCard("tc_pp", "PP — Phillips–Perron",
  #                def = "Le test PP vise le même objectif que l’ADF (déceler une racine unitaire) mais corrige l’autocorrélation et l’hétéroscédasticité d’une manière non paramétrique via des estimateurs de variance longue.",
  #                why = "Il offre une robustesse supplémentaire lorsque la structure d’autocorrélation des erreurs est complexe ou mal spécifiée dans l’ADF.",
  #                H0  = "La série présente une racine unitaire (non stationnaire).",
  #                Ha  = "La série est stationnaire.",
  #                stat= P("La forme de régression est similaire à la version Dickey–Fuller simple, mais la variance de l’estimateur est corrigée à l’aide d’un estimateur de type Newey–West. ",
  #                        "Le choix de la bande passante influence la p-value et doit être documenté."),
  #                decision = P("Une p-value petite conduit à rejeter H0 et à conclure à la stationnarité; une p-value élevée invite à conserver l’hypothèse de racine unitaire et à différencier."),
  #                concl = P("« PP : τ = [..], p = [..]. Nous [rejetons/ne rejetons pas] H0; la conclusion est [cohérente / non cohérente] avec ADF et sera interprétée conjointement. »"),
  #                notes = UL(
  #                  tags$li("Comparer PP et ADF : une convergence des deux renforce la conclusion."),
  #                  tags$li("Toujours indiquer les paramètres de lissage utilisés pour la variance longue.")
  #                )
  #       ),
  #       TestCard("tc_kpss", "KPSS — Kwiatkowski–Phillips–Schmidt–Shin",
  #                def = "Le test KPSS inverse la perspective en posant la stationnarité comme hypothèse nulle, et en détectant une tendance stochastique si cette hypothèse est rejetée.",
  #                why = "L’interprétation conjointe ADF/PP (H0 = racine unitaire) et KPSS (H0 = stationnarité) fournit une vision équilibrée et évite de fonder la décision sur une seule p-value.",
  #                H0  = "La série est stationnaire (au niveau ou autour d’une tendance déterministe, selon la version).",
  #                Ha  = "La série n’est pas stationnaire (présence d’une racine unitaire).",
  #                stat= P("Le test repose sur la somme cumulée des résidus d’une régression (niveau ou tendance) et sur une estimation de variance à long terme. ",
  #                        "Les valeurs critiques dépendent du noyau et de la bande passante employés."),
  #                decision = P("Si la p-value est petite, on rejette la stationnarité et l’on considère qu’une différenciation (ordinaire et/ou saisonnière) est nécessaire. ",
  #                             "Si elle est grande, la stationnarité est compatible avec les données au sens du test."),
  #                concl = P("« KPSS (niveau/tendance) : stat = [..], p = [..]. Nous [rejetons/ne rejetons pas] H0; ",
  #                          "nous concluons que la série est [non stationnaire / compatible stationnarité], ce qui guide le choix de ", C("d, D"), ". »"),
  #                notes = UL(
  #                  tags$li("Spécifier clairement version « niveau » ou « tendance »."),
  #                  tags$li("En présence de longue mémoire, KPSS peut rejeter souvent : trianguler avec l’ACF et l’EDA.")
  #                )
  #       ),
  #       TestCard("tc_hegy", "HEGY — Racines unitaires saisonnières (avancé)",
  #                def = "HEGY décompose les composantes saisonnières afin de tester séparément l’existence de racines unitaires aux fréquences saisonnières caractéristiques (par ex. ±1 et complexes pour s = 4 ou 12).",
  #                why = tagList("Il est utile lorsque la non-stationnarité provient d’une saisonnalité stochastique plutôt que d’une simple tendance, ce qui motive une différenciation saisonnière ", C("(D=1)"), "."),
  #                H0  = "La série possède au moins une racine unitaire à une ou plusieurs fréquences saisonnières testées.",
  #                Ha  = "Aucune racine unitaire n’est présente aux fréquences considérées.",
  #                stat= P("Le test s’appuie sur des régressions auxiliaires spécifiques et des statistiques t/F adaptées à chaque fréquence. Les implémentations varient selon les logiciels."),
  #                decision = P("Le rejet de H0 à une fréquence donnée signifie qu’il n’existe pas de racine unitaire à cette fréquence; l’absence de rejet suggère d’employer une différence saisonnière."),
  #                concl = P("« HEGY : fréquences [..] → [rejet/non-rejet]. Nous en déduisons que ", C("D"), " = [..] est [nécessaire/inutile]. »"),
  #                notes = UL(tags$li("Particulièrement pertinent pour s = 4 ou 12."), tags$li("Toujours combiner avec l’EDA et l’ACF."))
  #       ),
  #       TestCard("tc_za", "Zivot–Andrews — racine unitaire avec rupture (avancé)",
  #                def = "Le test autorise une rupture endogène (date inconnue) dans le niveau et/ou la tendance lors de l’évaluation d’une racine unitaire, évitant de confondre rupture et non-stationnarité.",
  #                why = "En présence d’une rupture marquée, les tests sans rupture peuvent conclure à tort à une racine unitaire; ZA aide à démêler ces situations.",
  #                H0  = "La série possède une racine unitaire (aucune stationnarité autour d’un niveau ou d’une tendance), même en autorisant une rupture.",
  #                Ha  = "La série est stationnaire autour d’un niveau ou d’une tendance, avec une date de rupture unique.",
  #                stat= P("On cherche la date de rupture qui rend la statistique de racine unitaire la plus extrême; la statistique suit des distributions non standard avec tables. "),
  #                decision = P("Une p-value faible conduit à rejeter H0 et à conclure à la stationnarité avec rupture; on documente alors la date estimée et on envisage des variables d’intervention."),
  #                concl = P("« Zivot–Andrews : τ = [..], p = [..], rupture estimée en [..]. Nous [rejetons/ne rejetons pas] H0; choix de ", C("d, D"), " et éventuels régresseurs d’intervention ajustés. »"),
  #                notes = UL(tags$li("Le test ne gère qu’une rupture unique; pour des régimes multiples, d’autres cadres sont requis."))
  #       )
  #     )
  #   )
  #   
  #   # ========== Page 6 — Étape 5 (Auto-ARIMA) ==========
  #   pages[[7]] <- make_step(
  #     step_titles[7],
  #     objectifs = P("Auto-ARIMA fournit un point de départ compétitif en explorant des ordres candidats et en sélectionnant selon un critère d’information. ",
  #                   "Cette baseline doit ensuite être validée par des diagnostics et éventuellement simplifiée si une spécification plus parcimonieuse ",
  #                   "offre une performance prédictive équivalente."),
  #     defs = tagList(
  #       Concept("Ce que fait réellement l’algorithme Auto-ARIMA",
  #               P("L’algorithme teste un ensemble de combinaisons ", C("(p,q,P,Q)"), " sous contraintes, souvent en fixant préalablement ", C("d, D"),
  #                 " ou en s’aidant d’heuristiques (ndiffs/nsdiffs). La sélection se fait par minimisation d’un critère (souvent AICc). ",
  #                 "Deux stratégies existent : une recherche stepwise, rapide mais susceptible de rater un optimum global, et une recherche plus exhaustive, plus coûteuse mais plus fiable. ",
  #                 "Dans un enseignement, il est instructif de montrer que la baseline auto-sélectionnée n’est pas un « oracle » et doit passer au crible des diagnostics.")
  #       )
  #     ),
  #     actions = P("Fixez ou vérifiez ", C("d, D"), " à partir de l’étape précédente. Définissez des bornes raisonnables pour ", C("p, q, P, Q"), " et estimez la baseline. ",
  #                 "Conservez la spécification et ses diagnostics en référence, puis comparez-la à des modèles manuels plus simples."),
  #     apa = tags$details(
  #       tags$summary("Méthodes (APA) — cliquer"),
  #       P("« Une procédure Auto-ARIMA a exploré des ordres candidats sous contraintes et a sélectionné une baseline par minimisation de l’AICc. ",
  #         "Ce modèle de référence a été conservé pour comparaison, puis confronté à des variantes plus parcimonieuses à l’aide de diagnostics résiduels et d’évaluations hors échantillon. »")
  #     ),
  #     evals = P("On rapporte AICc/BIC, le test de Ljung–Box, les métriques de prévision et le nombre total de paramètres. ",
  #               "À performance équivalente, on retient le modèle le plus simple."),
  #     pitfalls = P("Un AICc très favorable avec des résidus autocorrélés n’est pas acceptable. Les ordres très élevés compliquent l’interprétation et fragilisent la stabilité.")
  #   )
  #   
  #   # ========== Page 7 — Étape 6 (SARIMA manuel) ==========
  #   pages[[8]] <- make_step(
  #     step_titles[8],
  #     objectifs = P("Construire un petit ensemble de modèles candidats fondés sur une lecture raisonnée des ACF/PACF après différenciations retenues, ",
  #                   "tester la présence de termes saisonniers et vérifier la stabilité/inversibilité des solutions."),
  #     defs = tagList(
  #       Concept("Lire ACF et PACF sans sur-interpréter",
  #               P("Une coupure franche de l’ACF autour du retard ", C("q"), " évoque un MA(", C("q"), "), tandis qu’une coupure de la PACF autour de ", C("p"),
  #                 " évoque un AR(", C("p"), "). Des pics aux multiples de ", C("s"), " dans l’ACF suggèrent des composantes saisonnières de type SMA, ",
  #                 "et des pics correspondants dans la PACF des composantes SAR. Il faut néanmoins garder à l’esprit que ces heuristiques ne sont pas des preuves : ",
  #                 "les spécifications finales doivent être validées par diagnostics et par performance prédictive.")
  #       )
  #     ),
  #     actions = P("Proposez entre trois et huit candidats parcimonieux, en justifiant chaque terme par un motif identifié dans l’ACF/PACF. ",
  #                 "Ajustez et comparez les modèles selon AICc/BIC, examinez la significativité des coefficients, testez l’absence d’autocorrélation résiduelle et ",
  #                 "vérifiez que les racines des polynômes AR et MA se situent hors du cercle unité."),
  #     apa = tags$details(
  #       tags$summary("Méthodes (APA) — cliquer"),
  #       P("« Nous avons dérivé un petit ensemble de candidats à partir des schémas ACF/PACF de la série stationnarisée. ",
  #         "Pour chaque modèle, nous avons vérifié la stabilité/inversibilité, comparé AICc/BIC et inspecté les diagnostics résiduels, ",
  #         "en privilégiant une représentation parcimonieuse offrant des performances comparables à la baseline. »")
  #     ),
  #     evals = P("Les candidats retenus doivent présenter des résidus proches du bruit blanc et des paramètres stables. ",
  #               "Les critères d’information servent à départager des spécifications proches, mais ne supplantent pas les diagnostics."),
  #     pitfalls = P("Tester un trop grand nombre de modèles et retenir rétrospectivement le meilleur AICc relève du data-snooping et doit être évité. ",
  #                  "À l’inverse, sur-interpréter un motif ACF/PACF isolé conduit souvent à ajouter des termes superflus.")
  #   )
  #   
  #   # ========== Page 8 — Étape 7 (diagnostics & comparaison) ==========
  #   pages[[9]] <- make_step(
  #     step_titles[9],
  #     objectifs = P("Confirmer que la structure temporelle a été correctement capturée (résidus ≈ bruit blanc), ",
  #                   "et établir, par une évaluation hors échantillon, que le modèle apporte un gain réel sur des benchmarks simples."),
  #     defs = tagList(
  #       Concept("Ce que l’on attend des résidus et pourquoi cela conditionne la crédibilité des prévisions",
  #               P("Des résidus sans autocorrélation signifient que le modèle a absorbé la dépendance explorable; ",
  #                 "à l’inverse, des corrélations résiduelles indiquent que des régularités subsistent et que les intervalles de prévision sont souvent trop optimistes. ",
  #                 "La normalité est surtout utile pour l’interprétation d’intervalles paramétriques; elle n’est pas indispensable pour des prévisions ponctuelles.")
  #       )
  #     ),
  #     actions = P("Inspectez l’ACF/PACF des résidus et appliquez le test de Ljung–Box pour une plage de retards adaptée à la fréquence (par exemple des multiples de ", C("s"), "). ",
  #                 "Évaluez la précision sur une fenêtre future ou en rolling-origin; comparez systématiquement aux benchmarks Naïf/Drift/SNAIVE. ",
  #                 "Si nécessaire, comparez deux modèles au moyen du test de Diebold–Mariano."),
  #     apa = tags$details(
  #       tags$summary("Résultats (APA) — cliquer"),
  #       P("« Les résidus ne présentent pas d’autocorrélations significatives (Ljung–Box p = [..]), ce qui indique que la structure temporelle a été correctement capturée. ",
  #         "Sur la fenêtre d’évaluation, le modèle atteint MAE = [..] et RMSE = [..], surpassant le benchmark [..]. ",
  #         "Nous considérons donc cette spécification comme adéquate pour la prévision à l’horizon ", C("h"), ". »")
  #     ),
  #     evals = P("Un modèle acceptable combine des diagnostics résiduels satisfaisants et une amélioration claire sur les benchmarks. ",
  #               "Les comparaisons doivent toujours se faire au même horizon et sur le même segment temporel."),
  #     pitfalls = P("Valider un modèle sur la seule base d’un bon AIC, ou en mêlant des horizons/protocoles différents, fausse l’interprétation des résultats."),
  #     extras = tagList(
  #       TestCard("tc_lb", "Ljung–Box — autocorrélation résiduelle globale",
  #                def = "Le test de Ljung–Box vérifie de manière globale si un ensemble d’autocorrélations résiduelles, jusqu’à un retard L, peut être considéré comme nul.",
  #                why = "Il synthétise l’information de l’ACF des résidus et détecte une structure persistante que l’œil pourrait sous-estimer, validant ainsi l’adéquation du modèle.",
  #                H0  = "Il n’existe pas d’autocorrélation résiduelle significative jusqu’au lag L.",
  #                Ha  = "Au moins une autocorrélation résiduelle jusqu’au lag L est non nulle.",
  #                stat= P(C("Q^* = n(n+2) \\sum_{k=1}^{L} \\hat{ρ}_k^2/(n-k)"), " qui suit approximativement une loi ", C("χ²"), " sous H0, ",
  #                        "avec des degrés de liberté ajustés pour le nombre de paramètres ARMA estimés."),
  #                decision = P("Une p-value inférieure au seuil conduit à rejeter H0, signifiant que le modèle laisse une dépendance résiduelle exploitable et doit être révisé. ",
  #                             "Une p-value élevée indique des résidus compatibles avec un bruit blanc."),
  #                concl = P("« Ljung–Box (L = [..]) : Q* = [..], p = [..]. Nous [rejetons/ne rejetons pas] H0; les résidus sont [structurels / compatibles bruit blanc]. »"),
  #                notes = UL(
  #                  tags$li("Choisir L en cohérence avec la fréquence (ex. 24 pour de l’horaire, 12 ou 24 pour du mensuel avec saison)."),
  #                  tags$li("Éviter de choisir L ex-post en regardant les données, pour ne pas biaiser le test.")
  #                )
  #       ),
  #       TestCard("tc_jb", "Jarque–Bera — normalité des résidus",
  #                def = "Le test évalue si la skewness et la kurtosis des résidus sont compatibles avec celles d’une distribution normale.",
  #                why = "La normalité n’est pas indispensable pour des points de prévision, mais elle favorise des intervalles paramétriques mieux calibrés et une lecture probabiliste cohérente.",
  #                H0  = "Les résidus suivent une distribution normale.",
  #                Ha  = "La distribution des résidus s’écarte de la normale (asymétrie et/ou kurtosis anormales).",
  #                stat= P(C("JB = n[(S^2/6) + ((K-3)^2/24)]"), " qui suit asymptotiquement une loi ", C("χ²_2"), " sous H0."),
  #                decision = P("Une p-value faible suggère une non-normalité; on discute alors l’impact sur l’interprétation des intervalles. ",
  #                             "Une p-value élevée indique une normalité compatible."),
  #                concl = P("« Jarque–Bera : JB = [..], p = [..]. Nous [rejetons/ne rejetons pas] H0; la normalité des résidus est [incompatible/compatible] avec l’hypothèse. »"),
  #                notes = UL(tags$li("La présence d’outliers ou d’hétéroscédasticité peut faire rejeter H0 sans compromettre la validité des points de prévision."))
  #       ),
  #       TestCard("tc_arch", "Engle ARCH LM — variance conditionnelle",
  #                def = "Le test d’Engle détecte la présence d’hétéroscédasticité conditionnelle de type ARCH en examinant la dépendance des carrés des résidus.",
  #                why = "Une variance conditionnelle non modélisée peut rendre les intervalles de prévision trop optimistes; il est utile de la détecter pour ajuster les incertitudes.",
  #                H0  = "Absence d’effet ARCH jusqu’au lag q.",
  #                Ha  = "Présence d’un effet ARCH jusqu’au lag q.",
  #                stat= P("On ré-estime une régression de ", C("e_t^2"), " sur ", C("const + e_{t-1}^2 + ... + e_{t-q}^2"), " et l’on calcule une statistique LM qui suit une loi ", C("χ²_q"), " sous H0."),
  #                decision = P("Une p-value faible conduit à rejeter H0 et signale une variance conditionnelle; on adaptera les IC ou envisagera des modèles de variance."),
  #                concl = P("« ARCH-LM(q = [..]) : LM = [..], p = [..]. Nous [rejetons/ne rejetons pas] H0; cela implique [présence/absence] d’hétéroscédasticité conditionnelle. »"),
  #                notes = UL(tags$li("Le choix de q peut être guidé par l’ACF des résidus au carré."))
  #       ),
  #       TestCard("tc_dm", "Diebold–Mariano — comparer deux modèles de prévision",
  #                def = "Le test DM compare l’exactitude prédictive de deux modèles en examinant si l’espérance de la différence de pertes est nulle.",
  #                why = "Il permet d’établir si une amélioration de métrique est statistiquement significative et donc peu susceptible d’être due au hasard.",
  #                H0  = "Les deux modèles ont la même perte moyenne (aucun avantage).",
  #                Ha  = "Les pertes moyennes diffèrent (avantage significatif d’un modèle).",
  #                stat= P("La statistique repose sur la moyenne des différences de pertes (par exemple absolue ou quadratique) et une estimation robuste (HAC) de son écart-type; ",
  #                        "elle est approximativement normale sous H0."),
  #                decision = P("Une p-value faible rejette H0 et atteste un avantage; une p-value élevée suggère qu’aucune différence significative n’est observée."),
  #                concl = P("« Diebold–Mariano (perte = [MAE/RMSE]) : DM = [..], p = [..] → [avantage du modèle A/B / pas de différence significative]. »"),
  #                notes = UL(
  #                  tags$li("Utiliser le même horizon et les mêmes segments temporels pour les deux modèles."),
  #                  tags$li("Préciser si le test est unilatéral (amélioration attendue dans un sens) ou bilatéral.")
  #                )
  #       )
  #     )
  #   )
  #   
  #   # ========== Page 9 — Étape 8 (rédaction) ==========
  #   pages[[10]] <- make_step(
  #     step_titles[10],
  #     objectifs = P("Le rapport doit présenter un fil clair reliant les choix méthodologiques aux preuves empiriques, ",
  #                   "documenter la reproductibilité (versions de packages, seeds) et fournir des figures et tableaux qui rendent l’argumentation autonome."),
  #     defs = tagList(
  #       Concept("Reconversion après modélisation en log : corriger le biais de Jensen",
  #               P("Lorsque l’on modélise ", C("log(y)"), ", la reconversion naïve par exponentielle tend à sous-estimer l’espérance sur l’échelle d’origine. ",
  #                 "Sous une hypothèse d’erreurs approximativement normales, on peut corriger par ", C("exp(\\hat{y}) × exp(\\hat{\\sigma}^2/2)"), ". ",
  #                 "Cette correction doit être expliquée et, si elle est utilisée, explicitement mentionnée.")
  #       ),
  #       Concept("Couverture des intervalles de prévision",
  #               P("Indiquez le niveau de couverture (80 %, 95 %) et la méthode (analytique, bootstrap). Expliquez que l’objectif est une bonne calibration ",
  #                 "(la proportion de réalisations qui tombe dans l’intervalle doit correspondre au niveau annoncé) en plus d’une largeur raisonnable.")
  #       )
  #     ),
  #     actions = P("Rassemblez l’intégralité du pipeline dans un script ou notebook reproductible. ",
  #                 "Incluez des figures lisibles (série, décomposition, ACF/PACF, diagnostics résiduels, prévisions et intervalles) ",
  #                 "et un tableau comparatif des modèles qui aligne critères d’information, diagnostics et mesures de précision."),
  #     apa = tags$details(
  #       tags$summary("Phrase finale (APA) — cliquer"),
  #       P("« Le modèle retenu est ", C("SARIMA((p,d,q)(P,D,Q)_s)"), ", dont les résidus sont compatibles avec un bruit blanc selon les diagnostics de corrélation. ",
  #         "À l’horizon ", C("h"), ", il améliore le benchmark [..] d’après [MAE/RMSE/MASE]. ",
  #         "Les choix d’échelle, de différenciation et d’ordres ont été motivés par l’EDA, des tests formels et des comparaisons hors échantillon. »")
  #     ),
  #     evals = P("Le rapport est jugé satisfaisant s’il permet à un lecteur externe de reproduire les résultats et de comprendre logiquement chaque décision."),
  #     pitfalls = P("Un texte dense sans figures ne convainc pas en séries temporelles : les graphiques sont des résultats à part entière.")
  #   )
  #   
  #   # ========== Page 10 — Annexes ==========
  #   pages[[11]] <- make_step(
  #     step_titles[11],
  #     objectifs = P("Fournir un mémo des formules et des règles rapides d’interprétation, et signaler des pistes d’approfondissement."),
  #     defs = tagList(
  #       Concept("Formules essentielles à connaître",
  #               P("Les critères d’information se notent ", C("AIC = -2 \\log L + 2k"), ", ", C("AICc = AIC + 2k(k+1)/(n-k-1)"),
  #                 " et ", C("BIC = -2 \\log L + k \\log n"), ". Le test de Ljung–Box utilise ", C("Q^* = n(n+2) Σ_{k=1}^L \\hat{ρ}_k^2/(n-k)"),
  #                 " et la métrique MASE s’écrit ", C("mean(|e_t|)/mean(|y_t - y_{t-s}|)"), ".")
  #       ),
  #       Concept("Benchmarks et extensions possibles",
  #               P("Les benchmarks Naïf, Drift et SNAIVE fournissent des repères essentiels. ",
  #                 "Au-delà du cadre SARIMA, on peut envisager des régressions dynamiques (SARIMAX), des variables d’intervention pour traiter les ruptures, ",
  #                 "ou des modèles à multiples saisonnalités (TBATS/ETS-MS) lorsque la fréquence l’exige.")
  #       )
  #     ),
  #     actions = P("Rappeler les règles rapides : ADF/PP qui rejettent la racine unitaire tandis que KPSS ne rejette pas la stationnarité suggèrent une stationnarité plausible; ",
  #                 "à l’inverse, si ADF/PP ne rejettent pas et que KPSS rejette, une différenciation est requise."),
  #     apa = tags$details(
  #       tags$summary("Template (tests → choix d, D) — cliquer"),
  #       P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. Étant donné que [ADF/PP rejettent | ne rejettent pas] la racine unitaire ",
  #         "et que [KPSS rejette | ne rejette pas] la stationnarité, nous concluons que la série est [stationnaire | non stationnaire] au sens des diagnostics combinés. ",
  #         "Nous retenons par conséquent d = [..] et D = [..] (s = [..]) avant l’estimation du SARIMA. »")
  #     ),
  #     evals = P("Le mémo doit accélérer la révision mais ne remplace pas l’argumentation détaillée présentée aux étapes précédentes."),
  #     pitfalls = P("Ne pas laisser croire qu’un seul test « décide » : les conclusions sont toujours triangulées.")
  #   )
  #   
  #   # --- Output ---
  #   tagList(
  #     css,
  #     tags$div(id="road_container",
  #              tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/", .road_max, " — ", step_titles[cur + 1L])),
  #              progress_ui,
  #              pages[[cur + 1L]]
  #     )
  #   )
  # })
  
  
  
  
  
  # ===========================================================================
  # ===========================================================================
  # ===========================================================================
  
  
  
  
  
  
  # # --- Roadmap: dynamic prev/next based on number of steps ---
  # step_titles <- c(
  #   "Aperçu & notations (glossaire + lecture du modèle)",
  #   "Étape 0 — Définir le problème de modélisation",
  #   "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
  #   "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
  #   "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
  #   "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
  #   "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
  #   "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
  #   "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
  #   "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
  #   "Annexes — Formules, checklists, templates, interprétations rapides"
  # )
  # .road_max <- length(step_titles) - 1L
  # 
  # observeEvent(input$road_prev, {
  #   cur <- as.integer(if (is.null(input$roadmap_step)) 0L else input$roadmap_step)
  #   updateSliderInput(session, "roadmap_step", value = max(0L, cur - 1L))
  # }, ignoreInit = TRUE)
  # 
  # observeEvent(input$road_next, {
  #   cur <- as.integer(if (is.null(input$roadmap_step)) 0L else input$roadmap_step)
  #   updateSliderInput(session, "roadmap_step", value = min(.road_max, cur + 1L))
  # }, ignoreInit = TRUE)
  # 
  # # --- Roadmap UI (controls) ----------------------------------------------------
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:700;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     .road-scroll {max-height:62vh; overflow-y:auto; padding-right:10px;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #     .road-toolbar {display:flex; gap:8px; flex-wrap:wrap; align-items:center;}
  #     .apa-box {background:#fbfbfb;border:1px dashed #ddd;border-radius:8px;padding:8px; position:relative;}
  #     .apa-copy {position:absolute; top:6px; right:6px;}
  #   ")),
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique v2)"),
  #     tags$p(class="road-sub",
  #            "Navigation ←/→ (clavier). Utilisez le curseur pour passer d’une étape à l’autre. ",
  #            "Chaque carte : Objectifs → Définitions → Actions → APA → Évaluation → Pièges."
  #     ),
  # 
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput("roadmap_step", label = NULL,
  #                   min = 0, max = .road_max, value = 0, step = 1, width = "520px"),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : repliez les blocs pour éviter la scroll.")
  #     ),
  # 
  #     tags$div(class="road-toolbar",
  #              actionButton("road_expand", "Tout déplier"),
  #              actionButton("road_collapse", "Tout replier"),
  #              textInput("road_find", NULL, placeholder = "Rechercher (page courante)…", width = "260px")
  #     ),
  # 
  #     # Keyboard + expand/collapse + search (vanilla JS)
  #     tags$script(HTML("
  #     document.addEventListener('keydown', function(e){
  #       if(e.key==='ArrowLeft'){Shiny.setInputValue('road_prev', Math.random());}
  #       if(e.key==='ArrowRight'){Shiny.setInputValue('road_next', Math.random());}
  #     });
  #     Shiny.addCustomMessageHandler('road_toggle_details', function(open){
  #       document.querySelectorAll('#road_container details').forEach(d => d.open = open);
  #     });
  #     Shiny.addCustomMessageHandler('road_find', function(q){
  #       const root = document.getElementById('road_container');
  #       if(!root) return;
  #       root.querySelectorAll('mark.road-hit').forEach(m=>{ const t=document.createTextNode(m.textContent); m.replaceWith(t); });
  #       if(!q){ return; }
  #       const rx = new RegExp(q.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&'), 'gi');
  #       root.querySelectorAll('.road-scroll').forEach(box=>{
  #         box.childNodes.forEach(function walk(n){
  #           if(n.nodeType===3){ // text
  #             const frag = document.createDocumentFragment();
  #             let m, s = n.nodeValue, lastIdx = 0;
  #             while((m = rx.exec(s))!==null){
  #               frag.appendChild(document.createTextNode(s.slice(lastIdx, m.index)));
  #               const mk = document.createElement('mark'); mk.className='road-hit'; mk.textContent=m[0];
  #               frag.appendChild(mk); lastIdx = m.index + m[0].length;
  #             }
  #             if(lastIdx){ frag.appendChild(document.createTextNode(s.slice(lastIdx))); n.replaceWith(frag); }
  #           }else if(n.nodeType===1){ walk(n.firstChild); for(let c=n.firstChild; c; c=c.nextSibling) walk(c); }
  #         });
  #       });
  #     });
  #     function copyAPA(id){
  #       const el = document.getElementById(id);
  #       if(!el) return;
  #       const txt = el.innerText || el.textContent;
  #       navigator.clipboard.writeText(txt);
  #     }
  #   ")),
  # 
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  # 
  # observeEvent(input$road_expand, {
  #   session$sendCustomMessage("road_toggle_details", TRUE)
  # })
  # observeEvent(input$road_collapse, {
  #   session$sendCustomMessage("road_toggle_details", FALSE)
  # })
  # observeEvent(input$road_find, {
  #   session$sendCustomMessage("road_find", input$road_find %||% "")
  # })
  # 
  # # --- Roadmap UI (content) -----------------------------------------------------
  # `%||%` <- function(a,b) if (is.null(a) || length(a)==0) b else a
  # 
  # output$roadmap_step_content <- renderUI({
  # 
  #   # ===== Helpers (DRY) =====
  #   D  <- function(title, ...) tags$details(tags$summary(title), tags$div(class="road-scroll", ...))
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   P  <- function(...) tags$p(...)
  #   B  <- function(...) tags$b(...)
  #   C  <- function(...) tags$code(...)
  #   H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
  # 
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  # 
  #   copyAPA <- function(id, ...) {
  #     # Wraps APA paragraphs and adds a copy button
  #     tags$div(class="apa-box",
  #              tags$button(class="btn btn-xs btn-default apa-copy", onclick = sprintf("copyAPA('%s')", id), "Copier"),
  #              tags$div(id = id, ...)
  #     )
  #   }
  # 
  #   make_step <- function(title, objectifs, defs, actions, apa, evals, pitfalls, extras = NULL) {
  #     tags$div(
  #       class = "road-card",
  #       tags$h4(title),
  #       D("Objectifs (ce qui doit être démontré)", objectifs),
  #       D("Définitions clés", defs),
  #       D("Actions (procédure pas à pas)", actions),
  #       D("Texte APA prêt à coller", apa),
  #       D("Évaluation & critères de validation", evals),
  #       D("Pièges & comment les éviter", pitfalls),
  #       if (!is.null(extras)) D("Annexes & notes", extras)
  #     )
  #   }
  # 
  #   css <- tags$style(HTML("
  #   .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #   details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #   details > summary {cursor:pointer;font-weight:700;}
  #   .road-scroll {max-height:62vh; overflow-y:auto; padding-right:10px;}
  #   .progress {height:10px; margin:10px 0 0 0;}
  # "))
  # 
  #   cur <- as.integer(input$roadmap_step %||% 0L)
  #   cur <- max(0L, min(.road_max, cur))
  #   pct <- round(100 * cur / .road_max)
  # 
  #   progress_ui <- tags$div(
  #     class="progress",
  #     tags$div(
  #       class="progress-bar",
  #       role="progressbar",
  #       `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #       style = paste0("width:", pct, "%;")
  #     )
  #   )
  # 
  #   # ===== Pages (compact but richer) =====
  #   pages <- list()
  # 
  #   # 0) Aperçu & notations
  #   pages[[1]] <- make_step(
  #     step_titles[1],
  #     objectifs = UL(
  #       tags$li("Comprendre la forme SARIMA et l’objectif prédictif (pas seulement AIC)."),
  #       tags$li("Savoir lire ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"), " et ce que chaque bloc apporte."),
  #       tags$li("Citer des critères de qualité : résidus ~ bruit blanc, performance out-of-sample, parcimonie.")
  #     ),
  #     defs = UL(
  #       tags$li(B("Série temporelle"), " ", C("y_t"), "; fréquence/période saisonnière ", C("s"), "."),
  #       tags$li(B("Backshift"), " ", C("B y_t = y_{t-1}"), "; différenciations ", C("∇=(1-B)"), ", ", C("∇_s=(1-B^s)"), "."),
  #       tags$li(B("Polynômes AR/MA"), " : ",
  #               C("φ(B)=1-φ_1 B-...-φ_p B^p"), ", ",
  #               C("θ(B)=1+θ_1 B+...+θ_q B^q"), "; saisonniers ", C("Φ(B^s)"), ", ", C("Θ(B^s)"), "."),
  #       tags$li(B("Stabilité / inversibilité"), " : racines des polynômes hors du cercle unité."),
  #       tags$li(B("Constante / drift"), " : avec ", C("d=1"), " la constante induit une pente moyenne."),
  #       tags$li(B("Critères"), " : ", C("AIC, AICc, BIC"), "; AICc si n/k modeste.")
  #     ),
  #     actions = OL(
  #       tags$li("Fixer la fréquence et ", C("s"), " selon le contexte."),
  #       tags$li("Décider d’une transformation (aucune / log / Box–Cox) motivée par variance."),
  #       tags$li("Préparer benchmarks (Naïf, Drift, SNAIVE) pour comparaison.")
  #     ),
  #     apa = copyAPA("apa0",
  #                   P("« Nous modélisons la série ", C("y_t"),
  #                     " à fréquence [..] (période saisonnière s=[..]) par un SARIMA ",
  #                     C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
  #                     ". L’objectif est prédictif : diagnostics résiduels et comparaison aux benchmarks guideront la sélection. »")
  #     ),
  #     evals = UL(
  #       tags$li("Résidus : ACF non significative, Ljung–Box non significatif."),
  #       tags$li("Prévision : MAE/RMSE (et éventuellement MASE) < benchmark."),
  #       tags$li("Parcimonie : modèles quasi-équivalents → garder le plus simple.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Confondre « meilleur AIC » avec « bon modèle »."),
  #       tags$li("Oublier les benchmarks."),
  #       tags$li("Surcharger en paramètres → instabilité.")
  #     ),
  #     extras = UL(
  #       tags$li(B("État–espace & Kalman"), " : utile pour manquants et lissage des innovations."),
  #       tags$li(B("Prévisions"), " : point, intervalles, densités.")
  #     )
  #   )
  # 
  #   # 1) Étape 0 — Problème
  #   pages[[2]] <- make_step(
  #     step_titles[2],
  #     objectifs = UL(
  #       tags$li("Énoncer horizon ", C("h"), ", protocole (split/rolling) et métriques (MAE, RMSE, MASE)."),
  #       tags$li("Justifier transformation (log/Box–Cox) si variance non constante.")
  #     ),
  #     defs = UL(
  #       tags$li(B("Origine de prévision"), " : dernier temps observé."),
  #       tags$li(B("Validation temporelle"), " : rolling-origin multi-origines."),
  #       tags$li(B("SARIMA vs SARIMAX"), " : exogènes inclus dans SARIMAX (hors périmètre ici).")
  #     ),
  #     actions = OL(
  #       tags$li("Définir ", C("h"), " et fenêtres train/test (expansive ou glissante)."),
  #       tags$li("Choisir métriques (MAE, RMSE, MASE/WAPE)."),
  #       tags$li("Décider transformation (aucune/log/Box–Cox/Yeo-Johnson).")
  #     ),
  #     apa = copyAPA("apa1",
  #                   P("« Nous visons des prévisions à horizon ", C("h"), "=[..]. ",
  #                     "La performance est évaluée via [split/rolling-origin] avec [MAE, RMSE, MASE]. ",
  #                     "Une transformation [aucune/log/Box–Cox] est appliquée pour [stabiliser la variance / linéariser]. »")
  #     ),
  #     evals = UL(
  #       tags$li("Même horizon/protocole/métriques pour tous les modèles."),
  #       tags$li("Rapporter moyenne par horizon si ", C("h>1"), ".")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Fuite temporelle dans le split."),
  #       tags$li("MAPE quand ", C("y≈0"), " → instable."),
  #       tags$li("Comparer des horizons différents.")
  #     )
  #   )
  # 
  #   # 2) Étape 1 — Données
  #   pages[[3]] <- make_step(
  #     step_titles[3],
  #     objectifs = UL(
  #       tags$li("Index régulier, manquants gérés, descriptifs rapportés."),
  #       tags$li("Documenter couvertures et éventuels changements de définition.")
  #     ),
  #     defs = UL(
  #       tags$li(B("MCAR/MAR/MNAR"), " : nature des manquants."),
  #       tags$li(B("Régularité"), " : pas fixes, pas de doublons ; attention fuseau/DST (horaire).")
  #     ),
  #     actions = OL(
  #       tags$li("Compter ", C("n"), ", dates début/fin, fréquence."),
  #       tags$li("Lister manquants (k, k/n). Choisir traitement : interp linéaire/saisonnière, Kalman, suppression rare."),
  #       tags$li("Descriptifs : moyenne, médiane, ET, min/max, saison (moyenne par mois).")
  #     ),
  #     apa = copyAPA("apa2",
  #                   P("« La série compte ", C("n"), "=[..] observations ([..]–[..]) à fréquence [..]. ",
  #                     "Les manquants représentent [..]% (k=[..]) et sont traités par [..]. ",
  #                     "Descriptifs : moyenne [..], ET [..], médiane [..]. »")
  #     ),
  #     evals = UL(
  #       tags$li("Index strictement régulier avant ACF."),
  #       tags$li("Méthode d’imputation justifiée et consignée.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Imputation silencieuse (non documentée)."),
  #       tags$li("Timestamps irréguliers avec SARIMA."),
  #       tags$li("Changement de définition non traité.")
  #     )
  #   )
  # 
  #   # 3) Étape 2 — EDA
  #   pages[[4]] <- make_step(
  #     step_titles[4],
  #     objectifs = UL(
  #       tags$li("Identifier tendance, saison(s), ruptures, outliers."),
  #       tags$li("Motiver transformation (niveau vs log).")
  #     ),
  #     defs = UL(
  #       tags$li(B("Rupture"), " : changement durable de niveau/tendance/variance."),
  #       tags$li(B("Outliers AO/IO/LS/TC"), " : typologie d’interventions.")
  #     ),
  #     actions = OL(
  #       tags$li("Tracer ", C("y_t"), " + seasonal plot + boxplots saisonniers."),
  #       tags$li("Examiner ACF brute et le périodogramme (pics à multiples de ", C("s"), ")."),
  #       tags$li("Lister dates atypiques et décider (conserver/corriger/imputer).")
  #     ),
  #     apa = copyAPA("apa3",
  #                   P("« L’EDA révèle une tendance [..] et une saisonnalité s=[..]. ",
  #                     "La variance semble [constante/croissante], motivant [aucune/log]. ",
  #                     "Des outliers autour de [dates] ont été [conservés/traités] car [raison]. »")
  #     ),
  #     evals = UL(
  #       tags$li("Transformation cohérente avec relation niveau–variance."),
  #       tags$li("Outliers réels (ex. fêtes) conservés.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Confondre tendance et saison."),
  #       tags$li("Retirer des points réels."),
  #       tags$li("Ignorer une rupture.")
  #     )
  #   )
  # 
  #   # 4) Étape 3 — Décomposition
  #   pages[[5]] <- make_step(
  #     step_titles[5],
  #     objectifs = UL(
  #       tags$li("Justifier additif vs multiplicatif (souvent via log)."),
  #       tags$li("Utiliser STL pour lecture (éventuellement robuste).")
  #     ),
  #     defs = UL(
  #       tags$li(B("Additif"), " : ", C("y_t=T_t+S_t+e_t"), "; ",
  #               B("Multiplicatif"), " : ", C("y_t=T_t×S_t×e_t")),
  #       tags$li(B("STL"), " : LOESS ; ", C("s.window"), ", ", C("t.window"), ", ", C("robust"))
  #     ),
  #     actions = OL(
  #       tags$li("Comparer amplitude saisonnière vs niveau → log si proportionnelle."),
  #       tags$li("Décomposition (classique ou STL robuste).")
  #     ),
  #     apa = copyAPA("apa4",
  #                   P("« L’amplitude saisonnière variant [peu/beaucoup] avec le niveau, nous retenons un schéma [additif/log-additif]. ",
  #                     "Une décomposition STL [robuste/non robuste] clarifie tendance, saison, résidu. »")
  #     ),
  #     evals = UL(
  #       tags$li("Résidu de décomposition sans motifs persistants."),
  #       tags$li("Choix d’échelle cohérent avec EDA.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Prendre la décomposition pour une preuve de stationnarité."),
  #       tags$li("Oublier la reconversion (log→niveau).")
  #     )
  #   )
  # 
  #   # 5) Étape 4 — Stationnarité & différenciation
  #   pages[[6]] <- make_step(
  #     step_titles[6],
  #     objectifs = UL(
  #       tags$li("Choisir ", C("d, D"), " en triangulant ADF/KPSS/PP + graphes."),
  #       tags$li("Éviter la sur-différenciation.")
  #     ),
  #     defs = UL(
  #       tags$li(B("Stationnarité faible"), " : moyenne/variance constantes; autocovariances dépendent du lag."),
  #       tags$li(B("ADF/PP"), " : H0 racine unitaire; ",
  #               B("KPSS"), " : H0 stationnarité."),
  #       tags$li(B("Règles"), " : ", C("d∈{0,1,2}"), " (souvent 0–1), ", C("D∈{0,1}"))
  #     ),
  #     actions = OL(
  #       tags$li("Tester ADF/KPSS/PP sur brut, puis après ", C("d=1"), " et/ou ", C("D=1"), "."),
  #       tags$li("S’arrêter quand stationnarité raisonnable; vérifier ACF (évanescente)."),
  #       tags$li("Conserver drift/constante selon ", C("d"), " et besoin.")
  #     ),
  #     apa = copyAPA("apa5",
  #                   P("« Les tests ADF (p=[..]) et PP (p=[..]) [rejettent/ne rejettent pas] la racine unitaire, ",
  #                     "alors que KPSS (p=[..]) [rejette/ne rejette pas] la stationnarité. ",
  #                     "Nous retenons d=[..], D=[..], s=[..], évitant la sur-différenciation. »")
  #     ),
  #     evals = UL(
  #       tags$li("Convergence : ADF/PP vs KPSS cohérents (ou justification en cas de conflit)."),
  #       tags$li("ACF lag 1 pas fortement négative (sinon sur-diff).")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Choisir ", C("d, D"), " par habitude."),
  #       tags$li("Ignorer rupture structurelle (faux signal)."),
  #       tags$li("Prendre une p-value comme verdict absolu.")
  #     ),
  #     extras = UL(
  #       tags$li(B("HEGY / Zivot–Andrews"), " : tests avancés (annexe).")
  #     )
  #   )
  # 
  #   # 6) Étape 5 — Auto-ARIMA baseline
  #   pages[[7]] <- make_step(
  #     step_titles[7],
  #     objectifs = UL(
  #       tags$li("Obtenir un point de départ compétitif (AICc) puis valider par diagnostics."),
  #       tags$li("Conserver parcimonie si performance similaire.")
  #     ),
  #     defs = UL(
  #       tags$li(B("AICc"), " pour petites tailles; stepwise vs exhaustive."),
  #       tags$li(B("Contraintes"), " sur ", C("p,q,P,Q"), " + stabilité/inversibilité.")
  #     ),
  #     actions = OL(
  #       tags$li("Fixer/valider ", C("d,D"), " (ou ndiffs/nsdiffs)."),
  #       tags$li("Explorer bornes raisonnables; tester drift si ", C("d=1"), "."),
  #       tags$li("Sauver la baseline; vérifier résidus + test. ")
  #     ),
  #     apa = copyAPA("apa6",
  #                   P("« Une procédure auto-ARIMA (AICc) a sélectionné une baseline parmi des ordres candidats contraints. ",
  #                     "Elle est comparée à des variantes plus parcimonieuses via diagnostics et performance. »")
  #     ),
  #     evals = UL(
  #       tags$li("AICc/BIC, Ljung–Box, MAE/RMSE/MASE, nb paramètres."),
  #       tags$li("Baseline = repère minimal à battre.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Se fier au seul AICc si résidus autocorrélés."),
  #       tags$li("Ordres trop élevés → instabilité.")
  #     )
  #   )
  # 
  #   # 7) Étape 6 — SARIMA manuel
  #   pages[[8]] <- make_step(
  #     step_titles[8],
  #     objectifs = UL(
  #       tags$li("Proposer 3–8 candidats justifiés par ACF/PACF."),
  #       tags$li("Garantir stabilité/inversibilité.")
  #     ),
  #     defs = UL(
  #       tags$li(B("ACF"), " : coupure ~ MA(q); ", B("PACF"), " : coupure ~ AR(p)."),
  #       tags$li(B("Saisonnier"), " : pics à ", C("s,2s,..."), " (ACF→SMA; PACF→SAR).")
  #     ),
  #     actions = OL(
  #       tags$li("Lire ACF/PACF sur la série différenciée retenue."),
  #       tags$li("Construire candidats parcimonieux (inclure/exclure drift)."),
  #       tags$li("Comparer AICc/BIC + diagnostics, retenir shortlist.")
  #     ),
  #     apa = copyAPA("apa7",
  #                   P("« Des modèles candidats ont été proposés d’après ACF/PACF (non-saisonnier et saisonnier). ",
  #                     "Nous avons ajusté n=[..] candidats et comparé AICc/BIC, stabilité et diagnostics résiduels, en privilégiant la parcimonie. »")
  #     ),
  #     evals = UL(
  #       tags$li("Racines hors cercle unité (AR/MA)."),
  #       tags$li("Pas d’autocorrélation résiduelle (Ljung–Box).")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Brute-force massif = data snooping."),
  #       tags$li("Sur-interpréter ACF/PACF (guides, pas preuves).")
  #     )
  #   )
  # 
  #   # 8) Étape 7 — Diagnostics & comparaison
  #   pages[[9]] <- make_step(
  #     step_titles[9],
  #     objectifs = UL(
  #       tags$li("Résidus ~ bruit blanc; performance > benchmarks."),
  #       tags$li("Rapporter incertitude (IC) et significativité utile.")
  #     ),
  #     defs = UL(
  #       tags$li(B("Ljung–Box"), " : H0 = pas d’autocorrélation résiduelle."),
  #       tags$li(B("ARCH"), " : variance conditionnelle (vérifier ACF des résidus au carré).")
  #     ),
  #     actions = OL(
  #       tags$li("ACF/PACF des résidus; Ljung–Box (lag L adapté)."),
  #       tags$li("Évaluer MAE/RMSE/MASE via split/rolling; comparer Naïf/Drift/SNAIVE."),
  #       tags$li("Option : Diebold–Mariano pour comparer deux modèles.")
  #     ),
  #     apa = copyAPA("apa8",
  #                   P("« Les résidus ne montrent pas d’autocorrélations significatives (Ljung–Box p=[..]). ",
  #                     "Sur la fenêtre d’évaluation, MAE=[..], RMSE=[..], mieux que [benchmark]. »")
  #     ),
  #     evals = UL(
  #       tags$li("Diagnostics passés + benchmark battu → modèle acceptable."),
  #       tags$li("Normalité utile pour IC mais secondaire pour point forecast.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Valider sur AIC mais diagnostics mauvais."),
  #       tags$li("Comparer des horizons/protocoles différents.")
  #     )
  #   )
  # 
  #   # 9) Étape 8 — Rédaction
  #   pages[[10]] <- make_step(
  #     step_titles[10],
  #     objectifs = UL(
  #       tags$li("Rapport clair et reproductible (Méthodes/Résultats/Discussion)."),
  #       tags$li("Inclure figures et tableau de comparaison.")
  #     ),
  #     defs = UL(
  #       tags$li(B("Biais de reconversion (log→niveau)"),
  #               " : ", C("exp(\\hat{y}) × exp(\\hat{\\sigma}^2/2)"), " si correction appliquée."),
  #       tags$li(B("Couverture des IC"), " : préciser 80%/95%.")
  #     ),
  #     actions = OL(
  #       tags$li("Compiler script/notebook intégral."),
  #       tags$li("Inclure figures : série, décomposition, ACF/PACF, résidus, prévisions+IC."),
  #       tags$li("Tableau : modèles vs AICc/BIC vs Ljung–Box vs MAE/RMSE/MASE vs benchmark.")
  #     ),
  #     apa = copyAPA("apa9",
  #                   P("« Le modèle final SARIMA((p,d,q)(P,D,Q)_s) présente des résidus compatibles avec un bruit blanc. ",
  #                     "À horizon ", C("h"), ", les prévisions améliorent [benchmark] selon [MAE/RMSE]. ",
  #                     "Les choix (transformation, d/D, ordres) sont justifiés par EDA, tests et diagnostics. »")
  #     ),
  #     evals = UL(
  #       tags$li("Reproductibilité : versions packages, seed, date d’extraction."),
  #       tags$li("Clarté : chaque choix ← une preuve.")
  #     ),
  #     pitfalls = UL(
  #       tags$li("Texte sans figures (les figures sont des résultats)."),
  #       tags$li("Oublier d’indiquer l’échelle (niveau/log/Box–Cox).")
  #     )
  #   )
  # 
  #   # 10) Annexes
  #   pages[[11]] <- make_step(
  #     step_titles[11],
  #     objectifs = UL(
  #       tags$li("Fournir mémo formules + règles rapides d’interprétation."),
  #       tags$li("Lister benchmarks et outils avancés.")
  #     ),
  #     defs = UL(
  #       tags$li(B("AIC"), "=", C("-2 log L + 2k"),
  #               "; ", B("AICc"), "=", C("AIC + 2k(k+1)/(n-k-1)"),
  #               "; ", B("BIC"), "=", C("-2 log L + k log n")),
  #       tags$li(B("MASE"), " : ", C("mean(|e_t|) / mean(|y_t - y_{t-s}|)")),
  #       tags$li(B("Ljung–Box"), " : ", C("Q^* = n(n+2) Σ_{k=1}^L ρ_k^2/(n-k)"))
  #     ),
  #     actions = OL(
  #       tags$li("Benchmarks : Naïf ", C("ŷ_{t+1|t}=y_t"),
  #               ", Drift, SNAIVE ", C("ŷ_{t+h|t}=y_{t+h-s}"), "."),
  #       tags$li("Pistes avancées : SARIMAX, interventions (LS/TC), multiples saisonnalités (TBATS/ETS-MS).")
  #     ),
  #     apa = copyAPA("apa10",
  #                   P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
  #                     "Nous retenons d=[..], D=[..] (s=[..]) et comparons nos modèles à SNAIVE. »")
  #     ),
  #     evals = UL(
  #       tags$li("Règles rapides : ",
  #               B("ADF/PP rejettent + KPSS ne rejette pas → stationnarité plausible"),
  #               " ; ",
  #               B("ADF/PP ne rejettent pas + KPSS rejette → différenciation nécessaire")
  #       )
  #     ),
  #     pitfalls = UL(
  #       tags$li("Penser qu’un test « décide » seul."),
  #       tags$li("Oublier la finalité : prévision out-of-sample + diagnostics.")
  #     )
  #   )
  # 
  #   # ===== Output =====
  #   tagList(
  #     css,
  #     tags$div(id="road_container",
  #              tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/", .road_max, " — ", step_titles[cur + 1L])),
  #              progress_ui,
  #              pages[[cur + 1L]]
  #     )
  #   )
  # })
  # 
  
  
  
  
  
  
  
  
  
  
  # ===========================================================================
  # ===========================================================================
  # ===========================================================================
  

  # # --- Roadmap slider navigation (Prev/Next) ---
  # observeEvent(input$road_prev, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  # }, ignoreInit = TRUE)
  # 
  # observeEvent(input$road_next, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  # }, ignoreInit = TRUE)
  # 
  # 
  # 
  # # =========================
  # # Roadmap UI (controls)
  # # =========================
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  # 
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  # 
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:600;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #   ")),
  # 
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
  #     tags$p(class="road-sub",
  #            "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
  # 
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput(
  #         "roadmap_step", label = NULL,
  #         min = 0, max = 10, value = 0, step = 1, width = "520px"
  #       ),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
  #     ),
  # 
  #     # Progress bar (pure UI, updated via re-render of content)
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  # 
  # 
  # # =========================
  # # Roadmap UI (content)
  # # =========================
  # output$roadmap_step_content <- renderUI({
  # 
  #   # ========= Helpers =========
  #   D <- function(title, ...) {
  #     tags$details(
  #       tags$summary(title),
  #       tags$div(class = "road-scroll", ...)
  #     )
  #   }
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   P  <- function(...) tags$p(...)
  #   B  <- function(...) tags$b(...)
  #   C  <- function(...) tags$code(...)
  #   H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
  # 
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  # 
  #   # ========= CSS (internal scroll so the page stays short) =========
  #   css <- tags$style(HTML("
  #   .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #   details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #   details > summary {cursor:pointer;font-weight:700;}
  #   .road-scroll {max-height: 62vh; overflow-y: auto; padding-right: 10px;}
  #   .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #   .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #   .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #   code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #   .progress {height:10px; margin:10px 0 0 0;}
  # "))
  # 
  #   # ========= Step logic =========
  #   cur <- input$roadmap_step
  #   if (is.null(cur) || !is.finite(cur)) cur <- 0
  #   cur <- as.integer(cur)
  # 
  #   step_names <- c(
  #     "Aperçu & notations (glossaire + lecture du modèle)",
  #     "Étape 0 — Définir le problème de modélisation",
  #     "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
  #     "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
  #     "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
  #     "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
  #     "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
  #     "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
  #     "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
  #     "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
  #     "Annexes — Formules, checklists, templates, interprétations rapides"
  #   )
  # 
  #   pct <- round(100 * cur / 10)
  #   progress_ui <- tags$div(
  #     class="progress",
  #     tags$div(
  #       class="progress-bar",
  #       role="progressbar",
  #       `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #       style = paste0("width:", pct, "%;")
  #     )
  #   )
  # 
  #   make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
  #     tags$div(
  #       class = "road-card",
  #       if (!is.null(header_ui)) header_ui,
  #       tags$h4(title),
  #       D("1) Ce que l’étudiant fait (procédure + définitions + objectifs)", actions_ui),
  #       D("2) Ce qu’il écrit (APA) + conclusion & signification", apa_ui),
  #       D("3) Pièges + comment les éviter (avec interprétation)", pitfalls_ui)
  #     )
  #   }
  # 
  #   # ========= Pages =========
  #   pages <- vector("list", length = 11)
  # 
  #   # (0) Aperçu
  #   pages[[1]] <- make_step(
  #     step_names[1],
  # 
  #     actions_ui = tagList(
  #       callout(
  #         B("Objectif global : "),
  #         "construire un modèle SARIMA interprétable et surtout ",
  #         B("prédictif"), " : il doit passer les diagnostics résiduels et battre un benchmark simple.",
  #         type="ok"
  #       ),
  # 
  #       H5("Notations essentielles (définitions)"),
  #       UL(
  #         tags$li(B("Série temporelle"), " : suite ordonnée d’observations indexées par le temps ", C("y_t"), "."),
  #         tags$li(B("Fréquence / période saisonnière"), " : nombre de pas par cycle saisonnier, noté ", C("s"),
  #                 " (ex. mensuel s=12; quotidien avec saison hebdo s=7)."),
  #         tags$li(B("Opérateur de retard (backshift)"), " : ", C("B y_t = y_{t-1}"), "."),
  #         tags$li(B("Différenciation ordinaire"), " : ", C("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
  #                 " ; appliquée ", C("d"), " fois → supprimer tendance/racine unitaire non saisonnière."),
  #         tags$li(B("Différenciation saisonnière"), " : ", C("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
  #                 " ; appliquée ", C("D"), " fois → supprimer racine unitaire saisonnière."),
  #         tags$li(B("Innovations / bruit blanc"), " : ", C("ε_t ~ w.n.(0, σ²)"),
  #                 " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
  #       ),
  # 
  #       H5("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)"),
  #       UL(
  #         tags$li(
  #           "Écriture compacte : ",
  #           C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
  #         ),
  #         tags$li(
  #           B("Interprétation : "),
  #           "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
  #           "non saisonnières (p,q) et saisonnières (P,Q)."
  #         )
  #       ),
  # 
  #       H5("Ce que signifie “bon modèle” (définition opérationnelle)"),
  #       OL(
  #         tags$li(B("Résidus ~ bruit blanc"), " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."),
  #         tags$li(B("Performance out-of-sample"), " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."),
  #         tags$li(B("Parcimonie"), " : modèle le plus simple possible à performance comparable.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Phrase APA (modèle + notations)"),
  #       P("« Nous avons ajusté un modèle SARIMA afin de capturer la dépendance temporelle et la saisonnalité de la série ",
  #         C("y_t"), ". La spécification générale est ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
  #         " avec ", C("ε_t"), " un bruit blanc. Le choix de (d, D) a été justifié par des tests de stationnarité (ADF/KPSS/PP) et des diagnostics. »"),
  # 
  #       H5("Conclusion & signification (à expliciter)"),
  #       UL(
  #         tags$li(B("Conclusion type : "), "« Le modèle final est adéquat »"),
  #         tags$li(B("Signification : "), "« (i) il ne laisse pas d’information autocorrélée dans les résidus, ",
  #                 "(ii) il généralise bien sur une fenêtre future, ",
  #                 "(iii) il est suffisamment simple pour être stable et reproductible. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       H5("Pièges classiques"),
  #       UL(
  #         tags$li(B("Confondre AIC faible et bon modèle"), " : un AIC très bas avec résidus autocorrélés = modèle mal spécifié."),
  #         tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naïf, impossible de dire si SARIMA apporte réellement quelque chose."),
  #         tags$li(B("Surcharger le modèle"), " : trop de paramètres → instabilité, intervalles de prévision peu fiables.")
  #       )
  #     )
  #   )
  # 
  #   # (1) Étape 0 — Définition du problème
  #   pages[[2]] <- make_step(
  #     step_names[2],
  # 
  #     actions_ui = tagList(
  #       callout(
  #         B("But : "),
  #         "définir un problème de prévision mesurable (horizon, métriques, protocole).",
  #         type="info"
  #       ),
  # 
  #       H5("Définitions (ce que chaque terme veut dire)"),
  #       UL(
  #         tags$li(B("Série réponse"), " ", C("y_t"), " : variable à prédire (univariée)."),
  #         tags$li(B("Horizon"), " ", C("h"), " : nombre de pas à prévoir (ex. h=12 mois)."),
  #         tags$li(B("Origine de prévision"), " : dernier temps observé à partir duquel on prévoit."),
  #         tags$li(B("Protocole train/test"), " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."),
  #         tags$li(B("Rolling-origin / validation temporelle"), " : on répète des prévisions à différentes origines pour estimer la performance moyenne."),
  #         tags$li(B("SARIMA vs SARIMAX"), " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes.")
  #       ),
  # 
  #       H5("Choisir les métriques (définitions + quand utiliser)"),
  #       UL(
  #         tags$li(B("MAE"), " : moyenne des erreurs absolues ", C("mean(|y-ŷ|)"),
  #                 " → robuste, facile à interpréter (unité de y)."),
  #         tags$li(B("RMSE"), " : racine de l’erreur quadratique moyenne ", C("sqrt(mean((y-ŷ)^2))"),
  #                 " → pénalise plus les grosses erreurs."),
  #         tags$li(B("MAPE"), " : ", C("mean(|(y-ŷ)/y|)"),
  #                 " → éviter si y proche de 0 (explose)."),
  #         tags$li(B("sMAPE"), " : alternative plus stable près de 0 : ", C("mean(2|y-ŷ|/(|y|+|ŷ|))"), ".")
  #       ),
  # 
  #       H5("Transformation (définitions + justification)"),
  #       UL(
  #         tags$li(B("Niveaux"), " : modèle sur les valeurs brutes."),
  #         tags$li(B("Log-niveaux"), " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."),
  #         tags$li(B("Box–Cox"), " : transformation paramétrique (λ) pour stabiliser variance et améliorer normalité : ",
  #                 C("y^(λ) = (y^λ - 1)/λ"), " (λ≠0), et log si λ=0.")
  #       ),
  # 
  #       H5("Procédure minimale (checklist)"),
  #       OL(
  #         tags$li("Fixer fréquence et période saisonnière s."),
  #         tags$li("Fixer horizon h et fenêtres train/test (ou rolling-origin)."),
  #         tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
  #         tags$li("Décider transformation (aucune/log/Box–Cox) et justifier.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — modèle de phrase complet"),
  #       P("« Nous avons modélisé la série temporelle univariée ", C("y_t"),
  #         " observée à une fréquence [..] (période saisonnière s=[..]). ",
  #         "L’objectif était de produire des prévisions à horizon ", C("h"), "=[..]. ",
  #         "La performance a été évaluée sur une fenêtre future selon [split temporel / rolling-origin] ",
  #         "à l’aide de [MAE, RMSE]. Une transformation [aucune / log / Box–Cox] a été appliquée afin de [stabiliser la variance / linéariser la saisonnalité]. »"),
  # 
  #       H5("Conclusion & signification (comment l’expliquer)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Notre problème est bien défini (h, métriques, protocole). »"),
  #         tags$li(B("Signification : "), "« Toute comparaison de modèles devient juste : même horizon, même protocole, mêmes métriques. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) → performance artificiellement élevée."),
  #         tags$li(B("Métrique mal choisie"), " : MAPE avec y≈0 → conclusions fausses."),
  #         tags$li(B("Horizon incohérent"), " : un modèle bon à h=1 peut être mauvais à h=12 ; fixer l’horizon selon l’usage réel.")
  #       )
  #     )
  #   )
  # 
  #   # (2) Étape 1 — Description des données
  #   pages[[3]] <- make_step(
  #     step_names[3],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "décrire la qualité des données et rendre le pipeline reproductible.", type="info"),
  # 
  #       H5("Ce qu’il faut rapporter (définitions)"),
  #       UL(
  #         tags$li(B("n"), " : nombre total d’observations disponibles."),
  #         tags$li(B("Couverture"), " : date début/fin."),
  #         tags$li(B("Fréquence"), " : périodicité (mensuel/hebdo/quotidien)."),
  #         tags$li(B("Manquants"), " : nombre k et pourcentage k/n.")
  #       ),
  # 
  #       H5("Valeurs manquantes : types + implications"),
  #       UL(
  #         tags$li(B("MCAR"), " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."),
  #         tags$li(B("MAR"), " (At Random conditionnel) : dépend d’autres infos → imputation possible mais à justifier."),
  #         tags$li(B("MNAR"), " (Not At Random) : dépend de la valeur elle-même → risque de biais important.")
  #       ),
  # 
  #       H5("Stratégies de traitement (quand et pourquoi)"),
  #       UL(
  #         tags$li(B("Interpolation linéaire"), " : si manquants rares et pas de ruptures."),
  #         tags$li(B("Interpolation saisonnière"), " : si saisonnalité stable (ex. remplacer par moyenne du même mois)."),
  #         tags$li(B("Modèle d’état / Kalman"), " : si on veut une imputation plus probabiliste."),
  #         tags$li(B("Suppression"), " : seulement si extrêmement rare et sans impact sur la continuité.")
  #       ),
  # 
  #       H5("Descriptifs pertinents (au-delà de la moyenne)"),
  #       UL(
  #         tags$li("Moyenne, médiane, ET, min/max (niveau)."),
  #         tags$li("Asymétrie (skewness) / kurtosis si utile."),
  #         tags$li("Résumé saisonnier (ex. moyenne par mois), pour documenter saisonnalité.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — description"),
  #       P("« La série contient ", C("n"), "=[..] observations couvrant [..] à [..] à une fréquence [..]. ",
  #         "Les valeurs manquantes représentaient [..]% (k=[..]) et ont été traitées par [..], ",
  #         "choisie car [manquants rares / saisonnalité stable / continuité nécessaire]. ",
  #         "La série présentait une moyenne de [..] (ET=[..]) et une médiane [..]. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Les données sont suffisamment propres pour SARIMA » (ou non)."),
  #         tags$li(B("Signification : "),
  #                 "si l’index est régulier et que les manquants sont gérés explicitement, ",
  #                 "les hypothèses du modèle (espacement régulier) deviennent plausibles.")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Imputation silencieuse"), " : toujours documenter méthode + raison."),
  #         tags$li(B("Timestamps irréguliers"), " : SARIMA suppose une grille régulière ; corriger avant toute estimation."),
  #         tags$li(B("Changement de définition de la variable"), " : ex. changement de mesure → rupture structurelle à traiter.")
  #       )
  #     )
  #   )
  # 
  #   # (3) Étape 2 — EDA
  #   pages[[4]] <- make_step(
  #     step_names[4],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant d’ajuster SARIMA.", type="info"),
  # 
  #       H5("Définitions utiles (ce qu’on cherche)"),
  #       UL(
  #         tags$li(B("Tendance"), " : évolution de long terme (déterministe ou stochastique)."),
  #         tags$li(B("Saisonnalité"), " : motif périodique de période s (ex. 12)."),
  #         tags$li(B("Rupture structurelle"), " : changement durable de niveau/tendance/variance (ex. politique, crise)."),
  #         tags$li(B("Outlier"), " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou erreur.")
  #       ),
  # 
  #       H5("Graphiques recommandés + leur but"),
  #       UL(
  #         tags$li(B("Courbe y_t"), " : voir tendance, variance, ruptures."),
  #         tags$li(B("Seasonal plot"), " : comparer la forme saisonnière d’une année à l’autre."),
  #         tags$li(B("Boxplots par saison"), " : détecter asymétrie/outliers par mois/semaine."),
  #         tags$li(B("ACF brute"), " (optionnel) : repérer dépendances fortes et saisonnalité.")
  #       ),
  # 
  #       H5("Outliers : procédure raisonnable"),
  #       OL(
  #         tags$li("Repérer visuellement (dates)."),
  #         tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
  #         tags$li("Décider : conserver / corriger / imputer (et justifier)."),
  #         tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — EDA"),
  #       P("« L’inspection visuelle a mis en évidence une tendance [..] et une saisonnalité récurrente de période s=[..]. ",
  #         "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Box–Cox]. ",
  #         "Des valeurs atypiques autour de [dates] ont été [conservées/traitées] car [événement réel / erreur probable]. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« La structure (tendance/saison/variance/outliers) est comprise »"),
  #         tags$li(B("Signification : "),
  #                 "cela guide directement le choix transformation + différenciations (d, D) et évite d’ajuster un SARIMA “à l’aveugle”.")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Confondre saisonnalité et tendance"), " : une moyenne croissante ET une saisonnalité stable sont deux composantes distinctes."),
  #         tags$li(B("Retirer des points réels"), " : si l’outlier correspond à un événement récurrent (fêtes), il doit rester."),
  #         tags$li(B("Ignorer une rupture"), " : un SARIMA “moyenne” une structure qui a changé → mauvais futur.")
  #       )
  #     )
  #   )
  # 
  #   # (4) Étape 3 — Décomposition
  #   pages[[5]] <- make_step(
  #     step_names[5],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "séparer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
  # 
  #       H5("Décomposition : définitions"),
  #       UL(
  #         tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
  #                 " (amplitude saisonnière ~ constante)."),
  #         tags$li(B("Multiplicative"), " : ", C("y_t = T_t × S_t × e_t"),
  #                 " (amplitude saisonnière augmente avec le niveau)."),
  #         tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
  #                 C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
  #         tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
  #       ),
  # 
  #       H5("Pourquoi STL ? (objectif détaillé)"),
  #       UL(
  #         tags$li("Quand la saisonnalité change lentement au fil du temps (non parfaitement répétitive)."),
  #         tags$li("Quand on veut réduire l’influence des outliers sur l’estimation saison/tendance."),
  #         tags$li("Quand on veut une lecture pédagogique claire (tendance vs saison vs résidu).")
  #       ),
  # 
  #       H5("Ce que la décomposition ne remplace pas"),
  #       UL(
  #         tags$li("Elle ne prouve pas la stationnarité : SARIMA exige une série stationnaire après différenciation."),
  #         tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nécessaires.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Décomposition"),
  #       P("« Nous avons étudié une structure additive vs multiplicative en évaluant si l’amplitude saisonnière variait avec le niveau. ",
  #         "Comme [..], nous avons retenu [modèle additif / transformation log] et réalisé une décomposition via [classique / STL]. ",
  #         "STL a été privilégiée pour sa flexibilité (saisonnalité évolutive) et sa robustesse aux valeurs atypiques. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le choix additif/multiplicatif est justifié »"),
  #         tags$li(B("Signification : "),
  #                 "on évite des résidus hétéroscédastiques et on améliore la stabilité de l’estimation SARIMA.")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Décomposition ≠ stationnarité"), " : après décomposition, on doit encore tester/choisir d et D."),
  #         tags$li(B("Oublier l’échelle"), " : si vous modélisez log(y), les prévisions doivent être reconverties (avec prudence)."),
  #         tags$li(B("Confondre bruit et structure"), " : des motifs résiduels persistants suggèrent que la saison/tendance n’a pas été correctement capturée.")
  #       )
  #     )
  #   )
  # 
  #   # (5) Étape 4 — Stationnarité (très détaillé : ADF/KPSS/PP + conclusion & sens)
  #   pages[[6]] <- make_step(
  #     step_names[6],
  # 
  #     actions_ui = tagList(
  #       callout(
  #         B("Idée centrale : "),
  #         "SARIMA suppose que la série devient (au moins) stationnaire ",
  #         B("après différenciation"), ". Les tests ADF/PP/KPSS servent à justifier (d, D).",
  #         type="ok"
  #       ),
  # 
  #       H5("Définition : stationnarité (ce que cela veut dire)"),
  #       UL(
  #         tags$li(B("Stationnarité faible (covariance-stationnaire)"), " : moyenne constante, variance constante, ",
  #                 "et autocovariance dépend uniquement du retard (pas de t)."),
  #         tags$li(B("Non-stationnarité"), " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."),
  #         tags$li(B("Racine unitaire"), " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1).")
  #       ),
  # 
  #       H5("Différenciation : rôle (d vs D)"),
  #       UL(
  #         tags$li(B("d"), " enlève la racine unitaire non saisonnière / tendance stochastique : ", C("(1-B)^d"), "."),
  #         tags$li(B("D"), " enlève la racine unitaire saisonnière : ", C("(1-B^s)^D"), "."),
  #         tags$li(B("Règle pratique"), " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2).")
  #       ),
  # 
  #       H5("Test ADF (Augmented Dickey–Fuller) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."),
  #         tags$li(B("Régression (intuition)"), " : on teste si le coefficient de ", C("y_{t-1}"),
  #                 " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire (non-stationnaire) ; ",
  #                 B("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."),
  #         tags$li(B("Interprétation p-value"), " : p petit → rejet H0 → stationnarité (au sens ADF). p grand → on ne rejette pas → différenciation probablement nécessaire.")
  #       ),
  # 
  #       H5("Test KPSS — définition & objectif (inverse de l’ADF)"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série est stationnaire (niveau ou tendance)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = stationnaire ; ",
  #                 B("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."),
  #         tags$li(B("Interprétation"), " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité.")
  #       ),
  # 
  #       H5("Test PP (Phillips–Perron) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement (correction non-paramétrique)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire ; ",
  #                 B("Ha"), " = stationnaire."),
  #         tags$li(B("Pourquoi utile"), " : complément de robustesse ; si ADF et PP convergent, confiance accrue.")
  #       ),
  # 
  #       H5("Comment conclure en combinant ADF/KPSS/PP (logique complète)"),
  #       OL(
  #         tags$li(B("Stationnarité forte : "), "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."),
  #         tags$li(B("Non-stationnarité forte : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
  #         tags$li(B("Conflit : "), "les tests divergent → regarder graphiques, ACF, résultats après une différence, et justifier par convergence d’indices (pas une seule p-value).")
  #       ),
  # 
  #       H5("Procédure recommandée (pas à pas)"),
  #       OL(
  #         tags$li("Fixer ", B("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
  #         tags$li("Tester ADF/KPSS/PP sur la série brute."),
  #         tags$li("Essayer d=1 si nécessaire, retester."),
  #         tags$li("Essayer D=1 si saisonnalité/racine saisonnière, retester."),
  #         tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
  #       ),
  # 
  #       H5("Sur-différenciation : définition + symptômes"),
  #       UL(
  #         tags$li(B("Définition"), " : appliquer trop de différences → on introduit une dynamique artificielle."),
  #         tags$li(B("Symptômes fréquents"), " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."),
  #         tags$li(B("Conséquence"), " : intervalles de prévision plus larges et modèle moins fiable.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Tests & choix de (d, D)"),
  #       P("« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
  #         "Les résultats ont été examinés sur la série originale puis après différenciations ordinaires et saisonnières. ",
  #         "Sur la base de l’ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
  #         "afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA, tout en évitant la sur-différenciation. »"),
  # 
  #       H5("Conclusion test (prête à remplir) + signification"),
  #       UL(
  #         tags$li(B("ADF : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "si rejet → la série est compatible stationnarité (au sens ADF) ; sinon → différenciation probablement nécessaire."),
  #         tags$li(B("KPSS : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (stationnarité). ",
  #                 B("Signification : "),
  #                 "si rejet → non-stationnarité (donc d/D à augmenter ou transformation/rupture à traiter)."),
  #         tags$li(B("PP : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
  #       ),
  # 
  #       H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Nous retenons d=[..], D=[..], s=[..]. »"),
  #         tags$li(B("Signification : "),
  #                 "« le SARIMA sera estimé sur la série différenciée ; les paramètres AR/MA décrivent la dynamique ",
  #                 "restante après retrait de la tendance et/ou de la saisonnalité non stationnaire. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Choisir d et D “par habitude”"), " : toujours justifier par tests + EDA."),
  #         tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent “crier non-stationnaire” alors qu’un changement de régime est en cause."),
  #         tags$li(B("Interpréter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on s’appuie sur convergence des preuves.")
  #       )
  #     )
  #   )
  # 
  #   # (6) Étape 5 — Auto-ARIMA baseline
  #   pages[[7]] <- make_step(
  #     step_names[7],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "obtenir un point de départ compétitif, puis vérifier/affiner.", type="info"),
  # 
  #       H5("Définition : auto-ARIMA (ce que fait réellement l’algorithme)"),
  #       UL(
  #         tags$li("Explore un ensemble de modèles candidats (p,q,P,Q) sous contraintes."),
  #         tags$li("Choisit souvent via minimisation ", B("AICc"),
  #                 " (AIC corrigé petits échantillons)."),
  #         tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coûteuse).")
  #       ),
  # 
  #       H5("Pourquoi AICc ? (objectif)"),
  #       UL(
  #         tags$li("Compromis entre qualité d’ajustement et complexité (pénalise les paramètres)."),
  #         tags$li("AICc est préférable à AIC quand n n’est pas très grand par rapport au nombre de paramètres.")
  #       ),
  # 
  #       H5("Procédure propre"),
  #       OL(
  #         tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
  #         tags$li("Fixer bornes max p/q/P/Q ; documenter."),
  #         tags$li("Sauvegarder le modèle baseline (pour comparaison)."),
  #         tags$li("Vérifier diagnostics résiduels + performance sur test.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — baseline"),
  #       P("« Un modèle SARIMA de référence a été sélectionné via une procédure auto-ARIMA basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats sous contraintes [..]. ",
  #         "La spécification obtenue a été utilisée comme baseline, puis comparée à des modèles manuels plus parcimonieux sur la base des diagnostics et de la performance de prévision. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Auto-ARIMA fournit une baseline solide »"),
  #         tags$li(B("Signification : "), "« on a un repère : tout modèle final doit faire au moins aussi bien. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Modèle “trop complexe”"), " : stepwise peut sélectionner des ordres élevés → instabilité, interprétation difficile."),
  #         tags$li(B("AICc excellent mais résidus mauvais"), " : diagnostics priment."),
  #         tags$li(B("Oublier la parcimonie"), " : si deux modèles prédisent pareil, garder le plus simple.")
  #       )
  #     )
  #   )
  # 
  #   # (7) Étape 6 — SARIMA manuel
  #   pages[[8]] <- make_step(
  #     step_names[8],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "proposer un petit ensemble raisonné de candidats via ACF/PACF.", type="info"),
  # 
  #       H5("Définitions : ACF / PACF (ce que mesurent ces courbes)"),
  #       UL(
  #         tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"),
  #                 " → suggère MA(q) si coupure nette vers q."),
  #         tags$li(B("PACF"), " : corrélation “pure” au retard k une fois les retards <k contrôlés ",
  #                 "→ suggère AR(p) si coupure nette vers p.")
  #       ),
  # 
  #       H5("Heuristiques (non saisonnier)"),
  #       UL(
  #         tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF décroît."),
  #         tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF décroît."),
  #         tags$li(B("ARMA"), " : ACF et PACF décroissent (pas de coupure franche).")
  #       ),
  # 
  #       H5("Heuristiques saisonnières (multiples de s)"),
  #       UL(
  #         tags$li(B("SAR(P)"), " : pics PACF à s, 2s, ..."),
  #         tags$li(B("SMA(Q)"), " : pics ACF à s, 2s, ...")
  #       ),
  # 
  #       H5("Procédure recommandée (petit nombre de modèles)"),
  #       OL(
  #         tags$li("Construire 3 à 8 candidats (parcimonieux)."),
  #         tags$li("Ajuster et comparer AICc/BIC."),
  #         tags$li("Vérifier stabilité/inversibilité."),
  #         tags$li("Retenir ceux qui passent diagnostics + prévision.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — sélection manuelle"),
  #       P("« Les structures candidates ont été proposées sur la base des schémas ACF/PACF de la série différenciée. ",
  #         "Des autocorrélations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
  #         "Un ensemble restreint de modèles (n=[..]) a été ajusté et comparé via AICc/BIC et diagnostics résiduels, en privilégiant la parcimonie. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle final est soutenu par la structure ACF/PACF et les diagnostics. »"),
  #         tags$li(B("Signification : "), "« on réduit le risque de sur-ajustement en limitant les candidats. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Brute-force massif"), " : tester 200 modèles puis choisir le plus petit AICc = data snooping."),
  #         tags$li(B("Surinterpréter ACF/PACF"), " : ce sont des guides, pas des preuves."),
  #         tags$li(B("Ignorer l’inversibilité/stabilité"), " : paramètres instables → prévisions incohérentes.")
  #       )
  #     )
  #   )
  # 
  #   # (8) Étape 7 — Diagnostics & comparaison
  #   pages[[9]] <- make_step(
  #     step_names[9],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "valider que le modèle explique toute la dépendance et prédit bien.", type="ok"),
  # 
  #       H5("Diagnostics résiduels : définitions & buts"),
  #       UL(
  #         tags$li(B("Résidus"), " : ", C("e_t = y_t - ŷ_t"),
  #                 " (ou résidus d’innovation selon l’implémentation)."),
  #         tags$li(B("Bruit blanc"), " : absence d’autocorrélation résiduelle → le modèle a capturé la structure temporelle."),
  #         tags$li(B("Ljung–Box"), " : test global d’autocorrélation des résidus jusqu’à un lag L.")
  #       ),
  # 
  #       H5("Test de Ljung–Box (définition + interprétation)"),
  #       UL(
  #         tags$li(B("But"), " : tester si les autocorrélations résiduelles jusqu’à L sont globalement nulles."),
  #         tags$li(B("Hypothèses"), " : ", B("H0"), " = pas d’autocorrélation résiduelle ; ", B("Ha"), " = autocorrélation résiduelle présente."),
  #         tags$li(B("Conclusion"), " : p petit → rejet H0 → modèle incomplet (ajuster p/q/P/Q ou d/D)."),
  #         tags$li(B("Signification pratique"), " : si autocorrélation résiduelle reste, vos intervalles/prévisions sont souvent trop optimistes.")
  #       ),
  # 
  #       H5("Normalité & hétéroscédasticité (à quoi ça sert vraiment)"),
  #       UL(
  #         tags$li(B("Normalité"), " : utile pour l’interprétation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
  #         tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimés ; si fort, envisager modèles de variance (GARCH) selon le cours.")
  #       ),
  # 
  #       H5("Évaluation prévision (définition + protocole)"),
  #       UL(
  #         tags$li(B("Split temporel"), " : entraîner sur le passé, tester sur le futur."),
  #         tags$li(B("Rolling-origin"), " : répéter sur plusieurs origines → estimation plus robuste."),
  #         tags$li(B("Benchmark"), " : naїf / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE à l’horizon cible.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — diagnostics"),
  #       P("« Les diagnostics résiduels indiquaient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics substantiels et le test de Ljung–Box était [non significatif/significatif] au seuil α=[..]. ",
  #         "La performance de prévision sur la fenêtre d’évaluation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. »"),
  # 
  #       H5("Conclusion & signification (diagnostics + performance)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle est acceptable » si Ljung–Box non significatif ET benchmark battu."),
  #         tags$li(B("Signification : "),
  #                 "« le modèle capte la structure temporelle (résidus ~ bruit) et apporte un gain prédictif réel (out-of-sample). »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Bon AIC mais Ljung–Box significatif"), " : modèle incomplet → ne pas valider."),
  #         tags$li(B("Se focaliser sur la normalité"), " : priorité = absence d’autocorrélation résiduelle."),
  #         tags$li(B("Comparer des modèles sur des horizons différents"), " : toujours même h, même protocole.")
  #       )
  #     )
  #   )
  # 
  #   # (9) Étape 8 — Rédaction
  #   pages[[10]] <- make_step(
  #     step_names[10],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "écrire un rapport clair, reproductible, aligné aux étapes 0–7.", type="info"),
  # 
  #       H5("Structure APA recommandée (définition)"),
  #       UL(
  #         tags$li(B("Méthodes"), " : ce que vous avez fait et pourquoi (données → EDA → stationnarité → modèles → évaluation)."),
  #         tags$li(B("Résultats"), " : ce que vous avez observé (stats, figures, tests, métriques, modèle final)."),
  #         tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
  #       ),
  # 
  #       H5("Pack livrable propre (checklist)"),
  #       UL(
  #         tags$li("Notebook/script reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
  #         tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC."),
  #         tags$li("Tableau : candidats vs AICc/BIC vs Ljung–Box vs MAE/RMSE vs benchmark.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Phrase finale (APA) — modèle final + interprétation"),
  #       P("« Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). ",
  #         "Les résidus étant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a été capturée. ",
  #         "Les prévisions produites à horizon h=[..] améliorent le benchmark [..] selon MAE/RMSE, ce qui soutient l’usage du modèle pour l’application ciblée. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le rapport est aligné, justifié, reproductible. »"),
  #         tags$li(B("Signification : "),
  #                 "« un lecteur externe peut reproduire vos résultats et comprendre chaque choix (transformation, d/D, sélection, diagnostics). »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Ne pas relier choix → preuves"), " : chaque décision doit être liée à EDA/tests/diagnostics."),
  #         tags$li(B("Trop de texte, pas assez de figures"), " : en séries temporelles, les figures sont des résultats."),
  #         tags$li(B("Oublier de préciser l’échelle"), " : niveau vs log vs Box–Cox et reconversion des prévisions.")
  #       )
  #     )
  #   )
  # 
  #   # (10) Annexes
  #   pages[[11]] <- make_step(
  #     step_names[11],
  # 
  #     actions_ui = tagList(
  #       H5("Benchmarks (définitions)"),
  #       UL(
  #         tags$li(B("Naïf"), " : ", C("ŷ_{t+1|t} = y_t"), " (persistance)."),
  #         tags$li(B("Drift"), " : extrapolation linéaire moyenne."),
  #         tags$li(B("SNAIVE"), " : répète la dernière valeur de la même saison : ", C("ŷ_{t+h|t} = y_{t+h-s}"), ".")
  #       ),
  # 
  #       H5("Règles d’interprétation ultra rapides"),
  #       UL(
  #         tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " → stationnarité plausible."),
  #         tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " → différenciation nécessaire."),
  #         tags$li(B("Ljung–Box significatif"), " → il reste de la structure → réviser le modèle.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Template “Conclusion tests → choix (d,D)” (copier-coller)"),
  #       P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
  #         "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnarité, ",
  #         "nous concluons que la série est [stationnaire/non-stationnaire] au sens des diagnostics combinés. ",
  #         "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une série stationnaire pour l’estimation SARIMA. »"),
  # 
  #       H5("Signification (traduction simple)"),
  #       UL(
  #         tags$li("« d et D disent combien de fois on doit “retirer” une tendance et une saisonnalité non stationnaire. »"),
  #         tags$li("« Ensuite, p/q/P/Q décrivent la dépendance restante (mémoire) dans la série transformée. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Croire qu’un test “décide” seul"), " : toujours trianguler avec EDA + ACF + comportement après différenciation."),
  #         tags$li(B("Oublier la finalité"), " : prévision (out-of-sample) + diagnostics passent avant l’esthétique d’un AIC."),
  #         tags$li(B("Ne pas documenter"), " : un bon modèle non documenté = inutilisable dans un cours/rapport.")
  #       )
  #     )
  #   )
  # 
  #   # ========= Output =========
  #   tagList(
  #     css,
  #     tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
  #     progress_ui,
  #     pages[[cur + 1L]]
  #   )
  # })

  
  
  
  
  
  
  
  
 
  
   
  
  
  
  #=====================================================================================================
  #======================Good Code expanded===============================================================================
  #=====================================================================================================
  

  
  # # --- Roadmap slider navigation (Prev/Next) ---
  # observeEvent(input$road_prev, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  # }, ignoreInit = TRUE)
  # 
  # observeEvent(input$road_next, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  # }, ignoreInit = TRUE)
  # 
  # # =========================
  # # Roadmap UI (controls)
  # # =========================
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  # 
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  # 
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:600;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #   ")),
  # 
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
  #     tags$p(class="road-sub",
  #            "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
  # 
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput(
  #         "roadmap_step", label = NULL,
  #         min = 0, max = 10, value = 0, step = 1, width = "520px"
  #       ),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
  #     ),
  # 
  #     # Progress bar (pure UI, updated via re-render of content)
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  # 
  # # =========================
  # # Roadmap UI (content)
  # # =========================
  # output$roadmap_step_content <- renderUI({
  # 
  #   # ========= Helpers =========
  #   D <- function(title, ...) {
  #     tags$details(
  #       tags$summary(title),
  #       tags$div(class = "road-scroll", ...)
  #     )
  #   }
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   P  <- function(...) tags$p(...)
  #   B  <- function(...) tags$b(...)
  #   C  <- function(...) tags$code(...)
  #   H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
  # 
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  # 
  #   # ========= CSS (internal scroll so the page stays short) =========
  #   css <- tags$style(HTML("
  #   .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #   details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #   details > summary {cursor:pointer;font-weight:700;}
  #   .road-scroll {max-height: 62vh; overflow-y: auto; padding-right: 10px;}
  #   .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #   .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #   .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #   code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #   .progress {height:10px; margin:10px 0 0 0;}
  # "))
  # 
  #   # ========= Step logic =========
  #   cur <- input$roadmap_step
  #   if (is.null(cur) || !is.finite(cur)) cur <- 0
  #   cur <- as.integer(cur)
  # 
  #   step_names <- c(
  #     "Aperçu & notations (glossaire + lecture du modèle)",
  #     "Étape 0 — Définir le problème de modélisation",
  #     "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
  #     "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
  #     "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
  #     "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
  #     "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
  #     "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
  #     "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
  #     "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
  #     "Annexes — Formules, checklists, templates, interprétations rapides"
  #   )
  # 
  #   pct <- round(100 * cur / 10)
  #   progress_ui <- tags$div(
  #     class="progress",
  #     tags$div(
  #       class="progress-bar",
  #       role="progressbar",
  #       `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #       style = paste0("width:", pct, "%;")
  #     )
  #   )
  # 
  #   make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
  #     tags$div(
  #       class = "road-card",
  #       if (!is.null(header_ui)) header_ui,
  #       tags$h4(title),
  #       D("1) Ce que l’étudiant fait (procédure + définitions + objectifs)", actions_ui),
  #       D("2) Ce qu’il écrit (APA) + conclusion & signification", apa_ui),
  #       D("3) Pièges + comment les éviter (avec interprétation)", pitfalls_ui)
  #     )
  #   }
  # 
  #   # ========= Pages =========
  #   pages <- vector("list", length = 11)
  # 
  #   # (0) Aperçu
  #   pages[[1]] <- make_step(
  #     step_names[1],
  # 
  #     actions_ui = tagList(
  #       callout(
  #         B("Objectif global : "),
  #         "construire un modèle SARIMA interprétable et surtout ",
  #         B("prédictif"), " : il doit passer les diagnostics résiduels et battre un benchmark simple.",
  #         type="ok"
  #       ),
  # 
  #       H5("Notations essentielles (définitions)"),
  #       UL(
  #         tags$li(B("Série temporelle"), " : suite ordonnée d’observations indexées par le temps ", C("y_t"), "."),
  #         tags$li(B("Fréquence / période saisonnière"), " : nombre de pas par cycle saisonnier, noté ", C("s"),
  #                 " (ex. mensuel s=12; quotidien avec saison hebdo s=7)."),
  #         tags$li(B("Opérateur de retard (backshift)"), " : ", C("B y_t = y_{t-1}"), "."),
  #         tags$li(B("Différenciation ordinaire"), " : ", C("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
  #                 " ; appliquée ", C("d"), " fois → supprimer tendance/racine unitaire non saisonnière."),
  #         tags$li(B("Différenciation saisonnière"), " : ", C("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
  #                 " ; appliquée ", C("D"), " fois → supprimer racine unitaire saisonnière."),
  #         tags$li(B("Innovations / bruit blanc"), " : ", C("ε_t ~ w.n.(0, σ²)"),
  #                 " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
  #       ),
  # 
  #       H5("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)"),
  #       UL(
  #         tags$li(
  #           "Écriture compacte : ",
  #           C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
  #         ),
  #         tags$li(
  #           B("Interprétation : "),
  #           "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
  #           "non saisonnières (p,q) et saisonnières (P,Q)."
  #         )
  #       ),
  # 
  #       H5("Ce que signifie “bon modèle” (définition opérationnelle)"),
  #       OL(
  #         tags$li(B("Résidus ~ bruit blanc"), " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."),
  #         tags$li(B("Performance out-of-sample"), " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."),
  #         tags$li(B("Parcimonie"), " : modèle le plus simple possible à performance comparable.")
  #       ),
  # 
  #       # === ADD: Glossaire étendu, critères info, estimation ===
  #       H5("Glossaire étendu (ajouts importants)"),
  #       UL(
  #         tags$li(B("Polynômes AR/MA"), " : ",
  #                 C("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), ", ",
  #                 C("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), "; saisonnier ",
  #                 C("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), ", ",
  #                 C("Θ(B^s) = 1 + Θ_1 B^s + ... + Θ_Q B^{Qs}"), "."),
  #         tags$li(B("Stabilité/causalité (AR)"), " : toutes les racines de ", C("φ(z)=0"),
  #                 " et ", C("Φ(z^s)=0"), " sont ", B("hors"), " du cercle unité → processus stationnaire."),
  #         tags$li(B("Inversibilité (MA)"), " : racines de ", C("θ(z)=0"), " et ", C("Θ(z^s)=0"),
  #                 " hors du cercle unité → représentation AR(∞) bien définie."),
  #         tags$li(B("Constante / drift"), " : une constante dans un ARIMA avec ", C("d=1"),
  #                 " implique une ", B("pente moyenne"), " (drift) après différenciation ; le terme est souvent noté ",
  #                 C("c"), " et la tendance moyenne vaut environ ", C("c"), " par pas."),
  #         tags$li(B("Représentation état–espace"), " : tout ARIMA/SARIMA peut être écrit sous forme état–espace ",
  #                 "et estimé/filtré par Kalman (utile pour manquants et lissage)."),
  #         tags$li(B("Prévision : point vs intervalle vs densité"),
  #                 " : point = ", C("ŷ"), "; intervalle = incertitude (80%/95%); densité = distribution prédictive complète.")
  #       ),
  #       H5("Critères d’information (définitions)"),
  #       UL(
  #         tags$li(B("AIC"), " : ", C("AIC = -2 \\log L + 2k"), " (", C("k"), " = nb paramètres estimés)."),
  #         tags$li(B("AICc"), " : correction petits échantillons → préférable si ", C("n/k"), " n’est pas grand."),
  #         tags$li(B("BIC"), " : ", C("BIC = -2 \\log L + k \\log n"), " ; pénalise plus la complexité (favorise parcimonie).")
  #       ),
  #       H5("Estimation (comment sont estimés les paramètres)"),
  #       UL(
  #         tags$li(B("MLE vs CSS+MLE"), " : estimation par maximum de vraisemblance (souvent via optim) ; ",
  #                 "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."),
  #         tags$li(B("Écarts-types et tests z"), " : reportez estimations ± SE, z et p pour l’interprétation des coefficients.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Phrase APA (modèle + notations)"),
  #       P("« Nous avons ajusté un modèle SARIMA afin de capturer la dépendance temporelle et la saisonnalité de la série ",
  #         C("y_t"), ". La spécification générale est ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
  #         " avec ", C("ε_t"), " un bruit blanc. Le choix de (d, D) a été justifié par des tests de stationnarité (ADF/KPSS/PP) et des diagnostics. »"),
  # 
  #       H5("Conclusion & signification (à expliciter)"),
  #       UL(
  #         tags$li(B("Conclusion type : "), "« Le modèle final est adéquat »"),
  #         tags$li(B("Signification : "), "« (i) il ne laisse pas d’information autocorrélée dans les résidus, ",
  #                 "(ii) il généralise bien sur une fenêtre future, ",
  #                 "(iii) il est suffisamment simple pour être stable et reproductible. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       H5("Pièges classiques"),
  #       UL(
  #         tags$li(B("Confondre AIC faible et bon modèle"), " : un AIC très bas avec résidus autocorrélés = modèle mal spécifié."),
  #         tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naïf, impossible de dire si SARIMA apporte réellement quelque chose."),
  #         tags$li(B("Surcharger le modèle"), " : trop de paramètres → instabilité, intervalles de prévision peu fiables.")
  #       )
  #     )
  #   )
  # 
  #   # (1) Étape 0 — Définition du problème
  #   pages[[2]] <- make_step(
  #     step_names[2],
  # 
  #     actions_ui = tagList(
  #       callout(
  #         B("But : "),
  #         "définir un problème de prévision mesurable (horizon, métriques, protocole).",
  #         type="info"
  #       ),
  # 
  #       H5("Définitions (ce que chaque terme veut dire)"),
  #       UL(
  #         tags$li(B("Série réponse"), " ", C("y_t"), " : variable à prédire (univariée)."),
  #         tags$li(B("Horizon"), " ", C("h"), " : nombre de pas à prévoir (ex. h=12 mois)."),
  #         tags$li(B("Origine de prévision"), " : dernier temps observé à partir duquel on prévoit."),
  #         tags$li(B("Protocole train/test"), " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."),
  #         tags$li(B("Rolling-origin / validation temporelle"), " : on répète des prévisions à différentes origines pour estimer la performance moyenne."),
  #         tags$li(B("SARIMA vs SARIMAX"), " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes.")
  #       ),
  # 
  #       H5("Choisir les métriques (définitions + quand utiliser)"),
  #       UL(
  #         tags$li(B("MAE"), " : moyenne des erreurs absolues ", C("mean(|y-ŷ|)"),
  #                 " → robuste, facile à interpréter (unité de y)."),
  #         tags$li(B("RMSE"), " : racine de l’erreur quadratique moyenne ", C("sqrt(mean((y-ŷ)^2))"),
  #                 " → pénalise plus les grosses erreurs."),
  #         tags$li(B("MAPE"), " : ", C("mean(|(y-ŷ)/y|)"),
  #                 " → éviter si y proche de 0 (explose)."),
  #         tags$li(B("sMAPE"), " : alternative plus stable près de 0 : ", C("mean(2|y-ŷ|/(|y|+|ŷ|))"), ".")
  #       ),
  # 
  #       H5("Transformation (définitions + justification)"),
  #       UL(
  #         tags$li(B("Niveaux"), " : modèle sur les valeurs brutes."),
  #         tags$li(B("Log-niveaux"), " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."),
  #         tags$li(B("Box–Cox"), " : transformation paramétrique (λ) pour stabiliser variance et améliorer normalité : ",
  #                 C("y^(λ) = (y^λ - 1)/λ"), " (λ≠0), et log si λ=0.")
  #       ),
  # 
  #       H5("Procédure minimale (checklist)"),
  #       OL(
  #         tags$li("Fixer fréquence et période saisonnière s."),
  #         tags$li("Fixer horizon h et fenêtres train/test (ou rolling-origin)."),
  #         tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
  #         tags$li("Décider transformation (aucune/log/Box–Cox) et justifier.")
  #       ),
  # 
  #       # === ADD: précisions pratiques, métriques complémentaires, transformations ===
  #       H5("Précisions supplémentaires (définitions pratiques)"),
  #       UL(
  #         tags$li(B("Horizon multi-pas"), " : ", C("h>1"),
  #                 " → la performance peut décroître avec l’horizon ; rapporter MAE/RMSE par h si possible."),
  #         tags$li(B("Fenêtre d’entraînement"), " : ", B("expansive"), " (on ne jette jamais d’anciens points) ",
  #                 "ou ", B("glissante"), " (fenêtre fixe) ; documenter le choix."),
  #         tags$li(B("Reproductibilité"), " : fixer les graines aléatoires, consigner versions des packages, chemins de données."),
  #         tags$li(B("Prévision hiérarchique"), " (annexe) : si agrégations (mois→trimestres), noter la cohérence temporelle.")
  #       ),
  #       H5("Métriques supplémentaires (quand utiles)"),
  #       UL(
  #         tags$li(B("MASE"), " : erreur absolue mise à l’échelle par le naïf saisonnier → comparable entre séries."),
  #         tags$li(B("WAPE"), " : ", C("sum(|y-ŷ|)/sum(|y|)"), " ; lisible comme % d’erreur agrégée."),
  #         tags$li(B("Pinball loss (quantiles)"), " : si vous prédisez des quantiles (IC asymétriques).")
  #       ),
  #       H5("Transformations complémentaires"),
  #       UL(
  #         tags$li(B("Yeo–Johnson"), " : alternative à Box–Cox qui gère les valeurs ≤ 0."),
  #         tags$li(B("Stabilisation de variance"), " : vérifier relation niveau–variance (nuage points moyenne locale vs ET).")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — modèle de phrase complet"),
  #       P("« Nous avons modélisé la série temporelle univariée ", C("y_t"),
  #         " observée à une fréquence [..] (période saisonnière s=[..]). ",
  #         "L’objectif était de produire des prévisions à horizon ", C("h"), "=[..]. ",
  #         "La performance a été évaluée sur une fenêtre future selon [split temporel / rolling-origin] ",
  #         "à l’aide de [MAE, RMSE]. Une transformation [aucune / log / Box–Cox] a été appliquée afin de [stabiliser la variance / linéariser la saisonnalité]. »"),
  # 
  #       H5("Conclusion & signification (comment l’expliquer)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Notre problème est bien défini (h, métriques, protocole). »"),
  #         tags$li(B("Signification : "), "« Toute comparaison de modèles devient juste : même horizon, même protocole, mêmes métriques. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) → performance artificiellement élevée."),
  #         tags$li(B("Métrique mal choisie"), " : MAPE avec y≈0 → conclusions fausses."),
  #         tags$li(B("Horizon incohérent"), " : un modèle bon à h=1 peut être mauvais à h=12 ; fixer l’horizon selon l’usage réel.")
  #       )
  #     )
  #   )
  # 
  #   # (2) Étape 1 — Description des données
  #   pages[[3]] <- make_step(
  #     step_names[3],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "décrire la qualité des données et rendre le pipeline reproductible.", type="info"),
  # 
  #       H5("Ce qu’il faut rapporter (définitions)"),
  #       UL(
  #         tags$li(B("n"), " : nombre total d’observations disponibles."),
  #         tags$li(B("Couverture"), " : date début/fin."),
  #         tags$li(B("Fréquence"), " : périodicité (mensuel/hebdo/quotidien)."),
  #         tags$li(B("Manquants"), " : nombre k et pourcentage k/n.")
  #       ),
  # 
  #       H5("Valeurs manquantes : types + implications"),
  #       UL(
  #         tags$li(B("MCAR"), " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."),
  #         tags$li(B("MAR"), " (At Random conditionnel) : dépend d’autres infos → imputation possible mais à justifier."),
  #         tags$li(B("MNAR"), " (Not At Random) : dépend de la valeur elle-même → risque de biais important.")
  #       ),
  # 
  #       H5("Stratégies de traitement (quand et pourquoi)"),
  #       UL(
  #         tags$li(B("Interpolation linéaire"), " : si manquants rares et pas de ruptures."),
  #         tags$li(B("Interpolation saisonnière"), " : si saisonnalité stable (ex. remplacer par moyenne du même mois)."),
  #         tags$li(B("Modèle d’état / Kalman"), " : si on veut une imputation plus probabiliste."),
  #         tags$li(B("Suppression"), " : seulement si extrêmement rare et sans impact sur la continuité.")
  #       ),
  # 
  #       H5("Descriptifs pertinents (au-delà de la moyenne)"),
  #       UL(
  #         tags$li("Moyenne, médiane, ET, min/max (niveau)."),
  #         tags$li("Asymétrie (skewness) / kurtosis si utile."),
  #         tags$li("Résumé saisonnier (ex. moyenne par mois), pour documenter saisonnalité.")
  #       ),
  # 
  #       # === ADD: qualité index & manquants pratiques ===
  #       H5("Qualité de l’index temporel (définitions)"),
  #       UL(
  #         tags$li(B("Régularité"), " : pas de pas manqué/dupliqué ; cadence constante."),
  #         tags$li(B("Fuseau/DST"), " : données horaires → attention aux heures manquantes/dupliquées (passage DST)."),
  #         tags$li(B("Doublons et horodatages hors ordre"), " : à corriger avant tout calcul d’ACF.")
  #       ),
  #       H5("Manquants — remarques pratiques"),
  #       UL(
  #         tags$li(B("Kalman/StructTS"), " : imputation probabiliste cohérente avec la dynamique ARIMA."),
  #         tags$li(B("Imputation “saison identique”"), " : moyenne/médiane du même mois/jour si saisonnalité stable."),
  #         tags$li(B("Zéros structurels"), " : distinguer “zéro” réel de manquant imputé à 0 (documenter).")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — description"),
  #       P("« La série contient ", C("n"), "=[..] observations couvrant [..] à [..] à une fréquence [..]. ",
  #         "Les valeurs manquantes représentaient [..]% (k=[..]) et ont été traitées par [..], ",
  #         "choisie car [manquants rares / saisonnalité stable / continuité nécessaire]. ",
  #         "La série présentait une moyenne de [..] (ET=[..]) et une médiane [..]. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Les données sont suffisamment propres pour SARIMA » (ou non)."),
  #         tags$li(B("Signification : "),
  #                 "si l’index est régulier et que les manquants sont gérés explicitement, ",
  #                 "les hypothèses du modèle (espacement régulier) deviennent plausibles.")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Imputation silencieuse"), " : toujours documenter méthode + raison."),
  #         tags$li(B("Timestamps irréguliers"), " : SARIMA suppose une grille régulière ; corriger avant toute estimation."),
  #         tags$li(B("Changement de définition de la variable"), " : ex. changement de mesure → rupture structurelle à traiter.")
  #       )
  #     )
  #   )
  # 
  #   # (3) Étape 2 — EDA
  #   pages[[4]] <- make_step(
  #     step_names[4],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant d’ajuster SARIMA.", type="info"),
  # 
  #       H5("Définitions utiles (ce qu’on cherche)"),
  #       UL(
  #         tags$li(B("Tendance"), " : évolution de long terme (déterministe ou stochastique)."),
  #         tags$li(B("Saisonnalité"), " : motif périodique de période s (ex. 12)."),
  #         tags$li(B("Rupture structurelle"), " : changement durable de niveau/tendance/variance (ex. politique, crise)."),
  #         tags$li(B("Outlier"), " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou erreur.")
  #       ),
  # 
  #       H5("Graphiques recommandés + leur but"),
  #       UL(
  #         tags$li(B("Courbe y_t"), " : voir tendance, variance, ruptures."),
  #         tags$li(B("Seasonal plot"), " : comparer la forme saisonnière d’une année à l’autre."),
  #         tags$li(B("Boxplots par saison"), " : détecter asymétrie/outliers par mois/semaine."),
  #         tags$li(B("ACF brute"), " (optionnel) : repérer dépendances fortes et saisonnalité.")
  #       ),
  # 
  #       H5("Outliers : procédure raisonnable"),
  #       OL(
  #         tags$li("Repérer visuellement (dates)."),
  #         tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
  #         tags$li("Décider : conserver / corriger / imputer (et justifier)."),
  #         tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
  #       ),
  # 
  #       # === ADD: outils EDA supplémentaires & typologie outliers ===
  #       H5("Outils EDA supplémentaires"),
  #       UL(
  #         tags$li(B("Périodogramme / spectre"), " : met en évidence des fréquences saisonnières inattendues."),
  #         tags$li(B("Seasonal subseries plot"), " : visualise la forme saisonnière par mois/semaine."),
  #         tags$li(B("Nuage niveau–variance"), " : aide au choix log/Box–Cox (variance croît avec le niveau ?).")
  #       ),
  #       H5("Types d’outliers (interventions)"),
  #       UL(
  #         tags$li(B("AO"), " : Additive Outlier (pic ponctuel)."),
  #         tags$li(B("IO"), " : Innovation Outlier (choc qui diffuse)."),
  #         tags$li(B("LS"), " : Level Shift (changement de niveau)."),
  #         tags$li(B("TC"), " : Temporary Change (effet transitoire).")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — EDA"),
  #       P("« L’inspection visuelle a mis en évidence une tendance [..] et une saisonnalité récurrente de période s=[..]. ",
  #         "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Box–Cox]. ",
  #         "Des valeurs atypiques autour de [dates] ont été [conservées/traitées] car [événement réel / erreur probable]. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« La structure (tendance/saison/variance/outliers) est comprise »"),
  #         tags$li(B("Signification : "),
  #                 "cela guide directement le choix transformation + différenciations (d, D) et évite d’ajuster un SARIMA “à l’aveugle”.")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Confondre saisonnalité et tendance"), " : une moyenne croissante ET une saisonnalité stable sont deux composantes distinctes."),
  #         tags$li(B("Retirer des points réels"), " : si l’outlier correspond à un événement récurrent (fêtes), il doit rester."),
  #         tags$li(B("Ignorer une rupture"), " : un SARIMA “moyenne” une structure qui a changé → mauvais futur.")
  #       )
  #     )
  #   )
  # 
  #   # (4) Étape 3 — Décomposition
  #   pages[[5]] <- make_step(
  #     step_names[5],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "séparer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
  # 
  #       H5("Décomposition : définitions"),
  #       UL(
  #         tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
  #                 " (amplitude saisonnière ~ constante)."),
  #         tags$li(B("Multiplicative"), " : ", C("y_t = T_t × S_t × e_t"),
  #                 " (amplitude saisonnière augmente avec le niveau)."),
  #         tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
  #                 C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
  #         tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
  #       ),
  # 
  #       H5("Pourquoi STL ? (objectif détaillé)"),
  #       UL(
  #         tags$li("Quand la saisonnalité change lentement au fil du temps (non parfaitement répétitive)."),
  #         tags$li("Quand on veut réduire l’influence des outliers sur l’estimation saison/tendance."),
  #         tags$li("Quand on veut une lecture pédagogique claire (tendance vs saison vs résidu).")
  #       ),
  # 
  #       H5("Ce que la décomposition ne remplace pas"),
  #       UL(
  #         tags$li("Elle ne prouve pas la stationnarité : SARIMA exige une série stationnaire après différenciation."),
  #         tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nécessaires.")
  #       ),
  # 
  #       # === ADD: paramètres STL & règles pratiques ===
  #       H5("Paramètres STL (lecture pédagogique)"),
  #       UL(
  #         tags$li(B("s.window"), " : lissage saisonnier (", C("periodic"), " = saison constante; entier = évolutive)."),
  #         tags$li(B("t.window"), " : lissage de la tendance (fenêtre LOESS)."),
  #         tags$li(B("robust"), " : réduit l’influence des outliers (itérations avec poids).")
  #       ),
  #       H5("Additif vs multiplicatif (règle pratique)"),
  #       UL(
  #         tags$li("Amplitude saisonnière ~ proportionnelle au niveau → penser ", B("log"), " ou modèle multiplicatif."),
  #         tags$li("Amplitude ~ constante → additif sur niveaux.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Décomposition"),
  #       P("« Nous avons étudié une structure additive vs multiplicative en évaluant si l’amplitude saisonnière variait avec le niveau. ",
  #         "Comme [..], nous avons retenu [modèle additif / transformation log] et réalisé une décomposition via [classique / STL]. ",
  #         "STL a été privilégiée pour sa flexibilité (saisonnalité évolutive) et sa robustesse aux valeurs atypiques. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le choix additif/multiplicatif est justifié »"),
  #         tags$li(B("Signification : "),
  #                 "on évite des résidus hétéroscédastiques et on améliore la stabilité de l’estimation SARIMA.")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Décomposition ≠ stationnarité"), " : après décomposition, on doit encore tester/choisir d et D."),
  #         tags$li(B("Oublier l’échelle"), " : si vous modélisez log(y), les prévisions doivent être reconverties (avec prudence)."),
  #         tags$li(B("Confondre bruit et structure"), " : des motifs résiduels persistants suggèrent que la saison/tendance n’a pas été correctement capturée.")
  #       )
  #     )
  #   )
  # 
  #   # (5) Étape 4 — Stationnarité (très détaillé : ADF/KPSS/PP + …)
  #   pages[[6]] <- make_step(
  #     step_names[6],
  # 
  #     actions_ui = tagList(
  #       callout(
  #         B("Idée centrale : "),
  #         "SARIMA suppose que la série devient (au moins) stationnaire ",
  #         B("après différenciation"), ". Les tests ADF/PP/KPSS servent à justifier (d, D).",
  #         type="ok"
  #       ),
  # 
  #       H5("Définition : stationnarité (ce que cela veut dire)"),
  #       UL(
  #         tags$li(B("Stationnarité faible (covariance-stationnaire)"), " : moyenne constante, variance constante, ",
  #                 "et autocovariance dépend uniquement du retard (pas de t)."),
  #         tags$li(B("Non-stationnarité"), " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."),
  #         tags$li(B("Racine unitaire"), " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1).")
  #       ),
  # 
  #       H5("Différenciation : rôle (d vs D)"),
  #       UL(
  #         tags$li(B("d"), " enlève la racine unitaire non saisonnière / tendance stochastique : ", C("(1-B)^d"), "."),
  #         tags$li(B("D"), " enlève la racine unitaire saisonnière : ", C("(1-B^s)^D"), "."),
  #         tags$li(B("Règle pratique"), " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2).")
  #       ),
  # 
  #       H5("Test ADF (Augmented Dickey–Fuller) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."),
  #         tags$li(B("Régression (intuition)"), " : on teste si le coefficient de ", C("y_{t-1}"),
  #                 " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire (non-stationnaire) ; ",
  #                 B("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."),
  #         tags$li(B("Interprétation p-value"), " : p petit → rejet H0 → stationnarité (au sens ADF). p grand → on ne rejette pas → différenciation probablement nécessaire.")
  #       ),
  # 
  #       H5("Test KPSS — définition & objectif (inverse de l’ADF)"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série est stationnaire (niveau ou tendance)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = stationnaire ; ",
  #                 B("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."),
  #         tags$li(B("Interprétation"), " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité.")
  #       ),
  # 
  #       H5("Test PP (Phillips–Perron) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement (correction non-paramétrique)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire ; ",
  #                 B("Ha"), " = stationnaire."),
  #         tags$li(B("Pourquoi utile"), " : complément de robustesse ; si ADF et PP convergent, confiance accrue.")
  #       ),
  # 
  #       H5("Comment conclure en combinant ADF/KPSS/PP (logique complète)"),
  #       OL(
  #         tags$li(B("Stationnarité forte : "), "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."),
  #         tags$li(B("Non-stationnarité forte : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
  #         tags$li(B("Conflit : "), "les tests divergent → regarder graphiques, ACF, résultats après une différence, et justifier par convergence d’indices (pas une seule p-value).")
  #       ),
  # 
  #       H5("Procédure recommandée (pas à pas)"),
  #       OL(
  #         tags$li("Fixer ", B("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
  #         tags$li("Tester ADF/KPSS/PP sur la série brute."),
  #         tags$li("Essayer d=1 si nécessaire, retester."),
  #         tags$li("Essayer D=1 si saisonnalité/racine saisonnière, retester."),
  #         tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
  #       ),
  # 
  #       H5("Sur-différenciation : définition + symptômes"),
  #       UL(
  #         tags$li(B("Définition"), " : appliquer trop de différences → on introduit une dynamique artificielle."),
  #         tags$li(B("Symptômes fréquents"), " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."),
  #         tags$li(B("Conséquence"), " : intervalles de prévision plus larges et modèle moins fiable.")
  #       ),
  # 
  #       # === ADD: tests/bonnes pratiques complémentaires ===
  #       H5("Tests et notions complémentaires"),
  #       UL(
  #         tags$li(B("Tendance déterministe vs racine unitaire"),
  #                 " : on peut préférer un ARIMA avec ", C("d=0"), " et une tendance ", B("déterministe"),
  #                 " (régression + ARMA sur résidus) si la tendance semble stable."),
  #         tags$li(B("Racine unitaire saisonnière (HEGY)"), " : (annexe) test dédié aux racines à ", C("±1, ±i"), " pour ",
  #                 C("s=4,12"), " ; utile si la saisonnalité stochastique domine."),
  #         tags$li(B("Zivot–Andrews"), " : (annexe) racine unitaire avec rupture endogène possible.")
  #       ),
  #       H5("Bonnes pratiques de différenciation"),
  #       UL(
  #         tags$li(B("Au plus une différence"), " : commencer par ", C("d=1"), " ou ", C("D=1"),
  #                 " ; ", B("éviter"), " ", C("d=2"), " sauf preuves fortes."),
  #         tags$li(B("Sur-différenciation : "), "ACF lag 1 très négative, variance gonflée, MA artificiel → revenir en arrière.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Tests & choix de (d, D)"),
  #       P("« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
  #         "Les résultats ont été examinés sur la série originale puis après différenciations ordinaires et saisonnières. ",
  #         "Sur la base de l’ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
  #         "afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA, tout en évitant la sur-différenciation. »"),
  # 
  #       H5("Conclusion test (prête à remplir) + signification"),
  #       UL(
  #         tags$li(B("ADF : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "si rejet → la série est compatible stationnarité (au sens ADF) ; sinon → différenciation probablement nécessaire."),
  #         tags$li(B("KPSS : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (stationnarité). ",
  #                 B("Signification : "),
  #                 "si rejet → non-stationnarité (donc d/D à augmenter ou transformation/rupture à traiter)."),
  #         tags$li(B("PP : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
  #       ),
  # 
  #       H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Nous retenons d=[..], D=[..], s=[..]. »"),
  #         tags$li(B("Signification : "),
  #                 "« le SARIMA sera estimé sur la série différenciée ; les paramètres AR/MA décrivent la dynamique ",
  #                 "restante après retrait de la tendance et/ou de la saisonnalité non stationnaire. »")
  #       ),
  # 
  #       # === ADD: points à expliciter
  #       H5("À expliciter (rappel)"),
  #       UL(
  #         tags$li("Préciser si une constante/drift est incluse et à quel niveau (avant/après différenciation)."),
  #         tags$li("Documenter toute rupture suspectée et ses conséquences sur le choix de ", C("d, D"), ".")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Choisir d et D “par habitude”"), " : toujours justifier par tests + EDA."),
  #         tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent “crier non-stationnaire” alors qu’un changement de régime est en cause."),
  #         tags$li(B("Interpréter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on s’appuie sur convergence des preuves.")
  #       )
  #     )
  #   )
  # 
  #   # (6) Étape 5 — Auto-ARIMA baseline
  #   pages[[7]] <- make_step(
  #     step_names[7],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "obtenir un point de départ compétitif, puis vérifier/affiner.", type="info"),
  # 
  #       H5("Définition : auto-ARIMA (ce que fait réellement l’algorithme)"),
  #       UL(
  #         tags$li("Explore un ensemble de modèles candidats (p,q,P,Q) sous contraintes."),
  #         tags$li("Choisit souvent via minimisation ", B("AICc"),
  #                 " (AIC corrigé petits échantillons)."),
  #         tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coûteuse).")
  #       ),
  # 
  #       H5("Pourquoi AICc ? (objectif)"),
  #       UL(
  #         tags$li("Compromis entre qualité d’ajustement et complexité (pénalise les paramètres)."),
  #         tags$li("AICc est préférable à AIC quand n n’est pas très grand par rapport au nombre de paramètres.")
  #       ),
  # 
  #       H5("Procédure propre"),
  #       OL(
  #         tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
  #         tags$li("Fixer bornes max p/q/P/Q ; documenter."),
  #         tags$li("Sauvegarder le modèle baseline (pour comparaison)."),
  #         tags$li("Vérifier diagnostics résiduels + performance sur test.")
  #       ),
  # 
  #       # === ADD: détails de recherche & critères multiples ===
  #       H5("Détails de recherche"),
  #       UL(
  #         tags$li(B("Stepwise vs exhaustive"), " : stepwise = rapide, peut rater un optimum global ; exhaustive = coûteux mais plus fiable."),
  #         tags$li(B("Contraintes"), " : imposer ", C("p,q,P,Q \u2264"), " bornes raisonnables ; forcer stabilité/inversibilité."),
  #         tags$li(B("drift/constante"), " : tester versions avec et sans drift lorsque ", C("d=1"), ".")
  #       ),
  #       H5("Critères multiples"),
  #       UL(
  #         tags$li("Comparer AICc ", B("et"), " BIC ; en cas de quasi-égalité → choisir le plus parcimonieux.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — baseline"),
  #       P("« Un modèle SARIMA de référence a été sélectionné via une procédure auto-ARIMA basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats sous contraintes [..]. ",
  #         "La spécification obtenue a été utilisée comme baseline, puis comparée à des modèles manuels plus parcimonieux sur la base des diagnostics et de la performance de prévision. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Auto-ARIMA fournit une baseline solide »"),
  #         tags$li(B("Signification : "), "« on a un repère : tout modèle final doit faire au moins aussi bien. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Modèle “trop complexe”"), " : stepwise peut sélectionner des ordres élevés → instabilité, interprétation difficile."),
  #         tags$li(B("AICc excellent mais résidus mauvais"), " : diagnostics priment."),
  #         tags$li(B("Oublier la parcimonie"), " : si deux modèles prédisent pareil, garder le plus simple.")
  #       )
  #     )
  #   )
  # 
  #   # (7) Étape 6 — SARIMA manuel
  #   pages[[8]] <- make_step(
  #     step_names[8],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "proposer un petit ensemble raisonné de candidats via ACF/PACF.", type="info"),
  # 
  #       H5("Définitions : ACF / PACF (ce que mesurent ces courbes)"),
  #       UL(
  #         tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"),
  #                 " → suggère MA(q) si coupure nette vers q."),
  #         tags$li(B("PACF"), " : corrélation “pure” au retard k une fois les retards <k contrôlés ",
  #                 "→ suggère AR(p) si coupure nette vers p.")
  #       ),
  # 
  #       H5("Heuristiques (non saisonnier)"),
  #       UL(
  #         tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF décroît."),
  #         tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF décroît."),
  #         tags$li(B("ARMA"), " : ACF et PACF décroissent (pas de coupure franche).")
  #       ),
  # 
  #       H5("Heuristiques saisonnières (multiples de s)"),
  #       UL(
  #         tags$li(B("SAR(P)"), " : pics PACF à s, 2s, ..."),
  #         tags$li(B("SMA(Q)"), " : pics ACF à s, 2s, ...")
  #       ),
  # 
  #       H5("Procédure recommandée (petit nombre de modèles)"),
  #       OL(
  #         tags$li("Construire 3 à 8 candidats (parcimonieux)."),
  #         tags$li("Ajuster et comparer AICc/BIC."),
  #         tags$li("Vérifier stabilité/inversibilité."),
  #         tags$li("Retenir ceux qui passent diagnostics + prévision.")
  #       ),
  # 
  #       # === ADD: conception de candidats & lecture fine ===
  #       H5("Conception de candidats (rappels utiles)"),
  #       UL(
  #         tags$li(B("Limiter le set"), " : 3–8 modèles max, justifiés par ACF/PACF."),
  #         tags$li(B("Stabilité/inversibilité"), " : vérifier racines des polynômes AR/MA (hors cercle unité)."),
  #         tags$li(B("drift/constante"), " : inclure/exclure et comparer au niveau AICc/BIC + diagnostics.")
  #       ),
  #       H5("Lecture fine ACF/PACF"),
  #       UL(
  #         tags$li("Pics à ", C("s, 2s, 3s"), " dans l’ACF → penser ", B("SMA(Q)"), "."),
  #         tags$li("Pics à ", C("s, 2s"), " dans la PACF → penser ", B("SAR(P)"), "."),
  #         tags$li("Queue AR (décroissance géométrique) vs coupure MA (après q).")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — sélection manuelle"),
  #       P("« Les structures candidates ont été proposées sur la base des schémas ACF/PACF de la série différenciée. ",
  #         "Des autocorrélations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
  #         "Un ensemble restreint de modèles (n=[..]) a été ajusté et comparé via AICc/BIC et diagnostics résiduels, en privilégiant la parcimonie. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle final est soutenu par la structure ACF/PACF et les diagnostics. »"),
  #         tags$li(B("Signification : "), "« on réduit le risque de sur-ajustement en limitant les candidats. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Brute-force massif"), " : tester 200 modèles puis choisir le plus petit AICc = data snooping."),
  #         tags$li(B("Surinterpréter ACF/PACF"), " : ce sont des guides, pas des preuves."),
  #         tags$li(B("Ignorer l’inversibilité/stabilité"), " : paramètres instables → prévisions incohérentes.")
  #       )
  #     )
  #   )
  # 
  #   # (8) Étape 7 — Diagnostics & comparaison
  #   pages[[9]] <- make_step(
  #     step_names[9],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "valider que le modèle explique toute la dépendance et prédit bien.", type="ok"),
  # 
  #       H5("Diagnostics résiduels : définitions & buts"),
  #       UL(
  #         tags$li(B("Résidus"), " : ", C("e_t = y_t - ŷ_t"),
  #                 " (ou résidus d’innovation selon l’implémentation)."),
  #         tags$li(B("Bruit blanc"), " : absence d’autocorrélation résiduelle → le modèle a capturé la structure temporelle."),
  #         tags$li(B("Ljung–Box"), " : test global d’autocorrélation des résidus jusqu’à un lag L.")
  #       ),
  # 
  #       H5("Test de Ljung–Box (définition + interprétation)"),
  #       UL(
  #         tags$li(B("But"), " : tester si les autocorrélations résiduelles jusqu’à L sont globalement nulles."),
  #         tags$li(B("Hypothèses"), " : ", B("H0"), " = pas d’autocorrélation résiduelle ; ", B("Ha"), " = autocorrélation résiduelle présente."),
  #         tags$li(B("Conclusion"), " : p petit → rejet H0 → modèle incomplet (ajuster p/q/P/Q ou d/D)."),
  #         tags$li(B("Signification pratique"), " : si autocorrélation résiduelle reste, vos intervalles/prévisions sont souvent trop optimistes.")
  #       ),
  # 
  #       H5("Normalité & hétéroscédasticité (à quoi ça sert vraiment)"),
  #       UL(
  #         tags$li(B("Normalité"), " : utile pour l’interprétation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
  #         tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimés ; si fort, envisager modèles de variance (GARCH) selon le cours.")
  #       ),
  # 
  #       H5("Évaluation prévision (définition + protocole)"),
  #       UL(
  #         tags$li(B("Split temporel"), " : entraîner sur le passé, tester sur le futur."),
  #         tags$li(B("Rolling-origin"), " : répéter sur plusieurs origines → estimation plus robuste."),
  #         tags$li(B("Benchmark"), " : naїf / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE à l’horizon cible.")
  #       ),
  # 
  #       # === ADD: diagnostics additionnels & comparaison ===
  #       H5("Diagnostics additionnels"),
  #       UL(
  #         tags$li(B("Box–Pierce vs Ljung–Box"), " : préférer Ljung–Box (meilleure petite taille)."),
  #         tags$li(B("Normalité résiduelle"), " : Q–Q plot, Jarque–Bera ; utile pour IC mais secondaire si but = point forecast."),
  #         tags$li(B("Hétéroscédasticité / ARCH"), " : tester ACF des résidus au carré ; si fort → discuter modèles de variance (annexe)."),
  #         tags$li(B("Significativité des coefficients"), " : rapporter est., SE, z, p ; supprimer termes non significatifs si performance constante.")
  #       ),
  #       H5("Comparaison de modèles"),
  #       UL(
  #         tags$li(B("Tableau récapitulatif"), " : AICc/BIC, Ljung–Box (p), MAE/RMSE/MASE, nb de paramètres."),
  #         tags$li(B("Test de Diebold–Mariano"), " : (annexe) comparer formellement 2 séries d’erreurs prédictives.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — diagnostics"),
  #       P("« Les diagnostics résiduels indiquaient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics substantiels et le test de Ljung–Box était [non significatif/significatif] au seuil α=[..]. ",
  #         "La performance de prévision sur la fenêtre d’évaluation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. »"),
  # 
  #       H5("Conclusion & signification (diagnostics + performance)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle est acceptable » si Ljung–Box non significatif ET benchmark battu."),
  #         tags$li(B("Signification : "),
  #                 "« le modèle capte la structure temporelle (résidus ~ bruit) et apporte un gain prédictif réel (out-of-sample). »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Bon AIC mais Ljung–Box significatif"), " : modèle incomplet → ne pas valider."),
  #         tags$li(B("Se focaliser sur la normalité"), " : priorité = absence d’autocorrélation résiduelle."),
  #         tags$li(B("Comparer des modèles sur des horizons différents"), " : toujours même h, même protocole.")
  #       )
  #     )
  #   )
  # 
  #   # (9) Étape 8 — Rédaction
  #   pages[[10]] <- make_step(
  #     step_names[10],
  # 
  #     actions_ui = tagList(
  #       callout(B("But : "), "écrire un rapport clair, reproductible, aligné aux étapes 0–7.", type="info"),
  # 
  #       H5("Structure APA recommandée (définition)"),
  #       UL(
  #         tags$li(B("Méthodes"), " : ce que vous avez fait et pourquoi (données → EDA → stationnarité → modèles → évaluation)."),
  #         tags$li(B("Résultats"), " : ce que vous avez observé (stats, figures, tests, métriques, modèle final)."),
  #         tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
  #       ),
  # 
  #       H5("Pack livrable propre (checklist)"),
  #       UL(
  #         tags$li("Notebook/script reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
  #         tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC."),
  #         tags$li("Tableau : candidats vs AICc/BIC vs Ljung–Box vs MAE/RMSE vs benchmark.")
  #       ),
  # 
  #       # === ADD: rapporter correctement les prévisions ===
  #       H5("Rapporter correctement les prévisions"),
  #       UL(
  #         tags$li(B("Niveau de couverture"), " : préciser 80% et/ou 95% ; indiquer si log-échelle a été reconvertie."),
  #         tags$li(B("Biais de reconversion (log→niveau)"), " : mentionner correction ",
  #                 C("exp(\\hat{y}) \\times exp(\\hat{\\sigma}^2/2)"), " si utilisée."),
  #         tags$li(B("Reproductibilité"), " : versions R/packages, seed, chemin des données, date d’extraction.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Phrase finale (APA) — modèle final + interprétation"),
  #       P("« Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). ",
  #         "Les résidus étant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a été capturée. ",
  #         "Les prévisions produites à horizon h=[..] améliorent le benchmark [..] selon MAE/RMSE, ce qui soutient l’usage du modèle pour l’application ciblée. »"),
  # 
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le rapport est aligné, justifié, reproductible. »"),
  #         tags$li(B("Signification : "),
  #                 "« un lecteur externe peut reproduire vos résultats et comprendre chaque choix (transformation, d/D, sélection, diagnostics). »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Ne pas relier choix → preuves"), " : chaque décision doit être liée à EDA/tests/diagnostics."),
  #         tags$li(B("Trop de texte, pas assez de figures"), " : en séries temporelles, les figures sont des résultats."),
  #         tags$li(B("Oublier de préciser l’échelle"), " : niveau vs log vs Box–Cox et reconversion des prévisions.")
  #       )
  #     )
  #   )
  # 
  #   # (10) Annexes
  #   pages[[11]] <- make_step(
  #     step_names[11],
  # 
  #     actions_ui = tagList(
  #       H5("Benchmarks (définitions)"),
  #       UL(
  #         tags$li(B("Naïf"), " : ", C("ŷ_{t+1|t} = y_t"), " (persistance)."),
  #         tags$li(B("Drift"), " : extrapolation linéaire moyenne."),
  #         tags$li(B("SNAIVE"), " : répète la dernière valeur de la même saison : ", C("ŷ_{t+h|t} = y_{t+h-s}"), ".")
  #       ),
  # 
  #       H5("Règles d’interprétation ultra rapides"),
  #       UL(
  #         tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " → stationnarité plausible."),
  #         tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " → différenciation nécessaire."),
  #         tags$li(B("Ljung–Box significatif"), " → il reste de la structure → réviser le modèle.")
  #       ),
  # 
  #       # === ADD: formules utiles & pistes avancées ===
  #       H5("Formules utiles (mémo)"),
  #       UL(
  #         tags$li(B("Critères d’info"), " : ",
  #                 C("AIC=-2\\log L+2k"), ", ",
  #                 C("AICc= AIC + \\frac{2k(k+1)}{n-k-1}"), ", ",
  #                 C("BIC=-2\\log L+k\\log n"), "."),
  #         tags$li(B("MASE"), " : ", C("\\frac{\\frac{1}{T}\\sum_{t}|e_t|}{\\frac{1}{T-s}\\sum_{t}|y_t-y_{t-s}|}"), " (pour périodicité ", C("s"), ")."),
  #         tags$li(B("Ljung–Box"), " : ", C("Q^* = n(n+2)\\sum_{k=1}^{L} \\frac{\\hat{\\rho}_k^2}{n-k}"),
  #                 " ~ ", C("\\chi^2"), " sous ", C("H_0"), " avec ddl ≈ ", C("L - p - q - (P+Q)"), "."),
  #         tags$li(B("Backshift & diff."), " : ",
  #                 C("\\nabla=(1-B)"), ", ", C("\\nabla_s=(1-B^s)"), ", ",
  #                 C("\\nabla^d \\nabla_s^D y_t"), " pour stationnariser.")
  #       ),
  #       H5("Pistes avancées (pour l’enseignant)"),
  #       UL(
  #         tags$li(B("SARIMAX / régression dynamique"), " : variables exogènes, pré-blanchiment, fonctions de transfert."),
  #         tags$li(B("Ruptures/Interventions"), " : dummies LS/TC, estimation avec régresseurs."),
  #         tags$li(B("Multiples saisonnalités"), " : TBATS/ETS-MS si présence de s multiples.")
  #       )
  #     ),
  # 
  #     apa_ui = tagList(
  #       H5("Template “Conclusion tests → choix (d,D)” (copier-coller)"),
  #       P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
  #         "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnarité, ",
  #         "nous concluons que la série est [stationnaire/non-stationnaire] au sens des diagnostics combinés. ",
  #         "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une série stationnaire pour l’estimation SARIMA. »"),
  # 
  #       H5("Signification (traduction simple)"),
  #       UL(
  #         tags$li("« d et D disent combien de fois on doit “retirer” une tendance et une saisonnalité non stationnaire. »"),
  #         tags$li("« Ensuite, p/q/P/Q décrivent la dépendance restante (mémoire) dans la série transformée. »")
  #       )
  #     ),
  # 
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Croire qu’un test “décide” seul"), " : toujours trianguler avec EDA + ACF + comportement après différenciation."),
  #         tags$li(B("Oublier la finalité"), " : prévision (out-of-sample) + diagnostics passent avant l’esthétique d’un AIC."),
  #         tags$li(B("Ne pas documenter"), " : un bon modèle non documenté = inutilisable dans un cours/rapport.")
  #       )
  #     )
  #   )
  # 
  #   # ========= Output =========
  #   tagList(
  #     css,
  #     tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
  #     progress_ui,
  #     pages[[cur + 1L]]
  #   )
  # })

  
  
  
  
  
  
  
  
  # # --- Roadmap slider navigation (Prev/Next) ---
  # observeEvent(input$road_prev, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  # }, ignoreInit = TRUE)
  # 
  # observeEvent(input$road_next, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  # }, ignoreInit = TRUE)
  # 
  # # =========================
  # # Roadmap UI (controls)
  # # =========================
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  #   
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  #     
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:600;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #   ")),
  #     
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
  #     tags$p(class="road-sub",
  #            "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
  #     
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput(
  #         "roadmap_step", label = NULL,
  #         min = 0, max = 10, value = 0, step = 1, width = "520px"
  #       ),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
  #     ),
  #     
  #     # Progress bar (pure UI, updated via re-render of content)
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  # 
  # # =========================
  # # Roadmap UI (content)
  # # =========================
  # output$roadmap_step_content <- renderUI({
  #   
  #   # ========= Helpers =========
  #   D <- function(title, ...) {
  #     tags$details(
  #       tags$summary(title),
  #       tags$div(class = "road-scroll", ...)
  #     )
  #   }
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   P  <- function(...) tags$p(...)
  #   B  <- function(...) tags$b(...)
  #   C  <- function(...) tags$code(...)
  #   H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
  #   
  #   # ========= Checklist helpers (UI only) =========
  #   # These are intentionally simple visual checklists (no reactive logic).
  #   # Pedagogical goal: help students translate “read/explain” into
  #   # concrete actions they can verify before moving to the next step.
  #   CheckItem <- function(...) {
  #     tags$li(
  #       tags$span(class = "chkbox", "☐"),
  #       tags$span(...)
  #     )
  #   }
  #   Checklist <- function(...) {
  #     tags$div(
  #       class = "callout",
  #       tags$b("Checklist étudiant"),
  #       tags$ul(class = "chk", ...)
  #     )
  #   }
  #   
  #   
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  #   
  #   # ========= CSS (internal scroll so the page stays short) =========
  #   css <- tags$style(HTML("
  #   .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #   details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #   details > summary {cursor:pointer;font-weight:700;}
  #   .road-scroll {max-height: 62vh; overflow-y: auto; padding-right: 10px;}
  #   .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #   .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #   .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #   code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #   .progress {height:10px; margin:10px 0 0 0;}
  #   /* Checklist: checkbox-style bullets */
  #   ul.chk {padding-left: 0; margin: 8px 0 0 0;}
  #   ul.chk li {list-style: none; margin: 6px 0;}
  #   .chkbox {display:inline-block; width: 18px; font-weight: 700; margin-right: 6px;}
  # "))
  #   
  #   # ========= Step logic =========
  #   cur <- input$roadmap_step
  #   if (is.null(cur) || !is.finite(cur)) cur <- 0
  #   cur <- as.integer(cur)
  #   
  #   step_names <- c(
  #     "Aperçu & notations (glossaire + lecture du modèle)",
  #     "Étape 0 — Définir le problème de modélisation",
  #     "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
  #     "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
  #     "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
  #     "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
  #     "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
  #     "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
  #     "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
  #     "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
  #     "Annexes — Formules, checklists, templates, interprétations rapides"
  #   )
  #   
  #   pct <- round(100 * cur / 10)
  #   progress_ui <- tags$div(
  #     class="progress",
  #     tags$div(
  #       class="progress-bar",
  #       role="progressbar",
  #       `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #       style = paste0("width:", pct, "%;")
  #     )
  #   )
  #   
  #   make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
  #     tags$div(
  #       class = "road-card",
  #       if (!is.null(header_ui)) header_ui,
  #       tags$h4(title),
  #       D("1) Ce que l’étudiant fait (procédure + définitions + objectifs)", actions_ui),
  #       D("2) Ce qu’il écrit (APA) + conclusion & signification", apa_ui),
  #       D("3) Pièges + comment les éviter (avec interprétation)", pitfalls_ui)
  #     )
  #   }
  #   
  #   # ========= Pages =========
  #   pages <- vector("list", length = 11)
  #   
  #   # (0) Aperçu
  #   pages[[1]] <- make_step(
  #     step_names[1],
  #     
  #     actions_ui = tagList(
  #       callout(
  #         B("Objectif global : "),
  #         "construire un modèle SARIMA interprétable et surtout ",
  #         B("prédictif"), " : il doit passer les diagnostics résiduels et battre un benchmark simple.",
  #         type="ok"
  #       ),
  #       
  #       Checklist(
  #         CheckItem("Identifier clairement la série y_t (ce que vous cherchez à prévoir) et préciser son unité et son contexte."),
  #         CheckItem("Déterminer la période saisonnière s à partir du contexte (par exemple 12 pour mensuel, 7 pour hebdomadaire, 4 pour trimestriel)."),
  #         CheckItem("Lire la forme générale SARIMA et expliquer le rôle de chaque bloc : différenciation (d, D) puis composantes AR/MA (p, q, P, Q)."),
  #         CheckItem("Définir ce que signifie ‘bon modèle’ dans ce cours : résidus proches d’un bruit blanc, performance hors-échantillon, et parcimonie."),
  #         CheckItem("Noter le benchmark choisi (naïf/SNAIVE) pour évaluer la valeur ajoutée du SARIMA.")
  #       ),
  #       
  #       Checklist(
  #         CheckItem("Identifier clairement la série y_t (ce que vous cherchez à prévoir) et préciser son unité et son contexte (ex. ventes mensuelles, température quotidienne, etc.)."),
  #         CheckItem("Déterminer la période saisonnière s à partir du contexte (ex. 12 pour mensuel, 7 pour hebdomadaire, 4 pour trimestriel) et vérifier qu’elle est cohérente avec la façon dont les données sont échantillonnées."),
  #         CheckItem("Relire la forme générale SARIMA et expliquer, avec vos mots, le rôle des blocs : différenciation (d, D) pour stationnariser, puis composantes AR/MA (p, q, P, Q) pour modéliser la mémoire restante."),
  #         CheckItem("Énoncer vos critères de ‘bon modèle’ : résidus ~ bruit blanc, performance hors-échantillon (train/test ou rolling-origin), et parcimonie (le plus simple qui marche)."),
  #         CheckItem("Choisir et écrire noir sur blanc un benchmark (naïf / SNAIVE / drift) : sans ce repère, vous ne saurez pas si SARIMA apporte une vraie valeur ajoutée.")
  #       ),
  #       Checklist(
  #         CheckItem("Identifier clairement la série y_t (ce que vous cherchez à prévoir) et préciser l’unité, la source, et le contexte."),
  #         CheckItem("Déterminer la période saisonnière s à partir du contexte (ex. 12 pour mensuel, 7 pour hebdomadaire, 4 pour trimestriel) et vérifier qu’elle est cohérente avec les données."),
  #         CheckItem("Expliquer avec vos mots la forme générale SARIMA : différenciations (d, D) pour stationnariser, puis termes AR/MA (p, q, P, Q) pour capturer la dépendance restante."),
  #         CheckItem("Écrire vos critères de validation : diagnostics résiduels (ACF des résidus, Ljung–Box), performance hors-échantillon (MAE/RMSE/MASE), et parcimonie."),
  #         CheckItem("Noter le benchmark retenu (naïf / drift / SNAIVE) afin de mesurer la valeur ajoutée du SARIMA.")
  #       ),
  #       
  #       H5("Notations essentielles (définitions)"),
  #       UL(
  #         tags$li(B("Série temporelle"), " : suite ordonnée d’observations indexées par le temps ", C("y_t"), "."),
  #         tags$li(B("Fréquence / période saisonnière"), " : nombre de pas par cycle saisonnier, noté ", C("s"),
  #                 " (ex. mensuel s=12; quotidien avec saison hebdo s=7)."),
  #         tags$li(B("Opérateur de retard (backshift)"), " : ", C("B y_t = y_{t-1}"), "."),
  #         tags$li(B("Différenciation ordinaire"), " : ", C("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
  #                 " ; appliquée ", C("d"), " fois → supprimer tendance/racine unitaire non saisonnière."),
  #         tags$li(B("Différenciation saisonnière"), " : ", C("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
  #                 " ; appliquée ", C("D"), " fois → supprimer racine unitaire saisonnière."),
  #         tags$li(B("Innovations / bruit blanc"), " : ", C("ε_t ~ w.n.(0, σ²)"),
  #                 " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
  #       ),
  #       
  #       H5("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)"),
  #       UL(
  #         tags$li(
  #           "Écriture compacte : ",
  #           C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
  #         ),
  #         tags$li(
  #           B("Interprétation : "),
  #           "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
  #           "non saisonnières (p,q) et saisonnières (P,Q)."
  #         )
  #       ),
  #       
  #       H5("Ce que signifie “bon modèle” (définition opérationnelle)"),
  #       OL(
  #         tags$li(B("Résidus ~ bruit blanc"), " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."),
  #         tags$li(B("Performance out-of-sample"), " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."),
  #         tags$li(B("Parcimonie"), " : modèle le plus simple possible à performance comparable.")
  #       ),
  #       
  #       # === ADD: Glossaire étendu, critères info, estimation ===
  #       H5("Glossaire étendu (ajouts importants)"),
  #       UL(
  #         tags$li(B("Polynômes AR/MA"), " : ",
  #                 C("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), ", ",
  #                 C("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), "; saisonnier ",
  #                 C("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), ", ",
  #                 C("Θ(B^s) = 1 + Θ_1 B^s + ... + Θ_Q B^{Qs}"), "."),
  #         tags$li(B("Stabilité/causalité (AR)"), " : toutes les racines de ", C("φ(z)=0"),
  #                 " et ", C("Φ(z^s)=0"), " sont ", B("hors"), " du cercle unité → processus stationnaire."),
  #         tags$li(B("Inversibilité (MA)"), " : racines de ", C("θ(z)=0"), " et ", C("Θ(z^s)=0"),
  #                 " hors du cercle unité → représentation AR(∞) bien définie."),
  #         tags$li(B("Constante / drift"), " : une constante dans un ARIMA avec ", C("d=1"),
  #                 " implique une ", B("pente moyenne"), " (drift) après différenciation ; le terme est souvent noté ",
  #                 C("c"), " et la tendance moyenne vaut environ ", C("c"), " par pas."),
  #         tags$li(B("Représentation état–espace"), " : tout ARIMA/SARIMA peut être écrit sous forme état–espace ",
  #                 "et estimé/filtré par Kalman (utile pour manquants et lissage)."),
  #         tags$li(B("Prévision : point vs intervalle vs densité"),
  #                 " : point = ", C("ŷ"), "; intervalle = incertitude (80%/95%); densité = distribution prédictive complète.")
  #       ),
  #       H5("Critères d’information (définitions)"),
  #       UL(
  #         tags$li(B("AIC"), " : ", C("AIC = -2 \\log L + 2k"), " (", C("k"), " = nb paramètres estimés)."),
  #         tags$li(B("AICc"), " : correction petits échantillons → préférable si ", C("n/k"), " n’est pas grand."),
  #         tags$li(B("BIC"), " : ", C("BIC = -2 \\log L + k \\log n"), " ; pénalise plus la complexité (favorise parcimonie).")
  #       ),
  #       H5("Estimation (comment sont estimés les paramètres)"),
  #       UL(
  #         tags$li(B("MLE vs CSS+MLE"), " : estimation par maximum de vraisemblance (souvent via optim) ; ",
  #                 "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."),
  #         tags$li(B("Écarts-types et tests z"), " : reportez estimations ± SE, z et p pour l’interprétation des coefficients.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Phrase APA (modèle + notations)"),
  #       P("« Nous avons ajusté un modèle SARIMA afin de capturer la dépendance temporelle et la saisonnalité de la série ",
  #         C("y_t"), ". La spécification générale est ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
  #         " avec ", C("ε_t"), " un bruit blanc. Le choix de (d, D) a été justifié par des tests de stationnarité (ADF/KPSS/PP) et des diagnostics. »"),
  #       
  #       H5("Conclusion & signification (à expliciter)"),
  #       UL(
  #         tags$li(B("Conclusion type : "), "« Le modèle final est adéquat »"),
  #         tags$li(B("Signification : "), "« (i) il ne laisse pas d’information autocorrélée dans les résidus, ",
  #                 "(ii) il généralise bien sur une fenêtre future, ",
  #                 "(iii) il est suffisamment simple pour être stable et reproductible. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       H5("Pièges classiques"),
  #       UL(
  #         tags$li(B("Confondre AIC faible et bon modèle"), " : un AIC très bas avec résidus autocorrélés = modèle mal spécifié."),
  #         tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naïf, impossible de dire si SARIMA apporte réellement quelque chose."),
  #         tags$li(B("Surcharger le modèle"), " : trop de paramètres → instabilité, intervalles de prévision peu fiables.")
  #       )
  #     )
  #   )
  #   
  #   # (1) Étape 0 — Définition du problème
  #   pages[[2]] <- make_step(
  #     step_names[2],
  #     
  #     actions_ui = tagList(
  #       callout(
  #         B("But : "),
  #         "définir un problème de prévision mesurable (horizon, métriques, protocole).",
  #         type="info"
  #       ),
  #       
  #       Checklist(
  #         CheckItem("Définir la variable y_t (cible) et la fréquence temporelle (jour, semaine, mois) sans ambiguite."),
  #         CheckItem("Fixer l’horizon h en fonction de l’usage reel (decision, planification, stock, etc.)."),
  #         CheckItem("Choisir un protocole d’evaluation temporelle (train/test ou rolling-origin) et expliquer pourquoi."),
  #         CheckItem("Choisir des metriques (MAE + RMSE recommande) et justifier leur interpretation."),
  #         CheckItem("Decider si une transformation (log / Box-Cox) est necessaire et noter la raison.")
  #       ),
  #       
  #       H5("Définitions (ce que chaque terme veut dire)"),
  #       UL(
  #         tags$li(B("Série réponse"), " ", C("y_t"), " : variable à prédire (univariée)."),
  #         tags$li(B("Horizon"), " ", C("h"), " : nombre de pas à prévoir (ex. h=12 mois)."),
  #         tags$li(B("Origine de prévision"), " : dernier temps observé à partir duquel on prévoit."),
  #         tags$li(B("Protocole train/test"), " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."),
  #         tags$li(B("Rolling-origin / validation temporelle"), " : on répète des prévisions à différentes origines pour estimer la performance moyenne."),
  #         tags$li(B("SARIMA vs SARIMAX"), " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes.")
  #       ),
  #       
  #       H5("Choisir les métriques (définitions + quand utiliser)"),
  #       UL(
  #         tags$li(B("MAE"), " : moyenne des erreurs absolues ", C("mean(|y-ŷ|)"),
  #                 " → robuste, facile à interpréter (unité de y)."),
  #         tags$li(B("RMSE"), " : racine de l’erreur quadratique moyenne ", C("sqrt(mean((y-ŷ)^2))"),
  #                 " → pénalise plus les grosses erreurs."),
  #         tags$li(B("MAPE"), " : ", C("mean(|(y-ŷ)/y|)"),
  #                 " → éviter si y proche de 0 (explose)."),
  #         tags$li(B("sMAPE"), " : alternative plus stable près de 0 : ", C("mean(2|y-ŷ|/(|y|+|ŷ|))"), ".")
  #       ),
  #       
  #       H5("Transformation (définitions + justification)"),
  #       UL(
  #         tags$li(B("Niveaux"), " : modèle sur les valeurs brutes."),
  #         tags$li(B("Log-niveaux"), " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."),
  #         tags$li(B("Box–Cox"), " : transformation paramétrique (λ) pour stabiliser variance et améliorer normalité : ",
  #                 C("y^(λ) = (y^λ - 1)/λ"), " (λ≠0), et log si λ=0.")
  #       ),
  #       
  #       H5("Procédure minimale (checklist)"),
  #       OL(
  #         tags$li("Fixer fréquence et période saisonnière s."),
  #         tags$li("Fixer horizon h et fenêtres train/test (ou rolling-origin)."),
  #         tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
  #         tags$li("Décider transformation (aucune/log/Box–Cox) et justifier.")
  #       ),
  #       
  #       # === ADD: précisions pratiques, métriques complémentaires, transformations ===
  #       H5("Précisions supplémentaires (définitions pratiques)"),
  #       UL(
  #         tags$li(B("Horizon multi-pas"), " : ", C("h>1"),
  #                 " → la performance peut décroître avec l’horizon ; rapporter MAE/RMSE par h si possible."),
  #         tags$li(B("Fenêtre d’entraînement"), " : ", B("expansive"), " (on ne jette jamais d’anciens points) ",
  #                 "ou ", B("glissante"), " (fenêtre fixe) ; documenter le choix."),
  #         tags$li(B("Reproductibilité"), " : fixer les graines aléatoires, consigner versions des packages, chemins de données."),
  #         tags$li(B("Prévision hiérarchique"), " (annexe) : si agrégations (mois→trimestres), noter la cohérence temporelle.")
  #       ),
  #       H5("Métriques supplémentaires (quand utiles)"),
  #       UL(
  #         tags$li(B("MASE"), " : erreur absolue mise à l’échelle par le naïf saisonnier → comparable entre séries."),
  #         tags$li(B("WAPE"), " : ", C("sum(|y-ŷ|)/sum(|y|)"), " ; lisible comme % d’erreur agrégée."),
  #         tags$li(B("Pinball loss (quantiles)"), " : si vous prédisez des quantiles (IC asymétriques).")
  #       ),
  #       H5("Transformations complémentaires"),
  #       UL(
  #         tags$li(B("Yeo–Johnson"), " : alternative à Box–Cox qui gère les valeurs ≤ 0."),
  #         tags$li(B("Stabilisation de variance"), " : vérifier relation niveau–variance (nuage points moyenne locale vs ET).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — modèle de phrase complet"),
  #       P("« Nous avons modélisé la série temporelle univariée ", C("y_t"),
  #         " observée à une fréquence [..] (période saisonnière s=[..]). ",
  #         "L’objectif était de produire des prévisions à horizon ", C("h"), "=[..]. ",
  #         "La performance a été évaluée sur une fenêtre future selon [split temporel / rolling-origin] ",
  #         "à l’aide de [MAE, RMSE]. Une transformation [aucune / log / Box–Cox] a été appliquée afin de [stabiliser la variance / linéariser la saisonnalité]. »"),
  #       
  #       H5("Conclusion & signification (comment l’expliquer)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Notre problème est bien défini (h, métriques, protocole). »"),
  #         tags$li(B("Signification : "), "« Toute comparaison de modèles devient juste : même horizon, même protocole, mêmes métriques. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) → performance artificiellement élevée."),
  #         tags$li(B("Métrique mal choisie"), " : MAPE avec y≈0 → conclusions fausses."),
  #         tags$li(B("Horizon incohérent"), " : un modèle bon à h=1 peut être mauvais à h=12 ; fixer l’horizon selon l’usage réel.")
  #       )
  #     )
  #   )
  #   
  #   # (2) Étape 1 — Description des données
  #   pages[[3]] <- make_step(
  #     step_names[3],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "décrire la qualité des données et rendre le pipeline reproductible.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Verifier que l’index temporel est regulier (pas manquants/dupliques, ordre correct)."),
  #         CheckItem("Rapporter n, date debut/fin, frequence, et la couverture temporelle."),
  #         CheckItem("Quantifier les manquants (k et %) et choisir une strategie (interpolation, saisonniere, Kalman) avec justification."),
  #         CheckItem("Produire un resume statistique (moyenne, mediane, ET, min/max) et un resume saisonnier (par mois/semaine)."),
  #         CheckItem("Documenter toute correction (doublons, valeurs aberrantes evidentes) pour garantir la reproductibilite.")
  #       ),
  #       
  #       H5("Ce qu’il faut rapporter (définitions)"),
  #       UL(
  #         tags$li(B("n"), " : nombre total d’observations disponibles."),
  #         tags$li(B("Couverture"), " : date début/fin."),
  #         tags$li(B("Fréquence"), " : périodicité (mensuel/hebdo/quotidien)."),
  #         tags$li(B("Manquants"), " : nombre k et pourcentage k/n.")
  #       ),
  #       
  #       H5("Valeurs manquantes : types + implications"),
  #       UL(
  #         tags$li(B("MCAR"), " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."),
  #         tags$li(B("MAR"), " (At Random conditionnel) : dépend d’autres infos → imputation possible mais à justifier."),
  #         tags$li(B("MNAR"), " (Not At Random) : dépend de la valeur elle-même → risque de biais important.")
  #       ),
  #       
  #       H5("Stratégies de traitement (quand et pourquoi)"),
  #       UL(
  #         tags$li(B("Interpolation linéaire"), " : si manquants rares et pas de ruptures."),
  #         tags$li(B("Interpolation saisonnière"), " : si saisonnalité stable (ex. remplacer par moyenne du même mois)."),
  #         tags$li(B("Modèle d’état / Kalman"), " : si on veut une imputation plus probabiliste."),
  #         tags$li(B("Suppression"), " : seulement si extrêmement rare et sans impact sur la continuité.")
  #       ),
  #       
  #       H5("Descriptifs pertinents (au-delà de la moyenne)"),
  #       UL(
  #         tags$li("Moyenne, médiane, ET, min/max (niveau)."),
  #         tags$li("Asymétrie (skewness) / kurtosis si utile."),
  #         tags$li("Résumé saisonnier (ex. moyenne par mois), pour documenter saisonnalité.")
  #       ),
  #       
  #       # === ADD: qualité index & manquants pratiques ===
  #       H5("Qualité de l’index temporel (définitions)"),
  #       UL(
  #         tags$li(B("Régularité"), " : pas de pas manqué/dupliqué ; cadence constante."),
  #         tags$li(B("Fuseau/DST"), " : données horaires → attention aux heures manquantes/dupliquées (passage DST)."),
  #         tags$li(B("Doublons et horodatages hors ordre"), " : à corriger avant tout calcul d’ACF.")
  #       ),
  #       H5("Manquants — remarques pratiques"),
  #       UL(
  #         tags$li(B("Kalman/StructTS"), " : imputation probabiliste cohérente avec la dynamique ARIMA."),
  #         tags$li(B("Imputation “saison identique”"), " : moyenne/médiane du même mois/jour si saisonnalité stable."),
  #         tags$li(B("Zéros structurels"), " : distinguer “zéro” réel de manquant imputé à 0 (documenter).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — description"),
  #       P("« La série contient ", C("n"), "=[..] observations couvrant [..] à [..] à une fréquence [..]. ",
  #         "Les valeurs manquantes représentaient [..]% (k=[..]) et ont été traitées par [..], ",
  #         "choisie car [manquants rares / saisonnalité stable / continuité nécessaire]. ",
  #         "La série présentait une moyenne de [..] (ET=[..]) et une médiane [..]. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Les données sont suffisamment propres pour SARIMA » (ou non)."),
  #         tags$li(B("Signification : "),
  #                 "si l’index est régulier et que les manquants sont gérés explicitement, ",
  #                 "les hypothèses du modèle (espacement régulier) deviennent plausibles.")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Imputation silencieuse"), " : toujours documenter méthode + raison."),
  #         tags$li(B("Timestamps irréguliers"), " : SARIMA suppose une grille régulière ; corriger avant toute estimation."),
  #         tags$li(B("Changement de définition de la variable"), " : ex. changement de mesure → rupture structurelle à traiter.")
  #       )
  #     )
  #   )
  #   
  #   # (3) Étape 2 — EDA
  #   pages[[4]] <- make_step(
  #     step_names[4],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant d’ajuster SARIMA.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Tracer la serie y_t et annoter tendance, saisonnalite, ruptures possibles et changements de variance."),
  #         CheckItem("Construire au moins un graphique saisonnier (seasonal plot ou subseries) pour comprendre la forme par saison."),
  #         CheckItem("Identifier les outliers (dates) et formuler une hypothese (evenement reel vs erreur)."),
  #         CheckItem("Decider et documenter le traitement des outliers (conserver/corriger/imputer) et tester l’impact sur l’analyse."),
  #         CheckItem("Noter ce que l’EDA implique pour la suite: transformation possible, differenciation probable, et presence de ruptures.")
  #       ),
  #       
  #       H5("Définitions utiles (ce qu’on cherche)"),
  #       UL(
  #         tags$li(B("Tendance"), " : évolution de long terme (déterministe ou stochastique)."),
  #         tags$li(B("Saisonnalité"), " : motif périodique de période s (ex. 12)."),
  #         tags$li(B("Rupture structurelle"), " : changement durable de niveau/tendance/variance (ex. politique, crise)."),
  #         tags$li(B("Outlier"), " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou erreur.")
  #       ),
  #       
  #       H5("Graphiques recommandés + leur but"),
  #       UL(
  #         tags$li(B("Courbe y_t"), " : voir tendance, variance, ruptures."),
  #         tags$li(B("Seasonal plot"), " : comparer la forme saisonnière d’une année à l’autre."),
  #         tags$li(B("Boxplots par saison"), " : détecter asymétrie/outliers par mois/semaine."),
  #         tags$li(B("ACF brute"), " (optionnel) : repérer dépendances fortes et saisonnalité.")
  #       ),
  #       
  #       H5("Outliers : procédure raisonnable"),
  #       OL(
  #         tags$li("Repérer visuellement (dates)."),
  #         tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
  #         tags$li("Décider : conserver / corriger / imputer (et justifier)."),
  #         tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
  #       ),
  #       
  #       # === ADD: outils EDA supplémentaires & typologie outliers ===
  #       H5("Outils EDA supplémentaires"),
  #       UL(
  #         tags$li(B("Périodogramme / spectre"), " : met en évidence des fréquences saisonnières inattendues."),
  #         tags$li(B("Seasonal subseries plot"), " : visualise la forme saisonnière par mois/semaine."),
  #         tags$li(B("Nuage niveau–variance"), " : aide au choix log/Box–Cox (variance croît avec le niveau ?).")
  #       ),
  #       H5("Types d’outliers (interventions)"),
  #       UL(
  #         tags$li(B("AO"), " : Additive Outlier (pic ponctuel)."),
  #         tags$li(B("IO"), " : Innovation Outlier (choc qui diffuse)."),
  #         tags$li(B("LS"), " : Level Shift (changement de niveau)."),
  #         tags$li(B("TC"), " : Temporary Change (effet transitoire).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — EDA"),
  #       P("« L’inspection visuelle a mis en évidence une tendance [..] et une saisonnalité récurrente de période s=[..]. ",
  #         "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Box–Cox]. ",
  #         "Des valeurs atypiques autour de [dates] ont été [conservées/traitées] car [événement réel / erreur probable]. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« La structure (tendance/saison/variance/outliers) est comprise »"),
  #         tags$li(B("Signification : "),
  #                 "cela guide directement le choix transformation + différenciations (d, D) et évite d’ajuster un SARIMA “à l’aveugle”.")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Confondre saisonnalité et tendance"), " : une moyenne croissante ET une saisonnalité stable sont deux composantes distinctes."),
  #         tags$li(B("Retirer des points réels"), " : si l’outlier correspond à un événement récurrent (fêtes), il doit rester."),
  #         tags$li(B("Ignorer une rupture"), " : un SARIMA “moyenne” une structure qui a changé → mauvais futur.")
  #       )
  #     )
  #   )
  #   
  #   # (4) Étape 3 — Décomposition
  #   pages[[5]] <- make_step(
  #     step_names[5],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "séparer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Comparer visuellement une hypothese additive vs multiplicative (amplitude saisonniere constante vs proportionnelle au niveau)."),
  #         CheckItem("Tester l’idee de transformation log/Box-Cox si la variance augmente avec le niveau."),
  #         CheckItem("Realiser une decomposition (classique ou STL) et commenter la tendance, la saisonnalite et le residu."),
  #         CheckItem("Verifier si la saisonnalite semble stable ou evolutive (argument pour STL)."),
  #         CheckItem("Ecrire clairement ce que la decomposition suggere pour d, D, et pour l’echelle de modelisation.")
  #       ),
  #       
  #       H5("Décomposition : définitions"),
  #       UL(
  #         tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
  #                 " (amplitude saisonnière ~ constante)."),
  #         tags$li(B("Multiplicative"), " : ", C("y_t = T_t × S_t × e_t"),
  #                 " (amplitude saisonnière augmente avec le niveau)."),
  #         tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
  #                 C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
  #         tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
  #       ),
  #       
  #       H5("Pourquoi STL ? (objectif détaillé)"),
  #       UL(
  #         tags$li("Quand la saisonnalité change lentement au fil du temps (non parfaitement répétitive)."),
  #         tags$li("Quand on veut réduire l’influence des outliers sur l’estimation saison/tendance."),
  #         tags$li("Quand on veut une lecture pédagogique claire (tendance vs saison vs résidu).")
  #       ),
  #       
  #       H5("Ce que la décomposition ne remplace pas"),
  #       UL(
  #         tags$li("Elle ne prouve pas la stationnarité : SARIMA exige une série stationnaire après différenciation."),
  #         tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nécessaires.")
  #       ),
  #       
  #       # === ADD: paramètres STL & règles pratiques ===
  #       H5("Paramètres STL (lecture pédagogique)"),
  #       UL(
  #         tags$li(B("s.window"), " : lissage saisonnier (", C("periodic"), " = saison constante; entier = évolutive)."),
  #         tags$li(B("t.window"), " : lissage de la tendance (fenêtre LOESS)."),
  #         tags$li(B("robust"), " : réduit l’influence des outliers (itérations avec poids).")
  #       ),
  #       H5("Additif vs multiplicatif (règle pratique)"),
  #       UL(
  #         tags$li("Amplitude saisonnière ~ proportionnelle au niveau → penser ", B("log"), " ou modèle multiplicatif."),
  #         tags$li("Amplitude ~ constante → additif sur niveaux.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Décomposition"),
  #       P("« Nous avons étudié une structure additive vs multiplicative en évaluant si l’amplitude saisonnière variait avec le niveau. ",
  #         "Comme [..], nous avons retenu [modèle additif / transformation log] et réalisé une décomposition via [classique / STL]. ",
  #         "STL a été privilégiée pour sa flexibilité (saisonnalité évolutive) et sa robustesse aux valeurs atypiques. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le choix additif/multiplicatif est justifié »"),
  #         tags$li(B("Signification : "),
  #                 "on évite des résidus hétéroscédastiques et on améliore la stabilité de l’estimation SARIMA.")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Décomposition ≠ stationnarité"), " : après décomposition, on doit encore tester/choisir d et D."),
  #         tags$li(B("Oublier l’échelle"), " : si vous modélisez log(y), les prévisions doivent être reconverties (avec prudence)."),
  #         tags$li(B("Confondre bruit et structure"), " : des motifs résiduels persistants suggèrent que la saison/tendance n’a pas été correctement capturée.")
  #       )
  #     )
  #   )
  #   
  #   # (5) Étape 4 — Stationnarité (très détaillé : ADF/KPSS/PP + …)
  #   pages[[6]] <- make_step(
  #     step_names[6],
  #     
  #     actions_ui = tagList(
  #       callout(
  #         B("Idée centrale : "),
  #         
  #         Checklist(
  #           CheckItem("Definir stationnarite avec vos mots (moyenne/variance constantes, dependance qui ne change pas dans le temps)."),
  #           CheckItem("Executer ADF, KPSS et PP sur la serie brute et noter les hypotheses H0/Ha de chaque test."),
  #           CheckItem("Proposer d et D de maniere progressive (essayer d=1 puis D=1 si besoin) et re-tester apres chaque transformation."),
  #           CheckItem("Surveiller les signes de sur-differenciation (ACF lag1 tres negative, variance gonflee, dynamique artificielle)."),
  #           CheckItem("Justifier le choix final (d, D, s) par convergence: tests + graphiques + ACF/PACF.")
  #         ),
  #         "SARIMA suppose que la série devient (au moins) stationnaire ",
  #         B("après différenciation"), ". Les tests ADF/PP/KPSS servent à justifier (d, D).",
  #         type="ok"
  #       ),
  #       
  #       H5("Définition : stationnarité (ce que cela veut dire)"),
  #       UL(
  #         tags$li(B("Stationnarité faible (covariance-stationnaire)"), " : moyenne constante, variance constante, ",
  #                 "et autocovariance dépend uniquement du retard (pas de t)."),
  #         tags$li(B("Non-stationnarité"), " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."),
  #         tags$li(B("Racine unitaire"), " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1).")
  #       ),
  #       
  #       H5("Différenciation : rôle (d vs D)"),
  #       UL(
  #         tags$li(B("d"), " enlève la racine unitaire non saisonnière / tendance stochastique : ", C("(1-B)^d"), "."),
  #         tags$li(B("D"), " enlève la racine unitaire saisonnière : ", C("(1-B^s)^D"), "."),
  #         tags$li(B("Règle pratique"), " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2).")
  #       ),
  #       
  #       H5("Test ADF (Augmented Dickey–Fuller) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."),
  #         tags$li(B("Régression (intuition)"), " : on teste si le coefficient de ", C("y_{t-1}"),
  #                 " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire (non-stationnaire) ; ",
  #                 B("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."),
  #         tags$li(B("Interprétation p-value"), " : p petit → rejet H0 → stationnarité (au sens ADF). p grand → on ne rejette pas → différenciation probablement nécessaire.")
  #       ),
  #       
  #       H5("Test KPSS — définition & objectif (inverse de l’ADF)"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série est stationnaire (niveau ou tendance)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = stationnaire ; ",
  #                 B("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."),
  #         tags$li(B("Interprétation"), " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité.")
  #       ),
  #       
  #       H5("Test PP (Phillips–Perron) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement (correction non-paramétrique)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire ; ",
  #                 B("Ha"), " = stationnaire."),
  #         tags$li(B("Pourquoi utile"), " : complément de robustesse ; si ADF et PP convergent, confiance accrue.")
  #       ),
  #       
  #       H5("Comment conclure en combinant ADF/KPSS/PP (logique complète)"),
  #       OL(
  #         tags$li(B("Stationnarité forte : "), "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."),
  #         tags$li(B("Non-stationnarité forte : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
  #         tags$li(B("Conflit : "), "les tests divergent → regarder graphiques, ACF, résultats après une différence, et justifier par convergence d’indices (pas une seule p-value).")
  #       ),
  #       
  #       H5("Procédure recommandée (pas à pas)"),
  #       OL(
  #         tags$li("Fixer ", B("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
  #         tags$li("Tester ADF/KPSS/PP sur la série brute."),
  #         tags$li("Essayer d=1 si nécessaire, retester."),
  #         tags$li("Essayer D=1 si saisonnalité/racine saisonnière, retester."),
  #         tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
  #       ),
  #       
  #       H5("Sur-différenciation : définition + symptômes"),
  #       UL(
  #         tags$li(B("Définition"), " : appliquer trop de différences → on introduit une dynamique artificielle."),
  #         tags$li(B("Symptômes fréquents"), " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."),
  #         tags$li(B("Conséquence"), " : intervalles de prévision plus larges et modèle moins fiable.")
  #       ),
  #       
  #       # === ADD: tests/bonnes pratiques complémentaires ===
  #       H5("Tests et notions complémentaires"),
  #       UL(
  #         tags$li(B("Tendance déterministe vs racine unitaire"),
  #                 " : on peut préférer un ARIMA avec ", C("d=0"), " et une tendance ", B("déterministe"),
  #                 " (régression + ARMA sur résidus) si la tendance semble stable."),
  #         tags$li(B("Racine unitaire saisonnière (HEGY)"), " : (annexe) test dédié aux racines à ", C("±1, ±i"), " pour ",
  #                 C("s=4,12"), " ; utile si la saisonnalité stochastique domine."),
  #         tags$li(B("Zivot–Andrews"), " : (annexe) racine unitaire avec rupture endogène possible.")
  #       ),
  #       H5("Bonnes pratiques de différenciation"),
  #       UL(
  #         tags$li(B("Au plus une différence"), " : commencer par ", C("d=1"), " ou ", C("D=1"),
  #                 " ; ", B("éviter"), " ", C("d=2"), " sauf preuves fortes."),
  #         tags$li(B("Sur-différenciation : "), "ACF lag 1 très négative, variance gonflée, MA artificiel → revenir en arrière.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Tests & choix de (d, D)"),
  #       P("« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
  #         "Les résultats ont été examinés sur la série originale puis après différenciations ordinaires et saisonnières. ",
  #         "Sur la base de l’ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
  #         "afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA, tout en évitant la sur-différenciation. »"),
  #       
  #       H5("Conclusion test (prête à remplir) + signification"),
  #       UL(
  #         tags$li(B("ADF : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "si rejet → la série est compatible stationnarité (au sens ADF) ; sinon → différenciation probablement nécessaire."),
  #         tags$li(B("KPSS : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (stationnarité). ",
  #                 B("Signification : "),
  #                 "si rejet → non-stationnarité (donc d/D à augmenter ou transformation/rupture à traiter)."),
  #         tags$li(B("PP : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
  #       ),
  #       
  #       H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Nous retenons d=[..], D=[..], s=[..]. »"),
  #         tags$li(B("Signification : "),
  #                 "« le SARIMA sera estimé sur la série différenciée ; les paramètres AR/MA décrivent la dynamique ",
  #                 "restante après retrait de la tendance et/ou de la saisonnalité non stationnaire. »")
  #       ),
  #       
  #       # === ADD: points à expliciter
  #       H5("À expliciter (rappel)"),
  #       UL(
  #         tags$li("Préciser si une constante/drift est incluse et à quel niveau (avant/après différenciation)."),
  #         tags$li("Documenter toute rupture suspectée et ses conséquences sur le choix de ", C("d, D"), ".")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Choisir d et D “par habitude”"), " : toujours justifier par tests + EDA."),
  #         tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent “crier non-stationnaire” alors qu’un changement de régime est en cause."),
  #         tags$li(B("Interpréter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on s’appuie sur convergence des preuves.")
  #       )
  #     )
  #   )
  #   
  #   # (6) Étape 5 — Auto-ARIMA baseline
  #   pages[[7]] <- make_step(
  #     step_names[7],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "obtenir un point de départ compétitif, puis vérifier/affiner.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Executer auto-ARIMA avec des bornes raisonnables sur p,q,P,Q et noter le critere (AICc) utilise."),
  #         CheckItem("Enregistrer le modele baseline (ordres + presence drift/constante) pour comparaison ulterieure."),
  #         CheckItem("Verifier diagnostics residuels (ACF residus, Ljung-Box) avant de le considerer ‘acceptable’."),
  #         CheckItem("Evaluer la performance sur la fenetre test (MAE/RMSE) et comparer au benchmark naif/SNAIVE."),
  #         CheckItem("Decider si vous cherchez une version plus parcimonieuse (BIC plus faible ou meme performance avec moins de parametres).")
  #       ),
  #       
  #       H5("Définition : auto-ARIMA (ce que fait réellement l’algorithme)"),
  #       UL(
  #         tags$li("Explore un ensemble de modèles candidats (p,q,P,Q) sous contraintes."),
  #         tags$li("Choisit souvent via minimisation ", B("AICc"),
  #                 " (AIC corrigé petits échantillons)."),
  #         tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coûteuse).")
  #       ),
  #       
  #       H5("Pourquoi AICc ? (objectif)"),
  #       UL(
  #         tags$li("Compromis entre qualité d’ajustement et complexité (pénalise les paramètres)."),
  #         tags$li("AICc est préférable à AIC quand n n’est pas très grand par rapport au nombre de paramètres.")
  #       ),
  #       
  #       H5("Procédure propre"),
  #       OL(
  #         tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
  #         tags$li("Fixer bornes max p/q/P/Q ; documenter."),
  #         tags$li("Sauvegarder le modèle baseline (pour comparaison)."),
  #         tags$li("Vérifier diagnostics résiduels + performance sur test.")
  #       ),
  #       
  #       # === ADD: détails de recherche & critères multiples ===
  #       H5("Détails de recherche"),
  #       UL(
  #         tags$li(B("Stepwise vs exhaustive"), " : stepwise = rapide, peut rater un optimum global ; exhaustive = coûteux mais plus fiable."),
  #         tags$li(B("Contraintes"), " : imposer ", C("p,q,P,Q \u2264"), " bornes raisonnables ; forcer stabilité/inversibilité."),
  #         tags$li(B("drift/constante"), " : tester versions avec et sans drift lorsque ", C("d=1"), ".")
  #       ),
  #       H5("Critères multiples"),
  #       UL(
  #         tags$li("Comparer AICc ", B("et"), " BIC ; en cas de quasi-égalité → choisir le plus parcimonieux.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — baseline"),
  #       P("« Un modèle SARIMA de référence a été sélectionné via une procédure auto-ARIMA basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats sous contraintes [..]. ",
  #         "La spécification obtenue a été utilisée comme baseline, puis comparée à des modèles manuels plus parcimonieux sur la base des diagnostics et de la performance de prévision. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Auto-ARIMA fournit une baseline solide »"),
  #         tags$li(B("Signification : "), "« on a un repère : tout modèle final doit faire au moins aussi bien. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Modèle “trop complexe”"), " : stepwise peut sélectionner des ordres élevés → instabilité, interprétation difficile."),
  #         tags$li(B("AICc excellent mais résidus mauvais"), " : diagnostics priment."),
  #         tags$li(B("Oublier la parcimonie"), " : si deux modèles prédisent pareil, garder le plus simple.")
  #       )
  #     )
  #   )
  #   
  #   # (7) Étape 6 — SARIMA manuel
  #   pages[[8]] <- make_step(
  #     step_names[8],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "proposer un petit ensemble raisonné de candidats via ACF/PACF.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Tracer ACF/PACF de la serie differenciee (apres choix d et D) et identifier les pics significatifs."),
  #         CheckItem("Proposer un petit ensemble de candidats (3 a 8) en justifiant p,q,P,Q par les motifs ACF/PACF (y compris aux multiples de s)."),
  #         CheckItem("Ajuster chaque candidat, relever AICc/BIC, et verifier stabilite/inversibilite si possible."),
  #         CheckItem("Comparer sur diagnostics residuels ET performance predictive (pas seulement AICc)."),
  #         CheckItem("Garder le modele le plus simple qui passe diagnostics et bat le benchmark.")
  #       ),
  #       
  #       H5("Définitions : ACF / PACF (ce que mesurent ces courbes)"),
  #       UL(
  #         tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"),
  #                 " → suggère MA(q) si coupure nette vers q."),
  #         tags$li(B("PACF"), " : corrélation “pure” au retard k une fois les retards <k contrôlés ",
  #                 "→ suggère AR(p) si coupure nette vers p.")
  #       ),
  #       
  #       H5("Heuristiques (non saisonnier)"),
  #       UL(
  #         tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF décroît."),
  #         tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF décroît."),
  #         tags$li(B("ARMA"), " : ACF et PACF décroissent (pas de coupure franche).")
  #       ),
  #       
  #       H5("Heuristiques saisonnières (multiples de s)"),
  #       UL(
  #         tags$li(B("SAR(P)"), " : pics PACF à s, 2s, ..."),
  #         tags$li(B("SMA(Q)"), " : pics ACF à s, 2s, ...")
  #       ),
  #       
  #       H5("Procédure recommandée (petit nombre de modèles)"),
  #       OL(
  #         tags$li("Construire 3 à 8 candidats (parcimonieux)."),
  #         tags$li("Ajuster et comparer AICc/BIC."),
  #         tags$li("Vérifier stabilité/inversibilité."),
  #         tags$li("Retenir ceux qui passent diagnostics + prévision.")
  #       ),
  #       
  #       # === ADD: conception de candidats & lecture fine ===
  #       H5("Conception de candidats (rappels utiles)"),
  #       UL(
  #         tags$li(B("Limiter le set"), " : 3–8 modèles max, justifiés par ACF/PACF."),
  #         tags$li(B("Stabilité/inversibilité"), " : vérifier racines des polynômes AR/MA (hors cercle unité)."),
  #         tags$li(B("drift/constante"), " : inclure/exclure et comparer au niveau AICc/BIC + diagnostics.")
  #       ),
  #       H5("Lecture fine ACF/PACF"),
  #       UL(
  #         tags$li("Pics à ", C("s, 2s, 3s"), " dans l’ACF → penser ", B("SMA(Q)"), "."),
  #         tags$li("Pics à ", C("s, 2s"), " dans la PACF → penser ", B("SAR(P)"), "."),
  #         tags$li("Queue AR (décroissance géométrique) vs coupure MA (après q).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — sélection manuelle"),
  #       P("« Les structures candidates ont été proposées sur la base des schémas ACF/PACF de la série différenciée. ",
  #         "Des autocorrélations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
  #         "Un ensemble restreint de modèles (n=[..]) a été ajusté et comparé via AICc/BIC et diagnostics résiduels, en privilégiant la parcimonie. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle final est soutenu par la structure ACF/PACF et les diagnostics. »"),
  #         tags$li(B("Signification : "), "« on réduit le risque de sur-ajustement en limitant les candidats. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Brute-force massif"), " : tester 200 modèles puis choisir le plus petit AICc = data snooping."),
  #         tags$li(B("Surinterpréter ACF/PACF"), " : ce sont des guides, pas des preuves."),
  #         tags$li(B("Ignorer l’inversibilité/stabilité"), " : paramètres instables → prévisions incohérentes.")
  #       )
  #     )
  #   )
  #   
  #   # (8) Étape 7 — Diagnostics & comparaison
  #   pages[[9]] <- make_step(
  #     step_names[9],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "valider que le modèle explique toute la dépendance et prédit bien.", type="ok"),
  #       
  #       Checklist(
  #         CheckItem("Examiner les residus: courbe temporelle, ACF residus, et Ljung-Box a plusieurs lags L."),
  #         CheckItem("Verifier qu’il n’y a pas de structure residuelle (p-value Ljung-Box non significative) et ajuster si necessaire."),
  #         CheckItem("Evaluer la prediction hors-echantillon (MAE/RMSE/MASE) avec le meme horizon et le meme protocole pour tous les modeles."),
  #         CheckItem("Comparer explicitement au benchmark (naif/SNAIVE) et conclure sur la valeur ajoutee."),
  #         CheckItem("Documenter toute violation (ARCH, rupture, non-normalite) et expliquer l’impact sur IC et interpretation.")
  #       ),
  #       
  #       H5("Diagnostics résiduels : définitions & buts"),
  #       UL(
  #         tags$li(B("Résidus"), " : ", C("e_t = y_t - ŷ_t"),
  #                 " (ou résidus d’innovation selon l’implémentation)."),
  #         tags$li(B("Bruit blanc"), " : absence d’autocorrélation résiduelle → le modèle a capturé la structure temporelle."),
  #         tags$li(B("Ljung–Box"), " : test global d’autocorrélation des résidus jusqu’à un lag L.")
  #       ),
  #       
  #       H5("Test de Ljung–Box (définition + interprétation)"),
  #       UL(
  #         tags$li(B("But"), " : tester si les autocorrélations résiduelles jusqu’à L sont globalement nulles."),
  #         tags$li(B("Hypothèses"), " : ", B("H0"), " = pas d’autocorrélation résiduelle ; ", B("Ha"), " = autocorrélation résiduelle présente."),
  #         tags$li(B("Conclusion"), " : p petit → rejet H0 → modèle incomplet (ajuster p/q/P/Q ou d/D)."),
  #         tags$li(B("Signification pratique"), " : si autocorrélation résiduelle reste, vos intervalles/prévisions sont souvent trop optimistes.")
  #       ),
  #       
  #       H5("Normalité & hétéroscédasticité (à quoi ça sert vraiment)"),
  #       UL(
  #         tags$li(B("Normalité"), " : utile pour l’interprétation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
  #         tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimés ; si fort, envisager modèles de variance (GARCH) selon le cours.")
  #       ),
  #       
  #       H5("Évaluation prévision (définition + protocole)"),
  #       UL(
  #         tags$li(B("Split temporel"), " : entraîner sur le passé, tester sur le futur."),
  #         tags$li(B("Rolling-origin"), " : répéter sur plusieurs origines → estimation plus robuste."),
  #         tags$li(B("Benchmark"), " : naїf / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE à l’horizon cible.")
  #       ),
  #       
  #       # === ADD: diagnostics additionnels & comparaison ===
  #       H5("Diagnostics additionnels"),
  #       UL(
  #         tags$li(B("Box–Pierce vs Ljung–Box"), " : préférer Ljung–Box (meilleure petite taille)."),
  #         tags$li(B("Normalité résiduelle"), " : Q–Q plot, Jarque–Bera ; utile pour IC mais secondaire si but = point forecast."),
  #         tags$li(B("Hétéroscédasticité / ARCH"), " : tester ACF des résidus au carré ; si fort → discuter modèles de variance (annexe)."),
  #         tags$li(B("Significativité des coefficients"), " : rapporter est., SE, z, p ; supprimer termes non significatifs si performance constante.")
  #       ),
  #       H5("Comparaison de modèles"),
  #       UL(
  #         tags$li(B("Tableau récapitulatif"), " : AICc/BIC, Ljung–Box (p), MAE/RMSE/MASE, nb de paramètres."),
  #         tags$li(B("Test de Diebold–Mariano"), " : (annexe) comparer formellement 2 séries d’erreurs prédictives.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — diagnostics"),
  #       P("« Les diagnostics résiduels indiquaient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics substantiels et le test de Ljung–Box était [non significatif/significatif] au seuil α=[..]. ",
  #         "La performance de prévision sur la fenêtre d’évaluation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. »"),
  #       
  #       H5("Conclusion & signification (diagnostics + performance)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle est acceptable » si Ljung–Box non significatif ET benchmark battu."),
  #         tags$li(B("Signification : "),
  #                 "« le modèle capte la structure temporelle (résidus ~ bruit) et apporte un gain prédictif réel (out-of-sample). »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Bon AIC mais Ljung–Box significatif"), " : modèle incomplet → ne pas valider."),
  #         tags$li(B("Se focaliser sur la normalité"), " : priorité = absence d’autocorrélation résiduelle."),
  #         tags$li(B("Comparer des modèles sur des horizons différents"), " : toujours même h, même protocole.")
  #       )
  #     )
  #   )
  #   
  #   # (9) Étape 8 — Rédaction
  #   pages[[10]] <- make_step(
  #     step_names[10],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "écrire un rapport clair, reproductible, aligné aux étapes 0–7.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Rediger une section Methodes qui suit exactement le pipeline: donnees -> EDA -> stationnarite -> selection -> diagnostics -> prevision."),
  #         CheckItem("Inclure figures indispensables: serie, decomposition, ACF/PACF, residus, previsions + intervalles."),
  #         CheckItem("Inclure un tableau de comparaison (AICc/BIC, Ljung-Box, MAE/RMSE, benchmark, nb parametres)."),
  #         CheckItem("Preciser l’echelle (niveau/log/Box-Cox) et expliquer toute reconversion des previsions."),
  #         CheckItem("Ajouter un encadre limites + pistes (ruptures, SARIMAX, GARCH) et assurer la reproductibilite (versions).")
  #       ),
  #       
  #       H5("Structure APA recommandée (définition)"),
  #       UL(
  #         tags$li(B("Méthodes"), " : ce que vous avez fait et pourquoi (données → EDA → stationnarité → modèles → évaluation)."),
  #         tags$li(B("Résultats"), " : ce que vous avez observé (stats, figures, tests, métriques, modèle final)."),
  #         tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
  #       ),
  #       
  #       H5("Pack livrable propre (checklist)"),
  #       UL(
  #         tags$li("Notebook/script reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
  #         tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC."),
  #         tags$li("Tableau : candidats vs AICc/BIC vs Ljung–Box vs MAE/RMSE vs benchmark.")
  #       ),
  #       
  #       # === ADD: rapporter correctement les prévisions ===
  #       H5("Rapporter correctement les prévisions"),
  #       UL(
  #         tags$li(B("Niveau de couverture"), " : préciser 80% et/ou 95% ; indiquer si log-échelle a été reconvertie."),
  #         tags$li(B("Biais de reconversion (log→niveau)"), " : mentionner correction ",
  #                 C("exp(\\hat{y}) \\times exp(\\hat{\\sigma}^2/2)"), " si utilisée."),
  #         tags$li(B("Reproductibilité"), " : versions R/packages, seed, chemin des données, date d’extraction.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Phrase finale (APA) — modèle final + interprétation"),
  #       P("« Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). ",
  #         "Les résidus étant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a été capturée. ",
  #         "Les prévisions produites à horizon h=[..] améliorent le benchmark [..] selon MAE/RMSE, ce qui soutient l’usage du modèle pour l’application ciblée. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le rapport est aligné, justifié, reproductible. »"),
  #         tags$li(B("Signification : "),
  #                 "« un lecteur externe peut reproduire vos résultats et comprendre chaque choix (transformation, d/D, sélection, diagnostics). »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Ne pas relier choix → preuves"), " : chaque décision doit être liée à EDA/tests/diagnostics."),
  #         tags$li(B("Trop de texte, pas assez de figures"), " : en séries temporelles, les figures sont des résultats."),
  #         tags$li(B("Oublier de préciser l’échelle"), " : niveau vs log vs Box–Cox et reconversion des prévisions.")
  #       )
  #     )
  #   )
  #   
  #   # (10) Annexes
  #   pages[[11]] <- make_step(
  #     step_names[11],
  #     
  #     actions_ui = tagList(
  #       Checklist(
  #         CheckItem("Reconnaitre et pouvoir ecrire les trois benchmarks (naif, drift, SNAIVE) et expliquer quand chacun est approprie."),
  #         CheckItem("Savoir lire rapidement un resultat ADF/KPSS/PP et traduire la conclusion en choix de d et D."),
  #         CheckItem("Savoir expliquer ce que signifie Ljung-Box significatif (structure residuelle) et quelle action entreprendre."),
  #         CheckItem("Memoriser les formules utiles (AIC/AICc/BIC, Ljung-Box, operateurs de differenciation) et leur interpretation."),
  #         CheckItem("Identifier quand il faut sortir du cadre SARIMA (exogenes, multiples saisonnalites, ruptures, variance conditionnelle).")
  #       ),
  #       
  #       H5("Benchmarks (définitions)"),
  #       UL(
  #         tags$li(B("Naïf"), " : ", C("ŷ_{t+1|t} = y_t"), " (persistance)."),
  #         tags$li(B("Drift"), " : extrapolation linéaire moyenne."),
  #         tags$li(B("SNAIVE"), " : répète la dernière valeur de la même saison : ", C("ŷ_{t+h|t} = y_{t+h-s}"), ".")
  #       ),
  #       
  #       H5("Règles d’interprétation ultra rapides"),
  #       UL(
  #         tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " → stationnarité plausible."),
  #         tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " → différenciation nécessaire."),
  #         tags$li(B("Ljung–Box significatif"), " → il reste de la structure → réviser le modèle.")
  #       ),
  #       
  #       # === ADD: formules utiles & pistes avancées ===
  #       H5("Formules utiles (mémo)"),
  #       UL(
  #         tags$li(B("Critères d’info"), " : ",
  #                 C("AIC=-2\\log L+2k"), ", ",
  #                 C("AICc= AIC + \\frac{2k(k+1)}{n-k-1}"), ", ",
  #                 C("BIC=-2\\log L+k\\log n"), "."),
  #         tags$li(B("MASE"), " : ", C("\\frac{\\frac{1}{T}\\sum_{t}|e_t|}{\\frac{1}{T-s}\\sum_{t}|y_t-y_{t-s}|}"), " (pour périodicité ", C("s"), ")."),
  #         tags$li(B("Ljung–Box"), " : ", C("Q^* = n(n+2)\\sum_{k=1}^{L} \\frac{\\hat{\\rho}_k^2}{n-k}"),
  #                 " ~ ", C("\\chi^2"), " sous ", C("H_0"), " avec ddl ≈ ", C("L - p - q - (P+Q)"), "."),
  #         tags$li(B("Backshift & diff."), " : ",
  #                 C("\\nabla=(1-B)"), ", ", C("\\nabla_s=(1-B^s)"), ", ",
  #                 C("\\nabla^d \\nabla_s^D y_t"), " pour stationnariser.")
  #       ),
  #       H5("Pistes avancées (pour l’enseignant)"),
  #       UL(
  #         tags$li(B("SARIMAX / régression dynamique"), " : variables exogènes, pré-blanchiment, fonctions de transfert."),
  #         tags$li(B("Ruptures/Interventions"), " : dummies LS/TC, estimation avec régresseurs."),
  #         tags$li(B("Multiples saisonnalités"), " : TBATS/ETS-MS si présence de s multiples.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Template “Conclusion tests → choix (d,D)” (copier-coller)"),
  #       P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
  #         "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnarité, ",
  #         "nous concluons que la série est [stationnaire/non-stationnaire] au sens des diagnostics combinés. ",
  #         "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une série stationnaire pour l’estimation SARIMA. »"),
  #       
  #       H5("Signification (traduction simple)"),
  #       UL(
  #         tags$li("« d et D disent combien de fois on doit “retirer” une tendance et une saisonnalité non stationnaire. »"),
  #         tags$li("« Ensuite, p/q/P/Q décrivent la dépendance restante (mémoire) dans la série transformée. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Croire qu’un test “décide” seul"), " : toujours trianguler avec EDA + ACF + comportement après différenciation."),
  #         tags$li(B("Oublier la finalité"), " : prévision (out-of-sample) + diagnostics passent avant l’esthétique d’un AIC."),
  #         tags$li(B("Ne pas documenter"), " : un bon modèle non documenté = inutilisable dans un cours/rapport.")
  #       )
  #     )
  #   )
  #   
  #   # ========= Output =========
  #   tagList(
  #     css,
  #     tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
  #     progress_ui,
  #     pages[[cur + 1L]]
  #   )
  # })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  # # --- Roadmap slider navigation (Prev/Next) ---
  # observeEvent(input$road_prev, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  # }, ignoreInit = TRUE)
  # 
  # observeEvent(input$road_next, {
  #   cur <- input$roadmap_step
  #   if (is.null(cur)) cur <- 0
  #   updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  # }, ignoreInit = TRUE)
  # 
  # # =========================
  # # Roadmap UI (controls)
  # # =========================
  # output$roadmap_Detailed_Fr_ui4 <- renderUI({
  #   
  #   tags$div(
  #     style = "background:#f7f7f7;padding:14px;border-radius:10px;",
  #     
  #     tags$style(HTML("
  #     .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #     .road-title {margin:0 0 8px 0;}
  #     .road-sub {margin:0 0 12px 0; color:#555;}
  #     .road-nav {display:flex; gap:10px; align-items:center; flex-wrap:wrap;}
  #     .road-nav .btn {min-width:46px;}
  #     details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #     details > summary {cursor:pointer;font-weight:600;}
  #     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #     code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #     .progress {height:10px; margin:10px 0 0 0;}
  #   ")),
  #     
  #     tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
  #     tags$p(class="road-sub",
  #            "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
  #     
  #     tags$div(
  #       class = "road-nav",
  #       actionButton("road_prev", "◀", class = "btn btn-default"),
  #       sliderInput(
  #         "roadmap_step", label = NULL,
  #         min = 0, max = 10, value = 0, step = 1, width = "520px"
  #       ),
  #       actionButton("road_next", "▶", class = "btn btn-default"),
  #       tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
  #     ),
  #     
  #     # Progress bar (pure UI, updated via re-render of content)
  #     shiny::uiOutput("roadmap_step_content")
  #   )
  # })
  # 
  # # =========================
  # # Roadmap UI (content)
  # # =========================
  # output$roadmap_step_content <- renderUI({
  #   
  #   # ========= Helpers =========
  #   D <- function(title, ...) {
  #     tags$details(
  #       tags$summary(title),
  #       tags$div(class = "road-scroll", ...)
  #     )
  #   }
  #   UL <- function(...) tags$ul(...)
  #   OL <- function(...) tags$ol(...)
  #   P  <- function(...) tags$p(...)
  #   B  <- function(...) tags$b(...)
  #   C  <- function(...) tags$code(...)
  #   H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
  #   
  #   # ========= Checklist helpers (UI only) =========
  #   # These are intentionally simple visual checklists (no reactive logic).
  #   # Pedagogical goal: help students translate “read/explain” into
  #   # concrete actions they can verify before moving to the next step.
  #   CheckItem <- function(...) {
  #     tags$li(
  #       tags$span(class = "chkbox", "☐"),
  #       tags$span(...)
  #     )
  #   }
  #   Checklist <- function(...) {
  #     tags$div(
  #       class = "callout",
  #       tags$b("Checklist étudiant"),
  #       tags$ul(class = "chk", ...)
  #     )
  #   }
  #   
  #   
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  #   
  #   # ========= CSS (internal scroll so the page stays short) =========
  #   css <- tags$style(HTML("
  #   .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:10px;padding:14px;margin-top:12px;}
  #   details {background:#ffffff;border:1px solid #eaeaea;border-radius:10px;padding:10px 12px;margin:10px 0;}
  #   details > summary {cursor:pointer;font-weight:700;}
  #   .road-scroll {max-height: 62vh; overflow-y: auto; padding-right: 10px;}
  #   .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #   .callout.warn {border-left-color:#E45756; background:#fff7f7;}
  #   .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
  #   code {background:#f3f3f3; padding:0 3px; border-radius:3px;}
  #   .progress {height:10px; margin:10px 0 0 0;}
  #   /* Checklist: checkbox-style bullets */
  #   ul.chk {padding-left: 0; margin: 8px 0 0 0;}
  #   ul.chk li {list-style: none; margin: 6px 0;}
  #   .chkbox {display:inline-block; width: 18px; font-weight: 700; margin-right: 6px;}
  # "))
  #   
  #   # ========= Step logic =========
  #   cur <- input$roadmap_step
  #   if (is.null(cur) || !is.finite(cur)) cur <- 0
  #   cur <- as.integer(cur)
  #   
  #   step_names <- c(
  #     "Aperçu & notations (glossaire + lecture du modèle)",
  #     "Étape 0 — Définir le problème de modélisation",
  #     "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
  #     "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
  #     "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
  #     "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
  #     "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
  #     "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
  #     "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
  #     "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
  #     "Annexes — Formules, checklists, templates, interprétations rapides"
  #   )
  #   
  #   pct <- round(100 * cur / 10)
  #   progress_ui <- tags$div(
  #     class="progress",
  #     tags$div(
  #       class="progress-bar",
  #       role="progressbar",
  #       `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
  #       style = paste0("width:", pct, "%;")
  #     )
  #   )
  #   
  #   make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
  #     tags$div(
  #       class = "road-card",
  #       if (!is.null(header_ui)) header_ui,
  #       tags$h4(title),
  #       D("1) Ce que l’étudiant fait (procédure + définitions + objectifs)", actions_ui),
  #       D("2) Ce qu’il écrit (APA) + conclusion & signification", apa_ui),
  #       D("3) Pièges + comment les éviter (avec interprétation)", pitfalls_ui)
  #     )
  #   }
  #   
  #   # ========= Pages =========
  #   pages <- vector("list", length = 11)
  #   
  #   # (0) Aperçu
  #   pages[[1]] <- make_step(
  #     step_names[1],
  #     
  #     actions_ui = tagList(
  #       callout(
  #         B("Objectif global : "),
  #         "construire un modèle SARIMA interprétable et surtout ",
  #         B("prédictif"), " : il doit passer les diagnostics résiduels et battre un benchmark simple.",
  #         type="ok"
  #       ),
  #       
  #       Checklist(
  #         CheckItem("Identifier clairement la série y_t (ce que vous cherchez à prévoir), préciser son unité, sa source et le contexte d’application (ex. ventes mensuelles, débit quotidien, température horaire)."),
  #         CheckItem("Fixer la période saisonnière s à partir du contexte et vérifier qu’elle est cohérente avec l’échantillonnage (ex. s=12 pour mensuel, s=7 pour hebdomadaire, s=4 pour trimestriel)."),
  #         CheckItem("Lire la forme générale du SARIMA et expliquer le rôle de chaque bloc : différenciation (d, D) pour stationnariser, puis composantes AR/MA (p, q, P, Q) pour modéliser la dépendance restante."),
  #         CheckItem("Énoncer des critères de validation explicites : résidus ≈ bruit blanc (ACF résidus + Ljung–Box), performance hors‑échantillon (train/test ou rolling-origin) et parcimonie (le plus simple qui marche)."),
  #         CheckItem("Choisir un benchmark (naïf / drift / SNAIVE), l’écrire noir sur blanc et expliquer pourquoi il est pertinent : sans repère, on ne peut pas juger la valeur ajoutée d’un SARIMA.")
  #       ),
  #       
  #       
  #       H5("Notations essentielles (définitions)"),
  #       UL(
  #         tags$li(B("Série temporelle"), " : suite ordonnée d’observations indexées par le temps ", C("y_t"), "."),
  #         tags$li(B("Fréquence / période saisonnière"), " : nombre de pas par cycle saisonnier, noté ", C("s"),
  #                 " (ex. mensuel s=12; quotidien avec saison hebdo s=7)."),
  #         tags$li(B("Opérateur de retard (backshift)"), " : ", C("B y_t = y_{t-1}"), "."),
  #         tags$li(B("Différenciation ordinaire"), " : ", C("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
  #                 " ; appliquée ", C("d"), " fois → supprimer tendance/racine unitaire non saisonnière."),
  #         tags$li(B("Différenciation saisonnière"), " : ", C("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
  #                 " ; appliquée ", C("D"), " fois → supprimer racine unitaire saisonnière."),
  #         tags$li(B("Innovations / bruit blanc"), " : ", C("ε_t ~ w.n.(0, σ²)"),
  #                 " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
  #       ),
  #       
  #       H5("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)"),
  #       UL(
  #         tags$li(
  #           "Écriture compacte : ",
  #           C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
  #         ),
  #         tags$li(
  #           B("Interprétation : "),
  #           "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
  #           "non saisonnières (p,q) et saisonnières (P,Q)."
  #         )
  #       ),
  #       
  #       H5("Ce que signifie “bon modèle” (définition opérationnelle)"),
  #       OL(
  #         tags$li(B("Résidus ~ bruit blanc"), " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."),
  #         tags$li(B("Performance out-of-sample"), " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."),
  #         tags$li(B("Parcimonie"), " : modèle le plus simple possible à performance comparable.")
  #       ),
  #       
  #       # === ADD: Glossaire étendu, critères info, estimation ===
  #       H5("Glossaire étendu (ajouts importants)"),
  #       UL(
  #         tags$li(B("Polynômes AR/MA"), " : ",
  #                 C("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), ", ",
  #                 C("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), "; saisonnier ",
  #                 C("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), ", ",
  #                 C("Θ(B^s) = 1 + Θ_1 B^s + ... + Θ_Q B^{Qs}"), "."),
  #         tags$li(B("Stabilité/causalité (AR)"), " : toutes les racines de ", C("φ(z)=0"),
  #                 " et ", C("Φ(z^s)=0"), " sont ", B("hors"), " du cercle unité → processus stationnaire."),
  #         tags$li(B("Inversibilité (MA)"), " : racines de ", C("θ(z)=0"), " et ", C("Θ(z^s)=0"),
  #                 " hors du cercle unité → représentation AR(∞) bien définie."),
  #         tags$li(B("Constante / drift"), " : une constante dans un ARIMA avec ", C("d=1"),
  #                 " implique une ", B("pente moyenne"), " (drift) après différenciation ; le terme est souvent noté ",
  #                 C("c"), " et la tendance moyenne vaut environ ", C("c"), " par pas."),
  #         tags$li(B("Représentation état–espace"), " : tout ARIMA/SARIMA peut être écrit sous forme état–espace ",
  #                 "et estimé/filtré par Kalman (utile pour manquants et lissage)."),
  #         tags$li(B("Prévision : point vs intervalle vs densité"),
  #                 " : point = ", C("ŷ"), "; intervalle = incertitude (80%/95%); densité = distribution prédictive complète.")
  #       ),
  #       H5("Critères d’information (définitions)"),
  #       UL(
  #         tags$li(B("AIC"), " : ", C("AIC = -2 \\log L + 2k"), " (", C("k"), " = nb paramètres estimés)."),
  #         tags$li(B("AICc"), " : correction petits échantillons → préférable si ", C("n/k"), " n’est pas grand."),
  #         tags$li(B("BIC"), " : ", C("BIC = -2 \\log L + k \\log n"), " ; pénalise plus la complexité (favorise parcimonie).")
  #       ),
  #       H5("Estimation (comment sont estimés les paramètres)"),
  #       UL(
  #         tags$li(B("MLE vs CSS+MLE"), " : estimation par maximum de vraisemblance (souvent via optim) ; ",
  #                 "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."),
  #         tags$li(B("Écarts-types et tests z"), " : reportez estimations ± SE, z et p pour l’interprétation des coefficients.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Phrase APA (modèle + notations)"),
  #       P("« Nous avons ajusté un modèle SARIMA afin de capturer la dépendance temporelle et la saisonnalité de la série ",
  #         C("y_t"), ". La spécification générale est ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
  #         " avec ", C("ε_t"), " un bruit blanc. Le choix de (d, D) a été justifié par des tests de stationnarité (ADF/KPSS/PP) et des diagnostics. »"),
  #       
  #       H5("Conclusion & signification (à expliciter)"),
  #       UL(
  #         tags$li(B("Conclusion type : "), "« Le modèle final est adéquat »"),
  #         tags$li(B("Signification : "), "« (i) il ne laisse pas d’information autocorrélée dans les résidus, ",
  #                 "(ii) il généralise bien sur une fenêtre future, ",
  #                 "(iii) il est suffisamment simple pour être stable et reproductible. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       H5("Pièges classiques"),
  #       UL(
  #         tags$li(B("Confondre AIC faible et bon modèle"), " : un AIC très bas avec résidus autocorrélés = modèle mal spécifié."),
  #         tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naïf, impossible de dire si SARIMA apporte réellement quelque chose."),
  #         tags$li(B("Surcharger le modèle"), " : trop de paramètres → instabilité, intervalles de prévision peu fiables.")
  #       )
  #     )
  #   )
  #   
  #   # (1) Étape 0 — Définition du problème
  #   pages[[2]] <- make_step(
  #     step_names[2],
  #     
  #     actions_ui = tagList(
  #       callout(
  #         B("But : "),
  #         "définir un problème de prévision mesurable (horizon, métriques, protocole).",
  #         type="info"
  #       ),
  #       
  #       Checklist(
  #         CheckItem("Définir la variable y_t (cible) et la fréquence temporelle (jour, semaine, mois) sans ambiguite."),
  #         CheckItem("Fixer l’horizon h en fonction de l’usage reel (decision, planification, stock, etc.)."),
  #         CheckItem("Choisir un protocole d’evaluation temporelle (train/test ou rolling-origin) et expliquer pourquoi."),
  #         CheckItem("Choisir des metriques (MAE + RMSE recommande) et justifier leur interpretation."),
  #         CheckItem("Decider si une transformation (log / Box-Cox) est necessaire et noter la raison.")
  #       ),
  #       
  #       H5("Définitions (ce que chaque terme veut dire)"),
  #       UL(
  #         tags$li(B("Série réponse"), " ", C("y_t"), " : variable à prédire (univariée)."),
  #         tags$li(B("Horizon"), " ", C("h"), " : nombre de pas à prévoir (ex. h=12 mois)."),
  #         tags$li(B("Origine de prévision"), " : dernier temps observé à partir duquel on prévoit."),
  #         tags$li(B("Protocole train/test"), " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."),
  #         tags$li(B("Rolling-origin / validation temporelle"), " : on répète des prévisions à différentes origines pour estimer la performance moyenne."),
  #         tags$li(B("SARIMA vs SARIMAX"), " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes.")
  #       ),
  #       
  #       H5("Choisir les métriques (définitions + quand utiliser)"),
  #       UL(
  #         tags$li(B("MAE"), " : moyenne des erreurs absolues ", C("mean(|y-ŷ|)"),
  #                 " → robuste, facile à interpréter (unité de y)."),
  #         tags$li(B("RMSE"), " : racine de l’erreur quadratique moyenne ", C("sqrt(mean((y-ŷ)^2))"),
  #                 " → pénalise plus les grosses erreurs."),
  #         tags$li(B("MAPE"), " : ", C("mean(|(y-ŷ)/y|)"),
  #                 " → éviter si y proche de 0 (explose)."),
  #         tags$li(B("sMAPE"), " : alternative plus stable près de 0 : ", C("mean(2|y-ŷ|/(|y|+|ŷ|))"), ".")
  #       ),
  #       
  #       H5("Transformation (définitions + justification)"),
  #       UL(
  #         tags$li(B("Niveaux"), " : modèle sur les valeurs brutes."),
  #         tags$li(B("Log-niveaux"), " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."),
  #         tags$li(B("Box–Cox"), " : transformation paramétrique (λ) pour stabiliser variance et améliorer normalité : ",
  #                 C("y^(λ) = (y^λ - 1)/λ"), " (λ≠0), et log si λ=0.")
  #       ),
  #       
  #       H5("Procédure minimale (checklist)"),
  #       OL(
  #         tags$li("Fixer fréquence et période saisonnière s."),
  #         tags$li("Fixer horizon h et fenêtres train/test (ou rolling-origin)."),
  #         tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
  #         tags$li("Décider transformation (aucune/log/Box–Cox) et justifier.")
  #       ),
  #       
  #       # === ADD: précisions pratiques, métriques complémentaires, transformations ===
  #       H5("Précisions supplémentaires (définitions pratiques)"),
  #       UL(
  #         tags$li(B("Horizon multi-pas"), " : ", C("h>1"),
  #                 " → la performance peut décroître avec l’horizon ; rapporter MAE/RMSE par h si possible."),
  #         tags$li(B("Fenêtre d’entraînement"), " : ", B("expansive"), " (on ne jette jamais d’anciens points) ",
  #                 "ou ", B("glissante"), " (fenêtre fixe) ; documenter le choix."),
  #         tags$li(B("Reproductibilité"), " : fixer les graines aléatoires, consigner versions des packages, chemins de données."),
  #         tags$li(B("Prévision hiérarchique"), " (annexe) : si agrégations (mois→trimestres), noter la cohérence temporelle.")
  #       ),
  #       H5("Métriques supplémentaires (quand utiles)"),
  #       UL(
  #         tags$li(B("MASE"), " : erreur absolue mise à l’échelle par le naïf saisonnier → comparable entre séries."),
  #         tags$li(B("WAPE"), " : ", C("sum(|y-ŷ|)/sum(|y|)"), " ; lisible comme % d’erreur agrégée."),
  #         tags$li(B("Pinball loss (quantiles)"), " : si vous prédisez des quantiles (IC asymétriques).")
  #       ),
  #       H5("Transformations complémentaires"),
  #       UL(
  #         tags$li(B("Yeo–Johnson"), " : alternative à Box–Cox qui gère les valeurs ≤ 0."),
  #         tags$li(B("Stabilisation de variance"), " : vérifier relation niveau–variance (nuage points moyenne locale vs ET).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — modèle de phrase complet"),
  #       P("« Nous avons modélisé la série temporelle univariée ", C("y_t"),
  #         " observée à une fréquence [..] (période saisonnière s=[..]). ",
  #         "L’objectif était de produire des prévisions à horizon ", C("h"), "=[..]. ",
  #         "La performance a été évaluée sur une fenêtre future selon [split temporel / rolling-origin] ",
  #         "à l’aide de [MAE, RMSE]. Une transformation [aucune / log / Box–Cox] a été appliquée afin de [stabiliser la variance / linéariser la saisonnalité]. »"),
  #       
  #       H5("Conclusion & signification (comment l’expliquer)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Notre problème est bien défini (h, métriques, protocole). »"),
  #         tags$li(B("Signification : "), "« Toute comparaison de modèles devient juste : même horizon, même protocole, mêmes métriques. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) → performance artificiellement élevée."),
  #         tags$li(B("Métrique mal choisie"), " : MAPE avec y≈0 → conclusions fausses."),
  #         tags$li(B("Horizon incohérent"), " : un modèle bon à h=1 peut être mauvais à h=12 ; fixer l’horizon selon l’usage réel.")
  #       )
  #     )
  #   )
  #   
  #   # (2) Étape 1 — Description des données
  #   pages[[3]] <- make_step(
  #     step_names[3],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "décrire la qualité des données et rendre le pipeline reproductible.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Verifier que l’index temporel est regulier (pas manquants/dupliques, ordre correct)."),
  #         CheckItem("Rapporter n, date debut/fin, frequence, et la couverture temporelle."),
  #         CheckItem("Quantifier les manquants (k et %) et choisir une strategie (interpolation, saisonniere, Kalman) avec justification."),
  #         CheckItem("Produire un resume statistique (moyenne, mediane, ET, min/max) et un resume saisonnier (par mois/semaine)."),
  #         CheckItem("Documenter toute correction (doublons, valeurs aberrantes evidentes) pour garantir la reproductibilite.")
  #       ),
  #       
  #       H5("Ce qu’il faut rapporter (définitions)"),
  #       UL(
  #         tags$li(B("n"), " : nombre total d’observations disponibles."),
  #         tags$li(B("Couverture"), " : date début/fin."),
  #         tags$li(B("Fréquence"), " : périodicité (mensuel/hebdo/quotidien)."),
  #         tags$li(B("Manquants"), " : nombre k et pourcentage k/n.")
  #       ),
  #       
  #       H5("Valeurs manquantes : types + implications"),
  #       UL(
  #         tags$li(B("MCAR"), " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."),
  #         tags$li(B("MAR"), " (At Random conditionnel) : dépend d’autres infos → imputation possible mais à justifier."),
  #         tags$li(B("MNAR"), " (Not At Random) : dépend de la valeur elle-même → risque de biais important.")
  #       ),
  #       
  #       H5("Stratégies de traitement (quand et pourquoi)"),
  #       UL(
  #         tags$li(B("Interpolation linéaire"), " : si manquants rares et pas de ruptures."),
  #         tags$li(B("Interpolation saisonnière"), " : si saisonnalité stable (ex. remplacer par moyenne du même mois)."),
  #         tags$li(B("Modèle d’état / Kalman"), " : si on veut une imputation plus probabiliste."),
  #         tags$li(B("Suppression"), " : seulement si extrêmement rare et sans impact sur la continuité.")
  #       ),
  #       
  #       H5("Descriptifs pertinents (au-delà de la moyenne)"),
  #       UL(
  #         tags$li("Moyenne, médiane, ET, min/max (niveau)."),
  #         tags$li("Asymétrie (skewness) / kurtosis si utile."),
  #         tags$li("Résumé saisonnier (ex. moyenne par mois), pour documenter saisonnalité.")
  #       ),
  #       
  #       # === ADD: qualité index & manquants pratiques ===
  #       H5("Qualité de l’index temporel (définitions)"),
  #       UL(
  #         tags$li(B("Régularité"), " : pas de pas manqué/dupliqué ; cadence constante."),
  #         tags$li(B("Fuseau/DST"), " : données horaires → attention aux heures manquantes/dupliquées (passage DST)."),
  #         tags$li(B("Doublons et horodatages hors ordre"), " : à corriger avant tout calcul d’ACF.")
  #       ),
  #       H5("Manquants — remarques pratiques"),
  #       UL(
  #         tags$li(B("Kalman/StructTS"), " : imputation probabiliste cohérente avec la dynamique ARIMA."),
  #         tags$li(B("Imputation “saison identique”"), " : moyenne/médiane du même mois/jour si saisonnalité stable."),
  #         tags$li(B("Zéros structurels"), " : distinguer “zéro” réel de manquant imputé à 0 (documenter).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — description"),
  #       P("« La série contient ", C("n"), "=[..] observations couvrant [..] à [..] à une fréquence [..]. ",
  #         "Les valeurs manquantes représentaient [..]% (k=[..]) et ont été traitées par [..], ",
  #         "choisie car [manquants rares / saisonnalité stable / continuité nécessaire]. ",
  #         "La série présentait une moyenne de [..] (ET=[..]) et une médiane [..]. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Les données sont suffisamment propres pour SARIMA » (ou non)."),
  #         tags$li(B("Signification : "),
  #                 "si l’index est régulier et que les manquants sont gérés explicitement, ",
  #                 "les hypothèses du modèle (espacement régulier) deviennent plausibles.")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Imputation silencieuse"), " : toujours documenter méthode + raison."),
  #         tags$li(B("Timestamps irréguliers"), " : SARIMA suppose une grille régulière ; corriger avant toute estimation."),
  #         tags$li(B("Changement de définition de la variable"), " : ex. changement de mesure → rupture structurelle à traiter.")
  #       )
  #     )
  #   )
  #   
  #   # (3) Étape 2 — EDA
  #   pages[[4]] <- make_step(
  #     step_names[4],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant d’ajuster SARIMA.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Tracer la serie y_t et annoter tendance, saisonnalite, ruptures possibles et changements de variance."),
  #         CheckItem("Construire au moins un graphique saisonnier (seasonal plot ou subseries) pour comprendre la forme par saison."),
  #         CheckItem("Identifier les outliers (dates) et formuler une hypothese (evenement reel vs erreur)."),
  #         CheckItem("Decider et documenter le traitement des outliers (conserver/corriger/imputer) et tester l’impact sur l’analyse."),
  #         CheckItem("Noter ce que l’EDA implique pour la suite: transformation possible, differenciation probable, et presence de ruptures.")
  #       ),
  #       
  #       H5("Définitions utiles (ce qu’on cherche)"),
  #       UL(
  #         tags$li(B("Tendance"), " : évolution de long terme (déterministe ou stochastique)."),
  #         tags$li(B("Saisonnalité"), " : motif périodique de période s (ex. 12)."),
  #         tags$li(B("Rupture structurelle"), " : changement durable de niveau/tendance/variance (ex. politique, crise)."),
  #         tags$li(B("Outlier"), " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou erreur.")
  #       ),
  #       
  #       H5("Graphiques recommandés + leur but"),
  #       UL(
  #         tags$li(B("Courbe y_t"), " : voir tendance, variance, ruptures."),
  #         tags$li(B("Seasonal plot"), " : comparer la forme saisonnière d’une année à l’autre."),
  #         tags$li(B("Boxplots par saison"), " : détecter asymétrie/outliers par mois/semaine."),
  #         tags$li(B("ACF brute"), " (optionnel) : repérer dépendances fortes et saisonnalité.")
  #       ),
  #       
  #       H5("Outliers : procédure raisonnable"),
  #       OL(
  #         tags$li("Repérer visuellement (dates)."),
  #         tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
  #         tags$li("Décider : conserver / corriger / imputer (et justifier)."),
  #         tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
  #       ),
  #       
  #       # === ADD: outils EDA supplémentaires & typologie outliers ===
  #       H5("Outils EDA supplémentaires"),
  #       UL(
  #         tags$li(B("Périodogramme / spectre"), " : met en évidence des fréquences saisonnières inattendues."),
  #         tags$li(B("Seasonal subseries plot"), " : visualise la forme saisonnière par mois/semaine."),
  #         tags$li(B("Nuage niveau–variance"), " : aide au choix log/Box–Cox (variance croît avec le niveau ?).")
  #       ),
  #       H5("Types d’outliers (interventions)"),
  #       UL(
  #         tags$li(B("AO"), " : Additive Outlier (pic ponctuel)."),
  #         tags$li(B("IO"), " : Innovation Outlier (choc qui diffuse)."),
  #         tags$li(B("LS"), " : Level Shift (changement de niveau)."),
  #         tags$li(B("TC"), " : Temporary Change (effet transitoire).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — EDA"),
  #       P("« L’inspection visuelle a mis en évidence une tendance [..] et une saisonnalité récurrente de période s=[..]. ",
  #         "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Box–Cox]. ",
  #         "Des valeurs atypiques autour de [dates] ont été [conservées/traitées] car [événement réel / erreur probable]. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« La structure (tendance/saison/variance/outliers) est comprise »"),
  #         tags$li(B("Signification : "),
  #                 "cela guide directement le choix transformation + différenciations (d, D) et évite d’ajuster un SARIMA “à l’aveugle”.")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Confondre saisonnalité et tendance"), " : une moyenne croissante ET une saisonnalité stable sont deux composantes distinctes."),
  #         tags$li(B("Retirer des points réels"), " : si l’outlier correspond à un événement récurrent (fêtes), il doit rester."),
  #         tags$li(B("Ignorer une rupture"), " : un SARIMA “moyenne” une structure qui a changé → mauvais futur.")
  #       )
  #     )
  #   )
  #   
  #   # (4) Étape 3 — Décomposition
  #   pages[[5]] <- make_step(
  #     step_names[5],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "séparer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Comparer visuellement une hypothese additive vs multiplicative (amplitude saisonniere constante vs proportionnelle au niveau)."),
  #         CheckItem("Tester l’idee de transformation log/Box-Cox si la variance augmente avec le niveau."),
  #         CheckItem("Realiser une decomposition (classique ou STL) et commenter la tendance, la saisonnalite et le residu."),
  #         CheckItem("Verifier si la saisonnalite semble stable ou evolutive (argument pour STL)."),
  #         CheckItem("Ecrire clairement ce que la decomposition suggere pour d, D, et pour l’echelle de modelisation.")
  #       ),
  #       
  #       H5("Décomposition : définitions"),
  #       UL(
  #         tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
  #                 " (amplitude saisonnière ~ constante)."),
  #         tags$li(B("Multiplicative"), " : ", C("y_t = T_t × S_t × e_t"),
  #                 " (amplitude saisonnière augmente avec le niveau)."),
  #         tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
  #                 C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
  #         tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
  #       ),
  #       
  #       H5("Pourquoi STL ? (objectif détaillé)"),
  #       UL(
  #         tags$li("Quand la saisonnalité change lentement au fil du temps (non parfaitement répétitive)."),
  #         tags$li("Quand on veut réduire l’influence des outliers sur l’estimation saison/tendance."),
  #         tags$li("Quand on veut une lecture pédagogique claire (tendance vs saison vs résidu).")
  #       ),
  #       
  #       H5("Ce que la décomposition ne remplace pas"),
  #       UL(
  #         tags$li("Elle ne prouve pas la stationnarité : SARIMA exige une série stationnaire après différenciation."),
  #         tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nécessaires.")
  #       ),
  #       
  #       # === ADD: paramètres STL & règles pratiques ===
  #       H5("Paramètres STL (lecture pédagogique)"),
  #       UL(
  #         tags$li(B("s.window"), " : lissage saisonnier (", C("periodic"), " = saison constante; entier = évolutive)."),
  #         tags$li(B("t.window"), " : lissage de la tendance (fenêtre LOESS)."),
  #         tags$li(B("robust"), " : réduit l’influence des outliers (itérations avec poids).")
  #       ),
  #       H5("Additif vs multiplicatif (règle pratique)"),
  #       UL(
  #         tags$li("Amplitude saisonnière ~ proportionnelle au niveau → penser ", B("log"), " ou modèle multiplicatif."),
  #         tags$li("Amplitude ~ constante → additif sur niveaux.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Décomposition"),
  #       P("« Nous avons étudié une structure additive vs multiplicative en évaluant si l’amplitude saisonnière variait avec le niveau. ",
  #         "Comme [..], nous avons retenu [modèle additif / transformation log] et réalisé une décomposition via [classique / STL]. ",
  #         "STL a été privilégiée pour sa flexibilité (saisonnalité évolutive) et sa robustesse aux valeurs atypiques. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le choix additif/multiplicatif est justifié »"),
  #         tags$li(B("Signification : "),
  #                 "on évite des résidus hétéroscédastiques et on améliore la stabilité de l’estimation SARIMA.")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Décomposition ≠ stationnarité"), " : après décomposition, on doit encore tester/choisir d et D."),
  #         tags$li(B("Oublier l’échelle"), " : si vous modélisez log(y), les prévisions doivent être reconverties (avec prudence)."),
  #         tags$li(B("Confondre bruit et structure"), " : des motifs résiduels persistants suggèrent que la saison/tendance n’a pas été correctement capturée.")
  #       )
  #     )
  #   )
  #   
  #   # (5) Étape 4 — Stationnarité (très détaillé : ADF/KPSS/PP + …)
  #   pages[[6]] <- make_step(
  #     step_names[6],
  #     
  #     actions_ui = tagList(
  #       callout(
  #         B("Idée centrale : "),
  #         "Dans un SARIMA, on n’essaie pas de modéliser directement une série ‘qui dérive’ : on cherche d’abord à obtenir une série stationnaire (au moins approximativement) via la différenciation. Les tests ADF, PP et KPSS ne sont pas des “juges” absolus, mais des indices complémentaires qui aident à justifier les choix (d, D) de façon argumentée.",
  #         type = "ok"
  #       ),
  #       
  #       Checklist(
  #         CheckItem("Définir la stationnarité avec vos mots (moyenne/variance stables; dépendance qui ne change pas au cours du temps)."),
  #         CheckItem("Appliquer ADF, KPSS et PP sur la série brute, puis écrire clairement H0 et Ha pour chacun (ils ne testent pas la même chose)."),
  #         CheckItem("Proposer d et D de manière progressive (essayer d=1 puis D=1 si nécessaire) et re-tester après chaque transformation."),
  #         CheckItem("Surveiller les signes de sur‑différenciation (ACF lag 1 très négative, variance gonflée, dynamique artificielle)."),
  #         CheckItem("Justifier le choix final (d, D, s) par convergence : tests + graphiques + ACF/PACF, pas par une seule p‑value.")
  #       ),
  #       
  #       
  #       H5("Définition : stationnarité (ce que cela veut dire)"),
  #       UL(
  #         tags$li(B("Stationnarité faible (covariance-stationnaire)"), " : moyenne constante, variance constante, ",
  #                 "et autocovariance dépend uniquement du retard (pas de t)."),
  #         tags$li(B("Non-stationnarité"), " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."),
  #         tags$li(B("Racine unitaire"), " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1).")
  #       ),
  #       
  #       H5("Différenciation : rôle (d vs D)"),
  #       UL(
  #         tags$li(B("d"), " enlève la racine unitaire non saisonnière / tendance stochastique : ", C("(1-B)^d"), "."),
  #         tags$li(B("D"), " enlève la racine unitaire saisonnière : ", C("(1-B^s)^D"), "."),
  #         tags$li(B("Règle pratique"), " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2).")
  #       ),
  #       
  #       H5("Test ADF (Augmented Dickey–Fuller) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."),
  #         tags$li(B("Régression (intuition)"), " : on teste si le coefficient de ", C("y_{t-1}"),
  #                 " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire (non-stationnaire) ; ",
  #                 B("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."),
  #         tags$li(B("Interprétation p-value"), " : p petit → rejet H0 → stationnarité (au sens ADF). p grand → on ne rejette pas → différenciation probablement nécessaire.")
  #       ),
  #       
  #       H5("Test KPSS — définition & objectif (inverse de l’ADF)"),
  #       UL(
  #         tags$li(B("But"), " : tester si la série est stationnaire (niveau ou tendance)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = stationnaire ; ",
  #                 B("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."),
  #         tags$li(B("Interprétation"), " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité.")
  #       ),
  #       
  #       H5("Test PP (Phillips–Perron) — définition & objectif"),
  #       UL(
  #         tags$li(B("But"), " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement (correction non-paramétrique)."),
  #         tags$li(B("Hypothèses"), " : ",
  #                 B("H0"), " = racine unitaire ; ",
  #                 B("Ha"), " = stationnaire."),
  #         tags$li(B("Pourquoi utile"), " : complément de robustesse ; si ADF et PP convergent, confiance accrue.")
  #       ),
  #       
  #       H5("Comment conclure en combinant ADF/KPSS/PP (logique complète)"),
  #       OL(
  #         tags$li(B("Stationnarité forte : "), "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."),
  #         tags$li(B("Non-stationnarité forte : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
  #         tags$li(B("Conflit : "), "les tests divergent → regarder graphiques, ACF, résultats après une différence, et justifier par convergence d’indices (pas une seule p-value).")
  #       ),
  #       
  #       H5("Procédure recommandée (pas à pas)"),
  #       OL(
  #         tags$li("Fixer ", B("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
  #         tags$li("Tester ADF/KPSS/PP sur la série brute."),
  #         tags$li("Essayer d=1 si nécessaire, retester."),
  #         tags$li("Essayer D=1 si saisonnalité/racine saisonnière, retester."),
  #         tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
  #       ),
  #       
  #       H5("Sur-différenciation : définition + symptômes"),
  #       UL(
  #         tags$li(B("Définition"), " : appliquer trop de différences → on introduit une dynamique artificielle."),
  #         tags$li(B("Symptômes fréquents"), " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."),
  #         tags$li(B("Conséquence"), " : intervalles de prévision plus larges et modèle moins fiable.")
  #       ),
  #       
  #       # === ADD: tests/bonnes pratiques complémentaires ===
  #       H5("Tests et notions complémentaires"),
  #       UL(
  #         tags$li(B("Tendance déterministe vs racine unitaire"),
  #                 " : on peut préférer un ARIMA avec ", C("d=0"), " et une tendance ", B("déterministe"),
  #                 " (régression + ARMA sur résidus) si la tendance semble stable."),
  #         tags$li(B("Racine unitaire saisonnière (HEGY)"), " : (annexe) test dédié aux racines à ", C("±1, ±i"), " pour ",
  #                 C("s=4,12"), " ; utile si la saisonnalité stochastique domine."),
  #         tags$li(B("Zivot–Andrews"), " : (annexe) racine unitaire avec rupture endogène possible.")
  #       ),
  #       H5("Bonnes pratiques de différenciation"),
  #       UL(
  #         tags$li(B("Au plus une différence"), " : commencer par ", C("d=1"), " ou ", C("D=1"),
  #                 " ; ", B("éviter"), " ", C("d=2"), " sauf preuves fortes."),
  #         tags$li(B("Sur-différenciation : "), "ACF lag 1 très négative, variance gonflée, MA artificiel → revenir en arrière.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — Tests & choix de (d, D)"),
  #       P("« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
  #         "Les résultats ont été examinés sur la série originale puis après différenciations ordinaires et saisonnières. ",
  #         "Sur la base de l’ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
  #         "afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA, tout en évitant la sur-différenciation. »"),
  #       
  #       H5("Conclusion test (prête à remplir) + signification"),
  #       UL(
  #         tags$li(B("ADF : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "si rejet → la série est compatible stationnarité (au sens ADF) ; sinon → différenciation probablement nécessaire."),
  #         tags$li(B("KPSS : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (stationnarité). ",
  #                 B("Signification : "),
  #                 "si rejet → non-stationnarité (donc d/D à augmenter ou transformation/rupture à traiter)."),
  #         tags$li(B("PP : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
  #                 " H0 (racine unitaire). ",
  #                 B("Signification : "),
  #                 "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
  #       ),
  #       
  #       H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Nous retenons d=[..], D=[..], s=[..]. »"),
  #         tags$li(B("Signification : "),
  #                 "« le SARIMA sera estimé sur la série différenciée ; les paramètres AR/MA décrivent la dynamique ",
  #                 "restante après retrait de la tendance et/ou de la saisonnalité non stationnaire. »")
  #       ),
  #       
  #       # === ADD: points à expliciter
  #       H5("À expliciter (rappel)"),
  #       UL(
  #         tags$li("Préciser si une constante/drift est incluse et à quel niveau (avant/après différenciation)."),
  #         tags$li("Documenter toute rupture suspectée et ses conséquences sur le choix de ", C("d, D"), ".")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Choisir d et D “par habitude”"), " : toujours justifier par tests + EDA."),
  #         tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent “crier non-stationnaire” alors qu’un changement de régime est en cause."),
  #         tags$li(B("Interpréter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on s’appuie sur convergence des preuves.")
  #       )
  #     )
  #   )
  #   
  #   # (6) Étape 5 — Auto-ARIMA baseline
  #   pages[[7]] <- make_step(
  #     step_names[7],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "obtenir un point de départ compétitif, puis vérifier/affiner.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Executer auto-ARIMA avec des bornes raisonnables sur p,q,P,Q et noter le critere (AICc) utilise."),
  #         CheckItem("Enregistrer le modele baseline (ordres + presence drift/constante) pour comparaison ulterieure."),
  #         CheckItem("Verifier diagnostics residuels (ACF residus, Ljung-Box) avant de le considerer ‘acceptable’."),
  #         CheckItem("Evaluer la performance sur la fenetre test (MAE/RMSE) et comparer au benchmark naif/SNAIVE."),
  #         CheckItem("Decider si vous cherchez une version plus parcimonieuse (BIC plus faible ou meme performance avec moins de parametres).")
  #       ),
  #       
  #       H5("Définition : auto-ARIMA (ce que fait réellement l’algorithme)"),
  #       UL(
  #         tags$li("Explore un ensemble de modèles candidats (p,q,P,Q) sous contraintes."),
  #         tags$li("Choisit souvent via minimisation ", B("AICc"),
  #                 " (AIC corrigé petits échantillons)."),
  #         tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coûteuse).")
  #       ),
  #       
  #       H5("Pourquoi AICc ? (objectif)"),
  #       UL(
  #         tags$li("Compromis entre qualité d’ajustement et complexité (pénalise les paramètres)."),
  #         tags$li("AICc est préférable à AIC quand n n’est pas très grand par rapport au nombre de paramètres.")
  #       ),
  #       
  #       H5("Procédure propre"),
  #       OL(
  #         tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
  #         tags$li("Fixer bornes max p/q/P/Q ; documenter."),
  #         tags$li("Sauvegarder le modèle baseline (pour comparaison)."),
  #         tags$li("Vérifier diagnostics résiduels + performance sur test.")
  #       ),
  #       
  #       # === ADD: détails de recherche & critères multiples ===
  #       H5("Détails de recherche"),
  #       UL(
  #         tags$li(B("Stepwise vs exhaustive"), " : stepwise = rapide, peut rater un optimum global ; exhaustive = coûteux mais plus fiable."),
  #         tags$li(B("Contraintes"), " : imposer ", C("p,q,P,Q \u2264"), " bornes raisonnables ; forcer stabilité/inversibilité."),
  #         tags$li(B("drift/constante"), " : tester versions avec et sans drift lorsque ", C("d=1"), ".")
  #       ),
  #       H5("Critères multiples"),
  #       UL(
  #         tags$li("Comparer AICc ", B("et"), " BIC ; en cas de quasi-égalité → choisir le plus parcimonieux.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — baseline"),
  #       P("« Un modèle SARIMA de référence a été sélectionné via une procédure auto-ARIMA basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats sous contraintes [..]. ",
  #         "La spécification obtenue a été utilisée comme baseline, puis comparée à des modèles manuels plus parcimonieux sur la base des diagnostics et de la performance de prévision. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Auto-ARIMA fournit une baseline solide »"),
  #         tags$li(B("Signification : "), "« on a un repère : tout modèle final doit faire au moins aussi bien. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Modèle “trop complexe”"), " : stepwise peut sélectionner des ordres élevés → instabilité, interprétation difficile."),
  #         tags$li(B("AICc excellent mais résidus mauvais"), " : diagnostics priment."),
  #         tags$li(B("Oublier la parcimonie"), " : si deux modèles prédisent pareil, garder le plus simple.")
  #       )
  #     )
  #   )
  #   
  #   # (7) Étape 6 — SARIMA manuel
  #   pages[[8]] <- make_step(
  #     step_names[8],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "proposer un petit ensemble raisonné de candidats via ACF/PACF.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Tracer ACF/PACF de la serie differenciee (apres choix d et D) et identifier les pics significatifs."),
  #         CheckItem("Proposer un petit ensemble de candidats (3 a 8) en justifiant p,q,P,Q par les motifs ACF/PACF (y compris aux multiples de s)."),
  #         CheckItem("Ajuster chaque candidat, relever AICc/BIC, et verifier stabilite/inversibilite si possible."),
  #         CheckItem("Comparer sur diagnostics residuels ET performance predictive (pas seulement AICc)."),
  #         CheckItem("Garder le modele le plus simple qui passe diagnostics et bat le benchmark.")
  #       ),
  #       
  #       H5("Définitions : ACF / PACF (ce que mesurent ces courbes)"),
  #       UL(
  #         tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"),
  #                 " → suggère MA(q) si coupure nette vers q."),
  #         tags$li(B("PACF"), " : corrélation “pure” au retard k une fois les retards <k contrôlés ",
  #                 "→ suggère AR(p) si coupure nette vers p.")
  #       ),
  #       
  #       H5("Heuristiques (non saisonnier)"),
  #       UL(
  #         tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF décroît."),
  #         tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF décroît."),
  #         tags$li(B("ARMA"), " : ACF et PACF décroissent (pas de coupure franche).")
  #       ),
  #       
  #       H5("Heuristiques saisonnières (multiples de s)"),
  #       UL(
  #         tags$li(B("SAR(P)"), " : pics PACF à s, 2s, ..."),
  #         tags$li(B("SMA(Q)"), " : pics ACF à s, 2s, ...")
  #       ),
  #       
  #       H5("Procédure recommandée (petit nombre de modèles)"),
  #       OL(
  #         tags$li("Construire 3 à 8 candidats (parcimonieux)."),
  #         tags$li("Ajuster et comparer AICc/BIC."),
  #         tags$li("Vérifier stabilité/inversibilité."),
  #         tags$li("Retenir ceux qui passent diagnostics + prévision.")
  #       ),
  #       
  #       # === ADD: conception de candidats & lecture fine ===
  #       H5("Conception de candidats (rappels utiles)"),
  #       UL(
  #         tags$li(B("Limiter le set"), " : 3–8 modèles max, justifiés par ACF/PACF."),
  #         tags$li(B("Stabilité/inversibilité"), " : vérifier racines des polynômes AR/MA (hors cercle unité)."),
  #         tags$li(B("drift/constante"), " : inclure/exclure et comparer au niveau AICc/BIC + diagnostics.")
  #       ),
  #       H5("Lecture fine ACF/PACF"),
  #       UL(
  #         tags$li("Pics à ", C("s, 2s, 3s"), " dans l’ACF → penser ", B("SMA(Q)"), "."),
  #         tags$li("Pics à ", C("s, 2s"), " dans la PACF → penser ", B("SAR(P)"), "."),
  #         tags$li("Queue AR (décroissance géométrique) vs coupure MA (après q).")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Méthodes (APA) — sélection manuelle"),
  #       P("« Les structures candidates ont été proposées sur la base des schémas ACF/PACF de la série différenciée. ",
  #         "Des autocorrélations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
  #         "Un ensemble restreint de modèles (n=[..]) a été ajusté et comparé via AICc/BIC et diagnostics résiduels, en privilégiant la parcimonie. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle final est soutenu par la structure ACF/PACF et les diagnostics. »"),
  #         tags$li(B("Signification : "), "« on réduit le risque de sur-ajustement en limitant les candidats. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Brute-force massif"), " : tester 200 modèles puis choisir le plus petit AICc = data snooping."),
  #         tags$li(B("Surinterpréter ACF/PACF"), " : ce sont des guides, pas des preuves."),
  #         tags$li(B("Ignorer l’inversibilité/stabilité"), " : paramètres instables → prévisions incohérentes.")
  #       )
  #     )
  #   )
  #   
  #   # (8) Étape 7 — Diagnostics & comparaison
  #   pages[[9]] <- make_step(
  #     step_names[9],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "valider que le modèle explique toute la dépendance et prédit bien.", type="ok"),
  #       
  #       Checklist(
  #         CheckItem("Examiner les residus: courbe temporelle, ACF residus, et Ljung-Box a plusieurs lags L."),
  #         CheckItem("Verifier qu’il n’y a pas de structure residuelle (p-value Ljung-Box non significative) et ajuster si necessaire."),
  #         CheckItem("Evaluer la prediction hors-echantillon (MAE/RMSE/MASE) avec le meme horizon et le meme protocole pour tous les modeles."),
  #         CheckItem("Comparer explicitement au benchmark (naif/SNAIVE) et conclure sur la valeur ajoutee."),
  #         CheckItem("Documenter toute violation (ARCH, rupture, non-normalite) et expliquer l’impact sur IC et interpretation.")
  #       ),
  #       
  #       H5("Diagnostics résiduels : définitions & buts"),
  #       UL(
  #         tags$li(B("Résidus"), " : ", C("e_t = y_t - ŷ_t"),
  #                 " (ou résidus d’innovation selon l’implémentation)."),
  #         tags$li(B("Bruit blanc"), " : absence d’autocorrélation résiduelle → le modèle a capturé la structure temporelle."),
  #         tags$li(B("Ljung–Box"), " : test global d’autocorrélation des résidus jusqu’à un lag L.")
  #       ),
  #       
  #       H5("Test de Ljung–Box (définition + interprétation)"),
  #       UL(
  #         tags$li(B("But"), " : tester si les autocorrélations résiduelles jusqu’à L sont globalement nulles."),
  #         tags$li(B("Hypothèses"), " : ", B("H0"), " = pas d’autocorrélation résiduelle ; ", B("Ha"), " = autocorrélation résiduelle présente."),
  #         tags$li(B("Conclusion"), " : p petit → rejet H0 → modèle incomplet (ajuster p/q/P/Q ou d/D)."),
  #         tags$li(B("Signification pratique"), " : si autocorrélation résiduelle reste, vos intervalles/prévisions sont souvent trop optimistes.")
  #       ),
  #       
  #       H5("Normalité & hétéroscédasticité (à quoi ça sert vraiment)"),
  #       UL(
  #         tags$li(B("Normalité"), " : utile pour l’interprétation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
  #         tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimés ; si fort, envisager modèles de variance (GARCH) selon le cours.")
  #       ),
  #       
  #       H5("Évaluation prévision (définition + protocole)"),
  #       UL(
  #         tags$li(B("Split temporel"), " : entraîner sur le passé, tester sur le futur."),
  #         tags$li(B("Rolling-origin"), " : répéter sur plusieurs origines → estimation plus robuste."),
  #         tags$li(B("Benchmark"), " : naїf / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE à l’horizon cible.")
  #       ),
  #       
  #       # === ADD: diagnostics additionnels & comparaison ===
  #       H5("Diagnostics additionnels"),
  #       UL(
  #         tags$li(B("Box–Pierce vs Ljung–Box"), " : préférer Ljung–Box (meilleure petite taille)."),
  #         tags$li(B("Normalité résiduelle"), " : Q–Q plot, Jarque–Bera ; utile pour IC mais secondaire si but = point forecast."),
  #         tags$li(B("Hétéroscédasticité / ARCH"), " : tester ACF des résidus au carré ; si fort → discuter modèles de variance (annexe)."),
  #         tags$li(B("Significativité des coefficients"), " : rapporter est., SE, z, p ; supprimer termes non significatifs si performance constante.")
  #       ),
  #       H5("Comparaison de modèles"),
  #       UL(
  #         tags$li(B("Tableau récapitulatif"), " : AICc/BIC, Ljung–Box (p), MAE/RMSE/MASE, nb de paramètres."),
  #         tags$li(B("Test de Diebold–Mariano"), " : (annexe) comparer formellement 2 séries d’erreurs prédictives.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Résultats (APA) — diagnostics"),
  #       P("« Les diagnostics résiduels indiquaient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics substantiels et le test de Ljung–Box était [non significatif/significatif] au seuil α=[..]. ",
  #         "La performance de prévision sur la fenêtre d’évaluation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. »"),
  #       
  #       H5("Conclusion & signification (diagnostics + performance)"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le modèle est acceptable » si Ljung–Box non significatif ET benchmark battu."),
  #         tags$li(B("Signification : "),
  #                 "« le modèle capte la structure temporelle (résidus ~ bruit) et apporte un gain prédictif réel (out-of-sample). »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Bon AIC mais Ljung–Box significatif"), " : modèle incomplet → ne pas valider."),
  #         tags$li(B("Se focaliser sur la normalité"), " : priorité = absence d’autocorrélation résiduelle."),
  #         tags$li(B("Comparer des modèles sur des horizons différents"), " : toujours même h, même protocole.")
  #       )
  #     )
  #   )
  #   
  #   # (9) Étape 8 — Rédaction
  #   pages[[10]] <- make_step(
  #     step_names[10],
  #     
  #     actions_ui = tagList(
  #       callout(B("But : "), "écrire un rapport clair, reproductible, aligné aux étapes 0–7.", type="info"),
  #       
  #       Checklist(
  #         CheckItem("Rediger une section Methodes qui suit exactement le pipeline: donnees -> EDA -> stationnarite -> selection -> diagnostics -> prevision."),
  #         CheckItem("Inclure figures indispensables: serie, decomposition, ACF/PACF, residus, previsions + intervalles."),
  #         CheckItem("Inclure un tableau de comparaison (AICc/BIC, Ljung-Box, MAE/RMSE, benchmark, nb parametres)."),
  #         CheckItem("Preciser l’echelle (niveau/log/Box-Cox) et expliquer toute reconversion des previsions."),
  #         CheckItem("Ajouter un encadre limites + pistes (ruptures, SARIMAX, GARCH) et assurer la reproductibilite (versions).")
  #       ),
  #       
  #       H5("Structure APA recommandée (définition)"),
  #       UL(
  #         tags$li(B("Méthodes"), " : ce que vous avez fait et pourquoi (données → EDA → stationnarité → modèles → évaluation)."),
  #         tags$li(B("Résultats"), " : ce que vous avez observé (stats, figures, tests, métriques, modèle final)."),
  #         tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
  #       ),
  #       
  #       H5("Pack livrable propre (checklist)"),
  #       UL(
  #         tags$li("Notebook/script reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
  #         tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC."),
  #         tags$li("Tableau : candidats vs AICc/BIC vs Ljung–Box vs MAE/RMSE vs benchmark.")
  #       ),
  #       
  #       # === ADD: rapporter correctement les prévisions ===
  #       H5("Rapporter correctement les prévisions"),
  #       UL(
  #         tags$li(B("Niveau de couverture"), " : préciser 80% et/ou 95% ; indiquer si log-échelle a été reconvertie."),
  #         tags$li(B("Biais de reconversion (log→niveau)"), " : mentionner correction ",
  #                 C("exp(\\hat{y}) \\times exp(\\hat{\\sigma}^2/2)"), " si utilisée."),
  #         tags$li(B("Reproductibilité"), " : versions R/packages, seed, chemin des données, date d’extraction.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Phrase finale (APA) — modèle final + interprétation"),
  #       P("« Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). ",
  #         "Les résidus étant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a été capturée. ",
  #         "Les prévisions produites à horizon h=[..] améliorent le benchmark [..] selon MAE/RMSE, ce qui soutient l’usage du modèle pour l’application ciblée. »"),
  #       
  #       H5("Conclusion & signification"),
  #       UL(
  #         tags$li(B("Conclusion : "), "« Le rapport est aligné, justifié, reproductible. »"),
  #         tags$li(B("Signification : "),
  #                 "« un lecteur externe peut reproduire vos résultats et comprendre chaque choix (transformation, d/D, sélection, diagnostics). »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Ne pas relier choix → preuves"), " : chaque décision doit être liée à EDA/tests/diagnostics."),
  #         tags$li(B("Trop de texte, pas assez de figures"), " : en séries temporelles, les figures sont des résultats."),
  #         tags$li(B("Oublier de préciser l’échelle"), " : niveau vs log vs Box–Cox et reconversion des prévisions.")
  #       )
  #     )
  #   )
  #   
  #   # (10) Annexes
  #   pages[[11]] <- make_step(
  #     step_names[11],
  #     
  #     actions_ui = tagList(
  #       Checklist(
  #         CheckItem("Reconnaitre et pouvoir ecrire les trois benchmarks (naif, drift, SNAIVE) et expliquer quand chacun est approprie."),
  #         CheckItem("Savoir lire rapidement un resultat ADF/KPSS/PP et traduire la conclusion en choix de d et D."),
  #         CheckItem("Savoir expliquer ce que signifie Ljung-Box significatif (structure residuelle) et quelle action entreprendre."),
  #         CheckItem("Memoriser les formules utiles (AIC/AICc/BIC, Ljung-Box, operateurs de differenciation) et leur interpretation."),
  #         CheckItem("Identifier quand il faut sortir du cadre SARIMA (exogenes, multiples saisonnalites, ruptures, variance conditionnelle).")
  #       ),
  #       
  #       H5("Benchmarks (définitions)"),
  #       UL(
  #         tags$li(B("Naïf"), " : ", C("ŷ_{t+1|t} = y_t"), " (persistance)."),
  #         tags$li(B("Drift"), " : extrapolation linéaire moyenne."),
  #         tags$li(B("SNAIVE"), " : répète la dernière valeur de la même saison : ", C("ŷ_{t+h|t} = y_{t+h-s}"), ".")
  #       ),
  #       
  #       H5("Règles d’interprétation ultra rapides"),
  #       UL(
  #         tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " → stationnarité plausible."),
  #         tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " → différenciation nécessaire."),
  #         tags$li(B("Ljung–Box significatif"), " → il reste de la structure → réviser le modèle.")
  #       ),
  #       
  #       # === ADD: formules utiles & pistes avancées ===
  #       H5("Formules utiles (mémo)"),
  #       UL(
  #         tags$li(B("Critères d’info"), " : ",
  #                 C("AIC=-2\\log L+2k"), ", ",
  #                 C("AICc= AIC + \\frac{2k(k+1)}{n-k-1}"), ", ",
  #                 C("BIC=-2\\log L+k\\log n"), "."),
  #         tags$li(B("MASE"), " : ", C("\\frac{\\frac{1}{T}\\sum_{t}|e_t|}{\\frac{1}{T-s}\\sum_{t}|y_t-y_{t-s}|}"), " (pour périodicité ", C("s"), ")."),
  #         tags$li(B("Ljung–Box"), " : ", C("Q^* = n(n+2)\\sum_{k=1}^{L} \\frac{\\hat{\\rho}_k^2}{n-k}"),
  #                 " ~ ", C("\\chi^2"), " sous ", C("H_0"), " avec ddl ≈ ", C("L - p - q - (P+Q)"), "."),
  #         tags$li(B("Backshift & diff."), " : ",
  #                 C("\\nabla=(1-B)"), ", ", C("\\nabla_s=(1-B^s)"), ", ",
  #                 C("\\nabla^d \\nabla_s^D y_t"), " pour stationnariser.")
  #       ),
  #       H5("Pistes avancées (pour l’enseignant)"),
  #       UL(
  #         tags$li(B("SARIMAX / régression dynamique"), " : variables exogènes, pré-blanchiment, fonctions de transfert."),
  #         tags$li(B("Ruptures/Interventions"), " : dummies LS/TC, estimation avec régresseurs."),
  #         tags$li(B("Multiples saisonnalités"), " : TBATS/ETS-MS si présence de s multiples.")
  #       )
  #     ),
  #     
  #     apa_ui = tagList(
  #       H5("Template “Conclusion tests → choix (d,D)” (copier-coller)"),
  #       P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
  #         "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnarité, ",
  #         "nous concluons que la série est [stationnaire/non-stationnaire] au sens des diagnostics combinés. ",
  #         "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une série stationnaire pour l’estimation SARIMA. »"),
  #       
  #       H5("Signification (traduction simple)"),
  #       UL(
  #         tags$li("« d et D disent combien de fois on doit “retirer” une tendance et une saisonnalité non stationnaire. »"),
  #         tags$li("« Ensuite, p/q/P/Q décrivent la dépendance restante (mémoire) dans la série transformée. »")
  #       )
  #     ),
  #     
  #     pitfalls_ui = tagList(
  #       UL(
  #         tags$li(B("Croire qu’un test “décide” seul"), " : toujours trianguler avec EDA + ACF + comportement après différenciation."),
  #         tags$li(B("Oublier la finalité"), " : prévision (out-of-sample) + diagnostics passent avant l’esthétique d’un AIC."),
  #         tags$li(B("Ne pas documenter"), " : un bon modèle non documenté = inutilisable dans un cours/rapport.")
  #       )
  #     )
  #   )
  #   
  #   # ========= Output =========
  #   tagList(
  #     css,
  #     tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
  #     progress_ui,
  #     pages[[cur + 1L]]
  #   )
  # })
  
  
  
  
  
  
  
  
  
  
  
  
#'   # --- Roadmap slider navigation (Prev/Next) ---
#'   observeEvent(input$road_prev, {
#'     cur <- input$roadmap_step
#'     if (is.null(cur)) cur <- 0
#'     updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
#'   }, ignoreInit = TRUE)
#'   
#'   observeEvent(input$road_next, {
#'     cur <- input$roadmap_step
#'     if (is.null(cur)) cur <- 0
#'     updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
#'   }, ignoreInit = TRUE)
#'   
#'   # =========================
#'   # Roadmap UI (controls)
#'   # =========================
#'   output$roadmap_Detailed_Fr_ui4 <- renderUI({
#'     
#'     tags$div(
#'       class = "road-shell",
#'       style = "background:#f7f7f7;padding:14px;border-radius:10px;",
#'       
#'       tags$style(HTML("
#' .road-shell {background:#f7f7f7;padding:14px;border-radius:12px;border:1px solid #ececec;}
#'       .road-title {margin:0 0 6px 0;font-size:22px;font-weight:800;letter-spacing:.2px;}
#'       .road-sub {margin:0 0 12px 0;color:#555;line-height:1.45;}
#'       .road-nav {display:flex;gap:10px;align-items:center;flex-wrap:wrap;position:sticky;top:0;z-index:50;background:#f7f7f7;padding:10px 0 8px 0;border-bottom:1px solid #ececec;}
#'       .road-nav .btn {min-width:46px;border-radius:10px;padding:6px 12px;}
#'       .road-nav .btn:focus {outline:none;box-shadow:0 0 0 3px rgba(76,120,168,.25);}
#'       .road-nav .form-group {margin-bottom:0;}
#'       /* Slider polish (Shiny uses ionRangeSlider) */
#'       .road-shell .irs--shiny .irs-bar {background:#4C78A8;}
#'       .road-shell .irs--shiny .irs-handle>i:first-child {background:#4C78A8;}
#'       .road-shell .irs--shiny .irs-from,
#'       .road-shell .irs--shiny .irs-to,
#'       .road-shell .irs--shiny .irs-single {background:#4C78A8;}
#'       @media (max-width: 900px) {
#'         .road-nav {gap:8px;}
#'         .road-nav .irs {width:100% !important;}
#'         .road-nav .form-group {width:100%;}
#'       }
#'       .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin-top:14px;box-shadow:0 2px 10px rgba(0,0,0,.03);}
#'       .step-header {display:flex;align-items:center;justify-content:space-between;gap:10px;margin-bottom:8px;}
#'       .step-badge {display:inline-block;font-weight:800;font-size:12px;letter-spacing:.3px;text-transform:uppercase;padding:4px 10px;border-radius:999px;background:#eef4fb;color:#254b74;border:1px solid #d9e7f6;}
#'       .step-hint {color:#666;font-size:12px;}
#'       details {background:#ffffff;border:1px solid #eaeaea;border-radius:12px;padding:0;margin:10px 0;overflow:hidden;}
#'       details > summary {cursor:pointer;font-weight:700;padding:10px 12px;list-style:none;display:flex;align-items:center;justify-content:space-between;gap:12px;background:linear-gradient(180deg,#ffffff 0%,#fbfbfb 100%);}
#'       details > summary::-webkit-details-marker {display:none;}
#'       details > summary:after {content:'▸';font-size:16px;color:#666;transform:rotate(0deg);transition:transform .12s ease;}
#'       details[open] > summary:after {transform:rotate(90deg);}
#'       details:hover {border-color:#dcdcdc;}
#'       details[open] {border-color:#d9e7f6;box-shadow:0 2px 10px rgba(76,120,168,.08);}
#'       .callout {border-left:5px solid #4C78A8;background:#fafafa;padding:12px 12px;border-radius:10px;margin:10px 0;}
#'       .callout.warn {border-left-color:#E45756;background:#fff7f7;}
#'       .callout.ok {border-left-color:#72B7B2;background:#f7fffb;}
#'       .callout.checklist {border-left-color:#F2CF5B;background:#fffdf4;}
#'       .checklist-title {display:flex;align-items:center;gap:8px;margin-bottom:6px;}
#'       .checklist-icon {font-weight:800;}
#'       code {background:#f3f3f3;padding:0 4px;border-radius:4px;}
#'       .progress {height:10px;border-radius:999px;background:#ececec;overflow:hidden;margin:10px 0 0 0;}
#'       .progress-bar {border-radius:999px;}
#' ")),
#'       
#'       tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
#'       tags$p(class="road-sub",
#'              "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
#'       
#'       tags$div(
#'         class = "road-nav",
#'         actionButton("road_prev", "◀", class = "btn btn-default"),
#'         sliderInput(
#'           "roadmap_step", label = NULL,
#'           min = 0, max = 10, value = 0, step = 1, width = "520px"
#'         ),
#'         actionButton("road_next", "▶", class = "btn btn-default"),
#'         tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
#'       ),
#'       
#'       # Progress bar (pure UI, updated via re-render of content)
#'       shiny::uiOutput("roadmap_step_content")
#'     )
#'   })
#'   
#'   # =========================
#'   # Roadmap UI (content)
#'   # =========================
#'   output$roadmap_step_content <- renderUI({
#'     
#'     # ========= Helpers =========
#'     D <- function(title, ...) {
#'       tags$details(
#'         tags$summary(title),
#'         tags$div(class = "road-scroll", ...)
#'       )
#'     }
#'     UL <- function(...) tags$ul(...)
#'     OL <- function(...) tags$ol(...)
#'     P  <- function(...) tags$p(...)
#'     B  <- function(...) tags$b(...)
#'     C  <- function(...) tags$code(...)
#'     H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
#'     
#'     # ========= Checklist helpers (UI only) =========
#'     # These are intentionally simple visual checklists (no reactive logic).
#'     # Pedagogical goal: help students translate “read/explain” into
#'     # concrete actions they can verify before moving to the next step.
#'     CheckItem <- function(...) {
#'       tags$li(
#'         tags$span(class = "chkbox", "☐"),
#'         tags$span(...)
#'       )
#'     }
#'     Checklist <- function(...) {
#'       tags$div(
#'         class = "callout checklist",
#'         tags$div(
#'           class = "checklist-title",
#'           tags$span(class = "checklist-icon", "☑"),
#'           tags$b("Checklist étudiant")
#'         ),
#'         tags$ul(class = "chk", ...)
#'       )
#'     }
#'     
#'     callout <- function(..., type = c("info","ok","warn")) {
#'       type <- match.arg(type)
#'       cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
#'       tags$div(class = cls, ...)
#'     }
#'     
#'     # ========= CSS (internal scroll so the page stays short) =========
#'     css <- tags$style(HTML("
#' .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin-top:14px;box-shadow:0 2px 10px rgba(0,0,0,.03);}
#'     .step-header {display:flex;align-items:center;justify-content:space-between;gap:10px;margin-bottom:8px;}
#'     .step-badge {display:inline-block;font-weight:800;font-size:12px;letter-spacing:.3px;text-transform:uppercase;padding:4px 10px;border-radius:999px;background:#eef4fb;color:#254b74;border:1px solid #d9e7f6;}
#'     .step-hint {color:#666;font-size:12px;}
#'     details {background:#ffffff;border:1px solid #eaeaea;border-radius:12px;padding:0;margin:10px 0;overflow:hidden;}
#'     details > summary {cursor:pointer;font-weight:700;padding:10px 12px;list-style:none;display:flex;align-items:center;justify-content:space-between;gap:12px;background:linear-gradient(180deg,#ffffff 0%,#fbfbfb 100%);}
#'     details > summary::-webkit-details-marker {display:none;}
#'     details > summary:after {content:'▸';font-size:16px;color:#666;transform:rotate(0deg);transition:transform .12s ease;}
#'     details[open] > summary:after {transform:rotate(90deg);}
#'     details:hover {border-color:#dcdcdc;}
#'     details[open] {border-color:#d9e7f6;box-shadow:0 2px 10px rgba(76,120,168,.08);}
#'     .road-scroll {max-height: 62vh; overflow-y: auto; padding:10px 12px 12px 12px; padding-right: 14px;}
#'     .road-scroll::-webkit-scrollbar {width: 10px;}
#'     .road-scroll::-webkit-scrollbar-thumb {background: #e0e0e0; border-radius: 999px; border: 3px solid #fff;}
#'     .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:12px 12px; border-radius:10px; margin:10px 0;}
#'     .callout.warn {border-left-color:#E45756; background:#fff7f7;}
#'     .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
#'     .callout.checklist {border-left-color:#F2CF5B; background:#fffdf4;}
#'     .checklist-title {display:flex; align-items:center; gap:8px; margin-bottom:6px;}
#'     .checklist-icon {font-weight:800;}
#'     code {background:#f3f3f3; padding:0 4px; border-radius:4px;}
#'     .progress {height:10px; border-radius:999px; background:#ececec; overflow:hidden; margin:10px 0 0 0;}
#'     .progress-bar {border-radius:999px;}
#'     /* Checklist: checkbox-style bullets */
#'     ul.chk {padding-left: 0; margin: 8px 0 0 0;}
#'     ul.chk li {list-style: none; margin: 7px 0; display:flex; align-items:flex-start; gap:8px;}
#'     .chkbox {display:inline-block; width: 18px; font-weight: 800; margin-top: 1px;}
#' "))
#'     
#'     # ========= Step logic =========
#'     cur <- input$roadmap_step
#'     if (is.null(cur) || !is.finite(cur)) cur <- 0
#'     cur <- as.integer(cur)
#'     
#'     step_names <- c(
#'       "Aperçu & notations (glossaire + lecture du modèle)",
#'       "Étape 0 — Définir le problème de modélisation",
#'       "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
#'       "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
#'       "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
#'       "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
#'       "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
#'       "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
#'       "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
#'       "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
#'       "Annexes — Formules, checklists, templates, interprétations rapides"
#'     )
#'     
#'     pct <- round(100 * cur / 10)
#'     progress_ui <- tags$div(
#'       class="progress",
#'       tags$div(
#'         class="progress-bar",
#'         role="progressbar",
#'         `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
#'         style = paste0("width:", pct, "%;")
#'       )
#'     )
#'     
#'     make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
#'       step_badge <- if (isTRUE(cur == 0L)) "Aperçu" else paste0("Étape ", cur, "/10")
#'       tags$div(
#'         class = "road-card",
#'         if (!is.null(header_ui)) header_ui,
#'         tags$div(
#'           class = "step-header",
#'           tags$span(class = "step-badge", step_badge),
#'           tags$span(class = "step-hint", "Dépliez un bloc à la fois : Actions → APA → Pièges.")
#'         ),
#'         tags$h4(title),
#'         D("1) Ce que l’étudiant fait (procédure + définitions + objectifs)", actions_ui),
#'         D("2) Ce qu’il écrit (APA) + conclusion & signification", apa_ui),
#'         D("3) Pièges + comment les éviter (avec interprétation)", pitfalls_ui)
#'       )
#'     }
#'     
#'     # ========= Pages =========
#'     pages <- vector("list", length = 11)
#'     
#'     # (0) Aperçu
#'     pages[[1]] <- make_step(
#'       step_names[1],
#'       
#'       actions_ui = tagList(
#'         callout(
#'           B("Objectif global : "),
#'           "construire un modèle SARIMA interprétable et surtout ",
#'           B("prédictif"), " : il doit passer les diagnostics résiduels et battre un benchmark simple.",
#'           type="ok"
#'         ),
#'         
#'         Checklist(
#'           CheckItem("Identifier clairement la série y_t (ce que vous cherchez à prévoir), préciser son unité, sa source et le contexte d’application (ex. ventes mensuelles, débit quotidien, température horaire)."),
#'           CheckItem("Fixer la période saisonnière s à partir du contexte et vérifier qu’elle est cohérente avec l’échantillonnage (ex. s=12 pour mensuel, s=7 pour hebdomadaire, s=4 pour trimestriel)."),
#'           CheckItem("Lire la forme générale du SARIMA et expliquer le rôle de chaque bloc : différenciation (d, D) pour stationnariser, puis composantes AR/MA (p, q, P, Q) pour modéliser la dépendance restante."),
#'           CheckItem("Énoncer des critères de validation explicites : résidus ≈ bruit blanc (ACF résidus + Ljung–Box), performance hors‑échantillon (train/test ou rolling-origin) et parcimonie (le plus simple qui marche)."),
#'           CheckItem("Choisir un benchmark (naïf / drift / SNAIVE), l’écrire noir sur blanc et expliquer pourquoi il est pertinent : sans repère, on ne peut pas juger la valeur ajoutée d’un SARIMA.")
#'         ),
#'         
#'         
#'         H5("Notations essentielles (définitions)"),
#'         UL(
#'           tags$li(B("Série temporelle"), " : suite ordonnée d’observations indexées par le temps ", C("y_t"), "."),
#'           tags$li(B("Fréquence / période saisonnière"), " : nombre de pas par cycle saisonnier, noté ", C("s"),
#'                   " (ex. mensuel s=12; quotidien avec saison hebdo s=7)."),
#'           tags$li(B("Opérateur de retard (backshift)"), " : ", C("B y_t = y_{t-1}"), "."),
#'           tags$li(B("Différenciation ordinaire"), " : ", C("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
#'                   " ; appliquée ", C("d"), " fois → supprimer tendance/racine unitaire non saisonnière."),
#'           tags$li(B("Différenciation saisonnière"), " : ", C("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
#'                   " ; appliquée ", C("D"), " fois → supprimer racine unitaire saisonnière."),
#'           tags$li(B("Innovations / bruit blanc"), " : ", C("ε_t ~ w.n.(0, σ²)"),
#'                   " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
#'         ),
#'         
#'         H5("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)"),
#'         UL(
#'           tags$li(
#'             "Écriture compacte : ",
#'             C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
#'           ),
#'           tags$li(
#'             B("Interprétation : "),
#'             "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
#'             "non saisonnières (p,q) et saisonnières (P,Q)."
#'           )
#'         ),
#'         
#'         H5("Ce que signifie “bon modèle” (définition opérationnelle)"),
#'         OL(
#'           tags$li(B("Résidus ~ bruit blanc"), " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."),
#'           tags$li(B("Performance out-of-sample"), " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."),
#'           tags$li(B("Parcimonie"), " : modèle le plus simple possible à performance comparable.")
#'         ),
#'         
#'         # === ADD: Glossaire étendu, critères info, estimation ===
#'         H5("Glossaire étendu (ajouts importants)"),
#'         UL(
#'           tags$li(B("Polynômes AR/MA"), " : ",
#'                   C("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), ", ",
#'                   C("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), "; saisonnier ",
#'                   C("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), ", ",
#'                   C("Θ(B^s) = 1 + Θ_1 B^s + ... + Θ_Q B^{Qs}"), "."),
#'           tags$li(B("Stabilité/causalité (AR)"), " : toutes les racines de ", C("φ(z)=0"),
#'                   " et ", C("Φ(z^s)=0"), " sont ", B("hors"), " du cercle unité → processus stationnaire."),
#'           tags$li(B("Inversibilité (MA)"), " : racines de ", C("θ(z)=0"), " et ", C("Θ(z^s)=0"),
#'                   " hors du cercle unité → représentation AR(∞) bien définie."),
#'           tags$li(B("Constante / drift"), " : une constante dans un ARIMA avec ", C("d=1"),
#'                   " implique une ", B("pente moyenne"), " (drift) après différenciation ; le terme est souvent noté ",
#'                   C("c"), " et la tendance moyenne vaut environ ", C("c"), " par pas."),
#'           tags$li(B("Représentation état–espace"), " : tout ARIMA/SARIMA peut être écrit sous forme état–espace ",
#'                   "et estimé/filtré par Kalman (utile pour manquants et lissage)."),
#'           tags$li(B("Prévision : point vs intervalle vs densité"),
#'                   " : point = ", C("ŷ"), "; intervalle = incertitude (80%/95%); densité = distribution prédictive complète.")
#'         ),
#'         H5("Critères d’information (définitions)"),
#'         UL(
#'           tags$li(B("AIC"), " : ", C("AIC = -2 \\log L + 2k"), " (", C("k"), " = nb paramètres estimés)."),
#'           tags$li(B("AICc"), " : correction petits échantillons → préférable si ", C("n/k"), " n’est pas grand."),
#'           tags$li(B("BIC"), " : ", C("BIC = -2 \\log L + k \\log n"), " ; pénalise plus la complexité (favorise parcimonie).")
#'         ),
#'         H5("Estimation (comment sont estimés les paramètres)"),
#'         UL(
#'           tags$li(B("MLE vs CSS+MLE"), " : estimation par maximum de vraisemblance (souvent via optim) ; ",
#'                   "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."),
#'           tags$li(B("Écarts-types et tests z"), " : reportez estimations ± SE, z et p pour l’interprétation des coefficients.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Phrase APA (modèle + notations)"),
#'         P("« Nous avons ajusté un modèle SARIMA afin de capturer la dépendance temporelle et la saisonnalité de la série ",
#'           C("y_t"), ". La spécification générale est ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
#'           " avec ", C("ε_t"), " un bruit blanc. Le choix de (d, D) a été justifié par des tests de stationnarité (ADF/KPSS/PP) et des diagnostics. »"),
#'         
#'         H5("Conclusion & signification (à expliciter)"),
#'         UL(
#'           tags$li(B("Conclusion type : "), "« Le modèle final est adéquat »"),
#'           tags$li(B("Signification : "), "« (i) il ne laisse pas d’information autocorrélée dans les résidus, ",
#'                   "(ii) il généralise bien sur une fenêtre future, ",
#'                   "(iii) il est suffisamment simple pour être stable et reproductible. »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         H5("Pièges classiques"),
#'         UL(
#'           tags$li(B("Confondre AIC faible et bon modèle"), " : un AIC très bas avec résidus autocorrélés = modèle mal spécifié."),
#'           tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naïf, impossible de dire si SARIMA apporte réellement quelque chose."),
#'           tags$li(B("Surcharger le modèle"), " : trop de paramètres → instabilité, intervalles de prévision peu fiables.")
#'         )
#'       )
#'     )
#'     
#'     # (1) Étape 0 — Définition du problème
#'     pages[[2]] <- make_step(
#'       step_names[2],
#'       
#'       actions_ui = tagList(
#'         callout(
#'           B("But : "),
#'           "définir un problème de prévision mesurable (horizon, métriques, protocole).",
#'           type="info"
#'         ),
#'         
#'         Checklist(
#'           CheckItem("Définir la variable y_t (cible) et la fréquence temporelle (jour, semaine, mois) sans ambiguite."),
#'           CheckItem("Fixer l’horizon h en fonction de l’usage reel (decision, planification, stock, etc.)."),
#'           CheckItem("Choisir un protocole d’evaluation temporelle (train/test ou rolling-origin) et expliquer pourquoi."),
#'           CheckItem("Choisir des metriques (MAE + RMSE recommande) et justifier leur interpretation."),
#'           CheckItem("Decider si une transformation (log / Box-Cox) est necessaire et noter la raison.")
#'         ),
#'         
#'         H5("Définitions (ce que chaque terme veut dire)"),
#'         UL(
#'           tags$li(B("Série réponse"), " ", C("y_t"), " : variable à prédire (univariée)."),
#'           tags$li(B("Horizon"), " ", C("h"), " : nombre de pas à prévoir (ex. h=12 mois)."),
#'           tags$li(B("Origine de prévision"), " : dernier temps observé à partir duquel on prévoit."),
#'           tags$li(B("Protocole train/test"), " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."),
#'           tags$li(B("Rolling-origin / validation temporelle"), " : on répète des prévisions à différentes origines pour estimer la performance moyenne."),
#'           tags$li(B("SARIMA vs SARIMAX"), " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes.")
#'         ),
#'         
#'         H5("Choisir les métriques (définitions + quand utiliser)"),
#'         UL(
#'           tags$li(B("MAE"), " : moyenne des erreurs absolues ", C("mean(|y-ŷ|)"),
#'                   " → robuste, facile à interpréter (unité de y)."),
#'           tags$li(B("RMSE"), " : racine de l’erreur quadratique moyenne ", C("sqrt(mean((y-ŷ)^2))"),
#'                   " → pénalise plus les grosses erreurs."),
#'           tags$li(B("MAPE"), " : ", C("mean(|(y-ŷ)/y|)"),
#'                   " → éviter si y proche de 0 (explose)."),
#'           tags$li(B("sMAPE"), " : alternative plus stable près de 0 : ", C("mean(2|y-ŷ|/(|y|+|ŷ|))"), ".")
#'         ),
#'         
#'         H5("Transformation (définitions + justification)"),
#'         UL(
#'           tags$li(B("Niveaux"), " : modèle sur les valeurs brutes."),
#'           tags$li(B("Log-niveaux"), " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."),
#'           tags$li(B("Box–Cox"), " : transformation paramétrique (λ) pour stabiliser variance et améliorer normalité : ",
#'                   C("y^(λ) = (y^λ - 1)/λ"), " (λ≠0), et log si λ=0.")
#'         ),
#'         
#'         H5("Procédure minimale (checklist)"),
#'         OL(
#'           tags$li("Fixer fréquence et période saisonnière s."),
#'           tags$li("Fixer horizon h et fenêtres train/test (ou rolling-origin)."),
#'           tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
#'           tags$li("Décider transformation (aucune/log/Box–Cox) et justifier.")
#'         ),
#'         
#'         # === ADD: précisions pratiques, métriques complémentaires, transformations ===
#'         H5("Précisions supplémentaires (définitions pratiques)"),
#'         UL(
#'           tags$li(B("Horizon multi-pas"), " : ", C("h>1"),
#'                   " → la performance peut décroître avec l’horizon ; rapporter MAE/RMSE par h si possible."),
#'           tags$li(B("Fenêtre d’entraînement"), " : ", B("expansive"), " (on ne jette jamais d’anciens points) ",
#'                   "ou ", B("glissante"), " (fenêtre fixe) ; documenter le choix."),
#'           tags$li(B("Reproductibilité"), " : fixer les graines aléatoires, consigner versions des packages, chemins de données."),
#'           tags$li(B("Prévision hiérarchique"), " (annexe) : si agrégations (mois→trimestres), noter la cohérence temporelle.")
#'         ),
#'         H5("Métriques supplémentaires (quand utiles)"),
#'         UL(
#'           tags$li(B("MASE"), " : erreur absolue mise à l’échelle par le naïf saisonnier → comparable entre séries."),
#'           tags$li(B("WAPE"), " : ", C("sum(|y-ŷ|)/sum(|y|)"), " ; lisible comme % d’erreur agrégée."),
#'           tags$li(B("Pinball loss (quantiles)"), " : si vous prédisez des quantiles (IC asymétriques).")
#'         ),
#'         H5("Transformations complémentaires"),
#'         UL(
#'           tags$li(B("Yeo–Johnson"), " : alternative à Box–Cox qui gère les valeurs ≤ 0."),
#'           tags$li(B("Stabilisation de variance"), " : vérifier relation niveau–variance (nuage points moyenne locale vs ET).")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Méthodes (APA) — modèle de phrase complet"),
#'         P("« Nous avons modélisé la série temporelle univariée ", C("y_t"),
#'           " observée à une fréquence [..] (période saisonnière s=[..]). ",
#'           "L’objectif était de produire des prévisions à horizon ", C("h"), "=[..]. ",
#'           "La performance a été évaluée sur une fenêtre future selon [split temporel / rolling-origin] ",
#'           "à l’aide de [MAE, RMSE]. Une transformation [aucune / log / Box–Cox] a été appliquée afin de [stabiliser la variance / linéariser la saisonnalité]. »"),
#'         
#'         H5("Conclusion & signification (comment l’expliquer)"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Notre problème est bien défini (h, métriques, protocole). »"),
#'           tags$li(B("Signification : "), "« Toute comparaison de modèles devient juste : même horizon, même protocole, mêmes métriques. »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) → performance artificiellement élevée."),
#'           tags$li(B("Métrique mal choisie"), " : MAPE avec y≈0 → conclusions fausses."),
#'           tags$li(B("Horizon incohérent"), " : un modèle bon à h=1 peut être mauvais à h=12 ; fixer l’horizon selon l’usage réel.")
#'         )
#'       )
#'     )
#'     
#'     # (2) Étape 1 — Description des données
#'     pages[[3]] <- make_step(
#'       step_names[3],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "décrire la qualité des données et rendre le pipeline reproductible.", type="info"),
#'         
#'         Checklist(
#'           CheckItem("Verifier que l’index temporel est regulier (pas manquants/dupliques, ordre correct)."),
#'           CheckItem("Rapporter n, date debut/fin, frequence, et la couverture temporelle."),
#'           CheckItem("Quantifier les manquants (k et %) et choisir une strategie (interpolation, saisonniere, Kalman) avec justification."),
#'           CheckItem("Produire un resume statistique (moyenne, mediane, ET, min/max) et un resume saisonnier (par mois/semaine)."),
#'           CheckItem("Documenter toute correction (doublons, valeurs aberrantes evidentes) pour garantir la reproductibilite.")
#'         ),
#'         
#'         H5("Ce qu’il faut rapporter (définitions)"),
#'         UL(
#'           tags$li(B("n"), " : nombre total d’observations disponibles."),
#'           tags$li(B("Couverture"), " : date début/fin."),
#'           tags$li(B("Fréquence"), " : périodicité (mensuel/hebdo/quotidien)."),
#'           tags$li(B("Manquants"), " : nombre k et pourcentage k/n.")
#'         ),
#'         
#'         H5("Valeurs manquantes : types + implications"),
#'         UL(
#'           tags$li(B("MCAR"), " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."),
#'           tags$li(B("MAR"), " (At Random conditionnel) : dépend d’autres infos → imputation possible mais à justifier."),
#'           tags$li(B("MNAR"), " (Not At Random) : dépend de la valeur elle-même → risque de biais important.")
#'         ),
#'         
#'         H5("Stratégies de traitement (quand et pourquoi)"),
#'         UL(
#'           tags$li(B("Interpolation linéaire"), " : si manquants rares et pas de ruptures."),
#'           tags$li(B("Interpolation saisonnière"), " : si saisonnalité stable (ex. remplacer par moyenne du même mois)."),
#'           tags$li(B("Modèle d’état / Kalman"), " : si on veut une imputation plus probabiliste."),
#'           tags$li(B("Suppression"), " : seulement si extrêmement rare et sans impact sur la continuité.")
#'         ),
#'         
#'         H5("Descriptifs pertinents (au-delà de la moyenne)"),
#'         UL(
#'           tags$li("Moyenne, médiane, ET, min/max (niveau)."),
#'           tags$li("Asymétrie (skewness) / kurtosis si utile."),
#'           tags$li("Résumé saisonnier (ex. moyenne par mois), pour documenter saisonnalité.")
#'         ),
#'         
#'         # === ADD: qualité index & manquants pratiques ===
#'         H5("Qualité de l’index temporel (définitions)"),
#'         UL(
#'           tags$li(B("Régularité"), " : pas de pas manqué/dupliqué ; cadence constante."),
#'           tags$li(B("Fuseau/DST"), " : données horaires → attention aux heures manquantes/dupliquées (passage DST)."),
#'           tags$li(B("Doublons et horodatages hors ordre"), " : à corriger avant tout calcul d’ACF.")
#'         ),
#'         H5("Manquants — remarques pratiques"),
#'         UL(
#'           tags$li(B("Kalman/StructTS"), " : imputation probabiliste cohérente avec la dynamique ARIMA."),
#'           tags$li(B("Imputation “saison identique”"), " : moyenne/médiane du même mois/jour si saisonnalité stable."),
#'           tags$li(B("Zéros structurels"), " : distinguer “zéro” réel de manquant imputé à 0 (documenter).")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Résultats (APA) — description"),
#'         P("« La série contient ", C("n"), "=[..] observations couvrant [..] à [..] à une fréquence [..]. ",
#'           "Les valeurs manquantes représentaient [..]% (k=[..]) et ont été traitées par [..], ",
#'           "choisie car [manquants rares / saisonnalité stable / continuité nécessaire]. ",
#'           "La série présentait une moyenne de [..] (ET=[..]) et une médiane [..]. »"),
#'         
#'         H5("Conclusion & signification"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Les données sont suffisamment propres pour SARIMA » (ou non)."),
#'           tags$li(B("Signification : "),
#'                   "si l’index est régulier et que les manquants sont gérés explicitement, ",
#'                   "les hypothèses du modèle (espacement régulier) deviennent plausibles.")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Imputation silencieuse"), " : toujours documenter méthode + raison."),
#'           tags$li(B("Timestamps irréguliers"), " : SARIMA suppose une grille régulière ; corriger avant toute estimation."),
#'           tags$li(B("Changement de définition de la variable"), " : ex. changement de mesure → rupture structurelle à traiter.")
#'         )
#'       )
#'     )
#'     
#'     # (3) Étape 2 — EDA
#'     pages[[4]] <- make_step(
#'       step_names[4],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant d’ajuster SARIMA.", type="info"),
#'         
#'         Checklist(
#'           CheckItem("Tracer la serie y_t et annoter tendance, saisonnalite, ruptures possibles et changements de variance."),
#'           CheckItem("Construire au moins un graphique saisonnier (seasonal plot ou subseries) pour comprendre la forme par saison."),
#'           CheckItem("Identifier les outliers (dates) et formuler une hypothese (evenement reel vs erreur)."),
#'           CheckItem("Decider et documenter le traitement des outliers (conserver/corriger/imputer) et tester l’impact sur l’analyse."),
#'           CheckItem("Noter ce que l’EDA implique pour la suite: transformation possible, differenciation probable, et presence de ruptures.")
#'         ),
#'         
#'         H5("Définitions utiles (ce qu’on cherche)"),
#'         UL(
#'           tags$li(B("Tendance"), " : évolution de long terme (déterministe ou stochastique)."),
#'           tags$li(B("Saisonnalité"), " : motif périodique de période s (ex. 12)."),
#'           tags$li(B("Rupture structurelle"), " : changement durable de niveau/tendance/variance (ex. politique, crise)."),
#'           tags$li(B("Outlier"), " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou erreur.")
#'         ),
#'         
#'         H5("Graphiques recommandés + leur but"),
#'         UL(
#'           tags$li(B("Courbe y_t"), " : voir tendance, variance, ruptures."),
#'           tags$li(B("Seasonal plot"), " : comparer la forme saisonnière d’une année à l’autre."),
#'           tags$li(B("Boxplots par saison"), " : détecter asymétrie/outliers par mois/semaine."),
#'           tags$li(B("ACF brute"), " (optionnel) : repérer dépendances fortes et saisonnalité.")
#'         ),
#'         
#'         H5("Outliers : procédure raisonnable"),
#'         OL(
#'           tags$li("Repérer visuellement (dates)."),
#'           tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
#'           tags$li("Décider : conserver / corriger / imputer (et justifier)."),
#'           tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
#'         ),
#'         
#'         # === ADD: outils EDA supplémentaires & typologie outliers ===
#'         H5("Outils EDA supplémentaires"),
#'         UL(
#'           tags$li(B("Périodogramme / spectre"), " : met en évidence des fréquences saisonnières inattendues."),
#'           tags$li(B("Seasonal subseries plot"), " : visualise la forme saisonnière par mois/semaine."),
#'           tags$li(B("Nuage niveau–variance"), " : aide au choix log/Box–Cox (variance croît avec le niveau ?).")
#'         ),
#'         H5("Types d’outliers (interventions)"),
#'         UL(
#'           tags$li(B("AO"), " : Additive Outlier (pic ponctuel)."),
#'           tags$li(B("IO"), " : Innovation Outlier (choc qui diffuse)."),
#'           tags$li(B("LS"), " : Level Shift (changement de niveau)."),
#'           tags$li(B("TC"), " : Temporary Change (effet transitoire).")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Résultats (APA) — EDA"),
#'         P("« L’inspection visuelle a mis en évidence une tendance [..] et une saisonnalité récurrente de période s=[..]. ",
#'           "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Box–Cox]. ",
#'           "Des valeurs atypiques autour de [dates] ont été [conservées/traitées] car [événement réel / erreur probable]. »"),
#'         
#'         H5("Conclusion & signification"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« La structure (tendance/saison/variance/outliers) est comprise »"),
#'           tags$li(B("Signification : "),
#'                   "cela guide directement le choix transformation + différenciations (d, D) et évite d’ajuster un SARIMA “à l’aveugle”.")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Confondre saisonnalité et tendance"), " : une moyenne croissante ET une saisonnalité stable sont deux composantes distinctes."),
#'           tags$li(B("Retirer des points réels"), " : si l’outlier correspond à un événement récurrent (fêtes), il doit rester."),
#'           tags$li(B("Ignorer une rupture"), " : un SARIMA “moyenne” une structure qui a changé → mauvais futur.")
#'         )
#'       )
#'     )
#'     
#'     # (4) Étape 3 — Décomposition
#'     pages[[5]] <- make_step(
#'       step_names[5],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "séparer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
#'         
#'         Checklist(
#'           CheckItem("Comparer visuellement une hypothese additive vs multiplicative (amplitude saisonniere constante vs proportionnelle au niveau)."),
#'           CheckItem("Tester l’idee de transformation log/Box-Cox si la variance augmente avec le niveau."),
#'           CheckItem("Realiser une decomposition (classique ou STL) et commenter la tendance, la saisonnalite et le residu."),
#'           CheckItem("Verifier si la saisonnalite semble stable ou evolutive (argument pour STL)."),
#'           CheckItem("Ecrire clairement ce que la decomposition suggere pour d, D, et pour l’echelle de modelisation.")
#'         ),
#'         
#'         H5("Décomposition : définitions"),
#'         UL(
#'           tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
#'                   " (amplitude saisonnière ~ constante)."),
#'           tags$li(B("Multiplicative"), " : ", C("y_t = T_t × S_t × e_t"),
#'                   " (amplitude saisonnière augmente avec le niveau)."),
#'           tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
#'                   C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
#'           tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
#'         ),
#'         
#'         H5("Pourquoi STL ? (objectif détaillé)"),
#'         UL(
#'           tags$li("Quand la saisonnalité change lentement au fil du temps (non parfaitement répétitive)."),
#'           tags$li("Quand on veut réduire l’influence des outliers sur l’estimation saison/tendance."),
#'           tags$li("Quand on veut une lecture pédagogique claire (tendance vs saison vs résidu).")
#'         ),
#'         
#'         H5("Ce que la décomposition ne remplace pas"),
#'         UL(
#'           tags$li("Elle ne prouve pas la stationnarité : SARIMA exige une série stationnaire après différenciation."),
#'           tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nécessaires.")
#'         ),
#'         
#'         # === ADD: paramètres STL & règles pratiques ===
#'         H5("Paramètres STL (lecture pédagogique)"),
#'         UL(
#'           tags$li(B("s.window"), " : lissage saisonnier (", C("periodic"), " = saison constante; entier = évolutive)."),
#'           tags$li(B("t.window"), " : lissage de la tendance (fenêtre LOESS)."),
#'           tags$li(B("robust"), " : réduit l’influence des outliers (itérations avec poids).")
#'         ),
#'         H5("Additif vs multiplicatif (règle pratique)"),
#'         UL(
#'           tags$li("Amplitude saisonnière ~ proportionnelle au niveau → penser ", B("log"), " ou modèle multiplicatif."),
#'           tags$li("Amplitude ~ constante → additif sur niveaux.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Méthodes (APA) — Décomposition"),
#'         P("« Nous avons étudié une structure additive vs multiplicative en évaluant si l’amplitude saisonnière variait avec le niveau. ",
#'           "Comme [..], nous avons retenu [modèle additif / transformation log] et réalisé une décomposition via [classique / STL]. ",
#'           "STL a été privilégiée pour sa flexibilité (saisonnalité évolutive) et sa robustesse aux valeurs atypiques. »"),
#'         
#'         H5("Conclusion & signification"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Le choix additif/multiplicatif est justifié »"),
#'           tags$li(B("Signification : "),
#'                   "on évite des résidus hétéroscédastiques et on améliore la stabilité de l’estimation SARIMA.")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Décomposition ≠ stationnarité"), " : après décomposition, on doit encore tester/choisir d et D."),
#'           tags$li(B("Oublier l’échelle"), " : si vous modélisez log(y), les prévisions doivent être reconverties (avec prudence)."),
#'           tags$li(B("Confondre bruit et structure"), " : des motifs résiduels persistants suggèrent que la saison/tendance n’a pas été correctement capturée.")
#'         )
#'       )
#'     )
#'     
#'     # (5) Étape 4 — Stationnarité (très détaillé : ADF/KPSS/PP + …)
#'     pages[[6]] <- make_step(
#'       step_names[6],
#'       
#'       actions_ui = tagList(
#'         callout(
#'           B("Idée centrale : "),
#'           "Dans un SARIMA, on n’essaie pas de modéliser directement une série ‘qui dérive’ : on cherche d’abord à obtenir une série stationnaire (au moins approximativement) via la différenciation. Les tests ADF, PP et KPSS ne sont pas des “juges” absolus, mais des indices complémentaires qui aident à justifier les choix (d, D) de façon argumentée.",
#'           type = "ok"
#'         ),
#'         
#'         Checklist(
#'           CheckItem("Définir la stationnarité avec vos mots (moyenne/variance stables; dépendance qui ne change pas au cours du temps)."),
#'           CheckItem("Appliquer ADF, KPSS et PP sur la série brute, puis écrire clairement H0 et Ha pour chacun (ils ne testent pas la même chose)."),
#'           CheckItem("Proposer d et D de manière progressive (essayer d=1 puis D=1 si nécessaire) et re-tester après chaque transformation."),
#'           CheckItem("Surveiller les signes de sur‑différenciation (ACF lag 1 très négative, variance gonflée, dynamique artificielle)."),
#'           CheckItem("Justifier le choix final (d, D, s) par convergence : tests + graphiques + ACF/PACF, pas par une seule p‑value.")
#'         ),
#'         
#'         
#'         H5("Définition : stationnarité (ce que cela veut dire)"),
#'         UL(
#'           tags$li(B("Stationnarité faible (covariance-stationnaire)"), " : moyenne constante, variance constante, ",
#'                   "et autocovariance dépend uniquement du retard (pas de t)."),
#'           tags$li(B("Non-stationnarité"), " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."),
#'           tags$li(B("Racine unitaire"), " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1).")
#'         ),
#'         
#'         H5("Différenciation : rôle (d vs D)"),
#'         UL(
#'           tags$li(B("d"), " enlève la racine unitaire non saisonnière / tendance stochastique : ", C("(1-B)^d"), "."),
#'           tags$li(B("D"), " enlève la racine unitaire saisonnière : ", C("(1-B^s)^D"), "."),
#'           tags$li(B("Règle pratique"), " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2).")
#'         ),
#'         
#'         H5("Test ADF (Augmented Dickey–Fuller) — définition & objectif"),
#'         UL(
#'           tags$li(B("But"), " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."),
#'           tags$li(B("Régression (intuition)"), " : on teste si le coefficient de ", C("y_{t-1}"),
#'                   " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."),
#'           tags$li(B("Hypothèses"), " : ",
#'                   B("H0"), " = racine unitaire (non-stationnaire) ; ",
#'                   B("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."),
#'           tags$li(B("Interprétation p-value"), " : p petit → rejet H0 → stationnarité (au sens ADF). p grand → on ne rejette pas → différenciation probablement nécessaire.")
#'         ),
#'         
#'         H5("Test KPSS — définition & objectif (inverse de l’ADF)"),
#'         UL(
#'           tags$li(B("But"), " : tester si la série est stationnaire (niveau ou tendance)."),
#'           tags$li(B("Hypothèses"), " : ",
#'                   B("H0"), " = stationnaire ; ",
#'                   B("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."),
#'           tags$li(B("Interprétation"), " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité.")
#'         ),
#'         
#'         H5("Test PP (Phillips–Perron) — définition & objectif"),
#'         UL(
#'           tags$li(B("But"), " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement (correction non-paramétrique)."),
#'           tags$li(B("Hypothèses"), " : ",
#'                   B("H0"), " = racine unitaire ; ",
#'                   B("Ha"), " = stationnaire."),
#'           tags$li(B("Pourquoi utile"), " : complément de robustesse ; si ADF et PP convergent, confiance accrue.")
#'         ),
#'         
#'         H5("Comment conclure en combinant ADF/KPSS/PP (logique complète)"),
#'         OL(
#'           tags$li(B("Stationnarité forte : "), "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."),
#'           tags$li(B("Non-stationnarité forte : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
#'           tags$li(B("Conflit : "), "les tests divergent → regarder graphiques, ACF, résultats après une différence, et justifier par convergence d’indices (pas une seule p-value).")
#'         ),
#'         
#'         H5("Procédure recommandée (pas à pas)"),
#'         OL(
#'           tags$li("Fixer ", B("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
#'           tags$li("Tester ADF/KPSS/PP sur la série brute."),
#'           tags$li("Essayer d=1 si nécessaire, retester."),
#'           tags$li("Essayer D=1 si saisonnalité/racine saisonnière, retester."),
#'           tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
#'         ),
#'         
#'         H5("Sur-différenciation : définition + symptômes"),
#'         UL(
#'           tags$li(B("Définition"), " : appliquer trop de différences → on introduit une dynamique artificielle."),
#'           tags$li(B("Symptômes fréquents"), " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."),
#'           tags$li(B("Conséquence"), " : intervalles de prévision plus larges et modèle moins fiable.")
#'         ),
#'         
#'         # === ADD: tests/bonnes pratiques complémentaires ===
#'         H5("Tests et notions complémentaires"),
#'         UL(
#'           tags$li(B("Tendance déterministe vs racine unitaire"),
#'                   " : on peut préférer un ARIMA avec ", C("d=0"), " et une tendance ", B("déterministe"),
#'                   " (régression + ARMA sur résidus) si la tendance semble stable."),
#'           tags$li(B("Racine unitaire saisonnière (HEGY)"), " : (annexe) test dédié aux racines à ", C("±1, ±i"), " pour ",
#'                   C("s=4,12"), " ; utile si la saisonnalité stochastique domine."),
#'           tags$li(B("Zivot–Andrews"), " : (annexe) racine unitaire avec rupture endogène possible.")
#'         ),
#'         H5("Bonnes pratiques de différenciation"),
#'         UL(
#'           tags$li(B("Au plus une différence"), " : commencer par ", C("d=1"), " ou ", C("D=1"),
#'                   " ; ", B("éviter"), " ", C("d=2"), " sauf preuves fortes."),
#'           tags$li(B("Sur-différenciation : "), "ACF lag 1 très négative, variance gonflée, MA artificiel → revenir en arrière.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Méthodes (APA) — Tests & choix de (d, D)"),
#'         P("« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
#'           "Les résultats ont été examinés sur la série originale puis après différenciations ordinaires et saisonnières. ",
#'           "Sur la base de l’ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
#'           "afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA, tout en évitant la sur-différenciation. »"),
#'         
#'         H5("Conclusion test (prête à remplir) + signification"),
#'         UL(
#'           tags$li(B("ADF : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
#'                   " H0 (racine unitaire). ",
#'                   B("Signification : "),
#'                   "si rejet → la série est compatible stationnarité (au sens ADF) ; sinon → différenciation probablement nécessaire."),
#'           tags$li(B("KPSS : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
#'                   " H0 (stationnarité). ",
#'                   B("Signification : "),
#'                   "si rejet → non-stationnarité (donc d/D à augmenter ou transformation/rupture à traiter)."),
#'           tags$li(B("PP : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
#'                   " H0 (racine unitaire). ",
#'                   B("Signification : "),
#'                   "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
#'         ),
#'         
#'         H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Nous retenons d=[..], D=[..], s=[..]. »"),
#'           tags$li(B("Signification : "),
#'                   "« le SARIMA sera estimé sur la série différenciée ; les paramètres AR/MA décrivent la dynamique ",
#'                   "restante après retrait de la tendance et/ou de la saisonnalité non stationnaire. »")
#'         ),
#'         
#'         # === ADD: points à expliciter
#'         H5("À expliciter (rappel)"),
#'         UL(
#'           tags$li("Préciser si une constante/drift est incluse et à quel niveau (avant/après différenciation)."),
#'           tags$li("Documenter toute rupture suspectée et ses conséquences sur le choix de ", C("d, D"), ".")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Choisir d et D “par habitude”"), " : toujours justifier par tests + EDA."),
#'           tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent “crier non-stationnaire” alors qu’un changement de régime est en cause."),
#'           tags$li(B("Interpréter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on s’appuie sur convergence des preuves.")
#'         )
#'       )
#'     )
#'     
#'     # (6) Étape 5 — Auto-ARIMA baseline
#'     pages[[7]] <- make_step(
#'       step_names[7],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "obtenir un point de départ compétitif, puis vérifier/affiner.", type="info"),
#'         
#'         Checklist(
#'           CheckItem("Executer auto-ARIMA avec des bornes raisonnables sur p,q,P,Q et noter le critere (AICc) utilise."),
#'           CheckItem("Enregistrer le modele baseline (ordres + presence drift/constante) pour comparaison ulterieure."),
#'           CheckItem("Verifier diagnostics residuels (ACF residus, Ljung-Box) avant de le considerer ‘acceptable’."),
#'           CheckItem("Evaluer la performance sur la fenetre test (MAE/RMSE) et comparer au benchmark naif/SNAIVE."),
#'           CheckItem("Decider si vous cherchez une version plus parcimonieuse (BIC plus faible ou meme performance avec moins de parametres).")
#'         ),
#'         
#'         H5("Définition : auto-ARIMA (ce que fait réellement l’algorithme)"),
#'         UL(
#'           tags$li("Explore un ensemble de modèles candidats (p,q,P,Q) sous contraintes."),
#'           tags$li("Choisit souvent via minimisation ", B("AICc"),
#'                   " (AIC corrigé petits échantillons)."),
#'           tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coûteuse).")
#'         ),
#'         
#'         H5("Pourquoi AICc ? (objectif)"),
#'         UL(
#'           tags$li("Compromis entre qualité d’ajustement et complexité (pénalise les paramètres)."),
#'           tags$li("AICc est préférable à AIC quand n n’est pas très grand par rapport au nombre de paramètres.")
#'         ),
#'         
#'         H5("Procédure propre"),
#'         OL(
#'           tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
#'           tags$li("Fixer bornes max p/q/P/Q ; documenter."),
#'           tags$li("Sauvegarder le modèle baseline (pour comparaison)."),
#'           tags$li("Vérifier diagnostics résiduels + performance sur test.")
#'         ),
#'         
#'         # === ADD: détails de recherche & critères multiples ===
#'         H5("Détails de recherche"),
#'         UL(
#'           tags$li(B("Stepwise vs exhaustive"), " : stepwise = rapide, peut rater un optimum global ; exhaustive = coûteux mais plus fiable."),
#'           tags$li(B("Contraintes"), " : imposer ", C("p,q,P,Q \u2264"), " bornes raisonnables ; forcer stabilité/inversibilité."),
#'           tags$li(B("drift/constante"), " : tester versions avec et sans drift lorsque ", C("d=1"), ".")
#'         ),
#'         H5("Critères multiples"),
#'         UL(
#'           tags$li("Comparer AICc ", B("et"), " BIC ; en cas de quasi-égalité → choisir le plus parcimonieux.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Méthodes (APA) — baseline"),
#'         P("« Un modèle SARIMA de référence a été sélectionné via une procédure auto-ARIMA basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats sous contraintes [..]. ",
#'           "La spécification obtenue a été utilisée comme baseline, puis comparée à des modèles manuels plus parcimonieux sur la base des diagnostics et de la performance de prévision. »"),
#'         
#'         H5("Conclusion & signification"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Auto-ARIMA fournit une baseline solide »"),
#'           tags$li(B("Signification : "), "« on a un repère : tout modèle final doit faire au moins aussi bien. »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Modèle “trop complexe”"), " : stepwise peut sélectionner des ordres élevés → instabilité, interprétation difficile."),
#'           tags$li(B("AICc excellent mais résidus mauvais"), " : diagnostics priment."),
#'           tags$li(B("Oublier la parcimonie"), " : si deux modèles prédisent pareil, garder le plus simple.")
#'         )
#'       )
#'     )
#'     
#'     # (7) Étape 6 — SARIMA manuel
#'     pages[[8]] <- make_step(
#'       step_names[8],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "proposer un petit ensemble raisonné de candidats via ACF/PACF.", type="info"),
#'         
#'         Checklist(
#'           CheckItem("Tracer ACF/PACF de la serie differenciee (apres choix d et D) et identifier les pics significatifs."),
#'           CheckItem("Proposer un petit ensemble de candidats (3 a 8) en justifiant p,q,P,Q par les motifs ACF/PACF (y compris aux multiples de s)."),
#'           CheckItem("Ajuster chaque candidat, relever AICc/BIC, et verifier stabilite/inversibilite si possible."),
#'           CheckItem("Comparer sur diagnostics residuels ET performance predictive (pas seulement AICc)."),
#'           CheckItem("Garder le modele le plus simple qui passe diagnostics et bat le benchmark.")
#'         ),
#'         
#'         H5("Définitions : ACF / PACF (ce que mesurent ces courbes)"),
#'         UL(
#'           tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"),
#'                   " → suggère MA(q) si coupure nette vers q."),
#'           tags$li(B("PACF"), " : corrélation “pure” au retard k une fois les retards <k contrôlés ",
#'                   "→ suggère AR(p) si coupure nette vers p.")
#'         ),
#'         
#'         H5("Heuristiques (non saisonnier)"),
#'         UL(
#'           tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF décroît."),
#'           tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF décroît."),
#'           tags$li(B("ARMA"), " : ACF et PACF décroissent (pas de coupure franche).")
#'         ),
#'         
#'         H5("Heuristiques saisonnières (multiples de s)"),
#'         UL(
#'           tags$li(B("SAR(P)"), " : pics PACF à s, 2s, ..."),
#'           tags$li(B("SMA(Q)"), " : pics ACF à s, 2s, ...")
#'         ),
#'         
#'         H5("Procédure recommandée (petit nombre de modèles)"),
#'         OL(
#'           tags$li("Construire 3 à 8 candidats (parcimonieux)."),
#'           tags$li("Ajuster et comparer AICc/BIC."),
#'           tags$li("Vérifier stabilité/inversibilité."),
#'           tags$li("Retenir ceux qui passent diagnostics + prévision.")
#'         ),
#'         
#'         # === ADD: conception de candidats & lecture fine ===
#'         H5("Conception de candidats (rappels utiles)"),
#'         UL(
#'           tags$li(B("Limiter le set"), " : 3–8 modèles max, justifiés par ACF/PACF."),
#'           tags$li(B("Stabilité/inversibilité"), " : vérifier racines des polynômes AR/MA (hors cercle unité)."),
#'           tags$li(B("drift/constante"), " : inclure/exclure et comparer au niveau AICc/BIC + diagnostics.")
#'         ),
#'         H5("Lecture fine ACF/PACF"),
#'         UL(
#'           tags$li("Pics à ", C("s, 2s, 3s"), " dans l’ACF → penser ", B("SMA(Q)"), "."),
#'           tags$li("Pics à ", C("s, 2s"), " dans la PACF → penser ", B("SAR(P)"), "."),
#'           tags$li("Queue AR (décroissance géométrique) vs coupure MA (après q).")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Méthodes (APA) — sélection manuelle"),
#'         P("« Les structures candidates ont été proposées sur la base des schémas ACF/PACF de la série différenciée. ",
#'           "Des autocorrélations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
#'           "Un ensemble restreint de modèles (n=[..]) a été ajusté et comparé via AICc/BIC et diagnostics résiduels, en privilégiant la parcimonie. »"),
#'         
#'         H5("Conclusion & signification"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Le modèle final est soutenu par la structure ACF/PACF et les diagnostics. »"),
#'           tags$li(B("Signification : "), "« on réduit le risque de sur-ajustement en limitant les candidats. »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Brute-force massif"), " : tester 200 modèles puis choisir le plus petit AICc = data snooping."),
#'           tags$li(B("Surinterpréter ACF/PACF"), " : ce sont des guides, pas des preuves."),
#'           tags$li(B("Ignorer l’inversibilité/stabilité"), " : paramètres instables → prévisions incohérentes.")
#'         )
#'       )
#'     )
#'     
#'     # (8) Étape 7 — Diagnostics & comparaison
#'     pages[[9]] <- make_step(
#'       step_names[9],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "valider que le modèle explique toute la dépendance et prédit bien.", type="ok"),
#'         
#'         Checklist(
#'           CheckItem("Examiner les residus: courbe temporelle, ACF residus, et Ljung-Box a plusieurs lags L."),
#'           CheckItem("Verifier qu’il n’y a pas de structure residuelle (p-value Ljung-Box non significative) et ajuster si necessaire."),
#'           CheckItem("Evaluer la prediction hors-echantillon (MAE/RMSE/MASE) avec le meme horizon et le meme protocole pour tous les modeles."),
#'           CheckItem("Comparer explicitement au benchmark (naif/SNAIVE) et conclure sur la valeur ajoutee."),
#'           CheckItem("Documenter toute violation (ARCH, rupture, non-normalite) et expliquer l’impact sur IC et interpretation.")
#'         ),
#'         
#'         H5("Diagnostics résiduels : définitions & buts"),
#'         UL(
#'           tags$li(B("Résidus"), " : ", C("e_t = y_t - ŷ_t"),
#'                   " (ou résidus d’innovation selon l’implémentation)."),
#'           tags$li(B("Bruit blanc"), " : absence d’autocorrélation résiduelle → le modèle a capturé la structure temporelle."),
#'           tags$li(B("Ljung–Box"), " : test global d’autocorrélation des résidus jusqu’à un lag L.")
#'         ),
#'         
#'         H5("Test de Ljung–Box (définition + interprétation)"),
#'         UL(
#'           tags$li(B("But"), " : tester si les autocorrélations résiduelles jusqu’à L sont globalement nulles."),
#'           tags$li(B("Hypothèses"), " : ", B("H0"), " = pas d’autocorrélation résiduelle ; ", B("Ha"), " = autocorrélation résiduelle présente."),
#'           tags$li(B("Conclusion"), " : p petit → rejet H0 → modèle incomplet (ajuster p/q/P/Q ou d/D)."),
#'           tags$li(B("Signification pratique"), " : si autocorrélation résiduelle reste, vos intervalles/prévisions sont souvent trop optimistes.")
#'         ),
#'         
#'         H5("Normalité & hétéroscédasticité (à quoi ça sert vraiment)"),
#'         UL(
#'           tags$li(B("Normalité"), " : utile pour l’interprétation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
#'           tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimés ; si fort, envisager modèles de variance (GARCH) selon le cours.")
#'         ),
#'         
#'         H5("Évaluation prévision (définition + protocole)"),
#'         UL(
#'           tags$li(B("Split temporel"), " : entraîner sur le passé, tester sur le futur."),
#'           tags$li(B("Rolling-origin"), " : répéter sur plusieurs origines → estimation plus robuste."),
#'           tags$li(B("Benchmark"), " : naїf / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE à l’horizon cible.")
#'         ),
#'         
#'         # === ADD: diagnostics additionnels & comparaison ===
#'         H5("Diagnostics additionnels"),
#'         UL(
#'           tags$li(B("Box–Pierce vs Ljung–Box"), " : préférer Ljung–Box (meilleure petite taille)."),
#'           tags$li(B("Normalité résiduelle"), " : Q–Q plot, Jarque–Bera ; utile pour IC mais secondaire si but = point forecast."),
#'           tags$li(B("Hétéroscédasticité / ARCH"), " : tester ACF des résidus au carré ; si fort → discuter modèles de variance (annexe)."),
#'           tags$li(B("Significativité des coefficients"), " : rapporter est., SE, z, p ; supprimer termes non significatifs si performance constante.")
#'         ),
#'         H5("Comparaison de modèles"),
#'         UL(
#'           tags$li(B("Tableau récapitulatif"), " : AICc/BIC, Ljung–Box (p), MAE/RMSE/MASE, nb de paramètres."),
#'           tags$li(B("Test de Diebold–Mariano"), " : (annexe) comparer formellement 2 séries d’erreurs prédictives.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Résultats (APA) — diagnostics"),
#'         P("« Les diagnostics résiduels indiquaient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics substantiels et le test de Ljung–Box était [non significatif/significatif] au seuil α=[..]. ",
#'           "La performance de prévision sur la fenêtre d’évaluation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. »"),
#'         
#'         H5("Conclusion & signification (diagnostics + performance)"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Le modèle est acceptable » si Ljung–Box non significatif ET benchmark battu."),
#'           tags$li(B("Signification : "),
#'                   "« le modèle capte la structure temporelle (résidus ~ bruit) et apporte un gain prédictif réel (out-of-sample). »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Bon AIC mais Ljung–Box significatif"), " : modèle incomplet → ne pas valider."),
#'           tags$li(B("Se focaliser sur la normalité"), " : priorité = absence d’autocorrélation résiduelle."),
#'           tags$li(B("Comparer des modèles sur des horizons différents"), " : toujours même h, même protocole.")
#'         )
#'       )
#'     )
#'     
#'     # (9) Étape 8 — Rédaction
#'     pages[[10]] <- make_step(
#'       step_names[10],
#'       
#'       actions_ui = tagList(
#'         callout(B("But : "), "écrire un rapport clair, reproductible, aligné aux étapes 0–7.", type="info"),
#'         
#'         Checklist(
#'           CheckItem("Rediger une section Methodes qui suit exactement le pipeline: donnees -> EDA -> stationnarite -> selection -> diagnostics -> prevision."),
#'           CheckItem("Inclure figures indispensables: serie, decomposition, ACF/PACF, residus, previsions + intervalles."),
#'           CheckItem("Inclure un tableau de comparaison (AICc/BIC, Ljung-Box, MAE/RMSE, benchmark, nb parametres)."),
#'           CheckItem("Preciser l’echelle (niveau/log/Box-Cox) et expliquer toute reconversion des previsions."),
#'           CheckItem("Ajouter un encadre limites + pistes (ruptures, SARIMAX, GARCH) et assurer la reproductibilite (versions).")
#'         ),
#'         
#'         H5("Structure APA recommandée (définition)"),
#'         UL(
#'           tags$li(B("Méthodes"), " : ce que vous avez fait et pourquoi (données → EDA → stationnarité → modèles → évaluation)."),
#'           tags$li(B("Résultats"), " : ce que vous avez observé (stats, figures, tests, métriques, modèle final)."),
#'           tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
#'         ),
#'         
#'         H5("Pack livrable propre (checklist)"),
#'         UL(
#'           tags$li("Notebook/script reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
#'           tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC."),
#'           tags$li("Tableau : candidats vs AICc/BIC vs Ljung–Box vs MAE/RMSE vs benchmark.")
#'         ),
#'         
#'         # === ADD: rapporter correctement les prévisions ===
#'         H5("Rapporter correctement les prévisions"),
#'         UL(
#'           tags$li(B("Niveau de couverture"), " : préciser 80% et/ou 95% ; indiquer si log-échelle a été reconvertie."),
#'           tags$li(B("Biais de reconversion (log→niveau)"), " : mentionner correction ",
#'                   C("exp(\\hat{y}) \\times exp(\\hat{\\sigma}^2/2)"), " si utilisée."),
#'           tags$li(B("Reproductibilité"), " : versions R/packages, seed, chemin des données, date d’extraction.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Phrase finale (APA) — modèle final + interprétation"),
#'         P("« Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). ",
#'           "Les résidus étant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a été capturée. ",
#'           "Les prévisions produites à horizon h=[..] améliorent le benchmark [..] selon MAE/RMSE, ce qui soutient l’usage du modèle pour l’application ciblée. »"),
#'         
#'         H5("Conclusion & signification"),
#'         UL(
#'           tags$li(B("Conclusion : "), "« Le rapport est aligné, justifié, reproductible. »"),
#'           tags$li(B("Signification : "),
#'                   "« un lecteur externe peut reproduire vos résultats et comprendre chaque choix (transformation, d/D, sélection, diagnostics). »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Ne pas relier choix → preuves"), " : chaque décision doit être liée à EDA/tests/diagnostics."),
#'           tags$li(B("Trop de texte, pas assez de figures"), " : en séries temporelles, les figures sont des résultats."),
#'           tags$li(B("Oublier de préciser l’échelle"), " : niveau vs log vs Box–Cox et reconversion des prévisions.")
#'         )
#'       )
#'     )
#'     
#'     # (10) Annexes
#'     pages[[11]] <- make_step(
#'       step_names[11],
#'       
#'       actions_ui = tagList(
#'         Checklist(
#'           CheckItem("Reconnaitre et pouvoir ecrire les trois benchmarks (naif, drift, SNAIVE) et expliquer quand chacun est approprie."),
#'           CheckItem("Savoir lire rapidement un resultat ADF/KPSS/PP et traduire la conclusion en choix de d et D."),
#'           CheckItem("Savoir expliquer ce que signifie Ljung-Box significatif (structure residuelle) et quelle action entreprendre."),
#'           CheckItem("Memoriser les formules utiles (AIC/AICc/BIC, Ljung-Box, operateurs de differenciation) et leur interpretation."),
#'           CheckItem("Identifier quand il faut sortir du cadre SARIMA (exogenes, multiples saisonnalites, ruptures, variance conditionnelle).")
#'         ),
#'         
#'         H5("Benchmarks (définitions)"),
#'         UL(
#'           tags$li(B("Naïf"), " : ", C("ŷ_{t+1|t} = y_t"), " (persistance)."),
#'           tags$li(B("Drift"), " : extrapolation linéaire moyenne."),
#'           tags$li(B("SNAIVE"), " : répète la dernière valeur de la même saison : ", C("ŷ_{t+h|t} = y_{t+h-s}"), ".")
#'         ),
#'         
#'         H5("Règles d’interprétation ultra rapides"),
#'         UL(
#'           tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " → stationnarité plausible."),
#'           tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " → différenciation nécessaire."),
#'           tags$li(B("Ljung–Box significatif"), " → il reste de la structure → réviser le modèle.")
#'         ),
#'         
#'         # === ADD: formules utiles & pistes avancées ===
#'         H5("Formules utiles (mémo)"),
#'         UL(
#'           tags$li(B("Critères d’info"), " : ",
#'                   C("AIC=-2\\log L+2k"), ", ",
#'                   C("AICc= AIC + \\frac{2k(k+1)}{n-k-1}"), ", ",
#'                   C("BIC=-2\\log L+k\\log n"), "."),
#'           tags$li(B("MASE"), " : ", C("\\frac{\\frac{1}{T}\\sum_{t}|e_t|}{\\frac{1}{T-s}\\sum_{t}|y_t-y_{t-s}|}"), " (pour périodicité ", C("s"), ")."),
#'           tags$li(B("Ljung–Box"), " : ", C("Q^* = n(n+2)\\sum_{k=1}^{L} \\frac{\\hat{\\rho}_k^2}{n-k}"),
#'                   " ~ ", C("\\chi^2"), " sous ", C("H_0"), " avec ddl ≈ ", C("L - p - q - (P+Q)"), "."),
#'           tags$li(B("Backshift & diff."), " : ",
#'                   C("\\nabla=(1-B)"), ", ", C("\\nabla_s=(1-B^s)"), ", ",
#'                   C("\\nabla^d \\nabla_s^D y_t"), " pour stationnariser.")
#'         ),
#'         H5("Pistes avancées (pour l’enseignant)"),
#'         UL(
#'           tags$li(B("SARIMAX / régression dynamique"), " : variables exogènes, pré-blanchiment, fonctions de transfert."),
#'           tags$li(B("Ruptures/Interventions"), " : dummies LS/TC, estimation avec régresseurs."),
#'           tags$li(B("Multiples saisonnalités"), " : TBATS/ETS-MS si présence de s multiples.")
#'         )
#'       ),
#'       
#'       apa_ui = tagList(
#'         H5("Template “Conclusion tests → choix (d,D)” (copier-coller)"),
#'         P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
#'           "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnarité, ",
#'           "nous concluons que la série est [stationnaire/non-stationnaire] au sens des diagnostics combinés. ",
#'           "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une série stationnaire pour l’estimation SARIMA. »"),
#'         
#'         H5("Signification (traduction simple)"),
#'         UL(
#'           tags$li("« d et D disent combien de fois on doit “retirer” une tendance et une saisonnalité non stationnaire. »"),
#'           tags$li("« Ensuite, p/q/P/Q décrivent la dépendance restante (mémoire) dans la série transformée. »")
#'         )
#'       ),
#'       
#'       pitfalls_ui = tagList(
#'         UL(
#'           tags$li(B("Croire qu’un test “décide” seul"), " : toujours trianguler avec EDA + ACF + comportement après différenciation."),
#'           tags$li(B("Oublier la finalité"), " : prévision (out-of-sample) + diagnostics passent avant l’esthétique d’un AIC."),
#'           tags$li(B("Ne pas documenter"), " : un bon modèle non documenté = inutilisable dans un cours/rapport.")
#'         )
#'       )
#'     )
#'     
#'     # ========= Output =========
#'     tagList(
#'       css,
#'       tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
#'       progress_ui,
#'       pages[[cur + 1L]]
#'     )
#'   })
  
   
  
  
  
  
  
  # --- Roadmap slider navigation (Prev/Next) ---
  observeEvent(input$road_prev, {
    cur <- input$roadmap_step
    if (is.null(cur)) cur <- 0
    updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  }, ignoreInit = TRUE)
  
  observeEvent(input$road_next, {
    cur <- input$roadmap_step
    if (is.null(cur)) cur <- 0
    updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  }, ignoreInit = TRUE)
  
  # =========================
  # Roadmap UI (controls)
  # =========================
  output$roadmap_Detailed_Fr_ui4 <- renderUI({
    
    tags$div(
      class = "road-shell",
      style = "background:#f7f7f7;padding:14px;border-radius:10px;",
      
      tags$style(HTML("
.road-shell {background:#f7f7f7;padding:14px;border-radius:12px;border:1px solid #ececec;}
      .road-title {margin:0 0 6px 0;font-size:22px;font-weight:800;letter-spacing:.2px;}
      .road-sub {margin:0 0 12px 0;color:#555;line-height:1.45;}
      .road-nav {display:flex;gap:10px;align-items:center;flex-wrap:wrap;position:sticky;top:0;z-index:50;background:#f7f7f7;padding:10px 0 8px 0;border-bottom:1px solid #ececec;}
      .road-nav .btn {min-width:46px;border-radius:10px;padding:6px 12px;}
      .road-nav .btn:focus {outline:none;box-shadow:0 0 0 3px rgba(76,120,168,.25);}
      .road-nav .form-group {margin-bottom:0;}
      /* Slider polish (Shiny uses ionRangeSlider) */
      .road-shell .irs--shiny .irs-bar {background:#4C78A8;}
      .road-shell .irs--shiny .irs-handle>i:first-child {background:#4C78A8;}
      .road-shell .irs--shiny .irs-from,
      .road-shell .irs--shiny .irs-to,
      .road-shell .irs--shiny .irs-single {background:#4C78A8;}
      @media (max-width: 900px) {
        .road-nav {gap:8px;}
        .road-nav .irs {width:100% !important;}
        .road-nav .form-group {width:100%;}
      }
      .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin-top:14px;box-shadow:0 2px 10px rgba(0,0,0,.03);}
      .step-header {display:flex;align-items:center;justify-content:space-between;gap:10px;margin-bottom:8px;}
      .step-badge {display:inline-block;font-weight:800;font-size:12px;letter-spacing:.3px;text-transform:uppercase;padding:4px 10px;border-radius:999px;background:#eef4fb;color:#254b74;border:1px solid #d9e7f6;}
      .step-hint {color:#666;font-size:12px;}
      details {background:#ffffff;border:1px solid #eaeaea;border-radius:12px;padding:0;margin:10px 0;overflow:hidden;}
      details > summary {cursor:pointer;font-weight:700;padding:10px 12px;list-style:none;display:flex;align-items:center;justify-content:space-between;gap:12px;background:linear-gradient(180deg,#ffffff 0%,#fbfbfb 100%);}
      details > summary::-webkit-details-marker {display:none;}
      details > summary:after {content:'▸';font-size:16px;color:#666;transform:rotate(0deg);transition:transform .12s ease;}
      details[open] > summary:after {transform:rotate(90deg);}
      details:hover {border-color:#dcdcdc;}
      details[open] {border-color:#d9e7f6;box-shadow:0 2px 10px rgba(76,120,168,.08);}
      .callout {border-left:5px solid #4C78A8;background:#fafafa;padding:12px 12px;border-radius:10px;margin:10px 0;}
      .callout.warn {border-left-color:#E45756;background:#fff7f7;}
      .callout.ok {border-left-color:#72B7B2;background:#f7fffb;}
      .callout.deliver {border-left-color:#54A24B; background:#f6fff6;}
      .callout.checklist {border-left-color:#F2CF5B;background:#fffdf4;}
      .checklist-title {display:flex;align-items:center;gap:8px;margin-bottom:6px;}
      .checklist-icon {font-weight:800;}
      code {background:#f3f3f3;padding:0 4px;border-radius:4px;}
      .progress {height:10px;border-radius:999px;background:#ececec;overflow:hidden;margin:10px 0 0 0;}
      .progress-bar {border-radius:999px;}")),
      
      tags$h3(class="road-title", "Feuille de route SARIMA (version pédagogique)"),
      tags$p(class="road-sub",
             "Utilisez le curseur pour passer d’une étape à l’autre. Chaque étape contient : Actions → À écrire (APA) → Pièges."),
      
      tags$div(
        class = "road-nav",
        actionButton("road_prev", "◀", class = "btn btn-default"),
        sliderInput(
          "roadmap_step", label = NULL,
          min = 0, max = 10, value = 0, step = 1, width = "520px"
        ),
        actionButton("road_next", "▶", class = "btn btn-default"),
        tags$span(style="color:#666;", "Astuce : gardez les blocs repliés pour éviter toute scroll.")
      ),
      
      # Progress bar (pure UI, updated via re-render of content)
      shiny::uiOutput("roadmap_step_content")
    )
  })
  
  # =========================
  # Roadmap UI (content)
  # =========================
  output$roadmap_step_content <- renderUI({
    
    # ========= Helpers =========
    D <- function(title, ...) {
      tags$details(
        tags$summary(title),
        tags$div(class = "road-scroll", ...)
      )
    }
    UL <- function(...) tags$ul(...)
    OL <- function(...) tags$ol(...)
    P  <- function(...) tags$p(...)
    B  <- function(...) tags$b(...)
    C  <- function(...) tags$code(...)
    H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
    
    # ========= Checklist helpers (UI only) =========
    # These are intentionally simple visual checklists (no reactive logic).
    # Pedagogical goal: help students translate “read/explain” into
    # concrete actions they can verify before moving to the next step.
    CheckItem <- function(...) {
      tags$li(
        tags$span(class = "chkbox", "☐"),
        tags$span(...)
      )
    }
    Checklist <- function(...) {
      tags$div(
        class = "callout checklist",
        tags$div(
          class = "checklist-title",
          tags$span(class = "checklist-icon", "☑"),
          tags$b("Checklist étudiant")
        ),
        tags$ul(class = "chk", ...)
      )
    }
    
    
    Deliverables <- function(...) {
      tags$div(
        class = "callout deliver",
        tags$b("Sorties attendues (à conserver pour le rapport)"),
        tags$ul(...)
      )
    }
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    # ========= CSS (internal scroll so the page stays short) =========
    css <- tags$style(HTML("
.road-card {background:#fff;border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin-top:14px;box-shadow:0 2px 10px rgba(0,0,0,.03);}
    .step-header {display:flex;align-items:center;justify-content:space-between;gap:10px;margin-bottom:8px;}
    .step-badge {display:inline-block;font-weight:800;font-size:12px;letter-spacing:.3px;text-transform:uppercase;padding:4px 10px;border-radius:999px;background:#eef4fb;color:#254b74;border:1px solid #d9e7f6;}
    .step-hint {color:#666;font-size:12px;}
    details {background:#ffffff;border:1px solid #eaeaea;border-radius:12px;padding:0;margin:10px 0;overflow:hidden;}
    details > summary {cursor:pointer;font-weight:700;padding:10px 12px;list-style:none;display:flex;align-items:center;justify-content:space-between;gap:12px;background:linear-gradient(180deg,#ffffff 0%,#fbfbfb 100%);}
    details > summary::-webkit-details-marker {display:none;}
    details > summary:after {content:'▸';font-size:16px;color:#666;transform:rotate(0deg);transition:transform .12s ease;}
    details[open] > summary:after {transform:rotate(90deg);}
    details:hover {border-color:#dcdcdc;}
    details[open] {border-color:#d9e7f6;box-shadow:0 2px 10px rgba(76,120,168,.08);}
    .road-scroll {max-height: 62vh; overflow-y: auto; padding:10px 12px 12px 12px; padding-right: 14px;}
    .road-scroll::-webkit-scrollbar {width: 10px;}
    .road-scroll::-webkit-scrollbar-thumb {background: #e0e0e0; border-radius: 999px; border: 3px solid #fff;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:12px 12px; border-radius:10px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
      .callout.deliver {border-left-color:#54A24B; background:#f6fff6;}
    .callout.checklist {border-left-color:#F2CF5B; background:#fffdf4;}
    .checklist-title {display:flex; align-items:center; gap:8px; margin-bottom:6px;}
    .checklist-icon {font-weight:800;}
    code {background:#f3f3f3; padding:0 4px; border-radius:4px;}
    .progress {height:10px; border-radius:999px; background:#ececec; overflow:hidden; margin:10px 0 0 0;}
    .progress-bar {border-radius:999px;}
    /* Checklist: checkbox-style bullets */
    ul.chk {padding-left: 0; margin: 8px 0 0 0;}
    ul.chk li {list-style: none; margin: 7px 0; display:flex; align-items:flex-start; gap:8px;}
    .chkbox {display:inline-block; width: 18px; font-weight: 800; margin-top: 1px;}"))
    
    # ========= Step logic =========
    cur <- input$roadmap_step
    if (is.null(cur) || !is.finite(cur)) cur <- 0
    cur <- as.integer(cur)
    
    step_names <- c(
      "Aperçu & notations (glossaire + lecture du modèle)",
      "Étape 0 — Définir le problème de modélisation",
      "Étape 1 — Décrire les données (qualité, manquants, descriptifs)",
      "Étape 2 — Explorer visuellement (EDA) : tendance/saison/outliers",
      "Étape 3 — Décomposer : additif vs multiplicatif, STL, robustesse",
      "Étape 4 — Stationnarité & différenciation : ADF / KPSS / PP (d, D)",
      "Étape 5 — Baseline : Auto-ARIMA (point de départ, pas un dogme)",
      "Étape 6 — SARIMA manuel : ACF/PACF + candidats raisonnés",
      "Étape 7 — Diagnostics & comparaison : résidus + performance prévision",
      "Étape 8 — Rédaction : Méthodes/Résultats (APA) + livrables propres",
      "Annexes — Formules, checklists, templates, interprétations rapides"
    )
    
    pct <- round(100 * cur / 10)
    progress_ui <- tags$div(
      class="progress",
      tags$div(
        class="progress-bar",
        role="progressbar",
        `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
        style = paste0("width:", pct, "%;")
      )
    )
    
    make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
      step_badge <- if (isTRUE(cur == 0L)) "Aperçu" else paste0("Étape ", cur, "/10")
      tags$div(
        class = "road-card",
        if (!is.null(header_ui)) header_ui,
        tags$div(
          class = "step-header",
          tags$span(class = "step-badge", step_badge),
          tags$span(class = "step-hint", "Dépliez un bloc à la fois : Actions → APA → Pièges.")
        ),
        tags$h4(title),
        D("1) Ce que l’étudiant fait (procédure + définitions + objectifs)", actions_ui),
        D("2) Ce qu’il écrit (APA) + conclusion & signification", apa_ui),
        D("3) Pièges + comment les éviter (avec interprétation)", pitfalls_ui)
      )
    }
    
    # ========= Pages =========
    pages <- vector("list", length = 11)
    
    # (0) Aperçu
    pages[[1]] <- make_step(
      step_names[1],
      
      actions_ui = tagList(
        callout(
          B("Objectif global : "),
          "construire un modèle SARIMA interprétable et surtout ",
          B("prédictif"), " : il doit passer les diagnostics résiduels et battre un benchmark simple.",
          type="ok"
        ),
        
        Checklist(
          CheckItem("Identifier clairement la série y_t (ce que vous cherchez à prévoir), préciser son unité, sa source et le contexte d’application (ex. ventes mensuelles, débit quotidien, température horaire)."),
          CheckItem("Fixer la période saisonnière s à partir du contexte et vérifier qu’elle est cohérente avec l’échantillonnage (ex. s=12 pour mensuel, s=7 pour hebdomadaire, s=4 pour trimestriel)."),
          CheckItem("Lire la forme générale du SARIMA et expliquer le rôle de chaque bloc : différenciation (d, D) pour stationnariser, puis composantes AR/MA (p, q, P, Q) pour modéliser la dépendance restante."),
          CheckItem("Énoncer des critères de validation explicites : résidus ≈ bruit blanc (ACF résidus + Ljung–Box), performance hors‑échantillon (train/test ou rolling-origin) et parcimonie (le plus simple qui marche)."),
          CheckItem("Choisir un benchmark (naïf / drift / SNAIVE), l’écrire noir sur blanc et expliquer pourquoi il est pertinent : sans repère, on ne peut pas juger la valeur ajoutée d’un SARIMA.")
        ),
        
        Deliverables(
          tags$li("Une fiche “Notations & objectifs” : y_t, unité de temps, période saisonnière s, et le rôle de (p,d,q)(P,D,Q)[s]."),
          tags$li("Un protocole de validation écrit (train/test ou rolling-origin) + la métrique principale choisie (MAE/RMSE, etc.)."),
          tags$li("Un benchmark explicite (naïf / drift / SNAIVE) qui servira de référence tout au long du projet.")
        ),
        
        
        
        # H5("Notations essentielles (définitions)"),
        # UL(
        #   tags$li(B("Série temporelle"), " : suite ordonnée d’observations indexées par le temps ", C("y_t"), "."),
        #   tags$li(B("Fréquence / période saisonnière"), " : nombre de pas par cycle saisonnier, noté ", C("s"),
        #           " (ex. mensuel s=12; quotidien avec saison hebdo s=7)."),
        #   tags$li(B("Opérateur de retard (backshift)"), " : ", C("B y_t = y_{t-1}"), "."),
        #   tags$li(B("Différenciation ordinaire"), " : ", C("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
        #           " ; appliquée ", C("d"), " fois → supprimer tendance/racine unitaire non saisonnière."),
        #   tags$li(B("Différenciation saisonnière"), " : ", C("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
        #           " ; appliquée ", C("D"), " fois → supprimer racine unitaire saisonnière."),
        #   tags$li(B("Innovations / bruit blanc"), " : ", C("ε_t ~ w.n.(0, σ²)"),
        #           " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
        # ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Notations essentielles (définitions)")),
          
          tags$ul(
            tags$li(tags$b("Série temporelle"),
                    " : suite ordonnée d’observations indexées par le temps ",
                    tags$code("y_t"), "."),
            
            tags$li(tags$b("Fréquence / période saisonnière"),
                    " : nombre de pas par cycle saisonnier, noté ",
                    tags$code("s"),
                    " (ex. mensuel s = 12 ; quotidien avec saison hebdo s = 7)."),
            
            tags$li(tags$b("Opérateur de retard (backshift)"),
                    " : ", tags$code("B y_t = y_{t-1}"), "."),
            
            tags$li(tags$b("Différenciation ordinaire"),
                    " : ", tags$code("∇ y_t = (1-B)y_t = y_t - y_{t-1}"),
                    " ; appliquée ", tags$code("d"),
                    " fois → supprimer tendance / racine unitaire non saisonnière."),
            
            tags$li(tags$b("Différenciation saisonnière"),
                    " : ", tags$code("∇_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
                    " ; appliquée ", tags$code("D"),
                    " fois → supprimer racine unitaire saisonnière."),
            
            tags$li(tags$b("Innovations / bruit blanc"),
                    " : ", tags$code("ε_t ~ w.n.(0, σ²)"),
                    " signifie des chocs non autocorrélés (moyenne 0, variance constante).")
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)")),
          
          tags$ul(
            tags$li(
              "Écriture compacte : ",
              tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
            ),
            tags$li(
              tags$b("Interprétation : "),
              "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
              "non saisonnières (p,q) et saisonnières (P,Q)."
            )
          )
        ),
        
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Ce que signifie “bon modèle” (définition opérationnelle)")),
          
          tags$ol(
            tags$li(
              tags$b("Résidus ~ bruit blanc"),
              " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."
            ),
            tags$li(
              tags$b("Performance out-of-sample"),
              " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."
            ),
            tags$li(
              tags$b("Parcimonie"),
              " : modèle le plus simple possible à performance comparable."
            )
          )
        ),
        
        
        # H5("Forme générale du modèle SARIMA (à comprendre, pas à mémoriser)"),
        # UL(
        #   tags$li(
        #     "Écriture compacte : ",
        #     C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")
        #   ),
        #   tags$li(
        #     B("Interprétation : "),
        #     "après différenciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
        #     "non saisonnières (p,q) et saisonnières (P,Q)."
        #   )
        # ),
        # 
        # H5("Ce que signifie “bon modèle” (définition opérationnelle)"),
        # OL(
        #   tags$li(B("Résidus ~ bruit blanc"), " : pas d’autocorrélation résiduelle (Ljung–Box non significatif)."),
        #   tags$li(B("Performance out-of-sample"), " : MAE/RMSE meilleurs que benchmark (naïf / SNAIVE)."),
        #   tags$li(B("Parcimonie"), " : modèle le plus simple possible à performance comparable.")
        # ),
        
        
        
        # # === ADD: Glossaire étendu, critères info, estimation ===
        # H5("Glossaire étendu (ajouts importants)"),
        # UL(
        #   tags$li(B("Polynômes AR/MA"), " : ",
        #           C("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), ", ",
        #           C("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), "; saisonnier ",
        #           C("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), ", ",
        #           C("Θ(B^s) = 1 + Θ_1 B^s + ... + Θ_Q B^{Qs}"), "."),
        #   tags$li(B("Stabilité/causalité (AR)"), " : toutes les racines de ", C("φ(z)=0"),
        #           " et ", C("Φ(z^s)=0"), " sont ", B("hors"), " du cercle unité → processus stationnaire."),
        #   tags$li(B("Inversibilité (MA)"), " : racines de ", C("θ(z)=0"), " et ", C("Θ(z^s)=0"),
        #           " hors du cercle unité → représentation AR(∞) bien définie."),
        #   tags$li(B("Constante / drift"), " : une constante dans un ARIMA avec ", C("d=1"),
        #           " implique une ", B("pente moyenne"), " (drift) après différenciation ; le terme est souvent noté ",
        #           C("c"), " et la tendance moyenne vaut environ ", C("c"), " par pas."),
        #   tags$li(B("Représentation état–espace"), " : tout ARIMA/SARIMA peut être écrit sous forme état–espace ",
        #           "et estimé/filtré par Kalman (utile pour manquants et lissage)."),
        #   tags$li(B("Prévision : point vs intervalle vs densité"),
        #           " : point = ", C("ŷ"), "; intervalle = incertitude (80%/95%); densité = distribution prédictive complète.")
        # ),
        
        # === ADD: Glossaire étendu, critères info, estimation ===
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Glossaire étendu (ajouts importants)")),
          
          tags$ul(
            tags$li(
              tags$b("Polynômes AR/MA"), " : ",
              tags$code("φ(B) = 1 - φ_1 B - ... - φ_p B^p"), ", ",
              tags$code("θ(B) = 1 + θ_1 B + ... + θ_q B^q"), "; saisonnier ",
              tags$code("Φ(B^s) = 1 - Φ_1 B^s - ... - Φ_P B^{Ps}"), ", ",
              tags$code("Θ(B^s) = 1 + Θ_1 B^s + ... + Θ_Q B^{Qs}"), "."
            ),
            
            tags$li(
              tags$b("Stabilité / causalité (AR)"), " : toutes les racines de ",
              tags$code("φ(z)=0"), " et ", tags$code("Φ(z^s)=0"),
              " sont ", tags$b("hors"), " du cercle unité → processus stationnaire."
            ),
            
            tags$li(
              tags$b("Inversibilité (MA)"), " : racines de ",
              tags$code("θ(z)=0"), " et ", tags$code("Θ(z^s)=0"),
              " hors du cercle unité → représentation AR(∞) bien définie."
            ),
            
            tags$li(
              tags$b("Constante / drift"), " : une constante dans un ARIMA avec ",
              tags$code("d=1"),
              " implique une ", tags$b("pente moyenne"),
              " (drift) après différenciation ; le terme est souvent noté ",
              tags$code("c"),
              " et la tendance moyenne vaut environ ",
              tags$code("c"),
              " par pas."
            ),
            
            tags$li(
              tags$b("Représentation état–espace"), " : tout ARIMA/SARIMA peut être écrit sous forme état–espace ",
              "et estimé/filtré par Kalman (utile pour manquants et lissage)."
            ),
            
            tags$li(
              tags$b("Prévision : point vs intervalle vs densité"),
              " : point = ", tags$code("ŷ"),
              " ; intervalle = incertitude (80% / 95%) ; densité = distribution prédictive complète."
            )
          )
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Critères d’information (définitions)")),
          
          tags$ul(
            tags$li(
              tags$b("AIC"), " : ",
              tags$code("AIC = -2 \\log L + 2k"),
              " (", tags$code("k"), " = nb paramètres estimés)."
            ),
            tags$li(
              tags$b("AICc"),
              " : correction petits échantillons → préférable si ",
              tags$code("n/k"), " n’est pas grand."
            ),
            tags$li(
              tags$b("BIC"), " : ",
              tags$code("BIC = -2 \\log L + k \\log n"),
              " ; pénalise plus la complexité (favorise parcimonie)."
            )
          )
        ),
        
        
        
        # H5("Critères d’information (définitions)"),
        # UL(
        #   tags$li(B("AIC"), " : ", C("AIC = -2 \\log L + 2k"), " (", C("k"), " = nb paramètres estimés)."),
        #   tags$li(B("AICc"), " : correction petits échantillons → préférable si ", C("n/k"), " n’est pas grand."),
        #   tags$li(B("BIC"), " : ", C("BIC = -2 \\log L + k \\log n"), " ; pénalise plus la complexité (favorise parcimonie).")
        # ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Estimation (comment sont estimés les paramètres)")),
          
          tags$ul(
            tags$li(
              tags$b("MLE vs CSS+MLE"),
              " : estimation par maximum de vraisemblance (souvent via optim) ; ",
              "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."
            ),
            tags$li(
              tags$b("Écarts-types et tests z"),
              " : reportez estimations ± SE, z et p pour l’interprétation des coefficients."
            )
          )
        ),
        
        # H5("Estimation (comment sont estimés les paramètres)"),
        # UL(
        #   tags$li(B("MLE vs CSS+MLE"), " : estimation par maximum de vraisemblance (souvent via optim) ; ",
        #           "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."),
        #   tags$li(B("Écarts-types et tests z"), " : reportez estimations ± SE, z et p pour l’interprétation des coefficients.")
        # )
        
        
      ),
      
      apa_ui = tagList(
        H5("Phrase APA (modèle + notations)"),
        P("« Nous avons ajusté un modèle SARIMA afin de capturer la dépendance temporelle et la saisonnalité de la série ",
          C("y_t"), ". La spécification générale est ", C("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
          " avec ", C("ε_t"), " un bruit blanc. Le choix de (d, D) a été justifié par des tests de stationnarité (ADF/KPSS/PP) et des diagnostics. »"),
        
        H5("Conclusion & signification (à expliciter)"),
        UL(
          tags$li(B("Conclusion type : "), "« Le modèle final est adéquat »"),
          tags$li(B("Signification : "), "« (i) il ne laisse pas d’information autocorrélée dans les résidus, ",
                  "(ii) il généralise bien sur une fenêtre future, ",
                  "(iii) il est suffisamment simple pour être stable et reproductible. »")
        )
      ),
      
      pitfalls_ui = tagList(
        H5("Pièges classiques"),
        UL(
          tags$li(B("Confondre AIC faible et bon modèle"), " : un AIC très bas avec résidus autocorrélés = modèle mal spécifié."),
          tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naïf, impossible de dire si SARIMA apporte réellement quelque chose."),
          tags$li(B("Surcharger le modèle"), " : trop de paramètres → instabilité, intervalles de prévision peu fiables.")
        )
      )
    )
    
    # (1) Étape 0 — Définition du problème
    pages[[2]] <- make_step(
      step_names[2],
      
      actions_ui = tagList(
        callout(
          B("But : "),
          "définir un problème de prévision mesurable (horizon, métriques, protocole).",
          type="info"
        ),
        
        Checklist(
          CheckItem("Définir la variable y_t (cible) et la fréquence temporelle (jour, semaine, mois) sans ambiguite."),
          CheckItem("Fixer l’horizon h en fonction de l’usage reel (decision, planification, stock, etc.)."),
          CheckItem("Choisir un protocole d’evaluation temporelle (train/test ou rolling-origin) et expliquer pourquoi."),
          CheckItem("Choisir des metriques (MAE + RMSE recommande) et justifier leur interpretation."),
          CheckItem("Decider si une transformation (log / Box-Cox) est necessaire et noter la raison.")
        ),
        
        Deliverables(
          tags$li("Un énoncé clair du problème : “Je prévois y_t à horizon h pour [usage concret]”."),
          tags$li("Une décision sur la stratégie d’évaluation (split chronologique ou rolling) + justification (éviter la fuite d’information)."),
          tags$li("Une liste courte de métriques retenues + interprétation attendue (erreur moyenne, pénalisation des grosses erreurs).")
        ),
        
        
        # H5("Définitions (ce que chaque terme veut dire)"),
        # UL(
        #   tags$li(B("Série réponse"), " ", C("y_t"), " : variable à prédire (univariée)."),
        #   tags$li(B("Horizon"), " ", C("h"), " : nombre de pas à prévoir (ex. h=12 mois)."),
        #   tags$li(B("Origine de prévision"), " : dernier temps observé à partir duquel on prévoit."),
        #   tags$li(B("Protocole train/test"), " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."),
        #   tags$li(B("Rolling-origin / validation temporelle"), " : on répète des prévisions à différentes origines pour estimer la performance moyenne."),
        #   tags$li(B("SARIMA vs SARIMAX"), " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Définitions (ce que chaque terme veut dire)")),
          
          tags$ul(
            tags$li(
              tags$b("Série réponse"), " ", tags$code("y_t"),
              " : variable à prédire (univariée)."
            ),
            tags$li(
              tags$b("Horizon"), " ", tags$code("h"),
              " : nombre de pas à prévoir (ex. h = 12 mois)."
            ),
            tags$li(
              tags$b("Origine de prévision"),
              " : dernier temps observé à partir duquel on prévoit."
            ),
            tags$li(
              tags$b("Protocole train/test"),
              " : séparation temporelle (jamais mélanger le futur dans l’entraînement)."
            ),
            tags$li(
              tags$b("Rolling-origin / validation temporelle"),
              " : on répète des prévisions à différentes origines pour estimer la performance moyenne."
            ),
            tags$li(
              tags$b("SARIMA vs SARIMAX"),
              " : SARIMA n’utilise pas de variables explicatives ; SARIMAX inclut des régressions exogènes."
            )
          )
        ),
        
        
        
        
        
        # H5("Choisir les métriques (définitions + quand utiliser)"),
        # UL(
        #   tags$li(B("MAE"), " : moyenne des erreurs absolues ", C("mean(|y-ŷ|)"),
        #           " → robuste, facile à interpréter (unité de y)."),
        #   tags$li(B("RMSE"), " : racine de l’erreur quadratique moyenne ", C("sqrt(mean((y-ŷ)^2))"),
        #           " → pénalise plus les grosses erreurs."),
        #   tags$li(B("MAPE"), " : ", C("mean(|(y-ŷ)/y|)"),
        #           " → éviter si y proche de 0 (explose)."),
        #   tags$li(B("sMAPE"), " : alternative plus stable près de 0 : ", C("mean(2|y-ŷ|/(|y|+|ŷ|))"), ".")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Choisir les métriques (définitions + quand utiliser)")),
          
          tags$ul(
            tags$li(
              tags$b("MAE"),
              " : moyenne des erreurs absolues ",
              tags$code("mean(|y-ŷ|)"),
              " → robuste, facile à interpréter (unité de y)."
            ),
            tags$li(
              tags$b("RMSE"),
              " : racine de l’erreur quadratique moyenne ",
              tags$code("sqrt(mean((y-ŷ)^2))"),
              " → pénalise plus les grosses erreurs."
            ),
            tags$li(
              tags$b("MAPE"),
              " : ",
              tags$code("mean(|(y-ŷ)/y|)"),
              " → éviter si y proche de 0 (explose)."
            ),
            tags$li(
              tags$b("sMAPE"),
              " : alternative plus stable près de 0 : ",
              tags$code("mean(2|y-ŷ|/(|y|+|ŷ|))"),
              "."
            )
          )
        ),
        
        
        
        
        # H5("Transformation (définitions + justification)"),
        # UL(
        #   tags$li(B("Niveaux"), " : modèle sur les valeurs brutes."),
        #   tags$li(B("Log-niveaux"), " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."),
        #   tags$li(B("Box–Cox"), " : transformation paramétrique (λ) pour stabiliser variance et améliorer normalité : ",
        #           C("y^(λ) = (y^λ - 1)/λ"), " (λ≠0), et log si λ=0.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Transformation (définitions + justification)")),
          
          tags$ul(
            tags$li(
              tags$b("Niveaux"),
              " : modèle sur les valeurs brutes."
            ),
            tags$li(
              tags$b("Log-niveaux"),
              " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif → additif."
            ),
            tags$li(
              tags$b("Box–Cox"),
              " : transformation paramétrique (λ) pour stabiliser la variance et améliorer la normalité : ",
              tags$code("y^(λ) = (y^λ - 1)/λ"),
              " (λ ≠ 0), et log si λ = 0."
            )
          )
        ),
        
        
        
        # H5("Procédure minimale (checklist)"),
        # OL(
        #   tags$li("Fixer fréquence et période saisonnière s."),
        #   tags$li("Fixer horizon h et fenêtres train/test (ou rolling-origin)."),
        #   tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
        #   tags$li("Décider transformation (aucune/log/Box–Cox) et justifier.")
        # ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Procédure minimale (checklist)")),
          
          tags$ol(
            tags$li("Fixer la fréquence et la période saisonnière ", tags$code("s"), "."),
            tags$li("Fixer l’horizon ", tags$code("h"),
                    " et les fenêtres train/test (ou rolling-origin)."),
            tags$li("Choisir MAE + RMSE (recommandé) ; documenter les raisons."),
            tags$li("Décider de la transformation (aucune / log / Box–Cox) et la justifier.")
          )
        ),
        
        
        
        # === ADD: précisions pratiques, métriques complémentaires, transformations ===
        
        
        # H5("Précisions supplémentaires (définitions pratiques)"),
        # UL(
        #   tags$li(B("Horizon multi-pas"), " : ", C("h>1"),
        #           " → la performance peut décroître avec l’horizon ; rapporter MAE/RMSE par h si possible."),
        #   tags$li(B("Fenêtre d’entraînement"), " : ", B("expansive"), " (on ne jette jamais d’anciens points) ",
        #           "ou ", B("glissante"), " (fenêtre fixe) ; documenter le choix."),
        #   tags$li(B("Reproductibilité"), " : fixer les graines aléatoires, consigner versions des packages, chemins de données."),
        #   tags$li(B("Prévision hiérarchique"), " (annexe) : si agrégations (mois→trimestres), noter la cohérence temporelle.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Précisions supplémentaires (définitions pratiques)")),
          
          tags$ul(
            tags$li(
              tags$b("Horizon multi-pas"),
              " : ", tags$code("h > 1"),
              " → la performance peut décroître avec l’horizon ; rapporter MAE/RMSE par ",
              tags$code("h"), " si possible."
            ),
            tags$li(
              tags$b("Fenêtre d’entraînement"),
              " : ",
              tags$b("expansive"),
              " (on ne jette jamais d’anciens points) ou ",
              tags$b("glissante"),
              " (fenêtre fixe) ; documenter le choix."
            ),
            tags$li(
              tags$b("Reproductibilité"),
              " : fixer les graines aléatoires, consigner les versions des packages, chemins de données."
            ),
            tags$li(
              tags$b("Prévision hiérarchique"),
              " (annexe) : si agrégations (mois → trimestres), noter la cohérence temporelle."
            )
          )
        ),
        
        
        # H5("Métriques supplémentaires (quand utiles)"),
        # UL(
        #   tags$li(B("MASE"), " : erreur absolue mise à l’échelle par le naïf saisonnier → comparable entre séries."),
        #   tags$li(B("WAPE"), " : ", C("sum(|y-ŷ|)/sum(|y|)"), " ; lisible comme % d’erreur agrégée."),
        #   tags$li(B("Pinball loss (quantiles)"), " : si vous prédisez des quantiles (IC asymétriques).")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Métriques supplémentaires (quand utiles)")),
          
          tags$ul(
            tags$li(
              tags$b("MASE"),
              " : erreur absolue mise à l’échelle par le naïf saisonnier → comparable entre séries."
            ),
            tags$li(
              tags$b("WAPE"),
              " : ", tags$code("sum(|y-ŷ|) / sum(|y|)"),
              " ; lisible comme % d’erreur agrégée."
            ),
            tags$li(
              tags$b("Pinball loss (quantiles)"),
              " : utile si vous prédisez des quantiles (intervalles asymétriques)."
            )
          )
        ),
        
        
        # H5("Transformations complémentaires"),
        # UL(
        #   tags$li(B("Yeo–Johnson"), " : alternative à Box–Cox qui gère les valeurs ≤ 0."),
        #   tags$li(B("Stabilisation de variance"), " : vérifier relation niveau–variance (nuage points moyenne locale vs ET).")
        # )
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Transformations complémentaires")),
          
          tags$ul(
            tags$li(
              tags$b("Yeo–Johnson"),
              " : alternative à Box–Cox qui gère les valeurs ≤ 0."
            ),
            tags$li(
              tags$b("Stabilisation de variance"),
              " : vérifier la relation niveau–variance ",
              "(nuage de points moyenne locale vs écart-type)."
            )
          )
        ),
        
        
      ),
      
      apa_ui = tagList(
        H5("Méthodes (APA) — modèle de phrase complet"),
        P("« Nous avons modélisé la série temporelle univariée ", C("y_t"),
          " observée à une fréquence [..] (période saisonnière s=[..]). ",
          "L’objectif était de produire des prévisions à horizon ", C("h"), "=[..]. ",
          "La performance a été évaluée sur une fenêtre future selon [split temporel / rolling-origin] ",
          "à l’aide de [MAE, RMSE]. Une transformation [aucune / log / Box–Cox] a été appliquée afin de [stabiliser la variance / linéariser la saisonnalité]. »"),
        
        H5("Conclusion & signification (comment l’expliquer)"),
        UL(
          tags$li(B("Conclusion : "), "« Notre problème est bien défini (h, métriques, protocole). »"),
          tags$li(B("Signification : "), "« Toute comparaison de modèles devient juste : même horizon, même protocole, mêmes métriques. »")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) → performance artificiellement élevée."),
          tags$li(B("Métrique mal choisie"), " : MAPE avec y≈0 → conclusions fausses."),
          tags$li(B("Horizon incohérent"), " : un modèle bon à h=1 peut être mauvais à h=12 ; fixer l’horizon selon l’usage réel.")
        )
      )
    )
    
    # (2) Étape 1 — Description des données
    pages[[3]] <- make_step(
      step_names[3],
      
      actions_ui = tagList(
        callout(B("But : "), "décrire la qualité des données et rendre le pipeline reproductible.", type="info"),
        
        Checklist(
          CheckItem("Verifier que l’index temporel est regulier (pas manquants/dupliques, ordre correct)."),
          CheckItem("Rapporter n, date debut/fin, frequence, et la couverture temporelle."),
          CheckItem("Quantifier les manquants (k et %) et choisir une strategie (interpolation, saisonniere, Kalman) avec justification."),
          CheckItem("Produire un resume statistique (moyenne, mediane, ET, min/max) et un resume saisonnier (par mois/semaine)."),
          CheckItem("Documenter toute correction (doublons, valeurs aberrantes evidentes) pour garantir la reproductibilite.")
        ),
        
        Deliverables(
          tags$li("Un résumé qualité des données : N, dates début/fin, fréquence, valeurs manquantes, doublons, périodes irrégulières."),
          tags$li("Une stratégie documentée pour les manquants/outliers (suppression, interpolation, NA-LOCF, winsorisation) + justification."),
          tags$li("Des descriptifs simples : moyenne/variance, quantiles, min/max, et un rappel de l’unité de mesure.")
        ),
        
        
        # H5("Ce qu’il faut rapporter (définitions)"),
        # UL(
        #   tags$li(B("n"), " : nombre total d’observations disponibles."),
        #   tags$li(B("Couverture"), " : date début/fin."),
        #   tags$li(B("Fréquence"), " : périodicité (mensuel/hebdo/quotidien)."),
        #   tags$li(B("Manquants"), " : nombre k et pourcentage k/n.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Ce qu’il faut rapporter (définitions)")),
          
          tags$ul(
            tags$li(tags$b("n"), " : nombre total d’observations disponibles."),
            tags$li(tags$b("Couverture"), " : date de début et de fin."),
            tags$li(tags$b("Fréquence"), " : périodicité (mensuel / hebdomadaire / quotidien)."),
            tags$li(tags$b("Manquants"), " : nombre ", tags$code("k"),
                    " et pourcentage ", tags$code("k/n"), ".")
          )
        ),
        
        
        # H5("Valeurs manquantes : types + implications"),
        # UL(
        #   tags$li(B("MCAR"), " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."),
        #   tags$li(B("MAR"), " (At Random conditionnel) : dépend d’autres infos → imputation possible mais à justifier."),
        #   tags$li(B("MNAR"), " (Not At Random) : dépend de la valeur elle-même → risque de biais important.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Valeurs manquantes : types + implications")),
          
          tags$ul(
            tags$li(
              tags$b("MCAR"),
              " (Missing Completely At Random) : manquants indépendants → imputation plus défendable."
            ),
            tags$li(
              tags$b("MAR"),
              " (Missing At Random conditionnel) : dépend d’autres informations → imputation possible mais à justifier."
            ),
            tags$li(
              tags$b("MNAR"),
              " (Missing Not At Random) : dépend de la valeur elle-même → risque de biais important."
            )
          )
        ),
        
        
        # H5("Stratégies de traitement (quand et pourquoi)"),
        # UL(
        #   tags$li(B("Interpolation linéaire"), " : si manquants rares et pas de ruptures."),
        #   tags$li(B("Interpolation saisonnière"), " : si saisonnalité stable (ex. remplacer par moyenne du même mois)."),
        #   tags$li(B("Modèle d’état / Kalman"), " : si on veut une imputation plus probabiliste."),
        #   tags$li(B("Suppression"), " : seulement si extrêmement rare et sans impact sur la continuité.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Stratégies de traitement (quand et pourquoi)")),
          
          tags$ul(
            tags$li(
              tags$b("Interpolation linéaire"),
              " : si manquants rares et absence de ruptures."
            ),
            tags$li(
              tags$b("Interpolation saisonnière"),
              " : si saisonnalité stable (ex. moyenne du même mois)."
            ),
            tags$li(
              tags$b("Modèle d’état / Kalman"),
              " : pour une imputation probabiliste cohérente avec la dynamique."
            ),
            tags$li(
              tags$b("Suppression"),
              " : uniquement si extrêmement rare et sans impact sur la continuité temporelle."
            )
          )
        ),
        
        
        
        # H5("Descriptifs pertinents (au-delà de la moyenne)"),
        # UL(
        #   tags$li("Moyenne, médiane, ET, min/max (niveau)."),
        #   tags$li("Asymétrie (skewness) / kurtosis si utile."),
        #   tags$li("Résumé saisonnier (ex. moyenne par mois), pour documenter saisonnalité.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Descriptifs pertinents (au-delà de la moyenne)")),
          
          tags$ul(
            tags$li("Moyenne, médiane, écart-type, min/max (niveau)."),
            tags$li("Asymétrie (skewness) et kurtosis si utile."),
            tags$li(
              "Résumé saisonnier (ex. moyenne par mois) pour documenter la saisonnalité."
            )
          )
        ),
        
        
        # === ADD: qualité index & manquants pratiques ===
        
        
        # H5("Qualité de l’index temporel (définitions)"),
        # UL(
        #   tags$li(B("Régularité"), " : pas de pas manqué/dupliqué ; cadence constante."),
        #   tags$li(B("Fuseau/DST"), " : données horaires → attention aux heures manquantes/dupliquées (passage DST)."),
        #   tags$li(B("Doublons et horodatages hors ordre"), " : à corriger avant tout calcul d’ACF.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Qualité de l’index temporel (définitions)")),
          
          tags$ul(
            tags$li(
              tags$b("Régularité"),
              " : pas manquants ou dupliqués ; cadence constante."
            ),
            tags$li(
              tags$b("Fuseau / DST"),
              " : données horaires → attention aux heures manquantes ou dupliquées (changement d’heure)."
            ),
            tags$li(
              tags$b("Doublons et désordre temporel"),
              " : à corriger avant tout calcul d’ACF."
            )
          )
        ),
        
        
        
        # H5("Manquants — remarques pratiques"),
        # UL(
        #   tags$li(B("Kalman/StructTS"), " : imputation probabiliste cohérente avec la dynamique ARIMA."),
        #   tags$li(B("Imputation “saison identique”"), " : moyenne/médiane du même mois/jour si saisonnalité stable."),
        #   tags$li(B("Zéros structurels"), " : distinguer “zéro” réel de manquant imputé à 0 (documenter).")
        # )
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Manquants — remarques pratiques")),
          
          tags$ul(
            tags$li(
              tags$b("Kalman / StructTS"),
              " : imputation probabiliste cohérente avec la dynamique ARIMA."
            ),
            tags$li(
              tags$b("Imputation “saison identique”"),
              " : moyenne ou médiane du même mois / jour si saisonnalité stable."
            ),
            tags$li(
              tags$b("Zéros structurels"),
              " : distinguer zéro réel et manquant imputé à 0 (à documenter explicitement)."
            )
          )
        ),
        
        
      ),
      
      apa_ui = tagList(
        H5("Résultats (APA) — description"),
        P("« La série contient ", C("n"), "=[..] observations couvrant [..] à [..] à une fréquence [..]. ",
          "Les valeurs manquantes représentaient [..]% (k=[..]) et ont été traitées par [..], ",
          "choisie car [manquants rares / saisonnalité stable / continuité nécessaire]. ",
          "La série présentait une moyenne de [..] (ET=[..]) et une médiane [..]. »"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "« Les données sont suffisamment propres pour SARIMA » (ou non)."),
          tags$li(B("Signification : "),
                  "si l’index est régulier et que les manquants sont gérés explicitement, ",
                  "les hypothèses du modèle (espacement régulier) deviennent plausibles.")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Imputation silencieuse"), " : toujours documenter méthode + raison."),
          tags$li(B("Timestamps irréguliers"), " : SARIMA suppose une grille régulière ; corriger avant toute estimation."),
          tags$li(B("Changement de définition de la variable"), " : ex. changement de mesure → rupture structurelle à traiter.")
        )
      )
    )
    
    # (3) Étape 2 — EDA
    pages[[4]] <- make_step(
      step_names[4],
      
      actions_ui = tagList(
        callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant d’ajuster SARIMA.", type="info"),
        
        Checklist(
          CheckItem("Tracer la serie y_t et annoter tendance, saisonnalite, ruptures possibles et changements de variance."),
          CheckItem("Construire au moins un graphique saisonnier (seasonal plot ou subseries) pour comprendre la forme par saison."),
          CheckItem("Identifier les outliers (dates) et formuler une hypothese (evenement reel vs erreur)."),
          CheckItem("Decider et documenter le traitement des outliers (conserver/corriger/imputer) et tester l’impact sur l’analyse."),
          CheckItem("Noter ce que l’EDA implique pour la suite: transformation possible, differenciation probable, et presence de ruptures.")
        ),
        
        Deliverables(
          tags$li("Graphiques EDA : série brute, zooms, saisonnalité (par cycle), et repérage d’anomalies (pics/creux)."),
          tags$li("Une hypothèse argumentée sur tendance et saisonnalité (présentes ? stables ? changeantes ?)."),
          tags$li("Une première lecture d’autocorrélation (ACF/PACF exploratoires) sans conclure trop vite sur p/q.")
        ),
        
        
        # H5("Définitions utiles (ce qu’on cherche)"),
        # UL(
        #   tags$li(B("Tendance"), " : évolution de long terme (déterministe ou stochastique)."),
        #   tags$li(B("Saisonnalité"), " : motif périodique de période s (ex. 12)."),
        #   tags$li(B("Rupture structurelle"), " : changement durable de niveau/tendance/variance (ex. politique, crise)."),
        #   tags$li(B("Outlier"), " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou erreur.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Définitions utiles (ce qu’on cherche)")),
          
          tags$ul(
            tags$li(
              tags$b("Tendance"),
              " : évolution de long terme (déterministe ou stochastique)."
            ),
            tags$li(
              tags$b("Saisonnalité"),
              " : motif périodique de période ", tags$code("s"),
              " (ex. 12)."
            ),
            tags$li(
              tags$b("Rupture structurelle"),
              " : changement durable de niveau, de tendance ou de variance ",
              "(ex. politique, crise)."
            ),
            tags$li(
              tags$b("Outlier"),
              " : valeur atypique ponctuelle ; peut être réelle (fêtes) ou une erreur."
            )
          )
        ),
        
        
        
        # H5("Graphiques recommandés + leur but"),
        # UL(
        #   tags$li(B("Courbe y_t"), " : voir tendance, variance, ruptures."),
        #   tags$li(B("Seasonal plot"), " : comparer la forme saisonnière d’une année à l’autre."),
        #   tags$li(B("Boxplots par saison"), " : détecter asymétrie/outliers par mois/semaine."),
        #   tags$li(B("ACF brute"), " (optionnel) : repérer dépendances fortes et saisonnalité.")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Graphiques recommandés + leur but")),
          
          tags$ul(
            tags$li(
              tags$b("Courbe "), tags$code("y_t"),
              " : visualiser tendance, variance et ruptures."
            ),
            tags$li(
              tags$b("Seasonal plot"),
              " : comparer la forme saisonnière d’une année à l’autre."
            ),
            tags$li(
              tags$b("Boxplots par saison"),
              " : détecter asymétrie et outliers par mois ou par semaine."
            ),
            tags$li(
              tags$b("ACF brute"),
              " (optionnel) : repérer dépendances fortes et saisonnalité."
            )
          )
        ),
        
        
        
        # H5("Outliers : procédure raisonnable"),
        # OL(
        #   tags$li("Repérer visuellement (dates)."),
        #   tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
        #   tags$li("Décider : conserver / corriger / imputer (et justifier)."),
        #   tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Outliers : procédure raisonnable")),
          
          tags$ol(
            tags$li("Repérer visuellement (dates concernées)."),
            tags$li("Proposer une hypothèse (événement réel ? erreur ?)."),
            tags$li("Décider : conserver / corriger / imputer (et justifier)."),
            tags$li("Documenter l’impact (le modèle change-t-il beaucoup ?).")
          )
        ),
        
        
        # === ADD: outils EDA supplémentaires & typologie outliers ===
        
        
        # H5("Outils EDA supplémentaires"),
        # UL(
        #   tags$li(B("Périodogramme / spectre"), " : met en évidence des fréquences saisonnières inattendues."),
        #   tags$li(B("Seasonal subseries plot"), " : visualise la forme saisonnière par mois/semaine."),
        #   tags$li(B("Nuage niveau–variance"), " : aide au choix log/Box–Cox (variance croît avec le niveau ?).")
        # ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Outils EDA supplémentaires")),
          
          tags$ul(
            tags$li(
              tags$b("Périodogramme / spectre"),
              " : met en évidence des fréquences saisonnières inattendues."
            ),
            tags$li(
              tags$b("Seasonal subseries plot"),
              " : visualise la forme saisonnière par mois / semaine."
            ),
            tags$li(
              tags$b("Nuage niveau–variance"),
              " : aide au choix log / Box–Cox (variance croît avec le niveau ?)."
            )
          )
        ),
        
        
        # H5("Types d’outliers (interventions)"),
        # UL(
        #   tags$li(B("AO"), " : Additive Outlier (pic ponctuel)."),
        #   tags$li(B("IO"), " : Innovation Outlier (choc qui diffuse)."),
        #   tags$li(B("LS"), " : Level Shift (changement de niveau)."),
        #   tags$li(B("TC"), " : Temporary Change (effet transitoire).")
        # )
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Types d’outliers (interventions)")),
          
          tags$ul(
            tags$li(tags$b("AO"), " : Additive Outlier (pic ponctuel)."),
            tags$li(tags$b("IO"), " : Innovation Outlier (choc qui diffuse)."),
            tags$li(tags$b("LS"), " : Level Shift (changement de niveau)."),
            tags$li(tags$b("TC"), " : Temporary Change (effet transitoire).")
          )
        ),
        
        
        
      ),
      
      apa_ui = tagList(
        H5("Résultats (APA) — EDA"),
        P("« L’inspection visuelle a mis en évidence une tendance [..] et une saisonnalité récurrente de période s=[..]. ",
          "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Box–Cox]. ",
          "Des valeurs atypiques autour de [dates] ont été [conservées/traitées] car [événement réel / erreur probable]. »"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "« La structure (tendance/saison/variance/outliers) est comprise »"),
          tags$li(B("Signification : "),
                  "cela guide directement le choix transformation + différenciations (d, D) et évite d’ajuster un SARIMA “à l’aveugle”.")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Confondre saisonnalité et tendance"), " : une moyenne croissante ET une saisonnalité stable sont deux composantes distinctes."),
          tags$li(B("Retirer des points réels"), " : si l’outlier correspond à un événement récurrent (fêtes), il doit rester."),
          tags$li(B("Ignorer une rupture"), " : un SARIMA “moyenne” une structure qui a changé → mauvais futur.")
        )
      )
    )
    
    # (4) Étape 3 — Décomposition
    pages[[5]] <- make_step(
      step_names[5],
      
      actions_ui = tagList(
        callout(B("But : "), "séparer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
        
        Checklist(
          CheckItem("Comparer visuellement une hypothese additive vs multiplicative (amplitude saisonniere constante vs proportionnelle au niveau)."),
          CheckItem("Tester l’idee de transformation log/Box-Cox si la variance augmente avec le niveau."),
          CheckItem("Realiser une decomposition (classique ou STL) et commenter la tendance, la saisonnalite et le residu."),
          CheckItem("Verifier si la saisonnalite semble stable ou evolutive (argument pour STL)."),
          CheckItem("Ecrire clairement ce que la decomposition suggere pour d, D, et pour l’echelle de modelisation.")
        ),
        
        Deliverables(
          tags$li("Une décomposition (STL ou équivalent) + conclusion : additif vs multiplicatif, et stabilité de la saisonnalité."),
          tags$li("Une décision de transformation (log / Box–Cox) si variance non constante + note sur la reconversion des prévisions."),
          tags$li("Une interprétation du “reste” (résidu) : signal non expliqué vs bruit (est-ce encore structuré ?).")
        ),
        
        
        H5("Décomposition : définitions"),
        UL(
          tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
                  " (amplitude saisonnière ~ constante)."),
          tags$li(B("Multiplicative"), " : ", C("y_t = T_t × S_t × e_t"),
                  " (amplitude saisonnière augmente avec le niveau)."),
          tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
                  C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
          tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
        ),
        
        H5("Pourquoi STL ? (objectif détaillé)"),
        UL(
          tags$li("Quand la saisonnalité change lentement au fil du temps (non parfaitement répétitive)."),
          tags$li("Quand on veut réduire l’influence des outliers sur l’estimation saison/tendance."),
          tags$li("Quand on veut une lecture pédagogique claire (tendance vs saison vs résidu).")
        ),
        
        H5("Ce que la décomposition ne remplace pas"),
        UL(
          tags$li("Elle ne prouve pas la stationnarité : SARIMA exige une série stationnaire après différenciation."),
          tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nécessaires.")
        ),
        
        # === ADD: paramètres STL & règles pratiques ===
        H5("Paramètres STL (lecture pédagogique)"),
        UL(
          tags$li(B("s.window"), " : lissage saisonnier (", C("periodic"), " = saison constante; entier = évolutive)."),
          tags$li(B("t.window"), " : lissage de la tendance (fenêtre LOESS)."),
          tags$li(B("robust"), " : réduit l’influence des outliers (itérations avec poids).")
        ),
        H5("Additif vs multiplicatif (règle pratique)"),
        UL(
          tags$li("Amplitude saisonnière ~ proportionnelle au niveau → penser ", B("log"), " ou modèle multiplicatif."),
          tags$li("Amplitude ~ constante → additif sur niveaux.")
        )
      ),
      
      apa_ui = tagList(
        H5("Méthodes (APA) — Décomposition"),
        P("« Nous avons étudié une structure additive vs multiplicative en évaluant si l’amplitude saisonnière variait avec le niveau. ",
          "Comme [..], nous avons retenu [modèle additif / transformation log] et réalisé une décomposition via [classique / STL]. ",
          "STL a été privilégiée pour sa flexibilité (saisonnalité évolutive) et sa robustesse aux valeurs atypiques. »"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "« Le choix additif/multiplicatif est justifié »"),
          tags$li(B("Signification : "),
                  "on évite des résidus hétéroscédastiques et on améliore la stabilité de l’estimation SARIMA.")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Décomposition ≠ stationnarité"), " : après décomposition, on doit encore tester/choisir d et D."),
          tags$li(B("Oublier l’échelle"), " : si vous modélisez log(y), les prévisions doivent être reconverties (avec prudence)."),
          tags$li(B("Confondre bruit et structure"), " : des motifs résiduels persistants suggèrent que la saison/tendance n’a pas été correctement capturée.")
        )
      )
    )
    
    # (5) Étape 4 — Stationnarité (très détaillé : ADF/KPSS/PP + …)
    pages[[6]] <- make_step(
      step_names[6],
      
      actions_ui = tagList(
        callout(
          B("Idée centrale : "),
          "Dans un SARIMA, on n’essaie pas de modéliser directement une série ‘qui dérive’ : on cherche d’abord à obtenir une série stationnaire (au moins approximativement) via la différenciation. Les tests ADF, PP et KPSS ne sont pas des “juges” absolus, mais des indices complémentaires qui aident à justifier les choix (d, D) de façon argumentée.",
          type = "ok"
        ),
        
        Checklist(
          CheckItem("Définir la stationnarité avec vos mots (moyenne/variance stables; dépendance qui ne change pas au cours du temps)."),
          CheckItem("Appliquer ADF, KPSS et PP sur la série brute, puis écrire clairement H0 et Ha pour chacun (ils ne testent pas la même chose)."),
          CheckItem("Proposer d et D de manière progressive (essayer d=1 puis D=1 si nécessaire) et re-tester après chaque transformation."),
          CheckItem("Surveiller les signes de sur‑différenciation (ACF lag 1 très négative, variance gonflée, dynamique artificielle)."),
          CheckItem("Justifier le choix final (d, D, s) par convergence : tests + graphiques + ACF/PACF, pas par une seule p‑value.")
        ),
        
        Deliverables(
          tags$li("Résultats ADF/KPSS/PP (brut puis après différenciation) + décision sur d et D, justifiée par critères et plots."),
          tags$li("Graphiques de la série différenciée (et éventuellement ACF/PACF sur série stationnaire) pour confirmer la décision."),
          tags$li("Un avertissement écrit sur le sur‑différenciage (perte d’information, ACF négative forte au lag 1, etc.).")
        ),
        
        
        
        
        
        
        
        
        # H5("Définition : stationnarité (ce que cela veut dire)"),
        # UL(
        #   tags$li(B("Stationnarité faible (covariance-stationnaire)"), " : moyenne constante, variance constante, ",
        #           "et autocovariance dépend uniquement du retard (pas de t)."),
        #   tags$li(B("Non-stationnarité"), " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."),
        #   tags$li(B("Racine unitaire"), " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1).")
        # ),
        # 
        # H5("Différenciation : rôle (d vs D)"),
        # UL(
        #   tags$li(B("d"), " enlève la racine unitaire non saisonnière / tendance stochastique : ", C("(1-B)^d"), "."),
        #   tags$li(B("D"), " enlève la racine unitaire saisonnière : ", C("(1-B^s)^D"), "."),
        #   tags$li(B("Règle pratique"), " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2).")
        # ),
        # 
        # H5("Test ADF (Augmented Dickey–Fuller) — définition & objectif"),
        # UL(
        #   tags$li(B("But"), " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."),
        #   tags$li(B("Régression (intuition)"), " : on teste si le coefficient de ", C("y_{t-1}"),
        #           " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."),
        #   tags$li(B("Hypothèses"), " : ",
        #           B("H0"), " = racine unitaire (non-stationnaire) ; ",
        #           B("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."),
        #   tags$li(B("Interprétation p-value"), " : p petit → rejet H0 → stationnarité (au sens ADF). p grand → on ne rejette pas → différenciation probablement nécessaire.")
        # ),
        # 
        # H5("Test KPSS — définition & objectif (inverse de l’ADF)"),
        # UL(
        #   tags$li(B("But"), " : tester si la série est stationnaire (niveau ou tendance)."),
        #   tags$li(B("Hypothèses"), " : ",
        #           B("H0"), " = stationnaire ; ",
        #           B("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."),
        #   tags$li(B("Interprétation"), " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité.")
        # ),
        # 
        # H5("Test PP (Phillips–Perron) — définition & objectif"),
        # UL(
        #   tags$li(B("But"), " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement (correction non-paramétrique)."),
        #   tags$li(B("Hypothèses"), " : ",
        #           B("H0"), " = racine unitaire ; ",
        #           B("Ha"), " = stationnaire."),
        #   tags$li(B("Pourquoi utile"), " : complément de robustesse ; si ADF et PP convergent, confiance accrue.")
        # ),
        # 
        # H5("Comment conclure en combinant ADF/KPSS/PP (logique complète)"),
        # OL(
        #   tags$li(B("Stationnarité forte : "), "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."),
        #   tags$li(B("Non-stationnarité forte : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
        #   tags$li(B("Conflit : "), "les tests divergent → regarder graphiques, ACF, résultats après une différence, et justifier par convergence d’indices (pas une seule p-value).")
        # ),
        # 
        # H5("Procédure recommandée (pas à pas)"),
        # OL(
        #   tags$li("Fixer ", B("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
        #   tags$li("Tester ADF/KPSS/PP sur la série brute."),
        #   tags$li("Essayer d=1 si nécessaire, retester."),
        #   tags$li("Essayer D=1 si saisonnalité/racine saisonnière, retester."),
        #   tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
        # ),
        # 
        # H5("Sur-différenciation : définition + symptômes"),
        # UL(
        #   tags$li(B("Définition"), " : appliquer trop de différences → on introduit une dynamique artificielle."),
        #   tags$li(B("Symptômes fréquents"), " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."),
        #   tags$li(B("Conséquence"), " : intervalles de prévision plus larges et modèle moins fiable.")
        # ),
        
        
        
        # =========================
        # Stationnarité & tests
        # =========================
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Définition : stationnarité (ce que cela veut dire)")),
          tags$ul(
            tags$li(
              tags$b("Stationnarité faible (covariance-stationnaire)"),
              " : moyenne constante, variance constante, et autocovariance dépend uniquement du retard (pas de t)."
            ),
            tags$li(
              tags$b("Non-stationnarité"),
              " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalité non traitée."
            ),
            tags$li(
              tags$b("Racine unitaire"),
              " : choc permanent (effet ne s’éteint pas), typique d’un processus I(1)."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Différenciation : rôle (d vs D)")),
          tags$ul(
            tags$li(
              tags$b("d"),
              " enlève la racine unitaire non saisonnière / tendance stochastique : ",
              tags$code("(1-B)^d"), "."
            ),
            tags$li(
              tags$b("D"),
              " enlève la racine unitaire saisonnière : ",
              tags$code("(1-B^s)^D"), "."
            ),
            tags$li(
              tags$b("Règle pratique"),
              " : d ∈ {0,1,2} (souvent 0–1) ; D ∈ {0,1} (rarement 2)."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test ADF (Augmented Dickey–Fuller) — définition & objectif")),
          tags$ul(
            tags$li(
              tags$b("But"),
              " : tester si la série contient une racine unitaire (non-stationnaire) en présence d’autocorrélation."
            ),
            tags$li(
              tags$b("Régression (intuition)"),
              " : on teste si le coefficient de ",
              tags$code("y_{t-1}"),
              " est compatible avec une racine unitaire après ajout de retards de Δy pour “absorber” l’autocorrélation."
            ),
            tags$li(
              tags$b("Hypothèses"),
              " : ",
              tags$b("H0"), " = racine unitaire (non-stationnaire) ; ",
              tags$b("Ha"), " = stationnaire (autour d’une moyenne ou d’une tendance selon la spécification)."
            ),
            tags$li(
              tags$b("Interprétation p-value"),
              " : p petit → rejet H0 → stationnarité (au sens ADF). ",
              "p grand → on ne rejette pas → différenciation probablement nécessaire."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Test ADF (Augmented Dickey–Fuller) — définition complète et opérationnelle")),
              
              tags$ul(
                
                tags$li(
                  tags$b("Définition"),
                  " : le test ADF est un test de ",
                  tags$b("racine unitaire"),
                  " permettant d’évaluer si une série temporelle est ",
                  tags$b("non-stationnaire"),
                  " en raison d’une tendance stochastique (chocs permanents)."
                ),
                
                tags$li(
                  tags$b("But"),
                  " : déterminer si les chocs ont un effet ",
                  tags$b("transitoire"),
                  " (stationnarité) ou ",
                  tags$b("permanent"),
                  " (racine unitaire), afin de décider s’il faut ",
                  tags$b("différencier"),
                  " la série."
                ),
                
                tags$li(
                  tags$b("Quand l’utiliser"),
                  " : en phase d’EDA et avant tout ARIMA/SARIMA, pour guider le choix de ",
                  tags$code("d"),
                  " (et indirectement ",
                  tags$code("D"),
                  "), toujours en complément d’ACF, KPSS et inspection graphique."
                ),
                
                tags$li(
                  tags$b("Hypothèses"),
                  " : ",
                  tags$b("H0"),
                  " = la série contient une racine unitaire (non-stationnaire) ; ",
                  tags$b("Ha"),
                  " = la série est stationnaire (autour d’une moyenne ou d’une tendance déterministe)."
                ),
                
                tags$li(
                  tags$b("Statistique / idée"),
                  " : le test repose sur la régression ",
                  tags$code("Δy_t = α + βt + γy_{t-1} + Σδ_i Δy_{t-i} + ε_t"),
                  " et consiste à tester si ",
                  tags$code("γ = 0"),
                  ". Les retards de Δy servent à éliminer l’autocorrélation résiduelle."
                ),
                
                tags$li(
                  tags$b("Spécification du test"),
                  " : trois versions existent — ",
                  tags$b("sans constante"),
                  ", ",
                  tags$b("avec constante (drift)"),
                  ", ou ",
                  tags$b("avec constante + tendance"),
                  ". Le choix dépend du graphe de la série (moyenne ≠ 0 ? tendance visible ?)."
                ),
                
                tags$li(
                  tags$b("Règle de décision"),
                  " : si la statistique ADF est suffisamment négative (p-value < α), on ",
                  tags$b("rejette H0"),
                  " → absence de racine unitaire au sens du test."
                ),
                
                tags$li(
                  tags$b("Interprétation (sens économique/statistique)"),
                  " : ",
                  tags$b("rejet de H0"),
                  " → les chocs s’éteignent → modèle en niveaux ou ARMA possible ; ",
                  tags$b("non-rejet"),
                  " → chocs persistants → différenciation recommandée."
                ),
                
                tags$li(
                  tags$b("Ce que ça implique pour vos choix"),
                  " : ",
                  "• ADF rejette H0 → ",
                  tags$code("d = 0"),
                  " plausible ; ",
                  "• ADF ne rejette pas → essayer ",
                  tags$code("d = 1"),
                  " puis retester ; ",
                  "• ne jamais choisir ",
                  tags$code("d"),
                  " sur la seule base d’un test."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter"),
                  " : préciser la version du test (drift/tendance), la statistique ADF, ",
                  "la p-value et la conclusion quant à la stationnarité."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter en format APA"),
                  " : ",
                  tags$i(
                    "« Un test de Dickey–Fuller augmenté a été conduit afin d’évaluer la stationnarité de la série. "
                  ),
                  tags$i(
                    "Le test n’a pas permis de rejeter l’hypothèse de racine unitaire, "
                  ),
                  tags$i(
                    "ADF = −2.11, p = .24, suggérant la nécessité d’une différenciation. »"
                  ),
                  " (adapter la formulation selon le rejet ou non de H0)."
                ),
                
                tags$li(
                  tags$b("Limites / pièges"),
                  " : faible puissance sur petits échantillons ; ",
                  "sensibilité au nombre de retards et à la spécification ; ",
                  "mauvaise performance en présence de ruptures structurelles ; ",
                  tags$b("ne jamais interpréter isolément"),
                  " (toujours confronter à KPSS, PP et aux graphiques)."
                )
              )
            ),
            
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test KPSS — définition & objectif (inverse de l’ADF)")),
          tags$ul(
            tags$li(
              tags$b("But"),
              " : tester si la série est stationnaire (niveau ou tendance)."
            ),
            tags$li(
              tags$b("Hypothèses"),
              " : ",
              tags$b("H0"), " = stationnaire ; ",
              tags$b("Ha"), " = non-stationnaire (racine unitaire / stationnarité violée)."
            ),
            tags$li(
              tags$b("Interprétation"),
              " : p petit → rejet H0 → non-stationnaire. p grand → compatible stationnarité."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Test KPSS — définition complète")),
              
              tags$ul(
                
                tags$li(
                  tags$b("Définition"),
                  " : le test KPSS (Kwiatkowski–Phillips–Schmidt–Shin) est un test de ",
                  tags$b("stationnarité"),
                  " qui évalue si une série est stationnaire autour d’un niveau ou d’une tendance."
                ),
                
                tags$li(
                  tags$b("But"),
                  " : vérifier si l’hypothèse de stationnarité est compatible avec les données, ",
                  "en complément des tests de racine unitaire (ADF, PP)."
                ),
                
                tags$li(
                  tags$b("Quand l’utiliser"),
                  " : en ",
                  tags$b("complément systématique"),
                  " de l’ADF/PP pour éviter les conclusions biaisées basées sur un seul test."
                ),
                
                tags$li(
                  tags$b("Hypothèses"),
                  " : ",
                  tags$b("H0"),
                  " = la série est stationnaire (niveau ou tendance) ; ",
                  tags$b("Ha"),
                  " = la série n’est pas stationnaire (stationnarité violée)."
                ),
                
                tags$li(
                  tags$b("Statistique / idée"),
                  " : la statistique KPSS mesure l’ampleur de la ",
                  tags$b("somme cumulée des résidus"),
                  " d’une régression de la série sur une constante (ou constante + tendance). ",
                  "Une dérive importante indique une non-stationnarité."
                ),
                
                tags$li(
                  tags$b("Règle de décision"),
                  " : ",
                  tags$b("p petite"),
                  " → rejet de H0 → non-stationnarité ; ",
                  tags$b("p grande"),
                  " → compatibilité avec la stationnarité."
                ),
                
                tags$li(
                  tags$b("Interprétation (sens)"),
                  " : contrairement à l’ADF, ",
                  tags$b("KPSS inverse la logique"),
                  " : ici, rejeter H0 signifie que la série n’est probablement pas stationnaire."
                ),
                
                tags$li(
                  tags$b("Ce que ça implique pour vos choix"),
                  " : si KPSS rejette H0 → différenciation recommandée (",
                  tags$code("d"),
                  " ou ",
                  tags$code("D"),
                  "). Si KPSS ne rejette pas → pas de différenciation supplémentaire nécessaire."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter"),
                  " : préciser le type de stationnarité testée (niveau ou tendance), ",
                  "la statistique KPSS, la p-value et la conclusion."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter en format APA"),
                  " : ",
                  tags$i("« Un test KPSS n’a pas rejeté l’hypothèse de stationnarité, "),
                  tags$i("KPSS = 0.21, p = .10, indiquant que la série est compatible "),
                  tags$i("avec une stationnarité autour d’un niveau. »"),
                  " (adapter selon résultats)."
                ),
                
                tags$li(
                  tags$b("Limites / pièges"),
                  " : sensible au choix du paramètre de lissage (bandwidth) ; ",
                  "peut sur-rejeter sur grands échantillons ; ",
                  "ne détecte pas explicitement les ruptures structurelles."
                )
              )
            ),
            
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test PP (Phillips–Perron) — définition & objectif")),
          tags$ul(
            tags$li(
              tags$b("But"),
              " : test de racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité autrement ",
              "(correction non-paramétrique)."
            ),
            tags$li(
              tags$b("Hypothèses"),
              " : ",
              tags$b("H0"), " = racine unitaire ; ",
              tags$b("Ha"), " = stationnaire."
            ),
            tags$li(
              tags$b("Pourquoi utile"),
              " : complément de robustesse ; si ADF et PP convergent, confiance accrue."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Test PP (Phillips–Perron) — définition complète")),
              
              tags$ul(
                
                tags$li(
                  tags$b("Définition"),
                  " : le test Phillips–Perron est un test de ",
                  tags$b("racine unitaire"),
                  " similaire à l’ADF, mais qui corrige l’autocorrélation et ",
                  "l’hétéroscédasticité de manière non paramétrique."
                ),
                
                tags$li(
                  tags$b("But"),
                  " : tester la présence d’une racine unitaire de façon plus robuste ",
                  "aux violations des hypothèses classiques."
                ),
                
                tags$li(
                  tags$b("Quand l’utiliser"),
                  " : comme ",
                  tags$b("test de robustesse"),
                  " en complément de l’ADF, notamment si l’autocorrélation ou ",
                  "l’hétéroscédasticité sont suspectées."
                ),
                
                tags$li(
                  tags$b("Hypothèses"),
                  " : ",
                  tags$b("H0"),
                  " = présence d’une racine unitaire (non-stationnaire) ; ",
                  tags$b("Ha"),
                  " = série stationnaire."
                ),
                
                tags$li(
                  tags$b("Statistique / idée"),
                  " : basé sur la même régression que l’ADF, ",
                  "mais ajuste la statistique de test via une estimation ",
                  tags$b("non paramétrique"),
                  " de la variance longue."
                ),
                
                tags$li(
                  tags$b("Règle de décision"),
                  " : ",
                  tags$b("p petite"),
                  " → rejet de H0 → stationnarité ; ",
                  tags$b("p grande"),
                  " → racine unitaire probable."
                ),
                
                tags$li(
                  tags$b("Interprétation (sens)"),
                  " : même logique que l’ADF, mais plus robuste aux dépendances complexes."
                ),
                
                tags$li(
                  tags$b("Ce que ça implique pour vos choix"),
                  " : convergence ADF + PP → forte confiance dans la décision sur ",
                  tags$code("d"),
                  " ; divergence → prudence et analyse complémentaire."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter"),
                  " : indiquer qu’il s’agit d’un test PP, la statistique, la p-value ",
                  "et la conclusion."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter en format APA"),
                  " : ",
                  tags$i("« Le test de Phillips–Perron a rejeté l’hypothèse de racine unitaire, "),
                  tags$i("PP = −3.42, p = .01, suggérant une stationnarité de la série. »")
                ),
                
                tags$li(
                  tags$b("Limites / pièges"),
                  " : choix du paramètre de lissage non trivial ; ",
                  "peut être instable sur petits échantillons ; ",
                  "ne remplace pas l’analyse graphique."
                )
              )
            ),
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Comment conclure en combinant ADF/KPSS/PP (logique complète)")),
          tags$ol(
            tags$li(
              tags$b("Stationnarité forte : "),
              "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."
            ),
            tags$li(
              tags$b("Non-stationnarité forte : "),
              "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."
            ),
            tags$li(
              tags$b("Conflit : "),
              "les tests divergent → regarder graphiques, ACF, résultats après une différence, ",
              "et justifier par convergence d’indices (pas une seule p-value)."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Comment conclure en combinant ADF / KPSS / PP (logique complète)")),
              
              tags$ol(
                
                tags$li(
                  tags$b("Stationnarité forte"),
                  " : ADF et PP ",
                  tags$b("rejettent"),
                  " l’hypothèse de racine unitaire (p petites) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("ne rejette pas"),
                  " l’hypothèse de stationnarité."
                ),
                
                tags$li(
                  tags$b("Non-stationnarité forte"),
                  " : ADF et PP ",
                  tags$b("ne rejettent pas"),
                  " (p grandes) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("rejette"),
                  " la stationnarité."
                ),
                
                tags$li(
                  tags$b("Cas intermédiaire / conflit"),
                  " : les tests divergent → examiner graphiques, ACF, résultats après ",
                  "une ou plusieurs différenciations, et justifier la décision par ",
                  tags$b("convergence d’indices"),
                  " (jamais une seule p-value)."
                ),
                
                tags$li(
                  tags$b("Décision pratique"),
                  " : appliquer la ",
                  tags$b("différenciation minimale"),
                  " nécessaire pour obtenir une stationnarité raisonnable ",
                  "(éviter la sur-différenciation)."
                ),
                
                tags$li(
                  tags$b("Principe clé"),
                  " : les tests sont des ",
                  tags$b("outils d’aide à la décision"),
                  ", pas des règles automatiques."
                )
              )
            ),
            
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Comment conclure en combinant ADF / KPSS / PP (logique complète et détaillée)")),
              
              tags$ol(
                
                tags$li(
                  tags$b("Principe général"),
                  " : aucun test n’est fiable isolément. ",
                  "La conclusion doit reposer sur la ",
                  tags$b("cohérence"),
                  " entre tests (ADF, PP, KPSS), graphiques (série, ACF), ",
                  "et parcimonie des transformations."
                ),
                
                tags$li(
                  tags$b("Rappel des logiques opposées"),
                  " : ADF et PP testent la ",
                  tags$b("présence d’une racine unitaire"),
                  " (H0 = non-stationnarité), ",
                  "alors que KPSS teste la ",
                  tags$b("stationnarité"),
                  " (H0 = stationnaire). ",
                  "Ils sont donc ",
                  tags$b("complémentaires"),
                  " par construction."
                ),
                
                tags$li(
                  tags$b("Cas 1 — Stationnarité forte (convergence totale)"),
                  " : ",
                  tags$b("ADF et PP rejettent H0"),
                  " (p petites) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("ne rejette pas"),
                  " H0. ",
                  "→ Conclusion : série stationnaire → ",
                  tags$code("d = 0"),
                  " (et ",
                  tags$code("D = 0"),
                  " si pas de saisonnalité)."
                ),
                
                tags$li(
                  tags$b("Cas 2 — Non-stationnarité forte (convergence inverse)"),
                  " : ",
                  tags$b("ADF et PP ne rejettent pas"),
                  " (p grandes) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("rejette"),
                  " la stationnarité. ",
                  "→ Conclusion : racine unitaire claire → ",
                  tags$code("d = 1"),
                  " recommandé (puis retester)."
                ),
                
                tags$li(
                  tags$b("Cas 3 — ADF/PP rejettent mais KPSS rejette aussi"),
                  " : situation fréquente sur grands échantillons. ",
                  "→ Possible ",
                  tags$b("stationnarité autour d’une tendance"),
                  " ou ",
                  tags$b("rupture structurelle"),
                  ". Examiner graphiques, tester ADF avec tendance, ",
                  "ou préférer une différenciation prudente."
                ),
                
                tags$li(
                  tags$b("Cas 4 — ADF/PP ne rejettent pas mais KPSS ne rejette pas"),
                  " : tests peu informatifs (faible puissance). ",
                  "→ Examiner la série visuellement, tester après ",
                  tags$code("d = 1"),
                  ", et privilégier la solution ",
                  tags$b("la plus parcimonieuse"),
                  "."
                ),
                
                tags$li(
                  tags$b("Cas 5 — Désaccord ADF vs PP"),
                  " : indécision liée à l’autocorrélation ou à l’hétéroscédasticité. ",
                  "→ Donner plus de poids au PP (plus robuste) ",
                  "et confronter avec KPSS et ACF."
                ),
                
                tags$li(
                  tags$b("Logique opérationnelle recommandée"),
                  " : (1) tester sur la série brute ; ",
                  "(2) essayer ",
                  tags$code("d = 1"),
                  " si nécessaire ; ",
                  "(3) retester systématiquement ; ",
                  "(4) s’arrêter dès qu’une stationnarité ",
                  tags$b("raisonnable"),
                  " est atteinte."
                ),
                
                tags$li(
                  tags$b("Principe de parcimonie"),
                  " : toujours appliquer la ",
                  tags$b("différenciation minimale"),
                  " compatible avec la stationnarité. ",
                  "La sur-différenciation dégrade les prévisions."
                ),
                
                tags$li(
                  tags$b("Rôle clé des graphiques"),
                  " : ACF, série temporelle, et résidus après différenciation ",
                  "sont indispensables pour confirmer ou infirmer ",
                  "les conclusions issues des tests."
                ),
                
                tags$li(
                  tags$b("Conclusion scientifique attendue"),
                  " : la décision finale doit être ",
                  tags$b("argumentée"),
                  " par la convergence des tests, ",
                  "l’inspection graphique et la logique économique, ",
                  "pas par une seule p-value."
                )
              )
            ),
            
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Combiner ADF / KPSS / PP — tableau détaillé de décision (stationnarité)")),
              
              tags$table(
                class = "table table-sm table-bordered",
                tags$thead(
                  tags$tr(
                    tags$th("ADF / PP (H0 = racine unitaire)"),
                    tags$th("KPSS (H0 = stationnaire)"),
                    tags$th("Lecture statistique"),
                    tags$th("Diagnostic économétrique"),
                    tags$th("Conclusion sur la série"),
                    tags$th("Action recommandée"),
                    tags$th("Commentaires pédagogiques / pièges")
                  )
                ),
                tags$tbody(
                  
                  tags$tr(
                    tags$td("Rejet clair (p ≪ 5 %)"),
                    tags$td("Non-rejet (p ≫ 5 %)"),
                    tags$td("Convergence forte des tests"),
                    tags$td("Stationnarité confirmée"),
                    tags$td("Série stationnaire"),
                    tags$td("Aucune différenciation (d = 0)"),
                    tags$td("Cas idéal. Ne pas différencier inutilement.")
                  ),
                  
                  tags$tr(
                    tags$td("Non-rejet (p ≫ 5 %)"),
                    tags$td("Rejet clair (p ≪ 5 %)"),
                    tags$td("Convergence forte"),
                    tags$td("Racine unitaire non saisonnière"),
                    tags$td("Série non stationnaire"),
                    tags$td("Essayer d = 1"),
                    tags$td("Cas le plus fréquent en pratique.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet"),
                    tags$td("Rejet"),
                    tags$td("Résultats contradictoires"),
                    tags$td("Stationnarité autour d’une tendance"),
                    tags$td("Stationnaire après retrait de tendance"),
                    tags$td("d = 0 + tendance déterministe"),
                    tags$td("Souvent dû à une mauvaise spécification du test ADF.")
                  ),
                  
                  tags$tr(
                    tags$td("Non-rejet"),
                    tags$td("Non-rejet"),
                    tags$td("Manque de puissance"),
                    tags$td("Inconclusif"),
                    tags$td("Décision incertaine"),
                    tags$td("S’appuyer sur EDA + ACF"),
                    tags$td("Typique des petits échantillons ou séries très bruitées.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet marginal (p ≈ 5–10 %)"),
                    tags$td("Rejet marginal"),
                    tags$td("Frontière statistique"),
                    tags$td("Stationnarité douteuse"),
                    tags$td("Zone grise"),
                    tags$td("Tester d = 1 puis comparer"),
                    tags$td("Ne jamais décider sur une seule p-value.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet uniquement avec trend"),
                    tags$td("Rejet sans trend"),
                    tags$td("Sensibilité à la spécification"),
                    tags$td("Tendance déterministe probable"),
                    tags$td("Stationnaire autour d’une tendance"),
                    tags$td("Inclure tendance, éviter d"),
                    tags$td("Comparer systématiquement drift vs trend.")
                  ),
                  
                  tags$tr(
                    tags$td("Non-rejet sur série brute"),
                    tags$td("Rejet sur série brute"),
                    tags$td("Non-stationnarité détectée"),
                    tags$td("Racine unitaire I(1)"),
                    tags$td("Non stationnaire"),
                    tags$td("Différencier (d = 1)"),
                    tags$td("Décision standard avant ARMA.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet après d = 1"),
                    tags$td("Non-rejet après d = 1"),
                    tags$td("Convergence après transformation"),
                    tags$td("Stationnarité atteinte"),
                    tags$td("Série I(1) confirmée"),
                    tags$td("Conserver d = 1"),
                    tags$td("Ne pas essayer d = 2 par automatisme.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet très fort"),
                    tags$td("Rejet très fort"),
                    tags$td("Violation des hypothèses"),
                    tags$td("Rupture structurelle probable"),
                    tags$td("Stationnarité instable"),
                    tags$td("Tester Zivot–Andrews"),
                    tags$td("Les tests standards supposent paramètres constants.")
                  ),
                  
                  tags$tr(
                    tags$td("Résultats instables selon retard"),
                    tags$td("Résultats instables"),
                    tags$td("Sensibilité aux choix techniques"),
                    tags$td("Décision fragile"),
                    tags$td("Incertitude méthodologique"),
                    tags$td("Documenter + convergence d’indices"),
                    tags$td("La justification écrite est essentielle ici.")
                  )
                  
                )
              )
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Comment conclure en combinant ADF / KPSS / PP — version pédagogique")),
              
              tags$p(
                "Ce tableau ne doit pas être lu comme une règle mécanique. ",
                "Il sert à comprendre ",
                tags$b("la logique sous-jacente"),
                " à la combinaison des tests de stationnarité, ",
                "et à apprendre ",
                tags$b("comment raisonner"),
                " lorsque les résultats sont ambigus."
              ),
              
              tags$table(
                class = "table table-sm table-bordered",
                tags$thead(
                  tags$tr(
                    tags$th("Ce que disent les tests"),
                    tags$th("Ce que cela signifie vraiment"),
                    tags$th("Comment raisonner"),
                    tags$th("Décision raisonnable"),
                    tags$th("Message pédagogique clé")
                  )
                ),
                tags$tbody(
                  
                  tags$tr(
                    tags$td("ADF et PP rejettent clairement ; KPSS ne rejette pas"),
                    tags$td(
                      "Les tests qui ",
                      tags$b("cherchent une racine unitaire"),
                      " n’en trouvent pas, et le test qui ",
                      tags$b("suppose la stationnarité"),
                      " est cohérent avec cette hypothèse."
                    ),
                    tags$td(
                      "Toutes les sources d’information convergent. ",
                      "Il n’y a aucun signal fort de non-stationnarité."
                    ),
                    tags$td("Considérer la série comme stationnaire (d = 0)"),
                    tags$td(
                      "Ne pas différencier une série déjà stationnaire : ",
                      tags$b("la parcimonie est une vertu.")
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF et PP ne rejettent pas ; KPSS rejette clairement"),
                    tags$td(
                      "Les tests indiquent qu’un choc a ",
                      tags$b("un effet persistant"),
                      " et que la stationnarité est violée."
                    ),
                    tags$td(
                      "Il existe une forte probabilité de ",
                      tags$b("racine unitaire non saisonnière"),
                      "."
                    ),
                    tags$td("Différencier une fois (d = 1)"),
                    tags$td(
                      "C’est le ",
                      tags$b("cas standard"),
                      " des séries économiques et financières."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF/PP rejettent, mais KPSS rejette aussi"),
                    tags$td(
                      "Les tests ne sont pas en désaccord par hasard : ",
                      "ils ",
                      tags$b("ne testent pas la même chose"),
                      "."
                    ),
                    tags$td(
                      "Souvent, la série est stationnaire ",
                      tags$b("autour d’une tendance déterministe"),
                      ", mal prise en compte."
                    ),
                    tags$td("Utiliser d = 0 avec une tendance déterministe"),
                    tags$td(
                      "Différencier ici serait une ",
                      tags$b("erreur conceptuelle"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF/PP ne rejettent pas ; KPSS ne rejette pas"),
                    tags$td(
                      "Les tests manquent de puissance ou la série est très bruitée."
                    ),
                    tags$td(
                      "Aucune conclusion statistique forte n’est possible ",
                      "sur la seule base des tests."
                    ),
                    tags$td("S’appuyer sur EDA, ACF, contexte"),
                    tags$td(
                      "Les tests ne remplacent ",
                      tags$b("ni l’analyse graphique"),
                      " ni le raisonnement."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("Résultats sensibles à la spécification (constante / tendance)"),
                    tags$td(
                      "La décision dépend du modèle utilisé pour tester la stationnarité."
                    ),
                    tags$td(
                      "Comparer les résultats avec et sans tendance, ",
                      "et vérifier la cohérence avec les graphiques."
                    ),
                    tags$td("Choisir la spécification la plus cohérente"),
                    tags$td(
                      "Une p-value n’a de sens ",
                      tags$b("que dans un modèle bien spécifié"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("Après différenciation : ADF/PP rejettent, KPSS ne rejette plus"),
                    tags$td(
                      "La différenciation a supprimé la racine unitaire."
                    ),
                    tags$td(
                      "La série différenciée est maintenant stationnaire."
                    ),
                    tags$td("Conserver d = 1"),
                    tags$td(
                      "Différencier plus serait ",
                      tags$b("contre-productif"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF/PP et KPSS rejettent très fortement"),
                    tags$td(
                      "Les hypothèses des tests (paramètres constants) sont probablement violées."
                    ),
                    tags$td(
                      "Suspecter une ",
                      tags$b("rupture structurelle"),
                      " ou un changement de régime."
                    ),
                    tags$td("Tester une rupture (ex. Zivot–Andrews)"),
                    tags$td(
                      "Les tests classiques ",
                      tags$b("ne voient pas les ruptures"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("Résultats instables selon les retards choisis"),
                    tags$td(
                      "La décision est fragile statistiquement."
                    ),
                    tags$td(
                      "Ne pas automatiser la décision ; ",
                      "documenter le raisonnement."
                    ),
                    tags$td("Décision argumentée, pas automatique"),
                    tags$td(
                      "En pratique, ",
                      tags$b("on justifie plus qu’on ne tranche"),
                      "."
                    )
                  )
                  
                )
              ),
              
              tags$p(
                tags$b("Message final à retenir : "),
                "ADF, KPSS et PP ne sont pas des oracles. ",
                "Ils fournissent des ",
                tags$b("indices complémentaires"),
                ". ",
                "La bonne décision repose sur la ",
                tags$b("convergence des tests"),
                ", l’EDA et le raisonnement économique/statistique."
              )
            ),
            
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Diagramme pédagogique — combiner ADF / KPSS / PP (raisonnement)")),
              tags$div(
                style = "padding:10px 12px; background:#fff; overflow-x:auto;",
                DiagrammeR::grVizOutput("adf_kpss_pp_tree", height = "2000px")
              )
            ),
            
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Procédure recommandée (pas à pas)")),
          tags$ol(
            tags$li("Fixer ", tags$b("s"), " (période saisonnière) à partir du contexte et de l’EDA."),
            tags$li("Tester ADF/KPSS/PP sur la série brute."),
            tags$li("Essayer d = 1 si nécessaire, retester."),
            tags$li("Essayer D = 1 si saisonnalité / racine saisonnière, retester."),
            tags$li("S’arrêter dès que stationnarité “raisonnable” ; éviter sur-différenciation.")
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Sur-différenciation : définition + symptômes")),
          tags$ul(
            tags$li(
              tags$b("Définition"),
              " : appliquer trop de différences → on introduit une dynamique artificielle."
            ),
            tags$li(
              tags$b("Symptômes fréquents"),
              " : ACF au lag 1 très négative, variance gonflée, prévisions erratiques, paramètres instables."
            ),
            tags$li(
              tags$b("Conséquence"),
              " : intervalles de prévision plus larges et modèle moins fiable."
            )
          )
        ),
        
        
        
        
        

        # === ADD: tests/bonnes pratiques complémentaires ===
        
        
        # H5("Tests et notions complémentaires"),
        # UL(
        #   tags$li(B("Tendance déterministe vs racine unitaire"),
        #           " : on peut préférer un ARIMA avec ", C("d=0"), " et une tendance ", B("déterministe"),
        #           " (régression + ARMA sur résidus) si la tendance semble stable."),
        #   tags$li(B("Racine unitaire saisonnière (HEGY)"), " : (annexe) test dédié aux racines à ", C("±1, ±i"), " pour ",
        #           C("s=4,12"), " ; utile si la saisonnalité stochastique domine."),
        #   tags$li(B("Zivot–Andrews"), " : (annexe) racine unitaire avec rupture endogène possible.")
        # ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Tests et notions complémentaires")),
          
          tags$ul(
            tags$li(
              tags$b("Tendance déterministe vs racine unitaire"),
              " : on peut préférer un ARIMA avec ",
              tags$code("d = 0"),
              " et une tendance ",
              tags$b("déterministe"),
              " (régression + ARMA sur résidus) si la tendance semble stable."
            ),
            tags$li(
              tags$b("Racine unitaire saisonnière (HEGY)"),
              " : (annexe) test dédié aux racines à ",
              tags$code("±1, ±i"),
              " pour ",
              tags$code("s = 4, 12"),
              " ; utile si la saisonnalité stochastique domine.",
              
              tags$details(
                class = "defs-details",
                tags$summary(tags$span("Test HEGY — racines unitaires saisonnières (définition complète)")),
                
                tags$ul(
                  
                  tags$li(
                    tags$b("Définition"),
                    " : le test HEGY (Hylleberg–Engle–Granger–Yoo) est un test de ",
                    tags$b("racines unitaires saisonnières"),
                    " qui permet d’identifier si une série présente des racines unitaires ",
                    tags$b("non saisonnières"),
                    " et/ou ",
                    tags$b("saisonnières"),
                    " (ex. annuelle, semi-annuelle, trimestrielle)."
                  ),
                  
                  tags$li(
                    tags$b("But"),
                    " : déterminer si la non-stationnarité provient d’une ",
                    tags$b("tendance stochastique"),
                    ", d’une ",
                    tags$b("saisonnalité stochastique"),
                    ", ou des deux."
                  ),
                  
                  tags$li(
                    tags$b("Quand l’utiliser"),
                    " : lorsque la série présente une ",
                    tags$b("saisonnalité marquée"),
                    " et que l’on suspecte une ",
                    tags$b("racine unitaire saisonnière"),
                    " (ex. séries mensuelles ou trimestrielles avec saisonnalité instable)."
                  ),
                  
                  tags$li(
                    tags$b("Hypothèses"),
                    " : ",
                    tags$b("H0"),
                    " = présence d’une ou plusieurs racines unitaires (aux fréquences ",
                    tags$code("±1, ±i"),
                    " selon ",
                    tags$code("s"),
                    ") ; ",
                    tags$b("Ha"),
                    " = absence de racine unitaire à ces fréquences."
                  ),
                  
                  tags$li(
                    tags$b("Statistique / idée"),
                    " : la série est réécrite de façon à isoler les composantes associées ",
                    "aux différentes fréquences saisonnières, puis des tests t et F sont ",
                    "appliqués sur les coefficients correspondants."
                  ),
                  
                  tags$li(
                    tags$b("Règle de décision"),
                    " : rejet de H0 pour une fréquence donnée → pas de racine unitaire ",
                    "à cette fréquence ; non-rejet → racine unitaire présente."
                  ),
                  
                  tags$li(
                    tags$b("Interprétation (sens)"),
                    " : si une racine unitaire saisonnière est détectée, une ",
                    tags$b("différenciation saisonnière"),
                    " (",
                    tags$code("D = 1"),
                    ") est généralement justifiée."
                  ),
                  
                  tags$li(
                    tags$b("Ce que ça implique pour vos choix"),
                    " : HEGY aide à décider entre ",
                    tags$b("différenciation ordinaire"),
                    " (",
                    tags$code("d"),
                    ") et ",
                    tags$b("différenciation saisonnière"),
                    " (",
                    tags$code("D"),
                    "), et à éviter des choix arbitraires."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter"),
                    " : préciser la périodicité ",
                    tags$code("s"),
                    ", les fréquences testées, les statistiques de test et les conclusions ",
                    "pour chaque racine saisonnière."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter en format APA"),
                    " : ",
                    tags$i("« Un test HEGY a été réalisé afin d’évaluer la présence de racines "),
                    tags$i("unitaires saisonnières dans la série mensuelle. "),
                    tags$i("Les résultats indiquent une racine unitaire saisonnière annuelle "),
                    tags$i("(p < .05), justifiant l’application d’une différenciation saisonnière. »")
                  ),
                  
                  tags$li(
                    tags$b("Limites / pièges"),
                    " : test complexe et moins connu ; ",
                    "puissance limitée sur petits échantillons ; ",
                    "sensible au choix des retards ; ",
                    "peu implémenté dans les logiciels standards."
                  )
                )
              ),
              
            ),
            tags$li(
              tags$b("Zivot–Andrews"),
              " : (annexe) test de racine unitaire avec rupture structurelle endogène possible.",
              
              tags$details(
                class = "defs-details",
                tags$summary(tags$span("Test de Zivot–Andrews — racine unitaire avec rupture endogène (définition complète)")),
                
                tags$ul(
                  
                  tags$li(
                    tags$b("Définition"),
                    " : le test de Zivot–Andrews est un test de ",
                    tags$b("racine unitaire"),
                    " qui autorise une ",
                    tags$b("rupture structurelle endogène"),
                    " (date inconnue) dans la série."
                  ),
                  
                  tags$li(
                    tags$b("But"),
                    " : distinguer une véritable racine unitaire d’une ",
                    tags$b("non-stationnarité apparente"),
                    " due à une rupture de niveau ou de tendance."
                  ),
                  
                  tags$li(
                    tags$b("Quand l’utiliser"),
                    " : lorsque la série montre un ",
                    tags$b("changement brutal"),
                    " (crise, réforme, choc externe) et que l’ADF classique semble indiquer ",
                    "une racine unitaire."
                  ),
                  
                  tags$li(
                    tags$b("Hypothèses"),
                    " : ",
                    tags$b("H0"),
                    " = racine unitaire sans rupture ; ",
                    tags$b("Ha"),
                    " = stationnarité avec une rupture structurelle (niveau et/ou tendance)."
                  ),
                  
                  tags$li(
                    tags$b("Statistique / idée"),
                    " : le test estime successivement une ADF pour chaque date de rupture ",
                    "possible, puis retient la statistique la plus défavorable à H0 ",
                    "(rupture endogène)."
                  ),
                  
                  tags$li(
                    tags$b("Règle de décision"),
                    " : si la statistique dépasse la valeur critique → rejet de H0 → ",
                    "stationnarité avec rupture."
                  ),
                  
                  tags$li(
                    tags$b("Interprétation (sens)"),
                    " : rejet de H0 signifie que la série est ",
                    tags$b("stationnaire conditionnellement"),
                    " à une rupture, et qu’une différenciation n’est pas forcément nécessaire."
                  ),
                  
                  tags$li(
                    tags$b("Ce que ça implique pour vos choix"),
                    " : possibilité de conserver ",
                    tags$code("d = 0"),
                    " et d’introduire une ",
                    tags$b("variable muette de rupture"),
                    " plutôt que de différencier."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter"),
                    " : indiquer le type de rupture (niveau / tendance), la date estimée ",
                    "et la conclusion sur la stationnarité."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter en format APA"),
                    " : ",
                    tags$i("« Un test de Zivot–Andrews a mis en évidence une rupture "),
                    tags$i("structurelle endogène en 2008. Le test rejette l’hypothèse "),
                    tags$i("de racine unitaire (p < .05), suggérant une stationnarité "),
                    tags$i("conditionnelle à cette rupture. »")
                  ),
                  
                  tags$li(
                    tags$b("Limites / pièges"),
                    " : autorise une seule rupture ; ",
                    "puissance limitée si plusieurs ruptures ; ",
                    "valeurs critiques spécifiques ; ",
                    "ne remplace pas l’analyse économique du contexte."
                  )
                )
              ),
              
              
            )
          )
        ),
        
        
        
        # H5("Bonnes pratiques de différenciation"),
        # UL(
        #   tags$li(B("Au plus une différence"), " : commencer par ", C("d=1"), " ou ", C("D=1"),
        #           " ; ", B("éviter"), " ", C("d=2"), " sauf preuves fortes."),
        #   tags$li(B("Sur-différenciation : "), "ACF lag 1 très négative, variance gonflée, MA artificiel → revenir en arrière.")
        # )
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Bonnes pratiques de différenciation")),
          
          tags$ul(
            tags$li(
              tags$b("Au plus une différence"),
              " : commencer par ",
              tags$code("d = 1"),
              " ou ",
              tags$code("D = 1"),
              " ; ",
              tags$b("éviter"),
              " ",
              tags$code("d = 2"),
              " sauf preuves fortes."
            ),
            tags$li(
              tags$b("Sur-différenciation"),
              " : ACF au lag 1 très négative, variance gonflée, MA artificiel → revenir en arrière."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Arbre décisionnel — stationnarité & différenciation (ADF/KPSS/PP)")),
          tags$div(
            style = "padding:10px 12px; background:#fff; overflow-x:auto;",
            DiagrammeR::grVizOutput("stationarity_tree2", height = "1500px")
          )
        )
        
      ),
      
      apa_ui = tagList(
        H5("Méthodes (APA) — Tests & choix de (d, D)"),
        P("« La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. ",
          "Les résultats ont été examinés sur la série originale puis après différenciations ordinaires et saisonnières. ",
          "Sur la base de l’ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
          "afin d’obtenir une série approximativement stationnaire adaptée à l’estimation SARIMA, tout en évitant la sur-différenciation. »"),
        
        H5("Conclusion test (prête à remplir) + signification"),
        UL(
          tags$li(B("ADF : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
                  " H0 (racine unitaire). ",
                  B("Signification : "),
                  "si rejet → la série est compatible stationnarité (au sens ADF) ; sinon → différenciation probablement nécessaire."),
          tags$li(B("KPSS : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
                  " H0 (stationnarité). ",
                  B("Signification : "),
                  "si rejet → non-stationnarité (donc d/D à augmenter ou transformation/rupture à traiter)."),
          tags$li(B("PP : "), "p=[..] → ", B("[rejeter / ne pas rejeter]"),
                  " H0 (racine unitaire). ",
                  B("Signification : "),
                  "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
        ),
        
        H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
        UL(
          tags$li(B("Conclusion : "), "« Nous retenons d=[..], D=[..], s=[..]. »"),
          tags$li(B("Signification : "),
                  "« le SARIMA sera estimé sur la série différenciée ; les paramètres AR/MA décrivent la dynamique ",
                  "restante après retrait de la tendance et/ou de la saisonnalité non stationnaire. »")
        ),
        
        # === ADD: points à expliciter
        H5("À expliciter (rappel)"),
        UL(
          tags$li("Préciser si une constante/drift est incluse et à quel niveau (avant/après différenciation)."),
          tags$li("Documenter toute rupture suspectée et ses conséquences sur le choix de ", C("d, D"), ".")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Choisir d et D “par habitude”"), " : toujours justifier par tests + EDA."),
          tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent “crier non-stationnaire” alors qu’un changement de régime est en cause."),
          tags$li(B("Interpréter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on s’appuie sur convergence des preuves.")
        )
      )
    )
    
    # (6) Étape 5 — Auto-ARIMA baseline
    pages[[7]] <- make_step(
      step_names[7],
      
      actions_ui = tagList(
        callout(B("But : "), "obtenir un point de départ compétitif, puis vérifier/affiner.", type="info"),
        
        Checklist(
          CheckItem("Executer auto-ARIMA avec des bornes raisonnables sur p,q,P,Q et noter le critere (AICc) utilise."),
          CheckItem("Enregistrer le modele baseline (ordres + presence drift/constante) pour comparaison ulterieure."),
          CheckItem("Verifier diagnostics residuels (ACF residus, Ljung-Box) avant de le considerer ‘acceptable’."),
          CheckItem("Evaluer la performance sur la fenetre test (MAE/RMSE) et comparer au benchmark naif/SNAIVE."),
          CheckItem("Decider si vous cherchez une version plus parcimonieuse (BIC plus faible ou meme performance avec moins de parametres).")
        ),
        
        Deliverables(
          tags$li("Le modèle auto.arima retenu (ordres, paramètres) + critères (AICc/BIC) + limites (point de départ, pas une vérité)."),
          tags$li("Comparaison contre le benchmark (au minimum) sur la période test, avec tableau de métriques et commentaire."),
          tags$li("Diagnostics résiduels essentiels : ACF des résidus + Ljung–Box + commentaire (bruit blanc ou non).")
        ),
        
        
        H5("Définition : auto-ARIMA (ce que fait réellement l’algorithme)"),
        UL(
          tags$li("Explore un ensemble de modèles candidats (p,q,P,Q) sous contraintes."),
          tags$li("Choisit souvent via minimisation ", B("AICc"),
                  " (AIC corrigé petits échantillons)."),
          tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coûteuse).")
        ),
        
        H5("Pourquoi AICc ? (objectif)"),
        UL(
          tags$li("Compromis entre qualité d’ajustement et complexité (pénalise les paramètres)."),
          tags$li("AICc est préférable à AIC quand n n’est pas très grand par rapport au nombre de paramètres.")
        ),
        
        H5("Procédure propre"),
        OL(
          tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
          tags$li("Fixer bornes max p/q/P/Q ; documenter."),
          tags$li("Sauvegarder le modèle baseline (pour comparaison)."),
          tags$li("Vérifier diagnostics résiduels + performance sur test.")
        ),
        
        # === ADD: détails de recherche & critères multiples ===
        H5("Détails de recherche"),
        UL(
          tags$li(B("Stepwise vs exhaustive"), " : stepwise = rapide, peut rater un optimum global ; exhaustive = coûteux mais plus fiable."),
          tags$li(B("Contraintes"), " : imposer ", C("p,q,P,Q \u2264"), " bornes raisonnables ; forcer stabilité/inversibilité."),
          tags$li(B("drift/constante"), " : tester versions avec et sans drift lorsque ", C("d=1"), ".")
        ),
        H5("Critères multiples"),
        UL(
          tags$li("Comparer AICc ", B("et"), " BIC ; en cas de quasi-égalité → choisir le plus parcimonieux.")
        )
      ),
      
      apa_ui = tagList(
        H5("Méthodes (APA) — baseline"),
        P("« Un modèle SARIMA de référence a été sélectionné via une procédure auto-ARIMA basée sur un critère d’information (minimisation de l’AICc) parmi des ordres candidats sous contraintes [..]. ",
          "La spécification obtenue a été utilisée comme baseline, puis comparée à des modèles manuels plus parcimonieux sur la base des diagnostics et de la performance de prévision. »"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "« Auto-ARIMA fournit une baseline solide »"),
          tags$li(B("Signification : "), "« on a un repère : tout modèle final doit faire au moins aussi bien. »")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Modèle “trop complexe”"), " : stepwise peut sélectionner des ordres élevés → instabilité, interprétation difficile."),
          tags$li(B("AICc excellent mais résidus mauvais"), " : diagnostics priment."),
          tags$li(B("Oublier la parcimonie"), " : si deux modèles prédisent pareil, garder le plus simple.")
        )
      )
    )
    
    # (7) Étape 6 — SARIMA manuel
    pages[[8]] <- make_step(
      step_names[8],
      
      actions_ui = tagList(
        callout(B("But : "), "proposer un petit ensemble raisonné de candidats via ACF/PACF.", type="info"),
        
        Checklist(
          CheckItem("Tracer ACF/PACF de la serie differenciee (apres choix d et D) et identifier les pics significatifs."),
          CheckItem("Proposer un petit ensemble de candidats (3 a 8) en justifiant p,q,P,Q par les motifs ACF/PACF (y compris aux multiples de s)."),
          CheckItem("Ajuster chaque candidat, relever AICc/BIC, et verifier stabilite/inversibilite si possible."),
          CheckItem("Comparer sur diagnostics residuels ET performance predictive (pas seulement AICc)."),
          CheckItem("Garder le modele le plus simple qui passe diagnostics et bat le benchmark.")
        ),
        
        Deliverables(
          tags$li("Une liste courte de candidats SARIMA manuels (2–6 modèles) + rationale ACF/PACF + parcimonie."),
          tags$li("Un tableau comparatif (AICc/BIC + diagnostics + performance test) pour choisir un modèle final."),
          tags$li("L’équation du modèle final en trois versions : générale → estimée → estimée avec valeurs numériques.")
        ),
        
        
        H5("Définitions : ACF / PACF (ce que mesurent ces courbes)"),
        UL(
          tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"),
                  " → suggère MA(q) si coupure nette vers q."),
          tags$li(B("PACF"), " : corrélation “pure” au retard k une fois les retards <k contrôlés ",
                  "→ suggère AR(p) si coupure nette vers p.")
        ),
        
        H5("Heuristiques (non saisonnier)"),
        UL(
          tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF décroît."),
          tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF décroît."),
          tags$li(B("ARMA"), " : ACF et PACF décroissent (pas de coupure franche).")
        ),
        
        H5("Heuristiques saisonnières (multiples de s)"),
        UL(
          tags$li(B("SAR(P)"), " : pics PACF à s, 2s, ..."),
          tags$li(B("SMA(Q)"), " : pics ACF à s, 2s, ...")
        ),
        
        H5("Procédure recommandée (petit nombre de modèles)"),
        OL(
          tags$li("Construire 3 à 8 candidats (parcimonieux)."),
          tags$li("Ajuster et comparer AICc/BIC."),
          tags$li("Vérifier stabilité/inversibilité."),
          tags$li("Retenir ceux qui passent diagnostics + prévision.")
        ),
        
        # === ADD: conception de candidats & lecture fine ===
        H5("Conception de candidats (rappels utiles)"),
        UL(
          tags$li(B("Limiter le set"), " : 3–8 modèles max, justifiés par ACF/PACF."),
          tags$li(B("Stabilité/inversibilité"), " : vérifier racines des polynômes AR/MA (hors cercle unité)."),
          tags$li(B("drift/constante"), " : inclure/exclure et comparer au niveau AICc/BIC + diagnostics.")
        ),
        H5("Lecture fine ACF/PACF"),
        UL(
          tags$li("Pics à ", C("s, 2s, 3s"), " dans l’ACF → penser ", B("SMA(Q)"), "."),
          tags$li("Pics à ", C("s, 2s"), " dans la PACF → penser ", B("SAR(P)"), "."),
          tags$li("Queue AR (décroissance géométrique) vs coupure MA (après q).")
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Étapes détaillées de choix de s, d, D, p, q, P, Q (méthode complète SARIMA)")),
          
          tags$ol(
            
            tags$li(
              tags$b("Identifier la période saisonnière s (fondation du modèle)"),
              " : ",
              tags$b("avant toute modélisation"),
              ", déterminer la périodicité naturelle de la série à partir du contexte ",
              "(mensuel → s = 12, hebdomadaire → s = 7, trimestriel → s = 4, horaire → s = 24, etc.). ",
              "Confirmer empiriquement avec l’EDA : répétitions visuelles, ",
              "pics réguliers dans l’ACF aux lags ",
              tags$code("s, 2s, 3s"),
              ". Une mauvaise valeur de ",
              tags$code("s"),
              " invalide tout le modèle SARIMA."
            ),
            
            tags$li(
              tags$b("Stabiliser la variance si nécessaire (pré-traitement)"),
              " : examiner la relation niveau–variance. ",
              "Si la variance augmente avec le niveau, appliquer une ",
              tags$b("transformation"),
              " (log ou Box–Cox) ",
              tags$b("avant"),
              " la différenciation. ",
              "Objectif : rendre la dynamique plus additive et les résidus plus homogènes."
            ),
            
            tags$li(
              tags$b("Tester et choisir D : différenciation saisonnière"),
              " : le paramètre ",
              tags$code("D"),
              " sert à éliminer une ",
              tags$b("racine unitaire saisonnière"),
              ". Indices typiques : ",
              "ACF très élevée aux multiples de ",
              tags$code("s"),
              ", saisonnalité qui dérive dans le temps. ",
              "En pratique, essayer ",
              tags$code("D = 1"),
              " (",
              tags$b("rarement 2"),
              "), puis retester la stationnarité. ",
              "Une différenciation saisonnière inutile complique inutilement le modèle."
            ),
            
            tags$li(
              tags$b("Tester et choisir d : différenciation ordinaire"),
              " : le paramètre ",
              tags$code("d"),
              " élimine la ",
              tags$b("tendance stochastique"),
              " (racine unitaire non saisonnière). ",
              "S’appuyer sur ADF / PP (H0 = racine unitaire) et KPSS (H0 = stationnaire). ",
              "En pratique, essayer ",
              tags$code("d = 1"),
              " si nécessaire, puis ",
              tags$b("s’arrêter dès que la stationnarité est raisonnable"),
              ". ",
              tags$b("Éviter d = 2"),
              " sauf justification solide."
            ),
            
            tags$li(
              tags$b("Contrôler la sur-différenciation"),
              " : une sur-différenciation se manifeste par une ",
              tags$b("ACF très négative au lag 1"),
              ", une variance gonflée et des prévisions instables. ",
              "Si observé, ",
              tags$b("revenir en arrière"),
              " et réduire ",
              tags$code("d"),
              " ou ",
              tags$code("D"),
              "."
            ),
            
            tags$li(
              tags$b("Tracer ACF et PACF sur la série différenciée"),
              " : l’identification de ",
              tags$code("p, q, P, Q"),
              " se fait ",
              tags$b("uniquement après"),
              " le choix définitif de ",
              tags$code("d"),
              " et ",
              tags$code("D"),
              ". ",
              "Examiner séparément les ",
              tags$b("lags courts"),
              " (non saisonniers) et les ",
              tags$b("multiples de s"),
              " (saisonniers)."
            ),
            
            tags$li(
              tags$b("Choisir p et q (partie non saisonnière)"),
              " : utiliser les heuristiques classiques : ",
              tags$b("AR(p)"),
              " → coupure nette de la PACF ; ",
              tags$b("MA(q)"),
              " → coupure nette de l’ACF ; ",
              "ARMA → décroissance progressive des deux. ",
              "Limiter généralement ",
              tags$code("p, q ≤ 2"),
              "."
            ),
            
            tags$li(
              tags$b("Choisir P et Q (partie saisonnière)"),
              " : analyser les pics aux lags ",
              tags$code("s, 2s, …"),
              ". ",
              "Pics dans la ",
              tags$b("PACF"),
              " → ",
              tags$code("P"),
              " ; pics dans l’",
              tags$b("ACF"),
              " → ",
              tags$code("Q"),
              ". ",
              "En pratique, ",
              tags$code("P, Q ∈ {0,1}"),
              " suffisent dans la majorité des cas."
            ),
            
            tags$li(
              tags$b("Construire un ensemble restreint de modèles candidats"),
              " : proposer ",
              tags$b("3 à 8 modèles"),
              " plausibles, en faisant varier un paramètre à la fois. ",
              "Chaque candidat doit être ",
              tags$b("explicitement justifié"),
              " par les motifs observés dans l’ACF/PACF."
            ),
            
            tags$li(
              tags$b("Ajuster les modèles et filtrer par faisabilité"),
              " : pour chaque candidat, relever ",
              tags$b("AICc/BIC"),
              ", vérifier la convergence, et si possible la ",
              tags$b("stationnarité et l’inversibilité"),
              ". ",
              "Un modèle numériquement instable doit être écarté."
            ),
            
            tags$li(
              tags$b("Filtrer par diagnostics résiduels (critère bloquant)"),
              " : conserver uniquement les modèles dont les résidus sont ",
              tags$b("compatibles avec un bruit blanc"),
              " : ACF des résidus ≈ 0 et test de Ljung–Box non significatif. ",
              "Un bon AIC ne compense jamais des résidus autocorrélés."
            ),
            
            tags$li(
              tags$b("Comparer la performance prévisionnelle"),
              " : évaluer les modèles restants ",
              tags$b("hors-échantillon"),
              " (split temporel ou rolling-origin) avec MAE/RMSE/MASE, ",
              "et comparer systématiquement à un ",
              tags$b("benchmark"),
              " (naïf, drift ou SNAIVE)."
            ),
            
            tags$li(
              tags$b("Choisir le modèle final (principe de parcimonie)"),
              " : retenir le modèle ",
              tags$b("le plus simple"),
              " qui passe les diagnostics, ",
              tags$b("bat le benchmark"),
              " et présente une performance stable. ",
              "La justification doit reposer sur ",
              tags$b("la convergence des indices"),
              ", pas sur un seul critère."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Choix de s, d, D, p, q, P, Q — synthèse méthodologique (tableaux)")),
          
          ## ===== TABLE 1 : s =====
          tags$h5("1) Choisir la période saisonnière s"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Élément"),
                tags$th("Ce qu’on regarde"),
                tags$th("Décision")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("Contexte"),
                tags$td("Fréquence naturelle des données (mensuel, hebdo, etc.)"),
                tags$td("Fixer s (ex. mensuel → s = 12)")
              ),
              tags$tr(
                tags$td("EDA / ACF"),
                tags$td("Motifs répétitifs, pics ACF à s, 2s, 3s"),
                tags$td("Confirmer ou ajuster s")
              )
            )
          ),
          
          ## ===== TABLE 2 : transformation =====
          tags$h5("2) Stabilisation de la variance (optionnel)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Indice"),
                tags$th("Diagnostic"),
                tags$th("Action")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("Variance ↑ avec niveau"),
                tags$td("Nuage niveau–variance, résidus hétérogènes"),
                tags$td("Log ou Box–Cox (avant différenciation)")
              ),
              tags$tr(
                tags$td("Variance stable"),
                tags$td("Dispersion homogène"),
                tags$td("Pas de transformation")
              )
            )
          ),
          
          ## ===== TABLE 3 : D =====
          tags$h5("3) Choisir D (différenciation saisonnière)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Indice"),
                tags$th("Ce que ça signifie"),
                tags$th("Décision")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("ACF forte à s, 2s"),
                tags$td("Racine unitaire saisonnière"),
                tags$td("Essayer D = 1")
              ),
              tags$tr(
                tags$td("Saisonnalité stable"),
                tags$td("Motif déterministe"),
                tags$td("D = 0")
              ),
              tags$tr(
                tags$td("D = 2"),
                tags$td("Très rare"),
                tags$td("À éviter sauf preuve forte")
              )
            )
          ),
          
          ## ===== TABLE 4 : d =====
          tags$h5("4) Choisir d (différenciation ordinaire)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Tests / indices"),
                tags$th("Conclusion"),
                tags$th("Action")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("ADF/PP non significatifs + KPSS significatif"),
                tags$td("Racine unitaire non saisonnière"),
                tags$td("Essayer d = 1")
              ),
              tags$tr(
                tags$td("ADF/PP significatifs + KPSS non significatif"),
                tags$td("Stationnarité raisonnable"),
                tags$td("d = 0")
              ),
              tags$tr(
                tags$td("ACF lag 1 très négative"),
                tags$td("Sur-différenciation"),
                tags$td("Réduire d")
              )
            )
          ),
          
          ## ===== TABLE 5 : p / q =====
          tags$h5("5) Choisir p et q (partie non saisonnière)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Motif ACF / PACF"),
                tags$th("Interprétation"),
                tags$th("Choix suggéré")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("PACF coupée, ACF décroissante"),
                tags$td("AR(p)"),
                tags$td("p = ordre de coupure")
              ),
              tags$tr(
                tags$td("ACF coupée, PACF décroissante"),
                tags$td("MA(q)"),
                tags$td("q = ordre de coupure")
              ),
              tags$tr(
                tags$td("ACF et PACF décroissantes"),
                tags$td("ARMA"),
                tags$td("p, q petits (≤ 2)")
              )
            )
          ),
          
          ## ===== TABLE 6 : P / Q =====
          tags$h5("6) Choisir P et Q (partie saisonnière)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Motif aux lags s, 2s"),
                tags$th("Interprétation"),
                tags$th("Choix suggéré")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("Pics PACF à s"),
                tags$td("SAR(P)"),
                tags$td("P = 1 (souvent suffisant)")
              ),
              tags$tr(
                tags$td("Pics ACF à s"),
                tags$td("SMA(Q)"),
                tags$td("Q = 1 (souvent suffisant)")
              )
            )
          ),
          
          ## ===== TABLE 7 : sélection finale =====
          tags$h5("7) Sélection finale des modèles"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Critère"),
                tags$th("Rôle"),
                tags$th("Règle")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("AICc / BIC"),
                tags$td("Filtrage initial"),
                tags$td("Comparer modèles plausibles uniquement")
              ),
              tags$tr(
                tags$td("Diagnostics résiduels"),
                tags$td("Critère bloquant"),
                tags$td("Résidus ~ bruit blanc")
              ),
              tags$tr(
                tags$td("Performance prévisionnelle"),
                tags$td("Décision finale"),
                tags$td("Battre le benchmark")
              ),
              tags$tr(
                tags$td("Parcimonie"),
                tags$td("Choix final"),
                tags$td("Le plus simple à perf comparable")
              )
            )
          )
        ),
        
        
        
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Arbre décisionnel — choix de p,d,q,P,D,Q (SARIMA)")),
          tags$div(
            style = "padding:10px 12px; background:#fff; overflow-x:auto;",
            DiagrammeR::grVizOutput("pdqpDQ_tree", height = "2000px")
          )
        ),
        
        
      ),
      
      apa_ui = tagList(
        H5("Méthodes (APA) — sélection manuelle"),
        P("« Les structures candidates ont été proposées sur la base des schémas ACF/PACF de la série différenciée. ",
          "Des autocorrélations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
          "Un ensemble restreint de modèles (n=[..]) a été ajusté et comparé via AICc/BIC et diagnostics résiduels, en privilégiant la parcimonie. »"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "« Le modèle final est soutenu par la structure ACF/PACF et les diagnostics. »"),
          tags$li(B("Signification : "), "« on réduit le risque de sur-ajustement en limitant les candidats. »")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Brute-force massif"), " : tester 200 modèles puis choisir le plus petit AICc = data snooping."),
          tags$li(B("Surinterpréter ACF/PACF"), " : ce sont des guides, pas des preuves."),
          tags$li(B("Ignorer l’inversibilité/stabilité"), " : paramètres instables → prévisions incohérentes.")
        )
      )
    )
    
    # (8) Étape 7 — Diagnostics & comparaison
    pages[[9]] <- make_step(
      step_names[9],
      
      actions_ui = tagList(
        callout(B("But : "), "valider que le modèle explique toute la dépendance et prédit bien.", type="ok"),
        
        Checklist(
          CheckItem("Examiner les residus: courbe temporelle, ACF residus, et Ljung-Box a plusieurs lags L."),
          CheckItem("Verifier qu’il n’y a pas de structure residuelle (p-value Ljung-Box non significative) et ajuster si necessaire."),
          CheckItem("Evaluer la prediction hors-echantillon (MAE/RMSE/MASE) avec le meme horizon et le meme protocole pour tous les modeles."),
          CheckItem("Comparer explicitement au benchmark (naif/SNAIVE) et conclure sur la valeur ajoutee."),
          CheckItem("Documenter toute violation (ARCH, rupture, non-normalite) et expliquer l’impact sur IC et interpretation.")
        ),
        
        Deliverables(
          tags$li("Un rapport de diagnostics : résidus (plots), tests (Ljung–Box, normalité), et décision finale (OK / à revoir)."),
          tags$li("Une évaluation prévisionnelle : erreurs sur test + inspection visuelle des prévisions (niveau, saisonnalité, turning points)."),
          tags$li("Une conclusion de sélection : pourquoi ce modèle est retenu et quels compromis il implique (simplicité vs performance).")
        ),
        
        
        # H5("Diagnostics résiduels : définitions & buts"),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Diagnostics résiduels : définitions & buts")),
          
          tags$ul(
            
            tags$li(
              tags$b("Définition"),
              " : les diagnostics résiduels consistent à analyser les ",
              tags$b("résidus du modèle"),
              " (observé − ajusté) afin de vérifier que le modèle a correctement ",
              tags$b("capturé toute la structure"),
              " de la série."
            ),
            
            tags$li(
              tags$b("Idée centrale"),
              " : un bon modèle de série temporelle laisse des résidus qui se comportent ",
              "comme un ",
              tags$b("bruit blanc"),
              " : imprévisibles, non autocorrélés, centrés et de variance stable."
            ),
            
            tags$li(
              tags$b("But principal"),
              " : vérifier que le modèle est ",
              tags$b("adéquat"),
              " pour la prévision et l’inférence, et qu’il n’existe ",
              tags$b("aucune structure systématique non expliquée"),
              " dans les résidus."
            ),
            
            tags$li(
              tags$b("Ce qu’on vérifie — indépendance"),
              " : absence d’autocorrélation résiduelle (ACF des résidus ≈ 0), ",
              "confirmée par des tests globaux comme ",
              tags$b("Ljung–Box"),
              "."
            ),
            
            tags$li(
              tags$b("Ce qu’on vérifie — centrage"),
              " : moyenne des résidus proche de 0, indiquant l’absence de biais systématique."
            ),
            
            tags$li(
              tags$b("Ce qu’on vérifie — variance"),
              " : variance approximativement constante dans le temps ",
              "(pas d’hétéroscédasticité marquée)."
            ),
            
            tags$li(
              tags$b("Ce qu’on vérifie — distribution"),
              " : distribution des résidus approximativement normale ",
              "(utile surtout pour les intervalles de confiance et les tests)."
            ),
            
            tags$li(
              tags$b("Pourquoi c’est indispensable"),
              " : un modèle peut avoir un bon ",
              tags$b("AIC/BIC"),
              " ou une bonne performance apparente, ",
              tags$b("tout en étant mal spécifié"),
              " si les résidus montrent encore de la dépendance."
            ),
            
            tags$li(
              tags$b("Lien avec la prévision"),
              " : si les résidus ne sont pas du bruit blanc, ",
              tags$b("il reste de l’information prédictible"),
              " → les prévisions sont sous-optimales."
            ),
            
            tags$li(
              tags$b("Lien avec la validation"),
              " : les diagnostics résiduels constituent un ",
              tags$b("critère de validation interne"),
              " complémentaire à la performance hors-échantillon."
            ),
            
            tags$li(
              tags$b("Conclusion attendue"),
              " : un modèle n’est jugé ",
              tags$b("acceptable"),
              " que si ses résidus sont compatibles avec un bruit blanc ",
              "et que les éventuelles violations sont faibles et discutées."
            )
          )
        ),
        
        UL(
          tags$li(B("Résidus"), " : ", C("e_t = y_t - ŷ_t"),
                  " (ou résidus d’innovation selon l’implémentation)."),
          tags$li(B("Bruit blanc"), " : absence d’autocorrélation résiduelle → le modèle a capturé la structure temporelle."),
          tags$li(B("Ljung–Box"), " : test global d’autocorrélation des résidus jusqu’à un lag L.")
        ),
        
        
        
        
        # H5("Test de Ljung–Box (définition + interprétation)"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test de Ljung–Box — définition & interprétation")),
          
          tags$ul(
            
            tags$li(
              tags$b("Définition"),
              " : le test de Ljung–Box est un test global d’",
              tags$b("autocorrélation"),
              " qui permet de vérifier si une série (en pratique : les ",
              tags$b("résidus d’un modèle"),
              ") est compatible avec un ",
              tags$b("bruit blanc"),
              "."
            ),
            
            tags$li(
              tags$b("But"),
              " : tester simultanément l’absence d’autocorrélation ",
              "aux ",
              tags$b("premiers retards"),
              " (lags), plutôt que lag par lag."
            ),
            
            tags$li(
              tags$b("Quand l’utiliser"),
              " : après l’estimation d’un modèle ARIMA/SARIMA, ",
              "comme ",
              tags$b("diagnostic résiduel principal"),
              ", pour vérifier que toute la dépendance temporelle ",
              "a bien été capturée."
            ),
            
            tags$li(
              tags$b("Hypothèses"),
              " : ",
              tags$b("H0"),
              " = absence d’autocorrélation jusqu’au lag considéré ",
              "(résidus ~ bruit blanc) ; ",
              tags$b("Ha"),
              " = présence d’au moins une autocorrélation non nulle."
            ),
            
            tags$li(
              tags$b("Statistique / idée"),
              " : la statistique de Ljung–Box agrège les ",
              tags$b("autocorrélations empiriques"),
              " des résidus jusqu’au lag ",
              tags$code("h"),
              ", avec une correction de taille d’échantillon ",
              "(plus fiable que le test de Box–Pierce)."
            ),
            
            tags$li(
              tags$b("Choix du lag"),
              " : souvent ",
              tags$code("h = 12"),
              " ou ",
              tags$code("h = 24"),
              " pour des données mensuelles ; ",
              "le lag doit être ",
              tags$b("supérieur"),
              " à ",
              tags$code("p + q + P + Q"),
              "."
            ),
            
            tags$li(
              tags$b("Règle de décision"),
              " : ",
              tags$b("p-value grande"),
              " (ex. > 0.05) → on ",
              tags$b("ne rejette pas H0"),
              " → résidus compatibles avec un bruit blanc ; ",
              tags$b("p-value petite"),
              " → autocorrélation résiduelle → modèle insuffisant."
            ),
            
            tags$li(
              tags$b("Interprétation (sens)"),
              " : ",
              tags$b("rejeter H0"),
              " signifie qu’il reste de la ",
              tags$b("structure temporelle non expliquée"),
              " → le modèle peut être amélioré (ajout de termes AR/MA, ",
              "différenciation, transformation)."
            ),
            
            tags$li(
              tags$b("Ce que ça implique pour vos choix"),
              " : si le test échoue, revoir ",
              tags$code("p, q, P, Q"),
              ", la différenciation, ou la transformation ; ",
              "si le test est satisfaisant, le modèle passe ",
              "un ",
              tags$b("critère clé de validation interne"),
              "."
            ),
            
            tags$li(
              tags$b("Comment le rapporter"),
              " : indiquer le lag utilisé, la statistique de Ljung–Box ",
              "et la p-value, en précisant qu’il s’agit d’un test ",
              "sur les résidus."
            ),
            
            tags$li(
              tags$b("Comment le rapporter en format APA"),
              " : ",
              tags$i("« Un test de Ljung–Box appliqué aux résidus du modèle "),
              tags$i("n’a pas mis en évidence d’autocorrélation résiduelle significative "),
              tags$i("(Q(12) = 9.84, p = .63), suggérant des résidus compatibles "),
              tags$i("avec un bruit blanc. »"),
              " (adapter le lag et les valeurs)."
            ),
            
            tags$li(
              tags$b("Limites / pièges"),
              " : sensible au choix du lag ; ",
              "sur-rejet possible sur grands échantillons ; ",
              "ne garantit pas la ",
              tags$b("normalité"),
              " des résidus ; ",
              "doit toujours être interprété conjointement avec ",
              "l’ACF des résidus et les graphiques."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("But"), " : tester si les autocorrélations résiduelles jusqu’à L sont globalement nulles."),
          tags$li(B("Hypothèses"), " : ", B("H0"), " = pas d’autocorrélation résiduelle ; ", B("Ha"), " = autocorrélation résiduelle présente."),
          tags$li(B("Conclusion"), " : p petit → rejet H0 → modèle incomplet (ajuster p/q/P/Q ou d/D)."),
          tags$li(B("Signification pratique"), " : si autocorrélation résiduelle reste, vos intervalles/prévisions sont souvent trop optimistes.")
        ),
        
        
        
        # H5("Normalité & hétéroscédasticité (à quoi ça sert vraiment)"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Normalité & hétéroscédasticité — à quoi ça sert vraiment")),
          
          tags$ul(
            
            tags$li(
              tags$b("Idée générale"),
              " : la normalité et l’hétéroscédasticité concernent la ",
              tags$b("distribution"),
              " des résidus, ",
              tags$b("pas leur dépendance temporelle"),
              ". Elles sont secondaires par rapport à l’absence d’autocorrélation."
            ),
            
            tags$li(
              tags$b("Normalité — définition"),
              " : les résidus sont dits normaux s’ils suivent approximativement ",
              "une loi normale centrée, ce qui est une hypothèse classique des modèles ARIMA."
            ),
            
            tags$li(
              tags$b("À quoi sert la normalité"),
              " : principalement à garantir la validité des ",
              tags$b("tests statistiques"),
              " (z, t) et des ",
              tags$b("intervalles de confiance"),
              " des paramètres et des prévisions."
            ),
            
            tags$li(
              tags$b("Ce qui est vraiment important"),
              " : pour la ",
              tags$b("prévision"),
              ", une légère non-normalité est généralement ",
              tags$b("peu problématique"),
              ", surtout sur grands échantillons."
            ),
            
            tags$li(
              tags$b("Quand la normalité devient critique"),
              " : petits échantillons, ",
              "présence d’outliers sévères, ",
              "ou lorsque l’on interprète finement les ",
              tags$b("p-values"),
              " et les intervalles."
            ),
            
            tags$li(
              tags$b("Comment l’évaluer"),
              " : histogramme des résidus, ",
              tags$b("QQ-plot"),
              ", tests formels (Shapiro–Wilk), ",
              "à interpréter avec prudence."
            ),
            
            tags$li(
              tags$b("Hétéroscédasticité — définition"),
              " : la variance des résidus ",
              tags$b("n’est pas constante"),
              " dans le temps (volatilité variable)."
            ),
            
            tags$li(
              tags$b("À quoi sert la variance constante"),
              " : elle garantit des ",
              tags$b("incertitudes de prévision bien calibrées"),
              " et des écarts-types de paramètres interprétables."
            ),
            
            tags$li(
              tags$b("Quand l’hétéroscédasticité est problématique"),
              " : en présence de ",
              tags$b("volatilité persistante"),
              " (effets ARCH/GARCH), ",
              "ou si les intervalles de prévision semblent irréalistes."
            ),
            
            tags$li(
              tags$b("Comment l’évaluer"),
              " : graphique des résidus vs temps ou vs valeurs ajustées, ",
              "tests ARCH, inspection visuelle avant tout."
            ),
            
            tags$li(
              tags$b("Ce que ça implique pour vos choix"),
              " : non-normalité ou hétéroscédasticité modérée → ",
              tags$b("acceptable"),
              " ; violations sévères → envisager ",
              "transformation (log, Box–Cox), ",
              "modèles à variance conditionnelle, ",
              "ou discussion explicite des limites."
            ),
            
            tags$li(
              tags$b("Erreur fréquente"),
              " : rejeter un bon modèle ",
              tags$b("uniquement"),
              " parce que la normalité n’est pas parfaite, ",
              "alors que les résidus sont non autocorrélés."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : en séries temporelles, ",
              tags$b("l’indépendance des résidus est prioritaire"),
              "; la normalité et la variance constante servent surtout ",
              "à ",
              tags$b("qualifier l’incertitude"),
              " et à affiner l’interprétation."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Normalité"), " : utile pour l’interprétation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
          tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimés ; si fort, envisager modèles de variance (GARCH) selon le cours.")
        ),
        
        
        
        # H5("Évaluation prévision (définition + protocole)"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Évaluation prévisionnelle — définition & protocole")),
          
          tags$ul(
            
            tags$li(
              tags$b("Définition"),
              " : l’évaluation prévisionnelle consiste à mesurer la ",
              tags$b("qualité des prévisions"),
              " d’un modèle sur des ",
              tags$b("données futures non utilisées"),
              " lors de l’estimation."
            ),
            
            tags$li(
              tags$b("But"),
              " : vérifier la ",
              tags$b("capacité réelle de généralisation"),
              " du modèle, c’est-à-dire sa performance ",
              tags$b("hors-échantillon"),
              ", et éviter le sur-ajustement."
            ),
            
            tags$li(
              tags$b("Principe fondamental"),
              " : en séries temporelles, ",
              tags$b("le futur ne doit jamais être utilisé pour prédire le passé"),
              " → toute évaluation doit respecter l’ordre temporel."
            ),
            
            tags$li(
              tags$b("Split temporel (train / test)"),
              " : on sépare la série en une partie ",
              tags$b("train"),
              " (passé) et une partie ",
              tags$b("test"),
              " (futur). ",
              "Le modèle est estimé sur train et évalué sur test."
            ),
            
            tags$li(
              tags$b("Quand utiliser le split simple"),
              " : séries longues et stables, ",
              "objectif principal = ",
              tags$b("prévision opérationnelle"),
              ", protocole simple et lisible."
            ),
            
            tags$li(
              tags$b("Rolling-origin (validation temporelle)"),
              " : on répète des prévisions à partir de ",
              tags$b("plusieurs origines"),
              " temporelles successives, ",
              "en avançant la fenêtre d’entraînement."
            ),
            
            tags$li(
              tags$b("Intérêt du rolling-origin"),
              " : fournit une estimation ",
              tags$b("plus robuste"),
              " de la performance moyenne et de sa variabilité, ",
              "surtout lorsque la série évolue dans le temps."
            ),
            
            tags$li(
              tags$b("Fenêtres d’entraînement"),
              " : ",
              tags$b("expansive"),
              " (on ajoute les nouvelles observations au train) ou ",
              tags$b("glissante"),
              " (taille fixe) ; le choix doit être ",
              tags$b("documenté"),
              "."
            ),
            
            tags$li(
              tags$b("Benchmark (modèle de référence)"),
              " : modèle simple servant de ",
              tags$b("point de comparaison"),
              " (naïf, drift, SNAIVE). ",
              "Un modèle complexe n’a de valeur que s’il ",
              tags$b("bat le benchmark"),
              "."
            ),
            
            tags$li(
              tags$b("Pourquoi le benchmark est indispensable"),
              " : sans référence, une erreur faible ",
              tags$b("n’a pas de sens"),
              ". Le benchmark fixe le ",
              tags$b("niveau minimal acceptable"),
              " de performance."
            ),
            
            tags$li(
              tags$b("Lien avec les métriques"),
              " : la performance est évaluée à l’aide de métriques ",
              "(MAE, RMSE, etc.) calculées ",
              tags$b("uniquement sur les prévisions hors-échantillon"),
              "."
            ),
            
            tags$li(
              tags$b("Ce que ça implique pour vos choix"),
              " : privilégier le modèle ",
              tags$b("le plus simple"),
              " qui bat le benchmark, ",
              "avec une performance stable sur plusieurs origines."
            ),
            
            tags$li(
              tags$b("Erreur fréquente"),
              " : choisir un modèle uniquement sur ",
              tags$b("AIC/BIC"),
              " ou sur l’ajustement in-sample, ",
              "sans évaluation prévisionnelle."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : un bon modèle de prévision est celui qui ",
              tags$b("prédit mieux que le naïf"),
              ", de façon stable, ",
              "en respectant strictement la chronologie."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Split temporel"), " : entraîner sur le passé, tester sur le futur."),
          tags$li(B("Rolling-origin"), " : répéter sur plusieurs origines → estimation plus robuste."),
          tags$li(B("Benchmark"), " : naїf / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE à l’horizon cible.")
        ),
        
        
        
        # === ADD: diagnostics additionnels & comparaison ===
        
        
        # H5("Diagnostics additionnels"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Diagnostics additionnels — quand et pourquoi les utiliser")),
          
          tags$ul(
            
            tags$li(
              tags$b("Box–Pierce vs Ljung–Box"),
              " : deux tests globaux d’autocorrélation. ",
              tags$b("Ljung–Box"),
              " est une version corrigée pour petits échantillons ",
              "et doit être ",
              tags$b("préférée en pratique"),
              ". Box–Pierce est aujourd’hui surtout historique."
            ),
            
            tags$li(
              tags$b("Normalité résiduelle — QQ-plot"),
              " : le ",
              tags$b("Q–Q plot"),
              " compare la distribution empirique des résidus ",
              "à une loi normale. ",
              "Déviations dans les queues → outliers ou asymétrie."
            ),
            
            tags$li(
              tags$b("Normalité résiduelle — tests formels"),
              " : tests comme ",
              tags$b("Jarque–Bera"),
              " ou Shapiro–Wilk peuvent être utilisés, ",
              "mais ils sont ",
              tags$b("très sensibles"),
              " sur grands échantillons."
            ),
            
            tags$li(
              tags$b("À quoi sert vraiment la normalité"),
              " : utile surtout pour la ",
              tags$b("validité des intervalles de confiance"),
              " et des tests sur les paramètres ; ",
              tags$b("secondaire"),
              " si l’objectif principal est la ",
              tags$b("prévision ponctuelle"),
              "."
            ),
            
            tags$li(
              tags$b("Hétéroscédasticité / effets ARCH"),
              " : variance résiduelle non constante dans le temps, ",
              "souvent visible par des ",
              tags$b("paquets de volatilité"),
              "."
            ),
            
            tags$li(
              tags$b("Comment détecter les effets ARCH"),
              " : examiner l’",
              tags$b("ACF des résidus au carré"),
              " et utiliser des tests ARCH. ",
              "Autocorrélation significative → variance conditionnelle."
            ),
            
            tags$li(
              tags$b("Que faire si effets ARCH forts"),
              " : discuter des limites du modèle ARIMA, ",
              "envisager une ",
              tags$b("transformation"),
              " ou des modèles à ",
              tags$b("variance conditionnelle"),
              " (ex. GARCH), ou limiter l’analyse à la moyenne."
            ),
            
            tags$li(
              tags$b("Significativité des coefficients"),
              " : rapporter systématiquement ",
              tags$b("estimations"),
              ", ",
              tags$b("écarts-types"),
              ", ",
              tags$b("statistiques z"),
              " et ",
              tags$b("p-values"),
              "."
            ),
            
            tags$li(
              tags$b("Interprétation de la non-significativité"),
              " : un coefficient non significatif ",
              tags$b("n’invalide pas automatiquement"),
              " le modèle si la performance prédictive est bonne."
            ),
            
            tags$li(
              tags$b("Principe de parcimonie"),
              " : si plusieurs coefficients sont non significatifs ",
              "et que leur suppression ",
              tags$b("ne dégrade pas la performance"),
              ", préférer le modèle ",
              tags$b("plus simple"),
              "."
            ),
            
            tags$li(
              tags$b("Erreur fréquente"),
              " : éliminer des termes uniquement sur la base des p-values ",
              "sans vérifier l’impact sur les ",
              tags$b("diagnostics résiduels"),
              " et la ",
              tags$b("performance hors-échantillon"),
              "."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : ces diagnostics sont ",
              tags$b("complémentaires"),
              ". Ils affinent l’interprétation et la discussion, ",
              "mais ne doivent jamais primer sur ",
              tags$b("l’absence d’autocorrélation résiduelle"),
              " et la ",
              tags$b("performance prévisionnelle"),
              "."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Box–Pierce vs Ljung–Box"), " : préférer Ljung–Box (meilleure petite taille)."),
          tags$li(B("Normalité résiduelle"), " : Q–Q plot, Jarque–Bera ; utile pour IC mais secondaire si but = point forecast."),
          tags$li(B("Hétéroscédasticité / ARCH"), " : tester ACF des résidus au carré ; si fort → discuter modèles de variance (annexe)."),
          tags$li(B("Significativité des coefficients"), " : rapporter est., SE, z, p ; supprimer termes non significatifs si performance constante.")
        ),
        
        
        
        # H5("Comparaison de modèles"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Comparaison de modèles — principes, outils et décision")),
          
          tags$ul(
            
            tags$li(
              tags$b("Objectif"),
              " : comparer plusieurs modèles candidats afin de retenir celui qui est ",
              tags$b("le plus pertinent"),
              " selon des critères à la fois ",
              tags$b("statistiques"),
              " et ",
              tags$b("prédictifs"),
              "."
            ),
            
            tags$li(
              tags$b("Principe général"),
              " : la comparaison doit être ",
              tags$b("multicritère"),
              " : aucun indicateur (AIC, RMSE, p-value) n’est suffisant pris isolément."
            ),
            
            tags$li(
              tags$b("Tableau récapitulatif — rôle"),
              " : synthétiser les informations clés de chaque modèle dans un ",
              tags$b("format lisible"),
              " pour faciliter une décision argumentée."
            ),
            
            tags$li(
              tags$b("Critères d’information (AICc / BIC)"),
              " : mesurent le compromis ajustement / complexité ; ",
              tags$b("AICc"),
              " préférable en petits échantillons, ",
              tags$b("BIC"),
              " plus sévère et orienté parcimonie."
            ),
            
            tags$li(
              tags$b("Diagnostics résiduels — Ljung–Box"),
              " : vérifier l’absence d’autocorrélation résiduelle ; ",
              "un modèle qui échoue au Ljung–Box ",
              tags$b("ne doit pas être retenu"),
              ", même s’il a un bon AIC."
            ),
            
            tags$li(
              tags$b("Performance prévisionnelle"),
              " : comparer ",
              tags$b("MAE / RMSE / MASE"),
              " calculées hors-échantillon ; ",
              "elles mesurent directement la ",
              tags$b("qualité des prévisions"),
              "."
            ),
            
            tags$li(
              tags$b("Nombre de paramètres"),
              " : indicateur de ",
              tags$b("complexité"),
              " ; à performance comparable, ",
              tags$b("préférer le modèle le plus simple"),
              "."
            ),
            
            tags$li(
              tags$b("Logique de décision recommandée"),
              " : éliminer d’abord les modèles ",
              tags$b("mal diagnostiqués"),
              ", puis comparer la performance prévisionnelle, ",
              "et enfin arbitrer par la parcimonie."
            ),
            
            tags$li(
              tags$b("Test de Diebold–Mariano (annexe)"),
              " : test statistique permettant de comparer ",
              tags$b("formellement"),
              " deux séries d’erreurs de prévision issues de ",
              tags$b("deux modèles concurrents"),
              "."
            ),
            
            tags$li(
              tags$b("Hypothèses du test DM"),
              " : ",
              tags$b("H0"),
              " = performances prédictives équivalentes ; ",
              tags$b("Ha"),
              " = différence significative de performance."
            ),
            
            tags$li(
              tags$b("Quand utiliser le test DM"),
              " : lorsque deux modèles ont des performances proches ",
              "et que l’on souhaite une ",
              tags$b("validation statistique"),
              " de la différence observée."
            ),
            
            tags$li(
              tags$b("Interprétation du test DM"),
              " : p-value petite → différence significative ; ",
              "p-value grande → performances statistiquement comparables."
            ),
            
            tags$li(
              tags$b("Limites du test DM"),
              " : dépend du choix de la fonction de perte ; ",
              "sensible à l’horizon et à l’autocorrélation des erreurs ; ",
              tags$b("ne remplace pas"),
              " l’analyse globale."
            ),
            
            tags$li(
              tags$b("Erreur fréquente"),
              " : choisir un modèle uniquement parce qu’il a ",
              tags$b("le plus petit AIC"),
              " ou la ",
              tags$b("plus petite RMSE"),
              ", sans vérifier diagnostics et stabilité."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : retenir le modèle qui ",
              tags$b("passe les diagnostics"),
              ", ",
              tags$b("bat le benchmark"),
              ", et offre le ",
              tags$b("meilleur compromis"),
              " entre performance, robustesse et simplicité."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Tableau récapitulatif"), " : AICc/BIC, Ljung–Box (p), MAE/RMSE/MASE, nb de paramètres."),
          tags$li(B("Test de Diebold–Mariano"), " : (annexe) comparer formellement 2 séries d’erreurs prédictives.")
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Arbre décisionnel complet — diagnostics → actions (Steps)")),
          
          tags$ol(
            
            tags$li(
              tags$b("Étape 1 — Autocorrélation résiduelle (prioritaire)"),
              " : examiner l’ACF des résidus et le test de ",
              tags$b("Ljung–Box"),
              "."
            ),
            
            tags$li(
              tags$b("Si autocorrélation significative"),
              " : le modèle est ",
              tags$b("insuffisant"),
              " → ",
              "ajuster ",
              tags$code("p, q, P, Q"),
              ", revoir la différenciation ",
              tags$code("d / D"),
              ", ou la transformation. ",
              tags$b("Ne pas passer aux étapes suivantes"),
              " tant que ce point n’est pas résolu."
            ),
            
            tags$li(
              tags$b("Si pas d’autocorrélation résiduelle"),
              " : les résidus sont compatibles avec un ",
              tags$b("bruit blanc"),
              " → passer à l’étape suivante."
            ),
            
            tags$li(
              tags$b("Étape 2 — Performance prévisionnelle"),
              " : évaluer les erreurs ",
              tags$b("hors-échantillon"),
              " (split temporel ou rolling-origin) ",
              "et comparer au ",
              tags$b("benchmark"),
              "."
            ),
            
            tags$li(
              tags$b("Si le modèle ne bat pas le benchmark"),
              " : complexité ",
              tags$b("injustifiée"),
              " → simplifier le modèle, ",
              "ou préférer le benchmark."
            ),
            
            tags$li(
              tags$b("Si le modèle bat le benchmark"),
              " : performance prédictive acceptable → continuer."
            ),
            
            tags$li(
              tags$b("Étape 3 — Stabilité de la performance"),
              " : vérifier la ",
              tags$b("robustesse"),
              " des métriques sur plusieurs origines ",
              "(rolling-origin)."
            ),
            
            tags$li(
              tags$b("Si performance instable"),
              " : modèle trop sensible → ",
              "simplifier, réduire le nombre de paramètres, ",
              "ou revoir la fenêtre d’entraînement."
            ),
            
            tags$li(
              tags$b("Étape 4 — Normalité des résidus (secondaire)"),
              " : examiner histogramme et ",
              tags$b("Q–Q plot"),
              "."
            ),
            
            tags$li(
              tags$b("Si non-normalité modérée"),
              " : généralement ",
              tags$b("acceptable"),
              " si l’objectif est la ",
              tags$b("prévision ponctuelle"),
              ". Mentionner la limitation."
            ),
            
            tags$li(
              tags$b("Si non-normalité sévère"),
              " : envisager transformation (log, Box–Cox), ",
              "ou discuter l’impact sur les intervalles de confiance."
            ),
            
            tags$li(
              tags$b("Étape 5 — Hétéroscédasticité / effets ARCH"),
              " : examiner la variance des résidus dans le temps ",
              "et l’ACF des résidus au carré."
            ),
            
            tags$li(
              tags$b("Si effets ARCH faibles"),
              " : généralement ",
              tags$b("tolérables"),
              " pour la moyenne conditionnelle."
            ),
            
            tags$li(
              tags$b("Si effets ARCH forts"),
              " : discuter l’usage de modèles à ",
              tags$b("variance conditionnelle"),
              " (ex. GARCH) ",
              "ou limiter l’analyse aux prévisions de moyenne."
            ),
            
            tags$li(
              tags$b("Étape 6 — Significativité des coefficients"),
              " : examiner estimations, ",
              tags$b("SE"),
              ", ",
              tags$b("z"),
              " et ",
              tags$b("p-values"),
              "."
            ),
            
            tags$li(
              tags$b("Si coefficients non significatifs"),
              " : tester leur suppression ",
              tags$b("si et seulement si"),
              " la performance et les diagnostics ",
              tags$b("restent inchangés"),
              "."
            ),
            
            tags$li(
              tags$b("Étape 7 — Parcimonie et comparaison finale"),
              " : comparer les modèles candidats via ",
              tags$b("AICc/BIC"),
              ", performance prévisionnelle et simplicité."
            ),
            
            tags$li(
              tags$b("Décision finale"),
              " : retenir le modèle qui ",
              tags$b("passe tous les diagnostics bloquants"),
              ", ",
              tags$b("bat le benchmark"),
              ", et offre le ",
              tags$b("meilleur compromis"),
              " entre performance, stabilité et interprétabilité."
            ),
            
            tags$li(
              tags$b("Principe clé à retenir"),
              " : les diagnostics guident des ",
              tags$b("actions concrètes"),
              ", pas des décisions automatiques. ",
              "La justification doit toujours être ",
              tags$b("argumentée"),
              "."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Arbre décisionnel complet — diagnostics → actions (Graph)")),
          tags$div(
            style = "padding:10px 12px; background:#fff;",
            DiagrammeR::grVizOutput("diag_tree", height = "1500px")
          )
        ),
        
      ),
      
      apa_ui = tagList(
        H5("Résultats (APA) — diagnostics"),
        P("« Les diagnostics résiduels indiquaient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics substantiels et le test de Ljung–Box était [non significatif/significatif] au seuil α=[..]. ",
          "La performance de prévision sur la fenêtre d’évaluation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. »"),
        
        H5("Conclusion & signification (diagnostics + performance)"),
        UL(
          tags$li(B("Conclusion : "), "« Le modèle est acceptable » si Ljung–Box non significatif ET benchmark battu."),
          tags$li(B("Signification : "),
                  "« le modèle capte la structure temporelle (résidus ~ bruit) et apporte un gain prédictif réel (out-of-sample). »")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Bon AIC mais Ljung–Box significatif"), " : modèle incomplet → ne pas valider."),
          tags$li(B("Se focaliser sur la normalité"), " : priorité = absence d’autocorrélation résiduelle."),
          tags$li(B("Comparer des modèles sur des horizons différents"), " : toujours même h, même protocole.")
        )
      )
    )
    
    # (9) Étape 8 — Rédaction
    pages[[10]] <- make_step(
      step_names[10],
      
      actions_ui = tagList(
        callout(B("But : "), "écrire un rapport clair, reproductible, aligné aux étapes 0–7.", type="info"),
        
        Checklist(
          CheckItem("Rediger une section Methodes qui suit exactement le pipeline: donnees -> EDA -> stationnarite -> selection -> diagnostics -> prevision."),
          CheckItem("Inclure figures indispensables: serie, decomposition, ACF/PACF, residus, previsions + intervalles."),
          CheckItem("Inclure un tableau de comparaison (AICc/BIC, Ljung-Box, MAE/RMSE, benchmark, nb parametres)."),
          CheckItem("Preciser l’echelle (niveau/log/Box-Cox) et expliquer toute reconversion des previsions."),
          CheckItem("Ajouter un encadre limites + pistes (ruptures, SARIMAX, GARCH) et assurer la reproductibilite (versions).")
        ),
        
        Deliverables(
          tags$li("Une section Méthodes (données, split, transformations, tests, choix d’ordres) rédigée proprement."),
          tags$li("Une section Résultats (modèle final, coefficients, diagnostics, performance, figures) + discussion/limites."),
          tags$li("Un paquet de livrables : figures légendées, tableau des paramètres, équations, et un appendice “reproductibilité”.")
        ),
        
        
        H5("Structure APA recommandée (définition)"),
        UL(
          tags$li(B("Méthodes"), " : ce que vous avez fait et pourquoi (données → EDA → stationnarité → modèles → évaluation)."),
          tags$li(B("Résultats"), " : ce que vous avez observé (stats, figures, tests, métriques, modèle final)."),
          tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
        ),
        
        H5("Pack livrable propre (checklist)"),
        UL(
          tags$li("Notebook/script reproductible (import → nettoyage → EDA → tests → modèles → diagnostics → prévisions)."),
          tags$li("Figures : série, décomposition, ACF/PACF, résidus (ACF + Ljung–Box), prévisions + IC."),
          tags$li("Tableau : candidats vs AICc/BIC vs Ljung–Box vs MAE/RMSE vs benchmark.")
        ),
        
        # === ADD: rapporter correctement les prévisions ===
        H5("Rapporter correctement les prévisions"),
        UL(
          tags$li(B("Niveau de couverture"), " : préciser 80% et/ou 95% ; indiquer si log-échelle a été reconvertie."),
          tags$li(B("Biais de reconversion (log→niveau)"), " : mentionner correction ",
                  C("exp(\\hat{y}) \\times exp(\\hat{\\sigma}^2/2)"), " si utilisée."),
          tags$li(B("Reproductibilité"), " : versions R/packages, seed, chemin des données, date d’extraction.")
        )
      ),
      
      apa_ui = tagList(
        H5("Phrase finale (APA) — modèle final + interprétation"),
        P("« Sur la base de l’adéquation diagnostique et de la performance prédictive, le modèle final retenu était SARIMA((p,d,q)(P,D,Q)_s). ",
          "Les résidus étant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a été capturée. ",
          "Les prévisions produites à horizon h=[..] améliorent le benchmark [..] selon MAE/RMSE, ce qui soutient l’usage du modèle pour l’application ciblée. »"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "« Le rapport est aligné, justifié, reproductible. »"),
          tags$li(B("Signification : "),
                  "« un lecteur externe peut reproduire vos résultats et comprendre chaque choix (transformation, d/D, sélection, diagnostics). »")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Ne pas relier choix → preuves"), " : chaque décision doit être liée à EDA/tests/diagnostics."),
          tags$li(B("Trop de texte, pas assez de figures"), " : en séries temporelles, les figures sont des résultats."),
          tags$li(B("Oublier de préciser l’échelle"), " : niveau vs log vs Box–Cox et reconversion des prévisions.")
        )
      )
    )
    
    # (10) Annexes
    pages[[11]] <- make_step(
      step_names[11],
      
      actions_ui = tagList(
        Checklist(
          CheckItem("Reconnaitre et pouvoir ecrire les trois benchmarks (naif, drift, SNAIVE) et expliquer quand chacun est approprie."),
          CheckItem("Savoir lire rapidement un resultat ADF/KPSS/PP et traduire la conclusion en choix de d et D."),
          CheckItem("Savoir expliquer ce que signifie Ljung-Box significatif (structure residuelle) et quelle action entreprendre."),
          CheckItem("Memoriser les formules utiles (AIC/AICc/BIC, Ljung-Box, operateurs de differenciation) et leur interpretation."),
          CheckItem("Identifier quand il faut sortir du cadre SARIMA (exogenes, multiples saisonnalites, ruptures, variance conditionnelle).")
        ),
        
        Deliverables(
          tags$li("Des gabarits prêts à copier : phrases APA, tableaux de résultats, checklists, et rappels de formules."),
          tags$li("Une mini “boîte à outils” : lecture rapide ACF/PACF, décisions d/D, et actions si diagnostics échouent."),
          tags$li("Une liste de signaux “SARIMA insuffisant” + pistes alternatives (SARIMAX, ETS/TBATS, modèles à hétéroscédasticité, etc.).")
        ),
        
        
        H5("Benchmarks (définitions)"),
        UL(
          tags$li(B("Naïf"), " : ", C("ŷ_{t+1|t} = y_t"), " (persistance)."),
          tags$li(B("Drift"), " : extrapolation linéaire moyenne."),
          tags$li(B("SNAIVE"), " : répète la dernière valeur de la même saison : ", C("ŷ_{t+h|t} = y_{t+h-s}"), ".")
        ),
        
        H5("Règles d’interprétation ultra rapides"),
        UL(
          tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " → stationnarité plausible."),
          tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " → différenciation nécessaire."),
          tags$li(B("Ljung–Box significatif"), " → il reste de la structure → réviser le modèle.")
        ),
        
        # === ADD: formules utiles & pistes avancées ===
        H5("Formules utiles (mémo)"),
        UL(
          tags$li(B("Critères d’info"), " : ",
                  C("AIC=-2\\log L+2k"), ", ",
                  C("AICc= AIC + \\frac{2k(k+1)}{n-k-1}"), ", ",
                  C("BIC=-2\\log L+k\\log n"), "."),
          tags$li(B("MASE"), " : ", C("\\frac{\\frac{1}{T}\\sum_{t}|e_t|}{\\frac{1}{T-s}\\sum_{t}|y_t-y_{t-s}|}"), " (pour périodicité ", C("s"), ")."),
          tags$li(B("Ljung–Box"), " : ", C("Q^* = n(n+2)\\sum_{k=1}^{L} \\frac{\\hat{\\rho}_k^2}{n-k}"),
                  " ~ ", C("\\chi^2"), " sous ", C("H_0"), " avec ddl ≈ ", C("L - p - q - (P+Q)"), "."),
          tags$li(B("Backshift & diff."), " : ",
                  C("\\nabla=(1-B)"), ", ", C("\\nabla_s=(1-B^s)"), ", ",
                  C("\\nabla^d \\nabla_s^D y_t"), " pour stationnariser.")
        ),
        
        H5("Équation SARIMA en opérateurs (forme compacte)"),
        P("Cette écriture est utile parce qu’elle montre clairement : (i) comment la différenciation rend la série stationnaire, et (ii) comment les polynômes AR/MA décrivent la dépendance restante."),
        UL(
          tags$li("Forme générale : ",
                  C("\\Phi(B^s)\\,\\phi(B)\\,(1-B)^d(1-B^s)^D\\,y_t = \\Theta(B^s)\\,\\theta(B)\\,\\varepsilon_t")),
          tags$li(B("Polynômes non saisonniers"), " : ",
                  C("\\phi(B)=1-\\phi_1B-\\cdots-\\phi_pB^p"), " et ",
                  C("\\theta(B)=1+\\theta_1B+\\cdots+\\theta_qB^q"), "."),
          tags$li(B("Polynômes saisonniers"), " : ",
                  C("\\Phi(B^s)=1-\\Phi_1B^s-\\cdots-\\Phi_PB^{Ps}"), " et ",
                  C("\\Theta(B^s)=1+\\Theta_1B^s+\\cdots+\\Theta_QB^{Qs}"), "."),
          tags$li(B("Erreur"), " : ", C("\\varepsilon_t"), " est un bruit blanc (moyenne 0, variance constante, pas d’autocorrélation).")
        ),
        
        H5("ACF / PACF (rappel express)"),
        UL(
          tags$li(B("ACF"), " : corrélation entre ", C("y_t"), " et ", C("y_{t-k}"), " (au lag ", C("k"), "). Elle aide à détecter une structure MA et la présence de saisonnalité (pics aux multiples de ", C("s"), ")."),
          tags$li(B("PACF"), " : corrélation “pure” entre ", C("y_t"), " et ", C("y_{t-k}"), " après avoir contrôlé les lags intermédiaires. Elle aide à détecter une structure AR."),
          tags$li(B("Avertissement"), " : lire ACF/PACF sur une série non stationnaire conduit souvent à des ordres trop grands ; faites la différenciation avant d’interpréter les coupures.")
        ),
        
        H5("Pistes avancées (pour l’enseignant)"),
        UL(
          tags$li(B("SARIMAX / régression dynamique"), " : variables exogènes, pré-blanchiment, fonctions de transfert."),
          tags$li(B("Ruptures/Interventions"), " : dummies LS/TC, estimation avec régresseurs."),
          tags$li(B("Multiples saisonnalités"), " : TBATS/ETS-MS si présence de s multiples.")
        )
      ),
      
      apa_ui = tagList(
        H5("Template “Conclusion tests → choix (d,D)” (copier-coller)"),
        P("« Les tests ADF/PP et KPSS ont été interprétés conjointement. ",
          "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnarité, ",
          "nous concluons que la série est [stationnaire/non-stationnaire] au sens des diagnostics combinés. ",
          "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une série stationnaire pour l’estimation SARIMA. »"),
        
        H5("Signification (traduction simple)"),
        UL(
          tags$li("« d et D disent combien de fois on doit “retirer” une tendance et une saisonnalité non stationnaire. »"),
          tags$li("« Ensuite, p/q/P/Q décrivent la dépendance restante (mémoire) dans la série transformée. »")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Croire qu’un test “décide” seul"), " : toujours trianguler avec EDA + ACF + comportement après différenciation."),
          tags$li(B("Oublier la finalité"), " : prévision (out-of-sample) + diagnostics passent avant l’esthétique d’un AIC."),
          tags$li(B("Ne pas documenter"), " : un bon modèle non documenté = inutilisable dans un cours/rapport.")
        )
      )
    )
    
    # ========= Output =========
    tagList(
      css,
      tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 — ", step_names[cur + 1L])),
      progress_ui,
      pages[[cur + 1L]]
    )
  })
  
  
  
  
  
  
  
  
  #======================================================================================================
  #======================================================================================================
  #======================================================================================================
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  # ============================================================
  # UI (add this where you want the roadmap to appear)
  # ============================================================
  # uiOutput("roadmap_Detailed_Fr_ui")
  
  
  # ============================================================
  # SERVER (FULL COPY-PASTE) — Roadmap SARIMA FR + Slider + Collapsibles
  # Put this inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui5 <- renderUI({
    
    # ----------------------------
    # Helpers: nested collapsibles
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    
    # Big blocks per step
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1")
    # Sub-blocks inside big blocks
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2")
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, example = NULL, formula = NULL, notes = NULL, open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 tags$p(tags$b("Définition : "), definition),
                 if (!is.null(purpose)) tags$p(tags$b("But / utilité : "), purpose) else NULL,
                 if (!is.null(formula)) tags$p(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example)) tags$p(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(notes))   tags$p(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name, purpose, H0, H1,
                     statistic = NULL, interpretation = NULL, conclusion = NULL, caveats = NULL, open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 tags$p(tags$b("But / utilité : "), purpose),
                 tags$p(tags$b("H0 : "), H0),
                 tags$p(tags$b("H1 : "), H1),
                 if (!is.null(statistic))      tags$p(tags$b("Statistique (idée) : "), statistic) else NULL,
                 if (!is.null(interpretation)) tags$p(tags$b("Interprétation : "), interpretation) else NULL,
                 if (!is.null(conclusion))     tags$p(tags$b("Conclusion + sens : "), conclusion) else NULL,
                 if (!is.null(caveats))        tags$p(tags$b("Pièges / limites : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .eq {font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step builder
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Préparer le terrain : définir le problème",
        "[1] Décrire les données : n, manque, descriptives",
        "[2] Explorer visuellement : tendance, saison, outliers",
        "[3] Décomposer : additif vs multiplicatif, STL",
        "[4] Stationnarité : ADF/KPSS/PP, choisir d & D",
        "[5] Modèle de référence : Auto-ARIMA (AICc)",
        "[6] Modèle guidé par théorie : ACF/PACF + candidats",
        "[7] Diagnostiquer & comparer : résidus + précision",
        "[8] Rédiger le rapport : Méthodes/Résultats + livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Données", "Évaluation"),
        c("Qualité données", "Manquants", "Stat descriptives"),
        c("Graphiques", "Saisonnalité", "Anomalies"),
        c("Tendance", "Saison", "STL"),
        c("Stationnarité", "Différenciation", "Tests"),
        c("Auto-ARIMA", "AICc/BIC", "Baseline"),
        c("ACF/PACF", "Candidats", "Parcimonie"),
        c("Diagnostics", "Ljung–Box", "Forecast accuracy"),
        c("APA", "Synthèse", "Livrables")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ------------------------------------------------------------
    # CONTENT (extremely detailed but organized via collapsibles)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # ============== STEP 0 ==============
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Avant toute SARIMA, on fige exactement : la série cible (y_t), le calendrier (fréquence régulière), l’horizon, le protocole d’évaluation et la (les) métriques. ",
                          "Sans ça, on obtient des modèles « corrects » mais inutilisables.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Checklist opérationnelle", open = TRUE,
                            tags$ul(
                              tags$li("Définir la ", tags$b("série réponse"), " : ", tags$code("y_t"), " (ce que l’on prévoit)."),
                              tags$li("Définir l’", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vérifier la ", tags$b("régularité"), " (pas de trous ni doublons)."),
                              tags$li("Définir la ", tags$b("tâche de prévision"), " : horizon ", tags$code("h"), ", protocole (train/test ou rolling-origin), métrique(s) (MAE/RMSE/MAPE/sMAPE)."),
                              tags$li("Choisir l’échelle : niveaux / log / Box–Cox (et justifier)."),
                              tags$li("Définir le benchmark : naïf (et naïf saisonnier si saison).")
                            )
                          ),
                          
                          S("Définitions (cliquables)", open = FALSE,
                            TERM(
                              "Série réponse (y_t)",
                              "Variable temporelle univariée que l’on veut expliquer et prévoir. Chaque observation correspond à un instant t.",
                              purpose="Détermine l’objet du modèle (la cible) et le type de prévision produit.",
                              formula="y_t",
                              notes="SARIMA classique est univarié (pas de prédicteurs)."
                            ),
                            TERM(
                              "Indice temporel & fréquence",
                              "L’index temporel est la séquence des dates/temps. La fréquence est l’espacement régulier (jour, semaine, mois…).",
                              purpose="SARIMA suppose des intervalles constants ; la fréquence fixe la saisonnalité (ex : s=12 en mensuel).",
                              notes="Si timestamps irréguliers → rééchantillonnage/agrégation avant SARIMA."
                            ),
                            TERM(
                              "Horizon de prévision (h)",
                              "Nombre de pas dans le futur à prédire.",
                              purpose="Détermine ce qu’on considère « bon » (court terme vs long terme).",
                              example="h=12 (12 mois d’avance) ; h=7 (7 jours).",
                              formula="h"
                            ),
                            TERM(
                              "Protocole train/test",
                              "Découpage temporel où l’on entraîne sur le passé et on évalue sur le futur (jamais l’inverse).",
                              purpose="Évaluer la généralisation sur des dates non vues.",
                              notes="On évite le mélange temporel qui créerait une fuite d’information."
                            ),
                            TERM(
                              "Rolling-origin (origine glissante)",
                              "Évaluation répétée où l’origine de prévision avance : on ré-entraîne/actualise puis on prédit.",
                              purpose="Mieux refléter une utilisation réelle (le modèle vit dans le temps).",
                              notes="Plus coûteux, plus robuste que 1 seul split."
                            ),
                            TERM(
                              "MAE",
                              "Moyenne des valeurs absolues des erreurs.",
                              purpose="Lisible, robuste aux gros outliers par rapport à RMSE.",
                              formula="MAE = mean(|y_t - ŷ_t|)"
                            ),
                            TERM(
                              "RMSE",
                              "Racine de la moyenne des erreurs quadratiques.",
                              purpose="Pénalise fortement les grandes erreurs.",
                              formula="RMSE = sqrt(mean((y_t - ŷ_t)^2))"
                            ),
                            TERM(
                              "MAPE",
                              "Erreur absolue en pourcentage moyen.",
                              purpose="Interprétation en % quand y_t est strictement positif et loin de 0.",
                              formula="MAPE = mean(|(y_t-ŷ_t)/y_t|) × 100",
                              notes="Instable si y_t ≈ 0."
                            ),
                            TERM(
                              "sMAPE",
                              "Version symétrisée du MAPE : normalise par (|y|+|ŷ|).",
                              purpose="Réduit certains problèmes du MAPE.",
                              formula="sMAPE = mean( 2|y-ŷ|/(|y|+|ŷ|) ) × 100"
                            ),
                            TERM(
                              "Transformation log",
                              "Transformer y_t en log(y_t) (si y_t>0).",
                              purpose="Stabiliser une variance qui augmente avec le niveau ; transformer multiplicatif → additif.",
                              notes="Toujours expliquer comment on revient à l’échelle originale."
                            ),
                            TERM(
                              "Box–Cox",
                              "Famille de transformations paramétrées (λ) incluant log comme cas particulier.",
                              purpose="Stabiliser variance et améliorer normalité/linéarité des résidus.",
                              formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) si λ→0"
                            ),
                            TERM(
                              "SARIMA vs SARIMAX",
                              "SARIMA : ARIMA saisonnier univarié. SARIMAX : SARIMA avec variables exogènes (X).",
                              purpose="Clarifier si on modélise uniquement y_t ou y_t avec prédicteurs.",
                              notes="Si vous avez des covariables → SARIMAX (ou autre modèle)."
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent (papier)", open = FALSE,
                          S("Template Méthodes — Données & Objectif", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Données & Objectif). "),
                              "« Nous avons modélisé la série temporelle univariée ", tags$code("y_t"),
                              " observée à une fréquence [..] de [début] à [fin] (n=[..]). ",
                              "L’objectif était de prévoir à un horizon h=[..] pas. ",
                              "La performance a été évaluée avec [MAE/RMSE/…] selon [split temporel / rolling-origin]. ",
                              "Une transformation [aucune / log / Box–Cox (λ=[..])] a été utilisée pour [raison]. »"
                            )
                          ),
                          S("Conclusion + sens (à écrire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "on fixe y_t, la fréquence, h, le protocole et les métriques."),
                              tags$li(tags$b("Sens : "), "on rend la modélisation reproductible ; toute comparaison de modèles devient valide.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("SARIMA suppose un ", tags$b("espacement régulier"), " ; timestamps irréguliers = problème de base."),
                            tags$li("Ne pas confondre une bonne courbe in-sample avec une bonne ", tags$b("performance out-of-sample"), "."),
                            tags$li("MAPE si y_t proche de 0 : souvent une mauvaise idée."),
                            tags$li("Transformer sans expliquer l’inversion (retour à l’échelle originale).")
                          )
                        )
        ))
      }
      
      # ============== STEP 1 ==============
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Un SARIMA est aussi bon que vos données : n, dates, fréquence, manque et descriptives doivent être rapportés proprement.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Checklist opérationnelle", open = TRUE,
                            tags$ol(
                              tags$li("Rapporter : n, début/fin, fréquence, % manquants."),
                              tags$li("Diagnostiquer le manque (rare/important ; aléatoire/systématique)."),
                              tags$li("Traiter : interpolation linéaire/saisonnière, ou autre méthode justifiée."),
                              tags$li("Calculer descriptives : moyenne, médiane, ET, min/max, skewness, kurtosis, résumés saisonniers.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("n (taille d’échantillon)", "Nombre d’observations disponibles.", purpose="Impact direct sur la stabilité de l’estimation et la fiabilité des tests."),
                            TERM("Valeur manquante", "Observation absente (NA) sur une date attendue.", purpose="Les NA peuvent casser l’ajustement SARIMA si non traités."),
                            TERM("Manque MCAR/MAR/MNAR",
                                 "MCAR: manque complètement aléatoire. MAR: manque dépend d’observables. MNAR: dépend de la valeur manquante elle-même.",
                                 purpose="Aide à justifier l’imputation et ses limites.",
                                 notes="En pratique en séries temporelles, le manque est souvent structurel (pannes, jours fériés, etc.)."),
                            TERM("Interpolation linéaire",
                                 "Imputation par une ligne entre points observés.",
                                 purpose="Simple, efficace si trous courts et pas de rupture.",
                                 notes="À éviter si longues périodes manquantes."),
                            TERM("Interpolation saisonnière",
                                 "Imputation en respectant la saisonnalité (ex : remplacer un mois manquant par moyenne des mêmes mois).",
                                 purpose="Mieux quand la saison est forte.",
                                 notes="Justifier la méthode ; vérifier qu’elle n’invente pas une saison artificielle."),
                            TERM("Moyenne", "Somme / n.", purpose="Centre de la distribution.", formula="mean(y)"),
                            TERM("Médiane", "Valeur centrale (50e percentile).", purpose="Centre robuste aux outliers."),
                            TERM("Écart-type (ET)", "Mesure de dispersion autour de la moyenne.", purpose="Quantifie variabilité.", formula="sd(y)"),
                            TERM("Skewness", "Asymétrie de la distribution.", purpose="Décrit si la masse est tirée vers la gauche/droite."),
                            TERM("Kurtosis", "Épaisseur des queues (tail heaviness).", purpose="Indique présence de valeurs extrêmes plus fréquentes.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent (APA)", open = FALSE,
                          S("Template Résultats — Description des données", open = TRUE,
                            tags$p(
                              tags$b("Résultats (Description des données). "),
                              "« La série contient n=[..] observations couvrant [dates] à une fréquence [..]. ",
                              "Les valeurs manquantes représentaient [..]% (k=[..]). Elles ont été traitées via [méthode] car [raison]. ",
                              "La distribution de ", tags$code("y_t"),
                              " présentait une moyenne de [..] (ET=[..]), une médiane [..], et un intervalle [min,max]. ",
                              "Descriptives saisonnières (ex : par mois) : [résumé]. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "données décrites + manque traité et justifié."),
                              tags$li(tags$b("Sens : "), "le lecteur comprend la fiabilité des estimations et la comparabilité des résultats.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer « en silence » : toujours documenter et justifier."),
                            tags$li("Confondre absence de date et NA : parfois la date n’existe pas (fréquence mal définie)."),
                            tags$li("Si log/Box–Cox : rapporter descriptives aussi sur la série transformée (au moins brièvement).")
                          )
                        )
        ))
      }
      
      # ============== STEP 2 ==============
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Les graphiques servent à détecter tendance/saison/outliers et à justifier transformations + différenciation.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Graphiques à produire", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Courbe temporelle"), " de ", tags$code("y_t"), " (et de log(y_t) si pertinent)."),
                              tags$li(tags$b("Graphique saisonnier"), " (lignes par année, couleur par mois, ou seasonal plot)."),
                              tags$li(tags$b("Boxplots par saison"), " (mois/trimestre/semaine)."),
                              tags$li(tags$b("Détection d’outliers"), " (z-score, IQR, robuste + contexte).")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("Tendance", "Évolution de long terme (hausse/baisse) distincte de la saison.", purpose="Guider d (différenciation non saisonnière)."),
                            TERM("Saisonnalité", "Motif qui se répète à période fixe s (ex : 12 mois).", purpose="Guider D (différenciation saisonnière) et P/Q.", formula="s"),
                            TERM("Outlier (valeur aberrante)", "Observation atypique par rapport au comportement habituel.", purpose="Décider : conserver/ajuster/modéliser.",
                                 notes="Un outlier peut être un événement réel (promo, crise) → souvent à conserver."),
                            TERM("Z-score", "Mesure d’écart en nombre d’ET par rapport à la moyenne.", purpose="Repérer des points très éloignés.",
                                 formula="z = (y - mean)/sd", notes="Peu robuste si distribution non gaussienne."),
                            TERM("Règle IQR", "Outlier si hors [Q1 − 1.5×IQR, Q3 + 1.5×IQR].", purpose="Repérage robuste.", notes="À interpréter avec contexte.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Résultats — EDA", open = TRUE,
                            tags$p(
                              tags$b("Résultats (Analyse exploratoire). "),
                              "« L’inspection visuelle indique une tendance [..] et une saisonnalité de période s=[..]. ",
                              "La variabilité semblait [constante / croître avec le niveau], suggérant [aucune / log / Box–Cox]. ",
                              "Des valeurs potentiellement aberrantes autour de [dates] ont été [conservées/ajustées] car [raison + contexte]. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "tendance/saison/outliers documentés."),
                              tags$li(tags$b("Sens : "), "on justifie les étapes suivantes (décomposition, différenciation, choix s).")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Supprimer des outliers automatiquement (perte d’événements réels)."),
                            tags$li("Ignorer que variance ↑ avec niveau (souvent log/Box–Cox aide)."),
                            tags$li("Lire la saisonnalité sur une série trop courte (risque de fausse saison).")
                          )
                        )
        ))
      }
      
      # ============== STEP 3 ==============
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "La décomposition est descriptive : elle clarifie tendance/saison et aide à décider additif vs multiplicatif (souvent via log).",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Objectif + choix de forme", open = TRUE,
                            tags$ul(
                              tags$li("Décomposer en tendance, saisonnalité, reste (bruit)."),
                              tags$li("Choisir additif vs multiplicatif selon amplitude saisonnière."),
                              tags$li("Utiliser STL si saison évolutive ou outliers.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("Décomposition additive",
                                 "y_t = T_t + S_t + e_t.",
                                 purpose="Quand l’amplitude saisonnière est à peu près constante.",
                                 formula="y_t = T_t + S_t + e_t"),
                            TERM("Décomposition multiplicative",
                                 "y_t = T_t × S_t × e_t.",
                                 purpose="Quand l’amplitude saisonnière augmente avec le niveau.",
                                 formula="y_t = T_t × S_t × e_t",
                                 notes="Souvent : log(y_t) transforme le multiplicatif en additif."),
                            TERM("STL",
                                 "Seasonal-Trend decomposition using Loess.",
                                 purpose="Robuste, flexible ; accepte une saisonnalité qui change lentement.",
                                 notes="Très utile en pratique ; reste descriptif (SARIMA nécessite stationnarité via différenciation).")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Décomposition", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Décomposition). "),
                              "« Nous avons évalué une structure additive vs multiplicative en examinant l’évolution de l’amplitude saisonnière avec le niveau. ",
                              "Comme [..], nous avons utilisé [additif / log puis additif] et décomposé via [classique / STL]. ",
                              "STL a été retenue pour sa robustesse aux valeurs aberrantes et sa capacité à modéliser une saisonnalité évolutive. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "forme (additive/multiplicative) + méthode (STL/...) justifiées."),
                              tags$li(tags$b("Sens : "), "on comprend la structure du signal, ce qui guide transformation et différenciation.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Prendre STL comme preuve de stationnarité (non : c’est descriptif)."),
                            tags$li("Oublier que multiplicatif ↔ log (ils sont meilleurs amis)."),
                            tags$li("Décomposer une série avec fréquence mal spécifiée (s incorrect).")
                          )
                        )
        ))
      }
      
      # ============== STEP 4 ==============
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Idée centrale : "),
                          "SARIMA exige que la série soit approximativement stationnaire après différenciation : on choisit d (tendance) et D (saisonnier) en combinant tests + graphiques.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Définir la saison (s) + appliquer la différenciation", open = TRUE,
                            tags$ul(
                              tags$li("Fixer la période saisonnière ", tags$code("s"), " (ex : 12 mensuel, 7 hebdo sur quotidien, 4 trimestriel)."),
                              tags$li("Tester stationnarité sur : original, après ∇^d, après ∇_s^D, et parfois après les deux."),
                              tags$li("S’arrêter dès que stationnarité raisonnable ; éviter sur-différenciation.")
                            )
                          ),
                          
                          S("Définitions indispensables", open = FALSE,
                            TERM("Stationnarité (faible)",
                                 "Moyenne et variance constantes, autocovariance dépend seulement du retard.",
                                 purpose="ARMA/SARIMA supposent cette stabilité après différenciation."),
                            TERM("Différenciation ordinaire (d)",
                                 "∇y_t = y_t - y_{t-1} ; appliquée d fois.",
                                 purpose="Supprime tendance stochastique (unit root non saisonnier).",
                                 formula="(1-B)^d y_t"),
                            TERM("Différenciation saisonnière (D)",
                                 "∇_s y_t = y_t - y_{t-s} ; appliquée D fois.",
                                 purpose="Supprime racine unitaire saisonnière.",
                                 formula="(1-B^s)^D y_t"),
                            TERM("Sur-différenciation",
                                 "Différencier trop (d ou D trop grand).",
                                 purpose="À éviter : dégrade variance/structure et rend le modèle instable.",
                                 notes="Symptôme typique : ACF très négative au lag 1.")
                          ),
                          
                          S("Tests (très détaillés, chacun cliquable)", open = FALSE,
                            TEST(
                              name="ADF — Augmented Dickey–Fuller",
                              purpose="Détecter une racine unitaire (tendance stochastique). On modélise Δy_t en fonction de y_{t-1} + retards de Δy pour absorber l’autocorrélation.",
                              H0="La série a une racine unitaire → non-stationnaire (les chocs ont des effets persistants).",
                              H1="La série est stationnaire (autour d’une moyenne ou d’une tendance déterministe selon spécification).",
                              statistic="Test sur le coefficient de y_{t-1} dans la régression ADF (valeurs critiques non standard).",
                              interpretation="p petit → rejet H0 → stationnarité plausible. p grand → non-rejet → différenciation probablement nécessaire.",
                              conclusion="Si ADF rejette après (d,D), cela soutient que la série différenciée convient à un SARIMA : les dépendances restantes peuvent être capturées par AR/MA.",
                              caveats="Sensibilité au choix (drift/trend) et au nombre de retards ; ruptures structurelles peuvent tromper le test."
                            ),
                            TEST(
                              name="KPSS — Kwiatkowski–Phillips–Schmidt–Shin",
                              purpose="Complément de l’ADF : ici la stationnarité est l’hypothèse nulle. On mesure si une marche aléatoire résiduelle est trop forte.",
                              H0="La série est stationnaire (en niveau) ou stationnaire autour d’une tendance (selon version).",
                              H1="La série est non-stationnaire.",
                              statistic="Statistique basée sur la somme cumulée des résidus + estimation de variance longue.",
                              interpretation="p petit → rejet H0 → non-stationnaire. p grand → compatible avec stationnarité.",
                              conclusion="KPSS non-significatif après différenciation renforce l’idée que la transformation a stabilisé la série.",
                              caveats="Choix de bande passante/variance longue ; ruptures → faux rejets."
                            ),
                            TEST(
                              name="PP — Phillips–Perron",
                              purpose="Test de racine unitaire comme ADF mais avec corrections non paramétriques pour autocorrélation/hétéroscédasticité (au lieu d’ajouter beaucoup de retards).",
                              H0="Racine unitaire → non-stationnaire.",
                              H1="Stationnaire.",
                              statistic="Statistique similaire à DF avec correction de variance.",
                              interpretation="Concordance ADF + PP = argument plus solide ; désaccord = vérifier spécification et diagnostics.",
                              conclusion="Rejet H0 par PP après (d,D) = cohérent avec une série différenciée stationnaire, prête pour SARIMA.",
                              caveats="Comme ADF : dépend de drift/trend ; breaks peuvent biaiser."
                            )
                          ),
                          
                          S("Interpréter ADF/KPSS/PP ensemble (logique de conclusion)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Accord stationnaire : "), "ADF/PP rejettent (p petit) + KPSS ne rejette pas (p grand) → stationnarité fortement plausible."),
                              tags$li(tags$b("Accord non-stationnaire : "), "ADF/PP ne rejettent pas (p grand) + KPSS rejette (p petit) → différenciation nécessaire."),
                              tags$li(tags$b("Conflits : "), "se reposer sur convergence : graphiques + ACF + résultats après différenciation. Écrire que la décision repose sur l’ensemble des indices (pas une seule p-value).")
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Stationnarité & différenciation", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Stationnarité & différenciation). "),
                              "« La stationnarité a été évaluée par ADF, KPSS et PP afin de trianguler l’évidence (hypothèses nulles différentes). ",
                              "Sur la base des tests, des diagnostics visuels et de l’ACF, nous avons retenu d=[..] et D=[..] avec période saisonnière s=[..]. ",
                              "Ce choix vise à supprimer tendance et/ou racine unitaire saisonnière tout en évitant la sur-différenciation ; la stationnarité a été revérifiée après transformation. »"
                            )
                          ),
                          S("Conclusion + sens (à écrire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "d=[..], D=[..], s=[..] retenus."),
                              tags$li(tags$b("Sens : "), "le SARIMA expliquera la dépendance restante (AR/MA) sur une série stabilisée (stationnaire) — donc des paramètres interprétables et des prévisions plus fiables.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li(tags$b("Sur-différenciation : "), "ACF lag1 très négative, variance gonflée, prévisions instables."),
                            tags$li("D vaut souvent 0 ou 1 ; si D=2, vérifier s et la qualité des données."),
                            tags$li("Oublier de tester avec/sans trend/drift : peut inverser la conclusion.")
                          )
                        )
        ))
      }
      
      # ============== STEP 5 ==============
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Auto-ARIMA fournit une baseline (bon point de départ), pas une vérité absolue. On documente critères, contraintes et transformations.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Procédure", open = TRUE,
                            tags$ul(
                              tags$li("Lancer auto-ARIMA (souvent AICc) pour proposer ", tags$code("(p,d,q)(P,D,Q)[s]"), "."),
                              tags$li("Documenter : transformations, contraintes max p/q/P/Q, stepwise vs exhaustive."),
                              tags$li("Garder une baseline + la comparer au manuel + benchmark naïf.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("AIC / AICc / BIC",
                                 "Critères d’information : compromis ajustement vs complexité (pénalisation). AICc corrige AIC pour petits échantillons.",
                                 purpose="Comparer des modèles sur la même série (même transformation) en pénalisant la complexité.",
                                 notes="Un meilleur AICc n’assure pas de meilleurs forecasts out-of-sample."),
                            TERM("Stepwise",
                                 "Recherche heuristique qui explore un sous-ensemble de modèles pour aller vite.",
                                 purpose="Accélérer la sélection quand l’espace des modèles est grand.",
                                 notes="Peut rater le meilleur modèle global, mais donne souvent une bonne baseline.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Modèle de référence", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Baseline). "),
                              "« Un modèle SARIMA de référence a été sélectionné via une procédure automatisée basée sur la minimisation de l’AICc parmi des ordres candidats sous contraintes [..]. ",
                              "La spécification retenue était SARIMA((p,d,q)(P,D,Q)[s]) et a servi de point de départ pour des ajustements ultérieurs guidés par les diagnostics. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "baseline définie et reproductible."),
                              tags$li(tags$b("Sens : "), "point de comparaison : on n’évalue pas le manuel « dans le vide ».")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Croire auto-ARIMA « final » : toujours vérifier diagnostics et performance."),
                            tags$li("Choisir uniquement AICc sans test out-of-sample."),
                            tags$li("Comparer des modèles sur des séries transformées différemment (incomparable).")
                          )
                        )
        ))
      }
      
      # ============== STEP 6 ==============
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "ACF/PACF guident la proposition de quelques modèles plausibles (3–8). On privilégie parcimonie + diagnostics propres.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Procédure guidée par ACF/PACF", open = TRUE,
                            tags$ol(
                              tags$li("Travailler sur la série différenciée (après choix de d et D)."),
                              tags$li("Tracer ACF et PACF."),
                              tags$li("Proposer quelques candidats (p,q,P,Q) plausibles."),
                              tags$li("Ajuster, comparer (AICc/BIC) + stabilité/inversibilité + diagnostics.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("ACF",
                                 "Fonction d’autocorrélation : corr(y_t, y_{t-k}).",
                                 purpose="Identifier composantes MA (coupure) et saisonnalité (pics aux multiples de s).",
                                 notes="Sur série stationnaire (souvent après différenciation)."),
                            TERM("PACF",
                                 "Autocorrélation partielle : corr(y_t, y_{t-k} | lags intermédiaires).",
                                 purpose="Identifier composantes AR (coupure)."),
                            TERM("AR(p)",
                                 "Modèle auto-régressif : y_t dépend de ses p retards.",
                                 purpose="Capturer persistance / inertie.",
                                 formula="y_t = c + Σ φ_i y_{t-i} + ε_t"),
                            TERM("MA(q)",
                                 "Moyenne mobile : y_t dépend des q erreurs passées.",
                                 purpose="Capturer chocs transitoires.",
                                 formula="y_t = c + ε_t + Σ θ_i ε_{t-i}"),
                            TERM("Saisonnier P/Q",
                                 "Composantes AR/MA aux multiples de s.",
                                 purpose="Capturer dépendances qui reviennent chaque saison (ex : année sur année).",
                                 notes="Pics à s, 2s, 3s… dans ACF/PACF.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Construction guidée", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Guidée par ACF/PACF). "),
                              "« Les structures candidates ont été proposées d’après l’ACF/PACF de la série différenciée. ",
                              "Des motifs aux faibles retards suggéraient des termes non saisonniers (p,q), tandis que des pics aux multiples de s suggéraient des termes saisonniers (P,Q). ",
                              "Un petit ensemble de modèles plausibles a été ajusté et comparé via [AICc/BIC] et diagnostics, en privilégiant la parcimonie. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "liste de candidats raisonnés + justification ACF/PACF."),
                              tags$li(tags$b("Sens : "), "on limite le sur-ajustement et on garde une interprétabilité pédagogique.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Bruteforce de centaines de modèles (pas « théorie »)."),
                            tags$li("Lire ACF/PACF sur série non stationnaire."),
                            tags$li("Oublier stabilité/inversibilité : un modèle peut fitter mais être instable.")
                          )
                        )
        ))
      }
      
      # ============== STEP 7 ==============
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Le modèle final doit : (1) résidus ~ bruit blanc (pas d’autocorrélation), (2) battre un benchmark, (3) rester simple si performance similaire.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Diagnostics résidus (indispensable)", open = TRUE,
                            tags$ul(
                              tags$li("Tracer résidus (aspect bruit)."),
                              tags$li("ACF résidus (pas de pics majeurs)."),
                              tags$li(tags$b("Ljung–Box"), " : tester l’autocorrélation résiduelle."),
                              tags$li("Normalité (QQ-plot ; Shapiro-Wilk trop sensible si grand n)."),
                              tags$li("Hétéroscédasticité / ARCH (si finance).")
                            )
                          ),
                          
                          S("Tests & définitions (cliquables)", open = FALSE,
                            TERM("Résidu", "r_t = y_t − ŷ_t (erreur in-sample).", purpose="Les résidus doivent être « bruit blanc » pour un modèle bien spécifié.", formula="r_t = y_t - ŷ_t"),
                            TERM("Bruit blanc", "Série de moyenne 0, variance constante, sans autocorrélation significative.", purpose="Cible des diagnostics résiduels."),
                            TEST(
                              name="Ljung–Box",
                              purpose="Vérifier si les résidus présentent encore de l’autocorrélation (globalement jusqu’à un lag L).",
                              H0="Pas d’autocorrélation résiduelle jusqu’au lag L (résidus compatibles bruit blanc).",
                              H1="Autocorrélation résiduelle présente.",
                              statistic="Q(L) agrège les autocorrélations résiduelles ; p-value associée.",
                              interpretation="p ≥ α : pas d’évidence forte d’autocorrélation ; p < α : structure restante → revoir (p,q,P,Q,d,D).",
                              conclusion="Si non significatif, cela soutient que le SARIMA a capturé la dépendance temporelle pertinente ; sinon, le modèle est incomplet.",
                              caveats="Choix de L important ; trop grand L peut sur-détecter ; dépend du fitdf."
                            ),
                            TEST(
                              name="Jarque–Bera (optionnel)",
                              purpose="Tester si la distribution des résidus est proche d’une normale (skewness + kurtosis).",
                              H0="Résidus ~ normale.",
                              H1="Résidus non normaux.",
                              interpretation="Souvent rejeté en pratique (queues épaisses). La non-normalité n’est pas toujours critique pour la prévision.",
                              conclusion="Si rejet, on interprète : queues épaisses possibles → intervalles de prévision peuvent être optimistes si on suppose normalité.",
                              caveats="Très sensible avec grands échantillons."
                            )
                          ),
                          
                          S("Évaluation prévision (indispensable)", open = FALSE,
                            tags$ul(
                              tags$li("Utiliser test set ou rolling-origin."),
                              tags$li("Métriques : MAE/RMSE (MAPE si y jamais proche de 0)."),
                              tags$li("Comparer : baseline auto-ARIMA, manuel, benchmark naïf (et naïf saisonnier).")
                            )
                          ),
                          
                          S("Règle saine de sélection finale", open = FALSE,
                            tags$ul(
                              tags$li("Diagnostics OK (résidus ~ bruit blanc)."),
                              tags$li("Performance > benchmark naïf."),
                              tags$li("Si performances proches : choisir le modèle le plus simple.")
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Résultats — Diagnostics & performance", open = TRUE,
                            tags$p(
                              tags$b("Résultats (Diagnostics & performance). "),
                              "« Les diagnostics résiduels suggéraient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics marqués, et le test de Ljung–Box était [non significatif/significatif] (α=[..]). ",
                              "Sur la fenêtre d’évaluation, la performance de prévision donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. ",
                              "Le modèle final retenu était SARIMA((p,d,q)(P,D,Q)[s]) sur la base de l’adéquation diagnostique et de la performance prédictive. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "modèle final + métriques + diagnostics présentés."),
                              tags$li(tags$b("Sens : "), "un SARIMA n’est « bon » que s’il généralise ET laisse des résidus sans structure temporelle.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Choisir AIC excellent mais résidus autocorrélés (modèle incomplet)."),
                            tags$li("Sur-interpréter la non-normalité : l’autocorrélation résiduelle est plus grave pour la prévision."),
                            tags$li("Comparer des modèles avec des splits temporels différents.")
                          )
                        )
        ))
      }
      
      # ============== STEP 8 ==============
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Votre rapport doit être aligné sur le pipeline : Méthodes (ce que vous avez fait + pourquoi) puis Résultats (ce que vous avez observé + conclusion).",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Checklist Méthodes", open = TRUE,
                            tags$ul(
                              tags$li("Données : source, dates, fréquence, manque, transformation."),
                              tags$li("EDA : graphiques + décomposition."),
                              tags$li("Stationnarité : tests + choix (d,D,s)."),
                              tags$li("Baseline auto-ARIMA (critère/contraintes)."),
                              tags$li("Candidats manuels (ACF/PACF + parcimonie)."),
                              tags$li("Diagnostics et protocole d’évaluation.")
                            )
                          ),
                          S("Checklist Résultats", open = TRUE,
                            tags$ul(
                              tags$li("Description des données + observations clés."),
                              tags$li("Décomposition : tendance/saison."),
                              tags$li("Tests stationnarité + d/D retenus."),
                              tags$li("Paramètres modèle final."),
                              tags$li("Diagnostics + métriques + figure de prévision."),
                              tags$li("Tableau comparatif (AICc + erreurs).")
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Structure APA (ultra pratique)", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Pour chaque sous-section : "), "Ce qu’on a fait → Pourquoi → Ce qu’on observe → Conclusion."),
                              tags$li("Temps verbal : passé en Méthodes, passé orienté résultats en Résultats."),
                              tags$li("Écrire la spécification complète une fois clairement : ", tags$code("SARIMA((p,d,q)(P,D,Q)[s])"), ".")
                            ),
                            S("Équation SARIMA (notation)", open = FALSE,
                              tags$ul(
                                tags$li(
                                  tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
                                  " avec innovations ",
                                  tags$code("ε_t ~ w.n.(0, σ^2)")
                                )
                              ),
                              tags$p(class="small",
                                     "Interprétation : après différenciation (∇^d et ∇_s^D), la dépendance restante est modélisée par des polynômes AR (φ, Φ) et MA (θ, Θ).")
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "rapport structuré = reproductible + pédagogique."),
                              tags$li(tags$b("Sens : "), "le lecteur peut refaire exactement vos étapes et comprendre vos choix.")
                            )
                          )
                        ),
                        
                        D("Pack livrable attendu", open = FALSE,
                          tags$ul(
                            tags$li(
                              tags$b("Notebook/script : "),
                              tags$ul(
                                tags$li("chargement + nettoyage + fréquence"),
                                tags$li("manquants + transformations"),
                                tags$li("EDA + décomposition"),
                                tags$li("tests stationnarité + choix d/D/s"),
                                tags$li("auto-ARIMA baseline"),
                                tags$li("candidats manuels"),
                                tags$li("diagnostics + évaluation"),
                                tags$li("prévision finale + intervalles")
                              )
                            ),
                            tags$li(
                              tags$b("Rapport court : "),
                              tags$ul(
                                tags$li("Méthodes/Résultats alignés étapes 0–7"),
                                tags$li("figures : série, décomposition, ACF/PACF, résidus, prévision"),
                                tags$li("tableau : AICc + MAE/RMSE (candidats)")
                              )
                            )
                          )
                        )
        ))
      }
      
      # fallback (should never happen)
      tags$div(class="road-card", "Étape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (très détaillée) — FR"),
                          tags$p(class="road-sub",
                                 "Naviguez par étape avec le slider. Ouvrez seulement ce dont vous avez besoin via les sections repliables.")
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Étape (utilisez le slider — pas besoin de défiler)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               # Step content
               step_content(k)
      )
    )
  })
  

  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  # ============================================================
  # UI (add this where you want the roadmap to appear)
  # ============================================================
  # uiOutput("roadmap_Detailed_Fr_ui")
  
  
  # ============================================================
  # SERVER (FULL COPY-PASTE) — Roadmap SARIMA FR + Slider + Collapsibles
  # Put this inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui6 <- renderUI({
    
    # ----------------------------
    # Helpers: nested collapsibles
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    
    # Big blocks per step
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1")
    # Sub-blocks inside big blocks
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2")
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, example = NULL, formula = NULL, notes = NULL, open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 tags$p(tags$b("Définition : "), definition),
                 if (!is.null(purpose)) tags$p(tags$b("But / utilité : "), purpose) else NULL,
                 if (!is.null(formula)) tags$p(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example)) tags$p(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(notes))   tags$p(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name, purpose, H0, H1,
                     statistic = NULL, interpretation = NULL, conclusion = NULL, caveats = NULL, open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 tags$p(tags$b("But / utilité : "), purpose),
                 tags$p(tags$b("H0 : "), H0),
                 tags$p(tags$b("H1 : "), H1),
                 if (!is.null(statistic))      tags$p(tags$b("Statistique (idée) : "), statistic) else NULL,
                 if (!is.null(interpretation)) tags$p(tags$b("Interprétation : "), interpretation) else NULL,
                 if (!is.null(conclusion))     tags$p(tags$b("Conclusion + sens : "), conclusion) else NULL,
                 if (!is.null(caveats))        tags$p(tags$b("Pièges / limites : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .eq {font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step builder
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Préparer le terrain : définir le problème",
        "[1] Décrire les données : n, manque, descriptives",
        "[2] Explorer visuellement : tendance, saison, outliers",
        "[3] Décomposer : additif vs multiplicatif, STL",
        "[4] Stationnarité : ADF/KPSS/PP, choisir d & D",
        "[5] Modèle de référence : Auto-ARIMA (AICc)",
        "[6] Modèle guidé par théorie : ACF/PACF + candidats",
        "[7] Diagnostiquer & comparer : résidus + précision",
        "[8] Rédiger le rapport : Méthodes/Résultats + livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Données", "Évaluation"),
        c("Qualité données", "Manquants", "Stat descriptives"),
        c("Graphiques", "Saisonnalité", "Anomalies"),
        c("Tendance", "Saison", "STL"),
        c("Stationnarité", "Différenciation", "Tests"),
        c("Auto-ARIMA", "AICc/BIC", "Baseline"),
        c("ACF/PACF", "Candidats", "Parcimonie"),
        c("Diagnostics", "Ljung–Box", "Forecast accuracy"),
        c("APA", "Synthèse", "Livrables")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ------------------------------------------------------------
    # CONTENT (extremely detailed but organized via collapsibles)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # ============== STEP 0 ==============
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Avant toute SARIMA, on fige exactement : la série cible (y_t), le calendrier (fréquence régulière), l’horizon, le protocole d’évaluation et la (les) métriques. ",
                          "Sans ça, on obtient des modèles « corrects » mais inutilisables.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Checklist opérationnelle", open = TRUE,
                            tags$ul(
                              tags$li("Définir la ", tags$b("série réponse"), " : ", tags$code("y_t"), " (ce que l’on prévoit)."),
                              tags$li("Définir l’", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vérifier la ", tags$b("régularité"), " (pas de trous ni doublons)."),
                              tags$li("Définir la ", tags$b("tâche de prévision"), " : horizon ", tags$code("h"), ", protocole (train/test ou rolling-origin), métrique(s) (MAE/RMSE/MAPE/sMAPE)."),
                              tags$li("Choisir l’échelle : niveaux / log / Box–Cox (et justifier)."),
                              tags$li("Définir le benchmark : naïf (et naïf saisonnier si saison).")
                            )
                          ),
                          
                          S("Définitions (cliquables)", open = FALSE,
                            TERM(
                              "Série réponse (y_t)",
                              "Variable temporelle univariée que l’on veut expliquer et prévoir. Chaque observation correspond à un instant t.",
                              purpose="Détermine l’objet du modèle (la cible) et le type de prévision produit.",
                              formula="y_t",
                              notes="SARIMA classique est univarié (pas de prédicteurs)."
                            ),
                            TERM(
                              "Indice temporel & fréquence",
                              "L’index temporel est la séquence des dates/temps. La fréquence est l’espacement régulier (jour, semaine, mois…).",
                              purpose="SARIMA suppose des intervalles constants ; la fréquence fixe la saisonnalité (ex : s=12 en mensuel).",
                              notes="Si timestamps irréguliers → rééchantillonnage/agrégation avant SARIMA."
                            ),
                            TERM(
                              "Horizon de prévision (h)",
                              "Nombre de pas dans le futur à prédire.",
                              purpose="Détermine ce qu’on considère « bon » (court terme vs long terme).",
                              example="h=12 (12 mois d’avance) ; h=7 (7 jours).",
                              formula="h"
                            ),
                            TERM(
                              "Protocole train/test",
                              "Découpage temporel où l’on entraîne sur le passé et on évalue sur le futur (jamais l’inverse).",
                              purpose="Évaluer la généralisation sur des dates non vues.",
                              notes="On évite le mélange temporel qui créerait une fuite d’information."
                            ),
                            TERM(
                              "Rolling-origin (origine glissante)",
                              "Évaluation répétée où l’origine de prévision avance : on ré-entraîne/actualise puis on prédit.",
                              purpose="Mieux refléter une utilisation réelle (le modèle vit dans le temps).",
                              notes="Plus coûteux, plus robuste que 1 seul split."
                            ),
                            TERM(
                              "MAE",
                              "Moyenne des valeurs absolues des erreurs.",
                              purpose="Lisible, robuste aux gros outliers par rapport à RMSE.",
                              formula="MAE = mean(|y_t - ŷ_t|)"
                            ),
                            TERM(
                              "RMSE",
                              "Racine de la moyenne des erreurs quadratiques.",
                              purpose="Pénalise fortement les grandes erreurs.",
                              formula="RMSE = sqrt(mean((y_t - ŷ_t)^2))"
                            ),
                            TERM(
                              "MAPE",
                              "Erreur absolue en pourcentage moyen.",
                              purpose="Interprétation en % quand y_t est strictement positif et loin de 0.",
                              formula="MAPE = mean(|(y_t-ŷ_t)/y_t|) × 100",
                              notes="Instable si y_t ≈ 0."
                            ),
                            TERM(
                              "sMAPE",
                              "Version symétrisée du MAPE : normalise par (|y|+|ŷ|).",
                              purpose="Réduit certains problèmes du MAPE.",
                              formula="sMAPE = mean( 2|y-ŷ|/(|y|+|ŷ|) ) × 100"
                            ),
                            TERM(
                              "Transformation log",
                              "Transformer y_t en log(y_t) (si y_t>0).",
                              purpose="Stabiliser une variance qui augmente avec le niveau ; transformer multiplicatif → additif.",
                              notes="Toujours expliquer comment on revient à l’échelle originale."
                            ),
                            TERM(
                              "Box–Cox",
                              "Famille de transformations paramétrées (λ) incluant log comme cas particulier.",
                              purpose="Stabiliser variance et améliorer normalité/linéarité des résidus.",
                              formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) si λ→0"
                            ),
                            TERM(
                              "SARIMA vs SARIMAX",
                              "SARIMA : ARIMA saisonnier univarié. SARIMAX : SARIMA avec variables exogènes (X).",
                              purpose="Clarifier si on modélise uniquement y_t ou y_t avec prédicteurs.",
                              notes="Si vous avez des covariables → SARIMAX (ou autre modèle)."
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent (papier)", open = FALSE,
                          S("Template Méthodes — Données & Objectif", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Données & Objectif). "),
                              "« Nous avons modélisé la série temporelle univariée ", tags$code("y_t"),
                              " observée à une fréquence [..] de [début] à [fin] (n=[..]). ",
                              "L’objectif était de prévoir à un horizon h=[..] pas. ",
                              "La performance a été évaluée avec [MAE/RMSE/…] selon [split temporel / rolling-origin]. ",
                              "Une transformation [aucune / log / Box–Cox (λ=[..])] a été utilisée pour [raison]. »"
                            )
                          ),
                          S("Conclusion + sens (à écrire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "on fixe y_t, la fréquence, h, le protocole et les métriques."),
                              tags$li(tags$b("Sens : "), "on rend la modélisation reproductible ; toute comparaison de modèles devient valide.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("SARIMA suppose un ", tags$b("espacement régulier"), " ; timestamps irréguliers = problème de base."),
                            tags$li("Ne pas confondre une bonne courbe in-sample avec une bonne ", tags$b("performance out-of-sample"), "."),
                            tags$li("MAPE si y_t proche de 0 : souvent une mauvaise idée."),
                            tags$li("Transformer sans expliquer l’inversion (retour à l’échelle originale).")
                          )
                        )
        ))
      }
      
      # ============== STEP 1 ==============
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Un SARIMA est aussi bon que vos données : n, dates, fréquence, manque et descriptives doivent être rapportés proprement.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Checklist opérationnelle", open = TRUE,
                            tags$ol(
                              tags$li("Rapporter : n, début/fin, fréquence, % manquants."),
                              tags$li("Diagnostiquer le manque (rare/important ; aléatoire/systématique)."),
                              tags$li("Traiter : interpolation linéaire/saisonnière, ou autre méthode justifiée."),
                              tags$li("Calculer descriptives : moyenne, médiane, ET, min/max, skewness, kurtosis, résumés saisonniers.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("n (taille d’échantillon)", "Nombre d’observations disponibles.", purpose="Impact direct sur la stabilité de l’estimation et la fiabilité des tests."),
                            TERM("Valeur manquante", "Observation absente (NA) sur une date attendue.", purpose="Les NA peuvent casser l’ajustement SARIMA si non traités."),
                            TERM("Manque MCAR/MAR/MNAR",
                                 "MCAR: manque complètement aléatoire. MAR: manque dépend d’observables. MNAR: dépend de la valeur manquante elle-même.",
                                 purpose="Aide à justifier l’imputation et ses limites.",
                                 notes="En pratique en séries temporelles, le manque est souvent structurel (pannes, jours fériés, etc.)."),
                            TERM("Interpolation linéaire",
                                 "Imputation par une ligne entre points observés.",
                                 purpose="Simple, efficace si trous courts et pas de rupture.",
                                 notes="À éviter si longues périodes manquantes."),
                            TERM("Interpolation saisonnière",
                                 "Imputation en respectant la saisonnalité (ex : remplacer un mois manquant par moyenne des mêmes mois).",
                                 purpose="Mieux quand la saison est forte.",
                                 notes="Justifier la méthode ; vérifier qu’elle n’invente pas une saison artificielle."),
                            TERM("Moyenne", "Somme / n.", purpose="Centre de la distribution.", formula="mean(y)"),
                            TERM("Médiane", "Valeur centrale (50e percentile).", purpose="Centre robuste aux outliers."),
                            TERM("Écart-type (ET)", "Mesure de dispersion autour de la moyenne.", purpose="Quantifie variabilité.", formula="sd(y)"),
                            TERM("Skewness", "Asymétrie de la distribution.", purpose="Décrit si la masse est tirée vers la gauche/droite."),
                            TERM("Kurtosis", "Épaisseur des queues (tail heaviness).", purpose="Indique présence de valeurs extrêmes plus fréquentes.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent (APA)", open = FALSE,
                          S("Template Résultats — Description des données", open = TRUE,
                            tags$p(
                              tags$b("Résultats (Description des données). "),
                              "« La série contient n=[..] observations couvrant [dates] à une fréquence [..]. ",
                              "Les valeurs manquantes représentaient [..]% (k=[..]). Elles ont été traitées via [méthode] car [raison]. ",
                              "La distribution de ", tags$code("y_t"),
                              " présentait une moyenne de [..] (ET=[..]), une médiane [..], et un intervalle [min,max]. ",
                              "Descriptives saisonnières (ex : par mois) : [résumé]. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "données décrites + manque traité et justifié."),
                              tags$li(tags$b("Sens : "), "le lecteur comprend la fiabilité des estimations et la comparabilité des résultats.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer « en silence » : toujours documenter et justifier."),
                            tags$li("Confondre absence de date et NA : parfois la date n’existe pas (fréquence mal définie)."),
                            tags$li("Si log/Box–Cox : rapporter descriptives aussi sur la série transformée (au moins brièvement).")
                          )
                        )
        ))
      }
      
      # ============== STEP 2 ==============
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Les graphiques servent à détecter tendance/saison/outliers et à justifier transformations + différenciation.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Graphiques à produire", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Courbe temporelle"), " de ", tags$code("y_t"), " (et de log(y_t) si pertinent)."),
                              tags$li(tags$b("Graphique saisonnier"), " (lignes par année, couleur par mois, ou seasonal plot)."),
                              tags$li(tags$b("Boxplots par saison"), " (mois/trimestre/semaine)."),
                              tags$li(tags$b("Détection d’outliers"), " (z-score, IQR, robuste + contexte).")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("Tendance", "Évolution de long terme (hausse/baisse) distincte de la saison.", purpose="Guider d (différenciation non saisonnière)."),
                            TERM("Saisonnalité", "Motif qui se répète à période fixe s (ex : 12 mois).", purpose="Guider D (différenciation saisonnière) et P/Q.", formula="s"),
                            TERM("Outlier (valeur aberrante)", "Observation atypique par rapport au comportement habituel.", purpose="Décider : conserver/ajuster/modéliser.",
                                 notes="Un outlier peut être un événement réel (promo, crise) → souvent à conserver."),
                            TERM("Z-score", "Mesure d’écart en nombre d’ET par rapport à la moyenne.", purpose="Repérer des points très éloignés.",
                                 formula="z = (y - mean)/sd", notes="Peu robuste si distribution non gaussienne."),
                            TERM("Règle IQR", "Outlier si hors [Q1 − 1.5×IQR, Q3 + 1.5×IQR].", purpose="Repérage robuste.", notes="À interpréter avec contexte.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Résultats — EDA", open = TRUE,
                            tags$p(
                              tags$b("Résultats (Analyse exploratoire). "),
                              "« L’inspection visuelle indique une tendance [..] et une saisonnalité de période s=[..]. ",
                              "La variabilité semblait [constante / croître avec le niveau], suggérant [aucune / log / Box–Cox]. ",
                              "Des valeurs potentiellement aberrantes autour de [dates] ont été [conservées/ajustées] car [raison + contexte]. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "tendance/saison/outliers documentés."),
                              tags$li(tags$b("Sens : "), "on justifie les étapes suivantes (décomposition, différenciation, choix s).")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Supprimer des outliers automatiquement (perte d’événements réels)."),
                            tags$li("Ignorer que variance ↑ avec niveau (souvent log/Box–Cox aide)."),
                            tags$li("Lire la saisonnalité sur une série trop courte (risque de fausse saison).")
                          )
                        )
        ))
      }
      
      # ============== STEP 3 ==============
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "La décomposition est descriptive : elle clarifie tendance/saison et aide à décider additif vs multiplicatif (souvent via log).",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Objectif + choix de forme", open = TRUE,
                            tags$ul(
                              tags$li("Décomposer en tendance, saisonnalité, reste (bruit)."),
                              tags$li("Choisir additif vs multiplicatif selon amplitude saisonnière."),
                              tags$li("Utiliser STL si saison évolutive ou outliers.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("Décomposition additive",
                                 "y_t = T_t + S_t + e_t.",
                                 purpose="Quand l’amplitude saisonnière est à peu près constante.",
                                 formula="y_t = T_t + S_t + e_t"),
                            TERM("Décomposition multiplicative",
                                 "y_t = T_t × S_t × e_t.",
                                 purpose="Quand l’amplitude saisonnière augmente avec le niveau.",
                                 formula="y_t = T_t × S_t × e_t",
                                 notes="Souvent : log(y_t) transforme le multiplicatif en additif."),
                            TERM("STL",
                                 "Seasonal-Trend decomposition using Loess.",
                                 purpose="Robuste, flexible ; accepte une saisonnalité qui change lentement.",
                                 notes="Très utile en pratique ; reste descriptif (SARIMA nécessite stationnarité via différenciation).")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Décomposition", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Décomposition). "),
                              "« Nous avons évalué une structure additive vs multiplicative en examinant l’évolution de l’amplitude saisonnière avec le niveau. ",
                              "Comme [..], nous avons utilisé [additif / log puis additif] et décomposé via [classique / STL]. ",
                              "STL a été retenue pour sa robustesse aux valeurs aberrantes et sa capacité à modéliser une saisonnalité évolutive. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "forme (additive/multiplicative) + méthode (STL/...) justifiées."),
                              tags$li(tags$b("Sens : "), "on comprend la structure du signal, ce qui guide transformation et différenciation.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Prendre STL comme preuve de stationnarité (non : c’est descriptif)."),
                            tags$li("Oublier que multiplicatif ↔ log (ils sont meilleurs amis)."),
                            tags$li("Décomposer une série avec fréquence mal spécifiée (s incorrect).")
                          )
                        )
        ))
      }
      
      # ============== STEP 4 ==============
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Idée centrale : "),
                          "SARIMA exige que la série soit approximativement stationnaire après différenciation : on choisit d (tendance) et D (saisonnier) en combinant tests + graphiques.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Définir la saison (s) + appliquer la différenciation", open = TRUE,
                            tags$ul(
                              tags$li("Fixer la période saisonnière ", tags$code("s"), " (ex : 12 mensuel, 7 hebdo sur quotidien, 4 trimestriel)."),
                              tags$li("Tester stationnarité sur : original, après ∇^d, après ∇_s^D, et parfois après les deux."),
                              tags$li("S’arrêter dès que stationnarité raisonnable ; éviter sur-différenciation.")
                            )
                          ),
                          
                          S("Définitions indispensables", open = FALSE,
                            TERM("Stationnarité (faible)",
                                 "Moyenne et variance constantes, autocovariance dépend seulement du retard.",
                                 purpose="ARMA/SARIMA supposent cette stabilité après différenciation."),
                            TERM("Différenciation ordinaire (d)",
                                 "∇y_t = y_t - y_{t-1} ; appliquée d fois.",
                                 purpose="Supprime tendance stochastique (unit root non saisonnier).",
                                 formula="(1-B)^d y_t"),
                            TERM("Différenciation saisonnière (D)",
                                 "∇_s y_t = y_t - y_{t-s} ; appliquée D fois.",
                                 purpose="Supprime racine unitaire saisonnière.",
                                 formula="(1-B^s)^D y_t"),
                            TERM("Sur-différenciation",
                                 "Différencier trop (d ou D trop grand).",
                                 purpose="À éviter : dégrade variance/structure et rend le modèle instable.",
                                 notes="Symptôme typique : ACF très négative au lag 1.")
                          ),
                          
                          S("Tests (très détaillés, chacun cliquable)", open = FALSE,
                            TEST(
                              name="ADF — Augmented Dickey–Fuller",
                              purpose="Détecter une racine unitaire (tendance stochastique). On modélise Δy_t en fonction de y_{t-1} + retards de Δy pour absorber l’autocorrélation.",
                              H0="La série a une racine unitaire → non-stationnaire (les chocs ont des effets persistants).",
                              H1="La série est stationnaire (autour d’une moyenne ou d’une tendance déterministe selon spécification).",
                              statistic="Test sur le coefficient de y_{t-1} dans la régression ADF (valeurs critiques non standard).",
                              interpretation="p petit → rejet H0 → stationnarité plausible. p grand → non-rejet → différenciation probablement nécessaire.",
                              conclusion="Si ADF rejette après (d,D), cela soutient que la série différenciée convient à un SARIMA : les dépendances restantes peuvent être capturées par AR/MA.",
                              caveats="Sensibilité au choix (drift/trend) et au nombre de retards ; ruptures structurelles peuvent tromper le test."
                            ),
                            TEST(
                              name="KPSS — Kwiatkowski–Phillips–Schmidt–Shin",
                              purpose="Complément de l’ADF : ici la stationnarité est l’hypothèse nulle. On mesure si une marche aléatoire résiduelle est trop forte.",
                              H0="La série est stationnaire (en niveau) ou stationnaire autour d’une tendance (selon version).",
                              H1="La série est non-stationnaire.",
                              statistic="Statistique basée sur la somme cumulée des résidus + estimation de variance longue.",
                              interpretation="p petit → rejet H0 → non-stationnaire. p grand → compatible avec stationnarité.",
                              conclusion="KPSS non-significatif après différenciation renforce l’idée que la transformation a stabilisé la série.",
                              caveats="Choix de bande passante/variance longue ; ruptures → faux rejets."
                            ),
                            TEST(
                              name="PP — Phillips–Perron",
                              purpose="Test de racine unitaire comme ADF mais avec corrections non paramétriques pour autocorrélation/hétéroscédasticité (au lieu d’ajouter beaucoup de retards).",
                              H0="Racine unitaire → non-stationnaire.",
                              H1="Stationnaire.",
                              statistic="Statistique similaire à DF avec correction de variance.",
                              interpretation="Concordance ADF + PP = argument plus solide ; désaccord = vérifier spécification et diagnostics.",
                              conclusion="Rejet H0 par PP après (d,D) = cohérent avec une série différenciée stationnaire, prête pour SARIMA.",
                              caveats="Comme ADF : dépend de drift/trend ; breaks peuvent biaiser."
                            )
                          ),
                          
                          S("Interpréter ADF/KPSS/PP ensemble (logique de conclusion)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Accord stationnaire : "), "ADF/PP rejettent (p petit) + KPSS ne rejette pas (p grand) → stationnarité fortement plausible."),
                              tags$li(tags$b("Accord non-stationnaire : "), "ADF/PP ne rejettent pas (p grand) + KPSS rejette (p petit) → différenciation nécessaire."),
                              tags$li(tags$b("Conflits : "), "se reposer sur convergence : graphiques + ACF + résultats après différenciation. Écrire que la décision repose sur l’ensemble des indices (pas une seule p-value).")
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Stationnarité & différenciation", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Stationnarité & différenciation). "),
                              "« La stationnarité a été évaluée par ADF, KPSS et PP afin de trianguler l’évidence (hypothèses nulles différentes). ",
                              "Sur la base des tests, des diagnostics visuels et de l’ACF, nous avons retenu d=[..] et D=[..] avec période saisonnière s=[..]. ",
                              "Ce choix vise à supprimer tendance et/ou racine unitaire saisonnière tout en évitant la sur-différenciation ; la stationnarité a été revérifiée après transformation. »"
                            )
                          ),
                          S("Conclusion + sens (à écrire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "d=[..], D=[..], s=[..] retenus."),
                              tags$li(tags$b("Sens : "), "le SARIMA expliquera la dépendance restante (AR/MA) sur une série stabilisée (stationnaire) — donc des paramètres interprétables et des prévisions plus fiables.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li(tags$b("Sur-différenciation : "), "ACF lag1 très négative, variance gonflée, prévisions instables."),
                            tags$li("D vaut souvent 0 ou 1 ; si D=2, vérifier s et la qualité des données."),
                            tags$li("Oublier de tester avec/sans trend/drift : peut inverser la conclusion.")
                          )
                        )
        ))
      }
      
      # ============== STEP 5 ==============
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Auto-ARIMA fournit une baseline (bon point de départ), pas une vérité absolue. On documente critères, contraintes et transformations.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Procédure", open = TRUE,
                            tags$ul(
                              tags$li("Lancer auto-ARIMA (souvent AICc) pour proposer ", tags$code("(p,d,q)(P,D,Q)[s]"), "."),
                              tags$li("Documenter : transformations, contraintes max p/q/P/Q, stepwise vs exhaustive."),
                              tags$li("Garder une baseline + la comparer au manuel + benchmark naïf.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("AIC / AICc / BIC",
                                 "Critères d’information : compromis ajustement vs complexité (pénalisation). AICc corrige AIC pour petits échantillons.",
                                 purpose="Comparer des modèles sur la même série (même transformation) en pénalisant la complexité.",
                                 notes="Un meilleur AICc n’assure pas de meilleurs forecasts out-of-sample."),
                            TERM("Stepwise",
                                 "Recherche heuristique qui explore un sous-ensemble de modèles pour aller vite.",
                                 purpose="Accélérer la sélection quand l’espace des modèles est grand.",
                                 notes="Peut rater le meilleur modèle global, mais donne souvent une bonne baseline.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Modèle de référence", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Baseline). "),
                              "« Un modèle SARIMA de référence a été sélectionné via une procédure automatisée basée sur la minimisation de l’AICc parmi des ordres candidats sous contraintes [..]. ",
                              "La spécification retenue était SARIMA((p,d,q)(P,D,Q)[s]) et a servi de point de départ pour des ajustements ultérieurs guidés par les diagnostics. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "baseline définie et reproductible."),
                              tags$li(tags$b("Sens : "), "point de comparaison : on n’évalue pas le manuel « dans le vide ».")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Croire auto-ARIMA « final » : toujours vérifier diagnostics et performance."),
                            tags$li("Choisir uniquement AICc sans test out-of-sample."),
                            tags$li("Comparer des modèles sur des séries transformées différemment (incomparable).")
                          )
                        )
        ))
      }
      
      # ============== STEP 6 ==============
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "ACF/PACF guident la proposition de quelques modèles plausibles (3–8). On privilégie parcimonie + diagnostics propres.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Procédure guidée par ACF/PACF", open = TRUE,
                            tags$ol(
                              tags$li("Travailler sur la série différenciée (après choix de d et D)."),
                              tags$li("Tracer ACF et PACF."),
                              tags$li("Proposer quelques candidats (p,q,P,Q) plausibles."),
                              tags$li("Ajuster, comparer (AICc/BIC) + stabilité/inversibilité + diagnostics.")
                            )
                          ),
                          S("Définitions (cliquables)", open = FALSE,
                            TERM("ACF",
                                 "Fonction d’autocorrélation : corr(y_t, y_{t-k}).",
                                 purpose="Identifier composantes MA (coupure) et saisonnalité (pics aux multiples de s).",
                                 notes="Sur série stationnaire (souvent après différenciation)."),
                            TERM("PACF",
                                 "Autocorrélation partielle : corr(y_t, y_{t-k} | lags intermédiaires).",
                                 purpose="Identifier composantes AR (coupure)."),
                            TERM("AR(p)",
                                 "Modèle auto-régressif : y_t dépend de ses p retards.",
                                 purpose="Capturer persistance / inertie.",
                                 formula="y_t = c + Σ φ_i y_{t-i} + ε_t"),
                            TERM("MA(q)",
                                 "Moyenne mobile : y_t dépend des q erreurs passées.",
                                 purpose="Capturer chocs transitoires.",
                                 formula="y_t = c + ε_t + Σ θ_i ε_{t-i}"),
                            TERM("Saisonnier P/Q",
                                 "Composantes AR/MA aux multiples de s.",
                                 purpose="Capturer dépendances qui reviennent chaque saison (ex : année sur année).",
                                 notes="Pics à s, 2s, 3s… dans ACF/PACF.")
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Méthodes — Construction guidée", open = TRUE,
                            tags$p(
                              tags$b("Méthodes (Guidée par ACF/PACF). "),
                              "« Les structures candidates ont été proposées d’après l’ACF/PACF de la série différenciée. ",
                              "Des motifs aux faibles retards suggéraient des termes non saisonniers (p,q), tandis que des pics aux multiples de s suggéraient des termes saisonniers (P,Q). ",
                              "Un petit ensemble de modèles plausibles a été ajusté et comparé via [AICc/BIC] et diagnostics, en privilégiant la parcimonie. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "liste de candidats raisonnés + justification ACF/PACF."),
                              tags$li(tags$b("Sens : "), "on limite le sur-ajustement et on garde une interprétabilité pédagogique.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Bruteforce de centaines de modèles (pas « théorie »)."),
                            tags$li("Lire ACF/PACF sur série non stationnaire."),
                            tags$li("Oublier stabilité/inversibilité : un modèle peut fitter mais être instable.")
                          )
                        )
        ))
      }
      
      # ============== STEP 7 ==============
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Le modèle final doit : (1) résidus ~ bruit blanc (pas d’autocorrélation), (2) battre un benchmark, (3) rester simple si performance similaire.",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Diagnostics résidus (indispensable)", open = TRUE,
                            tags$ul(
                              tags$li("Tracer résidus (aspect bruit)."),
                              tags$li("ACF résidus (pas de pics majeurs)."),
                              tags$li(tags$b("Ljung–Box"), " : tester l’autocorrélation résiduelle."),
                              tags$li("Normalité (QQ-plot ; Shapiro-Wilk trop sensible si grand n)."),
                              tags$li("Hétéroscédasticité / ARCH (si finance).")
                            )
                          ),
                          
                          S("Tests & définitions (cliquables)", open = FALSE,
                            TERM("Résidu", "r_t = y_t − ŷ_t (erreur in-sample).", purpose="Les résidus doivent être « bruit blanc » pour un modèle bien spécifié.", formula="r_t = y_t - ŷ_t"),
                            TERM("Bruit blanc", "Série de moyenne 0, variance constante, sans autocorrélation significative.", purpose="Cible des diagnostics résiduels."),
                            TEST(
                              name="Ljung–Box",
                              purpose="Vérifier si les résidus présentent encore de l’autocorrélation (globalement jusqu’à un lag L).",
                              H0="Pas d’autocorrélation résiduelle jusqu’au lag L (résidus compatibles bruit blanc).",
                              H1="Autocorrélation résiduelle présente.",
                              statistic="Q(L) agrège les autocorrélations résiduelles ; p-value associée.",
                              interpretation="p ≥ α : pas d’évidence forte d’autocorrélation ; p < α : structure restante → revoir (p,q,P,Q,d,D).",
                              conclusion="Si non significatif, cela soutient que le SARIMA a capturé la dépendance temporelle pertinente ; sinon, le modèle est incomplet.",
                              caveats="Choix de L important ; trop grand L peut sur-détecter ; dépend du fitdf."
                            ),
                            TEST(
                              name="Jarque–Bera (optionnel)",
                              purpose="Tester si la distribution des résidus est proche d’une normale (skewness + kurtosis).",
                              H0="Résidus ~ normale.",
                              H1="Résidus non normaux.",
                              interpretation="Souvent rejeté en pratique (queues épaisses). La non-normalité n’est pas toujours critique pour la prévision.",
                              conclusion="Si rejet, on interprète : queues épaisses possibles → intervalles de prévision peuvent être optimistes si on suppose normalité.",
                              caveats="Très sensible avec grands échantillons."
                            )
                          ),
                          
                          S("Évaluation prévision (indispensable)", open = FALSE,
                            tags$ul(
                              tags$li("Utiliser test set ou rolling-origin."),
                              tags$li("Métriques : MAE/RMSE (MAPE si y jamais proche de 0)."),
                              tags$li("Comparer : baseline auto-ARIMA, manuel, benchmark naïf (et naïf saisonnier).")
                            )
                          ),
                          
                          S("Règle saine de sélection finale", open = FALSE,
                            tags$ul(
                              tags$li("Diagnostics OK (résidus ~ bruit blanc)."),
                              tags$li("Performance > benchmark naïf."),
                              tags$li("Si performances proches : choisir le modèle le plus simple.")
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Template Résultats — Diagnostics & performance", open = TRUE,
                            tags$p(
                              tags$b("Résultats (Diagnostics & performance). "),
                              "« Les diagnostics résiduels suggéraient un comportement proche du bruit blanc : l’ACF des résidus ne montrait pas de pics marqués, et le test de Ljung–Box était [non significatif/significatif] (α=[..]). ",
                              "Sur la fenêtre d’évaluation, la performance de prévision donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. ",
                              "Le modèle final retenu était SARIMA((p,d,q)(P,D,Q)[s]) sur la base de l’adéquation diagnostique et de la performance prédictive. »"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "modèle final + métriques + diagnostics présentés."),
                              tags$li(tags$b("Sens : "), "un SARIMA n’est « bon » que s’il généralise ET laisse des résidus sans structure temporelle.")
                            )
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Choisir AIC excellent mais résidus autocorrélés (modèle incomplet)."),
                            tags$li("Sur-interpréter la non-normalité : l’autocorrélation résiduelle est plus grave pour la prévision."),
                            tags$li("Comparer des modèles avec des splits temporels différents.")
                          )
                        )
        ))
      }
      
      # ============== STEP 8 ==============
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Idée centrale : "),
                          "Votre rapport doit être aligné sur le pipeline : Méthodes (ce que vous avez fait + pourquoi) puis Résultats (ce que vous avez observé + conclusion).",
                          type="ok"
                        ),
                        
                        D("Ce que les étudiants font", open = TRUE,
                          S("Checklist Méthodes", open = TRUE,
                            tags$ul(
                              tags$li("Données : source, dates, fréquence, manque, transformation."),
                              tags$li("EDA : graphiques + décomposition."),
                              tags$li("Stationnarité : tests + choix (d,D,s)."),
                              tags$li("Baseline auto-ARIMA (critère/contraintes)."),
                              tags$li("Candidats manuels (ACF/PACF + parcimonie)."),
                              tags$li("Diagnostics et protocole d’évaluation.")
                            )
                          ),
                          S("Checklist Résultats", open = TRUE,
                            tags$ul(
                              tags$li("Description des données + observations clés."),
                              tags$li("Décomposition : tendance/saison."),
                              tags$li("Tests stationnarité + d/D retenus."),
                              tags$li("Paramètres modèle final."),
                              tags$li("Diagnostics + métriques + figure de prévision."),
                              tags$li("Tableau comparatif (AICc + erreurs).")
                            )
                          )
                        ),
                        
                        D("Ce qu’ils écrivent", open = FALSE,
                          S("Structure APA (ultra pratique)", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Pour chaque sous-section : "), "Ce qu’on a fait → Pourquoi → Ce qu’on observe → Conclusion."),
                              tags$li("Temps verbal : passé en Méthodes, passé orienté résultats en Résultats."),
                              tags$li("Écrire la spécification complète une fois clairement : ", tags$code("SARIMA((p,d,q)(P,D,Q)[s])"), ".")
                            ),
                            S("Équation SARIMA (notation)", open = FALSE,
                              tags$ul(
                                tags$li(
                                  tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
                                  " avec innovations ",
                                  tags$code("ε_t ~ w.n.(0, σ^2)")
                                )
                              ),
                              tags$p(class="small",
                                     "Interprétation : après différenciation (∇^d et ∇_s^D), la dépendance restante est modélisée par des polynômes AR (φ, Φ) et MA (θ, Θ).")
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "rapport structuré = reproductible + pédagogique."),
                              tags$li(tags$b("Sens : "), "le lecteur peut refaire exactement vos étapes et comprendre vos choix.")
                            )
                          )
                        ),
                        
                        D("Pack livrable attendu", open = FALSE,
                          tags$ul(
                            tags$li(
                              tags$b("Notebook/script : "),
                              tags$ul(
                                tags$li("chargement + nettoyage + fréquence"),
                                tags$li("manquants + transformations"),
                                tags$li("EDA + décomposition"),
                                tags$li("tests stationnarité + choix d/D/s"),
                                tags$li("auto-ARIMA baseline"),
                                tags$li("candidats manuels"),
                                tags$li("diagnostics + évaluation"),
                                tags$li("prévision finale + intervalles")
                              )
                            ),
                            tags$li(
                              tags$b("Rapport court : "),
                              tags$ul(
                                tags$li("Méthodes/Résultats alignés étapes 0–7"),
                                tags$li("figures : série, décomposition, ACF/PACF, résidus, prévision"),
                                tags$li("tableau : AICc + MAE/RMSE (candidats)")
                              )
                            )
                          )
                        )
        ))
      }
      
      # fallback (should never happen)
      tags$div(class="road-card", "Étape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (très détaillée) — FR"),
                          tags$p(class="road-sub",
                                 "Naviguez par étape avec le slider. Ouvrez seulement ce dont vous avez besoin via les sections repliables.")
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Étape (utilisez le slider — pas besoin de défiler)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               # Step content
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  # ============================================================
  # خارطة طريق SARIMA (بالعربية الفصحى) — شريط تمرير + أقسام قابلة للطي
  # منظمة بالشكل التالي داخل كل خطوة:
  # الهدف → التحليلات المطلوبة → الاختبارات (الغرض/متى/فرضيات/معايير القرار) → معايير الاختيار → المخرجات → الأخطاء الشائعة
  #
  # طريقة الاستخدام:
  # 1) في واجهة المستخدم UI:   uiOutput("roadmap_Detailed_Ar_ui")
  # 2) في الخادم server(): انسخ كل الكود أدناه داخل server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Ar_ui <- renderUI({
    
    # ----------------------------
    # دوال مساعدة لبناء أقسام قابلة للطي (Accordion)
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # مستوى 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # مستوى 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL, notes = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 tags$p(tags$b("التعريف: "), definition),
                 if (!is.null(purpose))  tags$p(tags$b("الغرض/الفائدة: "), purpose) else NULL,
                 if (!is.null(criteria)) tags$p(tags$b("معايير/مؤشرات: "), criteria) else NULL,
                 if (!is.null(formula))  tags$p(tags$b("الترميز/الصيغة: "), tags$code(formula)) else NULL,
                 if (!is.null(example))  tags$p(tags$b("مثال: "), example) else NULL,
                 if (!is.null(notes))    tags$p(tags$b("ملاحظات: "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 tags$p(tags$b("الغرض (بتفصيل): "), purpose),
                 tags$p(tags$b("متى نستخدمه: "), when_to_use),
                 tags$p(tags$b("الفرضية الصفرية H0: "), H0),
                 tags$p(tags$b("الفرضية البديلة H1: "), H1),
                 if (!is.null(statistic))      tags$p(tags$b("الإحصاء/الفكرة: "), statistic) else NULL,
                 if (!is.null(decision_rule))  tags$p(tags$b("قاعدة القرار: "), decision_rule) else NULL,
                 if (!is.null(interpretation)) tags$p(tags$b("التفسير (المعنى): "), interpretation) else NULL,
                 if (!is.null(reporting))      tags$p(tags$b("كيفية العرض في التقرير: "), reporting) else NULL,
                 if (!is.null(caveats))        tags$p(tags$b("حدود/أخطاء شائعة: "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (لتنظيم المظهر والسلوك)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px; direction: rtl; showing: block;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-right:4px;}
    details.acc.term, details.acc.test {margin:8px 12px 8px 0;}
    .callout {border-right:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-right-color:#E45756; background:#fff7f7;}
    .callout.ok {border-right-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px; direction:ltr; unicode-bidi: plaintext;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-left:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 18px 6px 0;}
    .tight ol {margin: 6px 18px 6px 0;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # عناوين الخطوات + شارات
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] تأطير المشكلة والتحقق (Validation)",
        "[1] جودة البيانات والتحضير (NA، التواتر، القيم الشاذة)",
        "[2] الاستكشاف البصري (الاتجاه، الموسمية، التباين)",
        "[3] التفكيك/التحليل إلى مكونات (STL، جمعي/ضربي)",
        "[4] الاستقرارية والفرق (اختيار d و D و s) + الاختبارات",
        "[5] خط أساس (Naive / Auto-ARIMA) + معايير الاختيار",
        "[6] التحديد اليدوي (ACF/PACF) + قائمة نماذج مرشحة",
        "[7] التشخيص والمقارنة النهائية (بواقي + دقة التنبؤ)",
        "[8] التقرير والاستنتاج: الخلاصة ومعناها والمخرجات"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("الهدف", "الأفق", "البروتوكول", "المقاييس"),
        c("التواتر", "القيم الناقصة", "الشواذ", "التحويلات"),
        c("الرسوم", "الموسمية", "التباين", "الإشارة"),
        c("STL", "جمعي/ضربي", "البنية"),
        c("ADF/KPSS/PP", "d/D/s", "قواعد الاختيار"),
        c("خط الأساس", "AICc/BIC", "Naive"),
        c("ACF/PACF", "الاقتصاد في المعلمات", "مرشحات"),
        c("Ljung–Box", "ARCH", "الطبيعية", "الدقة"),
        c("تلخيص", "استنتاج", "المعنى", "قابلية الإعادة")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    criteria_block <- function(title, ...) {
      tags$div(class="box",
               tags$h5(title),
               ...
      )
    }
    
    # ------------------------------------------------------------
    # محتوى الخطوات (منظم للغاية)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =======================
      # (0) تأطير المشكلة
      # =======================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "تحديد مهمة التنبؤ بدقة (السلسلة، التواتر، الأفق، بروتوكول التحقق، المقاييس، وخطوط الأساس)، لأن أي مقارنة بدون ذلك تكون غير موثوقة.",
                                type="ok"
                        ),
                        
                        D("الهدف", open = TRUE,
                          tags$ul(
                            tags$li("تحديد المتغير الهدف ", tags$code("y_t"), " ووحدة القياس والتواتر (شبكة زمنية منتظمة)."),
                            tags$li("تحديد أفق التنبؤ ", tags$code("h"), " بما يطابق الاستخدام الفعلي."),
                            tags$li("تحديد بروتوكول التحقق: تقسيم زمني Train/Test أو أصل متحرك (Rolling-origin)."),
                            tags$li("تحديد المقاييس: MAE/RMSE (وMAPE/sMAPE حسب الحالة)."),
                            tags$li("تحديد خطوط الأساس: Naive وNaive موسمي إذا وُجدت موسمية.")
                          )
                        ),
                        
                        D("التحليلات المطلوبة", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 — تحديد التواتر والموسمية (s)",
                                                  tags$ul(
                                                    tags$li("تحديد مستوى التجميع: يومي/أسبوعي/شهري..."),
                                                    tags$li("اشتقاق ", tags$code("s"), " من التقويم: شهري s=12، ربع سنوي s=4، يومي مع أسبوعي s=7."),
                                                    tags$li("التحقق من انتظام الفواصل وعدم وجود تواريخ مكررة.")
                                                  )
                                   ),
                                   criteria_block("A2 — بروتوكول التحقق",
                                                  tags$ul(
                                                    tags$li(tags$b("تقسيم زمني: "), "التدريب على الماضي والاختبار على المستقبل."),
                                                    tags$li(tags$b("Rolling-origin: "), "تكرار التنبؤ عند عدة نقاط أصل لقياس أداء أكثر ثباتاً."),
                                                    tags$li("حجم نافذة الاختبار يُفضل أن يغطي موسماً كاملاً على الأقل عند الإمكان.")
                                                  )
                                   ),
                                   criteria_block("A3 — اختيار المقاييس",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE: "), "سهل التفسير ومتين نسبياً."),
                                                    tags$li(tags$b("RMSE: "), "يعاقب الأخطاء الكبيرة بشدة."),
                                                    tags$li(tags$b("MAPE: "), "يُستخدم فقط إذا كانت القيم موجبة وبعيدة عن الصفر."),
                                                    tags$li(tags$b("sMAPE: "), "بديل نسبي أكثر استقراراً من MAPE.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("معايير القرار (اختيارات واضحة)", open = TRUE,
                          tags$ul(
                            tags$li(tags$b("الأفق h: "), "يجب أن يطابق القرار/الاستخدام النهائي (قصير/طويل)."),
                            tags$li(tags$b("البروتوكول: "), "إذا توفرت بيانات كافية، Rolling-origin أفضل؛ وإلا تقسيم زمني واضح."),
                            tags$li(tags$b("المقاييس: "), "استخدم على الأقل MAE + RMSE لتجنب رؤية أحادية."),
                            tags$li(tags$b("خط الأساس: "), "إذا لم يتفوق النموذج عليه فالنتيجة التعليمية: النموذج غير مفيد لهذه المهمة.")
                          )
                        )
        ))
      }
      
      # =======================
      # (1) جودة البيانات
      # =======================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "جعل السلسلة قابلة للنمذجة: انتظام زمني، معالجة القيم الناقصة، فهم القيم الشاذة، وتبرير أي تحويل.",
                                type="ok"
                        ),
                        
                        D("الهدف", open = TRUE,
                          tags$ul(
                            tags$li("التحقق من انتظام التواريخ وعدم التكرار."),
                            tags$li("قياس القيم الناقصة (كمّاً وبنيةً) ومعالجتها بشكل مبرر."),
                            tags$li("تحديد القيم الشاذة (خطأ قياس أم حدث حقيقي)."),
                            tags$li("اختيار تحويل (log/Box–Cox) عند تغير التباين مع المستوى.")
                          )
                        ),
                        
                        D("مصطلحات (قابلة للطي)", open = FALSE,
                          TERM("القيم الناقصة (NA)",
                               "مشاهدة مفقودة عند زمن كان يجب أن توجد فيه قيمة.",
                               purpose="وجود NA قد يمنع تقدير SARIMA أو يسبب انحيازاً.",
                               criteria="الأهم ليس النسبة فقط، بل طول الفجوات وتواترها."),
                          TERM("الإحلال/الإكمال (Imputation)",
                               "تعويض القيم الناقصة بقيم محتملة.",
                               purpose="الحفاظ على انتظام السلسلة لإجراء النمذجة.",
                               criteria="الفجوات القصيرة: طرق بسيطة قد تكفي؛ الفجوات الطويلة: تتطلب تبريراً قوياً."),
                          TERM("قيمة شاذة (Outlier)",
                               "قيمة غير معتادة مقارنة بالسلوك العام.",
                               purpose="قد تشوه ACF/PACF والتقدير.",
                               criteria="إذا كانت خطأ → تصحيح/إزالة؛ إذا حدثاً حقيقياً → تُحفظ وتُشرح.")
                        ),
                        
                        D("معايير القرار", open = TRUE,
                          tags$ul(
                            tags$li(tags$b("الإحلال: "),
                                    "فجوات قصيرة → استيفاء خطي؛ موسمية قوية → استيفاء موسمي؛ فجوات طويلة → الحذر الشديد وربما تغيير التواتر/المصدر."),
                            tags$li(tags$b("الشواذ: "),
                                    "تقييم بالسياق؛ لا تحذف تلقائياً ما قد يمثل حدثاً يجب على التنبؤ احترامه."),
                            tags$li(tags$b("التحويل: "),
                                    "إذا التباين يزداد مع المستوى → log/Box–Cox مناسب.")
                          )
                        )
        ))
      }
      
      # =======================
      # (2) الاستكشاف البصري
      # =======================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "استخراج إشارات الاتجاه والموسمية وتغير التباين والقطوع (breaks) لتوجيه التحويل والفرق واختيار s.",
                                type="ok"
                        ),
                        
                        D("التحليلات المطلوبة + معاييرها", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 — الرسم الزمني",
                                                  tags$ul(
                                                    tags$li("المعيار: اتجاه واضح طويل المدى → d غالباً > 0."),
                                                    tags$li("المعيار: قفزة دائمة/تحول نظام → قد يلزم معالجة القطع (ليس SARIMA وحده دائماً).")
                                                  )
                                   ),
                                   criteria_block("A2 — الموسمية",
                                                  tags$ul(
                                                    tags$li("المعيار: نمط متكرر + قمم في ACF عند s,2s,... → موسمية قوية."),
                                                    tags$li("المعيار: boxplots حسب الشهر/الأسبوع تُظهر اختلافات ثابتة.")
                                                  )
                                   ),
                                   criteria_block("A3 — التباين",
                                                  tags$ul(
                                                    tags$li("المعيار: اتساع التذبذب يزداد مع المستوى → log/Box–Cox."),
                                                    tags$li("المعيار: تباين ثابت تقريباً → لا تحويل غالباً.")
                                                  )
                                   )
                          )
                        )
        ))
      }
      
      # =======================
      # (3) التفكيك
      # =======================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "تفكيك وصفي للاتجاه/الموسمية/البواقي لتبرير جمعي مقابل ضربي ولتوضيح البنية.",
                                type="ok"
                        ),
                        
                        D("مصطلحات ومعايير", open = TRUE,
                          TERM("تفكيك جمعي",
                               "y_t = T_t + S_t + e_t",
                               purpose="مناسب إذا كانت سعة الموسمية شبه ثابتة.",
                               criteria="قمم/قيعان موسمية لا تكبر مع ارتفاع المستوى.",
                               formula="y_t = T_t + S_t + e_t"),
                          TERM("تفكيك ضربي",
                               "y_t = T_t × S_t × e_t",
                               purpose="مناسب إذا كانت سعة الموسمية تكبر مع المستوى.",
                               criteria="قمم/قيعان موسمية أكبر عندما يكون المستوى أكبر.",
                               formula="y_t = T_t × S_t × e_t",
                               notes="غالباً log(y) يجعل البنية جمعية."),
                          TERM("STL",
                               "تفكيك موسمي-اتجاه باستخدام Loess.",
                               purpose="مرن ومتين عند تغير الموسمية أو وجود شواذ.",
                               criteria="موسمية غير ثابتة تماماً عبر الزمن أو شواذ واضحة.")
                        )
        ))
      }
      
      # =======================
      # (4) الاستقرارية + الاختبارات (تفصيل كبير)
      # =======================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("الهدف: "),
                                "اختيار d و D و s بحيث تصبح السلسلة (بعد الفرق) مستقرة تقريباً، وهو شرط أساسي لملاءمة SARIMA.",
                                type="ok"
                        ),
                        
                        D("معايير اختيار s و d و D", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("اختيار s",
                                                  tags$ul(
                                                    tags$li("من التقويم أولاً (شهري 12، أسبوعي 52، يومي-أسبوعي 7)."),
                                                    tags$li("من البيانات: قمم ACF عند s,2s,... ونمط موسمي واضح.")
                                                  )
                                   ),
                                   criteria_block("اختيار D (فرق موسمي)",
                                                  tags$ul(
                                                    tags$li("إذا كانت الموسمية قوية ومستمرة → D=1 غالباً كافٍ."),
                                                    tags$li("تجنب D=2 إلا نادراً جداً ومع تبرير قوي.")
                                                  )
                                   ),
                                   criteria_block("اختيار d (فرق غير موسمي)",
                                                  tags$ul(
                                                    tags$li("إذا كان هناك اتجاه عشوائي (unit root) → d=1 غالباً."),
                                                    tags$li("تجنب d=2 إلا نادراً جداً.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("الاختبارات (الغرض + معايير القرار)", open = TRUE,
                          
                          TEST(
                            name="ADF — ديكي-فولر المُعزَّز",
                            purpose=paste(
                              "الغرض هو كشف وجود جذر وحدوي (Unit Root) أي عدم استقرارية من نوع اتجاه عشوائي. ",
                              "يختبر ما إذا كان سلوك السلسلة يشبه المشي العشوائي، ويضيف فروقاً متأخرة للتعامل مع الارتباط الذاتي."
                            ),
                            when_to_use="لاختيار d والتحقق من أن السلسلة بعد الفرق أصبحت أقرب للاستقرارية.",
                            H0="يوجد جذر وحدوي → السلسلة غير مستقرة.",
                            H1="السلسلة مستقرة (حول متوسط أو حول اتجاه محدد حسب الإعداد).",
                            statistic="اختبار على معامل y_{t-1} في معادلة ADF مع فروق متأخرة.",
                            decision_rule="إذا p < 0.05 → نرفض H0 (استقرارية محتملة). إذا p ≥ 0.05 → لا نرفض H0 (قد تحتاج فرقاً إضافياً).",
                            interpretation="رفض H0 بعد تطبيق (d,D) يعني أن نمذجة ARMA (ومن ثم SARIMA) على السلسلة المُفرَّقة أصبحت منطقية.",
                            reporting="اذكر هل أدرجت drift/trend، عدد الإبطاءات، p-value والاستنتاج حول d.",
                            caveats="حساس لاختيار drift/trend وعدد الإبطاءات؛ والانقطاعات الهيكلية قد تضلل الاختبار."
                          ),
                          
                          TEST(
                            name="KPSS — الاستقرارية كفرضية صفرية",
                            purpose=paste(
                              "الغرض هو فحص الاستقرارية مباشرة لأن H0 هنا هي الاستقرارية. ",
                              "هذا يعاكس ADF ويُستخدم للتثليث (triangulation) عندما تختلف الفرضيات."
                            ),
                            when_to_use="لتأكيد الاستقرارية بعد الفرق ولتفسير النتائج مع ADF/PP.",
                            H0="السلسلة مستقرة (مستوى أو حول اتجاه حسب النسخة).",
                            H1="السلسلة غير مستقرة.",
                            statistic="إحصاء يعتمد على مجموع تراكمي لبواقي الانحدار وتقدير تباين طويل الأمد.",
                            decision_rule="إذا p < 0.05 → نرفض H0 (عدم استقرارية). إذا p ≥ 0.05 → متوافق مع الاستقرارية.",
                            interpretation="إذا KPSS لا يرفض بعد الفرق فهذا يدعم أن الفرق كان كافياً؛ وإذا رفض فقد تحتاج d/D أو توجد قطوع.",
                            reporting="حدد نسخة Level/Trend، p-value والاستنتاج.",
                            caveats="يتأثر بخيارات تقدير التباين طويل الأمد وبالقطوع الهيكلية."
                          ),
                          
                          TEST(
                            name="PP — فيليبس-بيرون (جذر وحدوي بتصحيح غير معلمي)",
                            purpose="مثل ADF لكنه يصحح الارتباط الذاتي/تغاير التباين بطريقة غير معلمية بدل إضافة إبطاءات كثيرة.",
                            when_to_use="كمكمل لـ ADF خصوصاً عندما تشك بوجود تغاير تباين أو ارتباط ذاتي يؤثر على ADF.",
                            H0="يوجد جذر وحدوي → عدم استقرارية.",
                            H1="استقرارية.",
                            statistic="إحصاء DF مع تصحيح للانحراف المعياري.",
                            decision_rule="p < 0.05 → رفض H0 → استقرارية محتملة.",
                            interpretation="توافق ADF وPP يعطي ثقة أعلى؛ اختلافهما يستدعي إعادة فحص الإعدادات والتشخيصات.",
                            reporting="أبلغ عن p-value والاستنتاج ضمن سياق التحويل/الفرق.",
                            caveats="حساس للقطوع، ويتأثر بإدراج drift/trend."
                          )
                        ),
                        
                        D("قواعد نهائية للاختيار (d,D)", open = TRUE,
                          tags$ul(
                            tags$li(tags$b("أفضل اتفاق: "), "ADF/PP يرفضان الجذر الوحدوي (p صغير) وKPSS لا يرفض الاستقرارية (p كبير)."),
                            tags$li(tags$b("عدم استقرارية واضحة: "), "ADF/PP لا يرفضان وKPSS يرفض."),
                            tags$li(tags$b("تجنب الإفراط في الفرق: "), "إذا ظهرت ACF سلبية قوية عند lag1 بعد الفرق → d كبير جداً.")
                          )
                        )
        ))
      }
      
      # =======================
      # (5) خط الأساس
      # =======================
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "بناء خط أساس واضح (Naive/Naive موسمي) + نموذج Auto-ARIMA قابل للتكرار قبل الاختيار النهائي.",
                                type="ok"
                        ),
                        
                        D("معايير الاختيار", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("AICc/BIC",
                                                  tags$ul(
                                                    tags$li("الأفضلية لـ AICc للتنبؤ غالباً؛ BIC أكثر صرامة في معاقبة التعقيد."),
                                                    tags$li("إذا ΔAICc < 2 → نماذج متقاربة → اختر الأبسط.")
                                                  )
                                   ),
                                   criteria_block("الأهم من AICc",
                                                  tags$ul(
                                                    tags$li("تشخيص البواقي (Ljung–Box) + أداء خارج العينة."),
                                                    tags$li("التفوق على Naive/Naive موسمي شرط عملي قوي.")
                                                  )
                                   )
                          )
                        )
        ))
      }
      
      # =======================
      # (6) ACF/PACF
      # =======================
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "اقتراح مجموعة صغيرة من المرشحين (3–8) بناءً على ACF/PACF ثم المقارنة وفق معايير واضحة.",
                                type="ok"
                        ),
                        
                        D("معايير تحديد p,q,P,Q", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("غير موسمي p,q",
                                                  tags$ul(
                                                    tags$li("PACF تقطع بعد p تقريباً → AR(p) مرشح."),
                                                    tags$li("ACF تقطع بعد q تقريباً → MA(q) مرشح."),
                                                    tags$li("حافظ على قيم صغيرة ما لم توجد ضرورة.")
                                                  )
                                   ),
                                   criteria_block("موسمي P,Q",
                                                  tags$ul(
                                                    tags$li("قمم PACF عند s → P=1 مرشح."),
                                                    tags$li("قمم ACF عند s → Q=1 مرشح."),
                                                    tags$li("غالباً P,Q ∈ {0,1}.")
                                                  )
                                   )
                          )
                        )
        ))
      }
      
      # =======================
      # (7) التشخيص النهائي
      # =======================
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "تأكيد أن البواقي لا تحتوي على بنية زمنية (≈ ضوضاء بيضاء) وأن التنبؤات تتفوق على خطوط الأساس.",
                                type="ok"
                        ),
                        
                        D("اختبارات البواقي (تفصيل)", open = TRUE,
                          TEST(
                            name="Ljung–Box",
                            purpose="اختبار ما إذا كانت الارتباطات الذاتية في البواقي حتى رتبة L تساوي صفراً بشكل إجمالي. إذا رُفض H0 فهناك بنية زمنية غير مُفسَّرة في النموذج.",
                            when_to_use="دائماً بعد ملاءمة SARIMA.",
                            H0="لا يوجد ارتباط ذاتي في البواقي حتى L.",
                            H1="يوجد ارتباط ذاتي في البواقي.",
                            decision_rule="p ≥ 0.05 → مقبول غالباً. p < 0.05 → عدّل النموذج (p/q/P/Q أو d/D).",
                            interpretation="رفض الاختبار يعني أن النموذج ترك معلومات زمنية في البواقي → تنبؤات أقل موثوقية.",
                            caveats="اختيار L مهم، ومع n كبير يصبح الاختبار حساساً."
                          ),
                          TEST(
                            name="ARCH LM",
                            purpose="كشف تكتل التذبذب (تغاير تباين شرطي). مهم عندما تكون السلسلة مالية أو يظهر تغير واضح في التباين عبر الزمن.",
                            when_to_use="عند الاشتباه بتغير التباين أو في السلاسل المالية.",
                            H0="لا توجد تأثيرات ARCH.",
                            H1="توجد تأثيرات ARCH.",
                            decision_rule="p < 0.05 → فكر في GARCH/نمذجة التباين.",
                            caveats="يتأثر بعدد الإبطاءات ووجود شواذ."
                          )
                        ),
                        
                        D("معايير الاختيار النهائي", open = TRUE,
                          tags$ul(
                            tags$li("يتفوق على Naive/Naive موسمي في MAE/RMSE."),
                            tags$li("Ljung–Box غير دال (p≥0.05) عند لاغات معقولة."),
                            tags$li("إذا تعادل الأداء تقريباً → اختر الأبسط.")
                          )
                        )
        ))
      }
      
      # =======================
      # (8) التقرير والخلاصة
      # =======================
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("الهدف: "),
                                "صياغة خلاصة واضحة: ما النموذج؟ لماذا؟ ماذا يعني ذلك؟ وما حدود الاستنتاج؟",
                                type="ok"
                        ),
                        
                        D("صيغة SARIMA", open = TRUE,
                          tags$ul(
                            tags$li(
                              tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
                              " حيث ",
                              tags$code("ε_t ~ w.n.(0, σ^2)")
                            )
                          )
                        ),
                        
                        D("قالب خاتمة جاهز", open = FALSE,
                          tags$p(
                            tags$b("خلاصة (نموذج نص). "),
                            "« تم اختيار النموذج النهائي SARIMA((p,d,q)(P,D,Q)[s]) بعد تثبيت s واختيار d وD بناءً على اختبارات ADF/KPSS/PP والتشخيصات. ",
                            "أظهرت بواقي النموذج سلوكاً قريباً من الضوضاء البيضاء (Ljung–Box غير دال عند α=0.05)، ",
                            "كما تفوقت التنبؤات خارج العينة على خطوط الأساس (Naive/Naive موسمي) وفق MAE وRMSE. ",
                            "يعني ذلك أن البنية الزمنية الأساسية (اتجاه/موسمية/اعتماد قصير الأجل) قد تم التقاطها بشكل ملائم ضمن حدود ثبات البنية عبر الزمن. »"
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "خطوة غير معروفة.")
    }
    
    # ----------------------------
    # شريط التمرير
    # ----------------------------
    k <- input$roadmap_step_ar
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "خارطة طريق SARIMA (مفصلة جداً) — العربية الفصحى"),
                          tags$p(class="road-sub",
                                 "استخدم شريط التمرير للتنقل دون تمرير الصفحة. كل خطوة: الهدف → التحليلات → الاختبارات → معايير القرار → المخرجات → الأخطاء الشائعة."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_ar",
                 label   = "الخطوة (شريط تمرير — لا حاجة للتمرير داخل الصفحة)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  # ============================================================
  # EXTREMELY DETAILED SARIMA ROADMAP (FR) — Slider + Collapsibles
  # Expanded with: detailed explanatory sentences for definitions + workflow steps
  # Organized by: Objectif → Analyses → Tests → Critères → Sorties → Pièges
  #
  # HOW TO USE
  # 1) In your UI:   uiOutput("roadmap_Detailed_Fr_ui")
  # 2) In server(): paste EVERYTHING below inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui7 <- renderUI({
    
    # ----------------------------
    # Helpers: accordion building
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # level 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # level 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    # A paragraph helper for readable long sentences
    P <- function(...) tags$p(...)
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
                     notes = NULL, how_to_apply = NULL, what_to_write = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("Définition : "), definition),
                 if (!is.null(purpose))       P(tags$b("But / utilité : "), purpose) else NULL,
                 if (!is.null(criteria))      P(tags$b("Critères / indices : "), criteria) else NULL,
                 if (!is.null(how_to_apply))  P(tags$b("Comment l’utiliser dans l’analyse : "), how_to_apply) else NULL,
                 if (!is.null(formula))       P(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example))       P(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(what_to_write)) P(tags$b("Phrase type (à écrire) : "), what_to_write) else NULL,
                 if (!is.null(notes))         P(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("But (très détaillé) : "), purpose),
                 P(tags$b("Quand l’utiliser : "), when_to_use),
                 P(tags$b("H0 : "), H0),
                 P(tags$b("H1 : "), H1),
                 if (!is.null(statistic))                P(tags$b("Statistique / idée : "), statistic) else NULL,
                 if (!is.null(decision_rule))            P(tags$b("Règle de décision : "), decision_rule) else NULL,
                 if (!is.null(interpretation))           P(tags$b("Interprétation (sens) : "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices))P(tags$b("Ce que ça implique pour vos choix : "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                P(tags$b("Comment le rapporter : "), reporting) else NULL,
                 if (!is.null(caveats))                  P(tags$b("Limites / pièges : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
    .tight ol {margin: 6px 0 6px 18px;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
    .muted {color:#555;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step labels & badges
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Cadrer le problème & la validation",
        "[1] Qualité des données & préparation (NA, fréquence, outliers)",
        "[2] Exploration visuelle (tendance, saison, variance)",
        "[3] Décomposition (additif/multiplicatif, STL)",
        "[4] Stationnarité & différenciation (choix d, D, s) + tests",
        "[5] Baseline (naïf / auto-ARIMA) + critères de sélection",
        "[6] Identification manuelle (ACF/PACF) + grille candidates",
        "[7] Diagnostics & comparaison finale (tests résidus + forecasting)",
        "[8] Rédaction: conclusion, signification, et livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Horizon", "Protocole", "Métriques"),
        c("Fréquence", "NA", "Outliers", "Transformations"),
        c("Graphiques", "Saisonnalité", "Variance", "Signal"),
        c("STL", "Additif vs multiplicatif", "Structure"),
        c("ADF/KPSS/PP", "d/D/s", "Règles de choix"),
        c("Baseline", "AICc/BIC", "Naïf"),
        c("ACF/PACF", "Parcimonie", "Candidats"),
        c("Ljung–Box", "ARCH", "Normalité", "Accuracy"),
        c("Synthèse", "Conclusion", "Sens", "Reproductible")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ----------------------------
    # Small helpers (criteria blocks)
    # ----------------------------
    criteria_block <- function(title, ..., note = NULL) {
      tags$div(class="box",
               tags$h5(title),
               if (!is.null(note)) tags$p(class="muted", note) else NULL,
               ...
      )
    }
    
    decision_rule_list <- function(...) {
      tags$ul(...)
    }
    
    # ------------------------------------------------------------
    # Step content (highly structured + expanded sentences)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================================================
      # STEP 0 — Cadrer
      # =========================================================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "définir clairement la tâche de prévision et un protocole d’évaluation fiable, car un modèle SARIMA ne peut pas être jugé correctement si l’objectif, l’horizon et la validation ne sont pas explicitement fixés dès le départ.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("À cette étape, l’étudiant doit produire une description opérationnelle du problème : quelle variable est prévue, sur quelle grille temporelle, avec quel horizon, et selon quelle règle d’évaluation. L’idée est simple : si deux étudiants choisissent des horizons ou des splits différents, ils ne répondent plus au même problème et leurs résultats ne sont pas comparables."),
                          tags$ul(
                            tags$li("Définir la cible ", tags$code("y_t"), " et la fréquence (régularité temporelle)."),
                            tags$li("Fixer un horizon ", tags$code("h"), " réaliste (usage métier / décision)."),
                            tags$li("Fixer un protocole de validation (train/test, rolling-origin) et les métriques (MAE/RMSE/...)."),
                            tags$li("Définir les benchmarks : naïf et naïf saisonnier si saison.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          P("Ici, on construit la “boîte noire” de l’évaluation : on s’assure que le temps est respecté (pas de mélange passé/futur), et on choisit des métriques qui correspondent aux coûts d’erreur. Un bon modèle pour RMSE n’est pas toujours celui qui optimise MAE : d’où l’intérêt d’en retenir au moins deux."),
                          tags$div(class="grid",
                                   criteria_block("A1 — Définir la fréquence & la saison (s)",
                                                  note = "Objectif : garantir que la série vit sur une grille régulière et que la saisonnalité s a une signification réelle (calendrier + données).",
                                                  tags$ul(
                                                    tags$li("Identifier la granularité : jour / semaine / mois / etc."),
                                                    tags$li("Déduire la saison ", tags$code("s"), " (ex : mensuel s=12, trimestriel s=4, quotidien hebdo s=7)."),
                                                    tags$li("Vérifier l’absence de trous ou doublons d’index (régularité).")
                                                  ),
                                                  P("Si la fréquence est irrégulière, SARIMA “voit” des retards qui ne représentent pas le même temps réel, ce qui casse la logique des dépendances (ACF/PACF) et rend les paramètres difficiles à interpréter.")
                                   ),
                                   criteria_block("A2 — Définir la validation",
                                                  note = "Objectif : mesurer la performance sur du futur non vu, comme dans la vraie vie.",
                                                  tags$ul(
                                                    tags$li(tags$b("Train/Test temporel : "), "entraîner sur le passé, tester sur le futur (jamais l’inverse)."),
                                                    tags$li(tags$b("Rolling-origin : "), "évaluer sur plusieurs origines → plus robuste."),
                                                    tags$li("Fixer la taille test : typiquement ≥ 1 saison (ex : ≥ 12 mois en mensuel) si possible.")
                                                  ),
                                                  P("Le rolling-origin est conseillé quand on veut enseigner la réalité opérationnelle : le modèle est mis à jour au fil du temps et évalué plusieurs fois, ce qui réduit le risque de “chance” sur un seul split.")
                                   ),
                                   criteria_block("A3 — Choisir métriques",
                                                  note = "Objectif : aligner la mesure d’erreur avec le sens métier (unités vs pénalisation des grosses erreurs).",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE : "), "robuste, lisible en unités."),
                                                    tags$li(tags$b("RMSE : "), "pénalise fortement les grosses erreurs."),
                                                    tags$li(tags$b("MAPE : "), "uniquement si y>0 et loin de 0 ; sinon préférer sMAPE/MAE."),
                                                    tags$li(tags$b("sMAPE : "), "alternative % plus stable que MAPE.")
                                                  ),
                                                  P("En pédagogie, MAE répond à la question : “en moyenne, je me trompe de combien ?”. RMSE répond à : “est-ce que j’évite vraiment les grosses erreurs ?”. Les deux ensemble donnent une lecture plus complète.")
                                   )
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          P("Les critères ci-dessous transforment l’étape 0 en décisions concrètes. À chaque décision, l’étudiant doit pouvoir expliquer pourquoi ce choix est cohérent avec le problème et comment il impacte la suite (stationnarité, saisonnalité, métriques)."),
                          decision_rule_list(
                            tags$li(tags$b("Horizon h : "), "doit correspondre au besoin. Exemple : si la décision est mensuelle (commande, budget), l’horizon doit être exprimé en mois et couvrir au moins une fenêtre utile de décision."),
                            tags$li(tags$b("Protocole : "), "si données suffisantes, préférer rolling-origin car il évalue plusieurs futurs. Si les données sont courtes, utiliser un split temporel clair et l’expliquer (dates exactes)."),
                            tags$li(tags$b("Métriques : "), "choisir au moins 2 (ex : MAE + RMSE) pour éviter de sur-optimiser une seule notion d’erreur."),
                            tags$li(tags$b("Benchmark : "), "toujours comparer à un naïf (et saisonnier si saison). Si votre modèle ne bat pas le naïf, la conclusion “négative” est informative : votre série est peut-être difficile, ou le modèle est incomplet.")
                          )
                        ),
                        
                        D("Définitions clés (cliquables)", open = FALSE,
                          TERM(
                            term="Série temporelle (y_t)",
                            definition="Une série temporelle est une séquence d’observations ordonnées par le temps, où chaque valeur y_t correspond à l’état du phénomène à l’instant t (par exemple, ventes mensuelles, température quotidienne, trafic horaire).",
                            purpose="Cette définition force à identifier clairement ce qui est observé, à quelle fréquence, et dans quelles unités, car SARIMA modélise la dépendance entre observations successives.",
                            criteria="On doit pouvoir répondre : quelle unité ? quelle fréquence ? quelles dates ? y_t contient-il des valeurs nulles ou négatives (important pour log/Box–Cox) ?",
                            how_to_apply="Avant toute modélisation, on vérifie que la série est triée par date, sans doublons, et que chaque pas de temps attendu est présent (ou explicitement manquant).",
                            what_to_write="« La variable d’intérêt y_t correspond à [définition], observée à une fréquence [..] entre [début] et [fin]. »"
                          ),
                          TERM(
                            term="Horizon de prévision (h)",
                            definition="L’horizon h est le nombre de pas dans le futur que l’on souhaite prédire. Par exemple, h=12 en mensuel signifie prévoir les 12 prochains mois.",
                            purpose="L’horizon définit la difficulté : plus h est grand, plus l’incertitude augmente et plus la saisonnalité/tendance doivent être correctement capturées.",
                            criteria="h doit être cohérent avec l’usage : prévoir 1 jour pour une décision annuelle n’a pas de sens, et prévoir 24 mois avec seulement 30 mois de données est risqué.",
                            how_to_apply="On fixe h avant de tester des modèles, car changer h change la conclusion (un modèle peut être excellent à court terme et moyen à long terme).",
                            formula="h"
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("À la fin de l’étape 0, l’étudiant doit pouvoir donner à n’importe qui une fiche-problème complète : si une autre personne refait l’analyse, elle doit obtenir la même configuration d’évaluation."),
                          tags$ul(
                            tags$li("Description complète de y_t (définition, unité, fréquence, dates)."),
                            tags$li("h + protocole (split/rolling) + métriques + benchmarks."),
                            tags$li("Règles de reproductibilité (seed si random, dates exactes du split).")
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Mélanger le temps (shuffle) : fuite d’information → résultats artificiellement élevés."),
                            tags$li("Comparer des modèles avec des splits différents → comparaison invalide."),
                            tags$li("MAPE avec y≈0 : l’erreur relative explose et peut dominer l’évaluation.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 1 — Qualité / Préparation
      # =========================================================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "garantir que la série est exploitable (grille régulière, NA traités, anomalies comprises) et surtout documenter chaque transformation, car une “petite correction” non expliquée peut changer totalement les tests (stationnarité, ACF/PACF) et donc la spécification SARIMA.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("L’objectif pédagogique est que l’étudiant distingue un problème de données (index, NA, erreur de saisie) d’un phénomène réel (événement, promotion, crise). SARIMA doit apprendre le comportement réel de la série : on corrige les erreurs, mais on ne supprime pas l’histoire."),
                          tags$ul(
                            tags$li("Vérifier fréquence régulière, dates uniques, tri temporel correct."),
                            tags$li("Détecter et traiter NA (selon nature du manque)."),
                            tags$li("Identifier outliers (erreur vs événement réel)."),
                            tags$li("Décider transformations (log/Box–Cox) si variance non constante.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          P("On suit une logique en quatre contrôles : (1) grille temporelle, (2) valeurs manquantes, (3) valeurs aberrantes, (4) transformation d’échelle. Chaque contrôle est associé à un choix, et chaque choix doit être justifié par un critère (pas “par habitude”)."),
                          tags$div(class="grid",
                                   criteria_block("A1 — Régularité temporelle",
                                                  note = "Objectif : s’assurer que “1 pas de temps” veut dire la même chose partout dans la série.",
                                                  tags$ul(
                                                    tags$li("Vérifier que chaque date attendue existe exactement une fois."),
                                                    tags$li("Vérifier l’espacement constant (pas d’irrégularité).")
                                                  ),
                                                  P("Si l’index est irrégulier, vous risquez d’induire de fausses autocorrélations (un retard de 1 n’est plus un intervalle constant). SARIMA doit reposer sur une base temporelle propre.")
                                   ),
                                   criteria_block("A2 — Manquants (NA)",
                                                  note = "Objectif : comprendre la structure du manque avant d’imputer.",
                                                  tags$ul(
                                                    tags$li("Mesurer %NA + longueurs de séquences manquantes (gaps)."),
                                                    tags$li("Décrire si le manque est structurel (jours fériés, pannes)."),
                                                    tags$li("Choisir une méthode d’imputation justifiée.")
                                                  ),
                                                  P("Un NA isolé ne pose pas la même question qu’un mois entier manquant. Plus le gap est long, plus l’imputation “invente” de l’information et doit être discutée dans le rapport.")
                                   ),
                                   criteria_block("A3 — Outliers",
                                                  note = "Objectif : décider si une valeur atypique est une erreur ou un signal réel que le modèle doit respecter.",
                                                  tags$ul(
                                                    tags$li("Détecter (IQR / z-score robuste / inspection) + valider contexte."),
                                                    tags$li("Décider : corriger (erreur) vs conserver (événement).")
                                                  ),
                                                  P("Un outlier peut être un événement réel (promo, rupture, changement politique). Le supprimer revient à dire “cela n’a jamais existé”, ce qui peut rendre vos prévisions irréalistes.")
                                   ),
                                   criteria_block("A4 — Transformation",
                                                  note = "Objectif : stabiliser la variance et rendre la dynamique plus “linéaire” pour SARIMA.",
                                                  tags$ul(
                                                    tags$li("Évaluer relation niveau↔variance (variance augmente avec le niveau ?)."),
                                                    tags$li("Tester log/Box–Cox si besoin."),
                                                    tags$li("Documenter l’inversion pour revenir à l’échelle originale.")
                                                  ),
                                                  P("Si l’amplitude des fluctuations augmente avec le niveau, un modèle sur les niveaux peut sur-réagir. La transformation log/Box–Cox rend souvent la saisonnalité plus additive et les résidus plus homogènes.")
                                   )
                          )
                        ),
                        
                        D("Définitions (cliquables)", open = FALSE,
                          TERM(
                            "NA / valeur manquante",
                            "Une valeur manquante (NA) signifie qu’à une date attendue, l’observation n’a pas été enregistrée. En série temporelle, cela peut être aléatoire (erreur de mesure) ou structurel (jours fériés, fermeture, capteur en panne).",
                            purpose="Les NA interrompent la continuité temporelle : SARIMA et les diagnostics ACF/PACF supposent une série complète, donc il faut soit imputer, soit adapter la fréquence/agrégation.",
                            criteria="On ne regarde pas seulement le pourcentage de NA, mais aussi leur structure : trous courts (1–2 points) vs longues séquences, périodicité du manque, et alignement avec le calendrier.",
                            how_to_apply="Commencez par compter les NA, puis visualisez leurs positions. Si les trous sont courts et rares, l’imputation simple est souvent acceptable. Si les trous sont longs, discutez l’impact (incertitude) et envisagez une solution alternative (agrégation, exclusion, autre source).",
                            what_to_write="« Les valeurs manquantes représentaient k=[..] points ([..]%), traitées par [méthode] car les gaps étaient [courts/rares] et la saisonnalité était [faible/forte]. »"
                          ),
                          TERM(
                            "Imputation",
                            "L’imputation consiste à remplacer une valeur manquante par une valeur plausible, construite à partir des observations voisines (linéaire) ou de la structure saisonnière (saisonnière).",
                            purpose="Elle permet de conserver une grille régulière et d’éviter que l’absence de données ne crée une rupture artificielle qui fausserait la stationnarité et les autocorrélations.",
                            criteria="Imputation simple si gaps très courts et dynamique lisse ; imputation saisonnière si saison forte ; prudence maximale si gaps longs.",
                            how_to_apply="Choisissez une méthode qui respecte la structure dominante : si saison forte, ne “lissez” pas au point d’effacer la saison. Après imputation, re-vérifiez les graphiques et l’ACF pour vous assurer que vous n’avez pas introduit de motifs artificiels.",
                            notes="Toujours justifier : une imputation est une hypothèse sur le monde réel."
                          ),
                          TERM(
                            "Outlier (aberrant)",
                            "Un outlier est une observation atypique par rapport au comportement habituel de la série. Il peut provenir d’une erreur (capteur, saisie) ou d’un événement réel (promotion, crise, rupture).",
                            purpose="Les outliers peuvent perturber l’identification (ACF/PACF) et l’estimation des paramètres, mais ils peuvent aussi représenter exactement ce que l’on veut prévoir (événements).",
                            criteria="La règle statistique (IQR, z-score) doit être complétée par le contexte : si l’événement est réel, il est souvent préférable de conserver et documenter.",
                            how_to_apply="Marquez les outliers sur le graphique, recherchez une explication, puis choisissez : corriger si impossible physiquement, sinon conserver. Si les outliers sont fréquents et structurés, envisagez un modèle d’intervention ou des variables exogènes (SARIMAX).",
                            what_to_write="« Les valeurs atypiques autour de [dates] ont été [conservées/ajustées] car [contexte]. »"
                          ),
                          TERM(
                            "Transformation Box–Cox",
                            "La transformation Box–Cox est une famille de transformations paramétrées (λ) qui vise à stabiliser la variance et parfois à rapprocher la distribution d’une forme plus symétrique. Le log est un cas particulier quand λ tend vers 0.",
                            purpose="Quand la variance augmente avec le niveau (série “en éventail”), Box–Cox aide SARIMA à modéliser une dynamique plus stable et à produire des résidus plus homogènes.",
                            criteria="Si amplitude saisonnière ou variance augmente avec le niveau, Box–Cox/log est souvent pertinent. Si variance stable, transformer peut être inutile et compliquer l’interprétation.",
                            how_to_apply="Appliquez la transformation, refaites les graphiques, puis refaites les diagnostics (ACF/PACF, stationnarité). Enfin, assurez-vous que vous savez revenir à l’échelle originale pour interpréter les prévisions.",
                            formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) si λ→0",
                            notes="Attention aux zéros/négatifs : il faut parfois un décalage (shift)."
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          P("Les critères ci-dessous traduisent les décisions de préparation. L’étudiant doit les appliquer comme une mini check-list, puis écrire une justification courte, mais explicite, pour chaque traitement."),
                          decision_rule_list(
                            tags$li(tags$b("Imputation : "),
                                    "si gaps très courts (ex : 1–2 points) et série relativement lisse → interpolation linéaire acceptable ; ",
                                    "si saison forte → imputation saisonnière préférable ; ",
                                    "si longs gaps → documenter fortement, envisager agrégation, exclusion, ou méthode modèle-based."),
                            tags$li(tags$b("Outliers : "),
                                    "si incohérence (valeur impossible) → corriger/supprimer ; ",
                                    "si événement réel → conserver et signaler ; éventuellement modèle d’intervention si l’impact est récurrent."),
                            tags$li(tags$b("Transformation : "),
                                    "si variance/amplitude saisonnière augmente avec le niveau → log/Box–Cox ; ",
                                    "si variance stable → pas de transformation (simplicité).")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("À la fin de l’étape 1, on doit pouvoir dire : “voici la série propre, voici ce qui a été modifié, et voici pourquoi”. Cela protège l’analyse contre les critiques et rend le travail pédagogique."),
                          tags$ul(
                            tags$li("Résumé de données : n, dates, fréquence, %NA, traitement NA."),
                            tags$li("Liste d’outliers + décision et justification."),
                            tags$li("Transformation retenue + justification + comment revenir à l’échelle originale.")
                          )
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer de longs trous sans discussion → conclusions fragiles car la dynamique imputée est spéculative."),
                            tags$li("Supprimer des outliers qui sont des événements → perdre l’information que la prévision devrait refléter."),
                            tags$li("Transformer (log/Box–Cox) sans expliquer l’inversion → prévisions difficiles à interpréter.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 2 — Exploration visuelle
      # =========================================================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "identifier tendance, saisonnalité, changements de variance, ruptures et anomalies afin de guider les décisions suivantes (transformation, différenciation, choix de s). Les graphiques servent ici de “preuve visuelle” qui complète les tests statistiques.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("Cette étape apprend à lire une série : reconnaître un mouvement de long terme (tendance), un motif qui se répète (saison), et des zones où la variance change. Ce sont exactement ces éléments que SARIMA va tenter de capturer (ou de rendre stationnaires par différenciation)."),
                          tags$ul(
                            tags$li("Visualiser la série brute et éventuellement transformée."),
                            tags$li("Détecter tendance (long terme) et saisonnalité (périodique)."),
                            tags$li("Repérer ruptures possibles et anomalies.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          P("On privilégie trois familles de graphiques : (1) la courbe temporelle, (2) les graphiques saisonniers, (3) des outils pour la variance. Ensuite, on relie chaque constat à une décision (log/Box–Cox, d, D, s)."),
                          tags$div(class="grid",
                                   criteria_block("A1 — Courbe temporelle",
                                                  note = "Objectif : repérer tendance, ruptures, périodes anormales, et intuition de stationnarité.",
                                                  tags$ul(
                                                    tags$li("Tracer y_t (et log/BC(y) si pertinent)."),
                                                    tags$li("Annoter périodes anormales (chocs, événements).")
                                                  ),
                                                  P("Une courbe qui “monte” durablement suggère un besoin de différenciation non saisonnière (d). Une courbe qui change brutalement de niveau peut signaler une rupture structurelle (le futur peut être différent du passé).")
                                   ),
                                   criteria_block("A2 — Saison",
                                                  note = "Objectif : confirmer la périodicité et estimer s.",
                                                  tags$ul(
                                                    tags$li("Seasonal plot / lignes par année (si mensuel)."),
                                                    tags$li("Boxplots par mois/trimestre/semaine."),
                                                    tags$li("ACF : pics aux multiples de s (indice fort de saison).")
                                                  ),
                                                  P("Si la saison est stable, le seasonal plot montre des motifs répétitifs. Si la saison est forte et persistante, une différenciation saisonnière (D=1) peut être nécessaire.")
                                   ),
                                   criteria_block("A3 — Variance",
                                                  note = "Objectif : détecter une variance non constante (hétéroscédasticité) avant modélisation.",
                                                  tags$ul(
                                                    tags$li("Comparer variabilité sur périodes faible vs forte moyenne."),
                                                    tags$li("Si variance augmente avec niveau → transformation.")
                                                  ),
                                                  P("Quand l’amplitude des fluctuations augmente avec le niveau, le modèle sur niveaux peut privilégier les périodes hautes. Une transformation (log/Box–Cox) rend souvent l’erreur plus homogène.")
                                   )
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          P("Ces critères relient directement les observations visuelles aux décisions de modélisation. L’étudiant doit écrire explicitement : ‘J’observe X, donc je choisis Y’."),
                          decision_rule_list(
                            tags$li(tags$b("Saisonnalité : "),
                                    "présence de motifs répétés et/ou pics ACF à s,2s,3s → saisonnalité probable, s doit correspondre au calendrier."),
                            tags$li(tags$b("Tendance : "),
                                    "niveau moyen qui dérive durablement et ACF qui décroît lentement → différenciation non saisonnière d probablement > 0."),
                            tags$li(tags$b("Variance non constante : "),
                                    "amplitude des fluctuations augmente quand le niveau augmente → log/Box–Cox, surtout si on veut des résidus plus homogènes.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("À la fin de l’étape 2, l’étudiant doit produire un paragraphe d’EDA : il ne suffit pas de montrer des figures, il faut expliquer ce qu’elles disent et ce que cela implique pour la suite."),
                          tags$ul(
                            tags$li("Commentaire EDA : tendance/saison/variance/outliers."),
                            tags$li("Hypothèses de travail : s plausible, besoin de transformation, besoin de d et/ou D.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 3 — Décomposition
      # =========================================================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "séparer descriptivement tendance/saison/bruit afin de clarifier la structure du signal et d’expliquer pourquoi on choisit une forme additive ou multiplicative. Cette étape n’est pas “le modèle”, mais un outil pour mieux décider.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("La décomposition est un langage pédagogique puissant : elle montre aux étudiants que la série n’est pas un “bloc” unique, mais un mélange de composants. Cela aide à justifier la transformation et à anticiper la différenciation."),
                          tags$ul(
                            tags$li("Décomposer y_t en composantes (tendance, saison, reste)."),
                            tags$li("Comparer additif vs multiplicatif (souvent via log)."),
                            tags$li("Utiliser STL si saison évolue ou si outliers présents.")
                          )
                        ),
                        
                        D("Tests / concepts clés", open = FALSE,
                          TERM(
                            "Décomposition additive",
                            "Dans une décomposition additive, la saisonnalité s’ajoute à la tendance : y_t = T_t + S_t + e_t. Cela signifie que l’écart saisonnier (pics-creux) reste à peu près de la même taille même si le niveau de la série change.",
                            purpose="Elle est utile quand la saison a une amplitude stable : la différence entre “mauvais mois” et “bon mois” est similaire à travers le temps.",
                            criteria="Visuellement, si les oscillations saisonnières ont une amplitude approximativement constante quelle que soit la hauteur du niveau, l’additif est approprié.",
                            how_to_apply="On peut comparer la série brute à log(y) : si log(y) rend la saison plus stable, on se rapproche d’un comportement additif dans l’espace transformé.",
                            formula="y_t = T_t + S_t + e_t",
                            what_to_write="« L’amplitude saisonnière semblant stable, nous avons adopté une lecture additive (y_t = T_t + S_t + e_t). »"
                          ),
                          TERM(
                            "Décomposition multiplicative",
                            "Dans une décomposition multiplicative, la saisonnalité agit comme un facteur proportionnel : y_t = T_t × S_t × e_t. Cela signifie que la saison ‘grossit’ quand le niveau de la série augmente.",
                            purpose="Elle est pertinente lorsque les périodes hautes ont des fluctuations saisonnières plus grandes que les périodes basses (effet de proportion).",
                            criteria="Si l’amplitude saisonnière augmente avec le niveau (éventail), la multiplicative est plausible.",
                            how_to_apply="On utilise souvent la transformation log pour passer d’une multiplicative à une additive : log(y_t) = log(T_t) + log(S_t) + log(e_t).",
                            formula="y_t = T_t × S_t × e_t",
                            notes="Souvent log(y_t) → structure additive sur log.",
                            what_to_write="« L’amplitude saisonnière augmentant avec le niveau, nous avons appliqué une transformation log afin d’obtenir une structure additive dans l’espace transformé. »"
                          ),
                          TERM(
                            "STL",
                            "STL (Seasonal-Trend decomposition using Loess) est une décomposition flexible qui permet à la saisonnalité d’évoluer lentement dans le temps et offre une meilleure robustesse face aux outliers.",
                            purpose="Elle est utile quand la saison n’est pas parfaitement stable (changement progressif des habitudes, croissance, évolution du calendrier).",
                            criteria="Si le seasonal plot montre une saison qui se déforme légèrement au fil des années, STL est souvent préférable à la décomposition classique.",
                            how_to_apply="On utilise STL pour décrire la structure et guider les choix. Ensuite, on revient aux diagnostics de stationnarité (tests + ACF) pour préparer SARIMA.",
                            notes="STL décrit; ne remplace pas la stationnarité requise pour SARIMA."
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          P("Le but n’est pas de “choisir STL pour faire joli”, mais de justifier un raisonnement cohérent : forme de saison → transformation → stationnarité plus plausible → SARIMA plus stable."),
                          decision_rule_list(
                            tags$li(tags$b("Additif : "), "si amplitude saisonnière ~ constante → modèle additif."),
                            tags$li(tags$b("Multiplicatif : "), "si amplitude saisonnière ∝ niveau → log/Box–Cox puis additif dans l’espace transformé."),
                            tags$li(tags$b("STL : "), "si saison évolutive ou outliers → STL préférable pour une lecture descriptive robuste.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("On attend une figure de décomposition et un paragraphe court reliant le diagnostic à une décision (transformation, type de saison)."),
                          tags$ul(
                            tags$li("Figure(s) de décomposition + commentaire tendance/saison."),
                            tags$li("Décision argumentée : additif vs multiplicatif (+ transformation).")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 4 — Stationnarité & différenciation + tests
      # =========================================================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "choisir ", tags$code("d"), ", ", tags$code("D"), " et ", tags$code("s"),
                          " afin d’obtenir une série (après différenciation) approximativement stationnaire. En pratique, on cherche la stationnarité “suffisante” (pas parfaite) avec le minimum de différenciation, car la sur-différenciation rend le modèle instable.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("Cette étape est le pivot SARIMA : vous décidez combien de tendance et de saison vous retirez pour laisser au modèle AR/MA la tâche d’expliquer la dépendance restante. Les tests (ADF/KPSS/PP) ne remplacent pas les graphiques : on les utilise ensemble pour trianguler."),
                          tags$ul(
                            tags$li("Fixer la saison ", tags$code("s"), " (à partir des données/du contexte)."),
                            tags$li("Choisir ", tags$code("d"), " (diff. non saisonnière) et ", tags$code("D"), " (diff. saisonnière)."),
                            tags$li("Justifier le choix avec : EDA + ACF/PACF + tests (ADF/KPSS/PP) + règles anti-sur-différenciation.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          P("Le workflow recommandé est : (1) choisir s, (2) tester D, (3) tester d, (4) re-vérifier stationnarité, (5) vérifier qu’on n’a pas sur-différencié. On préfère des valeurs petites : d∈{0,1} et D∈{0,1} dans la plupart des cas."),
                          tags$div(class="grid",
                                   criteria_block("A1 — Choisir s (période saisonnière)",
                                                  note = "Décision basée sur le calendrier + confirmation empirique via ACF/seasonal plot.",
                                                  tags$ul(
                                                    tags$li("Connaissance du calendrier (mensuel→12, trimestriel→4, quotidien hebdo→7, etc.)."),
                                                    tags$li("Indices empiriques : pics ACF à s,2s,... ; pattern stable sur seasonal plot."),
                                                    tags$li("Si ambigu : tester quelques s plausibles et comparer diagnostics.")
                                                  ),
                                                  P("s doit avoir une signification temporelle. Par exemple, en mensuel, s=12 est naturel. S’il y a une saison commerciale “semi-annuelle”, s=6 peut aussi être testé, mais doit être défendu par les données.")
                                   ),
                                   criteria_block("A2 — Décider D (diff saisonnière)",
                                                  note = "Objectif : retirer une non-stationnarité saisonnière persistante (racine unitaire saisonnière).",
                                                  tags$ul(
                                                    tags$li("Si forte saisonnalité persistante année-sur-année → envisager D=1."),
                                                    tags$li("Indices : ACF très forte au lag s sur la série brute; saison non supprimée par simple d."),
                                                    tags$li("Vérifier sur-diff : ACF lag s très négative après D=1 → signe D trop grand.")
                                                  ),
                                                  P("La différenciation saisonnière compare y_t à y_{t-s}. Si après D=1 vous observez une alternance artificielle (pics négatifs marqués), vous avez peut-être retiré trop de saison.")
                                   ),
                                   criteria_block("A3 — Décider d (diff non-saisonnière)",
                                                  note = "Objectif : retirer une tendance stochastique (unit root non saisonnier).",
                                                  tags$ul(
                                                    tags$li("Si tendance stochastique (unit root) → d=1 est souvent suffisant."),
                                                    tags$li("Indices : ACF décroit lentement sur la série brute; tests unit root."),
                                                    tags$li("Sur-diff : ACF lag1 très négative après diff → d trop grand.")
                                                  ),
                                                  P("d=1 correspond à modéliser les variations plutôt que les niveaux. Si les variations semblent stables, SARIMA est souvent plus fiable. d=2 est rarement nécessaire et doit être fortement justifié.")
                                   )
                          )
                        ),
                        
                        D("Définitions indispensables (cliquables)", open = FALSE,
                          TERM(
                            "Différenciation ordinaire (d)",
                            "Différencier une série consiste à remplacer y_t par la variation entre deux instants consécutifs : ∇y_t = y_t − y_{t−1}. Répéter l’opération d fois revient à retirer progressivement une tendance stochastique.",
                            purpose="Le but est d’obtenir une série dont la moyenne et la variance sont plus stables dans le temps, afin que les dépendances restantes puissent être capturées par les composantes AR/MA.",
                            criteria="d est généralement 0 ou 1. d=2 indique souvent une série très particulière ou un problème de spécification (ou de rupture).",
                            how_to_apply="On commence par d=0, puis d=1 si nécessaire. Après chaque essai, on examine la série différenciée, l’ACF et les tests unit root. On s’arrête dès que la stationnarité est raisonnable.",
                            formula="(1-B)^d y_t",
                            what_to_write="« Les diagnostics suggéraient une tendance stochastique ; nous avons appliqué une différenciation ordinaire (d=1) et revérifié la stationnarité. »"
                          ),
                          TERM(
                            "Différenciation saisonnière (D)",
                            "Différencier saisonnièrement consiste à comparer une observation à celle d’une saison précédente : ∇_s y_t = y_t − y_{t−s}. Cela retire une composante saisonnière persistante.",
                            purpose="Le but est de supprimer une non-stationnarité saisonnière (racine unitaire saisonnière) afin que la saison soit ensuite modélisée par les termes AR/MA saisonniers (P,Q).",
                            criteria="D est très souvent 0 ou 1. D=2 est rare et doit déclencher une re-vérification de s et de la qualité des données.",
                            how_to_apply="On essaie D=0 puis D=1 si la saison persiste fortement. Après D=1, on surveille les symptômes de sur-diff saisonnière (ACF très négative au lag s).",
                            formula="(1-B^s)^D y_t",
                            what_to_write="« La saisonnalité persistante a motivé une différenciation saisonnière (D=1) avec période s=[..]. »"
                          ),
                          TERM(
                            "Sur-différenciation",
                            "La sur-différenciation signifie retirer plus de structure que nécessaire. Elle peut créer une dynamique artificielle, comme une forte autocorrélation négative au premier retard, et rendre les prévisions plus instables.",
                            purpose="Éviter la sur-différenciation protège la stabilité des paramètres et limite l’amplification du bruit.",
                            criteria="Symptômes typiques : ACF au lag 1 très négative après d, ou ACF au lag s très négative après D. Prévisions qui oscillent de manière excessive.",
                            how_to_apply="Si les symptômes apparaissent, réduire d ou D, puis re-tester. La règle pédagogique : ‘minimum de différences pour stationnariser’.",
                            notes="Mieux vaut minimal : juste assez pour stationnariser."
                          )
                        ),
                        
                        D("Tests (purpose + critères détaillés)", open = FALSE,
                          
                          TEST(
                            name="ADF — Augmented Dickey–Fuller (racine unitaire)",
                            purpose=paste(
                              "Le test ADF vise à détecter une racine unitaire, c’est-à-dire une non-stationnarité où les chocs ont des effets persistants. ",
                              "Il examine si le niveau passé y_{t-1} explique Δy_t d’une façon compatible avec une marche aléatoire. ",
                              "Les retards de Δy_t sont ajoutés pour neutraliser l’autocorrélation et éviter un test trompeur."
                            ),
                            when_to_use="Pour décider si une différenciation non saisonnière (d) est nécessaire, puis pour valider que la série (après d et éventuellement D) est compatible avec la stationnarité.",
                            H0="La série a une racine unitaire → non-stationnaire (tendance stochastique).",
                            H1="La série est stationnaire (selon la spécification : avec ou sans drift/trend).",
                            statistic="Régression ADF : Δy_t ~ α + β t + γ y_{t-1} + Σ δ_i Δy_{t-i}. Le test porte sur γ avec des valeurs critiques spécifiques.",
                            decision_rule="Avec α=0.05 : si p-value < 0.05 → rejet H0 → stationnarité plausible. Si p-value ≥ 0.05 → non-rejet → d potentiellement insuffisant (ou rupture/ mauvaise spécification drift/trend).",
                            interpretation="Rejeter H0 signifie que la série n’a pas l’allure d’une marche aléatoire : elle tend à revenir vers un comportement stable (moyenne ou tendance déterministe).",
                            what_it_means_for_choices="Si ADF ne rejette pas sur la série brute, vous testez d=1 (et/ou D=1 si saison). Si ADF rejette après transformation, vous pouvez passer à l’identification ACF/PACF pour p,q,P,Q.",
                            reporting="Indiquer la version (avec drift / avec trend), le nombre de retards, la statistique, la p-value, et la décision sur d.",
                            caveats="Sensibilité au choix drift/trend et au nombre de retards. Les ruptures structurelles peuvent faire ‘sembler’ non-stationnaire une série qui change de régime."
                          ),
                          
                          TEST(
                            name="KPSS — Kwiatkowski–Phillips–Schmidt–Shin (stationnarité comme H0)",
                            purpose=paste(
                              "KPSS complète ADF en inversant l’hypothèse nulle : ici, la stationnarité est supposée vraie tant que les données ne la contredisent pas. ",
                              "Le test mesure si une composante de marche aléatoire résiduelle est trop grande pour être compatible avec une série stationnaire."
                            ),
                            when_to_use="Après ADF/PP, pour trianguler, et particulièrement utile quand ADF est ambigu. On l’utilise sur la série brute et sur la série différenciée.",
                            H0="La série est stationnaire (en niveau) OU stationnaire autour d’une tendance (selon version).",
                            H1="La série est non-stationnaire.",
                            statistic="Statistique basée sur la somme cumulée des résidus et une estimation de variance longue (bandwidth).",
                            decision_rule="Avec α=0.05 : si p-value < 0.05 → rejet H0 → non-stationnaire. Si p-value ≥ 0.05 → compatible avec stationnarité.",
                            interpretation="Un KPSS non significatif après différenciation renforce que la transformation a stabilisé la série ; un KPSS significatif suggère que la série garde une dérive ou une structure non stationnaire.",
                            what_it_means_for_choices="Convergence ADF/PP (rejet unit root) + KPSS (non-rejet stationnarité) = feu vert pour passer à p,q,P,Q. Si KPSS rejette, reconsidérer d/D ou la présence de rupture.",
                            reporting="Préciser version (level/trend), statistique, p-value, et conclusion sur stationnarité.",
                            caveats="Dépend du choix de variance longue. Très sensible aux ruptures : une série avec changement de niveau peut faire rejeter KPSS même si elle est localement stationnaire."
                          ),
                          
                          TEST(
                            name="PP — Phillips–Perron (racine unitaire avec correction non-paramétrique)",
                            purpose=paste(
                              "PP teste aussi la racine unitaire comme ADF, mais corrige l’autocorrélation et l’hétéroscédasticité de manière non paramétrique ",
                              "au lieu d’ajouter de nombreux retards. Cela peut être utile lorsque l’ADF dépend trop du choix du nombre de retards."
                            ),
                            when_to_use="En complément/alternative à ADF, surtout si vous suspectez autocorrélation ou variance non constante dans la régression ADF.",
                            H0="Racine unitaire → non-stationnaire.",
                            H1="Stationnaire.",
                            statistic="Statistique DF corrigée par estimation robuste de variance.",
                            decision_rule="Avec α=0.05 : p-value < 0.05 → rejet H0 → stationnarité plausible.",
                            interpretation="Si PP et ADF vont dans le même sens, la conclusion est plus solide. En cas de désaccord, on revient aux diagnostics visuels et à l’ACF.",
                            what_it_means_for_choices="Concordance ADF+PP: confiance plus élevée pour fixer d. Désaccord: tester une autre spécification (drift/trend), vérifier ruptures, recontrôler transformation.",
                            reporting="Rapporter statistique, p-value, spécification (drift/trend) et transformation utilisée.",
                            caveats="Comme ADF : dépend du drift/trend. Les ruptures peuvent biaiser la conclusion."
                          )
                        ),
                        
                        D("Critères de choix (décision) — d, D, s", open = TRUE,
                          P("L’étudiant doit appliquer ces règles comme une procédure : (1) choisir s, (2) essayer D, (3) essayer d, (4) contrôler sur-diff, (5) retenir la solution la plus simple qui rend la stationnarité raisonnable."),
                          tags$div(class="grid",
                                   
                                   criteria_block("Règle 1 — Triangulation ADF/KPSS/PP",
                                                  note = "Objectif : ne pas dépendre d’un seul test, car leurs hypothèses nulles diffèrent.",
                                                  tags$ul(
                                                    tags$li(tags$b("Stationnaire plausible : "), "ADF/PP rejettent (p<.05) ET KPSS ne rejette pas (p≥.05)."),
                                                    tags$li(tags$b("Non-stationnaire : "), "ADF/PP ne rejettent pas ET KPSS rejette."),
                                                    tags$li(tags$b("Conflit : "), "s’appuyer sur ACF/PACF + visualisation + minimiser la différenciation (éviter sur-diff).")
                                                  ),
                                                  P("En cas de conflit, l’étudiant doit écrire que la décision repose sur la convergence des indices (tests + ACF + plots), pas sur une seule p-value.")
                                   ),
                                   
                                   criteria_block("Règle 2 — Éviter la sur-différenciation",
                                                  note = "Objectif : préserver une dynamique interprétable et stable.",
                                                  tags$ul(
                                                    tags$li(tags$b("Sur-diff d : "), "ACF lag1 très négative après diff; variance augmente; modèle instable."),
                                                    tags$li(tags$b("Sur-diff D : "), "ACF au lag s très négative après diff saisonnière."),
                                                    tags$li("Si sur-diff suspectée → réduire d ou D et réévaluer tests/ACF.")
                                                  ),
                                                  P("Un bon critère pédagogique : si vous devez monter à d=2 ou D=2, stop et réexaminez (s, données, ruptures).")
                                   ),
                                   
                                   criteria_block("Règle 3 — Valeurs typiques",
                                                  note = "Objectif : démarrer simple, complexifier seulement si nécessaire.",
                                                  tags$ul(
                                                    tags$li(tags$b("d : "), "souvent 0 ou 1 (2 très rare)."),
                                                    tags$li(tags$b("D : "), "souvent 0 ou 1 (2 très rare)."),
                                                    tags$li(tags$b("s : "), "déduit du calendrier; si incertain, tester alternatives plausibles.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("Cette étape doit se conclure par un choix clair (s,d,D) et une justification écrite en 2–4 phrases, incluant le sens de la décision : ‘nous modélisons ensuite les dépendances restantes via AR/MA’."),
                          tags$ul(
                            tags$li("Valeurs retenues : ", tags$code("s"), ", ", tags$code("d"), ", ", tags$code("D"), " + justification."),
                            tags$li("Courtes phrases de conclusion : « tests + ACF suggèrent stationnarité après ... »."),
                            tags$li("Avertissement si conflit entre tests → justification qualitative.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEPS 5–8 (kept complete; already detailed; add sentences where most needed)
      # =========================================================
      # NOTE: To keep copy/paste manageable, steps 5–8 are preserved but enriched with
      # short explanatory paragraphs at the start of each step (as above).
      #
      # If you want them expanded to the same “paragraph density” as steps 0–4,
      # tell me “expand steps 5–8 too” and I’ll paste the fully expanded version.
      
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "établir un point de comparaison solide (benchmarks) et une baseline auto-ARIMA, puis définir des critères de sélection qui combinent information (AICc/BIC), validité (diagnostics) et finalité (performance de prévision).",
                          type="ok"
                        ),
                        D("Objectif", open = TRUE,
                          P("L’étape baseline évite un piège classique : croire qu’un SARIMA complexe est forcément utile. Ici, un modèle doit d’abord battre des règles simples (naïf, naïf saisonnier)."),
                          tags$ul(
                            tags$li("Construire benchmarks : naïf (ŷ_{t+h}=y_t) et naïf saisonnier (ŷ_{t+h}=y_{t+h-s})."),
                            tags$li("Obtenir une baseline SARIMA via auto-ARIMA (AICc/BIC) — reproductible."),
                            tags$li("Définir critères de sélection : AICc + diagnostics + performance out-of-sample.")
                          )
                        ),
                        D("Tests / concepts (cliquables)", open = FALSE,
                          TERM("Naïf (random walk forecast)",
                               "Le modèle naïf prédit que le futur sera identique à la dernière valeur observée. Malgré sa simplicité, il est souvent difficile à battre sur des séries très persistantes.",
                               purpose="Benchmark minimal : si votre modèle ne bat pas le naïf, vous n’avez pas encore capturé plus d’information que la persistance brute.",
                               criteria="Comparer MAE/RMSE sur test. Si gain faible, préférer la simplicité.",
                               how_to_apply="Toujours calculer ses erreurs sur la même fenêtre test/rolling que les autres modèles.",
                               formula="ŷ_{t+h} = y_t"),
                          TERM("Naïf saisonnier",
                               "Le modèle naïf saisonnier prédit que la valeur future sera égale à la valeur observée à la même saison précédente (ex : même mois l’an passé).",
                               purpose="Benchmark crucial si saisonnalité forte : beaucoup de modèles ‘sophistiqués’ échouent à le battre.",
                               criteria="Surtout pertinent quand s est bien défini et la saison stable.",
                               how_to_apply="Évaluer sur au moins une saison complète si possible.",
                               formula="ŷ_{t+h} = y_{t+h-s}"),
                          TERM("AICc vs BIC",
                               "AICc et BIC comparent l’ajustement en pénalisant la complexité. AICc est souvent utilisé pour la performance prédictive; BIC pénalise davantage et favorise des modèles plus simples.",
                               purpose="Réduire le risque de sur-ajustement en évitant des modèles inutilement complexes.",
                               criteria="ΔAICc < 2 : modèles très proches → choisir le plus simple (parcimonie).",
                               how_to_apply="N’utiliser AICc/BIC que pour comparer des modèles estimés sur la même série (même transformation, mêmes données).")
                        ),
                        D("Critères de choix (décision)", open = TRUE,
                          P("Le meilleur modèle n’est pas celui qui minimise seulement AICc : il doit aussi passer les diagnostics et battre les benchmarks en prévision."),
                          tags$div(class="grid",
                                   criteria_block("Sélection par information (AICc/BIC)",
                                                  tags$ul(
                                                    tags$li("Choisir AICc minimal comme candidat initial."),
                                                    tags$li("Si plusieurs modèles avec ΔAICc < 2 → choisir le plus simple (moins de paramètres)."),
                                                    tags$li("Vérifier aussi BIC si vous privilégiez parcimonie.")
                                                  )
                                   ),
                                   criteria_block("Critère de validité",
                                                  tags$ul(
                                                    tags$li("Diagnostics résidus acceptables (Ljung–Box non significatif, etc.)."),
                                                    tags$li("Paramètres stables (stationnarité/inversibilité).")
                                                  )
                                   ),
                                   criteria_block("Critère de finalité (prévision)",
                                                  tags$ul(
                                                    tags$li("Amélioration claire vs benchmarks (naïf, naïf saisonnier)."),
                                                    tags$li("Si gain faible → préférer modèle plus simple/robuste.")
                                                  )
                                   )
                          )
                        ),
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Table baseline: benchmarks + auto-ARIMA (AICc, MAE/RMSE sur test)."),
                            tags$li("Baseline choisie comme point de départ (pas forcément final).")
                          )
                        )
        ))
      }
      
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "utiliser ACF/PACF pour construire une petite grille de modèles candidats, puis sélectionner par parcimonie + diagnostics. On cherche un raisonnement, pas une recherche brute-force.",
                          type="ok"
                        ),
                        D("Objectif", open = TRUE,
                          P("L’étudiant apprend que ACF/PACF sont des heuristiques : elles suggèrent des ordres plausibles, mais ne remplacent pas la comparaison et les diagnostics."),
                          tags$ul(
                            tags$li("Travailler sur la série stationnaire (après d/D)."),
                            tags$li("Lire ACF/PACF pour proposer p,q (et P,Q saisonniers)."),
                            tags$li("Construire une grille courte de candidats et les comparer.")
                          )
                        ),
                        D("Concepts (cliquables)", open = FALSE,
                          TERM("ACF",
                               "L’ACF mesure la corrélation entre la série et ses retards. Sur une série stationnaire, un motif de coupure/atténuation peut suggérer la présence de termes MA.",
                               purpose="Aide à proposer q et Q, et à détecter les pics saisonniers aux multiples de s.",
                               criteria="Pics marqués à s,2s,... → saison; coupure rapide aux petits lags → MA plausible.",
                               how_to_apply="Tracer l’ACF après différenciation; proposer q/Q petits (0–2) puis vérifier diagnostics.")
                          ,
                          TERM("PACF",
                               "La PACF mesure la corrélation partielle entre y_t et y_{t-k} en contrôlant les lags intermédiaires. Une coupure rapide peut suggérer un ordre AR.",
                               purpose="Aide à proposer p et P.",
                               criteria="Pics PACF aux petits lags → AR plausible; pics à s → AR saisonnier.",
                               how_to_apply="Tracer la PACF après différenciation; proposer p/P petits puis comparer.")
                          ,
                          TERM("Bandes de significativité ACF/PACF",
                               "Les bandes ±1.96/√n donnent une approximation pour juger si un pic est statistiquement notable.",
                               purpose="Éviter de sur-interpréter du bruit.",
                               criteria="Des pics isolés peuvent apparaître par hasard; on cherche des motifs cohérents.",
                               how_to_apply="Regarder la structure globale (décroissance, répétition) plutôt que 1 seul pic.")
                        ),
                        D("Critères de choix (décision)", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("Candidats non saisonniers (p,q)",
                                                  tags$ul(
                                                    tags$li(tags$b("p : "), "si PACF a 1–2 pics forts aux petits lags → p=1 ou 2 plausible."),
                                                    tags$li(tags$b("q : "), "si ACF a 1–2 pics forts → q=1 ou 2 plausible."),
                                                    tags$li("Garder petit : p,q ≤ 3 sauf justification forte.")
                                                  )
                                   ),
                                   criteria_block("Candidats saisonniers (P,Q)",
                                                  tags$ul(
                                                    tags$li(tags$b("P : "), "pics PACF au lag s → P=1 plausible."),
                                                    tags$li(tags$b("Q : "), "pics ACF au lag s → Q=1 plausible."),
                                                    tags$li("Souvent P,Q ∈ {0,1}.")
                                                  )
                                   ),
                                   criteria_block("Parcimonie et sélection",
                                                  tags$ul(
                                                    tags$li("Si ΔAICc < 2 entre candidats → choisir le plus simple."),
                                                    tags$li("Refuser modèles avec paramètres non stables (explosifs) même si AICc bon."),
                                                    tags$li("Toujours vérifier diagnostics résiduels ensuite.")
                                                  )
                                   )
                          )
                        ),
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Liste courte de candidats SARIMA((p,d,q)(P,D,Q)[s])."),
                            tags$li("Justification ACF/PACF + parcimonie."),
                            tags$li("Comparaison AICc/BIC + diagnostics préliminaires.")
                          )
                        )
        ))
      }
      
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "valider que les résidus ressemblent à du bruit blanc (modèle adéquat) et que la précision de prévision bat les benchmarks. Les tests résiduels servent à détecter ce que votre modèle n’a pas appris.",
                          type="ok"
                        ),
                        D("Objectif", open = TRUE,
                          P("On peut avoir un AICc excellent et un modèle mauvais si les résidus restent autocorrélés. Cette étape impose la discipline : d’abord la validité (résidus), ensuite la performance (prévision)."),
                          tags$ul(
                            tags$li("Vérifier résidus : pas d’autocorrélation restante, variance stable, pas d’ARCH important (si pertinent)."),
                            tags$li("Comparer performance de prévision sur test/rolling (MAE/RMSE/...)."),
                            tags$li("Choisir final : diagnostics OK + performance + parcimonie.")
                          )
                        ),
                        D("Tests résidus (purpose + critères détaillés)", open = FALSE,
                          TEST(
                            name="Ljung–Box (autocorrélation résiduelle)",
                            purpose=paste(
                              "Tester si les autocorrélations des résidus (jusqu’à un lag L) sont globalement nulles. ",
                              "C’est un test central : si H0 est rejetée, le modèle laisse une structure temporelle non expliquée, ce qui signifie que la spécification SARIMA est incomplète."
                            ),
                            when_to_use="Toujours après estimation, et idéalement pour plusieurs choix de L (ex : L=10, L=2s).",
                            H0="Résidus ~ bruit blanc jusqu’au lag L (pas d’autocorrélation).",
                            H1="Autocorrélation résiduelle présente.",
                            statistic="Q(L) agrège les autocorrélations résiduelles; ddl ajustés par fitdf.",
                            decision_rule="Avec α=0.05 : p-value ≥ 0.05 → acceptable; p-value < 0.05 → revoir (p,q,P,Q,d,D) ou transformation.",
                            interpretation="Un rejet suggère qu’il existe des motifs temporels restants (retards non modélisés, saison manquante, sous-différenciation, etc.).",
                            what_it_means_for_choices="Si rejet → ajouter/ajuster AR ou MA (saisonnier ou non), ou reconsidérer d/D. Si non rejet → passer à l’évaluation de prévision et au choix parcimonieux.",
                            reporting="Rapporter L, Q, p-value, fitdf, et conclure sur ‘résidus compatibles avec bruit blanc’.",
                            caveats="Choix de L important ; grand n rend le test très sensible."
                          )
                        ),
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Table comparative : (AICc/BIC) + MAE/RMSE (test) + Ljung–Box p-value (résidus)."),
                            tags$li("Décision finale : modèle retenu + justification (diagnostics + performance + simplicité).")
                          )
                        )
        ))
      }
      
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "écrire une conclusion complète et compréhensible : le modèle retenu, la preuve (diagnostics + performance), et le sens (ce que le modèle raconte sur la série et quelles limites il a).",
                          type="ok"
                        ),
                        D("Équation SARIMA (notation correcte)", open = TRUE,
                          tags$ul(
                            tags$li(
                              tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
                              " avec innovations ",
                              tags$code("ε_t ~ w.n.(0, σ^2)")
                            )
                          ),
                          tags$p(class="small",
                                 "Lecture : on stabilise la série par différenciation, puis AR/MA capturent la dépendance restante. Cette phrase doit être explicitée dans le rapport pour montrer que vous comprenez le rôle de chaque composant."
                          )
                        ),
                        D("Template de texte (prêt à copier)", open = TRUE,
                          P(
                            tags$b("Conclusion (exemple). "),
                            "« Le modèle final retenu était SARIMA((p,d,q)(P,D,Q)[s]) estimé sur la série [transformée / non transformée]. ",
                            "Les diagnostics (ACF/PACF + tests ADF/KPSS/PP) ont motivé le choix de d=[..], D=[..] et s=[..]. ",
                            "Les résidus étaient compatibles avec un bruit blanc (Ljung–Box non significatif pour L=[..], α=0.05), ce qui suggère que la dépendance temporelle principale a été capturée. ",
                            "En évaluation hors échantillon, MAE=[..] et RMSE=[..] amélioraient les benchmarks [naïf / naïf saisonnier]. ",
                            "Cela signifie que la série présente une structure [saisonnière / inertielle / chocs transitoires] qui persiste suffisamment pour produire des prévisions utiles à horizon h=[..]. ",
                            "Les limites incluent [ruptures possibles, variables exogènes non modélisées, volatilité]. »"
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "Étape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (très détaillée) — FR"),
                          tags$p(class="road-sub",
                                 "Slider pour naviguer sans défiler. Chaque étape suit : Objectif → Analyses → Tests → Critères → Sorties → Pièges. "
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Étape (slider — pas besoin de scroll)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  # ============================================================
  # SARIMA ROADMAP (FR) — Slider + Collapsibles
  # Structure enforced for EVERY step:
  # Objectif → Analyses → Tests → Critères → Sorties → Ce que les étudiants font (Checklist)
  # → Ce que les étudiants écrivent (papier) → Conclusion (APA) → Pièges
  #
  # HOW TO USE
  # 1) UI:     uiOutput("roadmap_Detailed_Fr_ui")
  # 2) server: paste EVERYTHING below inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui8 <- renderUI({
    
    # ----------------------------
    # Helpers: accordion building
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # top
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # nested
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    P <- function(...) tags$p(...)
    H <- function(txt) tags$h5(style="margin:8px 0 6px 0;", txt)
    
    Checklist <- function(items) {
      tags$ul(lapply(items, function(x) tags$li(HTML(paste0("&#x2610; ", x)))))
    }
    
    PaperBlock <- function(title, text) {
      tags$div(
        class="paper-block",
        tags$p(tags$b(title)),
        tags$p(text)
      )
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, how_to_apply = NULL,
                     formula = NULL, example = NULL, what_to_write = NULL, notes = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("Définition : "), definition),
                 if (!is.null(purpose))      P(tags$b("But / utilité : "), purpose) else NULL,
                 if (!is.null(criteria))     P(tags$b("Critères / indices : "), criteria) else NULL,
                 if (!is.null(how_to_apply)) P(tags$b("Comment l’utiliser (pas à pas) : "), how_to_apply) else NULL,
                 if (!is.null(formula))      P(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example))      P(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(what_to_write))P(tags$b("Phrase-type (à écrire) : "), what_to_write) else NULL,
                 if (!is.null(notes))        P(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("But (détaillé) : "), purpose),
                 P(tags$b("Quand l’utiliser : "), when_to_use),
                 P(tags$b("H0 : "), H0),
                 P(tags$b("H1 : "), H1),
                 if (!is.null(statistic))                P(tags$b("Statistique / idée : "), statistic) else NULL,
                 if (!is.null(decision_rule))            P(tags$b("Règle de décision : "), decision_rule) else NULL,
                 if (!is.null(interpretation))           P(tags$b("Interprétation (sens) : "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices))P(tags$b("Implication pour vos choix : "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                P(tags$b("Comment le rapporter : "), reporting) else NULL,
                 if (!is.null(caveats))                  P(tags$b("Limites / pièges : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    StepPage <- function(
    but_text,
    objectif, analyses, tests, criteres, sorties,
    checklist_items, paper_text, apa_text, pieges_items,
    open_objectif = TRUE, open_analyses = TRUE
    ) {
      tags$div(class="road-card tight",
               callout(tags$b("But : "), but_text, type="ok"),
               
               D("Objectif", open = open_objectif, objectif),
               D("Analyses", open = open_analyses, analyses),
               D("Tests", open = FALSE, tests),
               D("Critères", open = FALSE, criteres),
               D("Sorties", open = FALSE, sorties),
               
               D("Ce que les étudiants font (Checklist opérationnelle)", open = FALSE,
                 P("L’étudiant doit pouvoir cocher chaque point. Si un point n’est pas faisable, il doit écrire pourquoi (données insuffisantes, fréquence inadéquate, etc.)."),
                 Checklist(checklist_items)
               ),
               
               D("Ce que les étudiants écrivent (papier)", open = FALSE,
                 PaperBlock("Texte à insérer dans le rapport (version “papier”)", paper_text)
               ),
               
               D("Ce que les étudiants écrivent (Conclusion en format APA)", open = FALSE,
                 PaperBlock("Conclusion (APA) — formulation recommandée", apa_text)
               ),
               
               D("Pièges", open = FALSE,
                 tags$ul(lapply(pieges_items, tags$li))
               )
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
    .tight ol {margin: 6px 0 6px 18px;}
    .paper-block {border:1px dashed #ddd; border-radius:10px; padding:10px; background:#fcfcfc;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step labels & badges
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Cadrer le problème & la validation",
        "[1] Qualité des données & préparation (NA, fréquence, outliers)",
        "[2] Exploration visuelle (tendance, saison, variance)",
        "[3] Décomposition (additif/multiplicatif, STL)",
        "[4] Stationnarité & différenciation (choix d, D, s) + tests",
        "[5] Baseline (naïf / auto-ARIMA) + critères de sélection",
        "[6] Identification manuelle (ACF/PACF) + grille candidates",
        "[7] Diagnostics & comparaison finale (tests résidus + forecasting)",
        "[8] Rédaction: conclusion, signification, et livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Horizon", "Protocole", "Métriques"),
        c("Fréquence", "NA", "Outliers", "Transformations"),
        c("Graphiques", "Saisonnalité", "Variance", "Signal"),
        c("STL", "Additif vs multiplicatif", "Structure"),
        c("ADF/KPSS/PP", "d/D/s", "Règles de choix"),
        c("Baseline", "AICc/BIC", "Naïf"),
        c("ACF/PACF", "Parcimonie", "Candidats"),
        c("Ljung–Box", "ARCH", "Normalité", "Accuracy"),
        c("Synthèse", "Conclusion", "Sens", "Reproductible")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ------------------------------------------------------------
    # Step content with REQUIRED structure for ALL steps
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================
      # STEP 0
      # =========================
      if (k == 0) {
        return(StepPage(
          but_text = "Définir précisément le problème de prévision (quoi, quand, à quel horizon) et le protocole d’évaluation, car sans validation temporelle correcte, toute performance rapportée peut être artificielle.",
          objectif = tagList(
            P("L’objectif est de transformer une intuition (“je veux prévoir”) en une spécification testable. À la fin, tout lecteur doit comprendre : la variable prévue, la fréquence, l’horizon, et comment la performance est mesurée sans fuite d’information."),
            tags$ul(
              tags$li("Définir la série réponse ", tags$code("y_t"), " (unité, sens, source)."),
              tags$li("Définir la fréquence (quotidien/hebdo/mensuel) et vérifier la régularité de l’index."),
              tags$li("Définir l’horizon ", tags$code("h"), " et le protocole (split temporel / rolling-origin)."),
              tags$li("Définir les métriques (MAE/RMSE/...) + benchmarks (naïf, naïf saisonnier).")
            )
          ),
          analyses = tagList(
            P("On établit une “contrainte temporelle” : l’entraînement se fait uniquement sur le passé, et l’évaluation uniquement sur le futur. Ensuite, on choisit des métriques cohérentes avec le coût des erreurs."),
            tags$ul(
              tags$li(tags$b("Index & fréquence : "), "contrôler doublons, trous, et cohérence de la périodicité."),
              tags$li(tags$b("Validation : "), "définir clairement train/test (dates exactes) ou rolling-origin."),
              tags$li(tags$b("Métriques : "), "choisir au moins deux mesures complémentaires (ex. MAE + RMSE).")
            )
          ),
          tests = tagList(
            P("À l’étape 0, il n’y a généralement pas de test statistique “formel” indispensable. On consolide surtout des définitions et des règles de validation."),
            TERM(
              "Rolling-origin (origine glissante)",
              "Procédure où l’on ré-estime (ou met à jour) le modèle sur des fenêtres temporelles successives et on évalue la prévision sur plusieurs futurs.",
              purpose="Réduire le risque qu’un seul split soit “chanceux” et mesurer la robustesse du modèle dans des conditions réalistes.",
              criteria="À privilégier si la série est suffisamment longue; choisir un nombre d’origines qui couvre plusieurs périodes.",
              how_to_apply="Définir une première fenêtre d’entraînement, prévoir à horizon h, avancer l’origine, répéter, puis agréger les erreurs (moyenne/ médiane).",
              what_to_write="« La performance a été évaluée via une validation rolling-origin sur [K] origines, à horizon h=[..]. »"
            ),
            TERM(
              "Fuite d’information (data leakage)",
              "Situation où une information du futur influence l’entraînement, ce qui augmente artificiellement la performance.",
              purpose="Éviter des conclusions fausses sur la qualité du modèle.",
              criteria="Tout prétraitement (imputation, scaling, Box–Cox) doit être défini sur train puis appliqué au test.",
              how_to_apply="Séparer train/test d’abord, puis appliquer traitements (si possible) en respectant la chronologie.",
              notes="Le shuffle aléatoire en série temporelle est presque toujours une erreur."
            )
          ),
          criteres = tagList(
            P("Critères décisionnels : l’objectif est d’aboutir à une configuration unique (h, protocole, métriques) que l’on ne modifie plus ensuite pour ‘faire monter’ le score."),
            tags$ul(
              tags$li(tags$b("Horizon : "), "doit correspondre au besoin décisionnel (ex : planification mensuelle → h en mois)."),
              tags$li(tags$b("Protocole : "), "rolling-origin si données suffisantes; sinon split temporel explicite."),
              tags$li(tags$b("Métriques : "), "MAE + RMSE (minimum) ; MAPE seulement si y ne s’approche jamais de 0."),
              tags$li(tags$b("Benchmark : "), "si votre modèle ne bat pas le naïf (ou naïf saisonnier), conclusion négative mais valide.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Fiche-problème : y_t (définition, unité), dates début/fin, fréquence."),
              tags$li("Validation : h, protocole (split/rolling), période test (dates)."),
              tags$li("Métriques : MAE/RMSE/..., benchmarks retenus.")
            )
          ),
          checklist_items = c(
            "J’ai défini y_t (unité, source, sens).",
            "J’ai vérifié que l’index est régulier (pas de doublons, pas de trous non justifiés).",
            "J’ai fixé h et je peux expliquer pourquoi cet horizon est pertinent.",
            "J’ai défini un protocole (split temporel ou rolling-origin) avec des dates explicites.",
            "J’ai choisi ≥2 métriques et ≥1 benchmark (naïf + saisonnier si saison)."
          ),
          paper_text =
            "« Nous avons étudié une série temporelle univariée (y_t) observée à une fréquence [..] de [date début] à [date fin] (n=[..]). L’objectif était de produire des prévisions à horizon h=[..]. La performance a été évaluée avec [MAE, RMSE] selon un protocole [split temporel/rolling-origin], en comparant le modèle à des benchmarks [naïf / naïf saisonnier]. »",
          apa_text =
            "« En conclusion (Étape 0), le problème de prévision a été défini de manière opérationnelle (variable y_t, fréquence, horizon h) et un protocole d’évaluation temporel a été spécifié afin d’éviter toute fuite d’information. Cette définition garantit que les performances rapportées reflètent une capacité de généralisation vers le futur plutôt qu’un ajustement au passé. »",
          pieges_items = list(
            "Modifier h ou le split après avoir vu les scores (optimisation a posteriori).",
            "Utiliser un shuffle aléatoire ou une CV classique non temporelle.",
            "Comparer des modèles évalués sur des fenêtres test différentes.",
            "Utiliser MAPE lorsque y peut être proche de zéro (instabilité)."
          )
        ))
      }
      
      # =========================
      # STEP 1
      # =========================
      if (k == 1) {
        return(StepPage(
          but_text = "Rendre la série exploitable : une grille temporelle correcte, un traitement justifié des NA, et une gestion raisonnée des outliers et des transformations, car ces choix changent directement les tests de stationnarité et l’identification SARIMA.",
          objectif = tagList(
            P("L’étudiant apprend à distinguer un problème de données (erreurs, manquants) d’un signal réel (événement). Chaque correction doit être documentée et justifiée."),
            tags$ul(
              tags$li("Contrôler la régularité temporelle, l’unicité des dates et le tri chronologique."),
              tags$li("Quantifier et traiter les valeurs manquantes (NA)."),
              tags$li("Identifier les outliers et décider : corriger (erreur) ou conserver (événement)."),
              tags$li("Évaluer la nécessité de log/Box–Cox si variance non constante.")
            )
          ),
          analyses = tagList(
            P("On suit une chaîne logique : (1) index, (2) NA, (3) outliers, (4) transformation. Après chaque action, on re-vérifie visuellement que la série n’a pas été déformée de façon artificielle."),
            tags$ul(
              tags$li(tags$b("Index : "), "doublons, trous, fréquence réelle vs fréquence annoncée."),
              tags$li(tags$b("NA : "), "pourcentage + structure des gaps, choix d’imputation adapté."),
              tags$li(tags$b("Outliers : "), "détection statistique + validation contextuelle."),
              tags$li(tags$b("Transformation : "), "stabilisation variance; prévoir l’inversion pour interpréter les prévisions.")
            )
          ),
          tests = tagList(
            P("Ici encore, le cœur est conceptuel (définitions + critères). Les tests de résidus viendront plus tard."),
            TERM(
              "NA / valeur manquante",
              "Observation absente à une date attendue. En série temporelle, l’absence est souvent structurée (pannes, jours fériés) plutôt que purement aléatoire.",
              purpose="Les NA rompent la continuité et peuvent fausser ACF/PACF et l’estimation SARIMA si ignorés.",
              criteria="Regarder %NA et la structure : trous courts vs longs; périodicité du manque; alignement calendrier.",
              how_to_apply="Cartographier les NA, décider si on impute (gaps courts) ou si on change la fréquence/stratégie (gaps longs).",
              what_to_write="« Les NA représentaient [..]%, traités par [méthode] car [gaps courts/structure saisonnière]. »"
            ),
            TERM(
              "Imputation",
              "Remplacement d’une valeur manquante par une valeur plausible estimée à partir des voisins (linéaire) ou du motif saisonnier.",
              purpose="Conserver une grille régulière et éviter une rupture artificielle.",
              criteria="Simple si trous très courts; saisonnière si saison forte; prudence si trous longs.",
              how_to_apply="Imputer, puis re-tracer la série et vérifier que la saison/tendance n’a pas été artificiellement lissée.",
              notes="Toujours documenter : l’imputation est une hypothèse."
            ),
            TERM(
              "Outlier (aberrant)",
              "Valeur atypique pouvant être erreur (capteur) ou événement réel (promo, crise).",
              purpose="Peut perturber paramètres et diagnostics, mais peut aussi être un signal que la prévision doit refléter.",
              criteria="Combiner règle statistique (IQR/z-score robuste) + contexte.",
              how_to_apply="Marquer sur graphique, décider corriger/supprimer si impossible physiquement; conserver si événement réel.",
              what_to_write="« Les valeurs atypiques autour de [dates] ont été [conservées/ajustées] car [raison]. »"
            ),
            TERM(
              "Box–Cox / log",
              "Famille de transformations (paramètre λ) pour stabiliser la variance; log est un cas particulier (λ→0).",
              purpose="Rendre la variance plus homogène et souvent rendre la saison plus additive.",
              criteria="Variance/amplitude saisonnière augmente avec le niveau → transformation utile.",
              how_to_apply="Tester log/Box–Cox, re-vérifier les graphiques et stationnarité ensuite; prévoir l’inversion.",
              formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) si λ→0"
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("NA : "), "si trous courts → imputation simple; si saison forte → imputation saisonnière; si trous longs → discuter/adapter."),
              tags$li(tags$b("Outliers : "), "corriger/supprimer si erreur; conserver si événement; considérer SARIMAX/intervention si récurrent."),
              tags$li(tags$b("Transformation : "), "si variance non constante → log/Box–Cox; sinon éviter complexité inutile.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Série ‘propre’ + journal des traitements (quoi, quand, pourquoi)."),
              tags$li("Résumé NA (k, %) + méthode d’imputation et justification."),
              tags$li("Liste outliers + décision + justification."),
              tags$li("Transformation retenue (ou non) + règle d’inversion.")
            )
          ),
          checklist_items = c(
            "J’ai vérifié doublons/trous et confirmé la fréquence réelle.",
            "J’ai mesuré %NA et la structure des gaps (courts/longs).",
            "J’ai choisi une méthode NA et je peux la justifier.",
            "J’ai détecté des outliers et décidé corriger vs conserver avec justification.",
            "J’ai évalué la variance et décidé log/Box–Cox si nécessaire (avec inversion)."
          ),
          paper_text =
            "« La série a été contrôlée pour la régularité temporelle (dates uniques, pas de doublons). Les valeurs manquantes (k=[..], [..]%) ont été traitées par [méthode] car [raison]. Les observations atypiques ont été identifiées et [conservées/ajustées] en tenant compte du contexte [..]. Une transformation [log/Box–Cox] a été [appliquée/non appliquée] afin de [stabiliser la variance/maintenir l’interprétabilité]. »",
          apa_text =
            "« En conclusion (Étape 1), les données ont été rendues cohérentes sur une grille régulière et les traitements (NA, outliers, transformation) ont été documentés et justifiés. Cette préparation réduit le risque de diagnostics trompeurs et assure que les décisions SARIMA ultérieures reposent sur le signal plutôt que sur des artefacts de données. »",
          pieges_items = list(
            "Imputer longuement sans discussion (invention de signal).",
            "Supprimer des événements réels (perte d’information utile).",
            "Appliquer log/Box–Cox sans expliquer comment revenir à l’échelle originale.",
            "Faire l’imputation en utilisant des informations du futur (leakage)."
          )
        ))
      }
      
      # =========================
      # STEP 2
      # =========================
      if (k == 2) {
        return(StepPage(
          but_text = "Lire la série : repérer tendance, saisonnalité, rupture et variance pour transformer ces observations en décisions (transformation, s, besoin de d/D).",
          objectif = tagList(
            P("L’objectif est de produire un diagnostic narratif : ce que montrent les graphes et comment cela influence la suite. On ne ‘met pas des figures’ : on écrit ce qu’elles prouvent."),
            tags$ul(
              tags$li("Visualiser la série (brute et éventuellement transformée)."),
              tags$li("Détecter tendance, saison et anomalies visibles."),
              tags$li("Évaluer la stabilité de variance et la présence de ruptures possibles.")
            )
          ),
          analyses = tagList(
            tags$ul(
              tags$li(tags$b("Courbe temporelle : "), "forme globale, tendances, zones anormales."),
              tags$li(tags$b("Graphiques saisonniers : "), "seasonal plot, boxplots par mois/semaine."),
              tags$li(tags$b("ACF (exploratoire) : "), "pics aux multiples de s pour confirmer la saison."),
              tags$li(tags$b("Variance : "), "amplitude augmente-t-elle avec le niveau ?")
            ),
            P("Chaque observation doit déboucher sur une hypothèse : ‘s=..’, ‘transformation nécessaire’, ‘d probable’, ‘D probable’, ou ‘rupture à discuter’.")
          ),
          tests = tagList(
            P("Peu de tests formels ici : on ancre surtout des définitions opérationnelles qui guideront les choix."),
            TERM(
              "Tendance",
              "Évolution de long terme du niveau moyen (hausse/baisse durable).",
              purpose="Une tendance persistante suggère souvent une non-stationnarité nécessitant une différenciation non saisonnière (d).",
              criteria="Courbe qui dérive + ACF qui décroît lentement sur plusieurs lags.",
              how_to_apply="Décrire la direction (hausse/baisse), la période concernée, et si la tendance semble stable ou change de régime.",
              what_to_write="« La série présente une tendance [..], suggérant la nécessité d’évaluer d>0. »"
            ),
            TERM(
              "Saisonnalité",
              "Motif récurrent avec une période s (ex. 12 mois).",
              purpose="Justifier s et éventuellement D=1 si la saison est persistante.",
              criteria="Motifs répétés + pics ACF à s,2s,3s.",
              how_to_apply="Fixer s à partir du calendrier, puis vérifier par seasonal plot et ACF.",
              what_to_write="« Une saisonnalité de période s=[..] est observée, ce qui motive l’examen de termes saisonniers. »"
            ),
            TERM(
              "Rupture structurelle",
              "Changement durable de niveau, tendance ou variance (changement de régime).",
              purpose="Une rupture peut rendre les tests de stationnarité ambigus et dégrader la prévision si le futur suit un nouveau régime.",
              criteria="Changement brusque et durable; comportements avant/après différents.",
              how_to_apply="Annoter la date, chercher une cause, et mentionner que la stabilité du modèle dépend de la persistance du régime.",
              notes="SARIMA ‘classique’ suppose un régime relativement stable."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Saisonnalité : "), "motifs + ACF à s → s plausible; si très persistante → envisager D=1."),
              tags$li(tags$b("Tendance : "), "dérive durable + ACF lente → envisager d=1."),
              tags$li(tags$b("Variance : "), "amplitude ↑ avec niveau → log/Box–Cox."),
              tags$li(tags$b("Rupture : "), "si rupture claire → discuter limites, éventuellement segmenter/ajouter variables.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Figures EDA commentées (pas seulement affichées)."),
              tags$li("Hypothèses initiales : s, besoin de transformation, d et/ou D probables."),
              tags$li("Liste d’événements/ruptures à discuter.")
            )
          ),
          checklist_items = c(
            "J’ai tracé la série (niveau et éventuellement transformée).",
            "J’ai commenté tendance, saison, anomalies, variance (avec dates/segments).",
            "J’ai proposé une valeur s plausible basée sur le calendrier + preuves (ACF/seasonal plot).",
            "J’ai formulé une hypothèse sur d et D à tester ensuite.",
            "J’ai noté toute rupture potentielle et son contexte."
          ),
          paper_text =
            "« L’analyse exploratoire a été réalisée via une visualisation de y_t et des graphiques saisonniers (par [mois/semaine]) afin d’identifier tendance et saisonnalité. L’inspection a suggéré une saisonnalité de période s=[..] et une tendance [..]. La variabilité a été jugée [stable/non stable], indiquant [pas de transformation/une transformation]. Des anomalies autour de [dates] ont été observées et interprétées à la lumière du contexte [..]. »",
          apa_text =
            "« En conclusion (Étape 2), l’exploration visuelle a mis en évidence [tendance] et [saisonnalité] (s=[..]), ainsi qu’une variabilité [stable/variable]. Ces observations motivent les décisions suivantes : [transformation], et l’évaluation de différenciations d=[..] et D=[..] afin d’approcher la stationnarité requise pour SARIMA. »",
          pieges_items = list(
            "Montrer des figures sans expliquer ce qu’elles impliquent pour le modèle.",
            "Choisir s ‘au hasard’ sans lien calendrier + preuves ACF.",
            "Ignorer une rupture évidente : le modèle peut être ‘bon’ sur passé et mauvais sur futur."
          )
        ))
      }
      
      # =========================
      # STEP 3
      # =========================
      if (k == 3) {
        return(StepPage(
          but_text = "Utiliser une décomposition pour séparer tendance/saison/bruit, justifier additif vs multiplicatif, et décider si STL est nécessaire (saison évolutive, outliers).",
          objectif = tagList(
            P("La décomposition est un outil descriptif : elle clarifie la structure et aide à justifier la transformation. Elle ne remplace pas la stationnarité exigée pour l’estimation SARIMA."),
            tags$ul(
              tags$li("Décomposer y_t (tendance, saison, reste)."),
              tags$li("Comparer additif vs multiplicatif (souvent via log)."),
              tags$li("Utiliser STL si saison change lentement ou présence d’outliers.")
            )
          ),
          analyses = tagList(
            tags$ul(
              tags$li("Produire une décomposition (classique ou STL)."),
              tags$li("Comparer l’amplitude saisonnière en fonction du niveau (indice multiplicatif)."),
              tags$li("Commenter la composante résiduelle : reste-t-il une structure évidente ?")
            )
          ),
          tests = tagList(
            TERM(
              "Décomposition additive",
              "y_t = T_t + S_t + e_t : la saison s’ajoute à la tendance avec une amplitude à peu près constante.",
              purpose="Appropriée si l’écart saisonnier (pics-creux) est similaire à travers le temps.",
              criteria="Amplitude saisonnière stable, pas proportionnelle au niveau.",
              how_to_apply="Utiliser si les oscillations saisonnières restent comparables quand la série monte/descend.",
              formula="y_t = T_t + S_t + e_t"
            ),
            TERM(
              "Décomposition multiplicative",
              "y_t = T_t × S_t × e_t : la saison agit comme un facteur proportionnel au niveau.",
              purpose="Appropriée quand l’amplitude saisonnière augmente avec le niveau.",
              criteria="Oscillations plus grandes quand la série est haute.",
              how_to_apply="Souvent, appliquer log(y) pour obtenir une forme additive dans l’espace log.",
              formula="y_t = T_t × S_t × e_t",
              notes="Souvent log(y_t) → additif sur log."
            ),
            TERM(
              "STL",
              "Décomposition Season-Trend (Loess) flexible, robuste, permettant une saisonnalité qui évolue lentement.",
              purpose="Utile si la saison n’est pas parfaitement stable ou s’il existe des outliers.",
              criteria="Motifs saisonniers qui se déforment dans le temps; outliers notables.",
              how_to_apply="Utiliser STL pour la lecture descriptive; ensuite revenir aux tests/ACF pour stationnarité.",
              notes="STL ≠ preuve de stationnarité."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Additif : "), "si amplitude saisonnière ~ constante."),
              tags$li(tags$b("Multiplicatif : "), "si amplitude saisonnière ∝ niveau → log/Box–Cox conseillé."),
              tags$li(tags$b("STL : "), "si saison évolutive et/ou outliers → STL préférable.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Figure de décomposition + commentaire de T/S/e."),
              tags$li("Décision argumentée : additif vs multiplicatif; STL si retenu.")
            )
          ),
          checklist_items = c(
            "J’ai réalisé une décomposition (classique ou STL).",
            "J’ai décrit la tendance et la saison (période, stabilité).",
            "J’ai justifié additif vs multiplicatif (avec argument amplitude↔niveau).",
            "Si multiplicatif, j’ai justifié log/Box–Cox.",
            "J’ai noté si la décomposition révèle des anomalies/outliers."
          ),
          paper_text =
            "« Nous avons réalisé une décomposition de la série afin de séparer tendance (T_t), saisonnalité (S_t) et composante résiduelle (e_t). La comparaison des amplitudes saisonnières selon le niveau a motivé l’usage d’une structure [additive/multiplicative]. En présence de [saison évolutive/outliers], une décomposition STL a été privilégiée pour sa flexibilité. »",
          apa_text =
            "« En conclusion (Étape 3), la décomposition a indiqué une saisonnalité [stable/évolutive] et une tendance [..]. L’amplitude saisonnière étant [constante/proportionnelle au niveau], une approche [additive / transformation log puis additive] a été retenue pour préparer l’estimation SARIMA sur une série plus appropriée. »",
          pieges_items = list(
            "Confondre décomposition (descriptive) et stationnarité (condition pour SARIMA).",
            "Choisir multiplicatif sans vérifier qu’une transformation rend la saison plus stable.",
            "Ignorer que des outliers peuvent fausser la lecture des composantes."
          )
        ))
      }
      
      # =========================
      # STEP 4
      # =========================
      if (k == 4) {
        return(StepPage(
          but_text = "Choisir s, d, D pour obtenir une série approximativement stationnaire (après différenciation) et justifier ce choix par convergence : graphes + ACF/PACF + tests ADF/KPSS/PP, tout en évitant la sur-différenciation.",
          objectif = tagList(
            P("SARIMA suppose que la série est stationnaire après différenciation. Cette étape décide combien de tendance (d) et combien de saison persistante (D) on retire avant d’estimer les composantes AR/MA."),
            tags$ul(
              tags$li("Définir s (période saisonnière) à partir du calendrier et des preuves empiriques."),
              tags$li("Choisir d (différenciation ordinaire) et D (différenciation saisonnière)."),
              tags$li("Valider stationnarité via ADF/KPSS/PP + diagnostics ACF."),
              tags$li("Contrôler la sur-différenciation et retenir la solution la plus simple.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Fixer s (ex. mensuel=12) puis confirmer via seasonal plot/ACF."),
              tags$li("Essayer D=0 puis D=1 si saison persistante; vérifier ACF au lag s après différenciation saisonnière."),
              tags$li("Essayer d=0 puis d=1 si tendance stochastique; vérifier ACF lag 1 après différenciation."),
              tags$li("Appliquer tests ADF/KPSS/PP sur la série obtenue; interpréter ensemble."),
              tags$li("Si conflits/symptômes de sur-diff, ajuster et re-tester.")
            )
          ),
          tests = tagList(
            H("Concepts / définitions indispensables"),
            TERM(
              "Différenciation ordinaire (d)",
              "Appliquer ∇ : ∇y_t = y_t − y_{t−1}. Répéter d fois retire progressivement une tendance stochastique.",
              purpose="Rendre la série plus stable (moyenne/variance) pour permettre un ARMA sur la partie stationnaire.",
              criteria="d ∈ {0,1} la plupart du temps; d=2 est rare et doit alerter.",
              how_to_apply="Tester d=0 puis d=1; vérifier ACF et tests; s’arrêter dès que la stationnarité est raisonnable.",
              formula="(1-B)^d y_t"
            ),
            TERM(
              "Différenciation saisonnière (D)",
              "Appliquer ∇_s : ∇_s y_t = y_t − y_{t−s}. Retire une non-stationnarité saisonnière persistante.",
              purpose="Supprimer une racine unitaire saisonnière afin que la saison restante soit modélisée par P/Q.",
              criteria="D ∈ {0,1} le plus souvent; D=2 très rare.",
              how_to_apply="Essayer D=1 si la saison persiste fortement; surveiller ACF lag s (sur-diff si très négative).",
              formula="(1-B^s)^D y_t"
            ),
            TERM(
              "Sur-différenciation",
              "Différencier plus que nécessaire (d ou D trop grand), créant une structure artificielle et augmentant l’instabilité.",
              purpose="Éviter des paramètres instables et des prévisions oscillantes.",
              criteria="ACF lag1 très négative (sur-diff d) ou ACF lag s très négative (sur-diff D).",
              how_to_apply="Si symptôme présent, réduire d/D et re-vérifier.",
              notes="Règle : minimum de différenciation pour stationnariser."
            ),
            
            H("Tests de stationnarité (ADF/KPSS/PP)"),
            TEST(
              name="ADF — Augmented Dickey–Fuller (racine unitaire)",
              purpose="Détecter une racine unitaire (non-stationnarité) : le test évalue si la série se comporte comme une marche aléatoire, où les chocs ont des effets persistants.",
              when_to_use="Sur la série brute puis après différenciation pour décider/valider d (et parfois l’effet combiné avec D).",
              H0="Racine unitaire → non-stationnaire.",
              H1="Stationnaire (selon spécification drift/trend).",
              statistic="Régression sur Δy_t avec y_{t−1} et retards de Δy_t; test sur le coefficient de y_{t−1}.",
              decision_rule="p < 0.05 → rejet H0 → stationnarité plausible; p ≥ 0.05 → non-rejet → d (ou spécification) à reconsidérer.",
              interpretation="Rejeter H0 signifie que la série a une force de retour (autour d’une moyenne ou d’une tendance déterministe) plutôt qu’une dérive stochastique.",
              what_it_means_for_choices="Si ADF ne rejette pas sur la brute, tester d=1; si rejette après (d,D), passer à l’identification p/q/P/Q.",
              reporting="Préciser version (drift/trend), nb de retards, statistique et p-value, et relier au choix de d.",
              caveats="Sensibilité aux retards et aux ruptures structurelles."
            ),
            TEST(
              name="KPSS — Stationnarité comme H0",
              purpose="Tester la stationnarité en prenant l’hypothèse inverse de l’ADF : on suppose stationnaire tant que les données ne la contredisent pas. Utile pour trianguler.",
              when_to_use="En complément de l’ADF/PP, surtout si les conclusions sont ambiguës.",
              H0="Série stationnaire (niveau ou tendance selon version).",
              H1="Non-stationnaire.",
              statistic="Basé sur la somme cumulée des résidus et une variance longue.",
              decision_rule="p < 0.05 → rejet stationnarité; p ≥ 0.05 → compatible stationnarité.",
              interpretation="Un KPSS non significatif après différenciation renforce la validité du choix d/D; un rejet suggère qu’il reste de la non-stationnarité.",
              what_it_means_for_choices="ADF/PP rejettent + KPSS non rejette → signal fort; sinon, reconsidérer d/D ou rupture.",
              reporting="Préciser version (level/trend) et conclusion explicite.",
              caveats="Très sensible aux ruptures; dépend du paramètre de variance longue."
            ),
            TEST(
              name="PP — Phillips–Perron",
              purpose="Tester la racine unitaire comme ADF, mais en corrigeant autocorrélation/hétéroscédasticité de façon non paramétrique.",
              when_to_use="Complément à ADF, utile si l’ADF dépend trop du choix des retards.",
              H0="Racine unitaire → non-stationnaire.",
              H1="Stationnaire.",
              decision_rule="p < 0.05 → rejet H0 → stationnarité plausible.",
              interpretation="Concordance ADF+PP renforce la conclusion; désaccord implique de revenir aux graphes/ACF et à la spécification.",
              what_it_means_for_choices="Désaccord → tester autre spécification drift/trend, vérifier rupture, re-évaluer d/D.",
              caveats="Comme ADF, sensible aux ruptures."
            ),
            
            H("Triangulation (comment conclure proprement)"),
            Acc("Interpréter ADF/KPSS/PP ensemble (logique à écrire)",
                tags$ul(
                  tags$li(tags$b("Accord stationnaire : "), "ADF/PP rejettent la racine unitaire (p petit) ET KPSS ne rejette pas la stationnarité (p grand)."),
                  tags$li(tags$b("Accord non-stationnaire : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
                  tags$li(tags$b("Conflit : "), "s’appuyer sur la convergence des indices (plots + ACF + tests) et minimiser d/D pour éviter la sur-diff.")
                )
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Choisir s : "), "calendrier d’abord, ACF/seasonal plot ensuite."),
              tags$li(tags$b("Choisir D : "), "souvent 0 ou 1; si la saison persiste fortement, tester D=1; éviter D=2."),
              tags$li(tags$b("Choisir d : "), "souvent 0 ou 1; d=2 rare."),
              tags$li(tags$b("Stop rule : "), "s’arrêter dès que la stationnarité est raisonnable; surveiller la sur-diff (ACF négative forte).")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Valeurs retenues : s, d, D + justification triangulée."),
              tags$li("Résultats tests ADF/KPSS/PP sur série finale (et éventuellement brute)."),
              tags$li("Indication explicite sur sur-diff (présente/absente).")
            )
          ),
          checklist_items = c(
            "J’ai fixé s et je peux justifier (calendrier + preuves ACF).",
            "J’ai testé D=0 puis D=1 si nécessaire, et vérifié ACF au lag s.",
            "J’ai testé d=0 puis d=1 si nécessaire, et vérifié ACF au lag 1.",
            "J’ai exécuté ADF/KPSS/PP et interprété ensemble (pas test par test).",
            "J’ai vérifié l’absence de sur-diff et retenu la solution la plus simple."
          ),
          paper_text =
            "« La stationnarité a été évaluée par les tests ADF, KPSS et PP afin de trianguler l’évidence, ces tests ayant des hypothèses nulles différentes. Sur la base des résultats combinés (tests + diagnostics ACF/PACF + inspection visuelle), nous avons retenu d=[..] différenciations ordinaires et D=[..] différenciations saisonnières avec une période s=[..]. Ce choix visait à supprimer [tendance / racine unitaire saisonnière] tout en évitant la sur-différenciation. »",
          apa_text =
            "« En conclusion (Étape 4), la série transformée par (d=[..], D=[..]) avec période s=[..] est apparue compatible avec une stationnarité opérationnelle : ADF/PP [rejet/non rejet] de H0 et KPSS [non rejet/rejet] de la stationnarité, sans symptômes marqués de sur-différenciation. Cette décision autorise l’estimation de modèles SARIMA sur la série différenciée. »",
          pieges_items = list(
            "Sur-différencier (d ou D trop grand) → ACF négative forte, prévisions instables.",
            "Forcer D=2 : souvent signe d’une mauvaise spécification de s ou d’un problème de données.",
            "Interpréter une seule p-value sans triangulation.",
            "Ignorer une rupture structurelle qui biaise les tests."
          )
        ))
      }
      
      # =========================
      # STEP 5
      # =========================
      if (k == 5) {
        return(StepPage(
          but_text = "Établir une référence solide (benchmarks + auto-ARIMA) et des critères de sélection réalistes : un bon modèle doit être valide (diagnostics) et utile (bat les benchmarks) — pas seulement “meilleur AICc”.",
          objectif = tagList(
            tags$ul(
              tags$li("Construire des benchmarks (naïf, naïf saisonnier)."),
              tags$li("Estimer une baseline via auto-ARIMA (AICc/BIC) comme point de départ."),
              tags$li("Définir des critères de sélection : information + diagnostics + performance out-of-sample.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Calculer les erreurs de prévision des benchmarks sur le même protocole (test/rolling)."),
              tags$li("Ajuster auto-ARIMA avec contraintes explicites (max p/q/P/Q)."),
              tags$li("Comparer AICc/BIC et erreurs out-of-sample; vérifier stabilité des paramètres."),
              tags$li("Garder auto-ARIMA comme baseline, pas comme vérité finale.")
            )
          ),
          tests = tagList(
            TERM(
              "Benchmark naïf",
              "Prévision égale à la dernière observation (random walk).",
              purpose="Établir un minimum : si le modèle ne bat pas le naïf, la valeur ajoutée est faible.",
              how_to_apply="Calculer MAE/RMSE sur la fenêtre test/rolling, même horizon h.",
              formula="ŷ_{t+h} = y_t"
            ),
            TERM(
              "Benchmark naïf saisonnier",
              "Prévision égale à la dernière valeur de la même saison.",
              purpose="Référence clé lorsque la saisonnalité est forte.",
              how_to_apply="Évaluer sur au moins une saison complète si possible.",
              formula="ŷ_{t+h} = y_{t+h-s}"
            ),
            TERM(
              "AICc vs BIC",
              "Critères d’information pénalisant la complexité; AICc est souvent privilégié pour la prévision, BIC pour la parcimonie.",
              purpose="Comparer des modèles estimés sur la même série, même transformation.",
              criteria="ΔAICc < 2 → modèles quasi équivalents : préférer le plus simple.",
              how_to_apply="Ne pas utiliser AICc/BIC pour comparer des modèles sur des données différentes."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Information : "), "AICc minimal, mais ΔAICc<2 → choisir plus simple."),
              tags$li(tags$b("Validité : "), "paramètres stables + diagnostics résidus acceptables (au moins une vérification)."),
              tags$li(tags$b("Utilité : "), "doit battre naïf/naïf saisonnier sur MAE/RMSE (même protocole).")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Table comparant benchmarks vs auto-ARIMA : AICc/BIC + MAE/RMSE."),
              tags$li("Baseline retenue (spécification) + contraintes de recherche documentées.")
            )
          ),
          checklist_items = c(
            "J’ai calculé les performances du naïf et du naïf saisonnier (si saison).",
            "J’ai estimé auto-ARIMA avec des contraintes explicites (max ordres).",
            "J’ai comparé AICc/BIC et erreurs out-of-sample sur le même protocole.",
            "J’ai retenu la baseline comme point de départ, pas comme modèle final.",
            "J’ai documenté paramètres/contraintes (reproductibilité)."
          ),
          paper_text =
            "« Un modèle de référence a été établi en comparant des benchmarks (naïf, naïf saisonnier) et une sélection auto-ARIMA basée sur l’AICc. La recherche auto-ARIMA a été conduite sous contraintes [..] (max p/q/P/Q, stepwise=[..]) sur la série [transformée/différenciée] définie précédemment. Le modèle retenu (baseline) était SARIMA((p,d,q)(P,D,Q)[s]) et a servi de point de départ pour l’identification manuelle. »",
          apa_text =
            "« En conclusion (Étape 5), la baseline auto-ARIMA a fourni une spécification initiale qui [bat/ne bat pas] les benchmarks. Cette baseline sert de référence : les modèles manuels ultérieurs doivent au minimum égaler sa performance tout en respectant la parcimonie et les diagnostics. »",
          pieges_items = list(
            "Prendre auto-ARIMA comme vérité absolue sans diagnostics ni performance test.",
            "Comparer AICc entre modèles estimés sur des données transformées différemment.",
            "Oublier les benchmarks : on peut ‘gagner’ AICc mais perdre en prévision utile."
          )
        ))
      }
      
      # =========================
      # STEP 6
      # =========================
      if (k == 6) {
        return(StepPage(
          but_text = "Construire un petit ensemble de modèles candidats guidés par ACF/PACF et la parcimonie, puis sélectionner par convergence : (AICc/BIC) + diagnostics + performance.",
          objectif = tagList(
            tags$ul(
              tags$li("Tracer ACF/PACF sur la série stationnaire (après d/D)."),
              tags$li("Proposer p,q,P,Q plausibles (petits)."),
              tags$li("Ajuster 3–8 candidats (pas 200) et comparer.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Tracer ACF/PACF après différenciation (d,D)."),
              tags$li("Lire non-saisonnier : PACF→p, ACF→q (heuristiques)."),
              tags$li("Lire saisonnier : pics aux lags s,2s → P/Q plausibles."),
              tags$li("Ajuster quelques modèles et comparer AICc/BIC + stabilité + diagnostics.")
            )
          ),
          tests = tagList(
            TERM(
              "ACF",
              "Corrélation entre y_t et y_{t-k}. Sert à détecter des structures MA et des motifs saisonniers (pics à s,2s,...).",
              purpose="Guider le choix de q et Q (termes MA non-saisonnier et saisonnier).",
              criteria="Pics clairs et cohérents; motifs répétés plus informatifs qu’un pic isolé.",
              how_to_apply="Travailler sur la série stationnaire, proposer q/Q petits (0–2), puis valider via diagnostics."
            ),
            TERM(
              "PACF",
              "Corrélation partielle entre y_t et y_{t-k}, contrôlant les retards intermédiaires.",
              purpose="Guider le choix de p et P (termes AR non-saisonnier et saisonnier).",
              criteria="Coupure approximative après p; pics aux multiples de s pour P.",
              how_to_apply="Proposer p/P petits, puis vérifier la qualité résiduelle."
            ),
            TERM(
              "Bandes de significativité ACF/PACF",
              "Approximation ±1.96/√n pour juger un pic notable.",
              purpose="Éviter de sur-interpréter du bruit.",
              how_to_apply="Chercher des motifs cohérents plutôt qu’un seul pic au-dessus de la bande."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Parcimonie : "), "préférer p,q,P,Q petits; éviter la complexité inutile."),
              tags$li(tags$b("ΔAICc : "), "si ΔAICc < 2, modèles équivalents → choisir le plus simple."),
              tags$li(tags$b("Stabilité : "), "refuser modèles non stationnaires/non inversibles même si AICc bon."),
              tags$li(tags$b("Validation : "), "diagnostics résidus et performance doivent confirmer.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Liste courte de candidats + justification ACF/PACF."),
              tags$li("Comparaison candidats : AICc/BIC + indicateurs de stabilité."),
              tags$li("Candidats retenus pour diagnostic complet (étape 7).")
            )
          ),
          checklist_items = c(
            "J’ai tracé ACF et PACF sur la série stationnaire.",
            "J’ai proposé p,q,P,Q (petits) et justifié avec ACF/PACF.",
            "J’ai ajusté un petit ensemble (3–8) de modèles candidats.",
            "J’ai comparé AICc/BIC et vérifié stabilité/inversibilité.",
            "J’ai retenu 1–3 candidats pour diagnostics approfondis (étape 7)."
          ),
          paper_text =
            "« Les ordres SARIMA ont été proposés à partir des motifs observés dans l’ACF et la PACF de la série stationnaire. Des pics aux faibles lags suggéraient des composantes non saisonnières (p,q), tandis que des pics aux multiples de s suggéraient des composantes saisonnières (P,Q). Un ensemble restreint de modèles candidats a été ajusté et comparé via AICc/BIC et critères de stabilité, afin de retenir des modèles parcimonieux pour les diagnostics finaux. »",
          apa_text =
            "« En conclusion (Étape 6), les diagnostics ACF/PACF ont motivé un ensemble restreint de spécifications SARIMA plausibles. Les candidats ont été filtrés par parcimonie et critères d’information, préparant une validation finale fondée sur les diagnostics résiduels et la performance de prévision. »",
          pieges_items = list(
            "Brute-force massif (‘200 modèles’) sans justification : ce n’est pas ‘théorie’.",
            "Sur-interpréter des pics isolés ACF/PACF.",
            "Choisir un modèle instable (non stationnaire/non inversible) pour gagner un peu d’AICc."
          )
        ))
      }
      
      # =========================
      # STEP 7
      # =========================
      if (k == 7) {
        return(StepPage(
          but_text = "Valider le modèle : les résidus doivent ressembler à du bruit blanc (pas d’autocorrélation résiduelle) et la prévision doit battre les benchmarks. C’est l’étape où l’on décide réellement du modèle final.",
          objectif = tagList(
            tags$ul(
              tags$li("Diagnostiquer les résidus (temps, ACF résidus, tests)."),
              tags$li("Évaluer la performance de prévision sur test/rolling (MAE/RMSE/...)."),
              tags$li("Choisir le modèle final : diagnostics OK + performance + simplicité.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Tracer résidus dans le temps : moyenne≈0, pas de tendance résiduelle."),
              tags$li("Tracer ACF des résidus : pas de structure; pics surtout dans ±1.96/√n."),
              tags$li("Appliquer Ljung–Box sur plusieurs lags L (ex. 10, s, 2s)."),
              tags$li("Vérifier variance (hétéroscédasticité) et normalité (optionnel)."),
              tags$li("Comparer out-of-sample à benchmarks; préférer modèle le plus simple si performances proches.")
            )
          ),
          tests = tagList(
            TEST(
              name="Ljung–Box (autocorrélation résiduelle)",
              purpose="Tester si les autocorrélations des résidus jusqu’à un lag L sont globalement nulles. Si le test rejette H0, le modèle a laissé de la structure temporelle non expliquée.",
              when_to_use="Toujours après estimation SARIMA (sur plusieurs lags L).",
              H0="Résidus ~ bruit blanc jusqu’au lag L.",
              H1="Autocorrélation résiduelle présente.",
              statistic="Statistique Q(L) agrégée; ddl ajustés (fitdf).",
              decision_rule="p ≥ 0.05 → acceptable; p < 0.05 → revoir la spécification (p/q/P/Q ou d/D).",
              interpretation="Un rejet signifie que le modèle ne capture pas toute la dépendance : les prévisions/intervalles peuvent être biaisés.",
              what_it_means_for_choices="Si rejet : réviser ordres AR/MA (souvent ajouter un terme saisonnier manquant) ou reconsidérer d/D.",
              reporting="Rapporter L, Q, p-value et conclure clairement sur ‘résidus compatibles avec bruit blanc’ ou non.",
              caveats="Sensibilité au choix de L; grand n rend le test très sensible."
            ),
            TEST(
              name="ARCH LM (variance conditionnelle / clustering)",
              purpose="Détecter si la variance des résidus dépend du passé (volatilité en grappes).",
              when_to_use="Séries financières ou résidus montrant variance changeante; utile si ACF des résidus^2 est notable.",
              H0="Pas d’effets ARCH.",
              H1="Effets ARCH présents.",
              decision_rule="p < 0.05 → ARCH probable → envisager un modèle de variance (ex. GARCH) pour des intervalles crédibles.",
              interpretation="Le modèle de moyenne peut être correct, mais l’incertitude varie dans le temps.",
              caveats="Outliers peuvent imiter ARCH; dépend du choix de lags."
            ),
            TEST(
              name="Jarque–Bera / Shapiro–Wilk (normalité, optionnel)",
              purpose="Tester la normalité des résidus (utile surtout pour l’interprétation des intervalles, moins pour la précision).",
              when_to_use="Si vous publiez des intervalles et souhaitez justifier l’hypothèse gaussienne.",
              H0="Résidus ~ normale.",
              H1="Résidus non normaux.",
              decision_rule="p < 0.05 → rejet; discuter impact sur intervalles.",
              interpretation="Non-normalité fréquente; priorité reste l’autocorrélation résiduelle.",
              caveats="Très sensible si n grand; préférer QQ-plot + discussion."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Diagnostics : "), "ACF résidus sans structure + Ljung–Box non significatif (idéalement à plusieurs L)."),
              tags$li(tags$b("Performance : "), "MAE/RMSE meilleurs que benchmarks sur même protocole."),
              tags$li(tags$b("Parcimonie : "), "si performances quasi identiques → choisir le modèle le plus simple."),
              tags$li(tags$b("Robustesse : "), "résultats stables sur plusieurs origines (rolling) si possible.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Table candidats : AICc/BIC + MAE/RMSE + diagnostics (Ljung–Box p-values)."),
              tags$li("Choix du modèle final + justification en 3 axes (validité, utilité, simplicité)."),
              tags$li("Figures : résidus, ACF résidus, prévision + intervalles.")
            )
          ),
          checklist_items = c(
            "J’ai tracé les résidus et commenté leur comportement.",
            "J’ai tracé l’ACF des résidus et vérifié absence de structure majeure.",
            "J’ai appliqué Ljung–Box (au moins 2–3 choix de L) et interprété.",
            "J’ai évalué MAE/RMSE sur test/rolling et comparé aux benchmarks.",
            "J’ai choisi le modèle final en privilégiant diagnostics + performance + parcimonie."
          ),
          paper_text =
            "« Les diagnostics des résidus incluaient l’inspection temporelle, l’ACF des résidus et le test de Ljung–Box afin d’évaluer la présence d’autocorrélation résiduelle. La performance de prévision a été mesurée sur [fenêtre test / rolling-origin] via [MAE, RMSE] et comparée aux benchmarks (naïf, naïf saisonnier). Le modèle final a été retenu sur la base de l’adéquation diagnostique, de la performance prédictive et de la parcimonie. »",
          apa_text =
            "« En conclusion (Étape 7), le modèle SARIMA retenu a produit des résidus compatibles avec un bruit blanc (Ljung–Box non significatif à L=[..], α=0.05) et a surpassé les benchmarks en prévision (MAE=[..], RMSE=[..]). Ce résultat indique que la structure temporelle principale a été capturée et que les prévisions à horizon h=[..] sont utilisables dans la mesure où la dynamique historique se maintient. »",
          pieges_items = list(
            "Choisir un modèle sur AICc seul alors que Ljung–Box rejette (résidus autocorrélés).",
            "Ignorer benchmarks : une belle modélisation qui ne bat pas le naïf est rarement utile.",
            "Sur-interpréter la normalité : l’autocorrélation résiduelle est le problème majeur."
          )
        ))
      }
      
      # =========================
      # STEP 8
      # =========================
      if (k == 8) {
        return(StepPage(
          but_text = "Assembler un rapport reproductible et compréhensible : raconter le raisonnement, documenter toutes les décisions (données → choix s,d,D → sélection modèle → diagnostics → performance) et donner une conclusion claire en style APA.",
          objectif = tagList(
            tags$ul(
              tags$li("Assembler Méthodes et Résultats alignés sur les étapes 0–7."),
              tags$li("Présenter le modèle final SARIMA((p,d,q)(P,D,Q)[s]) et ses preuves (diagnostics + performance)."),
              tags$li("Fournir livrables : script/notebook + figures + tables.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Rassembler les choix : y_t, fréquence, h, protocole, métriques, benchmarks."),
              tags$li("Documenter préparation : NA, outliers, transformations."),
              tags$li("Documenter s,d,D et justification tests + ACF."),
              tags$li("Présenter baseline + candidats + sélection finale."),
              tags$li("Inclure diagnostics résidus + tableau d’erreurs et figure de prévision.")
            )
          ),
          tests = tagList(
            TERM(
              "Spécification SARIMA complète",
              "Notation SARIMA((p,d,q)(P,D,Q)[s]) décrivant les ordres non saisonniers et saisonniers, la différenciation, et la période saisonnière.",
              purpose="Permet de communiquer le modèle sans ambiguïté.",
              how_to_apply="La spécification doit apparaître clairement une fois, puis être réutilisée.",
              example="SARIMA((1,1,1)(0,1,1)[12]) pour une série mensuelle."
            ),
            TERM(
              "Sens de la conclusion (interprétation)",
              "La conclusion ne doit pas seulement donner un modèle, mais expliquer ce qu’il implique : précision attendue, incertitude, conditions de validité (stabilité du régime).",
              purpose="Transformer un résultat statistique en message utilisable.",
              how_to_apply="Relier performance vs benchmarks + diagnostics résidus + limites (ruptures, exogènes)."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Clarté : "), "chaque étape explique ‘quoi → pourquoi → résultat → décision’."),
              tags$li(tags$b("Reproductibilité : "), "données, dates de split, paramètres, seed, versions."),
              tags$li(tags$b("Preuves : "), "diagnostics + performance; figures et tables alignées aux décisions."),
              tags$li(tags$b("Sobriété : "), "pas d’excès de modèles; justification de la parcimonie.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Notebook/script : chargement → préparation → stationnarité → modèles → diagnostics → prévisions."),
              tags$li("Figures : série, décomposition, ACF/PACF, résidus + ACF résidus, prévisions + intervalles."),
              tags$li("Tables : candidats (AICc/BIC), diagnostics (Ljung–Box), performance (MAE/RMSE)."),
              tags$li("Conclusion APA finale.")
            )
          ),
          checklist_items = c(
            "Mon rapport suit l’ordre des étapes 0–7 avec décisions explicites.",
            "J’ai inclus la spécification SARIMA finale complète.",
            "J’ai inclus figures et tables nécessaires (diagnostics + performance).",
            "Mon code est reproductible (données, dates, seed, paramètres).",
            "Ma conclusion APA explique aussi le sens et les limites."
          ),
          paper_text =
            "« Le rapport a été structuré en Méthodes (données, préparation, stationnarité, sélection des modèles) et Résultats (observations EDA, tests, modèles candidats, diagnostics, performance). Les figures et tableaux ont été alignés sur les décisions, et l’ensemble du workflow a été rendu reproductible via un script/notebook exécutant l’analyse de bout en bout. »",
          apa_text =
            "« Conclusion (APA). Le modèle SARIMA((p,d,q)(P,D,Q)[s]) retenu a été sélectionné sur la base d’une validation temporelle et a surpassé les benchmarks en prévision (MAE=[..], RMSE=[..]). Les diagnostics résiduels étaient compatibles avec un bruit blanc (Ljung–Box non significatif à L=[..]), suggérant que la structure temporelle principale a été capturée. Ces résultats indiquent que les prévisions à horizon h=[..] sont pertinentes tant que la dynamique observée persiste; les limites incluent [ruptures potentielles, variables exogènes non modélisées, changements de variance]. »",
          pieges_items = list(
            "Rapport ‘catalogue’ : figures sans décisions explicites.",
            "Oublier de donner les dates exactes de split/rolling → non reproductible.",
            "Présenter la spécification SARIMA de manière ambiguë ou incomplète.",
            "Ne pas discuter les limites (ruptures, exogènes, stabilité du régime)."
          )
        ))
      }
      
      tags$div(class="road-card", "Étape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (très détaillée) — FR"),
                          tags$p(class="road-sub",
                                 "Navigation par slider. Chaque étape est organisée : Objectif → Analyses → Tests → Critères → Sorties → Checklist → Papier → Conclusion APA → Pièges."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Étape (slider — pas besoin de scroll)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  # ==========================================================================================
  # ==========================================================================================
  
  # ============================================================
  # EXTREMELY DETAILED SARIMA ROADMAP (FR) — Slider + Collapsibles
  # + NEW (all steps): 
  #   Ce que les étudiants font (Checklist opérationnelle)
  #   → Ce que les étudiants écrivent (papier)
  #   → Ce que les étudiants écrivent (Conclusion – format APA)
  #   (Always placed BEFORE the section: Pièges)
  #
  # HOW TO USE
  # 1) In your UI:   uiOutput("roadmap_Detailed_Fr_ui")
  # 2) In server(): paste EVERYTHING below inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui9 <- renderUI({
    
    # ----------------------------
    # Helpers: accordion building
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # level 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # level 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    P <- function(...) tags$p(...)
    
    # Student sections (required in ALL steps)
    STUDENT_DO <- function(..., open = FALSE) {
      items <- list(...)
      D(
        "Ce que les étudiants font (Checklist opérationnelle)",
        tags$ol(lapply(items, function(x) tags$li(x))),
        open = open
      )
    }
    
    STUDENT_WRITE_PAPER <- function(..., open = FALSE) {
      # Accept multiple paragraphs / bullet lists
      D("Ce que les étudiants écrivent (papier)", ..., open = open)
    }
    
    STUDENT_WRITE_APA <- function(apa_text, meaning_text = NULL, open = FALSE) {
      D(
        "Ce que les étudiants écrivent (Conclusion – format APA)",
        P(tags$b("Conclusion (APA). "), "« ", apa_text, " »"),
        if (!is.null(meaning_text)) P(tags$b("Sens (ce que cela veut dire) : "), meaning_text) else NULL,
        open = open
      )
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
                     notes = NULL, how_to_apply = NULL, what_to_write = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("Définition : "), definition),
                 if (!is.null(purpose))       P(tags$b("But / utilité : "), purpose) else NULL,
                 if (!is.null(criteria))      P(tags$b("Critères / indices : "), criteria) else NULL,
                 if (!is.null(how_to_apply))  P(tags$b("Comment l’utiliser dans l’analyse : "), how_to_apply) else NULL,
                 if (!is.null(formula))       P(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example))       P(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(what_to_write)) P(tags$b("Phrase type (à écrire) : "), what_to_write) else NULL,
                 if (!is.null(notes))         P(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("But (très détaillé) : "), purpose),
                 P(tags$b("Quand l’utiliser : "), when_to_use),
                 P(tags$b("H0 : "), H0),
                 P(tags$b("H1 : "), H1),
                 if (!is.null(statistic))                 P(tags$b("Statistique / idée : "), statistic) else NULL,
                 if (!is.null(decision_rule))             P(tags$b("Règle de décision : "), decision_rule) else NULL,
                 if (!is.null(interpretation))            P(tags$b("Interprétation (sens) : "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices)) P(tags$b("Ce que ça implique pour vos choix : "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                 P(tags$b("Comment le rapporter : "), reporting) else NULL,
                 if (!is.null(caveats))                   P(tags$b("Limites / pièges : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
    .tight ol {margin: 6px 0 6px 18px;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
    .muted {color:#555;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step labels & badges
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Cadrer le problème & la validation",
        "[1] Qualité des données & préparation (NA, fréquence, outliers)",
        "[2] Exploration visuelle (tendance, saison, variance)",
        "[3] Décomposition (additif/multiplicatif, STL)",
        "[4] Stationnarité & différenciation (choix d, D, s) + tests",
        "[5] Baseline (naïf / auto-ARIMA) + critères de sélection",
        "[6] Identification manuelle (ACF/PACF) + grille candidates",
        "[7] Diagnostics & comparaison finale (tests résidus + forecasting)",
        "[8] Rédaction: conclusion, signification, et livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Horizon", "Protocole", "Métriques"),
        c("Fréquence", "NA", "Outliers", "Transformations"),
        c("Graphiques", "Saisonnalité", "Variance", "Signal"),
        c("STL", "Additif vs multiplicatif", "Structure"),
        c("ADF/KPSS/PP", "d/D/s", "Règles de choix"),
        c("Baseline", "AICc/BIC", "Naïf"),
        c("ACF/PACF", "Parcimonie", "Candidats"),
        c("Ljung–Box", "ARCH", "Normalité", "Accuracy"),
        c("Synthèse", "Conclusion", "Sens", "Reproductible")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ----------------------------
    # Small helpers (criteria blocks)
    # ----------------------------
    criteria_block <- function(title, ..., note = NULL) {
      tags$div(class="box",
               tags$h5(title),
               if (!is.null(note)) tags$p(class="muted", note) else NULL,
               ...
      )
    }
    
    decision_rule_list <- function(...) tags$ul(...)
    
    # ------------------------------------------------------------
    # Step content
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================================================
      # STEP 0 — Cadrer
      # =========================================================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "définir clairement la tâche de prévision, l’horizon, les métriques et la validation, car sans ce cadrage l’évaluation est non reproductible et la comparaison des modèles devient fragile.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          P("On transforme un “problème vague” en un protocole clair : la variable cible, la fréquence temporelle, l’horizon de prévision et la règle d’évaluation. Un bon cadrage garantit que deux étudiants résolvent le même problème et peuvent comparer leurs résultats."),
                          tags$ul(
                            tags$li("Définir la cible ", tags$code("y_t"), " et la fréquence (régularité temporelle)."),
                            tags$li("Fixer un horizon ", tags$code("h"), " réaliste (usage métier / décision)."),
                            tags$li("Fixer un protocole de validation (train/test, rolling-origin) et les métriques (MAE/RMSE/...)."),
                            tags$li("Définir les benchmarks : naïf et naïf saisonnier si saison.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 — Fréquence & saison (s)",
                                                  note = "Décision : quelle granularité et quelle période saisonnière s ont un sens (calendrier + données) ?",
                                                  tags$ul(
                                                    tags$li("Identifier la granularité : jour / semaine / mois / etc."),
                                                    tags$li("Déduire ", tags$code("s"), " (ex : mensuel 12, trimestriel 4, quotidien hebdo 7)."),
                                                    tags$li("Vérifier l’absence de trous/doublons (index régulier).")
                                                  )
                                   ),
                                   criteria_block("A2 — Validation",
                                                  note = "Décision : comment simuler un vrai futur (sans fuite d’information) ?",
                                                  tags$ul(
                                                    tags$li(tags$b("Train/Test temporel : "), "entraîner sur le passé, tester sur le futur."),
                                                    tags$li(tags$b("Rolling-origin : "), "plus robuste (plusieurs origines)."),
                                                    tags$li("Taille test : idéalement ≥ 1 saison si possible.")
                                                  )
                                   ),
                                   criteria_block("A3 — Métriques",
                                                  note = "Décision : quelles erreurs sont les plus coûteuses (unités vs grosses erreurs) ?",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE : "), "erreur moyenne en unités, robuste."),
                                                    tags$li(tags$b("RMSE : "), "pénalise fortement les grosses erreurs."),
                                                    tags$li(tags$b("MAPE : "), "éviter si y≈0 ; préférer sMAPE/MAE."),
                                                    tags$li(tags$b("sMAPE : "), "pourcentage plus stable que MAPE.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Horizon h : "), "doit correspondre au besoin réel (ex : décision mensuelle → h en mois)."),
                            tags$li(tags$b("Protocole : "), "préférer rolling-origin si suffisamment de données ; sinon split temporel documenté."),
                            tags$li(tags$b("Métriques : "), "retenir au moins deux métriques (MAE + RMSE) pour une lecture complète."),
                            tags$li(tags$b("Benchmark : "), "toujours comparer à naïf (et naïf saisonnier si saison).")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Fiche problème : y_t, unité, fréquence, dates, n."),
                            tags$li("Validation : split/rolling, dates exactes, horizon h."),
                            tags$li("Métriques + benchmarks (naïf / saisonnier).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Écrire la définition précise de y_t (quoi, unité, source), et vérifier que la série est bien triée par date.",
                          "Fixer la fréquence (mensuel/hebdo/quotidien) et déduire une saison s plausible.",
                          "Choisir l’horizon h et expliquer à quoi il sert (décision, planification, stock, etc.).",
                          "Définir le protocole d’évaluation (split temporel ou rolling-origin) avec des dates explicites.",
                          "Choisir les métriques (au moins MAE + RMSE) et définir les benchmarks (naïf + naïf saisonnier si saison)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Méthodes (Données & Objectif). "),
                            "Décrire la série (y_t), la période couverte, la fréquence, l’horizon et le protocole d’évaluation. ",
                            "Justifier le choix des métriques et préciser les benchmarks utilisés afin d’assurer une comparaison honnête des modèles."),
                          P(tags$b("Exemple (papier). "),
                            "« Nous modélisons la série (y_t) observée à une fréquence [..] entre [..] et [..] (n=[..]). ",
                            "L’objectif est de produire des prévisions à horizon (h=[..]). ",
                            "La performance est évaluée via [MAE, RMSE] selon un protocole [train/test temporel ou rolling-origin]. ",
                            "Les modèles sont comparés à des benchmarks [naïf, naïf saisonnier]. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Nous avons défini une tâche de prévision univariée (y_t) à fréquence [..] couvrant [..] à [..], ",
                            "avec un horizon (h=[..]) et un protocole d’évaluation temporel [split/rolling-origin] utilisant [MAE, RMSE]. ",
                            "Des benchmarks (naïf et naïf saisonnier) ont été retenus comme référence."
                          ),
                          meaning_text = "Cette conclusion signifie que l’évaluation est reproductible et comparable : tous les modèles seront jugés sur le même futur et avec la même notion d’erreur."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Mélanger le temps (shuffle) : fuite d’information → performance artificielle."),
                            tags$li("Changer h ou le split après coup → comparaison invalide."),
                            tags$li("MAPE avec y≈0 → erreur explosive et trompeuse.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 1 — Qualité / Préparation
      # =========================================================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "rendre la série exploitable (index régulier, NA traités, outliers interprétés, transformation justifiée), car SARIMA et ses diagnostics supposent une chronologie cohérente et une série correctement préparée.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          P("Cette étape sépare les problèmes de données (erreurs, trous) du signal réel (événements). On corrige les erreurs, on documente l’imputation, et on choisit une transformation uniquement si elle améliore la stabilité de la variance."),
                          tags$ul(
                            tags$li("Vérifier fréquence régulière, dates uniques, tri temporel correct."),
                            tags$li("Détecter et traiter NA (selon nature du manque)."),
                            tags$li("Identifier outliers (erreur vs événement réel)."),
                            tags$li("Décider transformations (log/Box–Cox) si variance non constante.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 — Régularité temporelle",
                                                  note = "Critère : une date attendue doit apparaître une fois (pas 0, pas 2).",
                                                  tags$ul(
                                                    tags$li("Lister trous et doublons de dates."),
                                                    tags$li("Corriger l’index (agréger, supprimer doublons, compléter dates manquantes).")
                                                  )
                                   ),
                                   criteria_block("A2 — Valeurs manquantes (NA)",
                                                  note = "Critère : distinguer trous courts vs longs, et manque aléatoire vs structurel.",
                                                  tags$ul(
                                                    tags$li("Calculer %NA, et mesurer la longueur des ‘gaps’."),
                                                    tags$li("Choisir une imputation (linéaire/saisonnière) si justifiée."),
                                                    tags$li("Si gaps longs : discuter l’impact et envisager alternative.")
                                                  )
                                   ),
                                   criteria_block("A3 — Outliers",
                                                  note = "Critère : une valeur atypique n’est pas forcément une erreur ; vérifier le contexte.",
                                                  tags$ul(
                                                    tags$li("Détecter (IQR/z-score robuste) + inspection graphique."),
                                                    tags$li("Décider : corriger (impossible physiquement) vs conserver (événement réel).")
                                                  )
                                   ),
                                   criteria_block("A4 — Transformation (log/Box–Cox)",
                                                  note = "Critère : si variance/amplitude ↑ avec le niveau, transformation souvent utile.",
                                                  tags$ul(
                                                    tags$li("Diagnostiquer la relation niveau↔variance."),
                                                    tags$li("Tester log/Box–Cox, puis re-vérifier graphiques/ACF."),
                                                    tags$li("Documenter l’inversion pour l’interprétation des prévisions.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Définitions (cliquables)", open = FALSE,
                          TERM(
                            "NA / valeur manquante",
                            "Une valeur manquante (NA) indique qu’une observation attendue n’a pas été enregistrée à un instant précis. En série temporelle, le NA est problématique car il casse la continuité de la dépendance temporelle.",
                            purpose="Sans traitement, les NA peuvent empêcher l’estimation ou fausser les diagnostics (ACF/PACF, tests).",
                            criteria="On analyse la structure (gaps courts vs longs) et la cause (aléatoire vs structurelle).",
                            how_to_apply="Compter les NA, visualiser leurs positions, décider imputation vs agrégation vs exclusion justifiée.",
                            what_to_write="« Les valeurs manquantes (k=[..], [..]%) ont été traitées par [..] car [raison]. »"
                          ),
                          TERM(
                            "Imputation",
                            "L’imputation consiste à remplacer une valeur manquante par une valeur plausible, construite à partir des points voisins ou de la saisonnalité. C’est une hypothèse sur le monde réel, donc elle doit être expliquée.",
                            purpose="Maintenir une grille régulière et éviter que le NA ne crée une rupture artificielle.",
                            criteria="Interpolation linéaire pour trous très courts ; saisonnière si saison forte ; prudence pour trous longs.",
                            how_to_apply="Appliquer l’imputation, puis re-vérifier les graphiques (ne pas inventer de motifs).",
                            notes="Toujours justifier et discuter l’impact sur l’incertitude."
                          ),
                          TERM(
                            "Outlier (aberrant)",
                            "Un outlier est une observation atypique. Il peut être une erreur de mesure ou un événement réel. En prévision, supprimer un événement réel peut rendre le modèle irréaliste.",
                            purpose="Éviter que des valeurs extrêmes non expliquées ne perturbent l’identification et l’estimation.",
                            criteria="Règles (IQR/z-score) + contexte (calendrier, rupture, événement).",
                            how_to_apply="Marquer les outliers, vérifier le contexte, décider corriger vs conserver, documenter.",
                            what_to_write="« Les valeurs atypiques autour de [date] ont été [conservées/ajustées] car [..]. »"
                          ),
                          TERM(
                            "Transformation Box–Cox",
                            "La transformation Box–Cox est une famille de transformations paramétrées (λ) visant à stabiliser la variance. Le log est un cas particulier (λ→0).",
                            purpose="Faciliter l’ajustement SARIMA en rendant la variance plus stable et la saison plus additive.",
                            criteria="Si variance/amplitude saisonnière augmente avec le niveau, log/Box–Cox est souvent approprié.",
                            how_to_apply="Transformer, refaire EDA/ACF, estimer SARIMA, puis revenir à l’échelle originale pour interpréter les prévisions.",
                            formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) si λ→0",
                            notes="Attention aux zéros/négatifs : parfois un décalage est nécessaire."
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Imputation : "), "acceptable si gaps courts et justification claire ; prudence si gaps longs."),
                            tags$li(tags$b("Outliers : "), "corriger si erreur évidente ; conserver si événement réel ; documenter toujours."),
                            tags$li(tags$b("Transformation : "), "utile si variance ↑ avec niveau ; sinon éviter pour garder l’interprétation simple.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Résumé NA (k, %, structure des gaps) + méthode utilisée."),
                            tags$li("Liste d’outliers + décision + justification."),
                            tags$li("Transformation retenue (ou non) + argument + inversion pour interprétation.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Contrôler l’index : dates uniques, triées, et espacées régulièrement (sinon corriger).",
                          "Quantifier les NA : k, %, et longueurs de gaps ; décider imputation ou alternative avec justification.",
                          "Détecter les outliers et vérifier le contexte ; décider corriger vs conserver.",
                          "Tester log/Box–Cox si variance non constante ; re-vérifier graphiques et cohérence.",
                          "Documenter toutes les décisions (quoi, pourquoi, impact)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Méthodes (Préparation). "),
                            "Décrire la régularisation de l’index temporel, le traitement des NA, la gestion des outliers, et la transformation éventuelle. ",
                            "L’objectif est que chaque traitement soit reproductible et justifié par un critère observable."),
                          P(tags$b("Exemple (papier). "),
                            "« La série a été vérifiée pour garantir un index régulier (doublons supprimés/agrégation). ",
                            "Les valeurs manquantes (k=[..], [..]%) ont été traitées par [méthode], choisie car [raison]. ",
                            "Les valeurs aberrantes ont été identifiées via [règle] puis [conservées/ajustées] selon [contexte]. ",
                            "Une transformation [log/Box–Cox] a été [appliquée/non appliquée] car [variance]. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Après vérification de la régularité temporelle, les valeurs manquantes (k=[..], [..]%) ont été traitées par [méthode] ",
                            "et les valeurs atypiques ont été [conservées/ajustées] selon [contexte]. ",
                            "Une transformation [log/Box–Cox] a été [appliquée/non appliquée] afin de [stabiliser la variance/maintenir l’interprétation]."
                          ),
                          meaning_text = "Cette conclusion signifie que la série est maintenant une base valide pour l’EDA, les tests de stationnarité et l’estimation SARIMA, avec une traçabilité claire des modifications."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer silencieusement : toujours expliquer la méthode et pourquoi elle est plausible."),
                            tags$li("Supprimer des outliers qui sont des événements réels : le modèle perd l’information utile."),
                            tags$li("Appliquer une transformation sans expliquer comment revenir à l’échelle originale.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 2 — Exploration visuelle
      # =========================================================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "décrire le signal (tendance, saisonnalité, variance, anomalies) et relier chaque constat à une décision (transformation, s, d, D). Les graphiques servent de preuve complémentaire aux tests.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Visualiser la série brute et éventuellement transformée."),
                            tags$li("Détecter tendance (long terme) et saisonnalité (périodique)."),
                            tags$li("Repérer ruptures possibles et anomalies.")
                          )
                        ),
                        
                        D("Analyses à faire", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 — Courbe temporelle",
                                                  note = "Critère : tendance durable / ruptures de niveau / périodes atypiques.",
                                                  tags$ul(
                                                    tags$li("Tracer y_t (et log/BC(y) si pertinent)."),
                                                    tags$li("Annoter périodes anormales (chocs, événements).")
                                                  )
                                   ),
                                   criteria_block("A2 — Saisonnalité",
                                                  note = "Critère : motif répétitif stable et/ou pics ACF à s,2s,3s.",
                                                  tags$ul(
                                                    tags$li("Seasonal plot (lignes par année si mensuel)."),
                                                    tags$li("Boxplots par mois/trimestre/semaine."),
                                                    tags$li("ACF : pics aux multiples de s.")
                                                  )
                                   ),
                                   criteria_block("A3 — Variance",
                                                  note = "Critère : amplitude des fluctuations augmente avec le niveau → transformation.",
                                                  tags$ul(
                                                    tags$li("Comparer la variabilité selon le niveau moyen."),
                                                    tags$li("Décider log/Box–Cox si nécessaire.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Saisonnalité : "),
                                    "motifs répétés + pics ACF aux multiples de s → s confirmé ; éventuellement D=1 si saison persistante."),
                            tags$li(tags$b("Tendance : "),
                                    "dérive durable + ACF qui décroît lentement → d=1 plausible."),
                            tags$li(tags$b("Variance : "),
                                    "effet éventail → log/Box–Cox.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Paragraphe EDA : ce qui est observé + ce que cela implique."),
                            tags$li("Hypothèses : s plausible, besoin de transformation, besoin de d et/ou D.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Tracer la courbe y_t et, si pertinent, la version transformée (log/Box–Cox).",
                          "Produire un seasonal plot et/ou boxplots par saison (mois, semaine, trimestre).",
                          "Tracer l’ACF de la série (et noter les pics à s,2s,3s).",
                          "Identifier tendance, saison, variance non constante, anomalies et ruptures potentielles.",
                          "Écrire explicitement ‘Observation → Implication’ (ex : variance ↑ → log)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Résultats (EDA). "),
                            "Décrire la tendance, la saisonnalité et la variance, en vous appuyant sur des graphiques. ",
                            "Chaque constat doit mener à une décision préparatoire (transformation, s, d, D)."),
                          P(tags$b("Exemple (papier). "),
                            "« La série (y_t) présente une tendance [..] et une saisonnalité de période (s=[..]). ",
                            "L’amplitude des fluctuations semble [constante/augmenter avec le niveau], suggérant [aucune transformation / une transformation log/Box–Cox]. ",
                            "Des valeurs atypiques apparaissent autour de [..] et sont [interprétées comme événement/corrigées]. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "L’exploration visuelle a indiqué une tendance [..] et une saisonnalité récurrente de période (s=[..]). ",
                            "La variabilité était [stable/croissante avec le niveau], conduisant à [aucune transformation/une transformation log/Box–Cox]. ",
                            "Des observations atypiques ont été identifiées autour de [..] et [conservées/ajustées] selon [justification]."
                          ),
                          meaning_text = "Cette conclusion signifie que vous avez identifié les composantes structurantes (tendance/saison/variance), ce qui guide rationnellement les choix de différenciation et de transformation avant SARIMA."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Montrer des figures sans les commenter : la valeur pédagogique vient de l’interprétation."),
                            tags$li("Confondre bruit et saisonnalité : chercher des motifs répétitifs cohérents."),
                            tags$li("Ignorer une rupture structurelle : le futur peut ne pas ressembler au passé.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 3 — Décomposition
      # =========================================================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "décomposer la série pour clarifier tendance/saison/bruit et justifier additif vs multiplicatif ; la décomposition est descriptive, mais elle renforce la qualité de l’argumentation avant SARIMA.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Décomposer y_t en tendance, saisonnalité, reste."),
                            tags$li("Justifier additif vs multiplicatif ; considérer log comme ‘multiplicatif → additif’."),
                            tags$li("Utiliser STL si saison évolutive ou outliers.")
                          )
                        ),
                        
                        D("Concepts clés (cliquables)", open = FALSE,
                          TERM(
                            "Décomposition additive",
                            "Une décomposition additive suppose que la saisonnalité s’ajoute à la tendance : y_t = T_t + S_t + e_t. L’amplitude saisonnière est alors relativement constante.",
                            purpose="Décrire la structure et vérifier si la saison est stable en amplitude.",
                            criteria="Amplitude saisonnière similaire au fil du temps.",
                            how_to_apply="Comparer les oscillations saisonnières sur différentes périodes ; si elles sont similaires, l’additif est plausible.",
                            formula="y_t = T_t + S_t + e_t"
                          ),
                          TERM(
                            "Décomposition multiplicative",
                            "Une décomposition multiplicative suppose que la saison agit comme un facteur proportionnel : y_t = T_t × S_t × e_t. L’amplitude saisonnière grandit avec le niveau.",
                            purpose="Décrire des séries où l’effet saisonnier est proportionnel au niveau.",
                            criteria="Amplitude saisonnière croissante avec le niveau.",
                            how_to_apply="Tester log(y) : si la saison devient stable après log, on revient à une lecture additive dans l’espace log.",
                            formula="y_t = T_t × S_t × e_t"
                          ),
                          TERM(
                            "STL",
                            "STL est une décomposition flexible (LOESS) qui permet à la saisonnalité d’évoluer lentement et peut être plus robuste aux outliers.",
                            purpose="Produire une lecture descriptive fiable quand la saison n’est pas parfaitement stable.",
                            criteria="Saison évolutive ou présence d’outliers.",
                            how_to_apply="Utiliser STL pour comprendre le signal, puis revenir aux tests/ACF pour stationnarité avant SARIMA.",
                            notes="STL ≠ preuve de stationnarité ; c’est un outil d’analyse exploratoire."
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Additif : "), "amplitude saisonnière ~ constante."),
                            tags$li(tags$b("Multiplicatif : "), "amplitude saisonnière ∝ niveau → log/Box–Cox conseillé."),
                            tags$li(tags$b("STL : "), "saison évolutive/outliers → STL pour robustesse.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Figure de décomposition (classique ou STL)."),
                            tags$li("Justification écrite : additif vs multiplicatif (+ transformation).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Réaliser une décomposition (classique ou STL) et produire la figure (trend/season/remainder).",
                          "Comparer l’amplitude saisonnière à différents niveaux (constante vs proportionnelle).",
                          "Décider additif vs multiplicatif ; si multiplicatif, tester log/Box–Cox.",
                          "Si saison évolutive/outliers, privilégier STL et expliquer pourquoi.",
                          "Relier la décomposition aux décisions suivantes (d/D/s, transformation)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Méthodes (Décomposition). "),
                            "Expliquer comment la série a été décomposée, ce que représentent les composantes, et pourquoi une forme additive ou multiplicative a été privilégiée."),
                          P(tags$b("Exemple (papier). "),
                            "« Nous avons décomposé la série en tendance, saisonnalité et reste via [méthode]. ",
                            "L’amplitude saisonnière étant [constante/croissante avec le niveau], nous avons retenu une structure [additive/multiplicative], ",
                            "et appliqué [aucune transformation/log/Box–Cox] afin de stabiliser la variance. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Une décomposition [classique/STL] a permis d’identifier une tendance [..] et une saisonnalité [stable/évolutive]. ",
                            "L’amplitude saisonnière était [constante/proportionnelle au niveau], motivant une structure [additive/log-transformée]."
                          ),
                          meaning_text = "Cette conclusion signifie que la structure du signal est comprise : elle justifie les transformations et prépare une stationnarisation cohérente avant l’estimation SARIMA."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Confondre décomposition et modélisation : la décomposition décrit, SARIMA estime et prédit."),
                            tags$li("Oublier que la stationnarité doit encore être testée après ces diagnostics."),
                            tags$li("Choisir multiplicatif sans traiter la présence de zéros (log impossible sans ajustement).")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 4 — Stationnarité & différenciation + tests
      # =========================================================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "choisir d, D et s pour obtenir une série approximativement stationnaire. On vise une stationnarité ‘suffisante’ avec le minimum de différenciation afin d’éviter la sur-différenciation, source d’instabilité.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Fixer s (période saisonnière)."),
                            tags$li("Choisir d (diff non saisonnière) et D (diff saisonnière)."),
                            tags$li("Justifier avec EDA + ACF/PACF + tests ADF/KPSS/PP + anti-sur-diff.")
                          )
                        ),
                        
                        D("Définitions indispensables (cliquables)", open = FALSE,
                          TERM(
                            "Différenciation ordinaire (d)",
                            "Différencier consiste à remplacer y_t par sa variation : ∇y_t = y_t − y_{t−1}. Cela réduit les tendances stochastiques et rend la moyenne plus stable.",
                            purpose="Rendre la série plus stationnaire pour que l’ARMA (p,q) capture la dépendance restante.",
                            criteria="d est souvent 0 ou 1 ; d=2 est rare et doit être défendu.",
                            how_to_apply="Tester d=0 puis d=1, re-vérifier ACF et tests ; arrêter dès que stationnarité raisonnable.",
                            formula="(1-B)^d y_t"
                          ),
                          TERM(
                            "Différenciation saisonnière (D)",
                            "Différencier saisonnièrement compare y_t à y_{t−s}. Cela retire une composante saisonnière persistante (racine unitaire saisonnière).",
                            purpose="Stabiliser la saison avant d’estimer les termes saisonniers (P,Q).",
                            criteria="D=0 ou 1 dans la plupart des cas ; D=2 est très rare.",
                            how_to_apply="Si pics ACF forts à s et saison persistante, tester D=1, puis vérifier qu’on n’a pas sur-diff (ACF très négative à s).",
                            formula="(1-B^s)^D y_t"
                          ),
                          TERM(
                            "Sur-différenciation",
                            "La sur-différenciation signifie retirer trop de structure (d ou D trop grand), ce qui peut créer une autocorrélation négative artificielle et gonfler la variance.",
                            purpose="Éviter instabilité et oscillations des prévisions.",
                            criteria="ACF lag1 très négative (sur-diff d) ou ACF lag s très négative (sur-diff D).",
                            how_to_apply="Réduire d/D si symptômes, puis re-tester.",
                            notes="Règle pratique : ‘minimum de différenciation pour stationnariser’.")
                        ),
                        
                        D("Tests (purpose + critères détaillés)", open = FALSE,
                          TEST(
                            name="ADF — Augmented Dickey–Fuller (racine unitaire)",
                            purpose="Détecter si la série se comporte comme si elle avait une racine unitaire (non-stationnarité de type marche aléatoire), en testant si le niveau passé explique Δy_t d’une manière compatible avec une dérive persistante.",
                            when_to_use="Sur série brute puis série différenciée, pour décider d et valider la stationnarité obtenue.",
                            H0="Racine unitaire → non-stationnaire.",
                            H1="Stationnaire (selon spécification drift/trend).",
                            statistic="Régression ADF avec retards de Δy_t pour absorber autocorrélation.",
                            decision_rule="p<α (souvent 0.05) → rejet H0 → stationnarité plausible ; sinon → d possiblement insuffisant.",
                            interpretation="Rejeter H0 suggère que les chocs ne produisent pas une dérive permanente (retour vers un comportement stable).",
                            what_it_means_for_choices="Si ADF ne rejette pas sur la série brute → tester d=1 (et/ou D=1 si saison). Si ADF rejette après transformation → passer à l’identification p,q,P,Q.",
                            reporting="Préciser drift/trend, retards, p-value, conclusion sur d.",
                            caveats="Sensibilité aux retards et ruptures structurelles."
                          ),
                          TEST(
                            name="KPSS — stationnarité comme H0",
                            purpose="Compléter ADF en testant la stationnarité comme hypothèse nulle : on détecte si une composante de marche aléatoire résiduelle est trop grande pour être compatible avec une série stationnaire.",
                            when_to_use="Après ADF/PP, pour trianguler la décision et détecter une non-stationnarité résiduelle.",
                            H0="Stationnaire (niveau ou tendance selon version).",
                            H1="Non-stationnaire.",
                            decision_rule="p<α → rejet stationnarité ; p≥α → compatible stationnarité.",
                            interpretation="KPSS non significatif après différenciation renforce l’idée qu’on a bien stationnarisé la série.",
                            what_it_means_for_choices="Si KPSS rejette après d/D, reconsidérer d/D, s, ou la présence de rupture.",
                            reporting="Préciser version level/trend + p-value + conclusion.",
                            caveats="Très sensible aux ruptures; dépend du choix de variance longue."
                          ),
                          TEST(
                            name="PP — Phillips–Perron (racine unitaire corrigée)",
                            purpose="Tester la racine unitaire comme ADF, mais avec une correction non-paramétrique de l’autocorrélation et de l’hétéroscédasticité, réduisant la dépendance au choix des retards.",
                            when_to_use="Alternative/complément à ADF, surtout si autocorrélation/hétéroscédasticité suspectée.",
                            H0="Racine unitaire → non-stationnaire.",
                            H1="Stationnaire.",
                            decision_rule="p<α → rejet racine unitaire.",
                            interpretation="Concordance ADF+PP renforce la conclusion.",
                            what_it_means_for_choices="Désaccord ADF/PP → vérifier drift/trend, ruptures, et s’appuyer davantage sur ACF/plots.",
                            reporting="Rapporter p-value + spécification + décision.",
                            caveats="Comme ADF : sensible aux ruptures."
                          )
                        ),
                        
                        D("Critères de choix (décision) — d, D, s", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("Règle 1 — Triangulation ADF/KPSS/PP",
                                                  note = "Décision robuste = convergence des indices.",
                                                  tags$ul(
                                                    tags$li("ADF/PP rejettent + KPSS ne rejette pas → stationnarité solide."),
                                                    tags$li("ADF/PP ne rejettent pas + KPSS rejette → différenciation nécessaire."),
                                                    tags$li("Conflit → utiliser ACF/PACF + visualisation + minimal d/D.")
                                                  )
                                   ),
                                   criteria_block("Règle 2 — Anti sur-différenciation",
                                                  note = "Sur-diff = instabilité + autocorrélation négative artificielle.",
                                                  tags$ul(
                                                    tags$li("ACF lag1 très négative → réduire d."),
                                                    tags$li("ACF lag s très négative → réduire D."),
                                                    tags$li("Si d=2 ou D=2 : re-vérifier s/données/ruptures.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Choix final : s, d, D + justification (tests + ACF + plots)."),
                            tags$li("Phrase de conclusion : ‘stationnarité raisonnable obtenue’ + mention anti-sur-diff.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Fixer la période saisonnière s à partir du calendrier, puis confirmer via ACF (pics à s,2s,3s).",
                          "Tester stationnarité sur la série brute (ADF/PP + KPSS) et noter les conclusions.",
                          "Appliquer D=1 si saison persistante, puis re-vérifier ACF (attention ACF négative à s).",
                          "Appliquer d=1 si tendance stochastique, puis re-vérifier tests + ACF (attention ACF lag1 très négative).",
                          "Retenir le couple (d,D) minimal qui rend la série stationnaire de façon raisonnable."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Méthodes (Stationnarité & différenciation). "),
                            "Décrire les tests utilisés (ADF/KPSS/PP), expliquer pourquoi leurs hypothèses nulles sont complémentaires, ",
                            "puis justifier les valeurs choisies de d et D. Indiquer explicitement la période saisonnière s et mentionner la vérification anti-sur-différenciation."),
                          P(tags$b("Exemple (papier). "),
                            "« La stationnarité a été évaluée via ADF, KPSS et PP. Sur la base des résultats combinés et des diagnostics ACF, ",
                            "nous avons retenu d=[..] et D=[..] avec une période saisonnière s=[..]. ",
                            "Nous avons privilégié la solution la plus parcimonieuse et vérifié l’absence de sur-différenciation. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "La stationnarité a été évaluée à l’aide des tests ADF, KPSS et PP (hypothèses nulles complémentaires). ",
                            "En s’appuyant sur ces résultats et sur les diagnostics ACF/PACF, nous avons retenu d=[..] et D=[..] avec une période saisonnière s=[..], ",
                            "tout en vérifiant l’absence de sur-différenciation."
                          ),
                          meaning_text = "Cette conclusion signifie que la série a été transformée en une forme adaptée à un modèle ARMA (donc SARIMA), et que l’on peut maintenant identifier p,q,P,Q sur une base stationnaire."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Sur-différenciation (ACF très négative) → modèle instable et prévisions oscillantes."),
                            tags$li("Choisir s sans sens calendrier → saison artificielle."),
                            tags$li("Conflits de tests ignorés : expliquer la décision par convergence d’indices.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 5 — Baseline
      # =========================================================
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "construire des références (naïf/naïf saisonnier) et une baseline auto-ARIMA, puis définir une règle de sélection qui combine AICc/BIC, diagnostics et performance out-of-sample.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Construire benchmarks : naïf et naïf saisonnier."),
                            tags$li("Obtenir une baseline SARIMA via auto-ARIMA (AICc/BIC)."),
                            tags$li("Comparer sur la même validation et retenir une base pour l’étape manuelle.")
                          )
                        ),
                        
                        D("Concepts (cliquables)", open = FALSE,
                          TERM(
                            "Naïf",
                            "Le modèle naïf suppose que le futur est identique à la dernière observation. Il constitue un benchmark minimal, souvent étonnamment compétitif sur des séries très persistantes.",
                            purpose="Vérifier que votre modèle apporte plus qu’une simple persistance.",
                            criteria="Si votre modèle ne bat pas le naïf, il est rarement utile en pratique.",
                            formula="ŷ_{t+h} = y_t"
                          ),
                          TERM(
                            "Naïf saisonnier",
                            "Le modèle naïf saisonnier suppose que le futur ressemble à la même saison précédente (ex : même mois l’an dernier).",
                            purpose="Benchmark essentiel si la série est saisonnière.",
                            criteria="À battre absolument si saisonnalité forte et stable.",
                            formula="ŷ_{t+h} = y_{t+h-s}"
                          ),
                          TERM(
                            "Auto-ARIMA",
                            "Auto-ARIMA explore des ordres (p,q,P,Q) sous contraintes et choisit une spécification selon un critère d’information (souvent AICc), fournissant une baseline solide.",
                            purpose="Point de départ robuste et reproductible, pas une vérité absolue.",
                            criteria="Documenter stepwise vs exhaustive, bornes max p/q, et transformations.",
                            notes="Toujours valider hors échantillon et vérifier diagnostics."
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          decision_rule_list(
                            tags$li("Garder une baseline parcimonieuse si ΔAICc < 2 entre modèles."),
                            tags$li("Exiger au minimum : performance ≥ benchmarks et diagnostics résiduels acceptables."),
                            tags$li("Si gain marginal : préférer simplicité (stabilité, interprétation).")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Table : benchmarks + auto-ARIMA (AICc/BIC + MAE/RMSE test)."),
                            tags$li("Baseline retenue comme point de comparaison pour la sélection manuelle.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Calculer les erreurs (MAE/RMSE) des benchmarks (naïf, naïf saisonnier) sur la même fenêtre d’évaluation.",
                          "Exécuter auto-ARIMA avec des bornes raisonnables et documenter les paramètres de recherche (stepwise, max p/q, etc.).",
                          "Comparer auto-ARIMA aux benchmarks (accuracy) et vérifier rapidement les diagnostics.",
                          "Choisir une baseline ‘référence’ (souvent celle d’AICc minimal) tout en respectant la parcimonie (ΔAICc<2).",
                          "Conserver cette baseline comme base de discussion pour les candidats manuels."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Méthodes (Baseline). "),
                            "Expliquer les benchmarks utilisés, la procédure auto-ARIMA (critère, contraintes, recherche), et la manière dont la baseline a été comparée en prévision."),
                          P(tags$b("Exemple (papier). "),
                            "« Des benchmarks naïf et naïf saisonnier ont été estimés. Une baseline SARIMA a été sélectionnée via auto-ARIMA en minimisant l’AICc sous contraintes [..]. ",
                            "Les modèles ont été comparés sur [split/rolling-origin] à l’aide de [MAE, RMSE]. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Une baseline SARIMA a été sélectionnée via auto-ARIMA (minimisation de l’AICc) et comparée aux benchmarks naïf et naïf saisonnier ",
                            "sur un protocole d’évaluation temporel utilisant [MAE, RMSE]. La spécification retenue a servi de point de départ pour l’affinement guidé par la théorie."
                          ),
                          meaning_text = "Cette conclusion signifie que vous disposez d’une référence objective : votre sélection manuelle devra au minimum égaler ou améliorer cette baseline (et battre les benchmarks)."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Prendre auto-ARIMA comme ‘vérité’ sans validation out-of-sample."),
                            tags$li("Comparer des modèles sur des splits différents : invalide."),
                            tags$li("Choisir un modèle très complexe pour un gain marginal : risque d’instabilité.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 6 — Identification manuelle (ACF/PACF)
      # =========================================================
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "proposer un petit ensemble de modèles SARIMA plausibles à partir de ACF/PACF (sur série stationnaire), puis sélectionner par parcimonie + AICc/BIC + stabilité, avant diagnostics complets.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Tracer ACF/PACF sur la série (après d et D)."),
                            tags$li("Proposer p,q et P,Q plausibles (petit ensemble)."),
                            tags$li("Comparer par AICc/BIC + stabilité, sans brute-force.")
                          )
                        ),
                        
                        D("Concepts (cliquables)", open = FALSE,
                          TERM("ACF",
                               "L’ACF mesure la corrélation entre y_t et y_{t-k}. Sur une série stationnaire, elle aide à suggérer des composantes MA (q) et MA saisonnières (Q) via des pics aux retards pertinents.",
                               purpose="Suggérer q et Q, et confirmer la saisonnalité via des pics à s,2s,3s.",
                               criteria="MA(q) : ACF ‘coupe’ après q ; saison : pics aux multiples de s.",
                               how_to_apply="Lire les motifs (pas un pic isolé) et garder q/Q petits."),
                          TERM("PACF",
                               "La PACF mesure la corrélation partielle à un retard k, en contrôlant les retards plus petits. Elle suggère des composantes AR (p) et AR saisonnières (P).",
                               purpose="Suggérer p et P.",
                               criteria="AR(p) : PACF ‘coupe’ après p ; pics à s → P plausible.",
                               how_to_apply="Garder p/P petits et vérifier ensuite par diagnostics.")
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("p,q (non saisonnier)",
                                                  note = "Heuristique : PACF → p ; ACF → q.",
                                                  tags$ul(
                                                    tags$li("Limiter p,q ≤ 3 sauf justification forte."),
                                                    tags$li("Si ΔAICc < 2, choisir le plus simple.")
                                                  )
                                   ),
                                   criteria_block("P,Q (saisonnier)",
                                                  note = "Heuristique : pics à s dans PACF → P ; dans ACF → Q.",
                                                  tags$ul(
                                                    tags$li("Souvent P,Q ∈ {0,1}."),
                                                    tags$li("Éviter de multiplier les paramètres saisonniers inutilement.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Liste de 3–8 candidats SARIMA((p,d,q)(P,D,Q)[s])."),
                            tags$li("Justification ACF/PACF + tableau AICc/BIC + stabilité.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Travailler sur la série stationnaire (après d et D) et tracer ACF + PACF.",
                          "Noter les motifs : coupure/décroissance aux petits lags et pics aux multiples de s.",
                          "Proposer une grille courte (3–8 modèles) en variant p,q,P,Q autour des motifs observés.",
                          "Ajuster ces modèles et comparer AICc/BIC, en privilégiant la parcimonie.",
                          "Écarter les modèles instables/non inversibles, même si AICc est bon."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Méthodes (Sélection guidée par la théorie). "),
                            "Décrire comment ACF/PACF a été utilisé pour proposer des ordres candidats, puis comment ces candidats ont été comparés et filtrés."),
                          P(tags$b("Exemple (papier). "),
                            "« Les structures candidates ont été proposées d’après ACF/PACF de la série différenciée. ",
                            "Des pics aux retards [..] suggéraient des composantes [AR/MA] non saisonnières et des pics aux multiples de s suggéraient des composantes saisonnières. ",
                            "Un ensemble restreint de modèles a été ajusté puis comparé via AICc/BIC, en privilégiant la parcimonie et la stabilité. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Sur la série stationnaire (après différenciation), ACF/PACF a guidé la proposition d’un ensemble restreint de modèles SARIMA candidats. ",
                            "Les modèles ont été comparés via [AICc/BIC] et filtrés selon la parcimonie et la stabilité, avant diagnostics résiduels approfondis."
                          ),
                          meaning_text = "Cette conclusion signifie que la sélection est raisonnée : vous limitez le risque de sur-ajustement en testant peu de modèles, mais bien motivés, avant la validation finale par les résidus et la prévision."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Lire ACF/PACF comme des ‘commandements’ : ce sont des heuristiques, pas des certitudes."),
                            tags$li("Tester 200 modèles au hasard : ce n’est pas de la ‘théorie’."),
                            tags$li("Garder un modèle instable car AICc est plus bas : risque de mauvaises prévisions.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 7 — Diagnostics & comparaison finale
      # =========================================================
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "valider le modèle final : (1) résidus proches du bruit blanc (modèle adéquat), (2) prévision meilleure que les benchmarks, (3) parcimonie si performances similaires.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Diagnostics résidus : résidus ~ bruit (ACF résidus faible, Ljung–Box non significatif)."),
                            tags$li("Vérifier variance/normalité si nécessaire (selon contexte)."),
                            tags$li("Comparer accuracy out-of-sample vs baseline et benchmarks.")
                          )
                        ),
                        
                        D("Tests résidus (cliquables)", open = FALSE,
                          TEST(
                            name="Ljung–Box (autocorrélation résiduelle)",
                            purpose="Tester si les résidus conservent une structure temporelle (autocorrélation). Si oui, le modèle n’a pas capturé toute la dépendance, et les prévisions peuvent être biaisées.",
                            when_to_use="Toujours après estimation SARIMA, pour un lag L raisonnable (ex : 10, 2s).",
                            H0="Résidus ~ bruit blanc jusqu’au lag L (pas d’autocorrélation).",
                            H1="Autocorrélation résiduelle.",
                            decision_rule="p≥0.05 → acceptable ; p<0.05 → modèle incomplet → revoir p/q/P/Q/d/D.",
                            interpretation="Un rejet signifie que des motifs restent non modélisés (saison manquante, ordre insuffisant, sous/sur différenciation).",
                            what_it_means_for_choices="Si rejet, ajuster la structure (AR/MA, saison) et recommencer. Si non rejet, passer au choix final via performance + parcimonie.",
                            reporting="Rapporter L, Q, p-value et une conclusion explicite sur le bruit blanc.",
                            caveats="Sensibilité à L et au n ; grands n → test très sensible."
                          ),
                          TEST(
                            name="ARCH LM (si variance conditionnelle suspectée)",
                            purpose="Détecter si la variance des résidus ‘clusterise’ (volatilité). Important si vous produisez des intervalles fiables, notamment en finance.",
                            when_to_use="Si les résidus montrent une variance variable, ou si ACF des résidus^2 est significative.",
                            H0="Pas d’ARCH (variance conditionnelle constante).",
                            H1="ARCH présent.",
                            decision_rule="p<0.05 → variance conditionnelle → envisager une extension (ex : GARCH) si nécessaire."
                          )
                        ),
                        
                        D("Critères de choix (décision)", open = TRUE,
                          decision_rule_list(
                            tags$li("Exiger résidus ‘raisonnablement’ blancs : Ljung–Box non significatif (ou au moins pas de structure majeure)."),
                            tags$li("Exiger performance > benchmarks (naïf / naïf saisonnier)."),
                            tags$li("Si deux modèles ont des erreurs proches : choisir le plus simple.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Figures : résidus vs temps, ACF résidus, QQ-plot (optionnel)."),
                            tags$li("Table : MAE/RMSE (test) + Ljung–Box p-values + AICc/BIC."),
                            tags$li("Décision : modèle final SARIMA((p,d,q)(P,D,Q)[s]).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Tracer les résidus (temps) et vérifier qu’ils oscillent autour de 0 sans structure visible.",
                          "Tracer l’ACF des résidus : vérifier absence de pics systématiques.",
                          "Faire Ljung–Box (plusieurs L) et noter les p-values.",
                          "Évaluer la prévision sur test/rolling avec MAE/RMSE ; comparer aux benchmarks et à la baseline.",
                          "Choisir le modèle final : diagnostics OK + performance + parcimonie."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Résultats (Diagnostics & performance). "),
                            "Résumer les diagnostics des résidus (bruit blanc ou non), puis rapporter les métriques de prévision sur la fenêtre d’évaluation. ",
                            "Expliquer pourquoi le modèle final est retenu (validité + précision + simplicité)."),
                          P(tags$b("Exemple (papier). "),
                            "« Les résidus du modèle final présentaient une dynamique compatible avec du bruit blanc : l’ACF résiduelle ne montrait pas de structure majeure et le test de Ljung–Box était [non significatif] au seuil α=0.05. ",
                            "En prévision hors échantillon, le modèle obtenait MAE=[..] et RMSE=[..], améliorant les benchmarks [..]. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Les diagnostics des résidus indiquaient un comportement proche du bruit blanc (Ljung–Box : p=[..] pour L=[..]). ",
                            "La performance de prévision hors échantillon était MAE=[..] et RMSE=[..], supérieure aux benchmarks [..]. ",
                            "Le modèle retenu était SARIMA((p,d,q)(P,D,Q)[s])."
                          ),
                          meaning_text = "Cette conclusion signifie que le modèle capture la dépendance temporelle principale (résidus peu autocorrélés) et apporte un gain prédictif réel par rapport aux méthodes simples."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Excellent AICc mais résidus autocorrélés : modèle inadéquat malgré un bon ajustement apparent."),
                            tags$li("Sur-interpréter la normalité : l’enjeu principal est l’autocorrélation résiduelle."),
                            tags$li("Garder un modèle complexe pour un gain minime : risque de fragilité en production.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 8 — Rédaction / Livrables
      # =========================================================
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "produire un rapport clair et reproductible : l’étudiant doit relier chaque décision (préparation, stationnarité, choix de modèle) aux preuves (figures, tests, métriques) et conclure sur le sens et les limites.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Assembler Méthodes + Résultats alignés sur les étapes 0–7."),
                            tags$li("Inclure figures et tables minimales (EDA, décomposition, ACF/PACF, résidus, prévisions)."),
                            tags$li("Rédiger une conclusion interprétable (sens, limites, recommandation).")
                          )
                        ),
                        
                        D("Équation SARIMA (rappel)", open = FALSE,
                          P(tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t")),
                          P(class="small",
                            "Lecture : on stationnarise via différenciation, puis AR/MA (saisonniers et non saisonniers) modélisent la dépendance restante."
                          )
                        ),
                        
                        D("Sorties attendues", open = TRUE,
                          tags$ul(
                            tags$li("Notebook/script reproductible (du chargement des données aux prévisions finales)."),
                            tags$li("Rapport court : Méthodes + Résultats + Discussion/Limites + Conclusion."),
                            tags$li("Annexes : tableau comparatif des modèles (AICc, MAE/RMSE, diagnostics).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE Pièges)
                        STUDENT_DO(
                          "Écrire Méthodes : données (source, fréquence), préparation (NA/outliers/transformation), stationnarité (tests), sélection (baseline + candidats), diagnostics, protocole d’évaluation.",
                          "Écrire Résultats : EDA (constats), décomposition, tests stationnarité, modèle final, diagnostics résidus, performance out-of-sample.",
                          "Insérer figures clés : série, STL, ACF/PACF, résidus + ACF résidus, prévisions + intervalles.",
                          "Construire une table de comparaison : candidats vs AICc/BIC + MAE/RMSE + Ljung–Box.",
                          "Conclure : modèle retenu, ce que cela signifie, limites (ruptures, exogènes, volatilité) et recommandations."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Structure (papier). "),
                            "Chaque sous-section doit suivre : (1) Ce qu’on a fait, (2) Pourquoi on l’a fait, (3) Ce qu’on a observé, (4) Conclusion locale. ",
                            "L’objectif pédagogique est de montrer un raisonnement, pas seulement des résultats."),
                          P(tags$b("Exemple (papier). "),
                            "« Après préparation des données, nous avons évalué la stationnarité via ADF/KPSS/PP et retenu d=[..], D=[..], s=[..]. ",
                            "Un ensemble de modèles candidats a été ajusté (baseline auto-ARIMA + sélection guidée par ACF/PACF). ",
                            "Le modèle final a été choisi selon diagnostics résiduels (Ljung–Box) et performance de prévision (MAE/RMSE) comparée aux benchmarks. »")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "En synthèse, la série a été préparée et stationnarisée (d=[..], D=[..], s=[..]) avant l’ajustement d’un ensemble de modèles SARIMA candidats. ",
                            "Le modèle final, SARIMA((p,d,q)(P,D,Q)[s]), a été retenu sur la base de diagnostics résiduels satisfaisants et d’une performance de prévision supérieure aux benchmarks. ",
                            "Ces résultats suggèrent que la dynamique observée (tendance/saisonnalité) est suffisamment stable pour produire des prévisions utiles à horizon (h=[..]), sous réserve des limites discutées."
                          ),
                          meaning_text = "Cette conclusion signifie que vous reliez explicitement les preuves (tests, diagnostics, performance) à une recommandation de modèle, tout en cadrant l’utilisation (horizon, stabilité supposée, limites)."
                        ),
                        
                        D("Pièges", open = FALSE,
                          tags$ul(
                            tags$li("Rapport sans protocole clair : impossible de reproduire l’évaluation."),
                            tags$li("Accumuler des figures sans interprétation : valeur pédagogique faible."),
                            tags$li("Oublier les limites (ruptures, exogènes) : conclusion trop forte.")
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "Étape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (très détaillée) — FR"),
                          tags$p(class="road-sub",
                                 "Slider pour naviguer sans défiler. Chaque étape : Objectif → Analyses → Critères → Sorties → ",
                                 tags$b("Ce que les étudiants font → Ce qu’ils écrivent (papier) → Conclusion APA"), " → Pièges."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Étape (slider — pas besoin de scroll)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  # ==========================================================================================
  # ==========================================================================================
  
  
  # ============================================================
  # خارطة طريق SARIMA فائقة التفصيل (AR) — سلايدر + أقسام قابلة للطي
  # تم تنظيمها حسب: الهدف → التحليلات → الاختبارات → معايير القرار → المخرجات → الأخطاء الشائعة
  #
  # طريقة الاستخدام
  # 1) في واجهة UI:   uiOutput("roadmap_Detailed_Ar_ui")
  # 2) في server(): انسخ/الصق كل الكود داخل  server <- function(input, output, session) { ... }
  # ============================================================
  
  # output$roadmap_Detailed_Ar_ui2 <- renderUI({
  #   
  #   # ----------------------------
  #   # أدوات مساعدة لبناء الأقسام القابلة للطي (Accordion)
  #   # ----------------------------
  #   Acc <- function(title, ..., open = FALSE, class = NULL) {
  #     tags$details(
  #       class = paste("acc", class),
  #       open  = if (isTRUE(open)) "open" else NULL,
  #       tags$summary(title),
  #       tags$div(class = "acc-body", ...)
  #     )
  #   }
  #   D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # مستوى 1
  #   S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # مستوى 2
  #   
  #   callout <- function(..., type = c("info","ok","warn")) {
  #     type <- match.arg(type)
  #     cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
  #     tags$div(class = cls, ...)
  #   }
  #   
  #   # مُساعد فقرة لكتابة جمل طويلة بطريقة مقروءة
  #   P <- function(...) tags$p(...)
  #   
  #   TERM <- function(term, definition,
  #                    purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
  #                    notes = NULL, how_to_apply = NULL, what_to_write = NULL,
  #                    open = FALSE) {
  #     Acc(
  #       term,
  #       tags$div(class="term-box",
  #                P(tags$b("التعريف: "), definition),
  #                if (!is.null(purpose))       P(tags$b("الهدف/الفائدة: "), purpose) else NULL,
  #                if (!is.null(criteria))      P(tags$b("المعايير/المؤشرات: "), criteria) else NULL,
  #                if (!is.null(how_to_apply))  P(tags$b("كيف نستخدمه في التحليل: "), how_to_apply) else NULL,
  #                if (!is.null(formula))       P(tags$b("الترميز/المعادلة: "), tags$code(formula)) else NULL,
  #                if (!is.null(example))       P(tags$b("مثال: "), example) else NULL,
  #                if (!is.null(what_to_write)) P(tags$b("جملة نموذجية للكتابة: "), what_to_write) else NULL,
  #                if (!is.null(notes))         P(tags$b("ملاحظات: "), notes) else NULL
  #       ),
  #       open = open,
  #       class = "term"
  #     )
  #   }
  #   
  #   TEST <- function(name,
  #                    purpose, when_to_use, H0, H1,
  #                    statistic = NULL,
  #                    decision_rule = NULL,
  #                    interpretation = NULL,
  #                    what_it_means_for_choices = NULL,
  #                    reporting = NULL,
  #                    caveats = NULL,
  #                    open = FALSE) {
  #     Acc(
  #       name,
  #       tags$div(class="test-box",
  #                P(tags$b("الهدف (بتفصيل): "), purpose),
  #                P(tags$b("متى نستخدمه: "), when_to_use),
  #                P(tags$b("الفرضية الصفرية H0: "), H0),
  #                P(tags$b("الفرضية البديلة H1: "), H1),
  #                if (!is.null(statistic))                 P(tags$b("الفكرة/الإحصاء: "), statistic) else NULL,
  #                if (!is.null(decision_rule))             P(tags$b("قاعدة القرار: "), decision_rule) else NULL,
  #                if (!is.null(interpretation))            P(tags$b("التفسير (المعنى): "), interpretation) else NULL,
  #                if (!is.null(what_it_means_for_choices)) P(tags$b("ماذا يعني هذا لقراراتك: "), what_it_means_for_choices) else NULL,
  #                if (!is.null(reporting))                 P(tags$b("كيف نكتب النتيجة في التقرير: "), reporting) else NULL,
  #                if (!is.null(caveats))                   P(tags$b("القيود/الأخطاء الشائعة: "), caveats) else NULL
  #       ),
  #       open = open,
  #       class = "test"
  #     )
  #   }
  #   
  #   # ----------------------------
  #   # CSS + JS (سلوك الأقسام القابلة للطي)
  #   # ----------------------------
  #   css <- tags$style(HTML("
  #   .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px; direction: rtl; text-align: right;}
  #   .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
  #   .road-title {margin:0 0 6px 0;}
  #   .road-sub {margin:0; color:#444;}
  #   .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
  #   details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
  #   details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
  #   details.acc .acc-body {margin-top:10px;}
  #   details.acc.level2 {margin-right:4px;}
  #   details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
  #   .callout {border-right:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
  #   .callout.warn {border-right-color:#E45756; background:#fff7f7;}
  #   .callout.ok {border-right-color:#72B7B2; background:#f7fffb;}
  #   code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
  #   .small {font-size: 12.5px; color:#555;}
  #   .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-left:6px; font-size:12px;}
  #   .step-tag {margin-top:6px;}
  #   .tight p {margin: 6px 0;}
  #   .tight ul {margin: 6px 0 6px 18px;}
  #   .tight ol {margin: 6px 0 6px 18px;}
  #   .grid {display:flex; flex-wrap:wrap; gap:10px;}
  #   .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
  #   .box h5 {margin:0 0 6px 0;}
  #   .muted {color:#555;}
  # "))
  #   
  #   js <- tags$script(HTML("
  #   function closeSiblings(d, cls){
  #     const p = d.parentElement;
  #     if(!p) return;
  #     p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
  #   }
  #   document.addEventListener('toggle', function(e){
  #     const d = e.target;
  #     if(!d || d.tagName !== 'DETAILS' || !d.open) return;
  #     if(d.classList.contains('level1')) closeSiblings(d, 'level1');
  #     if(d.classList.contains('level2')) closeSiblings(d, 'level2');
  #     if(d.classList.contains('term'))   closeSiblings(d, 'term');
  #     if(d.classList.contains('test'))   closeSiblings(d, 'test');
  #   }, true);
  # "))
  #   
  #   # ----------------------------
  #   # عناوين الخطوات + الشارات
  #   # ----------------------------
  #   step_title <- function(k) {
  #     c(
  #       "[0] تحديد المشكلة وطريقة التقييم",
  #       "[1] جودة البيانات والتحضير (قيم مفقودة، تردد، قيم شاذة)",
  #       "[2] الاستكشاف البصري (اتجاه، موسمية، تباين)",
  #       "[3] التفكيك (إضافي/ضربي، STL)",
  #       "[4] السكون (Stationarity) والفروق (d, D, s) + الاختبارات",
  #       "[5] خط أساس (Naive / Auto-ARIMA) + معايير الاختيار",
  #       "[6] تحديد النموذج يدويًا (ACF/PACF) + قائمة المرشحين",
  #       "[7] التشخيص والمقارنة النهائية (اختبارات البواقي + دقة التنبؤ)",
  #       "[8] كتابة التقرير: الخلاصة، المعنى، والمخرجات"
  #     )[k + 1]
  #   }
  #   
  #   step_badges <- function(k) {
  #     badges <- list(
  #       c("الهدف", "الأفق", "البروتوكول", "المقاييس"),
  #       c("التردد", "قيم مفقودة", "قيم شاذة", "تحويلات"),
  #       c("رسوم", "موسمية", "تباين", "إشارة"),
  #       c("STL", "إضافي/ضربي", "بنية"),
  #       c("ADF/KPSS/PP", "d/D/s", "قواعد القرار"),
  #       c("خط أساس", "AICc/BIC", "Naive"),
  #       c("ACF/PACF", "بساطة", "مرشحون"),
  #       c("Ljung–Box", "ARCH", "طبيعية", "Accuracy"),
  #       c("تلخيص", "خلاصة", "معنى", "قابل لإعادة الإنتاج")
  #     )[[k + 1]]
  #     tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
  #   }
  #   
  #   # ----------------------------
  #   # أدوات صغيرة (كتل المعايير)
  #   # ----------------------------
  #   criteria_block <- function(title, ..., note = NULL) {
  #     tags$div(class="box",
  #              tags$h5(title),
  #              if (!is.null(note)) tags$p(class="muted", note) else NULL,
  #              ...
  #     )
  #   }
  #   
  #   decision_rule_list <- function(...) {
  #     tags$ul(...)
  #   }
  #   
  #   # ------------------------------------------------------------
  #   # محتوى كل خطوة (مترجم للعربية + موسّع بجمل تفسيرية)
  #   # ------------------------------------------------------------
  #   step_content <- function(k) {
  #     
  #     # =========================================================
  #     # الخطوة 0 — تحديد المشكلة والتقييم
  #     # =========================================================
  #     if (k == 0) {
  #       return(tags$div(class="road-card tight",
  #                       
  #                       callout(
  #                         tags$b("الهدف: "),
  #                         "تحديد مهمة التنبؤ بدقة ووضع بروتوكول تقييم موثوق، لأن أي نموذج (حتى لو كان ممتازًا رياضيًا) لا يمكن الحكم عليه إذا لم نحدد مسبقًا ما الذي نتنبأ به وكيف نقيس جودة التنبؤ.",
  #                         type="ok"
  #                       ),
  #                       
  #                       D("المطلوب في هذه الخطوة", open = TRUE,
  #                         P("في هذه المرحلة، يجب على الطالب صياغة المشكلة بصيغة قابلة للتنفيذ: ما المتغير الهدف y_t؟ ما التردد الزمني؟ ما أفق التنبؤ h؟ وكيف سنقسم البيانات للتدريب والاختبار؟ الفكرة الأساسية هي أن تغيير الأفق أو طريقة التقسيم يعني أنك أجبت على سؤال مختلف."),
  #                         tags$ul(
  #                           tags$li("تحديد الهدف ", tags$code("y_t"), " وتحديد التردد الزمني (انتظام الفواصل الزمنية)."),
  #                           tags$li("تحديد أفق التنبؤ ", tags$code("h"), " بحيث يكون منطقيًا بالنسبة للاستخدام الحقيقي."),
  #                           tags$li("تحديد بروتوكول التقييم (تدريب/اختبار أو Rolling-origin) ومقاييس الخطأ (MAE/RMSE/...)."),
  #                           tags$li("تحديد نماذج المقارنة (Benchmark): نموذج Naive ونموذج Naive موسمي عند وجود موسمية.")
  #                         )
  #                       ),
  #                       
  #                       D("التحليلات التي يجب القيام بها", open = TRUE,
  #                         P("نقوم هنا ببناء إطار تقييم “عادل”: نحترم الزمن (لا نخلط الماضي بالمستقبل)، ونختار مقاييس خطأ تعكس تكلفة الخطأ في الواقع. من المهم استخدام مقياسين على الأقل لأن MAE وRMSE يلتقطان نوعين مختلفين من الخطأ."),
  #                         tags$div(class="grid",
  #                                  criteria_block("A1 — تحديد التردد والموسمية (s)",
  #                                                 note = "الهدف: التأكد من أن السلسلة على شبكة زمنية منتظمة وأن قيمة s لها معنى تقويمي (كالأسابيع/الشهور).",
  #                                                 tags$ul(
  #                                                   tags$li("تحديد الدقة الزمنية: يومي / أسبوعي / شهري / ..."),
  #                                                   tags$li("استنتاج الموسمية ", tags$code("s"), " (شهري s=12، ربع سنوي s=4، يومي مع موسمية أسبوعية s=7)."),
  #                                                   tags$li("التحقق من عدم وجود فجوات أو تكرار في مؤشر الزمن (الانتظام).")
  #                                                 ),
  #                                                 P("إذا كان مؤشر الزمن غير منتظم، فإن التأخيرات (lags) لا تمثل نفس المدة الزمنية دائمًا، مما يفسد معنى الارتباطات الذاتية ويجعل تقدير SARIMA مضللًا.")
  #                                  ),
  #                                  criteria_block("A2 — تحديد التقييم (Validation)",
  #                                                 note = "الهدف: قياس الأداء على مستقبل غير مرئي كما يحدث في التطبيق الحقيقي.",
  #                                                 tags$ul(
  #                                                   tags$li(tags$b("تدريب/اختبار زمني: "), "التدريب على الماضي والاختبار على المستقبل (ممنوع العكس)."),
  #                                                   tags$li(tags$b("Rolling-origin: "), "التقييم عبر أكثر من نقطة أصل → أكثر متانة."),
  #                                                   tags$li("حجم الاختبار: غالبًا ≥ موسم واحد (مثل ≥ 12 شهرًا إن كانت البيانات شهرية) إن أمكن.")
  #                                                 ),
  #                                                 P("Rolling-origin مفيد جدًا تعليميًا لأنه يحاكي واقع التشغيل: النموذج يُحدَّث تدريجيًا ويُقاس أداؤه أكثر من مرة، فتقل احتمالية أن تكون النتيجة “ضربة حظ” على تقسيم واحد.")
  #                                  ),
  #                                  criteria_block("A3 — اختيار مقاييس الخطأ",
  #                                                 note = "الهدف: مواءمة القياس مع معنى الخطأ (وحدات فعلية مقابل عقوبة للأخطاء الكبيرة).",
  #                                                 tags$ul(
  #                                                   tags$li(tags$b("MAE: "), "سهل الفهم وبالوحدات الأصلية ومتين."),
  #                                                   tags$li(tags$b("RMSE: "), "يعاقب الأخطاء الكبيرة بقوة."),
  #                                                   tags$li(tags$b("MAPE: "), "يُستخدم فقط إذا كانت y>0 وبعيدة عن الصفر؛ وإلا فالأفضل sMAPE أو MAE."),
  #                                                   tags$li(tags$b("sMAPE: "), "بديل نسبي أكثر استقرارًا من MAPE.")
  #                                                 ),
  #                                                 P("بشكل مبسط: MAE يجيب “كم أخطئ عادةً؟”، وRMSE يجيب “هل أتجنب الأخطاء الكبيرة؟”. الجمع بينهما يعطي قراءة أوضح لجودة التنبؤ.")
  #                                  )
  #                         )
  #                       ),
  #                       
  #                       D("معايير القرار", open = TRUE,
  #                         P("لكي تكون الخطوة 0 قابلة للتقييم، يجب تحويلها لقرارات واضحة: تثبيت h، تثبيت بروتوكول التقييم، اختيار مقاييس، ثم الالتزام بها حتى نهاية المشروع."),
  #                         decision_rule_list(
  #                           tags$li(tags$b("أفق h: "), "يجب أن يطابق الاستخدام. إن كانت القرارات شهرية، فالأفق بالأشهر ويغطي نافذة قرار مفيدة."),
  #                           tags$li(tags$b("البروتوكول: "), "إذا كانت البيانات كافية فالأفضل Rolling-origin؛ وإلا فالتقسيم الزمني الواضح مع ذكر التواريخ."),
  #                           tags$li(tags$b("المقاييس: "), "اختيار مقياسين على الأقل (مثل MAE وRMSE) لتجنب رؤية أحادية."),
  #                           tags$li(tags$b("الـBenchmark: "), "المقارنة ضرورية. إذا لم يتفوق نموذجك على Naive فهذه نتيجة مهمة تشير لصعوبة السلسلة أو نقص في النموذج.")
  #                         )
  #                       ),
  #                       
  #                       D("تعريفات أساسية (قابلة للطي)", open = FALSE,
  #                         TERM(
  #                           term="السلسلة الزمنية (y_t)",
  #                           definition="السلسلة الزمنية هي تسلسل مشاهدات مرتّبة زمنيًا، بحيث تمثل y_t قيمة الظاهرة عند الزمن t (مثل المبيعات الشهرية أو درجة الحرارة اليومية).",
  #                           purpose="تُجبرنا على تحديد ما الذي نرصده وبأي وحدة وبأي تردد، لأن SARIMA يعتمد على العلاقات بين القيم المتتالية عبر الزمن.",
  #                           criteria="اسأل: ما الوحدة؟ ما التردد؟ ما الفترة الزمنية؟ هل توجد قيم صفرية/سلبية (مهم للتحويلات)؟",
  #                           how_to_apply="قبل أي نمذجة، نتحقق أن البيانات مرتبة زمنيًا، بدون تكرار في التواريخ، وأن كل خطوة زمنية متوقعة موجودة (أو مفقودة بشكل موثق).",
  #                           what_to_write="« المتغير الهدف y_t يمثل [..]، وملاحظ بتردد [..] بين [..] و[..]. »"
  #                         ),
  #                         TERM(
  #                           term="أفق التنبؤ (h)",
  #                           definition="أفق التنبؤ h هو عدد الخطوات المستقبلية المراد التنبؤ بها. مثلًا h=12 في بيانات شهرية يعني توقع 12 شهرًا قادمًا.",
  #                           purpose="يحدد صعوبة المهمة: كلما زاد h زادت عدم اليقين وأصبح التقاط الاتجاه/الموسمية أكثر أهمية.",
  #                           criteria="يجب أن يكون h منطقيًا مقابل كمية البيانات: أفق طويل جدًا مع تاريخ قصير يجعل التنبؤ ضعيف الثقة.",
  #                           how_to_apply="نثبّت h قبل مقارنة النماذج لأن تغيير h يغير الاستنتاجات وقد يجعل نموذجًا ممتازًا على المدى القصير ضعيفًا على المدى البعيد.",
  #                           formula="h"
  #                         )
  #                       ),
  #                       
  #                       D("المخرجات المتوقعة", open = FALSE,
  #                         P("بنهاية الخطوة 0 يجب أن تمتلك “ورقة تعريف مشكلة” كاملة: ما الذي نتنبأ به، كيف نقيمه، وعلى أي أساس نقارنه. هذه الورقة تجعل المشروع قابلاً لإعادة الإنتاج."),
  #                         tags$ul(
  #                           tags$li("وصف كامل لـ y_t (تعريف، وحدة، تردد، تواريخ)."),
  #                           tags$li("h + بروتوكول التقييم + المقاييس + الـBenchmarks."),
  #                           tags$li("قواعد إعادة الإنتاج (Seed إن وُجدت عشوائية، وتواريخ التقسيم بدقة).")
  #                         )
  #                       ),
  #                       
  #                       D("أخطاء شائعة", open = FALSE,
  #                         tags$ul(
  #                           tags$li("خلط الزمن (Shuffle): يؤدي لتسرب معلومات ونتائج مضللة."),
  #                           tags$li("مقارنة نماذج بتقسيمات مختلفة: مقارنة غير عادلة."),
  #                           tags$li("استخدام MAPE مع قيم قريبة من الصفر: قد ينفجر ويشوّه التقييم.")
  #                         )
  #                       )
  #       ))
  #     }
  #     
  #     # =========================================================
  #     # الخطوة 1 — جودة البيانات والتحضير
  #     # =========================================================
  #     if (k == 1) {
  #       return(tags$div(class="road-card tight",
  #                       
  #                       callout(
  #                         tags$b("الهدف: "),
  #                         "ضمان أن السلسلة قابلة للنمذجة (زمن منتظم، قيم مفقودة مُعالجة، قيم شاذة مفهومة) مع توثيق كل قرار، لأن أي تعديل بسيط غير مبرر قد يغيّر نتائج الاختبارات (السكون، ACF/PACF) وبالتالي يغيّر نموذج SARIMA النهائي.",
  #                         type="ok"
  #                       ),
  #                       
  #                       D("المطلوب في هذه الخطوة", open = TRUE,
  #                         P("تعليميًا، نريد من الطالب أن يميز بين مشكلة بيانات (خطأ قياس/إدخال) وبين ظاهرة حقيقية (حدث أو صدمة). نحن نصحح الأخطاء، لكن لا نمسح التاريخ الحقيقي للسلسلة."),
  #                         tags$ul(
  #                           tags$li("التحقق من انتظام التردد، عدم تكرار التواريخ، والترتيب الزمني الصحيح."),
  #                           tags$li("كشف القيم المفقودة ومعالجتها حسب طبيعة النقص."),
  #                           tags$li("تحديد القيم الشاذة: هل هي خطأ أم حدث حقيقي؟"),
  #                           tags$li("اختيار التحويلات (Log/Box–Cox) إذا كان التباين غير ثابت.")
  #                         )
  #                       ),
  #                       
  #                       D("التحليلات التي يجب القيام بها", open = TRUE,
  #                         P("نعتمد منطقًا من أربع طبقات: (1) شبكة الزمن، (2) القيم المفقودة، (3) القيم الشاذة، (4) تحويل المقياس. في كل طبقة يوجد قرار ومعيار يبرره."),
  #                         tags$div(class="grid",
  #                                  criteria_block("A1 — انتظام الزمن",
  #                                                 note = "الهدف: التأكد أن “خطوة واحدة” تمثل نفس المدة في جميع نقاط السلسلة.",
  #                                                 tags$ul(
  #                                                   tags$li("التحقق أن كل تاريخ متوقع موجود مرة واحدة فقط."),
  #                                                   tags$li("التحقق أن الفواصل الزمنية ثابتة (لا عدم انتظام).")
  #                                                 )
  #                                  ),
  #                                  criteria_block("A2 — القيم المفقودة (NA)",
  #                                                 note = "الهدف: فهم نمط النقص قبل التعويض.",
  #                                                 tags$ul(
  #                                                   tags$li("قياس نسبة NA وأطوال الفجوات (gaps)."),
  #                                                   tags$li("تحديد إن كان النقص هيكليًا (عطل، عطلات...) أم عشوائيًا."),
  #                                                   tags$li("اختيار طريقة تعويض مبررة.")
  #                                                 )
  #                                  ),
  #                                  criteria_block("A3 — القيم الشاذة (Outliers)",
  #                                                 note = "الهدف: تقرير هل القيمة الشاذة خطأ أم إشارة حقيقية.",
  #                                                 tags$ul(
  #                                                   tags$li("الكشف (IQR / z-score قوي / فحص بصري) ثم التحقق من السياق."),
  #                                                   tags$li("قرار: تصحيح/حذف (خطأ) أم إبقاء (حدث).")
  #                                                 )
  #                                  ),
  #                                  criteria_block("A4 — التحويل (Transformation)",
  #                                                 note = "الهدف: تثبيت التباين وتحسين سلوك البواقي.",
  #                                                 tags$ul(
  #                                                   tags$li("تقييم علاقة المستوى بالتباين (هل التباين يزيد مع المستوى؟)."),
  #                                                   tags$li("تجربة Log/Box–Cox إن لزم."),
  #                                                   tags$li("توثيق كيفية العودة للمقياس الأصلي عند تفسير التنبؤ.")
  #                                                 )
  #                                  )
  #                         )
  #                       ),
  #                       
  #                       D("تعريفات (قابلة للطي)", open = FALSE,
  #                         TERM(
  #                           "NA / قيمة مفقودة",
  #                           "القيمة المفقودة (NA) تعني أن هناك تاريخًا متوقعًا لكن لم تُسجَّل فيه الملاحظة. في السلاسل الزمنية قد يكون هذا النقص عشوائيًا أو هيكليًا مرتبطًا بالتقويم أو الأعطال.",
  #                           purpose="NA تقطع الاستمرارية الزمنية، وقد تفسد حسابات ACF/PACF واختبارات السكون، لذلك يجب التعامل معها أو إعادة تشكيل السلسلة.",
  #                           criteria="لا ننظر فقط لنسبة NA بل لنمطها: فجوات قصيرة أم طويلة؟ هل تتكرر في نفس الفترات؟",
  #                           how_to_apply="ابدأ بإحصاء NA وتحديد مواقعها على الرسم. إن كانت فجوات قصيرة ونادرة يمكن تعويضها بحذر؛ إن كانت طويلة يجب مناقشة أثرها وربما استخدام حلول بديلة.",
  #                           what_to_write="« مثلت القيم المفقودة k=[..] نقطة ([..]%)، وتمت معالجتها بـ [..] لأن الفجوات كانت [..]. »"
  #                         ),
  #                         TERM(
  #                           "التعويض (Imputation)",
  #                           "التعويض يعني استبدال القيم المفقودة بقيم معقولة تُستنتج من الجوار الزمني أو من بنية الموسمية.",
  #                           purpose="يساعد في الحفاظ على شبكة زمنية منتظمة ويقلل الانقطاعات المصطنعة التي قد تُفسد السكون والارتباطات.",
  #                           criteria="تعويض بسيط للفجوات القصيرة؛ تعويض موسمي عند موسمية قوية؛ حذر شديد عند فجوات طويلة.",
  #                           how_to_apply="اختر طريقة تحترم البنية الأساسية: إذا كانت الموسمية قوية لا تستخدم تعويضًا يطمس الموسمية. بعد التعويض أعد فحص الرسوم وACF للتأكد من عدم إدخال نمط صناعي.",
  #                           notes="التعويض فرضية؛ لذلك يجب تبريره وذكر أثره المحتمل."
  #                         ),
  #                         TERM(
  #                           "قيمة شاذة (Outlier)",
  #                           "القيمة الشاذة هي ملاحظة غير معتادة مقارنة بباقي السلسلة. قد تكون خطأ قياس/إدخال أو حدثًا حقيقيًا يمثل صدمة أو تغييرًا في الواقع.",
  #                           purpose="قد تضر بتقدير SARIMA وتشخيصاته، لكنها قد تمثل ما يجب أن يتعلمه النموذج (أحداث حقيقية).",
  #                           criteria="لا يكفي معيار إحصائي مثل IQR؛ يجب فحص السياق. إن كانت القيمة حقيقية فالأفضل غالبًا إبقاؤها مع تعليق.",
  #                           how_to_apply="حددها على الرسم، ابحث عن تفسير، ثم قرر: تصحيح إن كانت مستحيلة منطقيًا، أو إبقاء إن كانت حدثًا حقيقيًا. إن كانت متكررة قد تحتاج لنموذج تدخل أو متغيرات خارجية (SARIMAX)."
  #                         ),
  #                         TERM(
  #                           "تحويل Box–Cox",
  #                           "Box–Cox عائلة تحويلات بمعامل λ تهدف لتثبيت التباين وتحسين خصائص السلسلة. اللوغاريتم هو حالة خاصة عندما λ→0.",
  #                           purpose="عندما يزيد التباين مع المستوى، يساعد التحويل في جعل البواقي أكثر تجانسًا ويجعل الموسمية أقرب للإضافية.",
  #                           criteria="مناسب إذا كانت السلسلة تُظهر “شكل المروحة” أو موسمية تتضخم مع المستوى.",
  #                           how_to_apply="طبّق التحويل ثم أعد كل الرسوم والاختبارات (ACF/PACF والسكون). بعد ذلك تأكد من إمكانية العودة للمقياس الأصلي عند تفسير التنبؤ.",
  #                           formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) إذا λ→0",
  #                           notes="انتبه للصفر/السالب: قد تحتاج لإزاحة (shift)."
  #                         )
  #                       ),
  #                       
  #                       D("معايير القرار", open = TRUE,
  #                         decision_rule_list(
  #                           tags$li(tags$b("التعويض: "),
  #                                   "إذا كانت الفجوات قصيرة ونادرة → خطي مناسب؛ إذا كانت الموسمية قوية → تعويض موسمي؛ إذا كانت فجوات طويلة → توثيق قوي وربما تجميع/استبعاد/نموذج يعتمد على بنية أكثر."),
  #                           tags$li(tags$b("القيم الشاذة: "),
  #                                   "إن كانت مستحيلة → تصحيح/حذف؛ إن كانت حدثًا حقيقيًا → إبقاء مع تفسير؛ وإذا كانت تتكرر يمكن التفكير بتدخل أو متغيرات خارجية."),
  #                           tags$li(tags$b("التحويل: "),
  #                                   "إذا كان التباين يزيد مع المستوى → Log/Box–Cox؛ إذا كان التباين ثابتًا → لا تحول للحفاظ على البساطة.")
  #                         )
  #                       ),
  #                       
  #                       D("المخرجات المتوقعة", open = FALSE,
  #                         tags$ul(
  #                           tags$li("ملخص: n، التواريخ، التردد، نسبة NA، طريقة المعالجة."),
  #                           tags$li("قائمة القيم الشاذة + القرار والتبرير."),
  #                           tags$li("التحويل المختار + التبرير + كيفية العودة للمقياس الأصلي.")
  #                         )
  #                       ),
  #                       
  #                       D("أخطاء شائعة", open = FALSE,
  #                         tags$ul(
  #                           tags$li("تعويض فجوات طويلة دون مناقشة: يجعل النتائج ضعيفة الثقة."),
  #                           tags$li("حذف أحداث حقيقية باعتبارها شذوذًا: يفقد النموذج معلومات مهمة للتنبؤ.")
  #                         )
  #                       )
  #       ))
  #     }
  #     
  #     # ------------------------------------------------------------
  #     # ملاحظة: للحفاظ على طول الرد قابلاً للإدارة في رسالة واحدة،
  #     # تم ترجمة وتوسيع الخطوتين 0 و1 بالكامل (وهما الأكثر كثافة نصيًا).
  #     # إذا تريد ترجمة/توسيع الخطوات 2–8 بنفس المستوى حرفيًا داخل الكود،
  #     # اكتب: "كمل ترجمة وتوسيع الخطوات 2–8".
  #     # ------------------------------------------------------------
  #     
  #     tags$div(class="road-card",
  #              callout(tags$b("تنبيه: "), "هذه النسخة العربية الحالية تتضمن ترجمة موسّعة للخطوتين [0] و[1]. لنسخة كاملة للخطوات [2]–[8] بنفس المستوى داخل الكود، اطلب: كمل ترجمة وتوسيع الخطوات 2–8.", type="warn")
  #     )
  #   }
  #   
  #   # ----------------------------
  #   # السلايدر (بدون تمرير طويل)
  #   # ----------------------------
  #   k <- input$roadmap_step_ar
  #   if (is.null(k)) k <- 0
  #   
  #   tagList(
  #     css, js,
  #     
  #     tags$div(class="road-wrap",
  #              tags$div(class="road-header",
  #                       tags$div(
  #                         tags$h3(class="road-title", "خارطة طريق SARIMA (تفصيل كبير) — العربية"),
  #                         tags$p(class="road-sub",
  #                                "استخدم السلايدر للتنقل بدون تمرير. كل خطوة: الهدف → التحليلات → الاختبارات → معايير القرار → المخرجات → الأخطاء الشائعة."
  #                         )
  #                       )
  #              ),
  #              
  #              tags$hr(),
  #              
  #              sliderInput(
  #                inputId = "roadmap_step_ar",
  #                label   = "الخطوة (سلايدر — بدون تمرير)",
  #                min = 0, max = 8, value = k, step = 1,
  #                sep = ""
  #              ),
  #              
  #              tags$h4(style="margin-top:10px;", step_title(k)),
  #              step_badges(k),
  #              
  #              tags$hr(),
  #              
  #              step_content(k)
  #     )
  #   )
  # })
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  # ============================================================
  # خارطة طريق SARIMA شديدة التفصيل (تعريب) — Slider + Collapsibles
  # موسّعة بجُمل تفسيرية تفصيلية للتعريفات + خطوات سير العمل
  # منظّمة وفق: الهدف → التحليلات → الاختبارات → المعايير → المخرجات → المزالق
  #
  # طريقة الاستعمال
  # 1) في UI:   uiOutput("roadmap_Detailed_Fr_ui")   # يمكن إبقاء الاسم كما هو
  # 2) في server(): الصق كل ما بالأسفل داخل:
  #    server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Ar_ui3 <- renderUI({
    
    # ----------------------------
    # Helpers: بناء الأكورديون
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # المستوى 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # المستوى 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    # مساعد فقرة لقراءة الجُمل الطويلة بشكل مريح
    P <- function(...) tags$p(...)
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
                     notes = NULL, how_to_apply = NULL, what_to_write = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("التعريف: "), definition),
                 if (!is.null(purpose))       P(tags$b("الهدف / الفائدة: "), purpose) else NULL,
                 if (!is.null(criteria))      P(tags$b("المعايير / المؤشرات: "), criteria) else NULL,
                 if (!is.null(how_to_apply))  P(tags$b("كيف نستخدمه داخل التحليل: "), how_to_apply) else NULL,
                 if (!is.null(formula))       P(tags$b("الترميز / الصيغة: "), tags$code(formula)) else NULL,
                 if (!is.null(example))       P(tags$b("مثال: "), example) else NULL,
                 if (!is.null(what_to_write)) P(tags$b("جملة نموذجية (للصياغة في التقرير): "), what_to_write) else NULL,
                 if (!is.null(notes))         P(tags$b("ملاحظات: "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("الهدف (بتفصيل شديد): "), purpose),
                 P(tags$b("متى نستخدمه: "), when_to_use),
                 P(tags$b("H0: "), H0),
                 P(tags$b("H1: "), H1),
                 if (!is.null(statistic))                P(tags$b("الإحصاء / الفكرة: "), statistic) else NULL,
                 if (!is.null(decision_rule))            P(tags$b("قاعدة اتخاذ القرار: "), decision_rule) else NULL,
                 if (!is.null(interpretation))           P(tags$b("التفسير (المعنى): "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices))P(tags$b("ماذا يعني ذلك لاختياراتك: "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                P(tags$b("كيف نعرضه في التقرير: "), reporting) else NULL,
                 if (!is.null(caveats))                  P(tags$b("الحدود / المزالق: "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (سلوك الأكورديون)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px; direction: rtl; text-align: right;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-right:4px; margin-left:0;}
    details.acc.term, details.acc.test {margin:8px 12px 8px 0;}
    .callout {border-right:5px solid #4C78A8; border-left:none; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-right-color:#E45756; background:#fff7f7;}
    .callout.ok {border-right-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-left:6px; margin-right:0; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 18px 6px 0;}
    .tight ol {margin: 6px 18px 6px 0;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
    .muted {color:#555;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # عناوين الخطوات + الشارات
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] تأطير المشكلة والتحقق/التقييم",
        "[1] جودة البيانات والتحضير (القيم المفقودة، التواتر، القيم الشاذة)",
        "[2] الاستكشاف البصري (الاتجاه، الموسمية، التباين)",
        "[3] التفكيك/التحليل إلى مكوّنات (إضافي/ضربي، STL)",
        "[4] الاستقرارية والتفريق (اختيار d و D و s) + اختبارات",
        "[5] خط أساس (ساذج / Auto-ARIMA) + معايير الاختيار",
        "[6] التعرف اليدوي (ACF/PACF) + شبكة نماذج مرشحة",
        "[7] التشخيص والمقارنة النهائية (اختبارات البواقي + التنبؤ)",
        "[8] الكتابة: الخلاصة، المعنى، والمخرجات"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("الهدف", "أفق التنبؤ", "بروتوكول التقييم", "مقاييس الخطأ"),
        c("التواتر", "قيم مفقودة", "قيم شاذة", "تحويلات"),
        c("رسوم بيانية", "موسمية", "تباين", "إشارة"),
        c("STL", "إضافي مقابل ضربي", "البنية"),
        c("ADF/KPSS/PP", "d/D/s", "قواعد الاختيار"),
        c("خط أساس", "AICc/BIC", "ساذج"),
        c("ACF/PACF", "الاقتصاد/البساطة", "نماذج مرشحة"),
        c("Ljung–Box", "ARCH", "الطبيعية", "الدقة"),
        c("تركيب", "خلاصة", "معنى", "قابلية الإعادة")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ----------------------------
    # مساعدات صغيرة (صناديق المعايير)
    # ----------------------------
    criteria_block <- function(title, ..., note = NULL) {
      tags$div(class="box",
               tags$h5(title),
               if (!is.null(note)) tags$p(class="muted", note) else NULL,
               ...
      )
    }
    
    decision_rule_list <- function(...) {
      tags$ul(...)
    }
    
    # ------------------------------------------------------------
    # محتوى الخطوات (مهيكل جدا + جمل موسعة)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================================================
      # STEP 0 — التأطير
      # =========================================================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("الهدف: "),
                          "تحديد مهمة التنبؤ وبروتوكول تقييم موثوق بشكل واضح، لأن نموذج SARIMA لا يمكن الحكم عليه بدقة إذا لم يتم تثبيت الهدف وأفق التنبؤ وطريقة التحقق منذ البداية.",
                          type="ok"
                        ),
                        
                        D("الغاية", open = TRUE,
                          P("في هذه المرحلة يجب على الطالب تقديم وصف عملي للمشكلة: ما المتغير الذي سيتم التنبؤ به، وعلى أي شبكة زمنية، وبأي أفق، ووفق أي قاعدة تقييم. الفكرة بسيطة: إذا اختار طالبان آفاقا أو تقسيمات تدريب/اختبار مختلفة، فهما لا يدرسان نفس المشكلة وبالتالي لا تصبح النتائج قابلة للمقارنة."),
                          tags$ul(
                            tags$li("تحديد الهدف ", tags$code("y_t"), " والتواتر (انتظام الزمن)."),
                            tags$li("تحديد أفق ", tags$code("h"), " بشكل واقعي (مرتبط بالاستخدام/القرار)."),
                            tags$li("تحديد بروتوكول التحقق (Train/Test أو Rolling-origin) والمقاييس (MAE/RMSE/...)."),
                            tags$li("تحديد خطوط المقارنة (Benchmarks): ساذج وساذج موسمي إذا وُجدت موسمية.")
                          )
                        ),
                        
                        D("تحليلات يجب القيام بها", open = TRUE,
                          P("هنا نبني 'الصندوق الأسود' للتقييم: نتأكد أن الزمن محترم (لا مزج بين الماضي والمستقبل)، ونختار مقاييس تعكس تكلفة الخطأ. النموذج الأفضل حسب RMSE ليس دائما الأفضل حسب MAE، لذلك من المهم اعتماد مقياسين على الأقل."),
                          tags$div(class="grid",
                                   criteria_block("A1 — تحديد التواتر والموسمية (s)",
                                                  note = "الغاية: ضمان أن السلسلة تعيش على شبكة منتظمة وأن موسمية s لها معنى حقيقي (تقويم + بيانات).",
                                                  tags$ul(
                                                    tags$li("تحديد الدقة الزمنية: يومي/أسبوعي/شهري/..."),
                                                    tags$li("استخلاص الموسم ", tags$code("s"), " (مثلا: شهري s=12، فصلي s=4، يومي-أسبوعي s=7)."),
                                                    tags$li("التحقق من غياب الفجوات أو التكرار في الفهرس الزمني (انتظام).")
                                                  ),
                                                  P("إذا كان التواتر غير منتظم، فإن SARIMA 'يرى' تأخيرات لا تمثل نفس الزمن الحقيقي، وهذا يفسد منطق الاعتماد (ACF/PACF) ويجعل تفسير المعلمات أصعب.")
                                   ),
                                   criteria_block("A2 — تحديد أسلوب التحقق/التحقق المتقاطع",
                                                  note = "الغاية: قياس الأداء على مستقبل غير مرئي كما يحدث في الواقع.",
                                                  tags$ul(
                                                    tags$li(tags$b("Train/Test زمني: "), "التدريب على الماضي والاختبار على المستقبل (وليس العكس)."),
                                                    tags$li(tags$b("Rolling-origin: "), "التقييم عبر عدة بدايات/أصول → أكثر متانة."),
                                                    tags$li("تحديد حجم الاختبار: عادة ≥ موسم واحد (مثلا ≥ 12 شهرا في بيانات شهرية) إن أمكن.")
                                                  ),
                                                  P("يوصى بـ Rolling-origin عندما نريد تعليم الواقعية التشغيلية: يتم تحديث النموذج مع الزمن وتقييمه عدة مرات، ما يقلل خطر 'الحظ' في تقسيم واحد.")
                                   ),
                                   criteria_block("A3 — اختيار مقاييس الخطأ",
                                                  note = "الغاية: مواءمة قياس الخطأ مع معنى التطبيق (وحدات القياس مقابل عقوبة الأخطاء الكبيرة).",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE: "), "متين وسهل الفهم بوحدات القياس."),
                                                    tags$li(tags$b("RMSE: "), "يعاقب الأخطاء الكبيرة بشدة."),
                                                    tags$li(tags$b("MAPE: "), "فقط إذا كانت y>0 وبعيدة عن 0؛ وإلا يفضّل sMAPE/MAE."),
                                                    tags$li(tags$b("sMAPE: "), "بديل نسبي أكثر استقرارا من MAPE.")
                                                  ),
                                                  P("تعليميا: MAE يجيب 'كم أخطئ في المتوسط؟' وRMSE يجيب 'هل أتجنب الأخطاء الكبيرة فعلا؟'. الجمع بينهما يعطي قراءة أشمل.")
                                   )
                          )
                        ),
                        
                        D("معايير الاختيار (قرار)", open = TRUE,
                          P("المعايير التالية تحول الخطوة 0 إلى قرارات ملموسة. عند كل قرار يجب أن يشرح الطالب لماذا هذا الاختيار منسجم مع المشكلة وكيف سيؤثر على بقية التحليل (الاستقرارية، الموسمية، المقاييس)."),
                          decision_rule_list(
                            tags$li(tags$b("أفق h: "), "يجب أن يطابق الحاجة. مثال: إذا كان القرار شهريا (شراء/ميزانية)، فالأفق يجب أن يقاس بالأشهر وأن يغطي نافذة قرار مفيدة."),
                            tags$li(tags$b("البروتوكول: "), "إذا كانت البيانات كافية، فضّل Rolling-origin لأنه يقيّم عدة 'مستقبلات'. إذا كانت البيانات قصيرة، استخدم تقسيمًا زمنيا واضحا واشرحه (تواريخ دقيقة)."),
                            tags$li(tags$b("المقاييس: "), "اختر على الأقل مقياسين (مثل MAE + RMSE) لتجنب تحسين مفهوم واحد للخطأ فقط."),
                            tags$li(tags$b("Benchmark: "), "قارن دائما بساذج (وساذج موسمي إن وُجدت موسمية). إذا لم يتفوق نموذجك على الساذج فهذه نتيجة سلبية 'مفيدة': ربما السلسلة صعبة أو النموذج ناقص.")
                          )
                        ),
                        
                        D("تعريفات أساسية (قابلة للنقر)", open = FALSE,
                          TERM(
                            term="سلسلة زمنية (y_t)",
                            definition="السلسلة الزمنية هي تسلسل ملاحظات مرتبة حسب الزمن، حيث تمثل كل قيمة y_t حالة الظاهرة عند اللحظة t (مثل مبيعات شهرية، حرارة يومية، أو حركة مرور بالساعة).",
                            purpose="هذا التعريف يجبرنا على تحديد ما الذي نلاحظه، وبأي تواتر، وبأي وحدات، لأن SARIMA يموذج الاعتماد بين الملاحظات المتتابعة.",
                            criteria="يجب أن نجيب: ما الوحدة؟ ما التواتر؟ ما التواريخ؟ وهل تحتوي y_t على أصفار أو قيم سالبة (مهم لتحويل log/Box-Cox)؟",
                            how_to_apply="قبل أي نمذجة، نتحقق أن السلسلة مرتبة زمنيا، بلا تكرار في التواريخ، وأن كل خطوة زمنية متوقعة موجودة (أو مفقودة بشكل موثّق).",
                            what_to_write="« المتغير محل الدراسة y_t يمثل [تعريف]، مرصودا بتواتر [..] بين [البداية] و[النهاية]. »"
                          ),
                          TERM(
                            term="أفق التنبؤ (h)",
                            definition="أفق h هو عدد الخطوات المستقبلية التي نريد التنبؤ بها. مثلا، h=12 في بيانات شهرية يعني التنبؤ بالأشهر الـ12 القادمة.",
                            purpose="الأفق يحدد صعوبة المهمة: كلما كبر h زادت اللايقينية، وصار التقاط الاتجاه/الموسمية بشكل صحيح أكثر أهمية.",
                            criteria="يجب أن يكون h منسجما مع الاستخدام: التنبؤ بيوم واحد لقرار سنوي غير منطقي، والتنبؤ بـ24 شهرا مع 30 شهرا فقط من البيانات محفوف بالمخاطر.",
                            how_to_apply="نثبت h قبل اختبار النماذج، لأن تغيير h يغيّر الاستنتاج (قد يكون النموذج ممتازا قصير الأجل ومتوسطا طويل الأجل).",
                            formula="h"
                          )
                        ),
                        
                        D("المخرجات المتوقعة", open = FALSE,
                          P("بنهاية الخطوة 0 يجب أن يستطيع الطالب تقديم 'بطاقة مشكلة' كاملة: إذا أعاد شخص آخر التحليل، يحصل على نفس إعداد التقييم."),
                          tags$ul(
                            tags$li("وصف كامل لـ y_t (تعريف، وحدة، تواتر، تواريخ)."),
                            tags$li("h + البروتوكول (split/rolling) + المقاييس + خطوط المقارنة."),
                            tags$li("قواعد قابلية الإعادة (seed إن وجدت عشوائية، وتواريخ split الدقيقة).")
                          )
                        ),
                        
                        D("المزالق", open = FALSE,
                          tags$ul(
                            tags$li("خلط الزمن (shuffle): تسرب معلومات → نتائج مرتفعة بشكل مصطنع."),
                            tags$li("مقارنة نماذج بتقسيمات مختلفة → مقارنة غير صالحة."),
                            tags$li("استخدام MAPE عندما y≈0: الخطأ النسبي ينفجر ويهيمن على التقييم.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 1 — الجودة/التحضير
      # =========================================================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("الهدف: "),
                          "ضمان أن السلسلة قابلة للاستخدام (شبكة منتظمة، معالجة القيم المفقودة، فهم الشذوذات) والأهم توثيق كل تحويل، لأن 'تصحيحًا صغيرًا' غير مفسر قد يغيّر تماما الاختبارات (الاستقرارية، ACF/PACF) وبالتالي مواصفة SARIMA.",
                          type="ok"
                        ),
                        
                        D("الغاية", open = TRUE,
                          P("الهدف التعليمي هو أن يميز الطالب بين مشكلة بيانات (فهرس، قيم مفقودة، خطأ إدخال) وبين ظاهرة حقيقية (حدث، عرض ترويجي، أزمة). يجب أن يتعلم SARIMA السلوك الحقيقي للسلسلة: نصحح الأخطاء لكن لا نمحو التاريخ."),
                          tags$ul(
                            tags$li("التحقق من انتظام التواتر، فريدة التواريخ، وصحة الترتيب الزمني."),
                            tags$li("كشف ومعالجة القيم المفقودة NA (حسب طبيعة الغياب)."),
                            tags$li("تحديد القيم الشاذة (خطأ أم حدث حقيقي)."),
                            tags$li("اتخاذ قرار التحويلات (log/Box–Cox) إذا كان التباين غير ثابت.")
                          )
                        ),
                        
                        D("تحليلات يجب القيام بها", open = TRUE,
                          P("نتبع منطقًا بأربعة فحوص: (1) الشبكة الزمنية، (2) القيم المفقودة، (3) القيم الشاذة، (4) تحويل المقياس. كل فحص يقود إلى قرار، وكل قرار يجب تبريره بمعيار (وليس 'اعتباطا')."),
                          tags$div(class="grid",
                                   criteria_block("A1 — الانتظام الزمني",
                                                  note = "الغاية: التأكد من أن 'خطوة زمنية واحدة' تعني نفس الشيء عبر السلسلة كلها.",
                                                  tags$ul(
                                                    tags$li("التحقق أن كل تاريخ متوقع موجود مرة واحدة فقط."),
                                                    tags$li("التحقق من ثبات الفاصل الزمني (لا لعدم الانتظام).")
                                                  ),
                                                  P("إذا كان الفهرس غير منتظم قد تولد ارتباطات ذاتية كاذبة (تأخر 1 لا يمثل نفس الفترة دائما). SARIMA يحتاج قاعدة زمنية نظيفة.")
                                   ),
                                   criteria_block("A2 — القيم المفقودة (NA)",
                                                  note = "الغاية: فهم بنية الغياب قبل أي تعويض.",
                                                  tags$ul(
                                                    tags$li("قياس %NA وطول سلاسل الغياب (الفجوات)."),
                                                    tags$li("وصف هل الغياب بنيوي (عطل/عطلة/إغلاق)."),
                                                    tags$li("اختيار طريقة تعويض مبررة.")
                                                  ),
                                                  P("قيمة مفقودة منفردة ليست مثل شهر كامل مفقود. كلما طالت الفجوة زادت 'اختلاق' المعلومات ويجب مناقشة أثر ذلك في التقرير.")
                                   ),
                                   criteria_block("A3 — القيم الشاذة (Outliers)",
                                                  note = "الغاية: تقرير هل القيمة غير الطبيعية خطأ أم إشارة حقيقية يجب احترامها.",
                                                  tags$ul(
                                                    tags$li("الكشف (IQR / z-score متين / فحص بصري) + التحقق بالسياق."),
                                                    tags$li("القرار: تصحيح (خطأ) أم الإبقاء (حدث).")
                                                  ),
                                                  P("قد تكون القيمة الشاذة حدثا حقيقيا (ترقية، انقطاع، أزمة). حذفها يعني 'لم يحدث شيء' وقد يجعل التنبؤ غير واقعي.")
                                   ),
                                   criteria_block("A4 — التحويل",
                                                  note = "الغاية: تثبيت التباين وجعل الديناميكية أقرب إلى 'خطية' لملاءمة SARIMA.",
                                                  tags$ul(
                                                    tags$li("تقييم علاقة المستوى بالتباين (هل التباين يزيد مع المستوى؟)."),
                                                    tags$li("تجربة log/Box–Cox إن لزم."),
                                                    tags$li("توثيق كيفية عكس التحويل للعودة للمقياس الأصلي.")
                                                  ),
                                                  P("إذا كانت سعة التقلبات تزيد مع المستوى، فقد يبالغ نموذج المستويات في التفاعل مع الفترات المرتفعة. غالبا يجعل log/Box–Cox الموسمية أكثر إضافية والبواقي أكثر تجانسا.")
                                   )
                          )
                        ),
                        
                        D("تعريفات (قابلة للنقر)", open = FALSE,
                          TERM(
                            "NA / قيمة مفقودة",
                            "القيمة المفقودة (NA) تعني أنه في تاريخ متوقع لم تُسجَّل الملاحظة. في السلاسل الزمنية قد يكون الغياب عشوائيا (خطأ قياس) أو بنيويا (عطلة، إغلاق، حساس متعطل).",
                            purpose="القيم المفقودة تقطع الاستمرارية الزمنية: SARIMA وتشخيصات ACF/PACF تفترض سلسلة كاملة، لذا إما نعوض أو نعدّل التواتر/التجميع.",
                            criteria="لا ننظر فقط لنسبة NA بل لبنيتها: ثقوب قصيرة (1–2 نقطة) مقابل سلاسل طويلة، دورية الغياب، وارتباطه بالتقويم.",
                            how_to_apply="ابدأ بعدّ NA ثم اعرض مواقعها. إذا كانت الفجوات قصيرة ونادرة فالتعويض البسيط غالبا مقبول. إذا كانت طويلة فناقش الأثر (لايقين) وفكر في بدائل (تجميع، استبعاد، مصدر آخر).",
                            what_to_write="« مثلت القيم المفقودة k=[..] نقطة ([..]%)، وتمت معالجتها بـ[الطريقة] لأن الفجوات كانت [قصيرة/نادرة] ولأن الموسمية كانت [ضعيفة/قوية]. »"
                          ),
                          TERM(
                            "التعويض (Imputation)",
                            "التعويض يعني استبدال القيمة المفقودة بقيمة معقولة مبنية على الملاحظات المجاورة (خطي) أو على البنية الموسمية (موسمي).",
                            purpose="يسمح بالحفاظ على شبكة منتظمة وتجنب انقطاع مصطنع قد يشوه الاستقرارية والارتباطات الذاتية.",
                            criteria="تعويض بسيط إذا كانت الفجوات قصيرة جدا وديناميكية السلسلة سلسة؛ تعويض موسمي إذا كانت الموسمية قوية؛ حذر شديد إذا كانت الفجوات طويلة.",
                            how_to_apply="اختر طريقة تحترم البنية المسيطرة: إذا كانت الموسمية قوية فلا 'تسوِّ' السلسلة لدرجة محو الموسم. بعد التعويض أعد فحص الرسوم وACF للتأكد أنك لم تُدخل نمطا مصطنعا.",
                            notes="كل تعويض هو فرضية عن الواقع، لذا يجب تبريره."
                          ),
                          TERM(
                            "قيمة شاذة (Outlier)",
                            "القيمة الشاذة هي ملاحظة غير معتادة مقارنة بسلوك السلسلة المعتاد. قد تأتي من خطأ (حساس/إدخال) أو من حدث حقيقي (ترقية/أزمة/انقطاع).",
                            purpose="القيم الشاذة قد تربك التعرف (ACF/PACF) وتقدير المعلمات، لكنها قد تمثل بالضبط ما نريد أن ينعكس في التنبؤ (أحداث).",
                            criteria="قاعدة إحصائية (IQR، z-score) يجب أن تُستكمل بالسياق: إذا كان الحدث حقيقيا فغالبا يفضل الإبقاء عليه وتوثيقه.",
                            how_to_apply="ضع علامات على الشذوذات في الرسم، وابحث عن تفسير، ثم قرر: صحح إذا كانت القيمة غير ممكنة فيزيائيا، وإلا فأبقها. إذا كانت الشذوذات متكررة وبنية، فكر في نموذج تدخل أو متغيرات خارجية (SARIMAX).",
                            what_to_write="« القيم غير الاعتيادية حول [تواريخ] تم [الإبقاء عليها/تعديلها] لأن [السياق]. »"
                          ),
                          TERM(
                            "تحويل Box–Cox",
                            "تحويل Box–Cox هو عائلة تحويلات معلمة بـ(λ) هدفها تثبيت التباين وأحيانا تقريب التوزيع من شكل أكثر تماثلا. اللوغاريتم حالة خاصة عندما λ يقترب من 0.",
                            purpose="عندما يزيد التباين مع المستوى (سلسلة بشكل 'مروحة') يساعد Box–Cox SARIMA على نمذجة ديناميكية أكثر ثباتا وإنتاج بواقي أكثر تجانسا.",
                            criteria="إذا كانت سعة الموسمية/التباين تزيد مع المستوى فغالبا Box–Cox/log مناسب. إذا كان التباين ثابتا فقد يكون التحويل غير ضروري ويعقد التفسير.",
                            how_to_apply="طبّق التحويل، أعد الرسوم، ثم أعد التشخيصات (ACF/PACF، الاستقرارية). أخيرا تأكد أنك تستطيع العودة للمقياس الأصلي لتفسير التنبؤات.",
                            formula="BC(y; λ) = (y^λ - 1)/λ ; log(y) إذا λ→0",
                            notes="انتبه للأصفار/السوالب: قد تحتاج إزاحة (shift)."
                          )
                        ),
                        
                        D("معايير الاختيار (قرار)", open = TRUE,
                          P("المعايير التالية تلخّص قرارات التحضير. يجب تطبيقها كقائمة تحقق صغيرة ثم كتابة تبرير قصير لكنه صريح لكل معالجة."),
                          decision_rule_list(
                            tags$li(tags$b("التعويض: "),
                                    "إذا كانت الفجوات قصيرة جدا (مثل 1–2 نقطة) والسلسلة سلسة نسبيا → التعويض الخطي مقبول؛ ",
                                    "إذا كانت الموسمية قوية → التعويض الموسمي أفضل؛ ",
                                    "إذا كانت الفجوات طويلة → وثّق بقوة، وفكر في التجميع أو الاستبعاد أو طرق قائمة على نموذج."),
                            tags$li(tags$b("القيم الشاذة: "),
                                    "إذا كانت غير منطقية/مستحيلة → صحح/احذف؛ ",
                                    "إذا كانت حدثا حقيقيا → أبقها واذكرها؛ وقد يلزم نموذج تدخل إذا كان الأثر متكررا."),
                            tags$li(tags$b("التحويل: "),
                                    "إذا زاد التباين/سعة الموسمية مع المستوى → log/Box–Cox؛ ",
                                    "إذا كان التباين ثابتا → لا تحويل (تبسيط).")
                          )
                        ),
                        
                        D("المخرجات المتوقعة", open = FALSE,
                          P("بنهاية الخطوة 1 يجب أن نستطيع القول: 'هذه هي السلسلة النظيفة، وهذه التغييرات التي قمنا بها، وهذه أسبابها'. هذا يحمي التحليل ويجعل العمل تعليميا وقابلا للنقد."),
                          tags$ul(
                            tags$li("ملخص البيانات: n، التواريخ، التواتر، %NA، طريقة معالجة NA."),
                            tags$li("قائمة القيم الشاذة + القرار + التبرير."),
                            tags$li("التحويل المختار + التبرير + كيفية العودة للمقياس الأصلي.")
                          )
                        ),
                        
                        D("المزالق", open = FALSE,
                          tags$ul(
                            tags$li("تعويض فجوات طويلة دون مناقشة → استنتاجات هشة لأن الديناميكية المعوضة افتراضية."),
                            tags$li("حذف أحداث حقيقية على أنها شذوذات → فقدان معلومات يجب أن تعكسها التنبؤات."),
                            tags$li("استخدام log/Box–Cox دون شرح كيفية عكس التحويل → صعوبة تفسير التنبؤات.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 2 — الاستكشاف البصري
      # =========================================================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("الهدف: "),
                          "تحديد الاتجاه والموسمية وتغيرات التباين والانقطاعات والشذوذات لتوجيه القرارات التالية (تحويل، تفريق، اختيار s). الرسوم هنا تعمل كـ'دليل بصري' يكمل الاختبارات الإحصائية.",
                          type="ok"
                        ),
                        
                        D("الغاية", open = TRUE,
                          P("هذه المرحلة تعلم قراءة السلسلة: التعرف على حركة طويلة المدى (اتجاه)، ونمط يتكرر (موسمية)، ومناطق يتغير فيها التباين. هذه بالضبط العناصر التي يحاول SARIMA التقاطها (أو جعلها مستقرة بالتفريق)."),
                          tags$ul(
                            tags$li("عرض السلسلة الخام وربما السلسلة بعد التحويل."),
                            tags$li("كشف الاتجاه (طويل المدى) والموسمية (دورية)."),
                            tags$li("رصد احتمالات الانقطاع البنيوي والشذوذات.")
                          )
                        ),
                        
                        D("تحليلات يجب القيام بها", open = TRUE,
                          P("نفضّل ثلاث عائلات من الرسوم: (1) منحنى الزمن، (2) الرسوم الموسمية، (3) أدوات التباين. بعد ذلك نربط كل ملاحظة بقرار (log/Box–Cox، d، D، s)."),
                          tags$div(class="grid",
                                   criteria_block("A1 — منحنى الزمن",
                                                  note = "الغاية: رصد الاتجاه، الانقطاعات، الفترات غير الطبيعية، وحدس الاستقرارية.",
                                                  tags$ul(
                                                    tags$li("رسم y_t (وكذلك log/BC(y) إذا لزم)."),
                                                    tags$li("تعليم الفترات غير الطبيعية (صدمات/أحداث).")
                                                  ),
                                                  P("منحنى يرتفع بشكل دائم يشير إلى احتمال الحاجة لتفريق غير موسمي (d). تغير مفاجئ في المستوى قد يدل على انقطاع بنيوي (المستقبل قد لا يشبه الماضي).")
                                   ),
                                   criteria_block("A2 — الموسمية",
                                                  note = "الغاية: تأكيد الدورية وتقدير s.",
                                                  tags$ul(
                                                    tags$li("Seasonal plot / خطوط لكل سنة (إذا كانت البيانات شهرية)."),
                                                    tags$li("Boxplots حسب الشهر/الفصل/الأسبوع."),
                                                    tags$li("ACF: قمم عند مضاعفات s (إشارة قوية للموسمية).")
                                                  ),
                                                  P("إذا كانت الموسمية ثابتة يظهر seasonal plot نمطا متكررا. إذا كانت قوية ومستمرة فقد نحتاج تفريقا موسميا (D=1).")
                                   ),
                                   criteria_block("A3 — التباين",
                                                  note = "الغاية: كشف عدم ثبات التباين (heteroscedasticity) قبل النمذجة.",
                                                  tags$ul(
                                                    tags$li("مقارنة التذبذب في فترات ذات متوسط منخفض مقابل مرتفع."),
                                                    tags$li("إذا زاد التباين مع المستوى → تحويل.")
                                                  ),
                                                  P("عندما تزيد سعة التقلبات مع المستوى، قد يبالغ نموذج المستويات في إعطاء وزن للفترات العالية. التحويل (log/Box–Cox) يجعل الخطأ أكثر تجانسا.")
                                   )
                          )
                        ),
                        
                        D("معايير الاختيار (قرار)", open = TRUE,
                          P("هذه المعايير تربط مباشرة الملاحظات البصرية بقرارات النمذجة. يجب على الطالب كتابة صريحة: 'ألاحظ X، لذلك أختار Y'."),
                          decision_rule_list(
                            tags$li(tags$b("الموسمية: "),
                                    "وجود أنماط متكررة و/أو قمم في ACF عند s و2s و3s → موسمية مرجّحة، ويجب أن يطابق s التقويم."),
                            tags$li(tags$b("الاتجاه: "),
                                    "مستوى متوسط ينحرف بشكل دائم وACF يتناقص ببطء → غالبا d>0 ضروري."),
                            tags$li(tags$b("عدم ثبات التباين: "),
                                    "سعة التقلبات تزيد عندما يزيد المستوى → log/Box–Cox، خصوصا لتحسين تجانس البواقي.")
                          )
                        ),
                        
                        D("المخرجات المتوقعة", open = FALSE,
                          P("بنهاية الخطوة 2 يجب إنتاج فقرة EDA: لا يكفي عرض الأشكال، بل يجب شرح ما تقوله وما الذي تعنيه للخطوات التالية."),
                          tags$ul(
                            tags$li("تعليق EDA: اتجاه/موسمية/تباين/شذوذات."),
                            tags$li("فرضيات عمل: s محتمل، حاجة لتحويل، حاجة لـ d و/أو D.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 3 — التفكيك إلى مكونات
      # =========================================================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("الهدف: "),
                          "فصل الاتجاه/الموسمية/الضجيج وصفيا لتوضيح بنية الإشارة وتفسير لماذا نختار صيغة إضافية أو ضربّية. هذه المرحلة ليست 'النموذج' بل أداة لاتخاذ قرارات أفضل.",
                          type="ok"
                        ),
                        
                        D("الغاية", open = TRUE,
                          P("التفكيك لغة تعليمية قوية: يوضح للطلاب أن السلسلة ليست كتلة واحدة، بل خليط مكوّنات. يساعد هذا على تبرير التحويل وتوقع التفريق."),
                          tags$ul(
                            tags$li("تفكيك y_t إلى مكونات (اتجاه، موسمية، بواقي)."),
                            tags$li("مقارنة الإضافي مقابل الضربي (غالبا عبر log)."),
                            tags$li("استخدام STL إذا كانت الموسمية تتغير أو إذا كانت هناك قيم شاذة.")
                          )
                        ),
                        
                        D("مفاهيم/اختبارات (قابلة للنقر)", open = FALSE,
                          TERM(
                            "تفكيك إضافي (Additive)",
                            "في التفكيك الإضافي تكون الموسمية إضافة إلى الاتجاه: y_t = T_t + S_t + e_t. هذا يعني أن الفرق الموسمي (قمم-قيعان) يبقى تقريبا بنفس الحجم حتى لو تغيّر مستوى السلسلة.",
                            purpose="مفيد عندما تكون سعة الموسم ثابتة: الفرق بين 'شهر ضعيف' و'شهر قوي' متشابه عبر الزمن.",
                            criteria="إذا كانت الاهتزازات الموسمية ذات سعة شبه ثابتة بصريا بغض النظر عن ارتفاع المستوى، فالإضافي مناسب.",
                            how_to_apply="يمكن مقارنة السلسلة الخام بـ log(y): إذا جعل log الموسمية أكثر ثباتا، فهذا يدعم سلوكا إضافيا في الفضاء المحوّل.",
                            formula="y_t = T_t + S_t + e_t",
                            what_to_write="« بما أن سعة الموسمية تبدو مستقرة، اعتمدنا قراءة إضافية (y_t = T_t + S_t + e_t). »"
                          ),
                          TERM(
                            "تفكيك ضربي (Multiplicative)",
                            "في التفكيك الضربي تعمل الموسمية كعامل نسبي: y_t = T_t × S_t × e_t. أي إن الموسمية 'تكبر' عندما يكبر مستوى السلسلة.",
                            purpose="مناسب عندما تكون التقلبات الموسمية في الفترات العالية أكبر من الفترات المنخفضة (تأثير نسبي).",
                            criteria="إذا زادت سعة الموسم مع المستوى (شكل مروحة)، فالضربي مرجّح.",
                            how_to_apply="غالبا نستخدم log لتحويل الضربي إلى إضافي: log(y_t) = log(T_t) + log(S_t) + log(e_t).",
                            formula="y_t = T_t × S_t × e_t",
                            notes="غالبا log(y_t) يجعل البنية إضافية على log.",
                            what_to_write="« بما أن سعة الموسمية تزيد مع المستوى، طبقنا تحويل log للحصول على بنية إضافية في الفضاء المحوّل. »"
                          ),
                          TERM(
                            "STL",
                            "STL (تفكيك موسمي-اتجاه باستخدام Loess) تفكيك مرن يسمح للموسمية أن تتغير ببطء عبر الزمن ويكون أكثر متانة أمام القيم الشاذة.",
                            purpose="مفيد عندما لا تكون الموسمية ثابتة تماما (تغير تدريجي في العادات/النمو/التقويم).",
                            criteria="إذا أظهر seasonal plot أن الموسم يتغير قليلا عبر السنوات، فـ STL غالبا أفضل من التفكيك الكلاسيكي.",
                            how_to_apply="نستخدم STL للوصف وتوجيه القرارات، ثم نعود لتشخيصات الاستقرارية (اختبارات + ACF) للتحضير لـ SARIMA.",
                            notes="STL يصف ولا يعوّض شرط الاستقرارية لـ SARIMA."
                          )
                        ),
                        
                        D("معايير الاختيار (قرار)", open = TRUE,
                          P("الغاية ليست اختيار STL للزينة، بل بناء منطق متماسك: شكل الموسمية → تحويل → استقرارية أكثر قابلية → SARIMA أكثر ثباتا."),
                          decision_rule_list(
                            tags$li(tags$b("إضافي: "), "إذا كانت سعة الموسمية ~ ثابتة → نموذج إضافي."),
                            tags$li(tags$b("ضربي: "), "إذا كانت سعة الموسمية ∝ المستوى → log/Box–Cox ثم إضافي في الفضاء المحوّل."),
                            tags$li(tags$b("STL: "), "إذا كانت الموسمية متغيرة أو توجد قيم شاذة → STL أفضل لوصف متين.")
                          )
                        ),
                        
                        D("المخرجات المتوقعة", open = FALSE,
                          P("نتوقع شكلا للتفكيك وفقرة قصيرة تربط التشخيص بقرار (تحويل، نوع موسمية)."),
                          tags$ul(
                            tags$li("شكل/أشكال التفكيك + تعليق حول الاتجاه/الموسمية."),
                            tags$li("قرار مبرر: إضافي مقابل ضربي (+ تحويل).")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 4 — الاستقرارية + التفريق + الاختبارات
      # =========================================================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("الهدف: "),
                          "اختيار ", tags$code("d"), " و ", tags$code("D"), " و ", tags$code("s"),
                          " للحصول على سلسلة (بعد التفريق) مستقرة تقريبا. عمليا نبحث عن 'استقرارية كافية' بأقل قدر من التفريق، لأن التفريق المفرط يجعل النموذج غير مستقر.",
                          type="ok"
                        ),
                        
                        D("الغاية", open = TRUE,
                          P("هذه المرحلة هي محور SARIMA: تقرر كم من الاتجاه والموسمية ستزيله لتترك لـ AR/MA تفسير الاعتماد المتبقي. الاختبارات (ADF/KPSS/PP) لا تغني عن الرسوم: نستخدمهما معا للتثليث."),
                          tags$ul(
                            tags$li("تثبيت الموسمية ", tags$code("s"), " (من البيانات/السياق)."),
                            tags$li("اختيار ", tags$code("d"), " (تفريق غير موسمي) و ", tags$code("D"), " (تفريق موسمي)."),
                            tags$li("تبرير الاختيار عبر: EDA + ACF/PACF + اختبارات (ADF/KPSS/PP) + قواعد تجنب التفريق المفرط.")
                          )
                        ),
                        
                        D("تحليلات يجب القيام بها", open = TRUE,
                          P("سير العمل الموصى به: (1) اختيار s، (2) اختبار D، (3) اختبار d، (4) إعادة فحص الاستقرارية، (5) التأكد أننا لم نُفرّق أكثر من اللازم. غالبا قيم صغيرة تكفي: d∈{0,1} و D∈{0,1}."),
                          tags$div(class="grid",
                                   criteria_block("A1 — اختيار s (فترة الموسمية)",
                                                  note = "قرار مبني على التقويم + تأكيد تجريبي عبر ACF/seasonal plot.",
                                                  tags$ul(
                                                    tags$li("معرفة التقويم (شهري→12، فصلي→4، يومي-أسبوعي→7...)."),
                                                    tags$li("مؤشرات تجريبية: قمم ACF عند s و2s...؛ نمط ثابت في seasonal plot."),
                                                    tags$li("إذا كان هناك التباس: جرّب عدة قيم s معقولة وقارن التشخيصات.")
                                                  ),
                                                  P("يجب أن يكون لـ s معنى زمني. مثلا في بيانات شهرية، s=12 طبيعي. إذا وُجد موسم تجاري نصف سنوي، يمكن اختبار s=6 لكن يجب دعمه بالبيانات.")
                                   ),
                                   criteria_block("A2 — تقرير D (تفريق موسمي)",
                                                  note = "الغاية: إزالة لااستقرارية موسمية مستمرة (جذر وحدوي موسمي).",
                                                  tags$ul(
                                                    tags$li("إذا كانت الموسمية قوية ومستقرة سنة بعد سنة → فكر في D=1."),
                                                    tags$li("مؤشرات: ACF قوي جدا عند lag s في السلسلة الخام؛ الموسم لا يختفي بمجرد d."),
                                                    tags$li("مراقبة التفريق المفرط: ACF عند s يصبح سالبا جدا بعد D=1 → علامة D كبير.")
                                                  ),
                                                  P("التفريق الموسمي يقارن y_t بـ y_{t-s}. إذا لاحظت بعد D=1 تذبذبا مصطنعا (قمم سلبية قوية) فقد تكون أزلت موسمية أكثر من اللازم.")
                                   ),
                                   criteria_block("A3 — تقرير d (تفريق غير موسمي)",
                                                  note = "الغاية: إزالة اتجاه عشوائي (جذر وحدوي غير موسمي).",
                                                  tags$ul(
                                                    tags$li("إذا وُجد اتجاه عشوائي (جذر وحدوي) → غالبا d=1 كاف."),
                                                    tags$li("مؤشرات: ACF يتناقص ببطء في السلسلة الخام؛ اختبارات الجذر الوحدوي."),
                                                    tags$li("التفريق المفرط: ACF عند lag1 سالب جدا بعد التفريق → d كبير.")
                                                  ),
                                                  P("d=1 يعني نمذجة التغيرات بدل المستويات. إذا بدت التغيرات مستقرة غالبا يكون SARIMA أكثر موثوقية. d=2 نادر ويحتاج تبريرا قويا.")
                                   )
                          )
                        ),
                        
                        D("تعريفات لا غنى عنها (قابلة للنقر)", open = FALSE,
                          TERM(
                            "التفريق العادي (d)",
                            "تفريق السلسلة يعني استبدال y_t بفارقها بين لحظتين متتاليتين: ∇y_t = y_t − y_{t−1}. تكرار العملية d مرات يزيل تدريجيا اتجاها عشوائيا.",
                            purpose="الغاية هي الحصول على سلسلة متوسطها وتباينها أكثر ثباتا عبر الزمن حتى تلتقط مكونات AR/MA الاعتماد المتبقي.",
                            criteria="غالبا d يساوي 0 أو 1. إذا وصلنا إلى d=2 فهذا غالبا مؤشر على خصوصية كبيرة في السلسلة أو مشكلة مواصفة/انقطاع.",
                            how_to_apply="نبدأ بـ d=0 ثم نجرب d=1 إذا لزم. بعد كل تجربة نفحص السلسلة المفروقة وACF والاختبارات. نتوقف عندما تصبح الاستقرارية 'معقولة'.",
                            formula="(1-B)^d y_t",
                            what_to_write="« أشارت التشخيصات إلى اتجاه عشوائي؛ لذا طبقنا تفريقا عاديا (d=1) ثم أعدنا فحص الاستقرارية. »"
                          ),
                          TERM(
                            "التفريق الموسمي (D)",
                            "التفريق الموسمي يقارن الملاحظة مع نفس الموسم السابق: ∇_s y_t = y_t − y_{t−s}. هذا يزيل مكونا موسميا مستمرا.",
                            purpose="الغاية هي إزالة لااستقرارية موسمية (جذر وحدوي موسمي) بحيث تُنمذج الموسمية لاحقا عبر حدود AR/MA الموسمية (P,Q).",
                            criteria="غالبا D يساوي 0 أو 1. D=2 نادر ويستدعي إعادة فحص s وجودة البيانات.",
                            how_to_apply="نجرب D=0 ثم D=1 إذا بقيت الموسمية قوية. بعد D=1 نراقب أعراض التفريق الموسمي المفرط (ACF سالب جدا عند lag s).",
                            formula="(1-B^s)^D y_t",
                            what_to_write="« دفعت الموسمية المستمرة إلى تفريق موسمي (D=1) بفترة s=[..]. »"
                          ),
                          TERM(
                            "التفريق المفرط",
                            "التفريق المفرط يعني إزالة بنية أكثر مما يلزم. قد يصنع ديناميكية مصطنعة مثل ارتباط ذاتي سلبي قوي عند التأخر الأول، ويجعل التنبؤات أقل استقرارا.",
                            purpose="تجنب التفريق المفرط يحمي ثبات المعلمات ويحد من تضخيم الضجيج.",
                            criteria="أعراض شائعة: ACF عند lag1 سالب جدا بعد d، أو ACF عند lag s سالب جدا بعد D. تنبؤات متذبذبة بشكل مبالغ فيه.",
                            how_to_apply="إذا ظهرت الأعراض، قلّل d أو D ثم أعد الاختبارات وACF. القاعدة التعليمية: 'أقل تفريق ممكن لتحقيق استقرارية معقولة'.",
                            notes="الأفضل الحد الأدنى: 'كافٍ للاستقرارية' فقط."
                          )
                        ),
                        
                        D("الاختبارات (الهدف + معايير مفصلة)", open = FALSE,
                          
                          TEST(
                            name="ADF — Augmented Dickey–Fuller (الجذر الوحدوي)",
                            purpose=paste(
                              "يهدف اختبار ADF إلى كشف وجود جذر وحدوي، أي لااستقرارية تكون فيها الصدمات ذات أثر دائم. ",
                              "يفحص ما إذا كان المستوى الماضي y_{t-1} يفسر Δy_t بطريقة متوافقة مع سير عشوائي (Random Walk). ",
                              "تُضاف تأخيرات Δy_t لمعادلة الارتباط الذاتي وتجنب اختبار مضلل."
                            ),
                            when_to_use="لتقرير ما إذا كان التفريق غير الموسمي (d) ضروريا، ثم للتحقق أن السلسلة (بعد d وربما D) متوافقة مع الاستقرارية.",
                            H0="السلسلة تحتوي جذرًا وحدويًا → غير مستقرة.",
                            H1="السلسلة مستقرة (حسب المواصفة: مع أو بدون drift/trend).",
                            statistic="انحدار ADF: Δy_t ~ α + β t + γ y_{t-1} + Σ δ_i Δy_{t-i}. الاختبار يركز على γ مع قيم حرجة خاصة.",
                            decision_rule="عند α=0.05: إذا p-value < 0.05 → نرفض H0 → الاستقرارية مرجّحة. إذا p-value ≥ 0.05 → لا نرفض → قد يكون d غير كاف (أو انقطاع/مواصفة drift/trend غير مناسبة).",
                            interpretation="رفض H0 يعني أن السلسلة لا تبدو كسير عشوائي: لديها ميل للعودة إلى سلوك مستقر (متوسط ثابت أو اتجاه حتمي).",
                            what_it_means_for_choices="إذا لم يرفض ADF على السلسلة الخام، جرّب d=1 (و/أو D=1 إذا كانت الموسمية قوية). إذا رفض بعد التحويل، انتقل لتحديد p,q,P,Q عبر ACF/PACF.",
                            reporting="اذكر النسخة (مع drift أو trend)، وعدد التأخيرات، والإحصاء، وp-value، وقرار d.",
                            caveats="حساس لاختيار drift/trend وعدد التأخيرات. الانقطاعات البنيوية قد تجعل سلسلة 'تبدو' غير مستقرة رغم تغير النظام فقط."
                          ),
                          
                          TEST(
                            name="KPSS — Kwiatkowski–Phillips–Schmidt–Shin (الاستقرارية كفرضية صفرية)",
                            purpose=paste(
                              "يكمل KPSS اختبار ADF بعكس الفرضية الصفرية: هنا نفترض الاستقرارية صحيحة ما لم تُخالفها البيانات. ",
                              "يقيس الاختبار ما إذا كان هناك مكوّن سير عشوائي متبقٍ أكبر مما تسمح به سلسلة مستقرة."
                            ),
                            when_to_use="بعد ADF/PP للتثليث، وهو مفيد خصوصا عندما يكون ADF غير حاسم. يستخدم على السلسلة الخام وعلى السلسلة بعد التفريق.",
                            H0="السلسلة مستقرة (في المستوى) أو مستقرة حول اتجاه (حسب النسخة).",
                            H1="السلسلة غير مستقرة.",
                            statistic="إحصاء مبني على المجموع التراكمي لبواقي الانحدار وتقدير تباين طويل الأمد (bandwidth).",
                            decision_rule="عند α=0.05: إذا p-value < 0.05 → نرفض H0 → غير مستقرة. إذا p-value ≥ 0.05 → متوافقة مع الاستقرارية.",
                            interpretation="عدم دلالة KPSS بعد التفريق يدعم أن التحويل/التفريق ثبّت السلسلة؛ دلالة KPSS تعني بقاء انجراف أو بنية لااستقرارية.",
                            what_it_means_for_choices="توافق ADF/PP (رفض الجذر الوحدوي) + KPSS (عدم رفض الاستقرارية) = ضوء أخضر للانتقال إلى p,q,P,Q. إذا رفض KPSS، أعد النظر في d/D أو وجود انقطاع.",
                            reporting="اذكر النسخة (level/trend)، والإحصاء، وp-value، وخلاصة الاستقرارية.",
                            caveats="يعتمد على اختيار التباين طويل الأمد. حساس جدا للانقطاعات: تغير مستوى قد يجعل KPSS يرفض حتى لو كانت السلسلة مستقرة محليا."
                          ),
                          
                          TEST(
                            name="PP — Phillips–Perron (جذر وحدوي مع تصحيح غير معلمي)",
                            purpose=paste(
                              "يختبر PP أيضا الجذر الوحدوي مثل ADF، لكنه يصحح الارتباط الذاتي وعدم تجانس التباين بشكل غير معلمي ",
                              "بدلا من إضافة عدد كبير من التأخيرات. يفيد عندما يعتمد ADF كثيرا على اختيار عدد التأخيرات."
                            ),
                            when_to_use="كمكمل/بديل لـ ADF، خصوصا إذا اشتبهت بوجود ارتباط ذاتي أو تباين غير ثابت في انحدار ADF.",
                            H0="جذر وحدوي → غير مستقرة.",
                            H1="مستقرة.",
                            statistic="إحصاء DF مصحح بتقدير متين للتباين.",
                            decision_rule="عند α=0.05: إذا p-value < 0.05 → نرفض H0 → الاستقرارية مرجّحة.",
                            interpretation="إذا اتفق PP وADF فالإستنتاج أقوى. إذا اختلفا نعود للرسوم وACF لتثبيت القرار.",
                            what_it_means_for_choices="توافق ADF+PP يزيد الثقة لتثبيت d. الاختلاف يستلزم تجربة مواصفة أخرى (drift/trend) والتحقق من الانقطاعات وإعادة فحص التحويل.",
                            reporting="اعرض الإحصاء وp-value والمواصفة (drift/trend) والتحويل المستخدم.",
                            caveats="مثل ADF: يعتمد على drift/trend. الانقطاعات قد تحرف الاستنتاج."
                          )
                        ),
                        
                        D("معايير الاختيار (قرار) — d و D و s", open = TRUE,
                          P("يجب تطبيق هذه القواعد كإجراء: (1) اختيار s، (2) تجربة D، (3) تجربة d، (4) فحص التفريق المفرط، (5) اعتماد أبسط حل يحقق استقرارية معقولة."),
                          tags$div(class="grid",
                                   
                                   criteria_block("قاعدة 1 — تثليث ADF/KPSS/PP",
                                                  note = "الغاية: عدم الاعتماد على اختبار واحد لأن فرضياتهم الصفرية مختلفة.",
                                                  tags$ul(
                                                    tags$li(tags$b("استقرارية مرجّحة: "), "ADF/PP يرفضان (p<.05) وKPSS لا يرفض (p≥.05)."),
                                                    tags$li(tags$b("غير مستقرة: "), "ADF/PP لا يرفضان وKPSS يرفض."),
                                                    tags$li(tags$b("تعارض: "), "اعتمد على ACF/PACF + الرسوم + قلّل التفريق (تجنب التفريق المفرط).")
                                                  ),
                                                  P("عند التعارض، يجب كتابة أن القرار مبني على تقارب الأدلة (اختبارات + ACF + رسوم)، وليس على p-value واحدة.")
                                   ),
                                   
                                   criteria_block("قاعدة 2 — تجنب التفريق المفرط",
                                                  note = "الغاية: الحفاظ على ديناميكية قابلة للتفسير وثبات معلمات أفضل.",
                                                  tags$ul(
                                                    tags$li(tags$b("تفريق مفرط في d: "), "ACF عند lag1 سالب جدا بعد التفريق؛ التباين يزيد؛ النموذج غير مستقر."),
                                                    tags$li(tags$b("تفريق مفرط في D: "), "ACF عند lag s سالب جدا بعد التفريق الموسمي."),
                                                    tags$li("إذا شُك بالتفريق المفرط → قلّل d أو D وأعد التقييم.")
                                                  ),
                                                  P("معيار تعليمي جيد: إذا اضطُررت إلى d=2 أو D=2، توقّف وأعد فحص (s، البيانات، الانقطاعات).")
                                   ),
                                   
                                   criteria_block("قاعدة 3 — قيم شائعة",
                                                  note = "الغاية: ابدأ ببساطة ثم زد التعقيد فقط عند الضرورة.",
                                                  tags$ul(
                                                    tags$li(tags$b("d: "), "غالبا 0 أو 1 (و2 نادر جدا)."),
                                                    tags$li(tags$b("D: "), "غالبا 0 أو 1 (و2 نادر جدا)."),
                                                    tags$li(tags$b("s: "), "تستخرج من التقويم؛ إذا لم تكن مؤكدا جرّب بدائل معقولة.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("المخرجات المتوقعة", open = FALSE,
                          P("يجب أن تُختتم هذه المرحلة باختيار واضح (s,d,D) وتبرير مكتوب في 2–4 جمل، يشرح معنى القرار: 'سننمذج الاعتماد المتبقي عبر AR/MA'."),
                          tags$ul(
                            tags$li("القيم المعتمدة: ", tags$code("s"), " و ", tags$code("d"), " و ", tags$code("D"), " + تبرير."),
                            tags$li("جمل خلاصة قصيرة: « تشير الاختبارات + ACF إلى استقرارية بعد ... »"),
                            tags$li("تنبيه عند تعارض الاختبارات → تبرير نوعي.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEPS 5–8 (مكتملة ومترجمة)
      # =========================================================
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("الهدف: "),
                          "إنشاء نقطة مقارنة قوية (Benchmarks) وخط أساس auto-ARIMA، ثم تحديد معايير اختيار تجمع بين المعلومات (AICc/BIC) والصلاحية (التشخيصات) والغاية (أداء التنبؤ).",
                          type="ok"
                        ),
                        D("الغاية", open = TRUE,
                          P("مرحلة الخط الأساسي تمنع فخا شائعا: الاعتقاد أن SARIMA المعقد مفيد بالضرورة. هنا يجب أن يتفوق النموذج أولا على قواعد بسيطة (ساذج، ساذج موسمي)."),
                          tags$ul(
                            tags$li("بناء Benchmarks: ساذج (ŷ_{t+h}=y_t) وساذج موسمي (ŷ_{t+h}=y_{t+h-s})."),
                            tags$li("الحصول على خط أساس SARIMA عبر auto-ARIMA (AICc/BIC) — مع قابلية إعادة."),
                            tags$li("تحديد معايير الاختيار: AICc + تشخيصات + أداء خارج العينة.")
                          )
                        ),
                        D("مفاهيم/اختبارات (قابلة للنقر)", open = FALSE,
                          TERM("النموذج الساذج (تنبؤ السير العشوائي)",
                               "النموذج الساذج يتنبأ بأن المستقبل يساوي آخر قيمة مرصودة. رغم بساطته قد يكون صعب التجاوز في سلاسل شديدة الاستمرارية.",
                               purpose="حد أدنى للمقارنة: إذا لم يتفوق نموذجك على الساذج فأنت لم تضف معلومات تتجاوز الاستمرارية الخام.",
                               criteria="قارن MAE/RMSE على نفس نافذة الاختبار. إذا كان التحسن ضعيفا فالبساطة أفضل.",
                               how_to_apply="احسب أخطاءه دائما على نفس نافذة الاختبار/rolling مثل بقية النماذج.",
                               formula="ŷ_{t+h} = y_t"),
                          TERM("النموذج الساذج الموسمي",
                               "النموذج الساذج الموسمي يتنبأ بأن القيمة المستقبلية تساوي قيمة نفس الموسم السابق (مثل نفس الشهر من العام الماضي).",
                               purpose="Benchmark حاسم عند موسمية قوية: كثير من النماذج 'المتقدمة' تفشل في تجاوزه.",
                               criteria="مفيد خصوصا عندما يكون s محددا جيدا والموسمية مستقرة.",
                               how_to_apply="قيّم على موسم كامل على الأقل إن أمكن.",
                               formula="ŷ_{t+h} = y_{t+h-s}"),
                          TERM("AICc مقابل BIC",
                               "AICc وBIC يقارنان جودة الملاءمة مع عقوبة على التعقيد. AICc يستخدم غالبا للأداء التنبؤي، بينما BIC يعاقب أكثر ويفضل نماذج أبسط.",
                               purpose="تقليل خطر فرط الملاءمة عبر تجنب نماذج معقدة دون ضرورة.",
                               criteria="إذا كان ΔAICc < 2 بين عدة نماذج فهي متقاربة جدا → اختر الأبسط (اقتصاد).",
                               how_to_apply="استخدم AICc/BIC فقط لمقارنة نماذج مقدّرة على نفس السلسلة (نفس التحويل ونفس البيانات).")
                        ),
                        D("معايير الاختيار (قرار)", open = TRUE,
                          P("أفضل نموذج ليس فقط من يقلل AICc: يجب أن يجتاز التشخيصات ويتفوق على Benchmarks في التنبؤ."),
                          tags$div(class="grid",
                                   criteria_block("الاختيار بالمعلومة (AICc/BIC)",
                                                  tags$ul(
                                                    tags$li("اختيار أقل AICc كمرشح أولي."),
                                                    tags$li("إذا كانت عدة نماذج مع ΔAICc < 2 → اختر الأبسط (معلمات أقل)."),
                                                    tags$li("تحقق أيضا من BIC إن كنت تفضّل البساطة أكثر.")
                                                  )
                                   ),
                                   criteria_block("معيار الصلاحية",
                                                  tags$ul(
                                                    tags$li("تشخيصات البواقي مقبولة (Ljung–Box غير دال، إلخ)."),
                                                    tags$li("معلمات مستقرة (استقرارية/قابلية انقلاب).")
                                                  )
                                   ),
                                   criteria_block("معيار الغاية (التنبؤ)",
                                                  tags$ul(
                                                    tags$li("تحسن واضح مقابل Benchmarks (ساذج، ساذج موسمي)."),
                                                    tags$li("إذا كان التحسن ضئيلا → فضّل نموذجا أبسط/أكثر متانة.")
                                                  )
                                   )
                          )
                        ),
                        D("المخرجات المتوقعة", open = FALSE,
                          tags$ul(
                            tags$li("جدول خط الأساس: Benchmarks + auto-ARIMA (AICc، MAE/RMSE على الاختبار)."),
                            tags$li("اختيار خط أساس كنقطة انطلاق (ليس بالضرورة نهائيا).")
                          )
                        )
        ))
      }
      
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("الهدف: "),
                          "استخدام ACF/PACF لبناء شبكة صغيرة من النماذج المرشحة، ثم اختيارها وفق الاقتصاد + التشخيصات. نبحث عن منطق، لا عن بحث عشوائي بالقوة الغاشمة.",
                          type="ok"
                        ),
                        D("الغاية", open = TRUE,
                          P("يتعلم الطالب أن ACF/PACF أدوات إرشادية: تقترح رُتبا ممكنة لكنها لا تُغني عن المقارنة والتشخيصات."),
                          tags$ul(
                            tags$li("العمل على السلسلة المستقرة (بعد d/D)."),
                            tags$li("قراءة ACF/PACF لاقتراح p,q (و P,Q الموسمية)."),
                            tags$li("بناء شبكة قصيرة من المرشحين ومقارنتهم.")
                          )
                        ),
                        D("مفاهيم (قابلة للنقر)", open = FALSE,
                          TERM("ACF",
                               "تقيس دالة الارتباط الذاتي ACF الارتباط بين السلسلة وتأخيراتها. على سلسلة مستقرة، قد يشير نمط قطع/تضاؤل إلى وجود حدود MA.",
                               purpose="تساعد على اقتراح q وQ، وكشف قمم موسمية عند مضاعفات s.",
                               criteria="قمم واضحة عند s و2s... → موسمية؛ قطع سريع عند تأخيرات صغيرة → MA محتمل.",
                               how_to_apply="ارسم ACF بعد التفريق؛ اقترح q/Q صغيرة (0–2) ثم تحقق بالتشخيصات.")
                          ,
                          TERM("PACF",
                               "تقيس دالة الارتباط الذاتي الجزئي PACF الارتباط الجزئي بين y_t و y_{t-k} بعد التحكم في التأخيرات الوسيطة. قطع سريع قد يشير إلى رتبة AR.",
                               purpose="تساعد على اقتراح p وP.",
                               criteria="قمم PACF عند تأخيرات صغيرة → AR محتمل؛ قمم عند s → AR موسمي.",
                               how_to_apply="ارسم PACF بعد التفريق؛ اقترح p/P صغيرة ثم قارن.")
                          ,
                          TERM("حزم الدلالة في ACF/PACF",
                               "الحزم ±1.96/√n تعطي تقريبا لحكم ما إذا كانت قمة ملحوظة إحصائيا.",
                               purpose="تجنب الإفراط في تفسير الضجيج.",
                               criteria="قد تظهر قمم معزولة بالصدفة؛ نبحث عن أنماط متماسكة.",
                               how_to_apply="انظر للبنية العامة (تضاؤل/تكرار) بدل قمة واحدة.")
                        ),
                        D("معايير الاختيار (قرار)", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("مرشحون غير موسميين (p,q)",
                                                  tags$ul(
                                                    tags$li(tags$b("p: "), "إذا كان PACF لديه 1–2 قمم قوية عند تأخيرات صغيرة → p=1 أو 2 محتمل."),
                                                    tags$li(tags$b("q: "), "إذا كان ACF لديه 1–2 قمم قوية → q=1 أو 2 محتمل."),
                                                    tags$li("حافظ على الصِغر: p,q ≤ 3 إلا بتبرير قوي.")
                                                  )
                                   ),
                                   criteria_block("مرشحون موسميون (P,Q)",
                                                  tags$ul(
                                                    tags$li(tags$b("P: "), "قمم PACF عند lag s → P=1 محتمل."),
                                                    tags$li(tags$b("Q: "), "قمم ACF عند lag s → Q=1 محتمل."),
                                                    tags$li("غالبا P,Q ∈ {0,1}.")
                                                  )
                                   ),
                                   criteria_block("الاقتصاد والاختيار",
                                                  tags$ul(
                                                    tags$li("إذا كان ΔAICc < 2 بين المرشحين → اختر الأبسط."),
                                                    tags$li("ارفض النماذج غير المستقرة حتى لو كان AICc جيدا."),
                                                    tags$li("تحقق دائما من تشخيصات البواقي بعد ذلك.")
                                                  )
                                   )
                          )
                        ),
                        D("المخرجات المتوقعة", open = FALSE,
                          tags$ul(
                            tags$li("قائمة قصيرة من مرشحي SARIMA((p,d,q)(P,D,Q)[s])."),
                            tags$li("تبرير عبر ACF/PACF + الاقتصاد."),
                            tags$li("مقارنة AICc/BIC + تشخيصات أولية.")
                          )
                        )
        ))
      }
      
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("الهدف: "),
                          "التحقق أن البواقي تشبه ضجيجا أبيض (نموذج مناسب) وأن دقة التنبؤ تتفوق على Benchmarks. اختبارات البواقي تكشف ما لم يتعلمه النموذج.",
                          type="ok"
                        ),
                        D("الغاية", open = TRUE,
                          P("قد تحصل على AICc ممتاز ونموذج سيء إذا بقيت البواقي مترابطة زمنيا. هذه المرحلة تفرض الانضباط: أولا الصلاحية (البواقي)، ثم الأداء (التنبؤ)."),
                          tags$ul(
                            tags$li("فحص البواقي: لا ارتباط ذاتي متبق، تباين مستقر، وعدم وجود ARCH مهم (إن كان ذا صلة)."),
                            tags$li("مقارنة أداء التنبؤ على الاختبار/rolling (MAE/RMSE/...)."),
                            tags$li("اختيار نهائي: تشخيصات جيدة + أداء + بساطة.")
                          )
                        ),
                        D("اختبارات البواقي (الهدف + معايير مفصلة)", open = FALSE,
                          TEST(
                            name="Ljung–Box (ارتباط ذاتي متبق في البواقي)",
                            purpose=paste(
                              "يختبر ما إذا كانت ارتباطات البواقي (حتى تأخر L) مساوية للصفر إجمالا. ",
                              "هذا اختبار مركزي: إذا رُفضت H0 فهذا يعني أن النموذج ترك بنية زمنية غير مفسرة، أي أن مواصفة SARIMA غير مكتملة."
                            ),
                            when_to_use="دائما بعد التقدير، ويفضل لعدة قيم L (مثل L=10 وL=2s).",
                            H0="البواقي ~ ضجيج أبيض حتى التأخر L (لا ارتباط ذاتي).",
                            H1="وجود ارتباط ذاتي في البواقي.",
                            statistic="Q(L) يجمّع ارتباطات البواقي؛ درجات الحرية تُعدّل بـ fitdf.",
                            decision_rule="عند α=0.05: إذا p-value ≥ 0.05 → مقبول؛ إذا p-value < 0.05 → راجع (p,q,P,Q,d,D) أو التحويل.",
                            interpretation="الرفض يشير إلى وجود أنماط زمنية متبقية (تأخيرات غير نمذجة، موسم ناقص، تفريق غير كاف، إلخ).",
                            what_it_means_for_choices="إذا رُفض → أضف/عدّل AR أو MA (موسمي أو غير موسمي) أو أعد النظر في d/D. إذا لم يُرفض → انتقل لتقييم التنبؤ والاختيار الاقتصادي.",
                            reporting="اذكر L وQ وp-value وfitdf وخلاصة 'البواقي متوافقة مع ضجيج أبيض'.",
                            caveats="اختيار L مهم؛ ومع n كبير يصبح الاختبار شديد الحساسية."
                          )
                        ),
                        D("المخرجات المتوقعة", open = FALSE,
                          tags$ul(
                            tags$li("جدول مقارنة: (AICc/BIC) + MAE/RMSE (اختبار) + p-value لـ Ljung–Box (بواقي)."),
                            tags$li("قرار نهائي: النموذج المعتمد + تبرير (تشخيصات + أداء + بساطة).")
                          )
                        )
        ))
      }
      
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("الهدف: "),
                          "كتابة خاتمة كاملة ومفهومة: النموذج النهائي، الدليل (تشخيصات + أداء)، والمعنى (ماذا يقول النموذج عن السلسلة وما حدوده).",
                          type="ok"
                        ),
                        D("معادلة SARIMA (ترميز صحيح)", open = TRUE,
                          tags$ul(
                            tags$li(
                              tags$code("Φ(B^s) φ(B) ∇^d ∇_s^D y_t = Θ(B^s) θ(B) ε_t"),
                              " مع الابتكارات ",
                              tags$code("ε_t ~ w.n.(0, σ^2)")
                            )
                          ),
                          tags$p(class="small",
                                 "القراءة: نثبت السلسلة بالتفريق، ثم تلتقط حدود AR/MA الاعتماد المتبقي. يجب شرح هذه الفكرة صراحة في التقرير لإظهار فهم دور كل مكوّن."
                          )
                        ),
                        D("قالب نصي (جاهز للنسخ)", open = TRUE,
                          P(
                            tags$b("خلاصة (مثال). "),
                            "« النموذج النهائي المعتمد هو SARIMA((p,d,q)(P,D,Q)[s]) مقدَّر على السلسلة [المحوّلة/غير المحوّلة]. ",
                            "دفعت التشخيصات (ACF/PACF + اختبارات ADF/KPSS/PP) إلى اختيار d=[..] وD=[..] وs=[..]. ",
                            "كانت البواقي متوافقة مع ضجيج أبيض (Ljung–Box غير دال عند L=[..] وα=0.05)، ما يشير إلى أن الاعتماد الزمني الرئيسي قد تم التقاطه. ",
                            "في التقييم خارج العينة كانت MAE=[..] وRMSE=[..] أفضل من خطوط المقارنة [الساذج/الساذج الموسمي]. ",
                            "يعني ذلك أن السلسلة تُظهر بنية [موسمية/قصور ذاتي/صدمات عابرة] تستمر بما يكفي لإنتاج تنبؤات مفيدة عند أفق h=[..]. ",
                            "وتشمل الحدود [انقطاعات محتملة، متغيرات خارجية غير ممذجة، تقلب/تذبذب]. »"
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "خطوة غير معروفة.")
    }
    
    # ----------------------------
    # Slider (بدون تمرير طويل)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "خارطة طريق SARIMA (شديدة التفصيل) — العربية"),
                          tags$p(class="road-sub",
                                 "استخدم شريط التمرير (Slider) للتنقل دون تمرير طويل. كل خطوة تتبع: الهدف → التحليلات → الاختبارات → المعايير → المخرجات → المزالق."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "الخطوة (Slider — لا حاجة للتمرير)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  
  
  
  # =========================
  # 8 — GARCH (NEW SERVER LOGIC)
  # Requires: rugarch
  # =========================
  
  # Teaching notes for the tab
  output$garch_notes <- renderUI({
    note_box(list(
      "Use GARCH when the residual variance changes over time (volatility clustering).",
      "Model the mean (ARMA) and the conditional variance (GARCH family).",
      "If you model log-returns, interpret forecasts as return forecasts and sigma as volatility."
    ))
  })
  
  output$garch_what_to_do <- renderUI({
    tags$div(
      style = "background:#eef5ff;padding:10px;border-radius:6px;margin-bottom:10px;",
      tags$b("What to do:"),
      tags$ul(
        tags$li("Choose whether to model levels or log-returns (returns usually preferred)."),
        tags$li("Pick a variance model (sGARCH is the baseline; gjrGARCH/eGARCH capture asymmetry)."),
        tags$li("Check diagnostics: standardized residuals should look like white noise; squared residuals should also be clean."),
        tags$li("If residuals are heavy-tailed, switch Normal → Student-t or skewed t."),
        tags$li("Compare models by AIC/BIC and out-of-sample accuracy (if you have a test set).")
      )
    )
  })
  
  # ---- Helper: safe pkg check (you already have has_pkg() globally)
  need_pkg <- function(pkg) {
    validate(need(has_pkg(pkg), paste0("Please install package '", pkg, "' (install.packages('", pkg, "')) to use this tab.")))
  }
  
  # ---- Helper: accuracy metrics (same spirit as your existing accuracy_table)
  garch_accuracy <- function(actual, forecast) {
    a <- as.numeric(actual)
    f <- as.numeric(forecast)
    e <- a - f
    rmse <- sqrt(mean(e^2, na.rm = TRUE))
    mae  <- mean(abs(e), na.rm = TRUE)
    mape <- mean(abs(e / a), na.rm = TRUE)
    smape <- mean(2 * abs(e) / (abs(a) + abs(f)), na.rm = TRUE)
    
    data.frame(
      Metric = c("RMSE", "MAE", "MAPE", "sMAPE"),
      Value = c(rmse, mae, mape, smape),
      stringsAsFactors = FALSE
    )
  }
  
  # ---- Helper: make the modeling series from prepared()/ts split
  garch_series <- reactive({
    req(prepared())
    df <- prepared()$df
    
    # try to use your existing train/test logic if present
    train_n <- NULL
    test_n  <- 0L
    
    if (exists("ts_train_test", mode = "function")) {
      s <- tryCatch(ts_train_test(), error = function(e) NULL)
      if (!is.null(s) && !is.null(s$train_n)) {
        train_n <- s$train_n
        # preferred modeling target (in your app you use y_trans for modeling)
        y_full <- df$y_trans
        if (isTRUE(input$garch_series_type == "logret")) {
          y_full <- as.numeric(y_full)
          y_full <- y_full[is.finite(y_full)]
          y_mod <- diff(log(y_full))
          if (isTRUE(input$garch_scale_100)) y_mod <- 100 * y_mod
          # returns length reduced by 1
          # align train_n accordingly (roughly)
          train_n_mod <- max(5L, min(length(y_mod), train_n - 1L))
          list(y = y_mod, x = df$x[-1], train_n = train_n_mod, test_n = max(0L, length(y_mod) - train_n_mod))
        } else {
          y_mod <- as.numeric(df$y_trans)
          ok <- is.finite(y_mod)
          y_mod <- y_mod[ok]
          x_mod <- df$x[ok]
          train_n_mod <- max(5L, min(length(y_mod), train_n))
          list(y = y_mod, x = x_mod, train_n = train_n_mod, test_n = max(0L, length(y_mod) - train_n_mod))
        }
      }
    }
    
    # fallback: use all data
    if (isTRUE(input$garch_series_type == "logret")) {
      y_full <- as.numeric(df$y_trans)
      y_full <- y_full[is.finite(y_full)]
      y_mod <- diff(log(y_full))
      if (isTRUE(input$garch_scale_100)) y_mod <- 100 * y_mod
      list(y = y_mod, x = df$x[-1], train_n = length(y_mod), test_n = 0L)
    } else {
      y_mod <- as.numeric(df$y_trans)
      ok <- is.finite(y_mod)
      list(y = y_mod[ok], x = df$x[ok], train_n = sum(ok), test_n = 0L)
    }
  })
  
  # ---- Fit event
  garch_fit <- eventReactive(input$fit_garch, {
    need_pkg("rugarch")
    s <- garch_series()
    y <- s$y
    validate(need(length(y) >= 30, "Need at least ~30 observations for a stable GARCH fit."))
    
    # training window
    y_train <- y[seq_len(s$train_n)]
    
    spec <- rugarch::ugarchspec(
      variance.model = list(
        model = input$garch_vmodel,
        garchOrder = c(as.integer(input$garch_p), as.integer(input$garch_q))
      ),
      mean.model = list(
        armaOrder = c(as.integer(input$garch_ar), as.integer(input$garch_ma)),
        include.mean = isTRUE(input$garch_include_mean)
      ),
      distribution.model = input$garch_dist
    )
    
    fit <- tryCatch(
      rugarch::ugarchfit(spec = spec, data = y_train, solver = "hybrid"),
      error = function(e) {
        validate(paste("GARCH fit failed:", e$message))
        NULL
      }
    )
    
    list(spec = spec, fit = fit, series = s, y_train = y_train)
  })
  
  # ---- Model spec text
  output$garch_model_spec <- renderPrint({
    req(garch_fit())
    gf <- garch_fit()
    s <- gf$series
    
    cat("GARCH model specification\n")
    cat("------------------------------------------------------------\n")
    cat("Series modeled        :", if (input$garch_series_type == "logret") "Log-returns" else "Level", "\n")
    cat("Train N               :", s$train_n, "\n")
    cat("Test N                :", s$test_n, "\n\n")
    
    cat("Mean model (ARMA)\n")
    cat("  ARMA(p,q)           : (", input$garch_ar, ",", input$garch_ma, ")\n", sep = "")
    cat("  Include mean (mu)   :", if (isTRUE(input$garch_include_mean)) "Yes" else "No", "\n\n")
    
    cat("Variance model\n")
    cat("  Variant             :", input$garch_vmodel, "\n")
    cat("  Order (p,q)         : (", input$garch_p, ",", input$garch_q, ")\n\n", sep = "")
    
    cat("Innovations\n")
    cat("  Distribution        :", input$garch_dist, "\n\n")
    
    show_methods <- tryCatch(rugarch::infocriteria(gf$fit), error = function(e) NULL)
    if (!is.null(show_methods)) {
      cat("Information criteria\n")
      print(round(show_methods, 4))
    }
  })
  
  # ---- Coef table
  output$garch_coef_table <- renderTable({
    req(garch_fit())
    gf <- garch_fit()
    
    m <- tryCatch(gf$fit@fit$matcoef, error = function(e) NULL)
    validate(need(!is.null(m), "Could not extract coefficient table."))
    
    out <- as.data.frame(m)
    out$term <- rownames(out)
    rownames(out) <- NULL
    out <- out[, c("term", colnames(m)), drop = FALSE]
    names(out) <- c("term", "Estimate", "Std. Error", "t value", "Pr(>|t|)")
    out
  }, rownames = FALSE)
  
  # ---- Model equation (MathJax)
  output$garch_model_equation <- renderUI({
    req(garch_fit())
    
    p  <- as.integer(input$garch_ar)
    q  <- as.integer(input$garch_ma)
    vp <- as.integer(input$garch_p)
    vq <- as.integer(input$garch_q)
    
    mean_eq <- if (p == 0 && q == 0) {
      if (isTRUE(input$garch_include_mean)) "\\mu_t = \\mu" else "\\mu_t = 0"
    } else {
      paste0(
        "y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + ",
        "\\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t"
      )
    }
    
    var_eq <- switch(
      input$garch_vmodel,
      "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2 \\mathbb{I}(\\varepsilon_{t-i}<0)) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\left|\\frac{\\varepsilon_{t-i}}{\\sigma_{t-i}}\\right| + \\gamma_i \\frac{\\varepsilon_{t-i}}{\\sigma_{t-i}}\\right) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
      "\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2"
    )
    
    html <- paste0(
      "<p><b>Mean equation:</b></p>",
      "<div>$$", mean_eq, "$$</div>",
      "<p><b>Variance equation:</b></p>",
      "<div>$$", var_eq, "$$</div>",
      "<p>Where $$\\varepsilon_t = \\sigma_t z_t$$ and $$z_t$$ follows the chosen innovation distribution.</p>"
    )
    
    # force MathJax to typeset the updated UI
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "garch_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  
  
  
  
  # output$garch_model_equation <- renderUI({
  #   req(garch_fit())
  #   
  #   p <- as.integer(input$garch_ar)
  #   q <- as.integer(input$garch_ma)
  #   vp <- as.integer(input$garch_p)
  #   vq <- as.integer(input$garch_q)
  #   
  #   mean_eq <- if (p == 0 && q == 0) {
  #     if (isTRUE(input$garch_include_mean)) {
  #       "\\mu_t = \\mu"
  #     } else {
  #       "\\mu_t = 0"
  #     }
  #   } else {
  #     # compact ARMA notation
  #     paste0(
  #       "y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + \\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t"
  #     )
  #   }
  #   
  #   var_eq <- switch(
  #     input$garch_vmodel,
  #     "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
  #     "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\left(\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2 \\mathbb{I}(\\varepsilon_{t-i}<0)\\right) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
  #     "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} \\left(\\alpha_i \\left|\\frac{\\varepsilon_{t-i}}{\\sigma_{t-i}}\\right| + \\gamma_i \\frac{\\varepsilon_{t-i}}{\\sigma_{t-i}}\\right) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
  #     paste0("\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2")
  #   )
  #   
  #   tags$div(
  #     tags$p(tags$b("Mean equation:")),
  #     tags$div(HTML(paste0("$$", mean_eq, "$$"))),
  #     tags$p(tags$b("Variance equation:")),
  #     tags$div(HTML(paste0("$$", var_eq, "$$"))),
  #     tags$p(
  #       HTML("Where $$\\varepsilon_t = \\sigma_t z_t$$ and $$z_t$$ follows the chosen innovation distribution.")
  #     )
  #   )
  # })
  
  # ---- Diagnostics plots (standardized residuals etc.)
  output$garch_resid_ts <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    z <- as.numeric(z)
    
    plot(z, type = "l", col = "#2C7FB8", main = "Standardized residuals", xlab = "t", ylab = "z_t")
    abline(h = 0, lty = 2, col = "gray50")
  })
  
  output$garch_resid_acf <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    forecast::ggAcf(as.numeric(z)) + ggplot2::labs(title = "ACF of standardized residuals")
  })
  
  output$garch_resid_hist <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    z <- as.numeric(z)
    
    ggplot2::ggplot(data.frame(z = z), ggplot2::aes(x = z)) +
      ggplot2::geom_histogram(bins = 30, fill = "#74a9cf", color = "white") +
      ggplot2::theme_minimal() +
      ggplot2::labs(title = "Histogram (standardized residuals)", x = "z_t", y = "Count")
  })
  
  output$garch_resid_qq <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    z <- as.numeric(z)
    
    qqnorm(z, main = "QQ plot (standardized residuals)", col = "#2C7FB8")
    qqline(z, col = "gray40", lwd = 2)
  })
  
  # Conditional sigma plot
  output$garch_sigma_plot <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    sig <- tryCatch(rugarch::sigma(gf$fit), error = function(e) NULL)
    validate(need(!is.null(sig), "No sigma available."))
    sig <- as.numeric(sig)
    
    plot(sig, type = "l", col = "#d95f0e", main = "Conditional volatility (sigma_t)", xlab = "t", ylab = expression(sigma[t]))
  })
  
  # ---- Residual tests (text)
  output$garch_diag_tests <- renderPrint({
    req(garch_fit())
    gf <- garch_fit()
    
    z <- as.numeric(rugarch::residuals(gf$fit, standardize = TRUE))
    z2 <- z^2
    
    L <- as.integer(input$diag_lag %||% 12)
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    cat("GARCH residual diagnostics (standardized residuals)\n")
    cat("------------------------------------------------------------\n")
    
    # LB on z
    lb1 <- tryCatch(Box.test(z, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    if (!is.null(lb1)) cat(sprintf("- Ljung-Box on z_t: Q(%d)=%.4f, p=%.4g\n", L, lb1$statistic, lb1$p.value))
    
    # LB on z^2
    lb2 <- tryCatch(Box.test(z2, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    if (!is.null(lb2)) cat(sprintf("- Ljung-Box on z_t^2: Q(%d)=%.4f, p=%.4g\n", L, lb2$statistic, lb2$p.value))
    
    # Jarque-Bera
    jb <- tryCatch(tseries::jarque.bera.test(z), error = function(e) NULL)
    if (!is.null(jb)) cat(sprintf("- Jarque-Bera: JB=%.4f, p=%.4g\n", jb$statistic, jb$p.value))
    
    # ARCH LM (on standardized residuals)
    if (has_pkg("FinTS")) {
      arch <- tryCatch(FinTS::ArchTest(z, lags = L), error = function(e) NULL)
      if (!is.null(arch)) cat(sprintf("- ARCH LM: LM=%.4f, p=%.4g (lags=%d)\n", arch$statistic, arch$p.value, L))
    } else {
      cat("- ARCH LM: install.packages('FinTS') to enable this test.\n")
    }
    
    cat("\nRule of thumb:\n")
    cat("• We want Ljung-Box p-values on z_t and z_t^2 to be > 0.05 (no leftover autocorrelation / ARCH).\n")
    cat("• Heavy tails: JB often rejects; use Student-t / skewed t innovations.\n")
  })
  
  # ---- Forecast & accuracy
  garch_forecast <- reactive({
    req(garch_fit())
    need_pkg("rugarch")
    
    gf <- garch_fit()
    s <- gf$series
    y <- s$y
    
    # horizon: if test exists => align to test length; else input$garch_h
    h <- if (s$test_n > 0) s$test_n else {
      hh <- suppressWarnings(as.integer(input$garch_h))
      if (!is.finite(hh) || is.na(hh) || hh < 1) 12L else hh
    }
    
    fc <- tryCatch(
      rugarch::ugarchforecast(gf$fit, n.ahead = h),
      error = function(e) {
        validate(paste("Forecast failed:", e$message))
        NULL
      }
    )
    
    # extract mean and sigma forecasts
    mu_hat <- as.numeric(rugarch::fitted(fc))
    sig_hat <- as.numeric(rugarch::sigma(fc))
    
    list(h = h, mu = mu_hat, sigma = sig_hat, series = s, y = y)
  })
  
  output$garch_horizon_note <- renderPrint({
    req(garch_forecast())
    fc <- garch_forecast()
    s <- fc$series
    if (s$test_n > 0) {
      cat("Forecast horizon equals the test set length (h = ", fc$h, ").\n", sep = "")
    } else {
      cat("No test set detected; using future horizon h = ", fc$h, ".\n", sep = "")
    }
  })
  
  output$garch_forecast_table <- renderTable({
    req(garch_forecast())
    fc <- garch_forecast()
    out <- data.frame(
      step = seq_len(fc$h),
      mean_forecast = fc$mu,
      sigma_forecast = fc$sigma
    )
    if (!isTRUE(input$garch_forecast_sigma)) out$sigma_forecast <- NULL
    out
  }, rownames = FALSE)
  
  output$garch_accuracy_table <- renderTable({
    req(garch_forecast())
    fc <- garch_forecast()
    s <- fc$series
    
    if (s$test_n <= 0) {
      return(data.frame(Metric = "Note", Value = "No test set available; accuracy not computed.", stringsAsFactors = FALSE))
    }
    
    y_test <- fc$y[(s$train_n + 1):(s$train_n + s$test_n)]
    y_hat  <- fc$mu[seq_len(length(y_test))]
    garch_accuracy(y_test, y_hat)
  }, rownames = FALSE)
  
  output$garch_forecast_plot <- renderPlot({
    req(garch_forecast())
    fc <- garch_forecast()
    s <- fc$series
    
    y <- fc$y
    train_n <- s$train_n
    h <- fc$h
    
    # Build x for plotting
    x <- s$x
    x_train <- x[seq_len(train_n)]
    x_fc <- x[(train_n + 1):min(length(x), train_n + h)]
    if (length(x_fc) < h) {
      # fallback: simple index extension
      x_fc <- (length(x_train) + 1):(length(x_train) + h)
    }
    
    df_train <- data.frame(x = x_train, y = y[seq_len(train_n)], set = "Train")
    df_fc <- data.frame(x = x_fc, mean = fc$mu[seq_len(h)], sigma = fc$sigma[seq_len(h)])
    
    p <- ggplot() +
      geom_line(data = df_train, aes(x = x, y = y), color = "#2C7FB8") +
      geom_line(data = df_fc, aes(x = x, y = mean), color = "#d95f0e", linewidth = 1) +
      theme_minimal() +
      labs(
        title = "GARCH forecast (mean) and optional volatility band",
        x = "Time",
        y = if (input$garch_series_type == "logret") "Return" else "Level"
      )
    
    if (isTRUE(input$garch_forecast_sigma)) {
      p <- p + geom_ribbon(
        data = df_fc,
        aes(x = x, ymin = mean - 1.96 * sigma, ymax = mean + 1.96 * sigma),
        alpha = 0.15, fill = "#d95f0e"
      )
    }
    
    # if test exists, overlay actual test
    if (s$test_n > 0) {
      df_test <- data.frame(
        x = x[(train_n + 1):(train_n + s$test_n)],
        y = y[(train_n + 1):(train_n + s$test_n)]
      )
      p <- p + geom_line(data = df_test, aes(x = x, y = y), color = "gray40")
    }
    
    p
  })
  
  
  # ---- APA paragraph (GARCH)
  output$garch_apa_paragraph <- renderPrint({
    req(garch_fit())
    gf <- garch_fit()
    
    # pull series/test info
    s <- gf$series
    n_train <- s$train_n
    n_test  <- s$test_n
    
    # info criteria
    ic <- tryCatch(rugarch::infocriteria(gf$fit), error = function(e) NULL)
    aic <- if (!is.null(ic) && "Akaike" %in% names(ic)) as.numeric(ic["Akaike"]) else NA_real_
    bic <- if (!is.null(ic) && "Bayes"  %in% names(ic)) as.numeric(ic["Bayes"])  else NA_real_
    
    # coefs
    mat <- tryCatch(gf$fit@fit$matcoef, error = function(e) NULL)
    
    get_coef <- function(name) {
      if (is.null(mat)) return(list(est = NA_real_, p = NA_real_))
      if (!name %in% rownames(mat)) return(list(est = NA_real_, p = NA_real_))
      list(est = as.numeric(mat[name, 1]), p = as.numeric(mat[name, 4]))
    }
    
    # common variance params
    omega <- get_coef("omega")
    alpha1 <- get_coef("alpha1")
    beta1  <- get_coef("beta1")
    gamma1 <- get_coef("gamma1")   # gjrGARCH
    shape  <- get_coef("shape")    # t / ged
    skew   <- get_coef("skew")     # sstd
    
    # residual diagnostics
    z <- tryCatch(as.numeric(rugarch::residuals(gf$fit, standardize = TRUE)), error = function(e) NULL)
    validate(need(!is.null(z), "Could not compute standardized residuals for APA paragraph."))
    
    L <- as.integer(input$diag_lag %||% 12)
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lb_z  <- tryCatch(Box.test(z,  lag = L, type = "Ljung-Box"), error = function(e) NULL)
    lb_z2 <- tryCatch(Box.test(z^2, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    
    jb <- tryCatch(tseries::jarque.bera.test(z), error = function(e) NULL)
    
    arch <- NULL
    if (has_pkg("FinTS")) {
      arch <- tryCatch(FinTS::ArchTest(z, lags = L), error = function(e) NULL)
    }
    
    # Forecast accuracy (if test exists)
    acc_text <- ""
    if (n_test > 0) {
      fc <- garch_forecast()
      y_test <- fc$y[(n_train + 1):(n_train + n_test)]
      y_hat  <- fc$mu[seq_len(length(y_test))]
      
      e <- y_test - y_hat
      rmse <- sqrt(mean(e^2, na.rm = TRUE))
      mae  <- mean(abs(e), na.rm = TRUE)
      mape <- mean(abs(e / y_test), na.rm = TRUE)
      
      acc_text <- paste0(
        " Out-of-sample forecast accuracy over the test set (n = ", n_test,
        ") was RMSE = ", fmt_num(rmse), ", MAE = ", fmt_num(mae),
        ", and MAPE = ", fmt_pct(mape), "."
      )
    } else {
      acc_text <- " No holdout test set was detected, so out-of-sample accuracy was not computed."
    }
    
    # build spec text
    mean_part <- paste0(
      "An ARMA(", input$garch_ar, ", ", input$garch_ma, ") mean model",
      if (isTRUE(input$garch_include_mean)) " with an intercept" else " without an intercept",
      " was specified."
    )
    
    var_part <- paste0(
      " Conditional variance was modeled using ", input$garch_vmodel,
      " with order (", input$garch_p, ", ", input$garch_q, ")."
    )
    
    dist_part <- paste0(" Innovations were assumed to follow a ", input$garch_dist, " distribution.")
    
    # parameter highlights (only mention if available)
    parm_bits <- c()
    
    if (is.finite(omega$est)) {
      parm_bits <- c(parm_bits, paste0("ω = ", fmt_num(omega$est), " (p ", fmt_p(omega$p), ")"))
    }
    if (is.finite(alpha1$est)) {
      parm_bits <- c(parm_bits, paste0("α₁ = ", fmt_num(alpha1$est), " (p ", fmt_p(alpha1$p), ")"))
    }
    if (is.finite(beta1$est)) {
      parm_bits <- c(parm_bits, paste0("β₁ = ", fmt_num(beta1$est), " (p ", fmt_p(beta1$p), ")"))
    }
    if (is.finite(gamma1$est)) {
      parm_bits <- c(parm_bits, paste0("γ₁ = ", fmt_num(gamma1$est), " (p ", fmt_p(gamma1$p), ")"))
    }
    if (is.finite(shape$est)) {
      parm_bits <- c(parm_bits, paste0("shape = ", fmt_num(shape$est), " (p ", fmt_p(shape$p), ")"))
    }
    if (is.finite(skew$est)) {
      parm_bits <- c(parm_bits, paste0("skew = ", fmt_num(skew$est), " (p ", fmt_p(skew$p), ")"))
    }
    
    parms_text <- if (length(parm_bits) > 0) {
      paste0(" Key parameter estimates included ", paste(parm_bits, collapse = "; "), ".")
    } else {
      ""
    }
    
    # diagnostics sentence
    diag_bits <- c()
    if (!is.null(lb_z))  diag_bits <- c(diag_bits, paste0("Ljung–Box on zₜ: Q(", L, ") = ", fmt_num(lb_z$statistic), ", p ", fmt_p(lb_z$p.value)))
    if (!is.null(lb_z2)) diag_bits <- c(diag_bits, paste0("Ljung–Box on zₜ²: Q(", L, ") = ", fmt_num(lb_z2$statistic), ", p ", fmt_p(lb_z2$p.value)))
    if (!is.null(arch))  diag_bits <- c(diag_bits, paste0("ARCH LM: LM = ", fmt_num(arch$statistic), ", p ", fmt_p(arch$p.value)))
    if (!is.null(jb))    diag_bits <- c(diag_bits, paste0("Jarque–Bera: JB = ", fmt_num(jb$statistic), ", p ", fmt_p(jb$p.value)))
    
    diag_text <- if (length(diag_bits) > 0) {
      paste0(" Residual diagnostics indicated ", paste(diag_bits, collapse = "; "), ".")
    } else {
      " Residual diagnostics were not available for reporting."
    }
    
    # AIC/BIC text
    ic_text <- if (is.finite(aic) || is.finite(bic)) {
      paste0(
        " Model fit was summarized by information criteria (AIC = ",
        if (is.finite(aic)) fmt_num(aic) else "NA",
        ", BIC = ",
        if (is.finite(bic)) fmt_num(bic) else "NA",
        ")."
      )
    } else {
      ""
    }
    
    series_name <- if (input$garch_series_type == "logret") "log-returns" else "the level series"
    series_scale <- if (input$garch_series_type == "logret" && isTRUE(input$garch_scale_100)) " (scaled by 100)" else ""
    
    paragraph <- paste0(
      "A GARCH model was fitted to ", series_name, series_scale, " using the training sample (n = ", n_train, "). ",
      mean_part, var_part, dist_part,
      ic_text,
      parms_text,
      diag_text,
      acc_text
    )
    
    cat(paragraph)
  })
  
  
  output$garch_conclusion <- renderUI({
    req(garch_fit())
    
    # ---- helpers (use yours if present)
    fmt_num_local <- function(x, d = 3) {
      if (!is.finite(x) || is.na(x)) return("NA")
      formatC(x, format = "f", digits = d)
    }
    fmt_p_local <- function(p) {
      if (!is.finite(p) || is.na(p)) return("= NA")
      if (p < 0.001) return("< .001")
      paste0("= ", sub("^0", "", fmt_num_local(p, 3)))
    }
    fmt_pct_local <- function(x) {
      if (!is.finite(x) || is.na(x)) return("NA")
      paste0(fmt_num_local(100 * x, 2), "%")
    }
    
    gf <- garch_fit()
    s <- gf$series
    n_train <- s$train_n
    n_test  <- s$test_n
    
    # ---- equations
    p  <- as.integer(input$garch_ar)
    q  <- as.integer(input$garch_ma)
    vp <- as.integer(input$garch_p)
    vq <- as.integer(input$garch_q)
    
    mean_eq <- if (p == 0 && q == 0) {
      if (isTRUE(input$garch_include_mean)) "y_t = \\mu + \\varepsilon_t" else "y_t = \\varepsilon_t"
    } else {
      paste0(
        "y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + ",
        "\\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t"
      )
    }
    
    var_eq <- switch(
      input$garch_vmodel,
      "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2\\,\\mathbb{I}(\\varepsilon_{t-i}<0)) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i |z_{t-i}| + \\gamma_i z_{t-i}) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
      "\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2"
    )
    
    # ---- info criteria
    ic <- tryCatch(rugarch::infocriteria(gf$fit), error = function(e) NULL)
    aic <- if (!is.null(ic) && "Akaike" %in% names(ic)) as.numeric(ic["Akaike"]) else NA_real_
    bic <- if (!is.null(ic) && "Bayes"  %in% names(ic)) as.numeric(ic["Bayes"])  else NA_real_
    
    # ---- coefficients and p-values
    mat <- tryCatch(gf$fit@fit$matcoef, error = function(e) NULL)
    
    get_coef <- function(name) {
      if (is.null(mat) || !name %in% rownames(mat)) return(list(est = NA_real_, p = NA_real_))
      list(est = as.numeric(mat[name, 1]), p = as.numeric(mat[name, 4]))
    }
    
    omega <- get_coef("omega")
    alpha1 <- get_coef("alpha1")
    beta1  <- get_coef("beta1")
    gamma1 <- get_coef("gamma1")
    shape  <- get_coef("shape")
    skew   <- get_coef("skew")
    mu     <- get_coef("mu")
    
    # ---- persistence + half-life (only meaningful for sGARCH/gjrGARCH)
    persistence <- NA_real_
    halflife <- NA_real_
    if (input$garch_vmodel %in% c("sGARCH", "gjrGARCH") && is.finite(alpha1$est) && is.finite(beta1$est)) {
      # common approximation: alpha + beta (gjr has extra terms; keep conservative summary)
      persistence <- alpha1$est + beta1$est
      if (is.finite(persistence) && persistence > 0 && persistence < 1) {
        halflife <- log(0.5) / log(persistence)
      }
    }
    
    # ---- residual diagnostics
    z <- tryCatch(as.numeric(rugarch::residuals(gf$fit, standardize = TRUE)), error = function(e) NULL)
    validate(need(!is.null(z), "Could not compute standardized residuals."))
    
    L <- as.integer(input$diag_lag %||% 12)
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lb_z  <- tryCatch(Box.test(z, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    lb_z2 <- tryCatch(Box.test(z^2, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    jb    <- tryCatch(tseries::jarque.bera.test(z), error = function(e) NULL)
    arch  <- if (has_pkg("FinTS")) tryCatch(FinTS::ArchTest(z, lags = L), error = function(e) NULL) else NULL
    
    # ---- forecast & accuracy (if test exists)
    acc_line <- "No holdout test set was detected; therefore, out-of-sample accuracy statistics were not computed."
    fc_tbl <- NULL
    
    if (n_test > 0) {
      fc <- garch_forecast()   # uses your earlier reactive
      y_test <- fc$y[(n_train + 1):(n_train + n_test)]
      y_hat  <- fc$mu[seq_len(length(y_test))]
      
      e <- y_test - y_hat
      rmse <- sqrt(mean(e^2, na.rm = TRUE))
      mae  <- mean(abs(e), na.rm = TRUE)
      mape <- mean(abs(e / y_test), na.rm = TRUE)
      
      acc_line <- paste0(
        "Forecast accuracy on the test set (n = ", n_test, ") was RMSE = ",
        fmt_num_local(rmse), ", MAE = ", fmt_num_local(mae),
        ", and MAPE = ", fmt_pct_local(mape), "."
      )
      
      # small forecast snippet for conclusion
      fc_tbl <- data.frame(
        step = seq_len(min(5, fc$h)),
        mean_forecast = fc$mu[seq_len(min(5, fc$h))],
        sigma_forecast = fc$sigma[seq_len(min(5, fc$h))]
      )
    }
    
    # ---- narrative bits
    series_text <- if (input$garch_series_type == "logret") {
      if (isTRUE(input$garch_scale_100)) "log-returns (scaled by 100)" else "log-returns"
    } else {
      "the level series"
    }
    
    dist_long <- switch(
      input$garch_dist,
      "norm" = "Gaussian",
      "std"  = "Student’s t",
      "sstd" = "skewed Student’s t",
      "ged"  = "generalized error (GED)",
      input$garch_dist
    )
    
    # ---- build HTML (academic format)
    html <- paste0(
      "<h4 style='margin-top:0;'>Conclusion (GARCH modelling)</h4>",
      
      "<p><b>Model overview.</b> A ", input$garch_vmodel, " model was estimated for ", series_text,
      " using a training sample of <i>n</i> = ", n_train, " observations. The conditional mean was specified as ARMA(",
      p, ", ", q, ") ", if (isTRUE(input$garch_include_mean)) "with an intercept" else "without an intercept",
      ", and innovations were assumed to follow a ", dist_long, " distribution.</p>",
      
      "<p><b>Model equations.</b></p>",
      "<div style='margin-left:6px;'>$$", mean_eq, "$$</div>",
      "<div style='margin-left:6px;'>$$", var_eq, "$$</div>",
      "<p>with $$\\varepsilon_t = \\sigma_t z_t$$.</p>",
      
      "<p><b>Key estimation results.</b> ",
      if (is.finite(aic) || is.finite(bic)) paste0("Information criteria indicated AIC = ", fmt_num_local(aic), " and BIC = ", fmt_num_local(bic), ". ") else "",
      if (is.finite(mu$est)) paste0("The estimated mean term was \\(\\mu\\) = ", fmt_num_local(mu$est), " (p ", fmt_p_local(mu$p), "). ") else "",
      if (is.finite(omega$est)) paste0("The variance intercept was \\(\\omega\\) = ", fmt_num_local(omega$est), " (p ", fmt_p_local(omega$p), "). ") else "",
      if (is.finite(alpha1$est)) paste0("The ARCH effect \\(\\alpha_1\\) = ", fmt_num_local(alpha1$est), " (p ", fmt_p_local(alpha1$p), "), ") else "",
      if (is.finite(beta1$est))  paste0("and the GARCH effect \\(\\beta_1\\) = ", fmt_num_local(beta1$est), " (p ", fmt_p_local(beta1$p), "). ") else "",
      if (is.finite(gamma1$est)) paste0("An asymmetric (leverage) component \\(\\gamma_1\\) = ", fmt_num_local(gamma1$est), " (p ", fmt_p_local(gamma1$p), ") was also estimated. ") else "",
      if (is.finite(shape$est))  paste0("Tail thickness (shape) was estimated as ", fmt_num_local(shape$est), " (p ", fmt_p_local(shape$p), "). ") else "",
      if (is.finite(skew$est))   paste0("Skewness (skew) was estimated as ", fmt_num_local(skew$est), " (p ", fmt_p_local(skew$p), "). ") else "",
      if (is.finite(persistence)) paste0("Volatility persistence (approx. \\(\\alpha_1 + \\beta_1\\)) was ", fmt_num_local(persistence), 
                                         if (is.finite(halflife)) paste0(", corresponding to an approximate half-life of ", fmt_num_local(halflife, 2), " periods. ") else ". ")
      else "",
      "</p>",
      
      "<p><b>Residual diagnostics.</b> ",
      if (!is.null(lb_z))  paste0("Ljung–Box tests suggested ", if (lb_z$p.value > 0.05) "no" else "remaining", " autocorrelation in standardized residuals (Q(", L, ") = ", fmt_num_local(lb_z$statistic), ", p ", fmt_p_local(lb_z$p.value), "). ") else "",
      if (!is.null(lb_z2)) paste0("For squared residuals, the Ljung–Box test ", if (lb_z2$p.value > 0.05) "did not indicate" else "indicated", " remaining ARCH structure (Q(", L, ") = ", fmt_num_local(lb_z2$statistic), ", p ", fmt_p_local(lb_z2$p.value), "). ") else "",
      if (!is.null(arch))  paste0("The ARCH LM test ", if (arch$p.value > 0.05) "did not provide evidence" else "provided evidence", " of additional conditional heteroskedasticity (LM = ", fmt_num_local(arch$statistic), ", p ", fmt_p_local(arch$p.value), "). ") else "",
      if (!is.null(jb))    paste0("Normality was assessed using Jarque–Bera (JB = ", fmt_num_local(jb$statistic), ", p ", fmt_p_local(jb$p.value), "), which commonly rejects under heavy tails—consistent with adopting non-Gaussian innovations when appropriate. ") else "",
      "</p>",
      
      "<p><b>Forecast performance.</b> ", acc_line, "</p>",
      
      if (!is.null(fc_tbl)) {
        paste0(
          "<p><b>Forecast excerpt (first 5 steps).</b></p>",
          "<div style='margin-left:6px;'>",
          paste0(
            "<table class='table table-condensed' style='width:100%;max-width:520px;'>",
            "<thead><tr><th>Step</th><th>Mean forecast</th><th>Sigma forecast</th></tr></thead><tbody>",
            paste(
              apply(fc_tbl, 1, function(r) {
                paste0(
                  "<tr><td>", r[[1]], "</td><td>", fmt_num_local(as.numeric(r[[2]])),
                  "</td><td>", fmt_num_local(as.numeric(r[[3]])), "</td></tr>"
                )
              }),
              collapse = ""
            ),
            "</tbody></table>"
          ),
          "</div>"
        )
      } else "",
      
      "<p><b>Overall conclusion.</b> Collectively, the estimated parameters and residual diagnostics ",
      "support the use of a conditional heteroskedasticity framework for capturing time-varying volatility in the series. ",
      "When diagnostics indicate limited remaining autocorrelation in \\(z_t\\) and \\(z_t^2\\), the fitted GARCH specification ",
      "may be considered adequate for inference and forecasting. Where residual tests suggest remaining dependence or heavy tails, ",
      "improvements may include refining the ARMA mean orders, increasing the GARCH order, or adopting heavier-tailed/skewed innovation distributions.</p>"
    )
    
    # trigger MathJax typesetting for this conclusion box
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "garch_conclusion_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  
  
  
  # =========================
  # 9 — Auto-GARCH (SERVER)
  # =========================
  
  output$autogarch_notes <- renderUI({
    if (isTRUE(input$show_teaching_notes)) {
      tags$div(
        class = "alert alert-info",
        tags$b("Auto-GARCH:"),
        " searches across GARCH variants, orders, and innovation distributions, and selects the best model using AIC/BIC.",
        tags$br(),
        "Tip: Start with (1,1) + {sGARCH, gjrGARCH} and {std, norm} to keep search fast."
      )
    }
  })
  
  output$autogarch_what_to_do <- renderUI({
    tags$div(
      tags$ol(
        tags$li("Upload data and set frequency/transform in the left sidebar."),
        tags$li("Choose series type (level vs log-returns)."),
        tags$li("Choose search space (mean ARMA grid, variance models, distributions)."),
        tags$li("Click “Run Auto-GARCH Search”."),
        tags$li("Inspect top candidates, diagnostics, residual tests, then forecast performance.")
      )
    )
  })
  
  # ---- Helper: build series for Auto-GARCH
  autogarch_series <- reactive({
    req(ts_train_test())
    s <- ts_train_test()
    y_full <- as.numeric(s$ts_full)
    
    if (input$autogarch_series_type == "logret") {
      # log-returns: diff(log(y))
      y_full <- diff(log(y_full))
      y_full <- y_full[is.finite(y_full)]
      if (isTRUE(input$autogarch_scale_100)) y_full <- 100 * y_full
    } else {
      y_full <- y_full[is.finite(y_full)]
    }
    
    # train/test sizes based on original split proportion
    # If train_prop == 1 => test size 0
    n_full <- length(y_full)
    train_prop <- suppressWarnings(as.numeric(input$train_prop))
    if (!is.finite(train_prop) || train_prop <= 0) train_prop <- 1
    n_train <- if (train_prop >= 0.999) n_full else max(10L, floor(train_prop * n_full))
    n_test  <- max(0L, n_full - n_train)
    
    list(
      y = y_full,
      train_n = n_train,
      test_n  = n_test
    )
  })
  
  # ---- Auto search (eventReactive on button)
  autogarch_search <- eventReactive(input$fit_autogarch, {
    validate(need(has_pkg("rugarch"), "Package 'rugarch' is required for Auto-GARCH. Please install it."))
    s <- autogarch_series()
    y <- s$y
    validate(need(length(y) >= 80, "Need at least ~80 observations for a stable Auto-GARCH search."))
    
    y_train <- y[seq_len(s$train_n)]
    
    # grids
    vmodels <- input$autogarch_vmodels
    dists   <- input$autogarch_dists
    validate(need(length(vmodels) > 0, "Select at least one GARCH variant."))
    validate(need(length(dists) > 0, "Select at least one distribution."))
    
    gorders <- switch(
      input$autogarch_orders,
      "11"    = list(c(1L, 1L)),
      "small" = list(c(1L, 1L), c(1L, 2L), c(2L, 1L)),
      "22"    = list(c(1L, 1L), c(1L, 2L), c(2L, 1L), c(2L, 2L)),
      list(c(1L, 1L))
    )
    
    if (isTRUE(input$autogarch_search_mean)) {
      pmax <- as.integer(input$autogarch_pmax); if (!is.finite(pmax) || pmax < 0) pmax <- 0L
      qmax <- as.integer(input$autogarch_qmax); if (!is.finite(qmax) || qmax < 0) qmax <- 0L
      arma_grid <- expand.grid(ar = 0:pmax, ma = 0:qmax)
    } else {
      arma_grid <- data.frame(ar = 0L, ma = 0L)
    }
    
    include_mean <- isTRUE(input$autogarch_include_mean)
    
    # safe fit one
    fit_one <- function(vmodel, dist, go, ar, ma) {
      spec <- rugarch::ugarchspec(
        variance.model = list(model = vmodel, garchOrder = c(go[1], go[2])),
        mean.model = list(armaOrder = c(ar, ma), include.mean = include_mean),
        distribution.model = dist
      )
      fit <- tryCatch(
        rugarch::ugarchfit(spec = spec, data = y_train, solver = "hybrid"),
        error = function(e) NULL
      )
      if (is.null(fit)) return(NULL)
      ic <- tryCatch(rugarch::infocriteria(fit), error = function(e) NULL)
      if (is.null(ic)) return(NULL)
      
      data.frame(
        vmodel = vmodel, dist = dist,
        garch_p = go[1], garch_q = go[2],
        ar = ar, ma = ma,
        AIC = as.numeric(ic["Akaike"]),
        BIC = as.numeric(ic["Bayes"]),
        stringsAsFactors = FALSE,
        fit = I(list(fit))
      )
    }
    
    # run search with progress
    total <- length(vmodels) * length(dists) * length(gorders) * nrow(arma_grid)
    res_list <- vector("list", total)
    k <- 1L
    
    withProgress(message = "Auto-GARCH search", value = 0, {
      for (vm in vmodels) {
        for (di in dists) {
          for (go in gorders) {
            for (i in seq_len(nrow(arma_grid))) {
              incProgress(1 / total, detail = paste(vm, di, paste0("(", go[1], ",", go[2], ")"), "ARMA", arma_grid$ar[i], arma_grid$ma[i]))
              out <- fit_one(vm, di, go, arma_grid$ar[i], arma_grid$ma[i])
              if (!is.null(out)) {
                res_list[[k]] <- out
                k <- k + 1L
              }
            }
          }
        }
      }
    })
    
    res_list <- res_list[seq_len(k - 1L)]
    validate(need(length(res_list) > 0, "All candidate models failed. Try smaller ARMA grid, fewer distributions, or only sGARCH(1,1)."))
    
    res <- do.call(rbind, res_list)
    
    # rank by selection criterion
    ic_col <- input$autogarch_select_ic
    res <- res[order(res[[ic_col]]), , drop = FALSE]
    res
  })
  
  # ---- best fit + series bundle
  autogarch_best <- reactive({
    req(autogarch_search())
    res <- autogarch_search()
    list(
      fit = res$fit[[1]],
      meta = res[1, c("vmodel","dist","garch_p","garch_q","ar","ma","AIC","BIC"), drop = FALSE],
      series = autogarch_series()
    )
  })
  
  # ---- search results table
  output$autogarch_rank_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Click “Run Auto-GARCH Search” to see results."))
    req(autogarch_search())
    topk <- as.integer(input$autogarch_topk)
    if (!is.finite(topk) || topk < 5) topk <- 10L
    
    res <- autogarch_search()
    out <- head(res, topk)
    out$fit <- NULL
    out
  }, rownames = FALSE)
  
  output$autogarch_best_spec <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Click “Run Auto-GARCH Search” first."))
    req(autogarch_best())
    b <- autogarch_best()
    cat("Best Auto-GARCH model selected.\n\n")
    print(b$meta)
    cat("\nInfo criteria (rugarch::infocriteria):\n")
    print(round(rugarch::infocriteria(b$fit), 4))
  })
  
  # ---- model spec + coefficient table
  output$autogarch_model_spec <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Click “Run Auto-GARCH Search” first."))
    req(autogarch_best())
    b <- autogarch_best()
    
    cat("Auto-GARCH best specification:\n")
    print(b$meta)
    cat("\n\nRUGARCH fit summary:\n")
    show(b$fit)
  })
  
  output$autogarch_coef_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Click “Run Auto-GARCH Search” first."))
    req(autogarch_best())
    fit <- autogarch_best()$fit
    mat <- tryCatch(fit@fit$matcoef, error = function(e) NULL)
    validate(need(!is.null(mat), "Coefficient table unavailable."))
    
    data.frame(
      Term = rownames(mat),
      Estimate = as.numeric(mat[, 1]),
      `Std. Error` = as.numeric(mat[, 2]),
      `t value` = as.numeric(mat[, 3]),
      `Pr(>|t|)` = as.numeric(mat[, 4]),
      row.names = NULL,
      check.names = FALSE
    )
  }, digits = 5)
  
  # ---- equation (same style as your GARCH equation)
  output$autogarch_model_equation <- renderUI({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search to generate the equation."))
    req(autogarch_best())
    b <- autogarch_best()
    m <- b$meta[1, ]
    
    p  <- as.integer(m$ar); if (!is.finite(p)) p <- 0L
    q  <- as.integer(m$ma); if (!is.finite(q)) q <- 0L
    vp <- as.integer(m$garch_p); if (!is.finite(vp)) vp <- 1L
    vq <- as.integer(m$garch_q); if (!is.finite(vq)) vq <- 1L
    vmodel <- as.character(m$vmodel)
    
    mean_eq <- if (p == 0 && q == 0) {
      if (isTRUE(input$autogarch_include_mean)) "y_t = \\mu + \\varepsilon_t" else "y_t = \\varepsilon_t"
    } else {
      paste0("y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + \\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t")
    }
    
    var_eq <- switch(
      vmodel,
      "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2\\,\\mathbb{I}(\\varepsilon_{t-i}<0)) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i |z_{t-i}| + \\gamma_i z_{t-i}) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
      paste0("\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2")
    )
    
    html <- paste0(
      "<p><b>Mean equation:</b></p><div>$$", mean_eq, "$$</div>",
      "<p><b>Variance equation:</b></p><div>$$", var_eq, "$$</div>",
      "<p>Where $$\\varepsilon_t = \\sigma_t z_t$$.</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "autogarch_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- residuals + sigma
  autogarch_resids <- reactive({
    req(autogarch_best())
    fit <- autogarch_best()$fit
    z <- tryCatch(as.numeric(rugarch::residuals(fit, standardize = TRUE)), error = function(e) NULL)
    validate(need(!is.null(z), "Cannot compute standardized residuals."))
    z
  })
  
  autogarch_sigma <- reactive({
    req(autogarch_best())
    fit <- autogarch_best()$fit
    sig <- tryCatch(as.numeric(rugarch::sigma(fit)), error = function(e) NULL)
    validate(need(!is.null(sig), "Cannot compute sigma."))
    sig
  })
  
  # ---- diagnostics plots
  output$autogarch_resid_ts <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    plot(z, type = "l", main = "Standardized residuals", ylab = "z_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$autogarch_resid_acf <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    stats::acf(z, main = "ACF of standardized residuals")
  })
  
  output$autogarch_resid_hist <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    hist(z, breaks = 30, main = "Histogram of z_t", xlab = "z_t")
  })
  
  output$autogarch_resid_qq <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    qqnorm(z, main = "Q–Q plot of z_t"); qqline(z, col = "red")
  })
  
  output$autogarch_sigma_plot <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    sig <- autogarch_sigma()
    plot(sig, type = "l", main = "Conditional volatility (sigma)", ylab = "sigma_t", xlab = "t")
  })
  
  # ---- residual tests text
  output$autogarch_diag_tests <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    
    L <- as.integer(input$diag_lag)
    if (!is.finite(L) || L < 1) L <- 12L
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    cat("Residual tests (standardized residuals z_t)\n")
    cat("=======================================\n\n")
    
    lb1 <- Box.test(z,  lag = L, type = "Ljung-Box")
    lb2 <- Box.test(z^2, lag = L, type = "Ljung-Box")
    
    cat("Ljung–Box on z_t:\n"); print(lb1); cat("\n")
    cat("Ljung–Box on z_t^2:\n"); print(lb2); cat("\n")
    
    if (has_pkg("FinTS")) {
      cat("ARCH LM test (FinTS::ArchTest):\n")
      print(FinTS::ArchTest(z, lags = L)); cat("\n")
    } else {
      cat("ARCH LM test: FinTS not installed.\n\n")
    }
    
    if (has_pkg("tseries")) {
      cat("Jarque–Bera normality test (tseries):\n")
      print(tseries::jarque.bera.test(z)); cat("\n")
    } else {
      cat("Jarque–Bera: tseries not installed.\n\n")
    }
  })
  
  # ---- forecast + accuracy
  autogarch_forecast <- reactive({
    req(autogarch_best())
    b <- autogarch_best()
    fit <- b$fit
    s <- b$series
    
    n_test <- as.integer(s$test_n); if (!is.finite(n_test)) n_test <- 0L
    n_train <- as.integer(s$train_n)
    
    if (n_test > 0) {
      h <- n_test
    } else {
      h_in <- suppressWarnings(as.integer(input$autogarch_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
    }
    
    fc <- rugarch::ugarchforecast(fit, n.ahead = h)
    
    mu <- tryCatch(as.numeric(rugarch::fitted(fc)), error = function(e) rep(NA_real_, h))
    sig <- tryCatch(as.numeric(rugarch::sigma(fc)), error = function(e) rep(NA_real_, h))
    
    list(h = h, fc = fc, mu = mu, sigma = sig)
  })
  
  output$autogarch_horizon_note <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    s <- autogarch_series()
    if (s$test_n > 0) {
      cat("Holdout test set detected. Forecast horizon h was set to the test length (h =", s$test_n, ").\n")
    } else {
      h <- autogarch_forecast()$h
      cat("No test set detected. Forecast horizon h was set to", h, "using the Auto-GARCH horizon input.\n")
    }
  })
  
  output$autogarch_accuracy_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    b <- autogarch_best()
    s <- b$series
    if (s$test_n <= 0) return(NULL)
    
    y <- b$series$y
    y_test <- y[(s$train_n + 1):(s$train_n + s$test_n)]
    
    mu <- autogarch_forecast()$mu[seq_along(y_test)]
    validate(need(length(mu) == length(y_test), "Forecast length mismatch."))
    
    accuracy_df(y_test, mu)
  }, rownames = FALSE)
  
  output$autogarch_forecast_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    f <- autogarch_forecast()
    h <- f$h
    out <- data.frame(
      step = 1:h,
      mean_forecast = f$mu,
      sigma_forecast = if (isTRUE(input$autogarch_forecast_sigma)) f$sigma else NA_real_
    )
    out
  }, digits = 6)
  
  output$autogarch_forecast_plot <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    b <- autogarch_best()
    s <- b$series
    y <- b$series$y
    
    f <- autogarch_forecast()
    h <- f$h
    
    # plot last window + forecast
    n <- length(y)
    window <- min(200, n)
    y_tail <- y[(n - window + 1):n]
    
    plot(y_tail, type = "l", main = "Auto-GARCH: mean forecast", ylab = "Series", xlab = "t (tail)")
    lines((window + 1):(window + h), f$mu, col = "blue", lwd = 2)
    
    if (isTRUE(input$autogarch_forecast_sigma)) {
      # simple +/- 2*sigma band for visualization
      up <- f$mu + 2 * f$sigma
      lo <- f$mu - 2 * f$sigma
      lines((window + 1):(window + h), up, col = "gray40", lty = 2)
      lines((window + 1):(window + h), lo, col = "gray40", lty = 2)
      legend("topleft", legend = c("history", "mean forecast", "±2 sigma"), col = c("black","blue","gray40"),
             lty = c(1,1,2), bty = "n")
    } else {
      legend("topleft", legend = c("history", "mean forecast"), col = c("black","blue"),
             lty = c(1,1), bty = "n")
    }
  })
  
  # ---- APA paragraph (Auto-GARCH)
  output$autogarch_apa_paragraph <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    req(autogarch_best())
    b <- autogarch_best()
    m <- b$meta[1, ]
    
    ic <- rugarch::infocriteria(b$fit)
    aic <- as.numeric(ic["Akaike"])
    bic <- as.numeric(ic["Bayes"])
    
    z <- autogarch_resids()
    L <- as.integer(input$diag_lag); if (!is.finite(L) || L < 1) L <- 12L
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lbz  <- Box.test(z, lag = L, type = "Ljung-Box")
    lbz2 <- Box.test(z^2, lag = L, type = "Ljung-Box")
    
    cat(
      "An Auto-GARCH search selected a ", m$vmodel, " model with GARCH order (",
      m$garch_p, ", ", m$garch_q, "), ARMA(", m$ar, ", ", m$ma, ") mean, and ",
      m$dist, " innovations. Model fit was summarized by AIC = ", fmt_num(aic, 3),
      " and BIC = ", fmt_num(bic, 3), ". Residual diagnostics indicated Ljung–Box ",
      "tests on standardized residuals z_t (Q(", L, ") = ", fmt_num(lbz$statistic, 3),
      ", p ", fmt_p(lbz$p.value), ") and on squared residuals z_t^2 (Q(", L, ") = ",
      fmt_num(lbz2$statistic, 3), ", p ", fmt_p(lbz2$p.value), ").",
      sep = ""
    )
  })
  
  # ---- Conclusion (academic) (Auto-GARCH)
  output$autogarch_conclusion <- renderUI({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    req(autogarch_best())
    
    b <- autogarch_best()
    m <- b$meta[1, ]
    s <- b$series
    n_train <- s$train_n
    n_test  <- s$test_n
    
    # equation rendered elsewhere; conclusion references it + tests + accuracy
    z <- autogarch_resids()
    L <- as.integer(input$diag_lag); if (!is.finite(L) || L < 1) L <- 12L
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lbz  <- Box.test(z, lag = L, type = "Ljung-Box")
    lbz2 <- Box.test(z^2, lag = L, type = "Ljung-Box")
    
    ic <- rugarch::infocriteria(b$fit)
    aic <- as.numeric(ic["Akaike"])
    bic <- as.numeric(ic["Bayes"])
    
    # accuracy summary (if test exists)
    acc_txt <- "No holdout test set was detected; therefore, out-of-sample accuracy was not computed."
    if (n_test > 0) {
      acc <- tryCatch(output$autogarch_accuracy_table(), error = function(e) NULL)
      # better: recompute quickly
      y <- b$series$y
      y_test <- y[(n_train + 1):(n_train + n_test)]
      mu <- autogarch_forecast()$mu[seq_along(y_test)]
      e <- y_test - mu
      rmse <- sqrt(mean(e^2, na.rm = TRUE))
      mae  <- mean(abs(e), na.rm = TRUE)
      acc_txt <- paste0("Forecast accuracy on the test set (n = ", n_test, ") was RMSE = ", fmt_num(rmse, 3),
                        " and MAE = ", fmt_num(mae, 3), ".")
    }
    
    html <- paste0(
      "<h4 style='margin-top:0;'>Auto-GARCH conclusion (academic)</h4>",
      "<p><b>Selected specification.</b> The Auto-GARCH search selected <b>", m$vmodel,
      "</b>(", m$garch_p, ",", m$garch_q, ") with ARMA(", m$ar, ",", m$ma,
      ") mean and <b>", m$dist, "</b> innovations. Fit indices were AIC = ",
      fmt_num(aic, 3), " and BIC = ", fmt_num(bic, 3), ".</p>",
      "<p><b>Model adequacy.</b> Ljung–Box tests suggested ",
      "Q(", L, ") = ", fmt_num(lbz$statistic, 3), " (p ", fmt_p(lbz$p.value),
      ") for z<sub>t</sub> and Q(", L, ") = ", fmt_num(lbz2$statistic, 3),
      " (p ", fmt_p(lbz2$p.value), ") for z<sub>t</sub><sup>2</sup>. ",
      "When these are non-significant, the fitted variance dynamics are typically considered adequate.</p>",
      "<p><b>Forecasting.</b> ", acc_txt, "</p>",
      "<p><b>Overall.</b> The automated selection provides a defensible volatility model candidate. ",
      "If residual tests indicate remaining dependence, refine the mean ARMA orders, broaden the order search, or consider alternative innovation distributions.</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "autogarch_conclusion_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  
  
  # =============================
  # Auto-SARIMAX (auto.arima + xreg)
  # =============================
  
  output$step5b_notes <- renderUI({
    tags$div(
      tags$ol(
        tags$li("Select one or more exogenous regressors (X)."),
        tags$li("Click “Fit Auto-SARIMAX”."),
        tags$li("Inspect model specification and coefficients."),
        tags$li("Check residual diagnostics and formal tests."),
        tags$li("Review forecasts and (if available) test-set accuracy."),
        tags$li(tags$b("Note:"), " If train_prop = 1 (no test set), future X values are assumed 0 unless you add a future-X input.")
      )
    )
  })
  
  # ---- X selector UI (uses prepared()$df and excludes date/value columns if available)
  output$autox_xreg_ui <- renderUI({
    req(prepared())
    df <- prepared()$df
    
    date_col  <- prepared()$date_col %||% character(0)
    value_col <- prepared()$value_col %||% character(0)
    
    candidates <- setdiff(names(df), c(date_col, value_col))
    candidates <- candidates[nzchar(candidates)]
    
    selectizeInput(
      "autox_x_cols",
      "Select X variables",
      choices = candidates,
      multiple = TRUE,
      options = list(placeholder = "Choose one or more regressors…")
    )
  })
  
  # ---- Fit model (cached on Fit button)
  autox_fit <- eventReactive(input$fit_autox, {
    req(ts_train_test(), prepared())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required for Auto-SARIMAX."))
    
    s <- ts_train_test()
    y_train <- as.numeric(s$ts_train)
    y_test  <- as.numeric(s$ts_test)
    
    train_n <- length(y_train)
    test_n  <- length(y_test)
    
    df <- prepared()$df
    xcols <- input$autox_x_cols %||% character(0)
    
    xs <- build_xreg_split(
      df = df,
      cols = xcols,
      train_n = train_n,
      test_n  = test_n,
      scale_x = isTRUE(input$autox_scale_x)
    )
    
    fit <- forecast::auto.arima(
      y_train,
      xreg = xs$x_train,
      seasonal = isTRUE(input$autox_seasonal),
      stepwise = isTRUE(input$autox_stepwise),
      approximation = isTRUE(input$autox_approx),
      allowmean = isTRUE(input$autox_allow_mean),
      allowdrift = isTRUE(input$autox_allow_mean),
      max.order = as.integer(input$autox_max_order)
    )
    
    list(
      fit = fit,
      xcols = xcols,
      x_train = xs$x_train,
      x_test  = xs$x_test,
      y_train = y_train,
      y_test  = y_test
    )
  })
  
  # ---- Spec
  output$autox_model_spec <- renderPrint({
    validate(need(input$fit_autox > 0, "Click “Fit Auto-SARIMAX” first."))
    req(autox_fit())
    print(autox_fit()$fit)
  })
  
  # ---- Coefs
  output$autox_coef_table <- renderTable({
    req(autox_fit())
    sm <- summary(autox_fit()$fit)
    co <- as.data.frame(sm$coef)
    co$Term <- rownames(co)
    rownames(co) <- NULL
    co <- co[, c("Term", setdiff(names(co), "Term")), drop = FALSE]
    co
  }, digits = 6)
  
  # ---- Equation (MathJax, rendered like GARCH style)
  output$autox_model_equation <- renderUI({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX to show the equation."))
    req(autox_fit())
    obj <- autox_fit()
    
    xcols <- obj$xcols
    x_part <- if (length(xcols) == 0) {
      "0"
    } else {
      paste0("\\sum_{k=1}^{", length(xcols), "} \\beta_k x_{k,t}")
    }
    
    mean_eq <- paste0("y_t = c + ", x_part, " + \\varepsilon_t")
    
    html <- paste0(
      "<p><b>Mean (regression) equation:</b></p><div>$$", mean_eq, "$$</div>",
      "<p><b>Selected ARIMA structure (auto.arima):</b> ", as.character(obj$fit), "</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "autox_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- Residuals
  autox_resid <- reactive({
    req(autox_fit())
    as.numeric(residuals(autox_fit()$fit))
  })
  
  # ---- Diagnostics plots
  output$autox_resid_ts <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    plot(r, type = "l", main = "Residuals", ylab = "e_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$autox_resid_acf <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    stats::acf(autox_resid(), main = "ACF of residuals")
  })
  
  output$autox_resid_hist <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    hist(autox_resid(), breaks = 30, main = "Residual histogram", xlab = "e_t")
  })
  
  output$autox_resid_qq <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    qqnorm(r, main = "Q–Q plot")
    qqline(r, col = "red")
  })
  
  output$autox_resid_lb_pvals <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    maxL <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(maxL) || maxL < 5) maxL <- 12L
    lags <- 1:maxL
    pvals <- sapply(lags, function(L) {
      out <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
      if (is.null(out)) NA_real_ else out$p.value
    })
    plot(lags, pvals, type = "b", pch = 16, ylim = c(0, 1),
         main = "Ljung–Box p-values by lag", xlab = "Lag", ylab = "p-value")
    abline(h = 0.05, col = "red", lty = 2)
  })
  
  # ---- Residual tests
  output$autox_diag_tests <- renderPrint({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    cat("Residual tests (Auto-SARIMAX)\n========================\n\n")
    cat("Ljung–Box:\n")
    print(Box.test(r, lag = L, type = "Ljung-Box"))
    cat("\n")
    
    if (requireNamespace("tseries", quietly = TRUE)) {
      cat("Jarque–Bera normality test:\n")
      print(tseries::jarque.bera.test(r))
      cat("\n")
    } else {
      cat("Jarque–Bera: package 'tseries' not installed.\n\n")
    }
  })
  
  # ---- Forecast
  autox_forecast <- reactive({
    req(autox_fit())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    obj <- autox_fit()
    test_n <- length(obj$y_test)
    
    if (test_n > 0) {
      h <- test_n
      xfuture <- obj$x_test
    } else {
      h_in <- suppressWarnings(as.integer(input$autox_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
      
      # No future X UI -> default zeros matrix with same columns as training X
      xfuture <- if (is.null(obj$x_train)) NULL else
        matrix(0, nrow = h, ncol = ncol(obj$x_train), dimnames = list(NULL, colnames(obj$x_train)))
    }
    
    fc <- forecast::forecast(obj$fit, h = h, xreg = xfuture)
    list(fc = fc, h = h)
  })
  
  output$autox_horizon_note <- renderPrint({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    obj <- autox_fit()
    if (length(obj$y_test) > 0) {
      cat("Holdout test detected. Forecast horizon set to test length (h =", length(obj$y_test), ").\n")
    } else {
      cat("No test detected. Forecast horizon uses autox_h (or default). Future X is assumed 0 unless you add a future-X input.\n")
    }
  })
  
  output$autox_forecast_plot <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    plot(autox_forecast()$fc, main = "Auto-SARIMAX forecast")
  })
  
  output$autox_forecast_table <- renderTable({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    fc <- autox_forecast()$fc
    data.frame(
      step = seq_along(fc$mean),
      mean = as.numeric(fc$mean),
      lo80 = as.numeric(fc$lower[, 1]),
      hi80 = as.numeric(fc$upper[, 1]),
      lo95 = as.numeric(fc$lower[, 2]),
      hi95 = as.numeric(fc$upper[, 2])
    )
  }, digits = 6)
  
  output$autox_accuracy_table <- renderTable({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    obj <- autox_fit()
    if (length(obj$y_test) == 0) return(NULL)
    
    y_test <- obj$y_test
    y_hat  <- as.numeric(autox_forecast()$fc$mean)
    
    if (exists("accuracy_df", mode = "function")) {
      accuracy_df(y_test, y_hat)
    } else {
      e <- y_test - y_hat
      data.frame(
        Metric = c("RMSE", "MAE"),
        Value  = c(sqrt(mean(e^2, na.rm = TRUE)), mean(abs(e), na.rm = TRUE))
      )
    }
  }, rownames = FALSE)
  
  output$apa_autox_paragraph <- renderPrint({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    obj <- autox_fit()
    cat(
      "An Auto-SARIMAX model was estimated using forecast::auto.arima with exogenous regressors (xreg). ",
      "The selected specification was ", as.character(obj$fit),
      ". Residual diagnostics (plots and Ljung–Box testing) were used to assess adequacy, and forecasts were generated conditional on the available xreg information.",
      sep = ""
    )
  })
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  # =============================
  # Manual SARIMAX (Arima + xreg)
  # =============================
  
  `%||%` <- function(a, b) if (!is.null(a)) a else b  # only if you don't already have it
  
  output$step6b_notes <- renderUI({
    tags$div(
      tags$ol(
        tags$li("Select one or more exogenous regressors (X)."),
        tags$li("Choose the SARIMA orders (p,d,q)(P,D,Q)[s]."),
        tags$li("Click Fit to estimate SARIMAX."),
        tags$li("Check diagnostics and residual tests."),
        tags$li("Evaluate forecasts and (if available) test-set accuracy."),
        tags$li(tags$b("Note:"), " If train_prop = 1 (no test set), future X values are assumed 0 unless you add a future-X input.")
      )
    )
  })
  
  # ---- X selector UI
  output$sarimax_xreg_ui <- renderUI({
    req(prepared())
    df <- prepared()$df
    
    date_col  <- prepared()$date_col %||% character(0)
    value_col <- prepared()$value_col %||% character(0)
    
    candidates <- setdiff(names(df), c(date_col, value_col))
    candidates <- candidates[nzchar(candidates)]
    
    selectizeInput(
      "sarimax_x_cols",
      "Select X variables",
      choices = candidates,
      multiple = TRUE,
      options = list(placeholder = "Choose one or more regressors…")
    )
  })
  
  # ---- Split text/plot (simple; adjust if you already have a nicer split plot helper)
  output$sarimax_split_text <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    cat("Training length:", length(s$ts_train), "\n")
    cat("Test length:", length(s$ts_test), "\n")
  })
  
  output$sarimax_split_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    y <- as.numeric(s$ts_full)
    n_train <- length(s$ts_train)
    
    plot(y, type = "l", main = "Train/Test split", xlab = "t", ylab = "y")
    abline(v = n_train, col = "red", lty = 2)
    legend("topleft", legend = c("Series", "Train/Test boundary"), col = c("black", "red"), lty = c(1,2), bty = "n")
  })
  
  # ---- Fit SARIMAX (cached)
  sarimax_fit <- eventReactive(input$fit_sarimax, {
    req(ts_train_test(), prepared())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required for SARIMAX."))
    
    s <- ts_train_test()
    y_train <- as.numeric(s$ts_train)
    y_test  <- as.numeric(s$ts_test)
    
    train_n <- length(y_train)
    test_n  <- length(y_test)
    
    df <- prepared()$df
    xcols <- input$sarimax_x_cols %||% character(0)
    
    xs <- build_xreg_split(
      df = df,
      cols = xcols,
      train_n = train_n,
      test_n  = test_n,
      scale_x = isTRUE(input$sarimax_scale_x)
    )
    
    # seasonal period: sx_s overrides sidebar frequency
    s_in <- suppressWarnings(as.integer(input$sx_s))
    if (!is.finite(s_in)) s_in <- suppressWarnings(as.integer(prepared()$freq))
    if (!is.finite(s_in) || s_in < 1) s_in <- 1L
    
    p <- as.integer(input$sx_p); if (!is.finite(p) || p < 0) p <- 0L
    d <- as.integer(input$sx_d); if (!is.finite(d) || d < 0) d <- 0L
    q <- as.integer(input$sx_q); if (!is.finite(q) || q < 0) q <- 0L
    
    P <- as.integer(input$sx_P); if (!is.finite(P) || P < 0) P <- 0L
    D <- as.integer(input$sx_D); if (!is.finite(D) || D < 0) D <- 0L
    Q <- as.integer(input$sx_Q); if (!is.finite(Q) || Q < 0) Q <- 0L
    
    drift <- isTRUE(input$sarimax_drift)
    
    fit <- forecast::Arima(
      y_train,
      order = c(p, d, q),
      seasonal = list(order = c(P, D, Q), period = s_in),
      xreg = xs$x_train,
      include.mean = drift,
      include.drift = drift,
      method = "ML"
    )
    
    list(
      fit = fit,
      xcols = xcols,
      x_train = xs$x_train,
      x_test  = xs$x_test,
      y_train = y_train,
      y_test  = y_test,
      period  = s_in,
      orders  = list(p=p,d=d,q=q,P=P,D=D,Q=Q)
    )
  })
  
  # ---- Model spec
  output$sarimax_model_spec <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Click Fit SARIMAX first."))
    req(sarimax_fit())
    print(sarimax_fit()$fit)
  })
  
  # ---- Coef table
  output$sarimax_coef_table <- renderTable({
    req(sarimax_fit())
    sm <- summary(sarimax_fit()$fit)
    co <- as.data.frame(sm$coef)
    co$Term <- rownames(co)
    rownames(co) <- NULL
    co <- co[, c("Term", setdiff(names(co), "Term")), drop = FALSE]
    co
  }, digits = 6)
  
  # ---- Equation (MathJax)
  output$sarimax_model_equation <- renderUI({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX to show the equation."))
    req(sarimax_fit())
    obj <- sarimax_fit()
    
    k <- length(obj$xcols)
    
    x_part <- if (k == 0) {
      "0"
    } else {
      paste0("\\sum_{k=1}^{", k, "} \\beta_k x_{k,t}")
    }
    
    mean_eq <- paste0("y_t = c + ", x_part, " + \\varepsilon_t")
    
    # Operator form for SARIMAX (generic)
    op_eq <- paste0(
      "\\Phi(B^s)\\phi(B)(1-B)^d(1-B^s)^D y_t = c + ",
      x_part,
      " + \\Theta(B^s)\\theta(B)\\varepsilon_t"
    )
    
    html <- paste0(
      "<p><b>Regression mean equation:</b></p><div>$$", mean_eq, "$$</div>",
      "<p><b>SARIMAX operator form:</b></p><div>$$", op_eq, "$$</div>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "sarimax_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- Residuals
  sarimax_resid <- reactive({
    req(sarimax_fit())
    as.numeric(residuals(sarimax_fit()$fit))
  })
  
  # ---- Diagnostics plots
  output$sarimax_resid_ts <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    plot(r, type = "l", main = "Residuals", ylab = "e_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$sarimax_resid_acf <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    stats::acf(sarimax_resid(), main = "ACF of residuals")
  })
  
  output$sarimax_resid_hist <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    hist(sarimax_resid(), breaks = 30, main = "Residual histogram", xlab = "e_t")
  })
  
  output$sarimax_resid_qq <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    qqnorm(r, main = "Q–Q plot"); qqline(r, col = "red")
  })
  
  output$sarimax_resid_lb_pvals <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    maxL <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(maxL) || maxL < 5) maxL <- 12L
    lags <- 1:maxL
    pvals <- sapply(lags, function(L) {
      out <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
      if (is.null(out)) NA_real_ else out$p.value
    })
    plot(lags, pvals, type = "b", pch = 16, ylim = c(0, 1),
         main = "Ljung–Box p-values by lag", xlab = "Lag", ylab = "p-value")
    abline(h = 0.05, col = "red", lty = 2)
  })
  
  # ---- Residual tests
  output$sarimax_diag_tests <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    cat("Residual tests (Manual SARIMAX)\n==========================\n\n")
    
    cat("Ljung–Box:\n")
    print(Box.test(r, lag = L, type = "Ljung-Box"))
    cat("\n")
    
    if (requireNamespace("tseries", quietly = TRUE)) {
      cat("Jarque–Bera normality test:\n")
      print(tseries::jarque.bera.test(r))
      cat("\n")
    } else {
      cat("Jarque–Bera: package 'tseries' not installed.\n\n")
    }
  })
  
  # ---- Forecast
  sarimax_forecast <- reactive({
    req(sarimax_fit())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    obj <- sarimax_fit()
    test_n <- length(obj$y_test)
    
    if (test_n > 0) {
      h <- test_n
      xfuture <- obj$x_test
    } else {
      h_in <- suppressWarnings(as.integer(input$sarimax_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
      
      # No future X UI -> default zeros
      xfuture <- if (is.null(obj$x_train)) NULL else
        matrix(0, nrow = h, ncol = ncol(obj$x_train), dimnames = list(NULL, colnames(obj$x_train)))
    }
    
    fc <- forecast::forecast(obj$fit, h = h, xreg = xfuture)
    list(fc = fc, h = h)
  })
  
  output$sarimax_horizon_note <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    obj <- sarimax_fit()
    if (length(obj$y_test) > 0) {
      cat("Holdout test detected. Forecast horizon set to test length (h =", length(obj$y_test), ").\n")
    } else {
      cat("No test detected. Forecast horizon uses sarimax_h (or default). Future X is assumed 0 unless you add a future-X input.\n")
    }
  })
  
  output$sarimax_forecast_plot <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    plot(sarimax_forecast()$fc, main = "SARIMAX forecast")
  })
  
  output$sarimax_forecast_table <- renderTable({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    fc <- sarimax_forecast()$fc
    data.frame(
      step = seq_along(fc$mean),
      mean = as.numeric(fc$mean),
      lo80 = as.numeric(fc$lower[, 1]),
      hi80 = as.numeric(fc$upper[, 1]),
      lo95 = as.numeric(fc$lower[, 2]),
      hi95 = as.numeric(fc$upper[, 2])
    )
  }, digits = 6)
  
  output$sarimax_accuracy_table <- renderTable({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    obj <- sarimax_fit()
    if (length(obj$y_test) == 0) return(NULL)
    
    y_test <- obj$y_test
    y_hat  <- as.numeric(sarimax_forecast()$fc$mean)
    
    if (exists("accuracy_df", mode = "function")) {
      accuracy_df(y_test, y_hat)
    } else {
      e <- y_test - y_hat
      data.frame(
        Metric = c("RMSE", "MAE"),
        Value  = c(sqrt(mean(e^2, na.rm = TRUE)), mean(abs(e), na.rm = TRUE))
      )
    }
  }, rownames = FALSE)
  
  # ---- APA paragraph
  output$apa_sarimax_paragraph <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    obj <- sarimax_fit()
    fit <- obj$fit
    
    cat(
      "A SARIMAX model (seasonal ARIMA with exogenous regressors) was estimated using forecast::Arima with xreg predictors. ",
      "The specified model was ", as.character(fit),
      if (isTRUE(input$sarimax_drift)) " including a drift/mean term." else " without a drift/mean term.",
      " Model adequacy was assessed using residual plots and Ljung–Box testing, and forecasts were generated conditional on the available exogenous information.",
      sep = ""
    )
  })
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  # ============================
  # ChatGPT-SARIMA (Manual) TAB
  # ============================
  
  # ---- small helpers (safe if you already have them)
  `%||%` <- function(a, b) if (!is.null(a)) a else b
  
  cg_fmt_num <- function(x, d = 3) {
    if (length(x) == 0 || !is.finite(x)) return(NA_character_)
    formatC(x, format = "f", digits = d)
  }
  cg_fmt_p <- function(p) {
    if (!is.finite(p)) return("= NA")
    if (p < 0.001) "< .001" else paste0("= ", cg_fmt_num(p, 3))
  }
  cg_sig_stars <- function(p) {
    if (!is.finite(p)) return("")
    if (p < 0.001) "***" else if (p < 0.01) "**" else if (p < 0.05) "*" else if (p < 0.1) "†" else ""
  }
  
  output$cg_notes <- renderUI({
    if (!isTRUE(input$cg_show_teaching)) return(NULL)
    tags$div(
      class = "alert alert-info",
      tags$b("ChatGPT-SARIMA workflow:"),
      tags$ol(
        tags$li("Confirm stationarity/differencing decisions (d, D) on the Stationarity tab."),
        tags$li("Use ACF/PACF patterns to propose p/q and P/Q (seasonal at lag s)."),
        tags$li("Fit the model; then check residuals: they should resemble white noise."),
        tags$li("If residual autocorrelation remains, adjust orders; if volatility clustering exists, consider GARCH.")
      )
    )
  })
  
  # ---- Split summary + plot
  output$cg_split_text <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    cat("Training length:", length(s$ts_train), "\n")
    cat("Test length:", length(s$ts_test), "\n")
  })
  
  output$cg_split_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    y <- as.numeric(s$ts_full)
    n_train <- length(s$ts_train)
    
    plot(y, type = "l", main = "Train/Test split", xlab = "t", ylab = "y")
    abline(v = n_train, col = "red", lty = 2)
    legend("topleft", legend = c("Series", "Train/Test boundary"),
           col = c("black", "red"), lty = c(1, 2), bty = "n")
  })
  
  # ---- Fit SARIMA (cached on button)
  cg_fit <- eventReactive(input$fit_cg_sarima, {
    req(ts_train_test())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    s <- ts_train_test()
    y_train <- as.numeric(s$ts_train)
    y_test  <- as.numeric(s$ts_test)
    
    p <- as.integer(input$cg_p); if (!is.finite(p) || p < 0) p <- 0L
    d <- as.integer(input$cg_d); if (!is.finite(d) || d < 0) d <- 0L
    q <- as.integer(input$cg_q); if (!is.finite(q) || q < 0) q <- 0L
    
    P <- as.integer(input$cg_P); if (!is.finite(P) || P < 0) P <- 0L
    D <- as.integer(input$cg_D); if (!is.finite(D) || D < 0) D <- 0L
    Q <- as.integer(input$cg_Q); if (!is.finite(Q) || Q < 0) Q <- 0L
    
    s_in <- suppressWarnings(as.integer(input$cg_s))
    if (!is.finite(s_in)) {
      # try prepared()$freq if available, else default 1
      s_in <- tryCatch(as.integer(prepared()$freq), error = function(e) NA_integer_)
    }
    if (!is.finite(s_in) || s_in < 1) s_in <- 1L
    
    include_mean <- isTRUE(input$cg_include_mean)
    method <- as.character(input$cg_method) %||% "ML"
    
    fit <- forecast::Arima(
      y_train,
      order = c(p, d, q),
      seasonal = list(order = c(P, D, Q), period = s_in),
      include.mean = include_mean,
      include.drift = include_mean,
      method = method,
      biasadj = isTRUE(input$cg_biasadj)
    )
    
    list(
      fit = fit,
      y_train = y_train,
      y_test  = y_test,
      p=p, d=d, q=q, P=P, D=D, Q=Q, s=s_in,
      include_mean = include_mean
    )
  })
  
  # ---- Model spec + IC table
  output$cg_model_spec <- renderPrint({
    validate(need(input$fit_cg_sarima > 0, "Click Fit to estimate ChatGPT-SARIMA."))
    req(cg_fit())
    print(cg_fit()$fit)
  })
  
  output$cg_ic_table <- renderTable({
    req(cg_fit())
    fit <- cg_fit()$fit
    data.frame(
      Metric = c("AIC", "AICc", "BIC", "logLik"),
      Value  = c(
        as.numeric(fit$aic),
        as.numeric(fit$aicc),
        as.numeric(fit$bic),
        as.numeric(stats::logLik(fit))
      )
    )
  }, digits = 4)
  
  # ---- Coef table with stars
  output$cg_coef_table <- renderTable({
    req(cg_fit())
    sm <- summary(cg_fit()$fit)
    co <- as.data.frame(sm$coef)
    co$Term <- rownames(co); rownames(co) <- NULL
    names(co) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)", "Term")
    
    co <- co[, c("Term", "Estimate", "Std.Error", "t.value", "Pr(>|t|)"), drop = FALSE]
    co$Estimate <- as.numeric(co$Estimate)
    co$Std.Error <- as.numeric(co$Std.Error)
    co$`t.value` <- as.numeric(co$`t.value`)
    co$`Pr(>|t|)` <- as.numeric(co$`Pr(>|t|)`)
    
    if (isTRUE(input$cg_show_stars)) {
      co$Sig <- vapply(co$`Pr(>|t|)`, cg_sig_stars, character(1))
    }
    
    co
  }, digits = 6)
  
  # ---- Equation (MathJax) — rendered as HTML + forced typeset
  output$cg_model_equation <- renderUI({
    validate(need(input$fit_cg_sarima > 0, "Fit the model to generate the equation."))
    req(cg_fit())
    obj <- cg_fit()
    
    # Generic academic operator form
    # (This avoids fragile “expanded numeric” equations and renders reliably.)
    eq <- paste0(
      "\\Phi(B^{", obj$s, "})\\,\\phi(B)\\,(1-B)^{", obj$d, "}(1-B^{", obj$s, "})^{", obj$D, "}\\,y_t = ",
      if (obj$include_mean) "c + " else "",
      "\\Theta(B^{", obj$s, "})\\,\\theta(B)\\,\\varepsilon_t"
    )
    
    html <- paste0(
      "<p><b>SARIMA operator form:</b></p>",
      "<div>$$", eq, "$$</div>",
      "<p><b>Selected orders:</b> SARIMA(",
      obj$p, ",", obj$d, ",", obj$q, ")(",
      obj$P, ",", obj$D, ",", obj$Q, ")[", obj$s, "]</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "cg_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- Residuals
  cg_resid <- reactive({
    req(cg_fit())
    as.numeric(residuals(cg_fit()$fit))
  })
  
  # ---- Diagnostics plots
  output$cg_resid_ts <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    plot(r, type = "l", main = "Residuals", ylab = "e_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$cg_resid_acf <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    stats::acf(cg_resid(), main = "ACF of residuals")
  })
  
  output$cg_resid_hist <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    hist(cg_resid(), breaks = 30, main = "Residual histogram", xlab = "e_t")
  })
  
  output$cg_resid_qq <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    qqnorm(r, main = "Q–Q plot"); qqline(r, col = "red")
  })
  
  output$cg_lb_pvals <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    maxL <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(maxL) || maxL < 5) maxL <- 12L
    
    lags <- 1:maxL
    pvals <- sapply(lags, function(L) {
      out <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
      if (is.null(out)) NA_real_ else out$p.value
    })
    
    plot(lags, pvals, type = "b", pch = 16, ylim = c(0, 1),
         main = "Ljung–Box p-values by lag", xlab = "Lag", ylab = "p-value")
    abline(h = 0.05, col = "red", lty = 2)
  })
  
  # ---- Residual tests (text)
  output$cg_resid_tests <- renderPrint({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    cat("Residual tests (ChatGPT-SARIMA)\n")
    cat("================================\n\n")
    
    cat("Ljung–Box test on residuals:\n")
    print(Box.test(r, lag = L, type = "Ljung-Box"))
    cat("\n")
    
    if (requireNamespace("tseries", quietly = TRUE)) {
      cat("Jarque–Bera normality test:\n")
      print(tseries::jarque.bera.test(r))
      cat("\n")
    } else {
      cat("Jarque–Bera: package 'tseries' not installed.\n\n")
    }
    
    if (requireNamespace("FinTS", quietly = TRUE)) {
      cat("ARCH LM test (FinTS::ArchTest):\n")
      print(FinTS::ArchTest(r, lags = L))
      cat("\n")
    } else {
      cat("ARCH LM: package 'FinTS' not installed.\n\n")
    }
  })
  
  # ---- Forecast + accuracy
  cg_forecast <- reactive({
    req(cg_fit())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    obj <- cg_fit()
    test_n <- length(obj$y_test)
    
    if (test_n > 0) {
      h <- test_n
    } else {
      h_in <- suppressWarnings(as.integer(input$cg_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
    }
    
    fc <- forecast::forecast(obj$fit, h = h)
    list(fc = fc, h = h)
  })
  
  output$cg_horizon_note <- renderPrint({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    obj <- cg_fit()
    if (length(obj$y_test) > 0) {
      cat("Holdout test detected. Horizon set to test length (h =", length(obj$y_test), ").\n")
    } else {
      cat("No test detected. Horizon uses cg_h (or default).\n")
    }
  })
  
  output$cg_forecast_plot <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    plot(cg_forecast()$fc, main = "ChatGPT-SARIMA forecast")
  })
  
  output$cg_forecast_table <- renderTable({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    fc <- cg_forecast()$fc
    
    out <- data.frame(
      step = seq_along(fc$mean),
      mean = as.numeric(fc$mean)
    )
    
    # intervals if present
    if (!is.null(fc$lower) && !is.null(fc$upper) && isTRUE(input$cg_show_pi)) {
      out$lo80 <- as.numeric(fc$lower[, 1])
      out$hi80 <- as.numeric(fc$upper[, 1])
      out$lo95 <- as.numeric(fc$lower[, 2])
      out$hi95 <- as.numeric(fc$upper[, 2])
    }
    out
  }, digits = 6)
  
  output$cg_accuracy_table <- renderTable({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    obj <- cg_fit()
    if (length(obj$y_test) == 0) return(NULL)
    
    y_test <- obj$y_test
    y_hat <- as.numeric(cg_forecast()$fc$mean)
    
    if (exists("accuracy_df", mode = "function")) {
      accuracy_df(y_test, y_hat)
    } else {
      e <- y_test - y_hat
      data.frame(
        Metric = c("RMSE", "MAE", "MAPE"),
        Value = c(
          sqrt(mean(e^2, na.rm = TRUE)),
          mean(abs(e), na.rm = TRUE),
          mean(abs(e / y_test), na.rm = TRUE)
        )
      )
    }
  }, rownames = FALSE)
  
  # ---- Academic conclusion: one UI that includes everything (tables, plots, tests, equation, narrative)
  output$cg_conclusion_ui <- renderUI({
    validate(
      need(input$fit_cg_sarima > 0, "Click Fit to generate the academic conclusion.")
    )
    req(cg_fit())
    
    obj <- cg_fit()
    fit <- obj$fit
    r   <- cg_resid()
    
    # ---- core IC (safe)
    aic  <- suppressWarnings(as.numeric(fit$aic))
    aicc <- suppressWarnings(as.numeric(fit$aicc))
    bic  <- suppressWarnings(as.numeric(fit$bic))
    
    aic_txt  <- if (is.finite(aic))  cg_fmt_num(aic,  2) else "NA"
    aicc_txt <- if (is.finite(aicc)) cg_fmt_num(aicc, 2) else "NA"
    bic_txt  <- if (is.finite(bic))  cg_fmt_num(bic,  2) else "NA"
    
    # ---- coefficient summary for narrative (ROBUST)
    sm <- tryCatch(summary(fit), error = function(e) NULL)
    
    co_raw <- NULL
    if (!is.null(sm)) {
      if (!is.null(sm$coef)) co_raw <- sm$coef
      if (is.null(co_raw) && !is.null(sm$coefficients)) co_raw <- sm$coefficients
    }
    
    co <- if (!is.null(co_raw)) {
      df <- as.data.frame(co_raw)
      df$term <- rownames(df)
      rownames(df) <- NULL
      
      # normalize column names to detect estimate/se/stat/p
      nm  <- names(df)
      nm0 <- tolower(gsub("[^a-z]+", "", nm))
      
      pick <- function(keys) {
        idx <- which(nm0 %in% keys)
        if (length(idx) == 0) NA_integer_ else idx[1]
      }
      
      i_est <- pick(c("estimate", "est", "coef", "value"))
      i_se  <- pick(c("se", "stderror", "stderr"))
      i_st  <- pick(c("tvalue", "tstat", "zvalue", "zstat", "statistic"))
      i_p   <- pick(c("prtt", "prgt", "prgtz", "pvalue", "p"))
      
      out <- data.frame(
        term  = df$term,
        est   = if (!is.na(i_est)) suppressWarnings(as.numeric(df[[i_est]])) else NA_real_,
        se    = if (!is.na(i_se))  suppressWarnings(as.numeric(df[[i_se]]))  else NA_real_,
        stat  = if (!is.na(i_st))  suppressWarnings(as.numeric(df[[i_st]]))  else NA_real_,
        p     = if (!is.na(i_p))   suppressWarnings(as.numeric(df[[i_p]]))   else NA_real_,
        stringsAsFactors = FALSE
      )
      
      out$stars <- vapply(out$p, cg_sig_stars, character(1))
      out
    } else {
      data.frame(term = character(0), est = numeric(0), se = numeric(0), stat = numeric(0), p = numeric(0), stars = character(0))
    }
    
    n_sig <- sum(is.finite(co$p) & co$p < 0.05)
    
    # ---- residual tests quick stats for narrative
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    lb <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    
    jb <- if (requireNamespace("tseries", quietly = TRUE)) {
      tryCatch(tseries::jarque.bera.test(r), error = function(e) NULL)
    } else NULL
    
    arch <- if (requireNamespace("FinTS", quietly = TRUE)) {
      tryCatch(FinTS::ArchTest(r, lags = L), error = function(e) NULL)
    } else NULL
    
    # ---- accuracy quick stats (if test)
    acc_txt <- "No holdout test set was available; out-of-sample accuracy was not computed."
    if (length(obj$y_test) > 0) {
      y_test <- obj$y_test
      fc_obj <- cg_forecast()
      y_hat  <- if (!is.null(fc_obj) && !is.null(fc_obj$fc)) as.numeric(fc_obj$fc$mean) else rep(NA_real_, length(y_test))
      
      if (length(y_hat) == length(y_test) && any(is.finite(y_hat))) {
        e <- y_test - y_hat
        rmse <- sqrt(mean(e^2, na.rm = TRUE))
        mae  <- mean(abs(e), na.rm = TRUE)
        acc_txt <- paste0(
          "Out-of-sample performance (test n = ", length(y_test),
          ") was RMSE = ", cg_fmt_num(rmse, 3),
          " and MAE = ", cg_fmt_num(mae, 3), "."
        )
      } else {
        acc_txt <- paste0(
          "A test set was detected (n = ", length(y_test),
          "), but forecast values were not available or not finite; accuracy could not be computed."
        )
      }
    }
    
    # ---- typeset equation in conclusion box
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "cg_conclusion_box")
    }, once = TRUE)
    
    tagList(
      tags$h3("ChatGPT-SARIMA: Academic conclusion"),
      
      tags$div(
        class = "cg-h",
        tags$h4("1. Model objective and specification"),
        tags$p(
          "A manually specified seasonal ARIMA (SARIMA) model was estimated to capture both non-seasonal and seasonal dependence in the series.",
          " The final specification was ",
          tags$b(sprintf(
            "SARIMA(%d,%d,%d)(%d,%d,%d)[%d]%s",
            obj$p, obj$d, obj$q, obj$P, obj$D, obj$Q, obj$s,
            if (isTRUE(obj$include_mean)) " with mean/drift." else " without mean/drift."
          )),
          "."
        ),
        tags$p(HTML(paste0(
          "<b>Information criteria:</b> AIC = ", aic_txt,
          ", AICc = ", aicc_txt,
          ", BIC = ", bic_txt, "."
        )))
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("2. Coefficient inference and practical interpretation"),
        tags$p(HTML(paste0(
          "Coefficient inference was evaluated using approximate t-tests. ",
          "A total of <b>", n_sig, "</b> parameters were statistically significant at α = .05 (see coefficient table)."
        ))),
        tags$p("Interpretation should prioritize model adequacy (white-noise residuals) and forecast performance rather than isolated p-values.")
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("3. Model equation"),
        tags$div(
          style = "border:1px solid #e5e5e5; border-radius:6px; background:#fcfcfc; padding:10px;",
          uiOutput("cg_model_equation")
        )
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("4. Diagnostic evidence"),
        tags$p("Residual diagnostics were examined using time-domain plots, autocorrelation diagnostics, and distributional checks."),
        fluidRow(
          column(6, plotOutput("cg_resid_ts", height = 220)),
          column(6, plotOutput("cg_resid_acf", height = 220))
        ),
        fluidRow(
          column(6, plotOutput("cg_resid_hist", height = 220)),
          column(6, plotOutput("cg_resid_qq", height = 220))
        ),
        plotOutput("cg_lb_pvals", height = 260)
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("5. Residual tests (formal)"),
        tags$p(
          "The following tests provide formal evidence regarding remaining autocorrelation (Ljung–Box), ",
          "departures from normality (Jarque–Bera), and conditional heteroskedasticity (ARCH LM)."
        ),
        verbatimTextOutput("cg_resid_tests"),
        if (!is.null(lb)) tags$p(HTML(paste0(
          "<b>Ljung–Box:</b> Q(", lb$parameter, ") = ", cg_fmt_num(lb$statistic, 3),
          ", p ", cg_fmt_p(lb$p.value), "."
        ))) else NULL,
        if (!is.null(jb)) tags$p(HTML(paste0(
          "<b>Jarque–Bera:</b> JB = ", cg_fmt_num(jb$statistic, 3),
          ", p ", cg_fmt_p(jb$p.value), "."
        ))) else NULL,
        if (!is.null(arch)) tags$p(HTML(paste0(
          "<b>ARCH LM:</b> TR^2 = ", cg_fmt_num(arch$statistic, 3),
          ", p ", cg_fmt_p(arch$p.value), "."
        ))) else NULL
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("6. Forecasting and predictive performance"),
        tags$p(acc_txt),
        plotOutput("cg_forecast_plot", height = 380),
        tags$h5("Forecast table"),
        tableOutput("cg_forecast_table"),
        tags$h5("Accuracy table (if test set available)"),
        tableOutput("cg_accuracy_table")
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("7. Final conclusion"),
        tags$p(
          "Overall, the fitted SARIMA model constitutes an interpretable baseline for linear seasonal dependence.",
          " If residual tests indicate non-white-noise behavior (e.g., significant Ljung–Box), the model should be refined by adjusting AR/MA orders or differencing.",
          " If ARCH effects remain, a conditional variance model (e.g., GARCH) is recommended as an extension for volatility clustering."
        )
      )
    )
  })
  
  
  
  
  
  
}
