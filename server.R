# server.R â€” SARIMA Scientific Writing Lab (v2)
# FIX v2: Manual SARIMA validation forecast aligns with test horizon (h = test length).

library(shiny)
library(ggplot2)
library(forecast)
library(lubridate)
library(zoo)
library(tseries)
library(urca)
library(DT)
library(scales)

# library(gridExtra)
# library(colourpicker)
# library(patchwork)

for (pkg in c("gridExtra", "colourpicker", "patchwork")) {
  if (requireNamespace(pkg, quietly = TRUE)) {
    suppressPackageStartupMessages(library(pkg, character.only = TRUE))
  }
}


has_pkg <- function(pkg) requireNamespace(pkg, quietly = TRUE)





# ---------- Safety helpers (add once) ----------

is_finite_vec <- function(x) {
  x <- suppressWarnings(as.numeric(x))
  length(x) > 0 && any(is.finite(x))
}

safe_range <- function(x) {
  x <- suppressWarnings(as.numeric(x))
  if (length(x) == 0) return(NULL)
  r <- suppressWarnings(range(x, na.rm = TRUE, finite = TRUE))
  if (length(r) != 2 || any(!is.finite(r))) return(NULL)
  if (diff(r) == 0) return(NULL)
  r
}

# Safely extract and standardize coefficient table from MANY model types
coef_table_safe <- function(fit) {
  sm <- tryCatch(summary(fit), error = function(e) NULL)
  if (is.null(sm)) return(data.frame())
  
  # try common places:
  co <- NULL
  if (!is.null(sm$coef)) co <- sm$coef
  if (is.null(co) && !is.null(sm$coefficients)) co <- sm$coefficients
  if (is.null(co)) return(data.frame())
  
  co <- as.data.frame(co)
  co$term <- rownames(co)
  rownames(co) <- NULL
  
  # normalize column names
  nm <- names(co)
  nm0 <- tolower(gsub("[^a-z]+", "", nm))
  
  # Attempt to find estimate/se/t/p columns flexibly
  pick <- function(keys) {
    idx <- which(nm0 %in% keys)
    if (length(idx) == 0) NA_integer_ else idx[1]
  }
  
  i_est <- pick(c("estimate", "est", "coef", "value"))
  i_se  <- pick(c("se", "stderror", "stderr", "sestd"))
  i_t   <- pick(c("tvalue", "tstat", "zvalue", "zstat", "statistic"))
  i_p   <- pick(c("prtz", "prgtz", "prgt", "prtt", "prgtz", "pvalue", "pr", "prt"))
  
  out <- data.frame(
    term = co$term,
    est  = if (!is.na(i_est)) suppressWarnings(as.numeric(co[[i_est]])) else NA_real_,
    se   = if (!is.na(i_se))  suppressWarnings(as.numeric(co[[i_se]]))  else NA_real_,
    stat = if (!is.na(i_t))   suppressWarnings(as.numeric(co[[i_t]]))   else NA_real_,
    p    = if (!is.na(i_p))   suppressWarnings(as.numeric(co[[i_p]]))   else NA_real_,
    stringsAsFactors = FALSE
  )
  
  out
}

sig_stars <- function(p) {
  if (!is.finite(p)) return("")
  if (p < 0.001) "***" else if (p < 0.01) "**" else if (p < 0.05) "*" else if (p < 0.1) "." else ""
}


build_xreg_split <- function(df, cols, train_n, test_n, scale_x = FALSE) {
  if (length(cols) == 0) return(list(x_train = NULL, x_test = NULL, x_all = NULL))
  
  X <- df[, cols, drop = FALSE]
  
  # keep numeric columns only (convert logical to numeric)
  for (nm in names(X)) {
    if (is.logical(X[[nm]])) X[[nm]] <- as.numeric(X[[nm]])
  }
  # force numeric
  X <- data.frame(lapply(X, function(z) suppressWarnings(as.numeric(z))), check.names = FALSE)
  
  # handle missing values in xreg (simple: linear interpolation + LOCF fallback)
  for (j in seq_along(X)) {
    v <- X[[j]]
    idx <- which(is.finite(v))
    if (length(idx) >= 2) {
      v[!is.finite(v)] <- approx(x = idx, y = v[idx], xout = which(!is.finite(v)), method = "linear", rule = 2)$y
    }
    # if still NA (all missing), set 0
    v[!is.finite(v)] <- 0
    X[[j]] <- v
  }
  
  if (isTRUE(scale_x)) {
    X <- as.data.frame(scale(X), check.names = FALSE)
  }
  
  X_mat <- as.matrix(X)
  x_train <- X_mat[seq_len(train_n), , drop = FALSE]
  x_test  <- if (test_n > 0) X_mat[(train_n + 1):(train_n + test_n), , drop = FALSE] else NULL
  
  list(x_train = x_train, x_test = x_test, x_all = X_mat)
}



# ============================================================
# --- MOD: Robust date parsing (R Date / POSIX / Excel serial / text) ---
# ============================================================

parse_dates <- function(x, by_hint = NULL) {
  if (inherits(x, "Date"))  return(x)
  if (inherits(x, "POSIXt")) return(as.Date(x))
  
  if (is.numeric(x)) {
    med <- suppressWarnings(stats::median(x, na.rm = TRUE))
    if (is.finite(med) && med > -60000 && med < 60000) {
      return(as.Date(x, origin = "1970-01-01"))
    }
    return(as.Date(x, origin = "1899-12-30"))
  }
  
  x_chr <- trimws(as.character(x))
  x_chr[x_chr %in% c("", "NA", "NaN")] <- NA_character_
  
  d <- rep(as.Date(NA), length(x_chr))
  
  # month/year like 02/2020 or 2-2020 (require 4-digit year to avoid ambiguity)
  is_month_year <- grepl("^\\d{1,2}[-/]\\d{4}$", x_chr)
  if (any(is_month_year, na.rm = TRUE)) {
    tmp <- gsub("-", "/", x_chr[is_month_year])
    d[is_month_year] <- suppressWarnings(as.Date(zoo::as.yearmon(tmp, format = "%m/%Y")))
  }
  
  # reject tiny integer strings like "2", "12", "03"
  is_small_int <- grepl("^\\d{1,2}$", x_chr)
  x_chr[is_small_int] <- NA_character_
  
  # year-month like 2020-02 or "Jan 2020"
  looks_yearmon <- grepl("^\\d{4}[-/](\\d{1,2})$", x_chr) | grepl("^[A-Za-z]{3,}\\s*\\d{4}$", x_chr)
  if (any(looks_yearmon, na.rm = TRUE)) {
    idx_ym <- which(looks_yearmon & is.na(d) & !is.na(x_chr))
    d[idx_ym] <- suppressWarnings(as.Date(zoo::as.yearmon(x_chr[idx_ym])))
  }
  
  # day/month ambiguity handling (only where still NA)
  idx <- which(is.na(d) & !is.na(x_chr))
  if (length(idx)) {
    s <- x_chr[idx]
    candidates_all <- c(
      "%Y-%m-%d", "%Y/%m/%d",
      "%m-%d-%Y", "%d-%m-%Y",
      "%m/%d/%Y", "%d/%m/%Y",
      "%m-%d-%y", "%d-%m-%y",
      "%m/%d/%y", "%d/%m/%y"
    )
    
    has_dash  <- any(grepl("-", s), na.rm = TRUE)
    has_slash <- any(grepl("/", s), na.rm = TRUE)
    candidates <- candidates_all
    if (!has_dash)  candidates <- candidates[!grepl("-", candidates)]
    if (!has_slash) candidates <- candidates[!grepl("/", candidates)]
    
    expected_days <- switch(
      as.character(by_hint),
      "month" = 30, "quarter" = 91, "week" = 7, "day" = 1,
      NA_real_
    )
    
    score_dt <- function(dt) {
      n_ok <- sum(!is.na(dt))
      if (n_ok < 3) return(c(n_ok, -Inf, -Inf))
      u <- sort(unique(dt[!is.na(dt)]))
      if (length(u) < 3) return(c(n_ok, -Inf, -Inf))
      med_step <- suppressWarnings(stats::median(as.numeric(diff(u))))
      if (!is.finite(med_step)) med_step <- -Inf
      closeness <- if (is.finite(expected_days)) -abs(med_step - expected_days) else med_step
      c(n_ok, closeness, med_step)
    }
    
    parsed_list <- lapply(candidates, function(fmt) suppressWarnings(as.Date(s, format = fmt)))
    scores <- do.call(rbind, lapply(parsed_list, score_dt))
    best <- order(scores[, 1], scores[, 2], scores[, 3], decreasing = TRUE)[1]
    d[idx] <- parsed_list[[best]]
  }
  
  idx2 <- which(is.na(d) & !is.na(x_chr))
  if (length(idx2)) {
    d2 <- suppressWarnings(lubridate::parse_date_time(
      x_chr[idx2],
      orders = c("ymd", "Ymd", "Y-m-d", "Y/m/d", "bdY", "bY", "Y")
    ))
    d[idx2] <- as.Date(d2)
  }
  
  d
}




# parse_dates <- function(x, by_hint = NULL) {
#   # Returns a Date vector. Handles Date/POSIX, Excel serials, and common text formats.
#   if (inherits(x, "Date")) return(x)
#   if (inherits(x, "POSIXt")) return(as.Date(x))
#   
#   # Numeric: either R Date (days since 1970-01-01) or Excel serial (days since 1899-12-30)
#   if (is.numeric(x)) {
#     med <- suppressWarnings(stats::median(x, na.rm = TRUE))
#     if (is.finite(med) && med > -60000 && med < 60000) {
#       return(as.Date(x, origin = "1970-01-01"))
#     }
#     return(as.Date(x, origin = "1899-12-30"))
#   }
#   
#   x_chr <- trimws(as.character(x))
#   x_chr[x_chr %in% c("", "NA", "NaN")] <- NA_character_
#   
#   # âœ… create d BEFORE any d[...] assignment
#   d <- rep(as.Date(NA), length(x_chr))
#   
#   is_month_year <- grepl("^\\d{1,2}[-/]\\d{2,4}$", x_chr) &!grepl("^\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}$", x_chr)
#   
#   if (any(is_month_year, na.rm = TRUE)) {
#     tmp <- gsub("-", "/", x_chr[is_month_year])
#     # prefer 4-digit year; if 2-digit, interpret as 20xx is riskyâ€”better to require 4 digits or document it
#     d[is_month_year] <- suppressWarnings(as.Date(zoo::as.yearmon(tmp, format = "%m/%Y")))
#   }
# 
#   # reject "small integer" strings like "2", "12", "03"
#   is_small_int <- grepl("^\\d{1,2}$", x_chr)
#   x_chr[is_small_int] <- NA_character_
# 
#   # only use yearmon when it looks like year-month
#   looks_yearmon <- grepl("^\\d{4}[-/](\\d{1,2})$", x_chr) |
#     grepl("^[A-Za-z]{3,}\\s*\\d{4}$", x_chr)
# 
#   d <- rep(as.Date(NA), length(x_chr))
# 
#   if (any(looks_yearmon, na.rm = TRUE)) {
#     d[looks_yearmon] <- suppressWarnings(as.Date(zoo::as.yearmon(x_chr[looks_yearmon])))
#   }
# 
#   # ---- Robust day/month ambiguity handling ----
#   idx <- which(is.na(d) & !is.na(x_chr))
#   if (length(idx)) {
#     s <- x_chr[idx]
# 
#     # candidate formats (we'll filter based on separators seen in the data)
#     candidates_all <- c(
#       "%Y-%m-%d", "%Y/%m/%d",
#       "%m-%d-%Y", "%d-%m-%Y",
#       "%m/%d/%Y", "%d/%m/%Y",
#       "%m-%d-%y", "%d-%m-%y",
#       "%m/%d/%y", "%d/%m/%y"
#     )
# 
#     has_dash <- any(grepl("-", s), na.rm = TRUE)
#     has_slash <- any(grepl("/", s), na.rm = TRUE)
#     candidates <- candidates_all
#     if (!has_dash)  candidates <- candidates[!grepl("-", candidates)]
#     if (!has_slash) candidates <- candidates[!grepl("/", candidates)]
# 
#     expected_days <- switch(
#       as.character(by_hint),
#       "month"   = 30,
#       "quarter" = 91,
#       "week"    = 7,
#       "day"     = 1,
#       NA_real_
#     )
# 
#     score_dt <- function(dt) {
#       n_ok <- sum(!is.na(dt))
#       if (n_ok < 3) return(c(n_ok, -Inf, -Inf))
# 
#       u <- sort(unique(dt[!is.na(dt)]))
#       if (length(u) < 3) return(c(n_ok, -Inf, -Inf))
# 
#       med_step <- suppressWarnings(stats::median(as.numeric(diff(u))))
#       if (!is.finite(med_step)) med_step <- -Inf
# 
#       # prefer spacing that matches the chosen frequency (monthly vs daily ambiguity)
#       closeness <- if (is.finite(expected_days)) -abs(med_step - expected_days) else med_step
# 
#       c(n_ok, closeness, med_step)
#     }
# 
#     parsed_list <- lapply(candidates, function(fmt) suppressWarnings(as.Date(s, format = fmt)))
#     scores <- do.call(rbind, lapply(parsed_list, score_dt))
# 
#     best <- order(scores[, 1], scores[, 2], scores[, 3], decreasing = TRUE)[1]
#     d[idx] <- parsed_list[[best]]
#   }
# 
#   # fallback for remaining NAs (avoid re-introducing dmy/mdy ambiguity here)
#   idx2 <- which(is.na(d) & !is.na(x_chr))
#   if (length(idx2)) {
#     d2 <- suppressWarnings(lubridate::parse_date_time(
#       x_chr[idx2],
#       orders = c("ymd", "Ymd", "Y-m-d", "Y/m/d", "bdY", "bY", "Y")
#     ))
#     d[idx2] <- as.Date(d2)
#   }
# 
#   d
# }


# ---------------- APA helpers ----------------

fmt_p <- function(p) {
  if (is.na(p)) return("p = NA")
  if (p < 0.001) return("p < .001")
  s <- format(p, digits = 3, nsmall = 3)
  s <- sub("^0\\.", ".", s)
  paste0("p = ", s)
}



fmt_num <- function(x, digits = 4, trim = TRUE) {
  x <- suppressWarnings(as.numeric(x))
  if (length(x) == 0 || !is.finite(x)) return("NA")
  format(round(x, digits), nsmall = digits, trim = trim)
}




fmt_pct <- function(x, digits = 1) {
  if (is.na(x)) return("NA")
  paste0(fmt_num(100 * x, digits), "%")
}

# ---------------- Dates & time grid ----------------


freq_value <- function(input) {
  if (identical(input$frequency, "other")) as.numeric(input$customFrequency) else as.numeric(input$frequency)
}

freq_to_by <- function(freq) {
  switch(
    as.character(freq),
    "12" = "month",
    "4" = "quarter",
    "52" = "week",
    "365" = "day",
    "7" = "day",
    NULL
  )
}

make_regular_grid <- function(dates, by) {
  if (is.null(by)) return(sort(unique(dates)))
  seq.Date(from = min(dates), to = max(dates), by = by)
}

extend_grid <- function(last_x, h, by) {
  if (inherits(last_x, "Date") && !is.null(by)) {
    seq.Date(from = last_x, by = by, length.out = h + 1)[-1]
  } else {
    (as.numeric(last_x) + seq_len(h))
  }
}

# ---------------- Missing values & transforms ----------------

fill_missing <- function(y, policy, freq) {
  if (policy == "drop") return(y)
  if (policy == "locf") {
    y <- zoo::na.locf(y, na.rm = FALSE)
    y <- zoo::na.locf(y, fromLast = TRUE, na.rm = FALSE)
    return(y)
  }
  if (policy == "linear") return(zoo::na.approx(y, na.rm = FALSE))
  if (policy == "seasonal") return(as.numeric(forecast::na.interp(ts(y, frequency = freq))))
  y
}

apply_transform <- function(y, transform, lambda) {
  if (transform == "none") return(y)
  if (any(y <= 0, na.rm = TRUE)) stop("Chosen transformation requires strictly positive values.")
  if (transform == "log") return(log(y))
  if (transform == "boxcox") {
    lam <- if (!is.na(lambda)) lambda else forecast::BoxCox.lambda(y, lower = 0)
    return(forecast::BoxCox(y, lam))
  }
  y
}

# ---------------- Descriptives & diagnostics ----------------

basic_stats_df <- function(y) {
  y <- as.numeric(y)
  y_ok <- y[is.finite(y)]
  n <- length(y)
  n_ok <- length(y_ok)
  miss <- n - n_ok
  if (n_ok == 0) {
    return(data.frame(Metric = c("N", "Missing"), Value = c(n, miss), stringsAsFactors = FALSE))
  }
  mu <- mean(y_ok)
  sdv <- sd(y_ok)
  med <- median(y_ok)
  mn <- min(y_ok); mx <- max(y_ok)
  cv <- if (mu != 0) sdv / mu else NA_real_
  m3 <- mean((y_ok - mu)^3)
  m4 <- mean((y_ok - mu)^4)
  skew <- if (sdv > 0) m3 / (sdv^3) else NA_real_
  kurt <- if (sdv > 0) m4 / (sdv^4) else NA_real_
  data.frame(
    Metric = c("N", "Valid", "Missing", "Mean", "Median", "SD", "Min", "Max", "CV", "Skewness", "Kurtosis"),
    Value = c(n, n_ok, miss, mu, med, sdv, mn, mx, cv, skew, kurt),
    stringsAsFactors = FALSE
  )
}

z_outliers <- function(y, z_cut = 3) {
  y <- as.numeric(y)
  ok <- is.finite(y)
  mu <- mean(y[ok])
  sdv <- sd(y[ok])
  if (!is.finite(sdv) || sdv == 0) return(integer(0))
  which(abs((y - mu) / sdv) >= z_cut)
}

coef_table <- function(fit) {
  s <- tryCatch(summary(fit), error = function(e) NULL)
  if (is.null(s) || is.null(s$coef)) return(data.frame())
  cf <- as.data.frame(s$coef)
  cf$term <- rownames(cf)
  rownames(cf) <- NULL
  names(cf) <- sub("Pr\\(>\\|t\\|\\)", "p_value", names(cf))
  names(cf) <- sub("Pr\\(>\\|z\\|\\)", "p_value", names(cf))
  cf
}

diag_tests_text <- function(resid, lag, fitdf = 0) {
  r <- as.numeric(na.omit(resid))
  out <- c("Residual diagnostics")

  lb <- tryCatch(Box.test(r, lag = lag, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
  if (!is.null(lb)) out <- c(out, paste0("- Ljung-Box: Q(", lag, ") = ", fmt_num(lb$statistic, 2), ", ", fmt_p(lb$p.value)))

  jb <- tryCatch(tseries::jarque.bera.test(r), error = function(e) NULL)
  if (!is.null(jb)) out <- c(out, paste0("- Jarqueâ€“Bera: JB = ", fmt_num(jb$statistic, 2), ", ", fmt_p(jb$p.value)))

  sh <- tryCatch(stats::shapiro.test(if (length(r) > 5000) sample(r, 5000) else r), error = function(e) NULL)
  if (!is.null(sh)) out <- c(out, paste0("- Shapiroâ€“Wilk: W = ", fmt_num(sh$statistic, 3), ", ", fmt_p(sh$p.value)))

  if (has_pkg("nortest")) {
    ad <- tryCatch(nortest::ad.test(r), error = function(e) NULL)
    if (!is.null(ad)) out <- c(out, paste0("- Andersonâ€“Darling: A = ", fmt_num(ad$statistic, 2), ", ", fmt_p(ad$p.value)))
  }

  if (has_pkg("FinTS")) {
    arch <- tryCatch(FinTS::ArchTest(r, lags = min(12, max(1, floor(lag / 2)))), error = function(e) NULL)
    if (!is.null(arch)) out <- c(out, paste0("- ARCH LM: TR^2 = ", fmt_num(arch$statistic, 2), ", ", fmt_p(arch$p.value)))
  }

  out <- c(out, "", "Interpretation (typical): Ljung-Box p > .05 suggests residuals are approximately white noise.")
  paste(out, collapse = "\n")
}

accuracy_df <- function(actual, forecast_mean) {
  a <- as.numeric(actual)
  f <- as.numeric(forecast_mean)
  n <- min(length(a), length(f))
  a <- a[seq_len(n)]
  f <- f[seq_len(n)]
  e <- a - f

  rmse <- sqrt(mean(e^2, na.rm = TRUE))
  mae <- mean(abs(e), na.rm = TRUE)
  mape <- mean(abs(e / a), na.rm = TRUE)
  smape <- mean(2 * abs(e) / (abs(a) + abs(f)), na.rm = TRUE)

  data.frame(
    Metric = c("RMSE", "MAE", "MAPE", "sMAPE"),
    Value = c(rmse, mae, mape, smape),
    stringsAsFactors = FALSE
  )
}

forecast_table <- function(fc) {
  out <- data.frame(step = seq_along(fc$mean), mean = as.numeric(fc$mean))
  if (!is.null(fc$lower)) {
    out$lo80 <- as.numeric(fc$lower[, 1])
    out$hi80 <- as.numeric(fc$upper[, 1])
    if (ncol(fc$lower) >= 2) {
      out$lo95 <- as.numeric(fc$lower[, 2])
      out$hi95 <- as.numeric(fc$upper[, 2])
    }
  }
  out
}

# ---------------- Plot helpers (Date-safe) ----------------

plot_series_df <- function(df, train_n) {
  df$set <- ifelse(seq_len(nrow(df)) <= train_n, "Train", "Test/Future")
  df
}

plot_forecast_df <- function(obs_df, train_n, fc, by) {
  n_obs <- nrow(obs_df)
  test_n <- n_obs - train_n
  h <- length(fc$mean)

  # FIX v2:
  # If a test set exists, align the forecast x values with the test period.
  # Only extend beyond the observed sample if h > test length.
  if (test_n > 0) {
    x_test <- obs_df$x[(train_n + 1):n_obs]
    n_align <- min(h, length(x_test))
    x_fc <- x_test[seq_len(n_align)]
    if (h > n_align) {
      x_extra <- extend_grid(obs_df$x[n_obs], h - n_align, by)
      x_fc <- c(x_fc, x_extra)
    }
  } else {
    x_fc <- extend_grid(obs_df$x[n_obs], h, by)
  }

  fc_tab <- forecast_table(fc)
  fc_tab$x <- x_fc
  fc_tab
}

gg_forecast_plot <- function(obs_df, train_n, fc_df, title) {
  p <- ggplot() +
    geom_line(data = obs_df[seq_len(train_n), ], aes(x = x, y = y, color = "Train")) +
    theme_minimal() +
    labs(title = title, x = "Time", y = "Value", color = NULL) +
    theme(legend.position = "bottom")

  if (nrow(obs_df) > train_n) {
    p <- p + geom_line(data = obs_df[(train_n + 1):nrow(obs_df), ], aes(x = x, y = y, color = "Test"))
  }

  if ("lo95" %in% names(fc_df)) p <- p + geom_ribbon(data = fc_df, aes(x = x, ymin = lo95, ymax = hi95), alpha = 0.15)
  if ("lo80" %in% names(fc_df)) p <- p + geom_ribbon(data = fc_df, aes(x = x, ymin = lo80, ymax = hi80), alpha = 0.25)

  p + geom_line(data = fc_df, aes(x = x, y = mean, color = "Forecast"), linewidth = 1)
}





apply_smart_date_axis <- function(g, ddf) {
  if (!(inherits(ddf$t, "Date") || inherits(ddf$t, "POSIXct") || inherits(ddf$t, "POSIXt"))) return(g)
  
  span_days <- as.numeric(max(ddf$t, na.rm = TRUE) - min(ddf$t, na.rm = TRUE))
  
  # choose break spacing
  brks <- if (!is.finite(span_days) || span_days <= 0) {
    "1 year"
  } else if (span_days <= 90) {
    "1 week"
  } else if (span_days <= 365) {
    "1 month"
  } else if (span_days <= 3 * 365) {
    "3 months"
  } else if (span_days <= 10 * 365) {
    "1 year"
  } else {
    "2 years"
  }
  
  # choose label format by zoom level
  fmt <- if (!is.finite(span_days)) {
    "%Y"
  } else if (span_days <= 90) {
    "%d/%m/%y"   # short span â†’ day/month/year
  } else if (span_days <= 3 * 365) {
    "%m/%y"      # medium span â†’ month/year
  } else {
    "%Y"         # long span â†’ year only
  }
  
  if (inherits(ddf$t, "POSIXct") || inherits(ddf$t, "POSIXt")) {
    g + ggplot2::scale_x_datetime(date_breaks = brks, date_labels = fmt)
  } else {
    g + ggplot2::scale_x_date(date_breaks = brks, date_labels = fmt)
  }
}



downsample_rows <- function(df, n_max = 8000L) {
  n <- nrow(df)
  if (!is.finite(n) || n <= n_max) return(df)
  
  # keep first + last, plus evenly spaced middle indices
  mid_n <- max(0L, n_max - 2L)
  idx_mid <- if (mid_n > 0L) round(seq.int(2L, n - 1L, length.out = mid_n)) else integer(0)
  idx <- unique(c(1L, idx_mid, n))
  df[idx, , drop = FALSE]
}



callout <- function(body, title = NULL,
                    theme = c("blue","teal","green","amber","rose","purple","slate",
                              "cyan","sky","indigo","violet","fuchsia","lime",
                              "orange","red","stone","zinc"),
                    body_is_html = TRUE) {
  
  theme <- match.arg(theme)
  
  inner <- list()
  if (!is.null(title)) {
    inner <- c(inner, list(tags$h5(tags$strong(title))))
  }
  
  inner <- c(
    inner,
    list(
      if (body_is_html) {
        tags$p(HTML(body))
      } else {
        body   # ðŸ‘ˆ allow tagList / tags directly
      }
    )
  )
  
  tags$div(class = paste("callout", paste0("callout-", theme)), inner)
}








#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================
#=========================================================================================================




pkg_status_li <- function(pkg) {
  ok <- has_pkg(pkg)
  tags$li(
    if (ok) "âœ…" else "âŒ",
    tags$span(
      paste0(" ", pkg),
      style = if (ok) "color: #2e7d32;" else "color: #b71c1c;"
    )
  )
}



# ---------------- Shiny server ----------------

server <- function(input, output, session) {

  # ---- Roadmap & teaching notes ----

  
  # Required packages (UI-style environment check)
  output$package_status <- renderUI({
    
    required_pkgs <- c(
      "shiny",        # app framework
      "ggplot2",      # all plotting
      "forecast",     # SARIMA, ACF/PACF, decomposition, BoxCox
      "lubridate",    # date parsing
      "zoo",          # na.locf, na.approx, as.yearmon
      "tseries",      # ADF, Jarque-Bera
      "urca",         # unit root tests
      "DT",           # data tables
      "scales"        # plot scales
    )
    
    optional_pkgs <- c(
      "readxl",       # only needed for XLS/XLSX upload
      "colourpicker", # S(t) plot color pickers
      "patchwork",    # combined plots
      "gridExtra",    # plot layouts
      "shinythemes",  # UI theme
      "shinyjs",      # JS helpers (disable/enable UI)
      "nortest",      # Andersonâ€“Darling normality test
      "FinTS",         # ARCH LM test
      "DiagrammeR"
    )
    

        tags$div(
      style = "background:#eef5ff;padding:12px;border-radius:8px;",
      tags$h4("R environment check"),
      tags$p(
        style = "margin-top:-6px; font-size: 13px; color:#34495e;",
        "âœ… installed  â€¢  âŒ missing"
      ),
      
      tags$br(),
      
      fluidRow(
        column(
          width = 6,
          tags$b("Required packages"),
          tags$ul(lapply(required_pkgs, pkg_status_li))
        ),
        column(
          width = 6,
          tags$b(""),
          tags$ul(lapply(optional_pkgs, pkg_status_li))
        )
      ),
      
      if (any(!vapply(required_pkgs, has_pkg, logical(1)))) {
        tags$div(
          style = "margin-top:10px; color:#b71c1c; font-size:13px;",
          tags$b("Some required packages are missing."),
          tags$div("Install with:"),
          tags$pre(
            style = "background:white; padding:8px; border-radius:6px;",
            paste0(
              "install.packages(c(",
              paste0('"', required_pkgs, '"', collapse = ", "),
              "))"
            )
          )
        )
      } else {
        tags$div(
          style = "margin-top:10px; color:#2e7d32; font-size:13px;",
          tags$b("All required packages are installed.")
        )
      }
    )
  })
  
  
  
  output$roadmap_ui <- renderUI({
    
    required_pkgs <- c(
      "shiny", "ggplot2", "forecast", "lubridate", "zoo",
      "tseries", "urca", "DT", "scales"
    )
    
    optional_pkgs <- c(
      "readxl", "colourpicker", "patchwork", "gridExtra",
      "shinythemes", "shinyjs", "nortest", "FinTS"
    )
    
    # Helper for roadmap items with icons
    step_li <- function(ic, title_bold, rest_text) {
      tags$li(
        tags$span(icon(ic), style = "margin-right:8px; color:#2c3e50;"),
        tags$b(title_bold),
        HTML(paste0(": ", rest_text))
      )
    }
    
    tags$div(
      
      # =========================
      # Box 1: Roadmap steps
      # =========================
      tags$div(
        style = "background:#f7f7f7;padding:12px;border-radius:8px;margin-bottom:10px;",
        tags$h4("Roadmap (what students do, what they write)"),
        tags$ol(
          step_li("database",      "Describe the data",   "sample size, missing values, descriptive statistics."),
          step_li("chart-line",    "Explore visually",    "trend/seasonality/outliers; report observations."),
          step_li("layer-group",   "Decompose",           "justify additive vs multiplicative; use STL when robust needed."),
          step_li("check-circle",  "Check stationarity",  "ADF/KPSS/PP; justify differencing (d and D)."),
          step_li("robot",         "Fit a baseline model","Auto-ARIMA to obtain a strong starting SARIMA."),
          step_li("sliders-h",     "Fit a theory-driven model","Manual SARIMA using ACF/PACF + tests."),
          step_li("stethoscope",   "Diagnose & compare",  "residual tests + forecast accuracy; choose final model."),
          step_li("file-alt",      "Write your paper",    "use APA paragraphs in each step; assemble Methods/Results.")
        ),
        tags$br(),
      ),
      
   
      
      
      
      # =========================
      # 1 Not to change MÃ©thode de Boxâ€“Jenkins (SARIMA)
      # =========================
      

      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("MÃ©thode de Boxâ€“Jenkins (SARIMA) â€” diagramme dÃ©taillÃ©")),
        tags$div(
          style = "padding:10px 12px; background:#fff; overflow-x:auto;",
          DiagrammeR::grVizOutput("box_jenkins_sarima", height = "3000px")
        )
      ),
      
      
      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Boxâ€“Jenkins (SARIMA) â€” diagramme extrÃªmement dÃ©taillÃ© (avec explications)")),
        tags$div(
          style = "padding:10px 12px; background:#fff; overflow-x:auto;",
          DiagrammeR::grVizOutput("box_jenkins_sarima_xd", height = "3000px")
        )
      ),
      
      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Boxâ€“Jenkins SARIMA â€” diagramme ultra dÃ©taillÃ© (figures + APA + log/BoxCox + HEGY)")),
        tags$div(
          style = "padding:10px 12px; background:#fff; overflow-x:auto;",
          DiagrammeR::grVizOutput("box_jenkins_sarima_ultra", height = "5000px")
        )
      ),
      
      
      
      
      # =========================
      # 1 Not to change
      # =========================
      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Diagramme complet â€” analyse SARIMA (workflow)")),
        grVizOutput("sarima_workflow", height = "5500px")
      ),
      
      # =========================
      # 2 Not to change
      # =========================      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Arbre dÃ©cisionnel â€” choix de p,d,q,P,D,Q (SARIMA)")),
        tags$div(
          style = "padding:10px 12px; background:#fff; overflow-x:auto;",
          DiagrammeR::grVizOutput("pdqpDQ_tree", height = "4000px")
        )
      ),     
      
      # =========================
      # 3 Not to change
      # =========================      
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Diagramme complet â€” StationnaritÃ© & diffÃ©renciation (ADF/KPSS/PP) + checklist Ã©tudiant")),
        tags$div(
          style = "padding:10px 12px; background:#fff; overflow-x:auto;",
          DiagrammeR::grVizOutput("stationarity_diff_workflow", height = "4000px")
        )
      ),
      
      # =========================
      # 4 Not to change
      # =========================
      tags$details(
        class = "defs-details",
        tags$summary(tags$span("Arbre dÃ©cisionnel complet â€” diagnostics â†’ actions (Graph)")),
        tags$div(
          style = "padding:10px 12px; background:#fff;",
          DiagrammeR::grVizOutput("diag_tree", height = "2000px")
        )
      ),
      
      # # =========================
      # # 5 Not to change
      # # =========================     
      # tags$details(
      #   class = "defs-details",
      #   tags$summary(tags$span("Arbre dÃ©cisionnel â€” stationnaritÃ© & diffÃ©renciation (ADF/KPSS/PP)")),
      #   tags$div(
      #     style = "padding:10px 12px; background:#fff; overflow-x:auto;",
      #     DiagrammeR::grVizOutput("stationarity_tree2", height = "2000px")
      #   )
      # ),
      
      # # =========================
      # # 6 Not to change
      # # =========================     
      # tags$details(
      #   class = "defs-details",
      #   tags$summary(tags$span("Arbre dÃ©cisionnel â€” stationnaritÃ© & diffÃ©renciation (ADF/KPSS/PP)")),
      #   tags$div(
      #     style = "padding:10px 12px; background:#fff; overflow-x:auto;",
      #     DiagrammeR::grVizOutput("stationarity_tree", height = "1500px")
      #   )
      # ),
      
      # # =========================
      # # 7 Not to change
      # # =========================    
      # tags$details(
      #   class = "defs-details",
      #   tags$summary(tags$span("Diagramme pÃ©dagogique â€” combiner ADF / KPSS / PP (raisonnement)")),
      #   tags$div(
      #     style = "padding:10px 12px; background:#fff; overflow-x:auto;",
      #     DiagrammeR::grVizOutput("adf_kpss_pp_tree", height = "1900px")
      #   )
      # ),
      
      # # =========================
      # # 8 Not to change
      # # =========================     
      # tags$details(
      #   class = "defs-details",
      #   tags$summary(tags$span("Diagramme complet (avec explications) â€” combiner ADF / KPSS / PP")),
      #   tags$div(
      #     style = "padding:10px 12px; background:#fff; overflow-x:auto;",
      #     DiagrammeR::grVizOutput("adf_kpss_pp_tree_full", height = "2500px")
      #   )
      # ),
      
      
    )
  })
  
  
  
  note_box <- function(items) {
    if (!isTRUE(input$show_teaching_notes)) return(NULL)
    tags$div(
      style = "background:#eef5ff;padding:10px;border-radius:6px;margin-bottom:10px;",
      tags$b("What to do:"),
      tags$ul(lapply(items, tags$li))
    )
  }

  output$step1_notes <- renderUI({ note_box(list(
    "Check the data preview; confirm correct date/value columns.",
    "Describe missingness and how you handled it.",
    "Report mean/SD and distribution shape (skewness/kurtosis)."
  ))})

  output$step2_notes <- renderUI({ note_box(list(
    "Inspect trend and seasonality in the time series plot.",
    "Use seasonal/subseries plots to justify seasonality.",
    "Use ACF/PACF to propose candidate SARIMA orders."
  ))})

  output$step3_notes <- renderUI({ note_box(list(
    "Compare additive vs multiplicative decomposition.",
    "Use STL (robust) if you suspect outliers or changing seasonality.",
    "Interpret trend/seasonal/remainder components."
  ))})

  output$step4_notes <- renderUI({ note_box(list(
    "Run stationarity tests (ADF/KPSS/PP).",
    "Use suggested differencing as hints, not rules.",
    "Preview differenced series to confirm stationarity visually."
  ))})

  output$step5_notes <- renderUI({ note_box(list(
    "Fit Auto-ARIMA as a baseline.",
    "Report selected (p,d,q)(P,D,Q)[s] and key diagnostics.",
    "Evaluate forecast accuracy on the test set (if available)."
  ))})


#===================================================================================================
  
  output$step6_notes <- renderUI({
    
    tagList(
      
      # note_box(list(
      #   "Select orders guided by ACF/PACF and differencing evidence.",
      #   "Check residual diagnostics: white-noise residuals are expected.",
      #   "Compare with Auto-ARIMA to justify your final choice.",
      #   "IMPORTANT: With a test set, the validation forecast is forced to h = test length (overlays the test period)."
      # )),
      
      # callout(
      #   tagList(
      #     tags$p(
      #       tags$h4("Boxâ€“Jenkins methodology."),
      #     ),
      #   ),
      #   title =NULL,
      #   theme = "blue",
      #   body_is_html = FALSE
      # ),
      
      
      # tags$br(),
      # tags$p(
      #         tags$h4("Boxâ€“Jenkins methodology."),
      #       ),
      
      tags$br(),
      
      tags$h4(
        style = "font-weight: bold;",
        "Boxâ€“Jenkins methodology."
      ),
      
      
      # ------------------------------------------------------------------
      # Step 1 â€” Identification
      # ------------------------------------------------------------------
      callout(
        tagList(
          tags$p(
            "In the Boxâ€“Jenkins framework, ",
            tags$b("Identification"),
            " determines the differencing and proposes candidate SARIMA orders using time plots and ACF/PACF."
          ),
          tags$ol(
            style = "padding-left:18px; line-height:1.6;",
            tags$li(
              tags$b("Stationarity & differencing: "),
              "choose transformation if needed, then set d and D to remove trend and seasonal persistence while avoiding over-differencing."
            ),
            tags$li(
              tags$b("ACF/PACF-based candidates: "),
              "propose (p, q) from early-lag behavior and (P, Q) from spikes at multiples of the seasonal period s."
            )
          )
        ),
        title = "Step 1 â€” Identification",
        theme = "indigo",
        body_is_html = FALSE
      ),
      
      # ------------------------------------------------------------------
      # Step 2 â€” Estimation
      # ------------------------------------------------------------------
      callout(
        tagList(
          tags$p(
            tags$b("Estimation"),
            " fits candidate SARIMA models and compares them using parameter plausibility and information criteria."
          ),
          tags$ol(
            style = "padding-left:18px; line-height:1.6;",
            tags$li(
              tags$b("Fit candidates: "),
              "estimate parameters (typically by maximum likelihood) for a small, interpretable set of models."
            ),
            tags$li(
              tags$b("Compare fit: "),
              "use AIC, AICc, or BIC to eliminate clearly inferior or unstable specifications."
            )
          )
        ),
        title = "Step 2 â€” Estimation",
        theme = "teal",
        body_is_html = FALSE
      ),
      
      # ------------------------------------------------------------------
      # Step 3 â€” Diagnostic checking
      # ------------------------------------------------------------------
      callout(
        tagList(
          tags$p(
            tags$b("Diagnostic checking"),
            " validates whether residuals behave approximately like white noise (no remaining structure)."
          ),
          tags$ol(
            style = "padding-left:18px; line-height:1.6;",
            tags$li(
              tags$b("Autocorrelation: "),
              "inspect residual ACF/PACF and Ljungâ€“Box p-values across lags."
            ),
            tags$li(
              tags$b("Distribution: "),
              "examine residual histograms with normal overlays and Qâ€“Q plots; support with tests if needed."
            ),
            tags$li(
              tags$b("Variance: "),
              "check for ARCH effects; consider a GARCH extension if conditional heteroskedasticity is detected."
            )
          )
        ),
        title = "Step 3 â€” Diagnostic checking",
        theme = "amber",
        body_is_html = FALSE
      ),
      
      # ------------------------------------------------------------------
      # Step 4 â€” Forecasting & validation
      # ------------------------------------------------------------------
      callout(
        tagList(
          tags$p(
            tags$b("Forecasting & validation"),
            " provides final confirmation using holdout accuracy and forecast stability."
          ),
          tags$ol(
            style = "padding-left:18px; line-height:1.6;",
            tags$li(
              tags$b("Forecast: "),
              "generate forecasts from the final selected SARIMA model."
            ),
            tags$li(
              tags$b("Validate: "),
              "evaluate accuracy on the test set (if available) and confirm stable prediction intervals."
            )
          )
        ),
        title = "Step 4 â€” Forecasting & validation",
        theme = "blue",
        body_is_html = FALSE
      ),
      
      tags$br(), tags$br(),tags$br(),
      
    )
  })
  
  
  
  
  
  output$step7_notes <- renderUI({ note_box(list(
    "Compare models using AICc/BIC and test-set accuracy (if available).",
    "Use Methods/Results drafts as a starting point; edit for your dataset.",
    "Use the Checklist to avoid common reporting omissions."
  ))})

  output$paper_checklist_ui <- renderUI({
    tags$div(
      tags$h4("Paper checklist (SARIMA reporting essentials)"),
      tags$ul(
        tags$li("Data: variable, unit, frequency, time range, N."),
        tags$li("Missing values: amount and handling approach."),
        tags$li("Exploration: plots + seasonality indicators + ACF/PACF rationale."),
        tags$li("Stationarity: ADF/KPSS/PP results and differencing decisions."),
        tags$li("Model: (p,d,q)(P,D,Q)[s], software, estimation method."),
        tags$li("Diagnostics: Ljung-Box (+ normality/ARCH if reported)."),
        tags$li("Forecast evaluation: horizon, metrics, interpretation.")
      )
    )
  })

  # ---- Data ingest ----

  raw_data <- reactive({
    req(input$fileData)
    ext <- tolower(tools::file_ext(input$fileData$name))
    if (ext == "csv") {
      read.csv(input$fileData$datapath, stringsAsFactors = FALSE, check.names = FALSE)
    } else if (ext %in% c("xls", "xlsx")) {
      validate(need(has_pkg("readxl"), "Install package 'readxl' to read Excel files."))
      readxl::read_excel(input$fileData$datapath)
    } else {
      validate("Unsupported file type. Use CSV or XLSX.")
    }
  })

  output$dateColUI <- renderUI({
    req(raw_data())
    cols <- names(raw_data())
    selectInput("dateCol", "Date column", choices = cols, selected = cols[1])
  })

  output$valueColUI <- renderUI({
    req(raw_data())
    cols <- names(raw_data())
    selectInput("valueCol", "Value column", choices = cols, selected = cols[min(2, length(cols))])
  })

  
  # ============================================================
  # --- MOD: Use robust date parsing inside prepared() ---
  # ============================================================
  
  prepared <- reactive({
    req(raw_data(), input$dateCol, input$valueCol)
    
    f  <- freq_value(input)
    by <- freq_to_by(f)
    
    df <- raw_data()
    
    # --- Robust conversion to Date ---
    d <- parse_dates(df[[input$dateCol]], by_hint = by)
    
    # --- Debug: show a few unparsed values (small sample only) ---
    bad <- which(is.na(d) & !is.na(df[[input$dateCol]]))
    if (length(bad) > 0) {
      cat("[prepared] Unparsed date values (first 30):\n")
      print(head(df[[input$dateCol]][bad], 30))
    }
    
    # --- Guardrail: detect bogus dates like year 0002, 0012, etc. ---
    is_bad_year <- function(dd) {
      ok <- !is.na(dd)
      if (!any(ok)) return(TRUE)
      yy <- suppressWarnings(as.integer(format(dd[ok], "%Y")))
      all(!is.finite(yy)) || median(yy, na.rm = TRUE) < 1900 || median(yy, na.rm = TRUE) > 2100
    }
    
    bad_dates <- is_bad_year(d)
    
    # If dates look bogus, switch to index mode (do NOT pretend itâ€™s Date)
    if (isTRUE(bad_dates)) {
      by <- NULL
    }
    
    # --- Value column ---
    y <- suppressWarnings(as.numeric(df[[input$valueCol]]))
    
    # Keep only rows with valid dates (or if by == NULL, we still keep date NA rows out)
    keep <- !is.na(d)
    df2 <- data.frame(date = as.Date(d[keep]), y_raw = y[keep], stringsAsFactors = FALSE)
    
    # Sort by date
    df2 <- df2[order(df2$date), , drop = FALSE]
    
    # --- FIX: Collapse duplicate dates (prevents vertical spikes in geom_line) ---
    dup_n <- sum(duplicated(df2$date))
    if (dup_n > 0) {
      cat("[prepared] Duplicate dates detected:", dup_n, " (collapsing to one value per date)\n")
      
      # Show a small sample of duplicated dates
      dup_dates <- unique(df2$date[duplicated(df2$date)])
      print(head(dup_dates, 20))
      
      # Choose aggregation method:
      # - mean = typical for measurements
      # - sum  = totals like sales/volume per day
      # - last = last observation per day (needs original ordering)
      df2 <- aggregate(
        y_raw ~ date,
        data = df2,
        FUN = function(v) mean(v, na.rm = TRUE)
      )
      
      # Keep sorted after aggregation
      df2 <- df2[order(df2$date), , drop = FALSE]
    }
    
    # --- Align to regular calendar grid (only when weâ€™re in Date mode) ---
    if (isTRUE(input$align_regular) && !is.null(by)) {
      grid <- make_regular_grid(df2$date, by = by)
      df2  <- merge(data.frame(date = grid), df2, by = "date", all.x = TRUE, sort = TRUE)
    }
    
    # --- Missing handling + transform ---
    df2$y_filled <- fill_missing(df2$y_raw, input$missing_policy, f)
    
    df2$y_trans <- tryCatch(
      apply_transform(df2$y_filled, input$transform, input$lambda),
      error = function(e) { validate(e$message); df2$y_filled }
    )
    
    # --- X axis ---
    if (!is.null(by)) {
      df2$x <- df2$date
      x_label <- "Date"
    } else {
      df2$x <- seq_len(nrow(df2))
      x_label <- "Index"
    }
    
    list(df = df2, freq = f, by = by, x_label = x_label)
  })
  
  

  # ============================================================
  # --- MOD: Fix Train split = 100% (no test set) bug in ts_train_test() ---
  # Reason: ts(numeric(0)) is invalid in R ("ts must have at least one observation")
  # Fix: store ts_test = NULL when there is no test set, and guard all downstream uses.
  # ============================================================
  ts_train_test <- reactive({
    p <- prepared()
    df <- p$df
    
    ok <- is.finite(df$y_trans)
    dfm <- df[ok, , drop = FALSE]
    validate(need(nrow(dfm) >= 10, "Not enough valid observations after cleaning."))
    
    train_n <- max(2, floor(nrow(dfm) * as.numeric(input$train_prop)))
    train_n <- min(train_n, nrow(dfm)) # MOD: hard cap so train_n never exceeds n
    
    y_tr <- dfm$y_trans[seq_len(train_n)]
    y_te <- if (train_n < nrow(dfm)) dfm$y_trans[(train_n + 1):nrow(dfm)] else numeric(0)
    
    list(
      dfm = dfm,
      train_n = train_n,
      test_n = length(y_te),
      ts_train = ts(y_tr, start = 1, frequency = p$freq),
      
      # --- MOD: when test is empty, keep it NULL (do NOT create ts(numeric(0))) ---
      ts_test = if (length(y_te) > 0) {
        ts(y_te, start = train_n + 1, frequency = p$freq)
      } else {
        NULL
      }
    )
  })
  
  # ============================================================
  # --- MOD: Helper to safely reconstruct the full series (train + test) ---
  # Used in plots requiring the full observed sample.
  # ============================================================
  full_ts <- function(s) {
    if (!is.null(s$ts_test) && length(s$ts_test) > 0) {
      ts(
        c(as.numeric(s$ts_train), as.numeric(s$ts_test)),
        start = 1,
        frequency = frequency(s$ts_train)
      )
    } else {
      s$ts_train
    }
  }
  
  # ============================================================
  # --- MOD: Replace all "ts(c(train, test))" calls by full_ts(s) ---
  # This prevents errors when train_prop = 1 (test set absent).
  # ============================================================
  
  output$season_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Seasonal plots need frequency >= 2."))
    forecast::seasonplot(x, s = frequency(x))
  })
  
  output$subseries_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Subseries plot needs frequency >= 2."))
    forecast::ggsubseriesplot(x) + theme_minimal()
  })
  
  output$decomp_add <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    plot(decompose(x, type = "additive"))
  })
  
  output$decomp_mult <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    validate(need(all(x > 0, na.rm = TRUE), "Multiplicative decomposition requires strictly positive values."))
    plot(decompose(x, type = "multiplicative"))
  })
  
  output$diff_suggestion <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    x <- full_ts(s) # MOD
    d_rec <- tryCatch(forecast::ndiffs(x), error = function(e) NA_integer_)
    D_rec <- tryCatch(forecast::nsdiffs(x), error = function(e) NA_integer_)
    cat("Suggested differencing (heuristics):\n")
    cat("- ndiffs (d):", d_rec, "\n")
    cat("- nsdiffs (D):", D_rec, "\n")
  })
  
  
  
  # ---- Step 1 outputs ----
  
  
  # ============================================================
  # --- MOD: display Date columns as readable strings in the preview table ---
  # ============================================================
  

  output$full_data_table <- DT::renderDataTable({
    req(raw_data())
    
    df <- raw_data()
    
    # âœ… Force Date & POSIX columns to Day-Month-Year
    for (nm in names(df)) {
      if (inherits(df[[nm]], "Date")) {
        df[[nm]] <- format(df[[nm]], "%d-%m-%Y")
      }
      if (inherits(df[[nm]], "POSIXt")) {
        df[[nm]] <- format(df[[nm]], "%d-%m-%Y %H:%M:%S")
      }
    }
    
    DT::datatable(
      df,
      rownames = FALSE,
      filter = "top",
      extensions = "Scroller",
      options = list(
        deferRender = TRUE,
        scrollX = TRUE,
        scrollY = 520,
        scroller = TRUE,
        pageLength = 25,
        lengthMenu = list(
          c(10, 25, 50, 100, -1),
          c("10", "25", "50", "100", "All")
        )
      )
    )
  })
  
  
  
  output$data_preview <- renderTable({
    req(prepared())
    # df <- head(prepared()$df, 12)
    df <- prepared()$df
    
    # MOD: ensure Date columns print nicely (Shiny sometimes prints Date as numeric)
    for (nm in intersect(c("date", "x"), names(df))) {
      if (inherits(df[[nm]], "Date")) df[[nm]] <- format(df[[nm]], "%Y-%m-%d")
    }
    
    df
  }, rownames = FALSE)
  
  output$basic_stats <- renderTable({
    req(prepared())
    basic_stats_df(prepared()$df$y_filled)
  }, rownames = FALSE)
  
  output$hist_plot <- renderPlot({
    req(prepared())
    df <- prepared()$df
    
    ggplot(df, aes(x = y_filled)) +
      geom_histogram(bins = 30) +
      theme_minimal() +
      labs(title = "Distribution (filled values)", x = "Value", y = "Count")
  })
  


  

  output$missing_text <- renderPrint({
    req(prepared())
    p <- prepared()
    df <- p$df
    n <- nrow(df)
    miss_raw <- sum(is.na(df$y_raw))
    cat("Missing values\n")
    cat("- N rows:", n, "\n")
    cat("- Missing in raw y:", miss_raw, " (", fmt_pct(miss_raw / n), ")\n", sep = "")
    cat("- Handling method:", input$missing_policy, "\n")
    cat("- Date range:", format(min(df$date)), "to", format(max(df$date)), "\n")
  })

  output$outlier_table <- renderTable({
    req(prepared())
    df <- prepared()$df
    idx <- z_outliers(df$y_filled, z_cut = 3)
    if (length(idx) == 0) return(data.frame(message = "No |z| â‰¥ 3 outliers detected (filled values)."))
    data.frame(index = idx, date = df$date[idx], value = df$y_filled[idx], stringsAsFactors = FALSE)
  }, rownames = FALSE)

  output$apa_data_paragraph <- renderPrint({
    req(prepared())
    p <- prepared()
    df <- p$df
    n <- nrow(df)
    miss_raw <- sum(is.na(df$y_raw))
    miss_pct <- miss_raw / n
    trans <- switch(input$transform, none = "no transformation", log = "a log transformation", boxcox = "a Boxâ€“Cox transformation")
    cat(
      "APA-ready paragraph (edit variable names/unit as needed):\n\n",
      "The dataset comprised ", n, " observations collected from ", format(min(df$date)), " to ", format(max(df$date)), ". ",
      "Missing values were present in ", miss_raw, " observations (", fmt_pct(miss_pct), "). ",
      "Missingness was handled using the ", input$missing_policy, " approach. ",
      "Prior to modeling, ", trans, " was applied to the series when appropriate.\n",
      sep = ""
    )
  })

  # ---- Step 2 outputs ----
  
  output$plot_series <- renderPlot(
    {
      req(prepared(), ts_train_test())
      p <- prepared()
      s <- ts_train_test()
      df <- s$dfm
      df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test/Future")
      
      ggplot(df, aes(x = x, y = y_trans, color = set)) +
        geom_line(linewidth = 0.9) +
        theme_minimal() +
        labs(
          title = "Time series (transformed)",
          x = p$x_label,
          y = "Value",
          color = NULL
        ) +
        theme(legend.position = "bottom")
    },
    width = 1000,
    height = 650
  )


  output$acf_plot <- renderPlot({ req(ts_train_test()); x <- ts_train_test()$ts_train; plot(acf(x, lag.max = min(60, length(x) - 1)), main = "ACF (training)") })
  output$pacf_plot <- renderPlot({ req(ts_train_test()); x <- ts_train_test()$ts_train; plot(pacf(x, lag.max = min(60, length(x) - 1)), main = "PACF (training)") })

  output$apa_explore_paragraph <- renderPrint({
    req(prepared())
    p <- prepared()
    cat(
      "APA-ready paragraph (edit based on what you observed):\n\n",
      "Visual inspection of the time series suggested the presence of trend and/or seasonal patterns. ",
      "Seasonal and subseries plots were examined to evaluate recurring periodic behavior (s = ", p$freq, "). ",
      "Autocorrelation (ACF) and partial autocorrelation (PACF) plots were inspected to inform candidate ARIMA and seasonal ARIMA orders.\n",
      sep = ""
    )
  })

  
  
  
  
  
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  
  
  
  
  
  # server.R
  # library(DiagrammeR)  # ou utiliser DiagrammeR:: partout
  
  
  
  output$box_jenkins_sarima <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
digraph box_jenkins_sarima {

  graph [layout = dot, rankdir = TB, fontsize = 18, labelloc = t,
         label = 'MÃ©thode de Boxâ€“Jenkins pour SARIMA : Ã©tapes dÃ©taillÃ©es + boucle itÃ©rative',
         fontname = Helvetica, bgcolor = 'transparent',
         nodesep = 0.35, ranksep = 0.55]

  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
         fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
  edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.85]

  start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
  end   [shape = doublecircle, label = 'ModÃ¨le final\\n+ prÃ©visions\\n+ rapport', fillcolor = '#d5f5e3']

  /* ===== Phase 0: PrÃ©paration ===== */
  prep [label = '0) PrÃ©parer la sÃ©rie\\nâ€¢ dÃ©finir y_t, unitÃ©, contexte\\nâ€¢ fixer frÃ©quence & saisonnalitÃ© s\\nâ€¢ vÃ©rifier index (rÃ©gularitÃ©), manquants, outliers\\nâ€¢ (option) transformation (log/Boxâ€“Cox)',
        fillcolor = '#eaf2f8']

  split [label = '0bis) DÃ©finir la stratÃ©gie dâ€™Ã©valuation\\nâ€¢ split temporel ou rolling-origin\\nâ€¢ choisir horizon h\\nâ€¢ dÃ©finir benchmark (naÃ¯f / drift / SNAIVE)',
         fillcolor = '#eaf2f8']

  /* ===== Phase 1: Identification ===== */
  id_title [label = '1) IDENTIFICATION (Boxâ€“Jenkins)\\nObjectif : stationnariser + proposer (p,d,q)(P,D,Q)[s]',
            fillcolor = '#d6eaf8']

  station [label = '1a) StationnaritÃ© & diffÃ©renciation\\nâ€¢ EDA + ACF : tendance / saison\\nâ€¢ tests : ADF / KPSS / PP\\nâ€¢ proposer d puis D progressivement\\nâ€¢ retester aprÃ¨s chaque transformation',
           fillcolor = '#ecf0f1']

  overdiff [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
            label = 'Sur-diffÃ©renciation ?\\nACF lag 1 trÃ¨s nÃ©gative\\nvariance gonflÃ©e\\ndynamique artificielle']
  overAct [label = 'Action\\nâ€¢ rÃ©duire d ou D\\nâ€¢ reconsidÃ©rer drift/trend\\nâ€¢ prÃ©fÃ©rer tendance dÃ©terministe si appropriÃ©',
           fillcolor = '#f9e79f']

  acfpacf [label = '1b) ACF/PACF sur sÃ©rie diffÃ©renciÃ©e\\nâ€¢ lags courts â†’ p,q\\nâ€¢ lags s,2s,â€¦ â†’ P,Q\\nâ€¢ proposer 3â€“8 candidats parcimonieux',
           fillcolor = '#ecf0f1']

  /* ===== Phase 2: Estimation ===== */
  est_title [label = '2) ESTIMATION\\nObjectif : ajuster les candidats et comparer (AICc/BIC) + faisabilitÃ©',
             fillcolor = '#d6eaf8']

  fit [label = '2a) Ajuster chaque candidat\\nâ€¢ MLE ou CSS+MLE\\nâ€¢ relever : AICc/BIC, logLik, k\\nâ€¢ vÃ©rifier convergence\\nâ€¢ (si possible) stationnaritÃ©/inversibilitÃ©',
       fillcolor = '#ecf0f1']

  numprob [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
           label = 'ProblÃ¨mes dâ€™estimation ?\\n(non convergence, paramÃ¨tres extrÃªmes\\ninstabilitÃ© / non inversible)']
  numAct [label = 'Action\\nâ€¢ simplifier p/q/P/Q\\nâ€¢ revoir d/D (sur-diff ?)\\nâ€¢ traiter outliers/manquants\\nâ€¢ transformation (log/Boxâ€“Cox)\\nâ€¢ changer initialisation / mÃ©thode',
          fillcolor = '#fdebd0']

  /* ===== Phase 3: Diagnostics ===== */
  diag_title [label = '3) DIAGNOSTICS\\nObjectif : rÃ©sidus â‰ˆ bruit blanc + modÃ¨le utile en prÃ©vision',
              fillcolor = '#d6eaf8']

  resid [label = '3a) Diagnostics rÃ©siduels (bloquant)\\nâ€¢ tracer rÃ©sidus\\nâ€¢ ACF rÃ©sidus\\nâ€¢ Ljungâ€“Box (plusieurs lags)\\nAttendu : pas dâ€™autocorrÃ©lation',
         fillcolor = '#ecf0f1']

  okwn [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
        label = 'RÃ©sidus ~ bruit blanc ?\\nLjungâ€“Box non significatif\\nACF rÃ©sidus â‰ˆ 0']
  residAct [label = 'Action\\nâ€¢ ajuster p/q/P/Q\\nâ€¢ ajouter/supprimer saisonnier\\nâ€¢ revoir d/D\\nâ€¢ re-EDA : rupture/outliers\\nâ†’ retourner Ã  Identification',
            fillcolor = '#fdebd0']

  extra [label = '3b) Diagnostics additionnels (secondaire)\\nâ€¢ normalitÃ© (QQ plot, JB) : surtout pour IC/tests\\nâ€¢ hÃ©tÃ©roscÃ©dasticitÃ©/ARCH : ACF(e^2)\\nâ€¢ significativitÃ© coef : est, SE, z, p\\n  (supprimer si performance inchangÃ©e)',
         fillcolor = '#ecf0f1']

  /* ===== Phase 4: Validation / Forecast ===== */
  val_title [label = '4) VALIDATION & PRÃ‰VISION\\nObjectif : performance hors-Ã©chantillon + choix final',
             fillcolor = '#d6eaf8']

  fc [label = '4a) Ã‰valuer la prÃ©vision\\nâ€¢ sur test set : h = longueur(test)\\nâ€¢ ou rolling-origin\\nâ€¢ mÃ©triques : MAE/RMSE/MASE\\nâ€¢ comparer au benchmark',
       fillcolor = '#ecf0f1']

  better [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
          label = 'Bat le benchmark\\nET performance stable ?']
  valAct [label = 'Action\\nâ€¢ revoir candidats (parcimonie)\\nâ€¢ si aucun gain : garder benchmark\\nâ€¢ vÃ©rifier fenÃªtre, horizon, ruptures',
          fillcolor = '#fdebd0']

  choose [label = '4b) Choix final (rÃ¨gle)\\nâ€¢ garder le plus simple\\n  qui passe diagnostics\\n  ET bat le benchmark\\nâ€¢ documenter : convergence tests + graphiques + perf',
          fillcolor = '#d5f5e3']

  report [label = '5) RÃ©daction / rendu (APA)\\nâ€¢ DonnÃ©es + EDA + dÃ©composition\\nâ€¢ stationnaritÃ© (H0/Ha + rÃ©sultats)\\nâ€¢ modÃ¨les candidats + AICc/BIC\\nâ€¢ diagnostics + performance\\nâ€¢ modÃ¨le final + limites',
          fillcolor = '#eaf2f8']

  /* ===== Flow ===== */
  start -> prep -> split -> id_title -> station -> overdiff
  overdiff -> overAct [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
  overAct -> station
  overdiff -> acfpacf [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  acfpacf -> est_title -> fit -> numprob
  numprob -> numAct [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
  numAct -> acfpacf
  numprob -> diag_title [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  diag_title -> resid -> okwn
  okwn -> residAct [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
  residAct -> acfpacf
  okwn -> extra [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']

  extra -> val_title -> fc -> better
  better -> valAct [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
  valAct -> acfpacf
  better -> choose [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']

  choose -> report -> end
}
  ")
  })
  
  
  
  
  output$box_jenkins_sarima_xd <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
digraph box_jenkins_sarima_xd {

  graph [layout = dot, rankdir = TB, fontsize = 18, labelloc = t,
         label = 'MÃ©thode de Boxâ€“Jenkins pour SARIMA : diagramme extrÃªmement dÃ©taillÃ© (quoi faire, pourquoi, quoi Ã©crire)',
         fontname = Helvetica, bgcolor = 'transparent',
         nodesep = 0.32, ranksep = 0.55]

  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
         fontsize = 14, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
  edge  [fontname = Helvetica, fontsize = 12, color = '#34495e', arrowsize = 0.85]

  start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
  end   [shape = doublecircle, label = 'ModÃ¨le final\\n+ prÃ©visions\\n+ rapport', fillcolor = '#d5f5e3']

  /* ===================== PHASE 0 ===================== */
  p0 [label = 'PHASE 0 â€” PrÃ©parer & cadrer\\nBut : sâ€™assurer que la sÃ©rie est exploitable et que lâ€™Ã©valuation est correcte.\\nUne mauvaise frÃ©quence, des dates incorrectes ou une fuite temporelle rendent le SARIMA trompeur.',
      fillcolor = '#eaf2f8']

  p0a [label = '0a) VÃ©rifier les colonnes et lâ€™index temporel\\nConfirmer quelle colonne est la date et laquelle est y_t, puis vÃ©rifier lâ€™ordre chronologique.\\nUne sÃ©rie irrÃ©guliÃ¨re (pas manquÃ©s/duplicats) doit Ãªtre corrigÃ©e avant ACF/test.',
      fillcolor = '#ecf0f1']

  p0b [label = '0b) DÃ©finir la saisonnalitÃ© s (contexte + indices)\\nFixer s Ã  partir du contexte (ex. mensuel 12) puis vÃ©rifier via EDA/ACF (pics Ã  s, 2s...).\\nSi s est faux, les paramÃ¨tres saisonniers P,D,Q seront mal interprÃ©tÃ©s.',
      fillcolor = '#ecf0f1']

  p0c [label = '0c) DÃ©crire et traiter les manquants / outliers â€œgrossiersâ€\\nQuantifier k et k/n, dÃ©cider interpolation/Kalman/suppression et justifier.\\nLes outliers peuvent biaiser STL, ACF/PACF et tests ; au minimum, les documenter.',
      fillcolor = '#ecf0f1']

  p0d [label = '0d) (Option) Stabiliser la variance\\nSi la variance augmente avec le niveau, une transformation (log/Boxâ€“Cox) peut rendre la dynamique plus additive et aider lâ€™estimation.\\nÃ‰crire clairement la transformation appliquÃ©e et pourquoi.',
      fillcolor = '#ecf0f1']

  p0e [label = '0e) Choisir le protocole de validation\\nDÃ©finir split temporel ou rolling-origin, choisir horizon h et un benchmark (naÃ¯f / drift / SNAIVE).\\nLa qualitÃ© dâ€™un modÃ¨le se juge hors-Ã©chantillon, pas seulement par AICc.',
      fillcolor = '#ecf0f1']

  /* ===================== PHASE 1 ===================== */
  p1 [label = 'PHASE 1 â€” Identification (Boxâ€“Jenkins)\\nBut : rendre la sÃ©rie stationnaire (via d et D) puis proposer des candidats (p,q,P,Q) cohÃ©rents avec ACF/PACF.\\nOn vise des ordres faibles et une justification claire, pas lâ€™exhaustivitÃ©.',
      fillcolor = '#d6eaf8']

  p1a [label = '1a) EDA : sÃ©rie y_t + saisonnalitÃ© + ruptures\\nTracer y_t pour repÃ©rer tendance, saisonnalitÃ©, variance changeante et ruptures.\\nNoter des observations factuelles (dates) car elles guident d, D et les diagnostics.',
      fillcolor = '#ecf0f1']

  p1b [label = '1b) Tests de stationnaritÃ© sur la sÃ©rie brute\\nAppliquer ADF et PP (H0 : racine unitaire) et KPSS (H0 : stationnaire).\\nComme ils testent des hypothÃ¨ses inversÃ©es, on recherche la convergence plutÃ´t quâ€™une seule p-value.',
      fillcolor = '#ecf0f1']

  spec [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
        label = 'SpÃ©cification des tests (drift vs trend) change la conclusion ?\\nSi oui, il faut choisir la spÃ©cification cohÃ©rente avec lâ€™EDA et le justifier.']

  specAct [label = 'Action : comparer drift et trend\\nSi une tendance visuelle existe, inclure trend ; sinon drift/constante.\\nDocumenter ce choix : une p-value nâ€™a de sens que dans une spÃ©cification correcte.',
           fillcolor = '#f9e79f']

  p1c [label = '1c) Choisir d (diffÃ©renciation ordinaire) progressivement\\nSi non-stationnaritÃ© non saisonniÃ¨re : essayer d=1, puis retester.\\nOn sâ€™arrÃªte dÃ¨s que stationnaritÃ© â€œraisonnableâ€ est atteinte (Ã©viter d=2 sauf preuve).',
      fillcolor = '#ecf0f1']

  p1d [label = '1d) Choisir D (diffÃ©renciation saisonniÃ¨re) si nÃ©cessaire\\nSi pics ACF forts Ã  s,2s ou racine saisonniÃ¨re suspectÃ©e : essayer D=1 puis retester.\\nD=2 est rare et doit Ãªtre explicitement justifiÃ©.',
      fillcolor = '#ecf0f1']

  over [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
        label = 'Sur-diffÃ©renciation suspectÃ©e ?\\nSignes : ACF lag 1 trÃ¨s nÃ©gative, variance gonflÃ©e, dynamique artificielle.']

  overAct [label = 'Action : rÃ©duire d ou D\\nRevenir en arriÃ¨re et privilÃ©gier la diffÃ©renciation minimale.\\nSi la tendance est dÃ©terministe, envisager d=0 + terme de tendance plutÃ´t que d=1.',
           fillcolor = '#f9e79f']

  p1e [label = '1e) ACF/PACF sur la sÃ©rie aprÃ¨s d et D\\nSur lags courts : p,q ; sur lags s,2s,... : P,Q.\\nProposer 3â€“8 candidats parcimonieux en justifiant chaque terme par un motif.',
      fillcolor = '#ecf0f1']

  heur [label = 'Aide-mÃ©moire (heuristiques)\\nAR(p) : PACF â€œcoupeâ€ ; MA(q) : ACF â€œcoupeâ€ ; ARMA : dÃ©croissance des deux.\\nSaisonnier : pics PACF Ã  s â†’ P ; pics ACF Ã  s â†’ Q.',
      fillcolor = '#eaf2f8']

  /* ===================== PHASE 2 ===================== */
  p2 [label = 'PHASE 2 â€” Estimation\\nBut : ajuster les candidats et Ã©carter ceux qui sont instables ou inutiles.\\nOn compare AICc/BIC mais on exige aussi une estimation numÃ©riquement saine.',
      fillcolor = '#d6eaf8']

  p2a [label = '2a) Ajuster chaque candidat (MLE ou CSS+MLE)\\nRelever : AICc/BIC, logLik, nombre de paramÃ¨tres k, convergence.\\nUn modÃ¨le â€œmeilleur AICcâ€ mais instable ou non convergent nâ€™est pas un bon candidat.',
      fillcolor = '#ecf0f1']

  numprob [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
           label = 'ProblÃ¨mes dâ€™estimation ?\\nNon convergence, paramÃ¨tres extrÃªmes, non inversible/stationnaire, erreurs numÃ©riques.']

  numAct [label = 'Action : simplifier et stabiliser\\nRÃ©duire p/q/P/Q, vÃ©rifier d/D (sur-diff ?), traiter outliers/manquants, transformer.\\nPuis retourner Ã  lâ€™Ã©tape ACF/PACF et reformuler des candidats.',
          fillcolor = '#fdebd0']

  /* ===================== PHASE 3 ===================== */
  p3 [label = 'PHASE 3 â€” Diagnostics\\nBut : vÃ©rifier que le modÃ¨le a capturÃ© la dÃ©pendance et que les rÃ©sidus ressemblent Ã  du bruit blanc.\\nCâ€™est un critÃ¨re bloquant : sans rÃ©sidus propres, les prÃ©visions sont suspectes.',
      fillcolor = '#d6eaf8']

  p3a [label = '3a) VÃ©rification rÃ©siduelle principale (bloquante)\\nTracer rÃ©sidus, ACF des rÃ©sidus et appliquer Ljungâ€“Box Ã  plusieurs lags.\\nAttendu : pas dâ€™autocorrÃ©lation rÃ©siduelle (p-values non significatives).',
      fillcolor = '#ecf0f1']

  okwn [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
        label = 'RÃ©sidus ~ bruit blanc ?\\nACF rÃ©sidus â‰ˆ 0 + Ljungâ€“Box OK']

  p3Fail [label = 'Si Ã©chec : que faire ?\\nAjouter/retirer termes AR/MA (p,q,P,Q), reconsidÃ©rer d/D, revoir saisonnalitÃ© s.\\nToujours rÃ©-EDA : une rupture/outlier non traitÃ© peut crÃ©er de fausses autocorrÃ©lations.',
        fillcolor = '#fdebd0']

  p3b [label = '3b) Diagnostics additionnels (secondaires)\\nNormalitÃ© (QQ/JB) : surtout pour IC/tests, moins critique pour point forecast.\\nARCH/hÃ©tÃ©roscÃ©dasticitÃ© : regarder ACF(res^2) ; si fort, discuter variance conditionnelle.',
      fillcolor = '#ecf0f1']

  /* ===================== PHASE 4 ===================== */
  p4 [label = 'PHASE 4 â€” Validation & prÃ©vision\\nBut : vÃ©rifier lâ€™utilitÃ© rÃ©elle du modÃ¨le en prÃ©vision (hors-Ã©chantillon).\\nOn retient le plus simple qui passe diagnostics ET bat le benchmark de maniÃ¨re stable.',
      fillcolor = '#d6eaf8']

  p4a [label = '4a) Ã‰valuer la prÃ©cision hors-Ã©chantillon\\nSur test set : la prÃ©vision de validation est h = longueur(test) (recouvre tout le test).\\nOu rolling-origin : rÃ©pÃ©ter plusieurs origines pour estimer la performance moyenne.',
      fillcolor = '#ecf0f1']

  p4b [label = '4b) Comparer aux benchmarks\\nComparer MAE/RMSE/MASE au naÃ¯f/SNAIVE (selon la saison).\\nSans benchmark, on ne sait pas si SARIMA apporte une vraie valeur ajoutÃ©e.',
      fillcolor = '#ecf0f1']

  better [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
          label = 'Bat le benchmark\\nET performance stable ?']

  p4Fail [label = 'Si Ã©chec : que faire ?\\nSimplifier, changer candidats, revoir transformation, vÃ©rifier ruptures, ajuster fenÃªtre (expansive/glissante).\\nSi aucun modÃ¨le ne bat le benchmark, documenter et garder le benchmark.',
          fillcolor = '#fdebd0']

  choose [label = 'Choix final (rÃ¨gle)\\nRetenir le modÃ¨le le plus simple Ã  performance comparable.\\nJustifier par convergence : tests + graphiques + diagnostics + performance, pas AICc seul.',
          fillcolor = '#d5f5e3']

  /* ===================== PHASE 5 ===================== */
  p5 [label = 'PHASE 5 â€” RÃ©daction (APA)\\nBut : transformer les Ã©tapes en texte scientifique : MÃ©thodes (ce qui est fait) et RÃ©sultats (ce qui est observÃ©).\\nChaque dÃ©cision doit Ãªtre justifiÃ©e et reproductible (paramÃ¨tres, tests, mÃ©triques).',
      fillcolor = '#eaf2f8']

  report [label = 'Ã€ Ã©crire (structure minimale)\\nâ€¢ DonnÃ©es : n, dates, frÃ©quence, manquants, descriptifs\\nâ€¢ EDA/STL : observations + figures\\nâ€¢ StationnaritÃ© : H0/Ha + rÃ©sultats + (d,D)\\nâ€¢ ModÃ¨les : candidats + AICc/BIC\\nâ€¢ Diagnostics : Ljungâ€“Box + ACF rÃ©sidus\\nâ€¢ PrÃ©vision : protocole + mÃ©triques + benchmark\\nâ€¢ ModÃ¨le final : justification + limites',
      fillcolor = '#eaf2f8']


  /* ===================== FLOW ===================== */
  start -> p0 -> p0a -> p0b -> p0c -> p0d -> p0e -> p1

  p1 -> p1a -> p1b -> spec
  spec -> specAct [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
  specAct -> p1b
  spec -> p1c [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  p1c -> p1d -> over
  over -> overAct [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
  overAct -> p1c
  over -> p1e [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  p1e -> heur -> p2 -> p2a -> numprob
  numprob -> numAct [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
  numAct -> p1e
  numprob -> p3 [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  p3 -> p3a -> okwn
  okwn -> p3Fail [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
  p3Fail -> p1e
  okwn -> p3b [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']

  p3b -> p4 -> p4a -> p4b -> better
  better -> p4Fail [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
  p4Fail -> p1e
  better -> choose [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']

  choose -> p5 -> report -> end
}
  ")
  })
  
  
  
  
  output$box_jenkins_sarima_ultra <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
digraph box_jenkins_sarima_ultra {

  graph [layout = dot, rankdir = TB, fontsize = 18, labelloc = t,
         label = 'Boxâ€“Jenkins SARIMA â€” ultra dÃ©taillÃ© (micro-Ã©tapes, figures, gabarits APA, transformation, racine saisonniÃ¨re/HEGY)',
         fontname = Helvetica, bgcolor = 'transparent',
         nodesep = 0.30, ranksep = 0.52]

  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
         fontsize = 12, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.15]
  edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.85]

  start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
  end   [shape = doublecircle, label = 'ModÃ¨le final\\n+ prÃ©visions\\n+ rapport APA', fillcolor = '#d5f5e3']

  /* ===================== PHASE 0 ===================== */
  p0 [label = 'PHASE 0 â€” PrÃ©parer & cadrer\\nObjectif : Ã©viter les erreurs â€œamontâ€ (dates, frÃ©quence, fuite temporelle) qui invalident SARIMA.\\nÃ€ ce stade, on dÃ©crit la sÃ©rie, sa frÃ©quence, et on prÃ©pare lâ€™Ã©valuation.',
      fillcolor = '#eaf2f8']

  p0a [label = '0a) VÃ©rifier lâ€™index temporel\\nConfirmer colonnes date/valeur, ordre chronologique, cadence rÃ©guliÃ¨re.\\nCorriger pas manquÃ©s/duplicats et fuseau/DST si sÃ©rie horaire.',
      fillcolor = '#ecf0f1']
  fig0a [label = 'Figure 0a\\nâ€¢ AperÃ§u des donnÃ©es (head)\\nâ€¢ Calendrier (dÃ©but/fin)\\nâ€¢ VÃ©rif rÃ©gularitÃ© (pas/duplicats)',
          fillcolor = '#f7f9f9']
  apa0a [label = 'APA (DonnÃ©es â€” gabarit)\\nâ€œLes observations (N = {n}) couvrent la pÃ©riode {date_debut}â€“{date_fin} Ã  frÃ©quence {freq}. La variable analysÃ©e est {y} (unitÃ© : {unitÃ©}).â€',
          fillcolor = '#f7f9f9']

  p0b [label = '0b) Fixer la saisonnalitÃ© s\\nDÃ©finir s via contexte (mensuel 12, hebdo 7, etc.) et confirmer via EDA/ACF (pics Ã  s,2s,â€¦).\\nUn mauvais s fausse P,D,Q et les conclusions.',
      fillcolor = '#ecf0f1']
  fig0b [label = 'Figure 0b\\nâ€¢ SÃ©rie y_t brute\\nâ€¢ ACF (brute) avec repÃ¨re lags s,2sâ€¦\\nâ€¢ Seasonal/subseries plot (si pertinent)',
          fillcolor = '#f7f9f9']
  apa0b [label = 'APA (SaisonnalitÃ© â€” gabarit)\\nâ€œLa sÃ©rie prÃ©sente une saisonnalitÃ© de pÃ©riode s = {s}, cohÃ©rente avec {contexte}, confirmÃ©e par {figure} (pics aux lags s, 2s, â€¦).â€',
          fillcolor = '#f7f9f9']

  p0c [label = '0c) Manquants + outliers (qualitÃ©)\\nQuantifier k et k/n. Choisir interpolation/Kalman/suppression et justifier.\\nDocumenter outliers/ruptures : ils perturbent ACF/tests et lâ€™estimation.',
      fillcolor = '#ecf0f1']
  fig0c [label = 'Figure 0c\\nâ€¢ Barplot/heatmap des manquants\\nâ€¢ SÃ©rie avec points manquants/ruptures/outliers annotÃ©s',
          fillcolor = '#f7f9f9']
  apa0c [label = 'APA (Manquants â€” gabarit)\\nâ€œ{k} valeurs manquantes ({k/n}%) ont Ã©tÃ© traitÃ©es via {mÃ©thode} car {justification}. Les dates {â€¦} montrent des valeurs atypiques compatibles avec {hypothÃ¨se}.â€',
          fillcolor = '#f7f9f9']

  p0d [label = '0d) Descriptifs\\nCalculer moyenne/ET, min/max, et (option) skewness/kurtosis.\\nBut : documenter le niveau et la forme (utile pour log/Boxâ€“Cox et la discussion).',
      fillcolor = '#ecf0f1']
  tab0d [label = 'Table 0d\\nâ€¢ n, dates, frÃ©quence, s\\nâ€¢ k manquants, %\\nâ€¢ moyenne, ET, min/max\\nâ€¢ skewness/kurtosis (si rapportÃ©)',
          fillcolor = '#f7f9f9']
  apa0d [label = 'APA (Descriptifs â€” gabarit)\\nâ€œEn moyenne, y_t = {M} (ET = {SD}). La distribution est {symÃ©trique/asymÃ©trique} (skew = {â€¦}, kurtosis = {â€¦} si rapportÃ©).â€',
          fillcolor = '#f7f9f9']

  p0e [label = '0e) Protocole dâ€™Ã©valuation\\nDÃ©finir split temporel ou rolling-origin, horizon h, et un benchmark (naÃ¯f/drift/SNAIVE).\\nSans protocole OOS, on ne peut pas conclure sur la valeur prÃ©dictive.',
      fillcolor = '#ecf0f1']
  fig0e [label = 'Figure 0e\\nâ€¢ SchÃ©ma train/test (timeline)\\nâ€¢ Ou schÃ©ma rolling-origin (origines multiples)',
          fillcolor = '#f7f9f9']
  apa0e [label = 'APA (Validation â€” gabarit)\\nâ€œLa performance prÃ©dictive a Ã©tÃ© Ã©valuÃ©e via {split/rolling-origin}. Lâ€™horizon est h = {h} et le benchmark est {benchmark}.â€',
          fillcolor = '#f7f9f9']

  /* ===================== TRANSFORMATION BRANCH ===================== */
  trans0 [label = 'BRANCHE â€” Additif vs multiplicatif â†’ transformation\\nDÃ©cider si lâ€™on transforme y_t (log/Boxâ€“Cox) avant d/D.\\nObjectif : stabiliser la variance et rendre la saisonnalitÃ© plus additive.',
          fillcolor = '#d6eaf8']

  transCheck [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
              label = 'Variance augmente avec le niveau ?\\nIndices : dispersion â†‘ quand y_t â†‘\\n(amplitude saisonniÃ¨re croissante)']
  transAct1 [label = 'Action (log)\\nSi y_t > 0 et variance ~ proportionnelle au niveau : utiliser log.\\nÃ‰crire clairement : y*_t = log(y_t).',
             fillcolor = '#fdebd0']
  transAct2 [label = 'Action (Boxâ€“Cox)\\nSi besoin plus flexible : choisir Î» (par estimation)\\nBoxâ€“Cox stabilise variance; log est cas Î»=0.',
             fillcolor = '#fdebd0']
  transNo [label = 'Action (aucune transformation)\\nSi variance stable : garder niveaux.\\nÃ‰viter de transformer sans justification.',
            fillcolor = '#d5f5e3']
  figTrans [label = 'Figure (transformation)\\nâ€¢ SÃ©rie brute vs sÃ©rie transformÃ©e\\nâ€¢ Nuage niveauâ€“variance (option)\\nâ€¢ Comparaison amplitude saisonniÃ¨re',
            fillcolor = '#f7f9f9']
  apaTrans [label = 'APA (Transformation â€” gabarit)\\nâ€œUne transformation {log/Boxâ€“Cox (Î»={Î»})} a Ã©tÃ© appliquÃ©e afin de stabiliser la variance, car {indice empirique}.â€',
            fillcolor = '#f7f9f9']

  /* ===================== PHASE 1 IDENTIFICATION ===================== */
  p1 [label = 'PHASE 1 â€” Identification (Boxâ€“Jenkins)\\nBut : obtenir une sÃ©rie stationnaire (choisir d et D) puis proposer des candidats (p,q,P,Q) cohÃ©rents avec ACF/PACF.\\nOn procÃ¨de progressivement et on documente chaque dÃ©cision.',
      fillcolor = '#d6eaf8']

  eda1 [label = '1a) EDA ciblÃ©e\\nTracer y_t (ou y*_t). RepÃ©rer tendance, saisonnalitÃ©, ruptures/outliers.\\nCes observations guident le choix de drift/trend dans les tests et la nÃ©cessitÃ© de D.',
        fillcolor = '#ecf0f1']
  fig1a [label = 'Figure 1a\\nâ€¢ SÃ©rie (brute ou transformÃ©e)\\nâ€¢ Zoom sur pÃ©riodes suspectes\\nâ€¢ Plots saisonniers/subseries',
          fillcolor = '#f7f9f9']
  apa1a [label = 'APA (EDA â€” gabarit)\\nâ€œLâ€™inspection visuelle (Figure {â€¦}) suggÃ¨re {tendance}, {saisonnalitÃ©}, et {outliers/rupture} autour de {dates}.â€',
          fillcolor = '#f7f9f9']

  tests1 [label = '1b) Tests sur la sÃ©rie (brute/transformÃ©e)\\nADF & PP : H0 = racine unitaire (non-stationnaire).\\nKPSS : H0 = stationnaire. On cherche convergence + cohÃ©rence avec lâ€™EDA.',
           fillcolor = '#ecf0f1']
  tab1b [label = 'Table 1b\\nâ€¢ ADF : stat, p, spÃ©cification (drift/trend)\\nâ€¢ PP : stat, p\\nâ€¢ KPSS : stat, p\\nâ€¢ commentaire court (sens)',
           fillcolor = '#f7f9f9']
  apa1b [label = 'APA (Tests â€” gabarit)\\nâ€œADF/PP testent H0=racine unitaire, tandis que KPSS teste H0=stationnaire. Les rÃ©sultats indiquent {stationnaire / non-stationnaire / ambigu} (Table {â€¦}).â€',
           fillcolor = '#f7f9f9']

  spec [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
        label = 'Les conclusions changent\\nselon drift vs trend ?']
  specAct [label = 'Action\\nChoisir la spÃ©cification cohÃ©rente avec lâ€™EDA :\\nâ€¢ tendance visible â†’ trend\\nâ€¢ sinon â†’ drift/constante\\nDocumenter le choix.',
           fillcolor = '#f9e79f']
  figSpec [label = 'Figure (support spec)\\nâ€¢ SÃ©rie avec tendance\\nâ€¢ Comparaison drift vs trend (rÃ©sumÃ©)',
           fillcolor = '#f7f9f9']
  apaSpec [label = 'APA (Spec â€” gabarit)\\nâ€œLa spÃ©cification {trend/drift} a Ã©tÃ© retenue car {justification EDA}. Les conclusions des tests sont {stables/sensibles} Ã  ce choix.â€',
           fillcolor = '#f7f9f9']

  dChoice [label = '1c) Choisir d progressivement\\nSi non-stationnaritÃ© non saisonniÃ¨re : essayer d=1, puis retester.\\nBut : retirer la racine unitaire sans crÃ©er de dynamique artificielle.',
           fillcolor = '#ecf0f1']
  figD [label = 'Figure 1c\\nâ€¢ SÃ©rie aprÃ¨s d=1\\nâ€¢ ACF/PACF aprÃ¨s d=1',
         fillcolor = '#f7f9f9']
  apaD [label = 'APA (d â€” gabarit)\\nâ€œUne diffÃ©renciation ordinaire (d={d}) a Ã©tÃ© appliquÃ©e car {raison}. La sÃ©rie diffÃ©renciÃ©e apparaÃ®t {plus stationnaire} (Figure {â€¦}, Table {â€¦}).â€',
         fillcolor = '#f7f9f9']

  /* ===== SEASONAL ROOT BRANCH (D + HEGY) ===== */
  seasRoot [label = 'BRANCHE â€” Racine unitaire saisonniÃ¨re (choix de D)\\nObjectif : dÃ©cider si une diffÃ©renciation saisonniÃ¨re D est nÃ©cessaire.\\nOn combine indices ACF aux lags s,2s,â€¦ + tests + (annexe) HEGY.',
            fillcolor = '#d6eaf8']

  seasCheck [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
             label = 'Indices de racine saisonniÃ¨re ?\\nACF forte Ã  s,2s,â€¦\\nSaisonnalitÃ© â€œstochastiqueâ€\\n(amplitude/phase qui dÃ©rive)']
  doD1 [label = 'Action\\nAppliquer D=1 : Î”_s y_t = y_t âˆ’ y_{tâˆ’s}.\\nPuis retester (ADF/PP/KPSS) sur la sÃ©rie transformÃ©e.',
         fillcolor = '#fdebd0']
  figSeas [label = 'Figure (D)\\nâ€¢ ACF avant/aprÃ¨s D=1 (pics Ã  s)\\nâ€¢ SÃ©rie aprÃ¨s D=1\\nâ€¢ Seasonal plot (comparatif)',
           fillcolor = '#f7f9f9']
  apaSeas [label = 'APA (D â€” gabarit)\\nâ€œUne diffÃ©renciation saisonniÃ¨re (D={D}, s={s}) a Ã©tÃ© appliquÃ©e car {indice ACF/EDA}. AprÃ¨s transformation, la stationnaritÃ© est {plus plausible} (Table/Figure â€¦).â€',
           fillcolor = '#f7f9f9']

  hegy [label = 'Annexe (option) : HEGY\\nTest dÃ©diÃ© aux racines saisonniÃ¨res (selon s, ex. 4 ou 12).\\nUtile si ACF saisonniÃ¨re forte et rÃ©sultats ADF/KPSS/PP ambigus.',
        fillcolor = '#f4ecf7']
  apaHegy [label = 'APA (HEGY â€” gabarit, annexe)\\nâ€œUn test HEGY a Ã©tÃ© rÃ©alisÃ© en annexe pour Ã©valuer des racines saisonniÃ¨res. Les rÃ©sultats {soutiennent/ne soutiennent pas} la prÃ©sence dâ€™une racine saisonniÃ¨re.â€',
           fillcolor = '#f7f9f9']

  /* ===== Over-differencing ===== */
  over [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
        label = 'Sur-diffÃ©renciation ?\\nACF lag1 trÃ¨s nÃ©gative\\nvariance gonflÃ©e\\nprÃ©visions instables']
  overAct [label = 'Action\\nRÃ©duire d ou D et revenir Ã  la derniÃ¨re version â€œsaineâ€.\\nSi tendance dÃ©terministe plausible, prÃ©fÃ©rer d=0 + tendance plutÃ´t que d=1.',
           fillcolor = '#f9e79f']
  figOver [label = 'Figure (sur-diff)\\nâ€¢ ACF lag1 trÃ¨s nÃ©gative\\nâ€¢ Comparaison sÃ©rie diff vs non diff\\nâ€¢ RÃ©sidus/variance',
           fillcolor = '#f7f9f9']
  apaOver [label = 'APA (sur-diff â€” gabarit)\\nâ€œUne sur-diffÃ©renciation a Ã©tÃ© suspectÃ©e (ACF lag1 trÃ¨s nÃ©gative). Nous avons retenu {d,D} plus parcimonieux pour Ã©viter une dynamique artificielle.â€',
           fillcolor = '#f7f9f9']

  /* ===== Identify p,q,P,Q ===== */
  pq [label = '1d) Identifier p,q,P,Q (aprÃ¨s d et D)\\nTracer ACF/PACF sur la sÃ©rie stationnaire.\\nProposer 3â€“8 candidats parcimonieux et justifier chaque terme (y compris aux multiples de s).',
       fillcolor = '#ecf0f1']
  figPQ [label = 'Figure 1d\\nâ€¢ ACF/PACF aprÃ¨s (d,D)\\nâ€¢ repÃ¨res lags s,2s,â€¦\\nâ€¢ annotation des pics significatifs',
         fillcolor = '#f7f9f9']
  apaPQ [label = 'APA (candidats â€” gabarit)\\nâ€œÃ€ partir des motifs ACF/PACF (Figure â€¦), nous avons proposÃ© {K} modÃ¨les candidats SARIMA : {liste}. Les ordres {p,q,P,Q} sont motivÃ©s par {pics/coupures}.â€',
         fillcolor = '#f7f9f9']

  /* ===================== PHASE 2 ESTIMATION ===================== */
  p2 [label = 'PHASE 2 â€” Estimation\\nAjuster chaque candidat et comparer AICc/BIC, tout en exigeant une estimation stable (convergence).\\nAICc aide Ã  filtrer, mais ne remplace pas diagnostics et performance.',
      fillcolor = '#d6eaf8']

  fit [label = '2a) Ajuster candidats (MLE ou CSS+MLE)\\nCollecter : AICc/BIC, logLik, k, convergence.\\nNoter les coefficients (est, SE, z, p) pour lâ€™interprÃ©tation (avec prudence).',
       fillcolor = '#ecf0f1']
  tabFit [label = 'Table 2a (candidats)\\nâ€¢ (p,d,q)(P,D,Q)[s]\\nâ€¢ AICc, BIC, k\\nâ€¢ convergence OK ?\\nâ€¢ Ljungâ€“Box p (prÃ©liminaire)\\nâ€¢ MAE/RMSE (si test set)',
          fillcolor = '#f7f9f9']
  apaFit [label = 'APA (estimation â€” gabarit)\\nâ€œNous avons ajustÃ© {K} modÃ¨les SARIMA. Le tableau {â€¦} prÃ©sente AICc/BIC et le nombre de paramÃ¨tres. Les modÃ¨les non convergents ont Ã©tÃ© exclus.â€',
          fillcolor = '#f7f9f9']

  numprob [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
           label = 'ProblÃ¨mes dâ€™estimation ?\\nNon convergence / paramÃ¨tres extrÃªmes\\nNon inversible/stationnaire']
  numAct [label = 'Action\\nSimplifier p/q/P/Q, revoir d/D (sur-diff?), traiter outliers/manquants, transformation.\\nPuis revenir Ã  lâ€™identification et reformuler des candidats.',
          fillcolor = '#fdebd0']
  apaNum [label = 'APA (problÃ¨me estimation â€” gabarit)\\nâ€œCertains modÃ¨les ont montrÃ© une instabilitÃ© (non convergence / non-inversibilitÃ©). Ils ont Ã©tÃ© Ã©cartÃ©s au profit de spÃ©cifications plus parcimonieuses.â€',
          fillcolor = '#f7f9f9']

  /* ===================== PHASE 3 DIAGNOSTICS ===================== */
  p3 [label = 'PHASE 3 â€” Diagnostics\\nCritÃ¨re bloquant : rÃ©sidus â‰ˆ bruit blanc.\\nSi les rÃ©sidus conservent de lâ€™autocorrÃ©lation, le modÃ¨le nâ€™a pas capturÃ© la dÃ©pendance.',
      fillcolor = '#d6eaf8']

  resid [label = '3a) Diagnostics rÃ©siduels principaux\\nTracer rÃ©sidus + ACF rÃ©sidus. Appliquer Ljungâ€“Box Ã  plusieurs lags.\\nAttendu : pas de structure rÃ©siduelle (p-values non significatives).',
         fillcolor = '#ecf0f1']
  figRes [label = 'Figure 3a\\nâ€¢ RÃ©sidus vs temps\\nâ€¢ ACF rÃ©sidus\\nâ€¢ (option) histogramme/Q-Q',
          fillcolor = '#f7f9f9']
  apaRes [label = 'APA (diagnostics â€” gabarit)\\nâ€œLes rÃ©sidus du modÃ¨le {â€¦} ne montrent pas dâ€™autocorrÃ©lation significative (Ljungâ€“Box : p = {â€¦}; Figure â€¦), suggÃ©rant un bruit blanc.â€',
          fillcolor = '#f7f9f9']

  okwn [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
        label = 'RÃ©sidus ~ bruit blanc ?\\nACF â‰ˆ 0\\nLjungâ€“Box OK']
  fixRes [label = 'Si non : quoi faire ?\\nAjouter/retirer AR/MA (p,q,P,Q), ajuster saisonnier, revoir d/D, re-EDA (rupture/outliers).\\nPuis rÃ©-estimer et re-tester.',
           fillcolor = '#fdebd0']
  apaFix [label = 'APA (si Ã©chec â€” gabarit)\\nâ€œDes autocorrÃ©lations rÃ©siduelles ont Ã©tÃ© dÃ©tectÃ©es. Nous avons ajustÃ© la structure AR/MA et rÃ©Ã©valuÃ© la stationnaritÃ© (d,D) avant de rÃ©-estimer.â€',
          fillcolor = '#f7f9f9']

  extra [label = '3b) Diagnostics additionnels (secondaires)\\nNormalitÃ© (QQ/JB) : surtout pour IC/tests.\\nARCH : ACF(res^2) ; si fort â†’ discuter modÃ¨les de variance.\\nSignificativitÃ© : rapporter estÂ±SE, z, p (sans supprimer aveuglÃ©ment).',
         fillcolor = '#ecf0f1']
  figExtra [label = 'Figure 3b (option)\\nâ€¢ Q-Q plot\\nâ€¢ ACF(res^2)\\nâ€¢ Tableau coefficients (est, SE, z, p)',
            fillcolor = '#f7f9f9']
  apaExtra [label = 'APA (diag secondaires â€” gabarit)\\nâ€œLes diagnostics secondaires (normalitÃ©/ARCH) sont discutÃ©s en complÃ©ment. Ils sont surtout pertinents pour les intervalles de prÃ©vision, moins pour la prÃ©vision ponctuelle.â€',
            fillcolor = '#f7f9f9']

  /* ===================== PHASE 4 VALIDATION ===================== */
  p4 [label = 'PHASE 4 â€” Validation & prÃ©vision\\nComparer la prÃ©cision hors-Ã©chantillon (test/rolling-origin) et choisir le modÃ¨le final.\\nRÃ¨gle : plus simple modÃ¨le qui passe diagnostics et bat le benchmark.',
      fillcolor = '#d6eaf8']

  eval [label = '4a) Ã‰valuer la prÃ©cision\\nSi test set : validation forecast forcÃ©e h = longueur(test) (recouvre tout le test).\\nSinon : rolling-origin pour performance moyenne.',
        fillcolor = '#ecf0f1']
  figEval [label = 'Figure 4a\\nâ€¢ PrÃ©visions vs test (overlay)\\nâ€¢ Ou courbe erreurs rolling-origin\\nâ€¢ IC 80/95% si demandÃ©',
           fillcolor = '#f7f9f9']
  apaEval [label = 'APA (Ã©valuation â€” gabarit)\\nâ€œLa prÃ©cision a Ã©tÃ© Ã©valuÃ©e via {split/rolling-origin}. Sur test set, lâ€™horizon a Ã©tÃ© fixÃ© Ã  h={len_test} afin de recouvrir la pÃ©riode test (Figure â€¦).â€',
           fillcolor = '#f7f9f9']

  bench [label = '4b) Comparer au benchmark\\nComparer MAE/RMSE/MASE Ã  {naÃ¯f/SNAIVE}.\\nUn SARIMA nâ€™est utile que sâ€™il apporte un gain net et stable.',
         fillcolor = '#ecf0f1']
  tabBench [label = 'Table 4b\\nâ€¢ ModÃ¨le(s) final(aux) vs benchmark\\nâ€¢ MAE, RMSE, MASE\\nâ€¢ (option) Dieboldâ€“Mariano (annexe)',
            fillcolor = '#f7f9f9']
  apaBench [label = 'APA (benchmark â€” gabarit)\\nâ€œLe modÃ¨le SARIMA sÃ©lectionnÃ© amÃ©liore {mÃ©trique} par rapport au benchmark {â€¦} (Table â€¦), suggÃ©rant une valeur ajoutÃ©e prÃ©dictive.â€',
            fillcolor = '#f7f9f9']

  better [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
          label = 'Bat le benchmark\\nET performance stable ?']
  fail [label = 'Si non\\nSimplifier / revoir candidats / reconsidÃ©rer ruptures / transformation.\\nSi aucun gain : conserver benchmark et documenter.',
        fillcolor = '#fdebd0']
  apaFail [label = 'APA (si pas de gain â€” gabarit)\\nâ€œAucun modÃ¨le SARIMA nâ€™a surpassÃ© le benchmark de maniÃ¨re stable. Nous rapportons donc le benchmark comme rÃ©fÃ©rence principale et discutons les limites.â€',
           fillcolor = '#f7f9f9']

  choose [label = 'Choix final\\nRetenir le modÃ¨le le plus simple Ã  performance comparable.\\nJustifier par convergence : tests + figures + diagnostics + performance (pas AICc seul).',
          fillcolor = '#d5f5e3']
  apaChoose [label = 'APA (choix final â€” gabarit)\\nâ€œLe modÃ¨le final {SARIMA(...)} a Ã©tÃ© retenu car (i) rÃ©sidus â‰ˆ bruit blanc, (ii) performance OOS supÃ©rieure au benchmark, (iii) parcimonie.â€',
            fillcolor = '#f7f9f9']

  /* ===================== PHASE 5 REPORT ===================== */
  p5 [label = 'PHASE 5 â€” RÃ©daction (APA)\\nAssembler MÃ©thodes et RÃ©sultats. Chaque Ã©tape doit Ãªtre reproductible (paramÃ¨tres, tests, mÃ©triques).\\nLes figures/tables doivent Ãªtre rÃ©fÃ©rencÃ©es et interprÃ©tÃ©es.',
      fillcolor = '#eaf2f8']

  report [label = 'Plan minimal (Ã  livrer)\\nMÃ©thodes : donnÃ©es, transformation, tests, (d,D), candidats, estimation, protocole validation.\\nRÃ©sultats : EDA, STL (si utilisÃ©), tableaux modÃ¨les, diagnostics, performance, modÃ¨le final.\\nAnnexes : HEGY, DM test, dÃ©tails paramÃ¨tres.',
          fillcolor = '#eaf2f8']

  /* ===================== FLOW ===================== */
  start -> p0 -> p0a -> fig0a -> apa0a -> p0b -> fig0b -> apa0b -> p0c -> fig0c -> apa0c -> p0d -> tab0d -> apa0d -> p0e -> fig0e -> apa0e

  /* branch: transformation decision */
  apa0e -> trans0 -> transCheck
  transCheck -> transAct1 [label = 'Oui (log)', color = '#c0392b', fontcolor = '#c0392b']
  transCheck -> transAct2 [label = 'Oui (Boxâ€“Cox)', color = '#c0392b', fontcolor = '#c0392b']
  transCheck -> transNo   [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
  transAct1 -> figTrans -> apaTrans -> p1
  transAct2 -> figTrans -> apaTrans -> p1
  transNo   -> p1

  /* phase 1 */
  p1 -> eda1 -> fig1a -> apa1a -> tests1 -> tab1b -> apa1b -> spec
  spec -> specAct [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
  specAct -> figSpec -> apaSpec -> tests1
  spec -> dChoice [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  dChoice -> figD -> apaD -> seasRoot
  seasRoot -> seasCheck
  seasCheck -> doD1 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
  doD1 -> figSeas -> apaSeas -> hegy
  hegy -> apaHegy -> over
  seasCheck -> over [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  over -> overAct [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
  overAct -> figOver -> apaOver -> dChoice
  over -> pq [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  pq -> figPQ -> apaPQ -> p2

  /* phase 2 */
  p2 -> fit -> tabFit -> apaFit -> numprob
  numprob -> numAct [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
  numAct -> apaNum -> pq
  numprob -> p3 [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']

  /* phase 3 */
  p3 -> resid -> figRes -> apaRes -> okwn
  okwn -> fixRes [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
  fixRes -> apaFix -> pq
  okwn -> extra [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
  extra -> figExtra -> apaExtra -> p4

  /* phase 4 */
  p4 -> eval -> figEval -> apaEval -> bench -> tabBench -> apaBench -> better
  better -> fail [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
  fail -> apaFail -> pq
  better -> choose [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
  choose -> apaChoose -> p5 -> report -> end
}
  ")
  })
  
  
  
  
  
  
  output$sarima_workflow <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
digraph sarima_workflow_checklist {

  graph [rankdir=TB, bgcolor='white', fontname='Helvetica',
         labelloc=t, fontsize=16,
         label='SARIMA (workflow complet) â€” Checklist Ã©tudiante dÃ©taillÃ©e (actions + rÃ©daction + piÃ¨ges)',
         nodesep=0.28, ranksep=0.40, margin=0.02, pad=0.02];

  node  [shape=box, style='rounded,filled', color='#2c3e50', fillcolor='#f7f9fb',
         fontname='Helvetica', fontsize=11, penwidth=1.2];
  edge  [color='#34495e', fontname='Helvetica', fontsize=10, arrowsize=0.8];

  start [label='DÃ‰PART\\nObjectif : prÃ©voir y_t avec un SARIMA\\n(interprÃ©table + diagnostics OK + perf > benchmark)\\n\\nRÃ¨gle : on cherche la parcimonie + la justification (pas juste AIC)',
         fillcolor='#ecf0f1'];

  // =========================================================
  // CHECKLIST 0 â€” Protocole dâ€™Ã©valuation (avant toute chose)
  // =========================================================
  c0 [label='â˜ Ã‰tape 0 â€” Protocole (vous fixez les rÃ¨gles du jeu)\\n\\nCe que vous faites :\\n1) Fixer Î± (souvent 5%)\\n2) Fixer horizon h (ex: 12 pÃ©riodes)\\n3) Choisir benchmark : NAIVE / SNAIVE (si saisonnalitÃ©) / drift\\n4) Choisir mÃ©triques : MAE, RMSE, MASE (recommandÃ©)\\n5) Choisir validation : train/test temporel ou rolling-origin\\n\\nCe que vous Ã©crivez :\\nâ€¢ Î±, h, benchmark, mÃ©triques, mÃ©thode de validation\\n\\nPiÃ¨ges :\\nâ€¢ comparer des modÃ¨les sans benchmark\\nâ€¢ split alÃ©atoire (interdit en sÃ©ries temporelles)',
      fillcolor='#eaf2f8'];

  // =========================================================
  // CHECKLIST 1 â€” DonnÃ©es & index
  // =========================================================
  c1 [label='â˜ Ã‰tape 1 â€” DonnÃ©es & dÃ©finition de y_t\\n\\nCe que vous faites :\\n1) DÃ©finir y_t : unitÃ©, source, pÃ©riode couverte\\n2) VÃ©rifier frÃ©quence et rÃ©gularitÃ© (pas de trous â€œcachÃ©sâ€)\\n3) Fixer s (contexte + EDA) : mensuel=12, trimestriel=4â€¦\\n4) VÃ©rifier ordre, doublons, dates manquantes\\n\\nCe que vous Ã©crivez :\\nâ€¢ n, pÃ©riode [t_min, t_max], frÃ©quence, s, dÃ©finition de y_t\\n\\nPiÃ¨ges :\\nâ€¢ index irrÃ©gulier non corrigÃ©\\nâ€¢ doublons de dates (fausse saisonnalitÃ©)',
      fillcolor='#e8f8f5'];

  // =========================================================
  // CHECKLIST 2 â€” Manquants & qualitÃ©
  // =========================================================
  c2 [label='â˜ Ã‰tape 2 â€” Manquants & qualitÃ©\\n\\nCe que vous faites :\\n1) Quantifier : k manquants, k/n\\n2) DÃ©crire le pattern : isolÃ©s ? blocs ? saisonniers ?\\n3) Choisir traitement (selon contexte) :\\n   â€¢ drop (rare, si trÃ¨s peu)\\n   â€¢ interpolation linÃ©aire\\n   â€¢ imputation saisonniÃ¨re\\n   â€¢ Kalman (si dispo)\\n4) Re-tracer la sÃ©rie aprÃ¨s correction\\n\\nCe que vous Ã©crivez :\\nâ€¢ k, mÃ©thode choisie, justification + impact attendu\\n\\nPiÃ¨ges :\\nâ€¢ imputer sans le dire\\nâ€¢ combler un grand bloc sans justification',
      fillcolor='#e8f8f5'];

  // =========================================================
  // CHECKLIST 3 â€” Outliers & ruptures
  // =========================================================
  c3 [label='â˜ Ã‰tape 3 â€” Outliers & ruptures (avant dâ€™identifier p/q)\\n\\nCe que vous faites :\\n1) RepÃ©rer visuellement (pics / chutes / rupture de niveau)\\n2) Poser lâ€™hypothÃ¨se : valeur rÃ©elle ou erreur de mesure ?\\n3) DÃ©cider :\\n   â€¢ garder (si rÃ©el)\\n   â€¢ corriger/imputer (si erreur)\\n   â€¢ ajouter dummy/intervention (si choc ponctuel)\\n4) Noter lâ€™impact potentiel sur ACF/PACF et tests\\n\\nCe que vous Ã©crivez :\\nâ€¢ liste des anomalies + dÃ©cision + justification\\n\\nPiÃ¨ges :\\nâ€¢ supprimer des points â€œpour amÃ©liorer le modÃ¨leâ€\\nâ€¢ ignorer une rupture (Ã§a casse la stationnaritÃ©)',
      fillcolor='#e8f8f5'];

  // =========================================================
  // CHECKLIST 4 â€” EDA
  // =========================================================
  c4 [label='â˜ Ã‰tape 4 â€” EDA (Analyse Exploratoire des DonnÃ©es)\\n\\nCe que vous faites :\\n1) Tracer y_t et dÃ©crire : tendance, saison, cycles, volatilitÃ©\\n2) Seasonal plot / subseries plot\\n3) Boxplots par saison (variabilitÃ© par mois/trimestre)\\n4) ACF/PACF sur sÃ©rie brute (indicatif, pas dÃ©cision finale)\\n\\nCe que vous Ã©crivez :\\nâ€¢ 4 observations concrÃ¨tes (avec pÃ©riodes/dates)\\n\\nPiÃ¨ges :\\nâ€¢ sauter lâ€™EDA (on modÃ©lise alors â€œÃ  lâ€™aveugleâ€)\\nâ€¢ confondre tendance et saisonnalitÃ©',
      fillcolor='#fdebd0'];

  // =========================================================
  // CHECKLIST 5 â€” Transformation (variance)
  // =========================================================
  q_transform [shape=diamond, style='rounded,filled', fillcolor='#fef9e7',
               label='Variance augmente\\navec le niveau ?\\n(erreurs relatives\\n+ saison multiplicative)'];

  c5 [label='â˜ Ã‰tape 5 â€” Transformation (si besoin)\\n\\nPourquoi : stabiliser la variance et rendre les effets plus additifs.\\n\\nCe que vous faites :\\n1) Si variance ~ constante : pas de transformation\\n2) Si variance â†‘ avec niveau : log ou Boxâ€“Cox (Î»)\\n3) Re-tracer aprÃ¨s transformation\\n4) Noter comment interprÃ©ter (log â‡’ effets en % environ)\\n\\nCe que vous Ã©crivez :\\nâ€¢ â€œOn applique â€¦ car varianceâ€¦ (figure)â€\\n\\nPiÃ¨ges :\\nâ€¢ log sur donnÃ©es avec zÃ©ros/nÃ©gatifs sans prÃ©caution\\nâ€¢ transformer puis oublier de lâ€™expliquer',
      fillcolor='#fdebd0'];

  // =========================================================
  // CHECKLIST 6 â€” StationnaritÃ© & diffÃ©renciation (d, D)
  // =========================================================
  c6 [label='â˜ Ã‰tape 6 â€” StationnaritÃ© & choix de (d, D)\\n\\nCe que vous faites :\\n1) Tests ADF + PP + KPSS (spÃ©cification cohÃ©rente drift/trend)\\n2) VÃ©rifier saison : pics ACF Ã  s,2s,â€¦ (racine saisonniÃ¨re ?)\\n3) Si rupture suspectÃ©e : Zivotâ€“Andrews (option)\\n4) Appliquer diffÃ©renciation minimale : dâˆˆ{0,1}, Dâˆˆ{0,1}\\n5) Re-tester aprÃ¨s chaque diffÃ©renciation\\n\\nCe que vous Ã©crivez :\\nâ€¢ tableau tests + dÃ©cision d/D + figures avant/aprÃ¨s\\n\\nPiÃ¨ges :\\nâ€¢ d=2 ou D=2 sans argument\\nâ€¢ oublier de re-tester aprÃ¨s D',
      fillcolor='#fdebd0'];

  q_overdiff [shape=diamond, style='rounded,filled', fillcolor='#f5eef8',
              label='Sur-diffÃ©renciation ?\\nACF lag1 trÃ¨s nÃ©gative\\nvariance gonflÃ©e\\nprÃ©visions erratiques'];

  backtrack [label='Action si sur-diff\\nâ€¢ rÃ©duire d ou D\\nâ€¢ envisager trend dÃ©terministe\\nâ€¢ re-vÃ©rifier spÃ©cification des tests\\n\\nÃ€ Ã©crire : signe observÃ© + correction',
             fillcolor='#f5eef8'];

  // =========================================================
  // CHECKLIST 7 â€” Identification (p,q,P,Q) via ACF/PACF
  // =========================================================
  c7 [label='â˜ Ã‰tape 7 â€” Identification (p,q,P,Q)\\n\\nCe que vous faites :\\n1) Tracer ACF/PACF SUR la sÃ©rie diffÃ©renciÃ©e (aprÃ¨s d et D)\\n2) Lags courts : proposer p/q (0..2 souvent)\\n3) Lags saisonniers (s,2s,â€¦) : proposer P/Q (0..2 souvent)\\n4) Construire 3 Ã  8 candidats (baseline + variantes)\\n\\nCe que vous Ã©crivez :\\nâ€¢ hypothÃ¨ses : â€œPACF coupe â‡’ ARâ€, â€œACF coupe â‡’ MAâ€\\nâ€¢ liste candidats + justification brÃ¨ve\\n\\nPiÃ¨ges :\\nâ€¢ choisir p,q,P,Q grands â€œpar prÃ©cautionâ€\\nâ€¢ identifier sur sÃ©rie non stationnarisÃ©e',
      fillcolor='#d6eaf8'];

  // =========================================================
  // CHECKLIST 8 â€” Baseline Auto-ARIMA (benchmark SARIMA)
  // =========================================================
  c8 [label='â˜ Ã‰tape 8 â€” Baseline (Auto-ARIMA)\\n\\nPourquoi : donner un point de dÃ©part et un benchmark SARIMA.\\n\\nCe que vous faites :\\n1) Ajuster auto.arima sur la mÃªme sÃ©rie (mÃªmes d/D si imposÃ©s)\\n2) Noter AICc/BIC + ordre proposÃ©\\n3) Comparer avec vos candidats (pas remplacer la rÃ©flexion)\\n\\nCe que vous Ã©crivez :\\nâ€¢ modÃ¨le auto + critÃ¨res + comment il se compare\\n\\nPiÃ¨ges :\\nâ€¢ suivre auto-arima â€œcomme une vÃ©ritÃ©â€\\nâ€¢ comparer auto vs manuel sur des donnÃ©es diffÃ©rentes',
      fillcolor='#d6eaf8'];

  // =========================================================
  // CHECKLIST 9 â€” Estimation
  // =========================================================
  c9 [label='â˜ Ã‰tape 9 â€” Estimation des candidats\\n\\nCe que vous faites :\\n1) Estimer chaque candidat (MLE ou CSS+MLE)\\n2) Relever AICc/BIC\\n3) Noter warnings (convergence, stationnaritÃ©, inversibilitÃ©)\\n4) VÃ©rifier coefficients raisonnables (option : significativitÃ©)\\n\\nCe que vous Ã©crivez :\\nâ€¢ tableau : modÃ¨le | AICc/BIC | warnings | remarques\\n\\nPiÃ¨ges :\\nâ€¢ ignorer warnings\\nâ€¢ garder un modÃ¨le instable car AICc est â€œbeauâ€',
      fillcolor='#d6eaf8'];

  q_num [shape=diamond, style='rounded,filled', fillcolor='#f4ecf7',
         label='ProblÃ¨mes numÃ©riques ?\\n(convergence,\\nnon-inversible,\\nnon-stationnaire)'];

  act_num [label='Action si problÃ¨mes numÃ©riques\\nâ€¢ simplifier p/q/P/Q\\nâ€¢ vÃ©rifier sur-diff (d/D)\\nâ€¢ stabiliser variance (log/Boxâ€“Cox)\\nâ€¢ traiter outliers/ruptures (dummies)\\nâ€¢ changer initialisation/mÃ©thode\\n\\nÃ€ Ã©crire : problÃ¨me + correction',
           fillcolor='#f4ecf7'];

  // =========================================================
  // CHECKLIST 10 â€” Diagnostics rÃ©siduels (obligatoire)
  // =========================================================
  c10 [label='â˜ Ã‰tape 10 â€” Diagnostics rÃ©siduels (OBLIGATOIRE)\\n\\nCe que vous faites :\\n1) Tracer ACF des rÃ©sidus (doit Ãªtre ~0)\\n2) Ljungâ€“Box (p grand â‡’ pas dâ€™autocorr globale)\\n3) Option : normalitÃ© (QQ-plot)\\n4) Option : ARCH/volatilitÃ© (si variance en grappes)\\n\\nCe que vous Ã©crivez :\\nâ€¢ ACF rÃ©sidus + conclusion Ljungâ€“Box\\n\\nPiÃ¨ges :\\nâ€¢ conclure sans Ljungâ€“Box\\nâ€¢ confondre â€œrÃ©sidus petitsâ€ et â€œrÃ©sidus blancsâ€',
       fillcolor='#fadbd8'];

  q_diag_ok [shape=diamond, style='rounded,filled', fillcolor='#fef9e7',
             label='Diagnostics OK ?\\n(pas de structure\\n+ Ljungâ€“Box OK)'];

  refine [label='Action si diagnostics NOK\\nâ€¢ pics lags courts â‡’ ajuster p/q\\nâ€¢ pics Ã  s,2sâ€¦ â‡’ ajuster P/Q\\nâ€¢ structure lente â‡’ revoir d/D ou trend\\nâ€¢ re-EDA : rupture/outliers\\n\\nÃ€ Ã©crire : â€œpic observÃ© â†’ action SARIMAâ€',
          fillcolor='#fadbd8'];

  // =========================================================
  // CHECKLIST 11 â€” Validation hors-Ã©chantillon
  // =========================================================
  c11 [label='â˜ Ã‰tape 11 â€” Validation hors-Ã©chantillon\\n\\nCe que vous faites :\\n1) Train/Test temporel ou rolling-origin\\n2) Calculer MAE/RMSE/MASE (reco)\\n3) Comparer au benchmark (NAIVE/SNAIVE)\\n4) VÃ©rifier stabilitÃ© (pas un seul split chanceux)\\n\\nCe que vous Ã©crivez :\\nâ€¢ tableau mÃ©triques + graphique prÃ©visions vs rÃ©el\\n\\nPiÃ¨ges :\\nâ€¢ choisir sur AICc sans test\\nâ€¢ horizon h incohÃ©rent avec lâ€™objectif',
      fillcolor='#e8f8f5'];

  q_beats [shape=diamond, style='rounded,filled', fillcolor='#fef9e7',
           label='Meilleur que\\nbenchmark\\nET parcimonieux ?'];

  choose [label='â˜ Ã‰tape 12 â€” Choix final (convergence des preuves)\\n\\nCe que vous faites :\\n1) Retenir le plus simple qui :\\n   â€¢ passe diagnostics\\n   â€¢ bat benchmark\\n   â€¢ est stable\\n2) DÃ©partager par AICc/BIC si perf similaire\\n\\nCe que vous Ã©crivez :\\nâ€¢ conclusion : (p,d,q)(P,D,Q)[s] + justification\\nâ€¢ limites (ruptures, outliers, non-linÃ©aritÃ©s, etc.)',
      fillcolor='#e8f8f5'];

  // =========================================================
  // CHECKLIST 12 â€” PrÃ©visions & reporting (papier / APA)
  // =========================================================
  c12 [label='â˜ Ã‰tape 13 â€” PrÃ©visions\\n\\nCe que vous faites :\\n1) Produire prÃ©visions point + IC 80/95%\\n2) Visualiser + table (h)\\n3) InterprÃ©ter en langage mÃ©tier (ce que cela signifie)\\n\\nCe que vous Ã©crivez :\\nâ€¢ figure finale + 3 phrases dâ€™interprÃ©tation',
      fillcolor='#ecf0f1'];

  c13 [label='â˜ Ã‰tape 14 â€” Reporting (structure conseillÃ©e)\\n\\nÃ€ inclure :\\n1) DonnÃ©es : n, pÃ©riode, s, manquants, outliers\\n2) EDA : observations\\n3) Transformation (si appliquÃ©e)\\n4) DiffÃ©renciation : d, D + preuves\\n5) ModÃ¨le final : (p,d,q)(P,D,Q)[s]\\n6) Diagnostics rÃ©sidus\\n7) Validation + comparaison benchmark\\n8) Conclusion + limites',
      fillcolor='#ecf0f1'];

  end [label='FIN\\nSARIMA validÃ© + justifiÃ©\\n(et reproductible)', fillcolor='#ecf0f1'];

  // =======================
  // Flow
  // =======================
  start -> c0 -> c1 -> c2 -> c3 -> c4 -> q_transform;
  q_transform -> c5 [label='Oui'];
  q_transform -> c6 [label='Non / variance stable'];
  c5 -> c6;

  c6 -> q_overdiff;
  q_overdiff -> backtrack [label='Oui'];
  q_overdiff -> c7 [label='Non'];
  backtrack -> c6;

  c7 -> c8 -> c9 -> q_num;
  q_num -> act_num [label='Oui'];
  act_num -> c7;
  q_num -> c10 [label='Non'];

  c10 -> q_diag_ok;
  q_diag_ok -> refine [label='Non'];
  refine -> c7;
  q_diag_ok -> c11 [label='Oui'];

  c11 -> q_beats;
  q_beats -> choose [label='Oui'];
  q_beats -> refine [label='Non'];

  choose -> c12 -> c13 -> end;
}
  ")
  })
  
 
  
  output$pdqpDQ_tree <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
digraph pdqpDQ_tree {

  graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
         label = 'SARIMA : Choisir (p,d,q)(P,D,Q)[s] â€” Checklist Ã©tudiante dÃ©taillÃ©e (actions + rÃ©daction + piÃ¨ges)',
         fontname = Helvetica, bgcolor = 'transparent',
         nodesep = 0.28, ranksep = 0.40,
         margin = 0.02, pad = 0.02]

  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
         fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
  edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]

  start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
  end   [shape = doublecircle, label = 'ModÃ¨le final\\n(parcimonieux + valide)\\n+ rapport prÃªt', fillcolor = '#d5f5e3']

  // -------------------------------------------------
  // CHECKLIST STEP 0 â€” Rules / evaluation protocol
  // -------------------------------------------------
  c0 [label = 'â˜ Ã‰tape 0 â€” Cadre dâ€™Ã©valuation (AVANT de toucher p,q,P,Q)\\n\\nCe que vous faites :\\n1) Fixer Î± (souvent 5%) et le noter\\n2) Fixer horizon h de prÃ©vision (ex: 12 mois)\\n3) Choisir benchmark : NAIVE ou SNAIVE (si saisonnalitÃ©)\\n4) Choisir mÃ©triques : MAE, RMSE, MASE (recommandÃ©)\\n5) DÃ©finir split temporel : train/test (pas alÃ©atoire !)\\n\\nCe que vous Ã©crivez (rapport) :\\nâ€¢ Î±, h, benchmark, mÃ©triques, mÃ©thode de split\\n\\nPiÃ¨ges :\\nâ€¢ â€œmeilleur AICâ€ â‰  â€œmeilleure prÃ©visionâ€\\nâ€¢ split alÃ©atoire = erreur en sÃ©ries temporelles',
      fillcolor = '#eaf2f8']

  // -------------------------------------------------
  // CHECKLIST STEP 1 â€” Choose s
  // -------------------------------------------------
  c1 [label = 'â˜ Ã‰tape 1 â€” Fixer la saisonnalitÃ© s (contexte + EDA)\\n\\nCe que vous faites :\\n1) Utiliser le contexte (mensuel=>12, trimestriel=>4, hebdo=>52, etc.)\\n2) VÃ©rifier sur la sÃ©rie : motifs rÃ©pÃ©tÃ©s + pics ACF Ã  s,2s,â€¦\\n3) (Option) seasonal/subseries plot pour confirmer\\n\\nCe que vous Ã©crivez :\\nâ€¢ â€œNous retenons s = â€¦ car â€¦ (contexte + figure/ACF)â€\\n\\nPiÃ¨ges :\\nâ€¢ inventer s â€œparce que Ã§a marcheâ€\\nâ€¢ confondre cycle long et saisonnalitÃ©',
      fillcolor = '#ecf0f1']

  // Small decision (still checklist-style)
  dS [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
      label = 's clair ?\\n(EDA + logique)']
  aS [label = 'Action si s pas clair\\nâ€¢ tester 2 valeurs plausibles\\nâ€¢ comparer diagnostics + perf\\nâ€¢ documenter la dÃ©cision\\n(Ã©viter lâ€™arbitraire)',
      fillcolor = '#f9e79f']

  // -------------------------------------------------
  // CHECKLIST STEP 2 â€” d & D fixed (from stationarity workflow)
  // -------------------------------------------------
  c2 [label = 'â˜ Ã‰tape 2 â€” Fixer d et D (stationnariser la sÃ©rie)\\n\\nCe que vous faites :\\n1) Appliquer la diffÃ©renciation minimale : dâˆˆ{0,1}, Dâˆˆ{0,1}\\n2) Re-tester (ADF/PP/KPSS) aprÃ¨s chaque transformation\\n3) VÃ©rifier ACF aux multiples de s (racine saisonniÃ¨re ?)\\n4) Surveiller sur-diff : ACF lag1 trÃ¨s nÃ©gative, variance gonflÃ©e\\n\\nCe que vous Ã©crivez :\\nâ€¢ â€œAvant/AprÃ¨sâ€ : graph + tableau tests + dÃ©cision (d,D)\\n\\nPiÃ¨ges :\\nâ€¢ d=2 â€œpar rÃ©flexeâ€\\nâ€¢ oublier de re-tester aprÃ¨s D',
      fillcolor = '#fdebd0']

  // -------------------------------------------------
  // CHECKLIST STEP 3 â€” ACF/PACF on differenced series
  // -------------------------------------------------
  c3 [label = 'â˜ Ã‰tape 3 â€” ACF/PACF SUR la sÃ©rie stationnarisÃ©e (aprÃ¨s d et D)\\n\\nCe que vous faites :\\n1) Tracer ACF et PACF de la sÃ©rie diffÃ©renciÃ©e\\n2) Observer : lags courts (1..), et lags saisonniers (s,2s,â€¦)\\n3) Noter oÃ¹ il y a des pics significatifs (et leur signe)\\n\\nCe que vous Ã©crivez :\\nâ€¢ 3 observations concrÃ¨tes (ex : â€œpic Ã  lag 1â€, â€œpic Ã  sâ€)\\n\\nPiÃ¨ges :\\nâ€¢ regarder ACF/PACF AVANT diffÃ©renciation\\nâ€¢ sur-interprÃ©ter de petits pics isolÃ©s',
      fillcolor = '#ecf0f1']

  // -------------------------------------------------
  // CHECKLIST STEP 4 â€” Translate patterns into candidate ranges
  // -------------------------------------------------
  c4 [label = 'â˜ Ã‰tape 4 â€” Traduire motifs ACF/PACF â†’ hypothÃ¨ses (p,q,P,Q)\\n\\nRappels (heuristiques, pas des lois) :\\nâ€¢ AR(p) : PACF â€œcoupureâ€ ~ p, ACF dÃ©croÃ®t\\nâ€¢ MA(q) : ACF â€œcoupureâ€ ~ q, PACF dÃ©croÃ®t\\nâ€¢ Saison : pics Ã  s,2s,â€¦\\n  PACF â†’ P ; ACF â†’ Q\\n\\nCe que vous faites :\\n1) Proposer p,q petits (0..2 souvent) selon lags courts\\n2) Proposer P,Q petits (0..2 souvent) selon lags saisonniers\\n3) Garder 1 modÃ¨le trÃ¨s simple (baseline)\\n\\nCe que vous Ã©crivez :\\nâ€¢ â€œNous proposons p=â€¦ car PACFâ€¦, q=â€¦ car ACFâ€¦â€\\n\\nPiÃ¨ges :\\nâ€¢ choisir p=q=3 sans justification\\nâ€¢ confondre pics saisonniers (P/Q) et non-saisonniers (p/q)',
      fillcolor = '#d5f5e3']

  // -------------------------------------------------
  // CHECKLIST STEP 5 â€” Build candidate set
  // -------------------------------------------------
  c5 [label = 'â˜ Ã‰tape 5 â€” Construire une petite liste de candidats (3 Ã  8 modÃ¨les)\\n\\nCe que vous faites :\\n1) Inclure 1 baseline : (0,d,0)(0,D,0)[s] ou proche\\n2) Ajouter 2â€“4 modÃ¨les guidÃ©s par ACF/PACF\\n3) Ajouter 1 modÃ¨le â€œalternativeâ€ (ex : AR vs MA)\\n4) Garder parcimonie : Ã©viter trop de paramÃ¨tres\\n\\nCe que vous Ã©crivez :\\nâ€¢ Liste des modÃ¨les + 1 ligne de justification chacun\\n\\nPiÃ¨ges :\\nâ€¢ tester 40 modÃ¨les â€œau hasardâ€\\nâ€¢ oublier que trop de paramÃ¨tres = sur-ajustement',
      fillcolor = '#ecf0f1']

  // -------------------------------------------------
  // CHECKLIST STEP 6 â€” Fit + record criteria
  // -------------------------------------------------
  c6 [label = 'â˜ Ã‰tape 6 â€” Ajuster chaque candidat + consigner les rÃ©sultats\\n\\nCe que vous faites :\\n1) Ajuster chaque SARIMA candidat\\n2) Noter AICc et/ou BIC (comparaison in-sample)\\n3) VÃ©rifier coefficients raisonnables (option : significativitÃ©)\\n4) Noter warnings (convergence, inversibilitÃ©, stationnaritÃ©)\\n\\nCe que vous Ã©crivez :\\nâ€¢ Tableau : modÃ¨le | AICc | BIC | warnings | remarques\\n\\nPiÃ¨ges :\\nâ€¢ choisir â€œplus petit AICâ€ sans diagnostics\\nâ€¢ ignorer warnings de convergence',
      fillcolor = '#ecf0f1']

  dNum [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
        label = 'ProblÃ¨mes\\nnumÃ©riques ?\\n(convergence,\\nnon-inversible,\\nnon-stationnaire)']
  aNum [label = 'Action si problÃ¨mes numÃ©riques\\nâ€¢ simplifier p/q/P/Q\\nâ€¢ vÃ©rifier sur-diff (d/D trop grands ?)\\nâ€¢ stabiliser variance (log/Boxâ€“Cox)\\nâ€¢ traiter outliers / ruptures\\nâ€¢ changer initialisation/mÃ©thode\\n\\nÃ€ Ã©crire : problÃ¨me + correction',
        fillcolor = '#f4ecf7']

  // -------------------------------------------------
  // CHECKLIST STEP 7 â€” Residual diagnostics (mandatory)
  // -------------------------------------------------
  c7 [label = 'â˜ Ã‰tape 7 â€” Diagnostics rÃ©siduels (NON nÃ©gociable)\\n\\nCe que vous faites :\\n1) Tracer ACF des rÃ©sidus\\n2) Ljungâ€“Box : tester autocorr globale (p grand â‡’ OK)\\n3) VÃ©rifier variance : outliers / clusters (ARCH)\\n4) NormalitÃ© : secondaire (utile mais pas bloquant)\\n\\nCe que vous Ã©crivez :\\nâ€¢ Figure ACF rÃ©sidus + phrase conclusion LB\\n\\nPiÃ¨ges :\\nâ€¢ â€œÃ§a a lâ€™air bienâ€ sans Ljungâ€“Box\\nâ€¢ confondre bon fit in-sample et rÃ©sidus blancs',
      fillcolor = '#ecf0f1']

  dWB [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
       label = 'RÃ©sidus\\nâ‰ˆ bruit blanc ?\\n(ACF rÃ©sidus ~0\\n+ Ljungâ€“Box OK)']

  aWB [label = 'Action si rÃ©sidus PAS blancs (diagnostic â†’ paramÃ¨tre)\\nâ€¢ pics lags courts â‡’ ajuster p/q\\nâ€¢ pics Ã  s,2s,â€¦ â‡’ ajuster P/Q\\nâ€¢ structure lente â‡’ revoir d (ou trend)\\nâ€¢ re-EDA : rupture/outliers\\n\\nÃ€ Ã©crire : â€œpic observÃ© â†’ action SARIMAâ€',
        fillcolor = '#fdebd0']

  // -------------------------------------------------
  // CHECKLIST STEP 8 â€” Forecast evaluation vs benchmark
  // -------------------------------------------------
  c8 [label = 'â˜ Ã‰tape 8 â€” Ã‰valuation prÃ©visionnelle (hors-Ã©chantillon)\\n\\nCe que vous faites :\\n1) Split temporel (train/test) OU rolling-origin\\n2) Calculer MAE/RMSE/MASE sur test\\n3) Comparer au benchmark (NAIVE/SNAIVE)\\n4) VÃ©rifier stabilitÃ© (pas juste 1 split â€œchanceuxâ€)\\n\\nCe que vous Ã©crivez :\\nâ€¢ Tableau mÃ©triques + graphique prÃ©vision vs rÃ©el\\n\\nPiÃ¨ges :\\nâ€¢ conclure sur AICc sans test set\\nâ€¢ choisir un modÃ¨le complexe pour un gain minuscule',
      fillcolor = '#ecf0f1']

  dPerf [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
         label = 'Bat le\\nbenchmark ET\\nperformance stable ?']

  aPerf [label = 'Action si perf faible/instable\\nâ€¢ simplifier (rÃ©duire paramÃ¨tres)\\nâ€¢ revoir candidats (p/q/P/Q)\\nâ€¢ revoir split/horizon\\nâ€¢ si aucun gain : garder benchmark\\n\\nÃ€ Ã©crire : dÃ©cision + justification',
         fillcolor = '#fdebd0']

  // -------------------------------------------------
  // CHECKLIST STEP 9 â€” Final choice + report package
  // -------------------------------------------------
  c9 [label = 'â˜ Ã‰tape 9 â€” Choix final (convergence des preuves)\\n\\nRÃ¨gle pratique :\\nâ€¢ garder le plus simple qui :\\n  (i) passe diagnostics rÃ©siduels\\n  (ii) bat benchmark\\n  (iii) reste stable\\nâ€¢ utiliser AICc/BIC pour dÃ©partager si perf ~ Ã©gale\\n\\nCe que vous Ã©crivez :\\nâ€¢ paragraphe final : (p,d,q)(P,D,Q)[s] + pourquoi\\nâ€¢ limites (ruptures, outliers, non-linÃ©aritÃ©s, etc.)',
      fillcolor = '#d5f5e3']

  deliver [label = 'â˜ Ce que lâ€™Ã©tudiant remet (package final)\\n1) EDA + choix s\\n2) justification d/D (tests + figures)\\n3) ACF/PACF + hypothÃ¨ses p,q,P,Q\\n4) tableau candidats + AICc/BIC + warnings\\n5) diagnostics rÃ©sidus (ACF + Ljungâ€“Box)\\n6) perf vs benchmark (mÃ©triques + graphique)\\n7) conclusion finale + limites',
           fillcolor = '#eaf2f8']

  // -------------------------
  // Flow
  // -------------------------
  start -> c0 -> c1 -> dS
  dS -> c2 [label='Oui', color='#1e8449', fontcolor='#1e8449']
  dS -> aS [label='Non', color='#d68910', fontcolor='#d68910']
  aS -> c1

  c2 -> c3 -> c4 -> c5 -> c6 -> dNum
  dNum -> aNum [label='Oui', color='#c0392b', fontcolor='#c0392b']
  aNum -> c5
  dNum -> c7  [label='Non', color='#1e8449', fontcolor='#1e8449']

  c7 -> dWB
  dWB -> aWB [label='Non', color='#c0392b', fontcolor='#c0392b']
  aWB -> c5
  dWB -> c8  [label='Oui', color='#1e8449', fontcolor='#1e8449']

  c8 -> dPerf
  dPerf -> aPerf [label='Non', color='#c0392b', fontcolor='#c0392b']
  aPerf -> c5
  dPerf -> c9 [label='Oui', color='#1e8449', fontcolor='#1e8449']

  c9 -> deliver -> end
}
  ")
  })
  
  
  
  output$stationarity_tree <- renderGrViz({
    grViz("
          digraph stationarity_tree {
          
            graph [rankdir=TB, bgcolor='white', fontname='Helvetica'];
            node  [shape=box, style='rounded,filled', color='#2c3e50', fillcolor='#f7f9fb',
                   fontname='Helvetica', fontsize=11];
            edge  [color='#34495e', fontname='Helvetica', fontsize=10];
          
            start [label='DÃ©part\\n(EDA + contexte + ACF/PACF)'];
          
            q_season [label='SaisonnalitÃ© marquÃ©e\\net possiblement stochastique ?'];
            hegy [label='Faire HEGY\\n(racines unitaires saisonniÃ¨res)'];
            hegy_yes [label='HEGY indique racine\\nunitaire saisonniÃ¨re'];
            act_D1 [label='Action : appliquer\\nDiff saisonniÃ¨re D = 1\\nPuis retester ADF/PP/KPSS'];
            hegy_no [label='Pas de racine\\nunitaire saisonniÃ¨re claire'];
          
            q_break [label='Rupture structurelle\\nvisible/suspectÃ©e ?\\n(crise, rÃ©forme, choc)'];
            za [label='Faire Zivotâ€“Andrews\\n(racine unitaire + rupture endogÃ¨ne)'];
            za_reject [label='ZA rejette H0\\n=> stationnaritÃ© avec rupture'];
            act_dummy [label='Action : d = 0\\n+ dummy(s) de rupture\\n(ou modÃ¨le avec tendance dÃ©terministe)'];
            za_noreject [label='ZA ne rejette pas\\n=> racine unitaire possible'];
          
            tests [label='Lancer ADF + PP + KPSS\\n(sur la sÃ©rie actuelle)'];
          
            case_stationary [label='ADF rejette & PP rejette\\nET KPSS ne rejette pas', fillcolor='#e8f8f5'];
            act_d0 [label='Conclusion : stationnaire\\nAction : d = 0', fillcolor='#e8f8f5'];
          
            case_i1 [label='ADF ne rejette pas & PP ne rejette pas\\nET KPSS rejette', fillcolor='#fdebd0'];
            act_d1 [label='Conclusion : I(1) probable\\nAction : d = 1\\nPuis retester', fillcolor='#fdebd0'];
          
            case_conflict1 [label='ADF/PP rejettent\\nmais KPSS rejette aussi\\n(ou rÃ©sultats mixtes)', fillcolor='#fef9e7'];
            act_conflict1 [label='Action :\\n- vÃ©rifier spÃ©cification (constante/tendance)\\n- regarder ACF + plots\\n- tester aprÃ¨s d=1\\n- choisir parcimonie', fillcolor='#fef9e7'];
          
            case_conflict2 [label='ADF/PP ne rejettent pas\\nmais KPSS ne rejette pas\\n(test peu informatif)', fillcolor='#fef9e7'];
            act_conflict2 [label='Action :\\n- EDA + ACF\\n- essayer d=1 puis retester\\n- privilÃ©gier solution minimale', fillcolor='#fef9e7'];
          
            q_overdiff [label='AprÃ¨s diffÃ©renciation\\nACF lag 1 trÃ¨s nÃ©gative\\nou prÃ©visions erratiques ?', fillcolor='#f5eef8'];
            act_overdiff [label='Sur-diffÃ©renciation probable\\nAction : revenir en arriÃ¨re\\n(d ou D trop grand)', fillcolor='#f5eef8'];
          
            end [label='Fin\\n(choix final d, D justifiÃ©s\\n+ diagnostics rÃ©siduels)', fillcolor='#ecf0f1'];
          
            // Flow
            start -> q_season;
            q_season -> hegy [label='Oui'];
            q_season -> q_break [label='Non'];
          
            hegy -> hegy_yes [label='DÃ©tectÃ©e'];
            hegy -> hegy_no  [label='Non dÃ©tectÃ©e'];
            hegy_yes -> act_D1 -> q_break;
            hegy_no  -> q_break;
          
            q_break -> za [label='Oui'];
            q_break -> tests [label='Non'];
          
            za -> za_reject [label='Rejet H0'];
            za -> za_noreject [label='Non-rejet H0'];
            za_reject -> act_dummy -> tests;
            za_noreject -> tests;
          
            tests -> case_stationary;
            tests -> case_i1;
            tests -> case_conflict1;
            tests -> case_conflict2;
          
            case_stationary -> act_d0 -> q_overdiff;
            case_i1 -> act_d1 -> q_overdiff;
            case_conflict1 -> act_conflict1 -> q_overdiff;
            case_conflict2 -> act_conflict2 -> q_overdiff;
          
            q_overdiff -> act_overdiff [label='Oui'];
            q_overdiff -> end [label='Non'];
            act_overdiff -> tests;
          
          }
      ")
  })
  
 
  
  
  output$stationarity_tree2 <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
              digraph stationarity_tree2 {
              
                graph [layout = dot, rankdir = TB,
                       fontname = Helvetica, bgcolor = 'transparent',
                       nodesep = 0.35, ranksep = 0.45,
                       margin = 0.02, pad = 0.02]
              
                node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                       fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
              
                title [shape=plain, fontname=Helvetica, fontsize=16,
                       label='StationnaritÃ© & diffÃ©renciation : ADF / KPSS / PP â†’ choix de d et D']
                { rank = min; title }
                title -> start [style=invis]
              
                start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
                end   [shape = doublecircle, label = 'DÃ©cision\\n(d, D) validÃ©e', fillcolor = '#d5f5e3']
              
                prep [label = 'PrÃ©parer la sÃ©rie\\nâ€¢ frÃ©quence s dÃ©finie\\nâ€¢ manquants traitÃ©s\\nâ€¢ transformation (log/Boxâ€“Cox) si besoin\\nâ€¢ EDA (tendance / saisonnalitÃ©)']
              
                spec [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                      label = 'Choisir spÃ©cification des tests\\n(constante ? tendance ?)']
              
                noteSpec [label = 'RÃ¨gle :\\nâ€¢ si tendance visible â†’ inclure tendance (trend)\\nâ€¢ sinon drift / constante\\nâ€¢ Ã©viter â€˜noneâ€™ sauf justification']
              
                test0 [label = 'Tester sur la sÃ©rie brute\\nADF + PP (H0 : racine unitaire)\\nKPSS (H0 : stationnaire)']
              
                dStrongS [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                          label = 'StationnaritÃ© forte ?\\nADF/PP rejettent (p petit)\\nET KPSS ne rejette pas (p grand)']
              
                actS [label = 'Action :\\nâ€¢ d = 0\\nâ€¢ vÃ©rifier saisonnalitÃ© (D ?)\\nâ€¢ passer au test saisonnier']
              
                dStrongNS [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                           label = 'Non-stationnaritÃ© forte ?\\nADF/PP ne rejettent pas (p grand)\\nET KPSS rejette (p petit)']
              
                actNS [label = 'Action :\\nâ€¢ essayer d = 1\\nâ€¢ retester ADF / PP / KPSS\\nâ€¢ surveiller sur-diff (ACF lag 1 trÃ¨s nÃ©gative)']
              
                dConflict [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                           label = 'Conflit / cas ambigu ?\\n(ex. ADF rejette mais KPSS rejette aussi\\nou tous non significatifs)']
              
                actConflict [label = 'Actions :\\nâ€¢ reconsidÃ©rer trend vs drift\\nâ€¢ examiner graphiques + ACF\\nâ€¢ tester aprÃ¨s d = 1 puis comparer\\nâ€¢ suspecter rupture (Zivotâ€“Andrews)\\nâ€¢ documenter (convergence dâ€™indices)']
              
                retest [label = 'Retester aprÃ¨s d choisi\\nADF + PP + KPSS\\n(d doit Ãªtre minimal)']
              
                seasCheck [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                           label = 'Racine saisonniÃ¨re ?\\nIndices : pics ACF Ã  s, 2sâ€¦\\n+ KPSS / ADF sur sÃ©rie saisonniÃ¨re\\n(ou HEGY en annexe)']
              
                actSeas [label = 'Action :\\nâ€¢ essayer D = 1 (diff. saisonniÃ¨re)\\nâ€¢ retester stationnaritÃ©\\nâ€¢ D = 2 rarement justifiÃ©']
              
                overdiff [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
                          label = 'Sur-diffÃ©renciation suspectÃ©e ?\\nACF lag 1 trÃ¨s nÃ©gative\\nvariance gonflÃ©e\\nprÃ©visions erratiques']
              
                actOver [label = 'Action :\\nâ€¢ revenir en arriÃ¨re (d ou D trop Ã©levÃ©)\\nâ€¢ prÃ©fÃ©rer tendance dÃ©terministe\\nâ€¢ vÃ©rifier spÃ©cification des tests']
              
                stop [label = 'Stop quand stationnaritÃ© raisonnable\\n+ parcimonie\\n(d âˆˆ {0,1} le plus souvent\\n D âˆˆ {0,1})']
              
                start -> prep -> spec
                spec -> noteSpec -> test0
              
                test0 -> dStrongS
                dStrongS -> actS      [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                dStrongS -> dStrongNS [label = 'Non']
              
                dStrongNS -> actNS    [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                dStrongNS -> dConflict[label = 'Non']
              
                dConflict -> actConflict [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                actConflict -> actNS     [label = 'tester d = 1 (prudence)', color = '#7d3c98', fontcolor = '#7d3c98']
              
                actNS -> retest
                actS  -> seasCheck
                retest -> seasCheck
              
                seasCheck -> actSeas [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                seasCheck -> stop    [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
                actSeas -> overdiff
                overdiff -> actOver [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
                overdiff -> stop    [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
                actOver -> retest
                stop -> end
              }
        ")
  })
  
  
  
  output$diag_tree <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
              digraph diag_tree {
              
                graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                       label = 'Arbre dÃ©cisionnel : diagnostics rÃ©siduels â†’ actions (SARIMA)',
                       fontname = Helvetica, bgcolor = 'transparent',
                       nodesep = 0.35, ranksep = 0.45]
              
                node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                       fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
              
                start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
                end   [shape = doublecircle, label = 'ModÃ¨le final\\n(OK)', fillcolor = '#d5f5e3']
              
                fit  [label = 'Ajuster un modÃ¨le SARIMA candidat\\n(p,d,q)(P,D,Q)[s]']
                pre  [label = 'Fixer protocole prÃ©vision\\nSplit temporel ou rolling-origin\\n+ mÃ©triques (MAE/RMSE/MASE) + benchmark']
              
                d1 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = '1) AutocorrÃ©lation rÃ©siduelle ?\\nACF(res) + Ljungâ€“Box OK']
                a1 [label = 'Actions si Ã©chec :\\nâ€¢ revoir p,q,P,Q\\nâ€¢ ajuster d/D (sous/sur-diff)\\nâ€¢ transformation (log/Boxâ€“Cox)\\nâ€¢ outliers / manquants\\nâ€¢ saisonnalitÃ© (s)']
              
                d2 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = '2) Bat le benchmark hors-Ã©chantillon ?\\nMAE/RMSE/MASE meilleurs']
                a2 [label = 'Actions si Ã©chec :\\nâ€¢ simplifier (parcimonie)\\nâ€¢ revoir spÃ©cification\\nâ€¢ si aucun gain : garder benchmark']
              
                d3 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = '3) Performance stable (rolling-origin) ?']
                a3 [label = 'Actions si instable :\\nâ€¢ rÃ©duire complexitÃ©\\nâ€¢ expansive vs glissante\\nâ€¢ vÃ©rifier ruptures/rÃ©gimes\\nâ€¢ rÃ©Ã©valuer horizon h']
              
                d4 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                    label = '4) NormalitÃ© rÃ©siduelle problÃ©matique ?\\nQQ-plot / Jarqueâ€“Bera']
                a4 [label = 'Si objectif = point forecast :\\nâ€¢ souvent secondaire\\nSi IC/tests importants :\\nâ€¢ transformation\\nâ€¢ robustesse / discussion\\nâ€¢ traiter outliers']
              
                d5 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                    label = '5) HÃ©tÃ©roscÃ©dasticitÃ© / ARCH forte ?\\nACF(ÎµÂ²) / test ARCH']
                a5 [label = 'Actions :\\nâ€¢ discuter variance conditionnelle\\nâ€¢ transformation\\nâ€¢ (annexe) GARCH\\nâ€¢ attention calibration des IC']
              
                d6 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                    label = '6) Coefficients non significatifs ?\\n(est, SE, z, p)']
                a6 [label = 'Actions :\\nâ€¢ rapporter est Â± SE, z, p\\nâ€¢ supprimer termes non signif\\n  seulement si diagnostics + OOS inchangÃ©s\\nâ€¢ comparer AICc/BIC + nb paramÃ¨tres']
              
                start -> pre -> fit -> d1
              
                d1 -> a1 [label = 'Non (Ã©chec)', color = '#c0392b', fontcolor = '#c0392b']
                a1 -> fit
              
                d1 -> d2 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                d2 -> a2 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
                a2 -> fit
              
                d2 -> d3 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                d3 -> a3 [label = 'Non', color = '#c0392b', fontcolor = '#c0392b']
                a3 -> fit
              
                d3 -> d4 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
              
                d4 -> a4 [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                a4 -> d5
                d4 -> d5 [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
                d5 -> a5 [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                a5 -> d6
                d5 -> d6 [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
                d6 -> a6 [label = 'Oui', color = '#2471a3', fontcolor = '#2471a3']
                a6 -> end
                d6 -> end [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
              
              }
        ")
  })
  
  output$adf_kpss_pp_tree <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
              digraph adf_kpss_pp_tree {
              
                graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                       label = 'Comment conclure en combinant ADF / KPSS / PP (diagramme pÃ©dagogique)',
                       fontname = Helvetica, bgcolor = 'transparent',
                       nodesep = 0.35, ranksep = 0.45]
              
                node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                       fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
                edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
              
                start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
              
                tests [label = 'Appliquer les tests sur la sÃ©rie brute\\nADF + PP (H0 : racine unitaire)\\nKPSS (H0 : stationnaire)']
              
                d1 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                    label = 'ADF/PP rejettent\\nET KPSS ne rejette pas ?']
                s1 [label = 'InterprÃ©tation :\\nConvergence forte\\nâ†’ stationnaritÃ© confirmÃ©e']
                a1 [label = 'DÃ©cision :\\nd = 0\\n(ne pas diffÃ©rencier)']
              
                d2 [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                    label = 'ADF/PP ne rejettent pas\\nET KPSS rejette ?']
                s2 [label = 'InterprÃ©tation :\\nConvergence forte\\nâ†’ racine unitaire probable']
                a2 [label = 'DÃ©cision :\\nEssayer d = 1\\n(puis retester)']
              
                d3 [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                    label = 'ADF/PP rejettent\\nET KPSS rejette aussi ?']
                s3 [label = 'InterprÃ©tation :\\nStationnaritÃ© autour\\ndâ€™une tendance dÃ©terministe']
                a3 [label = 'DÃ©cision :\\nd = 0 + tendance\\n(Ã©viter diffÃ©renciation)']
              
                d4 [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
                    label = 'ADF/PP ne rejettent pas\\nET KPSS ne rejette pas ?']
                s4 [label = 'InterprÃ©tation :\\nManque de puissance\\nou sÃ©rie trÃ¨s bruitÃ©e']
                a4 [label = 'DÃ©cision :\\nSâ€™appuyer sur EDA, ACF, contexte\\n(dÃ©cision argumentÃ©e)']
              
                d5 [shape = diamond, style = 'rounded,filled', fillcolor = '#fadbd8',
                    label = 'RÃ©sultats instables\\nselon spÃ©cification\\n(constante / tendance) ?']
                s5 [label = 'InterprÃ©tation :\\nSensibilitÃ© au modÃ¨le\\nde test']
                a5 [label = 'DÃ©cision :\\nComparer plusieurs specs\\n+ documenter le choix']
              
                afterd [label = 'AprÃ¨s d = 1 (si appliquÃ©) :\\nretester ADF / PP / KPSS']
              
                d6 [shape = diamond, style = 'rounded,filled', fillcolor = '#e8f8f5',
                    label = 'ADF/PP rejettent\\nET KPSS ne rejette plus ?']
                a6 [label = 'Conclusion finale :\\nSÃ©rie I(1) confirmÃ©e\\nâ†’ conserver d = 1']
              
                d7 [shape = diamond, style = 'rounded,filled', fillcolor = '#f1948a',
                    label = 'ADF/PP et KPSS\\nrejettent fortement ?']
                a7 [label = 'InterprÃ©tation :\\nRupture structurelle probable\\nâ†’ tester Zivotâ€“Andrews']
              
                end [shape = doublecircle, label = 'DÃ©cision argumentÃ©e\\n(et justifiÃ©e)', fillcolor = '#d5f5e3']
              
                start -> tests
              
                tests -> d1
                d1 -> s1 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                s1 -> a1 -> end
              
                d1 -> d2 [label = 'Non']
                d2 -> s2 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                s2 -> a2 -> afterd
              
                d2 -> d3 [label = 'Non']
                d3 -> s3 [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
                s3 -> a3 -> end
              
                d3 -> d4 [label = 'Non']
                d4 -> s4 [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
                s4 -> a4 -> end
              
                afterd -> d6
                d6 -> a6 [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
                a6 -> end
              
                d6 -> d7 [label = 'Non']
                d7 -> a7 [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
                a7 -> end
              
                d7 -> a4 [label = 'Non']
              }
      ")
  })
  
  output$adf_kpss_pp_tree_full <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
            digraph adf_kpss_pp_tree_full {
            
              graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
                     label = 'Combiner ADF / KPSS / PP : diagramme complet et pÃ©dagogique',
                     fontname = Helvetica, bgcolor = 'transparent',
                     nodesep = 0.32, ranksep = 0.42]
            
              node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
                     fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
              edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]
            
              start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
            
              remind [label = 'Rappels (hypothÃ¨ses)\\nADF / PP : H0 = racine unitaire (non-stationnaire)\\nKPSS : H0 = stationnaire\\nâ†’ tests complÃ©mentaires (logiques inversÃ©es)',
                      fillcolor = '#eaf2f8']
            
              prep [label = 'Ã‰tape 0 : prÃ©parer\\nâ€¢ choisir la spÃ©cification (drift / trend)\\nâ€¢ traiter manquants / outliers majeurs\\nâ€¢ EDA (tendance, saisonnalitÃ©, ruptures)',
                    fillcolor = '#ecf0f1']
            
              tests [label = 'Ã‰tape 1 : tests sur sÃ©rie brute\\nâ€¢ ADF + PP\\nâ€¢ KPSS\\n(avec une spÃ©cification cohÃ©rente)',
                     fillcolor = '#ecf0f1']
            
              specSens [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
                        label = 'SensibilitÃ© Ã  la spÃ©cification ?\\nRÃ©sultats changent\\nsi drift vs trend']
            
              specAct [label = 'Action :\\nâ€¢ tester drift ET trend\\nâ€¢ conserver la spec cohÃ©rente avec lâ€™EDA\\nâ€¢ documenter (pourquoi cette spec)',
                       fillcolor = '#f9e79f']
            
              ## --- Cas de convergence forte ---
              stStrong [shape = diamond, style = 'rounded,filled', fillcolor = '#d5f5e3',
                        label = 'Convergence stationnaritÃ© ?\\nADF/PP rejettent H0 (p petit)\\nET KPSS ne rejette pas (p grand)']
            
              stExplain [label = 'Explication :\\nLes tests â€œracine unitaireâ€ ne voient pas de racine unitaire\\nET le test â€œstationnaritÃ©â€ est compatible avec stationnaritÃ©\\nâ†’ conclusion forte',
                         fillcolor = '#d5f5e3']
            
              stDecision [label = 'DÃ©cision :\\nSÃ©rie stationnaire\\nâ†’ d = 0 (ne pas diffÃ©rencier)',
                          fillcolor = '#d5f5e3']
            
              nsStrong [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
                        label = 'Convergence non-stationnaritÃ© ?\\nADF/PP ne rejettent pas (p grand)\\nET KPSS rejette (p petit)']
            
              nsExplain [label = 'Explication :\\nLes tests indiquent une racine unitaire probable\\nET KPSS rejette la stationnaritÃ©\\nâ†’ conclusion forte de non-stationnaritÃ©',
                         fillcolor = '#fdebd0']
            
              nsDecision [label = 'DÃ©cision :\\nEssayer d = 1\\n(puis retester)\\nPrincipe : diffÃ©renciation minimale',
                          fillcolor = '#fdebd0']
            
              ## --- Cas conflictuels ---
              conflict [shape = diamond, style = 'rounded,filled', fillcolor = '#f4ecf7',
                        label = 'Conflit ?\\n(ADF/PP rejettent)\\nET (KPSS rejette aussi)']
            
              conflictExplain [label = 'Explication :\\nSouvent stationnaritÃ© autour dâ€™une tendance\\nou spÃ©cification inadÃ©quate (drift vs trend)\\nou rupture structurelle\\nâ†’ on ne tranche pas automatiquement',
                               fillcolor = '#f4ecf7']
            
              conflictAct [label = 'Actions recommandÃ©es :\\n1) re-spÃ©cifier ADF/PP/KPSS (trend vs drift)\\n2) regarder sÃ©rie + ACF\\n3) tester aprÃ¨s d=1 et comparer\\n4) suspecter rupture (Zivotâ€“Andrews)',
                           fillcolor = '#f4ecf7']
            
              ## --- Cas inconclusif ---
              inconclusive [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
                            label = 'Inconclusif ?\\nADF/PP ne rejettent pas\\nET KPSS ne rejette pas']
            
              inconExplain [label = 'Explication :\\nFaible puissance (petit n) ou sÃ©rie trÃ¨s bruitÃ©e\\nâ†’ tests peu informatifs\\nâ†’ lâ€™EDA/ACF et la parcimonie guident la dÃ©cision',
                           fillcolor = '#f9e79f']
            
              inconAct [label = 'Actions :\\nâ€¢ sâ€™appuyer sur EDA + ACF\\nâ€¢ tester d=1 (prudence) puis comparer\\nâ€¢ documenter lâ€™incertitude',
                        fillcolor = '#f9e79f']
            
              ## --- AprÃ¨s d=1 ---
              afterd [label = 'Ã‰tape 2 : aprÃ¨s d = 1 (si appliquÃ©)\\nRetester ADF/PP/KPSS',
                      fillcolor = '#ecf0f1']
            
              okAfter [shape = diamond, style = 'rounded,filled', fillcolor = '#d5f5e3',
                       label = 'AprÃ¨s d=1 :\\nADF/PP rejettent\\nET KPSS ne rejette plus ?']
            
              okAfterExplain [label = 'Explication :\\nLa diffÃ©renciation a supprimÃ© la racine unitaire\\nâ†’ stationnaritÃ© atteinte\\nâ†’ ne pas aller Ã  d=2',
                              fillcolor = '#d5f5e3']
            
              okAfterDecision [label = 'Conclusion :\\nSÃ©rie I(1) confirmÃ©e\\nâ†’ conserver d = 1',
                               fillcolor = '#d5f5e3']
            
              ## --- Ruptures / cas extrÃªmes ---
              breakSuspect [shape = diamond, style = 'rounded,filled', fillcolor = '#f5b7b1',
                            label = 'Rupture structurelle suspectÃ©e ?\\nâ€¢ rÃ©sultats incohÃ©rents\\nâ€¢ changement brutal visuel\\nâ€¢ rejets â€œfortsâ€ contradictoires']
            
              breakExplain [label = 'Explication :\\nLes tests standards supposent paramÃ¨tres stables\\nUne rupture peut imiter une racine unitaire\\nâ†’ utiliser des tests avec rupture',
                            fillcolor = '#f5b7b1']
            
              breakAct [label = 'Action :\\nâ€¢ Zivotâ€“Andrews (rupture endogÃ¨ne)\\nâ€¢ discuter le contexte (date, Ã©vÃ©nement)\\nâ€¢ Ã©ventuellement inclure variables de rupture\\n  plutÃ´t que diffÃ©rencier',
                        fillcolor = '#f5b7b1']
            
              end [shape = doublecircle, label = 'DÃ©cision finale\\nargumentÃ©e + documentÃ©e', fillcolor = '#d5f5e3']
            
            
              start -> remind -> prep -> tests -> specSens
              specSens -> specAct [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
              specAct -> tests
              specSens -> stStrong [label = 'Non', color = '#1e8449', fontcolor = '#1e8449']
            
              stStrong -> stExplain [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
              stExplain -> stDecision -> end
            
              stStrong -> nsStrong [label = 'Non']
              nsStrong -> nsExplain [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
              nsExplain -> nsDecision -> afterd
            
              nsStrong -> conflict [label = 'Non']
              conflict -> conflictExplain [label = 'Oui', color = '#7d3c98', fontcolor = '#7d3c98']
              conflictExplain -> conflictAct -> breakSuspect
            
              conflict -> inconclusive [label = 'Non']
            
              inconclusive -> inconExplain [label = 'Oui', color = '#d68910', fontcolor = '#d68910']
              inconExplain -> inconAct -> afterd
            
              afterd -> okAfter
              okAfter -> okAfterExplain [label = 'Oui', color = '#1e8449', fontcolor = '#1e8449']
              okAfterExplain -> okAfterDecision -> end
            
              okAfter -> breakSuspect [label = 'Non']
            
              breakSuspect -> breakExplain [label = 'Oui', color = '#c0392b', fontcolor = '#c0392b']
              breakExplain -> breakAct -> end
            
              breakSuspect -> end [label = 'Non']
            }
      ")
  })
  
  
  output$stationarity_diff_workflow <- DiagrammeR::renderGrViz({
    DiagrammeR::grViz("
digraph stationarity_diff_workflow {

  graph [layout = dot, rankdir = TB, fontsize = 16, labelloc = t,
         label = 'StationnaritÃ© & diffÃ©renciation : ADF / KPSS / PP â†’ choix de (d, D)\\n(workflow trÃ¨s explicite + checklist Ã©tudiant + quoi Ã©crire)',
         fontname = Helvetica, bgcolor = 'transparent',
         nodesep = 0.30, ranksep = 0.40]

  node  [shape = box, style = 'rounded,filled', fontname = Helvetica,
         fontsize = 11, color = '#2c3e50', fillcolor = '#ecf0f1', penwidth = 1.2]
  edge  [fontname = Helvetica, fontsize = 10, color = '#34495e', arrowsize = 0.8]

  start [shape = circle, label = 'DÃ©part', fillcolor = '#d6eaf8']
  end   [shape = doublecircle, label = 'Choix final\\n(d, D, s) justifiÃ©\\n+ prÃªt pour (p,q,P,Q)', fillcolor = '#d5f5e3']

  alpha [label = 'â˜ Checklist 0 (rÃ©glages)\\nFixer Î± (souvent 5%)\\nâ€¢ rÃ¨gle gÃ©nÃ©rale : p < Î± â‡’ rejet H0\\nâ€¢ noter Î± dans le rapport',
         fillcolor = '#eaf2f8']

  c1 [label = 'â˜ Checklist 1 (concept)\\nDÃ©finir la stationnaritÃ© (avec vos mots)\\nâ€¢ moyenne stable\\nâ€¢ variance stable\\nâ€¢ dÃ©pendance/autocorr stable\\n\\nÃ€ Ã©crire : 2â€“3 phrases + un exemple (sÃ©rie non-stationnaire)',
      fillcolor = '#eaf2f8']

  setup [label = 'PrÃ©parer les donnÃ©es (avant tout test)\\nâ€¢ fixer s (contexte + EDA)\\nâ€¢ vÃ©rifier index date & pas de doublons\\nâ€¢ gÃ©rer manquants (na.approx/locf/suppression)\\nâ€¢ (option) stabiliser variance : log / Boxâ€“Cox\\nâ€¢ tracer sÃ©rie + ACF/PACF + saisonnalitÃ©',
          fillcolor = '#ecf0f1']

  eda [label = 'EDA guidÃ©e (ce que lâ€™Ã©tudiant observe)\\nâ€¢ tendance ? (hausse/baisse durable)\\nâ€¢ saisonnalitÃ© ? (pÃ©riode s, pics rÃ©guliers)\\nâ€¢ outliers / ruptures ? (chocs, changement rÃ©gime)\\n\\nÃ€ Ã©crire : 3 observations concrÃ¨tes (dates/pÃ©riodes + ce quâ€™on voit)',
       fillcolor = '#ecf0f1']

  c2 [label = 'â˜ Checklist 2 (tests : H0/Ha Ã  Ã©crire)\\nADF/PP : H0 = racine unitaire (non-stationnaire)\\nKPSS : H0 = stationnaire\\n\\nÃ€ Ã©crire : H0 et Ha pour chaque test + rÃ¨gle p<Î±',
      fillcolor = '#eaf2f8']

  spec0 [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
         label = 'Choix drift/trend\\nLa sÃ©rie montre une tendance dÃ©terministe ?']

  specAct0 [label = 'Action (spÃ©cification cohÃ©rente)\\nSi tendance visible â‡’ inclure trend\\nSinon â‡’ drift (constante) ou none\\n\\nÃ€ Ã©crire : justification (1 phrase) basÃ©e sur lâ€™EDA',
            fillcolor = '#f9e79f']

  lags [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
        label = 'Choix du nombre de retards (lags)\\nADF/PP sensibles au lag-length\\nAvez-vous une rÃ¨gle ?']

  lagsAct [label = 'Action (lags)\\nâ€¢ utiliser AIC/BIC auto si dispo\\nâ€¢ ou rÃ¨gle simple : assez de lags pour rÃ©sidus ~ blancs\\nâ€¢ vÃ©rifier que lâ€™ADF ne laisse pas dâ€™autocorr rÃ©siduelle\\n\\nÃ€ Ã©crire : mÃ©thode + valeur retenue',
           fillcolor = '#f9e79f']

  tests0 [label = 'Tests sur sÃ©rie brute\\nADF + PP + KPSS\\n(spÃ©cification cohÃ©rente : drift/trend + lags)\\n\\nÃ€ Ã©crire : tableau (stat, p-value, dÃ©cision)',
          fillcolor = '#ecf0f1']

  specSens [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
            label = 'RÃ©sultats instables\\nselon drift vs trend\\nou selon lags ?']

  specAct [label = 'Action (robustesse)\\nâ€¢ retester 2 specs plausibles\\nâ€¢ retester lags voisins\\nâ€¢ prÃ©fÃ©rer la spec cohÃ©rente avec lâ€™EDA\\nâ€¢ documenter les 2 rÃ©sultats (pas juste celui qui arrange)',
           fillcolor = '#f9e79f']

  dStationary [shape = diamond, style = 'rounded,filled', fillcolor = '#d5f5e3',
               label = 'StationnaritÃ© plausible ?\\nADF/PP rejettent (p petit)\\nET KPSS ne rejette pas (p grand)']

  expS [label = 'InterprÃ©tation\\nâ€¢ pas de racine unitaire dÃ©tectÃ©e (ADF/PP)\\nâ€¢ stationnaritÃ© compatible (KPSS)\\n=> d=0 (provisoirement)',
         fillcolor = '#d5f5e3']

  actS [label = 'DÃ©cision provisoire\\nâ€¢ d = 0\\nâ€¢ maintenant regarder racines saisonniÃ¨res (D ?)\\nâ€¢ contrÃ´ler ACF aux multiples de s',
         fillcolor = '#d5f5e3']

  dNonStat [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
            label = 'Non-stationnaritÃ© plausible ?\\nADF/PP ne rejettent pas\\nET KPSS rejette']

  expNS [label = 'InterprÃ©tation\\nâ€¢ racine unitaire probable\\nâ€¢ chocs persistants\\n=> diffÃ©renciation justifiÃ©e (d ou D)',
          fillcolor = '#fdebd0']

  conflict [shape = diamond, style = 'rounded,filled', fillcolor = '#f5cba7',
            label = 'Cas ambigu / conflit ?\\n(ADF rejette mais KPSS rejette aussi,\\nou aucun nâ€™est clair)']

  conflictAct [label = 'Action (si conflit)\\nâ€¢ sâ€™appuyer sur graphiques + ACF\\nâ€¢ vÃ©rifier outliers / ruptures (breaks)\\nâ€¢ tester aprÃ¨s transformation variance (log/BoxCox)\\nâ€¢ Ã©ventuellement : test avec rupture (Zivot-Andrews)\\n\\nÃ€ Ã©crire : pourquoi câ€™est ambigu + dÃ©cision prudente',
               fillcolor = '#f5cba7']

  c3 [label = 'â˜ Checklist 3 (diff progressive)\\nProposer d et D progressivement\\nâ€¢ essayer d=1 (souvent max)\\nâ€¢ puis D=1 si racine saisonniÃ¨re\\nâ€¢ retester aprÃ¨s CHAQUE transformation\\n\\nÃ€ Ã©crire : â€œAvant/AprÃ¨sâ€ (graph + tests)',
      fillcolor = '#eaf2f8']

  do_d1 [label = 'Appliquer d = 1\\nÎ” y_t = y_t âˆ’ y_{tâˆ’1}\\nPuis re-plot + re-tests\\n(Ã©viter d=2 sauf justification forte)',
         fillcolor = '#ecf0f1']

  tests_d [label = 'AprÃ¨s d = 1\\nâ€¢ tracer Î”y_t\\nâ€¢ ADF + PP + KPSS\\nâ€¢ vÃ©rifier ACF/PACF (structure rÃ©siduelle)',
           fillcolor = '#ecf0f1']

  seas [shape = diamond, style = 'rounded,filled', fillcolor = '#fdebd0',
        label = 'Racine saisonniÃ¨re probable ?\\nIndices : pics ACF Ã  s, 2sâ€¦\\nSaisonnalitÃ© stochastique (pas juste moyenne saisonniÃ¨re)']

  do_D1 [label = 'Appliquer D = 1\\nÎ”_s y_t = y_t âˆ’ y_{tâˆ’s}\\nPuis re-plot + re-tests\\n(garder Dâ‰¤1 en gÃ©nÃ©ral)',
         fillcolor = '#ecf0f1']

  tests_D [label = 'AprÃ¨s D = 1 (sur sÃ©rie transformÃ©e)\\nâ€¢ tracer Î”_s (ou Î”Î”_s)\\nâ€¢ ADF/PP/KPSS\\nâ€¢ vÃ©rifier ACF aux lags saisonniers',
           fillcolor = '#ecf0f1']

  over [shape = diamond, style = 'rounded,filled', fillcolor = '#f9e79f',
        label = 'Sur-diffÃ©renciation ?\\nâ€¢ ACF lag 1 trÃ¨s nÃ©gative\\nâ€¢ variance gonflÃ©e\\nâ€¢ oscillations artificielles\\nâ€¢ modÃ¨le instable']

  c4 [label = 'â˜ Checklist 4 (anti-sur-diff)\\nSurveiller les signes\\n(et revenir en arriÃ¨re si besoin)\\n\\nÃ€ Ã©crire : signe observÃ© + correction',
      fillcolor = '#eaf2f8']

  overAct [label = 'Actions si sur-diff\\nâ€¢ rÃ©duire d ou D\\nâ€¢ prÃ©fÃ©rer tendance dÃ©terministe (trend)\\nâ€¢ re-vÃ©rifier drift/trend & lags\\nâ€¢ re-tester aprÃ¨s correction',
           fillcolor = '#f9e79f']

  stop [label = 'Stop : stationnaritÃ© raisonnable + parcimonie\\nEn pratique : dâˆˆ{0,1} ; Dâˆˆ{0,1}\\n(augmenter uniquement si argument solide)',
        fillcolor = '#d5f5e3']

  justify [label = 'â˜ Checklist 5 (justification finale)\\nConclure sur (d, D, s) avec convergence :\\nâ€¢ tests (ADF/PP/KPSS)\\nâ€¢ graphiques avant/aprÃ¨s\\nâ€¢ ACF/PACF (dont lags saisonniers)\\nâ€¢ pas UNE seule p-value\\n\\nÃ€ Ã©crire : mini-paragraphe + tableau des tests',
          fillcolor = '#eaf2f8']

  bridge [label = 'Pont vers lâ€™Ã©tape suivante (SARIMA)\\nMaintenant identifier (p,q,P,Q) sur la sÃ©rie stationnarisÃ©e\\nâ€¢ ACF/PACF pour candidats\\nâ€¢ puis estimation + diagnostics rÃ©sidus',
          fillcolor = '#d6eaf8']

  // ----- Edges -----
  start -> alpha -> c1 -> setup -> eda -> c2 -> spec0
  spec0 -> specAct0 [label='Oui', color='#d68910', fontcolor='#d68910']
  spec0 -> lags      [label='Non', color='#1e8449', fontcolor='#1e8449']
  specAct0 -> lags

  lags -> lagsAct [label='Oui', color='#d68910', fontcolor='#d68910']
  lags -> tests0  [label='Non', color='#1e8449', fontcolor='#1e8449']
  lagsAct -> tests0

  tests0 -> specSens
  specSens -> specAct [label='Oui', color='#d68910', fontcolor='#d68910']
  specAct -> tests0
  specSens -> dStationary [label='Non', color='#1e8449', fontcolor='#1e8449']

  dStationary -> expS [label='Oui', color='#1e8449', fontcolor='#1e8449']
  expS -> actS -> seas

  dStationary -> dNonStat [label='Non']
  dNonStat -> expNS [label='Oui', color='#c0392b', fontcolor='#c0392b']
  expNS -> conflict

  dNonStat -> conflict [label='Non (mixte)', color='#7d3c98', fontcolor='#7d3c98']

  conflict -> conflictAct [label='Oui', color='#7d3c98', fontcolor='#7d3c98']
  conflictAct -> c3

  conflict -> c3 [label='DÃ©cision prudente', color='#34495e', fontcolor='#34495e']

  c3 -> do_d1 -> tests_d -> seas

  seas -> do_D1 [label='Oui', color='#c0392b', fontcolor='#c0392b']
  do_D1 -> tests_D -> over
  seas -> over   [label='Non', color='#1e8449', fontcolor='#1e8449']

  over -> c4 [label='Oui', color='#d68910', fontcolor='#d68910']
  c4 -> overAct -> tests0
  over -> stop [label='Non', color='#1e8449', fontcolor='#1e8449']

  stop -> justify -> bridge -> end
}
  ")
  })
  
 
  
  
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  # ============================================================      # ============================================================    
  
  
  
  

  
  
  # ============================================================
  # S(t) plots tab (SERVER) â€” paste INSIDE server()
  # ============================================================
  
  # ---- helpers ----
  to_num <- function(x, d = NA_real_) {
    y <- suppressWarnings(as.numeric(x))
    ifelse(is.finite(y), y, d)
  }
  
  # fmt_num <- function(x, d = 4) {
  #   if (!is.finite(x)) return("NA")
  #   format(round(x, d), nsmall = d)
  # }
  
  # S_Lag <- suppressWarnings(as.integer(input$stp_corr_lag))
  # if (!is.finite(S_Lag) || S_Lag < 1) S_Lag <- 40L
  # S_Lag <- max(1L, min(S_Lag, length(ts_obj) - 1L))
  
  
  # ============================================================
  # 0) Scope control: prevent "Training only" when train_prop == 1.00
  # ============================================================
  output$stp_scope_ui <- renderUI({
    tp <- to_num(input$train_prop, 1)
    has_test <- isTRUE(tp < 1)
    
    if (!has_test) {
      radioButtons(
        "stp_scope",
        label = NULL,
        choices = c("Full series" = "full"),
        selected = "full"
      )
    } else {
      radioButtons(
        "stp_scope",
        label = NULL,
        choices = c("Full series" = "full", "Training only" = "train"),
        selected = input$stp_scope %||% "full"
      )
    }
  })
  
  output$stp_scope_warning <- renderUI({
    tp <- to_num(input$train_prop, 1)
    if (isTRUE(tp >= 1)) {
      tags$div(
        style = "color:#b22222; font-size:12px; margin-top:-6px;",
        "No test set â†’ training = full series"
      )
    } else NULL
  })
  
  observeEvent(input$train_prop, {
    tp <- to_num(input$train_prop, 1)
    if (isTRUE(tp >= 1) && identical(input$stp_scope, "train")) {
      updateRadioButtons(session, "stp_scope", selected = "full")
    }
  }, ignoreInit = TRUE)
  
  # ============================================================
  # 1) Global transform info (read-only)
  # ============================================================
  output$stp_transform_info <- renderPrint({
    tr <- input$transform %||% "none"
    if (tr == "boxcox") {
      lam <- input$lambda
      cat("Transformation:", "Box-Cox", "\n")
      cat("Î»:", if (is.null(lam) || (length(lam) == 1 && is.na(lam))) "auto (estimated)" else as.character(lam), "\n")
    } else if (tr == "log") {
      cat("Transformation:", "Log (ln y)", "\n")
    } else {
      cat("Transformation:", "None", "\n")
    }
  })
  
  output$stp_transform_note <- renderUI({
    tr <- input$transform %||% "none"
    lam <- input$lambda
    
    tr_lbl <- switch(tr,
                     "none" = "None",
                     "log" = "Log (ln y)",
                     "boxcox" = "Box-Cox",
                     tr)
    
    if (identical(tr, "boxcox")) {
      tags$div(
        style = "font-size:12px;",
        tags$b("Transformation (global): "), tr_lbl, " â€” ",
        tags$b("Î»: "), if (is.null(lam) || is.na(lam)) "auto" else as.character(lam)
      )
    } else {
      tags$div(
        style = "font-size:12px;",
        tags$b("Transformation (global): "), tr_lbl
      )
    }
  })
  
  # ============================================================
  # 2) Theme/palette helpers  (IMPORTANT: rotation is controlled here)
  # ============================================================
  stp_theme_picker <- function(key) {
    switch(
      key,
      "Minimal" = ggplot2::theme_minimal(),
      "Classic" = ggplot2::theme_classic(),
      "Light"   = ggplot2::theme_light(),
      "Dark"    = ggplot2::theme_dark(),
      "BW"      = ggplot2::theme_bw(),
      "Void"    = ggplot2::theme_void(),
      ggplot2::theme_gray()
    )
  }
  
  stp_apply_theme <- function(g) {
    ang <- to_num(input$stp_x_angle, 30)
    rot <- isTRUE(input$stp_x_rotate %||% TRUE)
    
    g +
      stp_theme_picker(input$stp_theme %||% "Minimal") +
      ggplot2::theme(
        text = ggplot2::element_text(size = to_num(input$stp_base_size, 12)),
        plot.title = ggplot2::element_text(hjust = 0.5),
        
        # âœ… rotation is applied HERE so it always wins over the theme preset
        axis.text.x = ggplot2::element_text(
          angle = if (rot) ang else 0,
          hjust = if (!rot || ang == 0) 0.5 else 1,
          vjust = if (!rot || ang == 0) 0.5 else 1
        )
      )
  }
  
  stp_apply_palette <- function(g) {
    pal <- input$stp_palette %||% "Paired (brewer)"
    rev <- isTRUE(input$stp_palette_rev)
    
    if (pal == "Viridis") {
      g +
        ggplot2::scale_color_viridis_d(direction = ifelse(rev, -1, 1)) +
        ggplot2::scale_fill_viridis_d(direction = ifelse(rev, -1, 1))
    } else {
      brewer_name <- sub(" \\(brewer\\)$", "", pal)
      g +
        ggplot2::scale_color_brewer(palette = brewer_name, direction = ifelse(rev, -1, 1)) +
        ggplot2::scale_fill_brewer(palette = brewer_name, direction = ifelse(rev, -1, 1))
    }
  }
  
  # ============================================================
  # 3) Conditional style UI (COLOUR PICKERS)
  # ============================================================
  output$stp_style_ui <- renderUI({
    req(input$stp_plot_type)
    pt <- input$stp_plot_type
    
    if (!requireNamespace("colourpicker", quietly = TRUE)) {
      return(tags$div(
        style = "color:#b22222; font-size:12px;",
        "Package 'colourpicker' is required for color pickers. Install it: install.packages('colourpicker')"
      ))
    }
    
    is_liney <- pt %in% c("Line", "Line + Points", "Smoothed (LOESS)", "Moving average",
                          "Cumulative sum", "Seasonal plot", "Seasonal subseries",
                          "Polar seasonal", "Periodogram",
                          "Classical decomposition (additive)", "Classical decomposition (multiplicative)",
                          "STL decomposition")
    
    is_pointy <- pt %in% c("Points", "Line + Points", "Smoothed (LOESS)",
                           "Lag-1 scatter", "Lag plot (1..m)", "QQ plot")
    
    is_filly  <- pt %in% c("Histogram", "Density", "Seasonal boxplot")
    
    tagList(
      if (is_liney) tagList(
        colourpicker::colourInput("stp_line_color", "Line color", value = "#2C7FB8", allowTransparent = FALSE),
        sliderInput("stp_line_width", "Line width", min = 0.1, max = 5, value = 0.9, step = 0.1)
      ),
      if (is_pointy) tagList(
        colourpicker::colourInput("stp_point_color", "Point color", value = "#2C7FB8", allowTransparent = FALSE),
        sliderInput("stp_point_size", "Point size", min = 0.5, max = 8, value = 2, step = 0.5)
      ),
      if (is_filly) tagList(
        colourpicker::colourInput("stp_fill_color", "Fill color", value = "#2C7FB8", allowTransparent = FALSE)
      )
    )
  })
  
  # ============================================================
  # 4) Data reactive: choose scope + apply GLOBAL transform
  # ============================================================
  stp_data <- reactive({
    req(prepared(), ts_train_test())
    p <- prepared()
    s <- ts_train_test()
    
    df_all <- p$df
    req(df_all)
    
    validate(need("y_filled" %in% names(df_all), "prepared()$df must contain column y_filled."))
    
    if (!("x" %in% names(df_all))) df_all$x <- seq_len(nrow(df_all))
    
    df_all <- df_all[is.finite(df_all$y_filled), , drop = FALSE]
    validate(need(nrow(df_all) >= 5, "Not enough data to plot."))
    
    train_n <- s$train_n %||% floor(nrow(df_all) * to_num(input$train_prop, 1))
    train_n <- max(2, min(as.integer(train_n), nrow(df_all)))
    
    has_test <- isTRUE(to_num(input$train_prop, 1) < 1)
    scope_in <- input$stp_scope %||% "full"
    scope <- if (!has_test) "full" else scope_in
    
    df_use <- if (identical(scope, "train")) df_all[seq_len(train_n), , drop = FALSE] else df_all
    
    tr <- input$transform %||% "none"
    y <- df_use$y_filled
    y_plot <- y
    lambda_used <- NA_real_
    
    if (tr == "log") {
      validate(need(all(y > 0, na.rm = TRUE), "Log transform requires strictly positive values."))
      y_plot <- log(y)
    } else if (tr == "boxcox") {
      validate(need(all(y > 0, na.rm = TRUE), "Box-Cox transform requires strictly positive values."))
      lam <- input$lambda
      if (is.null(lam) || (length(lam) == 1 && is.na(lam))) {
        lam <- forecast::BoxCox.lambda(y, method = "guerrero")
      } else {
        lam <- as.numeric(lam)
      }
      lambda_used <- lam
      y_plot <- forecast::BoxCox(y, lam)
    }
    
    df_use$y_plot <- as.numeric(y_plot)
    
    freq_use <- p$freq %||% 1
    ts_use <- stats::ts(df_use$y_plot, start = 1, frequency = freq_use)
    
    list(
      df = df_use,
      ts = ts_use,
      freq = freq_use,
      scope = scope,
      train_n = train_n,
      n_total = nrow(df_all),
      transform = tr,
      lambda_used = lambda_used,
      x_is_date = inherits(df_use$x, "Date"),
      x_is_dt   = inherits(df_use$x, "POSIXct") || inherits(df_use$x, "POSIXt")
    )
  })
  
  # ============================================================
  # 5) Labels helper (teaching subtitle)
  # ============================================================
  stp_labels <- function(d, default_title = "S(t)", default_y = "Value") {
    title_in <- input$stp_title %||% ""
    sub_in   <- input$stp_subtitle %||% ""
    x_in     <- input$stp_xlab %||% ""
    y_in     <- input$stp_ylab %||% ""
    
    scope_txt <- if (identical(d$scope, "train")) "training" else "full"
    n_txt <- paste0("n=", nrow(d$df))
    s_txt <- paste0("s=", d$freq)
    
    tr_txt <- switch(
      d$transform,
      "log" = "transform=log",
      "boxcox" = paste0("transform=BoxCox(Î»=", ifelse(is.finite(d$lambda_used), fmt_num(d$lambda_used, 3), "auto"), ")"),
      "none" = "transform=none",
      "transform=none"
    )
    
    teaching_sub <- paste(scope_txt, n_txt, s_txt, tr_txt, sep = " â€¢ ")
    
    list(
      title = if (nzchar(title_in)) title_in else default_title,
      subtitle = if (nzchar(sub_in)) sub_in else teaching_sub,
      x = if (nzchar(x_in)) x_in else "Time",
      y = if (nzchar(y_in)) y_in else default_y
    )
  }
  
  # ============================================================
  # 6) Smart date axis (NO ROTATION here)
  # ============================================================

  stp_apply_x_scale <- function(g, d) {
    if (!isTRUE(d$x_is_date) && !isTRUE(d$x_is_dt)) return(g)
    
    n_ticks <- as.integer(to_num(input$stp_x_ticks, 8))
    
    fmt_choice <- input$stp_date_format %||% "auto"
    fmt_custom <- input$stp_date_format_custom %||% "%Y-%m"
    lang <- input$stp_date_lang %||% "en"
    
    # ---- format selection ----
    fmt <- if (identical(fmt_choice, "custom")) fmt_custom else fmt_choice
    
    if (identical(fmt, "auto")) {
      n <- nrow(d$df)
      if (n <= 24) fmt <- "%b %Y"
      else if (n <= 120) fmt <- "%Y-%m"
      else fmt <- "%Y"
    }
    
    # ---- locale mapping ----
    locale_map <- c(
      "en" = "en",
      "fr" = "fr",
      "ar" = "ar"
    )
    locale_use <- locale_map[[lang]] %||% "en"
    
    # ---- label function (locale-aware) ----
    base_label_fun <- scales::label_date(
      format = fmt,
      locale = locale_use
    )
    
    # ---- force Western digits for Arabic labels only ----
    label_fun <- function(x) {
      lab <- base_label_fun(x)
      
      if (identical(lang, "ar")) {
        # Arabic-Indic: Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©
        arabic_indic <- c("Ù ","Ù¡","Ù¢","Ù£","Ù¤","Ù¥","Ù¦","Ù§","Ù¨","Ù©")
        # Eastern Arabic-Indic (Persian): Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹
        eastern_arabic_indic <- c("Û°","Û±","Û²","Û³","Û´","Ûµ","Û¶","Û·","Û¸","Û¹")
        western <- as.character(0:9)
        
        lab <- as.character(lab)
        for (i in 0:9) {
          lab <- gsub(arabic_indic[i + 1], western[i + 1], lab, fixed = TRUE)
          lab <- gsub(eastern_arabic_indic[i + 1], western[i + 1], lab, fixed = TRUE)
        }
      }
      
      lab
    }
    
    if (isTRUE(d$x_is_date)) {
      g + ggplot2::scale_x_date(
        labels = label_fun,
        breaks = scales::pretty_breaks(n = n_ticks)
      )
    } else {
      g + ggplot2::scale_x_datetime(
        labels = label_fun,
        breaks = scales::pretty_breaks(n = n_ticks)
      )
    }
  }
  
  
  
  # ============================================================
  # 7) UI dispatcher for multi-panel plot types
  # ============================================================
 
  output$stp_plot_ui <- renderUI({
    req(input$stp_plot_type)
    pt <- input$stp_plot_type
    h  <- to_num(input$stp_plot_height_px, 520)
    
    if (pt == "ACF+PACF") {
      
      fluidRow(
        column(6, plotOutput("stp_acf",  width = "100%", height = h)),
        column(6, plotOutput("stp_pacf", width = "100%", height = h))
      )
      
    } else if (pt == "Time + ACF+PACF") {
      
      gap_px <- round(h * 0.12)  # height of empty middle row
      
      fluidRow(
        column(
          12,
          
          # â”€â”€ Row 1: Time plot â”€â”€
          plotOutput("stp_main", width = "100%", height = round(h * 0.9)),
          
          # â”€â”€ Row 2: empty spacer row â”€â”€
          fluidRow(
            column(
              12,
              div(style = paste0("height:", gap_px, "px;"))
            )
          ),
          
          # â”€â”€ Row 3: ACF (left-indented) + PACF (right-indented) â”€â”€
          fluidRow(
            column(
              6,
              div(
                style = "padding-left: 24px;",
                plotOutput("stp_acf", width = "100%", height = round(h * 0.6))
              )
            ),
            column(
              6,
              div(
                style = "padding-right: 24px;",
                plotOutput("stp_pacf", width = "100%", height = round(h * 0.6))
              )
            )
          )
        )
      )
      
    } else if (pt == "Lag plot (1..m)") {
      
      plotOutput("stp_lag_grid", width = "100%", height = round(h * 1.2))
      
    } else if (pt == "ACF") {
      
      plotOutput("stp_acf", width = "100%", height = h)
      
    } else if (pt == "PACF") {
      
      plotOutput("stp_pacf", width = "100%", height = h)
      
    } else {
      
      plotOutput("stp_main", width = "100%", height = h)
      
    }
  })
  
  
  
  
  # ============================================================
  # 8) Main plot  (FIXED ORDER: theme first, x-scale last)
  # ============================================================
  output$stp_main <- renderPlot({
    d <- stp_data()
    df <- d$df
    pt <- input$stp_plot_type %||% "Line"
    
    line_col <- input$stp_line_color %||% "#2C7FB8"
    lw       <- to_num(input$stp_line_width, 1)
    pt_col   <- input$stp_point_color %||% line_col
    ps       <- to_num(input$stp_point_size, 2)
    fill_col <- input$stp_fill_color %||% line_col
    a        <- to_num(input$stp_alpha, 1)
    
    labs0 <- stp_labels(d, default_title = "S(t)", default_y = "Value")
    
    base <- ggplot2::ggplot(df, ggplot2::aes(x = x, y = y_plot)) +
      ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$x, y = labs0$y)
    
    # ---- plot switch ----
    if (pt == "Line") {
      g <- base + ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Points") {
      g <- base + ggplot2::geom_point(color = pt_col, size = ps, alpha = a)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Line + Points") {
      g <- base +
        ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a) +
        ggplot2::geom_point(color = pt_col, size = ps, alpha = a)
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    
    
    if (pt == "Smoothed (LOESS)") {
      span <- to_num(input$stp_loess_span, 0.4)
      
      n_full <- nrow(df)
      n_cap  <- 8000L                  # <= change if you want
      dfL    <- downsample_rows(df, n_max = n_cap)
      
      # confidence band is expensive: keep it only for smaller n
      show_se <- nrow(dfL) <= 2500L
      
      # points are also expensive: disable when too many
      show_points <- nrow(dfL) <= 6000L
      
      # OPTIONAL: add an informative subtitle when downsampling kicks in
      labsL <- labs0
      if (n_full > n_cap) {
        labsL$subtitle <- paste0(
          labs0$subtitle,
          if (nzchar(labs0$subtitle)) "  â€¢  " else "",
          "LOESS computed on ", nrow(dfL), "/", n_full, " points (downsampled for speed)."
        )
      }
      
      baseL <- ggplot2::ggplot(dfL, ggplot2::aes(x = x, y = y_plot)) +
        ggplot2::labs(title = labsL$title, subtitle = labsL$subtitle, x = labsL$x, y = labsL$y)
      
      g <- baseL
      if (show_points) {
        g <- g + ggplot2::geom_point(color = pt_col, size = ps, alpha = a)
      }
      
      g <- g +
        ggplot2::geom_smooth(
          method = "loess",
          span   = span,
          se     = show_se,
          color  = line_col,
          linewidth = lw,
          alpha  = 0.2
        )
      
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    

    if (pt == "Moving average") {
      k <- as.integer(to_num(input$stp_ma_k, 5))
      show_raw <- isTRUE(input$stp_ma_show_raw)
      
      df2 <- df
      df2$ma <- zoo::rollmean(df2$y_plot, k = k, fill = NA, align = "center")
      
      g <- ggplot2::ggplot(df2, ggplot2::aes(x = x)) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$x, y = labs0$y)
      
      if (show_raw) {
        g <- g + ggplot2::geom_line(ggplot2::aes(y = y_plot), color = "gray60", linewidth = 0.6, alpha = 0.7)
      }
      g <- g + ggplot2::geom_line(ggplot2::aes(y = ma), color = line_col, linewidth = lw, alpha = a)
      
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    if (pt == "Cumulative sum") {
      df2 <- df
      df2$cs <- cumsum(df2$y_plot)
      
      g <- ggplot2::ggplot(df2, ggplot2::aes(x = x, y = cs)) +
        ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$x, y = "Cumsum")
      
      g <- stp_apply_theme(g)
      g <- stp_apply_x_scale(g, d)
      return(g)
    }
    
    
    # ---- Seasonal plots ----
    if (pt %in% c("Seasonal plot", "Seasonal subseries", "Polar seasonal", "Seasonal boxplot")) {
      validate(need(is.finite(d$freq) && d$freq >= 2, "Seasonal plots require frequency >= 2."))
      
      x_ts <- d$ts  # ts object built from y_plot + frequency
      
      if (pt == "Seasonal plot") {
        g <- forecast::ggseasonplot(x_ts, polar = FALSE) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
        g <- stp_apply_palette(g)
        g <- stp_apply_theme(g)
        return(g)
      }
      
      if (pt == "Polar seasonal") {
        g <- forecast::ggseasonplot(x_ts, polar = TRUE) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
        g <- stp_apply_palette(g)
        g <- stp_apply_theme(g)
        return(g)
      }
      
      if (pt == "Seasonal subseries") {
        g <- forecast::ggsubseriesplot(x_ts) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
        g <- stp_apply_theme(g)
        return(g)
      }
      
      if (pt == "Seasonal boxplot") {
        df2 <- data.frame(season = factor(stats::cycle(x_ts)), y = as.numeric(x_ts))
        g <- ggplot2::ggplot(df2, ggplot2::aes(x = season, y = y, fill = season)) +
          ggplot2::geom_boxplot(alpha = 0.6) +
          ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = "Season", y = labs0$y)
        g <- stp_apply_palette(g)
        g <- stp_apply_theme(g)
        return(g)
      }
    }
    
    # ---- Decomposition plots ----
    if (pt %in% c("Classical decomposition (additive)", "Classical decomposition (multiplicative)")) {
      validate(need(is.finite(d$freq) && d$freq >= 2, "Decomposition requires frequency >= 2."))
      
      x_ts <- d$ts
      type <- if (pt == "Classical decomposition (multiplicative)") "multiplicative" else "additive"
      
      # multiplicative requires strictly positive values
      if (type == "multiplicative") {
        validate(need(all(as.numeric(x_ts) > 0), "Multiplicative decomposition requires strictly positive values."))
      }
      
      dc <- stats::decompose(x_ts, type = type)
      g <- forecast::autoplot(dc) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
      g <- stp_apply_theme(g)
      return(g)
    }
    
    if (pt == "STL decomposition") {
      validate(need(is.finite(d$freq) && d$freq >= 2, "STL requires frequency >= 2."))
      
      x_ts <- d$ts
      fit <- stats::stl(x_ts, s.window = "periodic", robust = TRUE)
      
      g <- forecast::autoplot(fit) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle)
      g <- stp_apply_theme(g)
      return(g)
    }
    
    
    
    
    if (pt == "Histogram") {
      bins <- as.integer(to_num(input$stp_hist_bins, 30))
      g <- ggplot2::ggplot(df, ggplot2::aes(x = y_plot)) +
        ggplot2::geom_histogram(bins = bins, fill = fill_col, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$y, y = "Count")
      return(stp_apply_theme(g))
    }
    
    if (pt == "Density") {
      bw_adj <- to_num(input$stp_bw_adj, 1)
      g <- ggplot2::ggplot(df, ggplot2::aes(x = y_plot)) +
        ggplot2::geom_density(adjust = bw_adj, fill = fill_col, alpha = 0.25) +
        ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = labs0$y, y = "Density")
      return(stp_apply_theme(g))
    }
    
    if (pt == "QQ plot") {
      g <- ggplot2::ggplot(df, ggplot2::aes(sample = y_plot)) +
        ggplot2::stat_qq(color = pt_col, alpha = a) +
        ggplot2::stat_qq_line(color = line_col, linewidth = lw) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = "Theoretical", y = "Sample")
      return(stp_apply_theme(g))
    }
    
    if (pt == "Lag-1 scatter") {
      y <- df$y_plot
      validate(need(length(y) >= 3, "Not enough observations for lag scatter."))
      dfl <- data.frame(x = y[-length(y)], y = y[-1])
      g <- ggplot2::ggplot(dfl, ggplot2::aes(x = x, y = y)) +
        ggplot2::geom_point(color = pt_col, size = ps, alpha = a) +
        ggplot2::labs(title = labs0$title, subtitle = labs0$subtitle, x = "S(t-1)", y = "S(t)")
      return(stp_apply_theme(g))
    }
    
    # (seasonal/decomposition/periodogram parts unchanged...)
    stp_apply_theme(base + ggplot2::geom_line(color = line_col, linewidth = lw, alpha = a))
    
  }, width  = function() to_num(input$stp_plot_width_px, 980),
  height = function() to_num(input$stp_plot_height_px, 520))
  
  # ============================================================
  # 9) ACF/PACF panels
  # ============================================================
  output$stp_acf <- renderPlot({
    d <- stp_data()
    x_ts <- d$ts
    
    # --- slider-driven lag (robust + capped) ---
    S_Lag <- suppressWarnings(as.integer(input$stp_corr_lag))
    if (!is.finite(S_Lag) || S_Lag < 1) S_Lag <- 40L   # default = UI value
    S_Lag <- max(1L, min(S_Lag, length(x_ts) - 1L))
    
    g <- forecast::ggAcf(x_ts, lag.max = S_Lag) +
      ggplot2::labs(title = "ACF", subtitle = stp_labels(d)$subtitle)
    
    stp_apply_theme(g)
  })
  
  output$stp_pacf <- renderPlot({
    d <- stp_data()
    x_ts <- d$ts
    
    # --- slider-driven lag (robust + capped) ---
    S_Lag <- suppressWarnings(as.integer(input$stp_corr_lag))
    if (!is.finite(S_Lag) || S_Lag < 1) S_Lag <- 40L
    S_Lag <- max(1L, min(S_Lag, length(x_ts) - 1L))
    
    g <- forecast::ggPacf(x_ts, lag.max = S_Lag) +
      ggplot2::labs(title = "PACF", subtitle = stp_labels(d)$subtitle)
    
    stp_apply_theme(g)
  })
  
  
  
  
  # ============================================================
  # 10) Lag grid (1..m)
  # ============================================================
  output$stp_lag_grid <- renderPlot({
    d <- stp_data()
    df <- d$df
    
    m <- as.integer(to_num(input$stp_lag_m, 12))
    validate(need(m >= 1, "m must be >= 1."))
    
    y <- df$y_plot
    validate(need(length(y) >= (m + 2), "Not enough observations for requested lag grid."))
    
    out <- lapply(1:m, function(k) {
      data.frame(
        lag = paste0("Lag ", k),
        x = y[seq_len(length(y) - k)],
        y = y[(k + 1):length(y)]
      )
    })
    dfl <- do.call(rbind, out)
    
    pt_col <- input$stp_point_color %||% "#2C7FB8"
    ps <- to_num(input$stp_point_size, 2)
    a  <- to_num(input$stp_alpha, 1)
    
    g <- ggplot2::ggplot(dfl, ggplot2::aes(x = x, y = y)) +
      ggplot2::geom_point(color = pt_col, size = ps, alpha = a) +
      ggplot2::facet_wrap(~ lag, scales = "free", ncol = 3) +
      ggplot2::labs(title = "Lag plots (1..m)", subtitle = stp_labels(d)$subtitle, x = "S(t-k)", y = "S(t)")
    
    stp_apply_theme(g)
    
  }, width  = function() to_num(input$stp_plot_width_px, 980),
  height = function() round(to_num(input$stp_plot_height_px, 520) * 1.2))
  
  
  
  
  
  
  
  
  
  
  
  
  
  # ---- Step 3 outputs ----

  output$decomp_add <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    plot(decompose(x, type = "additive"))
  })

  output$decomp_mul <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    validate(need(frequency(x) >= 2, "Decomposition needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    validate(need(all(as.numeric(x) > 0), "Multiplicative decomposition requires strictly positive values."))
    plot(decompose(x, type = "multiplicative"))
  })

  output$stl_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    validate(need(frequency(x) >= 2, "STL needs frequency >= 2."))
    validate(need(length(x) >= 2 * frequency(x), "Need at least 2 seasonal cycles."))
    fit <- stl(x, s.window = "periodic", robust = TRUE)
    plot(fit, main = "STL decomposition (robust)")
  })

  output$apa_decomp_paragraph <- renderPrint({
    cat(
      "APA-ready paragraph (edit based on which decomposition you used):\n\n",
      "Decomposition methods were used to separate the series into trend, seasonal, and remainder components. ",
      "Classical decomposition was evaluated under additive and multiplicative assumptions, and robust STL decomposition ",
      "was also examined to reduce the influence of potential outliers. ",
      "The decomposition results provided evidence regarding the stability of seasonality and the magnitude of irregular variation.\n",
      sep = ""
    )
  })

  # ---- Step 4 outputs ----

  output$diff_suggestion <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    d_rec <- tryCatch(forecast::ndiffs(x), error = function(e) NA_integer_)
    D_rec <- tryCatch(forecast::nsdiffs(x), error = function(e) NA_integer_)
    cat("Suggested differencing (heuristics):\n")
    cat("- ndiffs (d):", d_rec, "\n")
    cat("- nsdiffs (D):", D_rec, "\n")
  })
  
 
  
  stationarity <- eventReactive(input$run_tests, {
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0) a else b
    to_int <- function(x, d = 0L) { v <- suppressWarnings(as.integer(x)); if (!is.finite(v)) d else v }
    
    s <- ts_train_test()
    x <- as.numeric(stats::na.omit(s$ts_train))
    x <- x[is.finite(x)]
    
    k <- max(0L, to_int(input$adf_lags, 10L))
    
    # single source of truth for the deterministic type
    type_used <- tolower(as.character(input$adf_type %||% input$adfTypeSt2 %||% "drift"))
    type_used <- if (type_used %in% c("none", "drift", "trend")) type_used else "drift"
    
    alpha_used <- suppressWarnings(as.numeric(input$alphaSt2 %||% 0.05))
    if (!is.finite(alpha_used)) alpha_used <- 0.05
    
    out <- list(
      type_used  = type_used,
      alpha_used = alpha_used,
      k_used     = k,
      series     = x
    )
    
    # run tests (keep errors if any)
    out$adf <- tryCatch(
      tseries::adf.test(x, k = k, alternative = input$alternd2St %||% "stationary"),
      error = function(e) { out$adf_error <<- e$message; NULL }
    )
    
    out$kpss <- tryCatch({
      null_kpss <- if (identical(type_used, "trend")) "Trend" else "Level"
      tseries::kpss.test(x, null = null_kpss)
    }, error = function(e) { out$kpss_error <<- e$message; NULL })
    
    out$pp <- tryCatch(
      tseries::pp.test(x),
      error = function(e) { out$pp_error <<- e$message; NULL }
    )
    
    out$ur <- tryCatch(
      urca::ur.df(x, type = type_used, lags = k),
      error = function(e) { out$ur_error <<- e$message; NULL }
    )
    
    # NEW: Auto-lag ADF (AIC)
    out$ur_auto <- tryCatch(
      urca::ur.df(x, type = type_used, selectlags = "AIC"),
      error = function(e) { out$ur_auto_error <<- e$message; NULL }
    )
    
    # Infer chosen k from regression terms: number of z.diff* terms ~= k
    out$k_auto <- tryCatch({
      if (is.null(out$ur_auto)) return(NA_integer_)
      sm <- summary(out$ur_auto)
      rn <- rownames(sm@testreg$coefficients)
      as.integer(sum(grepl("^z\\.diff", rn)))
    }, error = function(e) NA_integer_)
    
    out
  })
  
  
 
  
  alpha_to_col <- function(a) {
    if (!is.finite(a)) return("5pct")
    if (abs(a - 0.01) < 1e-8) return("1pct")
    if (abs(a - 0.05) < 1e-8) return("5pct")
    if (abs(a - 0.10) < 1e-8 || abs(a - 0.1) < 1e-8) return("10pct")
    "5pct"
  }
  
  extract_tau_urdf <- function(ur_obj, alpha_used = 0.05, type_used = NULL) {
    out <- list(tau_obs = NA_real_, tau_crit = NA_real_, tau_row = NA_character_, alpha_col = NA_character_)
    if (is.null(ur_obj)) return(out)
    
    # tau observed: first entry whose name starts with "tau" (fallback: first element)
    ts_vec <- tryCatch(ur_obj@teststat, error = function(e) NULL)
    if (!is.null(ts_vec)) {
      nms <- names(ts_vec)
      if (!is.null(nms)) {
        idx <- grep("^tau", nms)
        out$tau_obs <- suppressWarnings(as.numeric(ts_vec[ if (length(idx)) idx[1] else 1 ]))
      } else {
        out$tau_obs <- suppressWarnings(as.numeric(ts_vec[1]))
      }
    }
    
    cv <- tryCatch(ur_obj@cval, error = function(e) NULL)
    if (is.null(cv)) return(out)
    
    # Work with matrix cval (usual case)
    if (is.matrix(cv)) {
      rnames <- rownames(cv); cnames <- colnames(cv)
      
      # preferred tau row from declared type
      tau_pref <- switch(tolower(type_used %||% ""), "none" = "tau1", "drift" = "tau2", "trend" = "tau3", NA_character_)
      tau_rows <- grep("^tau", rnames, value = TRUE)
      
      row_pick <- if (!is.na(tau_pref) && tau_pref %in% rnames) tau_pref else if (length(tau_rows)) tau_rows[1] else NA_character_
      out$tau_row <- row_pick
      
      col_pick <- alpha_to_col(alpha_used)
      if (!is.null(cnames) && !(col_pick %in% cnames)) {
        # choose the nearest available alpha column
        pct <- suppressWarnings(as.numeric(gsub("pct", "", cnames)))/100
        if (any(is.finite(pct))) col_pick <- cnames[ which.min(abs(pct - alpha_used)) ] else col_pick <- cnames[1]
      }
      out$alpha_col <- col_pick
      
      if (!is.na(row_pick) && !is.null(col_pick) && row_pick %in% rnames && col_pick %in% cnames) {
        out$tau_crit <- suppressWarnings(as.numeric(cv[row_pick, col_pick]))
      }
      return(out)
    }
    
    # Named vector fallback (rare)
    col_pick <- alpha_to_col(alpha_used)
    out$alpha_col <- col_pick
    if (!is.null(names(cv)) && col_pick %in% names(cv)) {
      out$tau_crit <- suppressWarnings(as.numeric(cv[[col_pick]]))
    }
    out
  }
  
  
  
 
  
  
  
  
  output$stationarity_results <- renderPrint({
    req(stationarity())
    st <- stationarity()
    
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0) a else b
    to_num <- function(x, d = NA_real_) {
      y <- suppressWarnings(as.numeric(x))
      if (length(y) == 0 || all(is.na(y)) || !is.finite(y[1])) d else y[1]
    }
    fmt_p   <- if (exists("fmt_p", inherits = TRUE)) get("fmt_p") else function(p) if (!is.finite(p)) "NA" else format.pval(p, digits = 4, eps = .Machine$double.eps)
    fmt_num <- if (exists("fmt_num", inherits = TRUE)) get("fmt_num") else function(x, d = 4) if (!is.finite(x)) "NA" else format(round(x, d), nsmall = d)
    
    adf_type_ui  <- input$adfTypeSt2 %||% "trend"
    k_lags       <- to_num(input$LagOrderADFd2St, 10)
    alpha        <- to_num(input$alphaSt2, 0.05)
    kpss_null_ui <- if (identical(adf_type_ui, "trend")) "tau" else "mu"
    
    tau_row   <- switch(adf_type_ui, "none"="tau1", "drift"="tau2", "trend"="tau3", "tau3")
    alpha_col <- switch(as.character(alpha), "0.01"="1pct", "0.05"="5pct", "0.1"="10pct", "0.10"="10pct", "5pct")
    
    adf_p     <- if (!is.null(st$adf))  to_num(st$adf$p.value)    else NA_real_
    adf_stat  <- if (!is.null(st$adf))  to_num(st$adf$statistic)  else NA_real_
    kpss_p    <- if (!is.null(st$kpss)) to_num(st$kpss$p.value)   else NA_real_
    kpss_stat <- if (!is.null(st$kpss)) to_num(st$kpss$statistic) else NA_real_
    pp_p      <- if (!is.null(st$pp))   to_num(st$pp$p.value)     else NA_real_
    pp_stat   <- if (!is.null(st$pp))   to_num(st$pp$statistic)   else NA_real_
    
    tau_obs  <- NA_real_
    tau_crit <- NA_real_
    if (!is.null(st$ur)) {
      tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[tau_row]))
      if (!is.finite(tau_obs)) tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[1]))
      cv <- tryCatch(st$ur@cval, error = function(e) NULL)
      if (!is.null(cv) && is.matrix(cv) && !is.null(rownames(cv)) && !is.null(colnames(cv)) &&
          tau_row %in% rownames(cv) && alpha_col %in% colnames(cv)) {
        tau_crit <- suppressWarnings(as.numeric(cv[tau_row, alpha_col]))
      } else if (!is.null(cv) && !is.matrix(cv) && !is.null(names(cv)) && alpha_col %in% names(cv)) {
        tau_crit <- suppressWarnings(as.numeric(cv[[alpha_col]]))
      }
    }
    
    adf_dec_ts  <- if (is.finite(adf_p))  (adf_p  < alpha) else NA
    adf_dec_ur  <- if (is.finite(tau_obs) && is.finite(tau_crit)) (tau_obs < tau_crit) else NA
    kpss_reject <- if (is.finite(kpss_p)) (kpss_p < alpha) else NA
    pp_reject   <- if (is.finite(pp_p))   (pp_p   < alpha) else NA
    
    cat("==========================================================================\n")
    cat("           ACADEMIC REPORT: STATIONARITY TESTS (TRAINING SERIES)          \n")
    cat("==========================================================================\n")
    cat(sprintf(" Significance Level (Î±): %.2f\n", alpha))
    cat("--------------------------------------------------------------------------\n")
    
    # 1) ADF (tseries)
    cat(" 1) AUGMENTED DICKEYâ€“FULLER â€” tseries::adf.test\n")
    if (is.null(st$adf)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  â€¢ Parametric unit-root test with lagged differences (need for differencing d).\n")
      cat(" HYPOTHESES:\n")
      cat("  â€¢ H0: Unit root (non-stationary)\n")
      cat("  â€¢ Ha: Stationary\n")
      cat(sprintf(" DECISION RULE (Î±=%.2f): Reject H0 if P-value < Î±.\n", alpha))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  â€¢ Proper lag length k; low power near unit root.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  â€¢ DF statistic : %s\n", fmt_num(adf_stat, 4)))
      cat(sprintf("  â€¢ P-value      : %s\n\n", fmt_p(adf_p)))
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ts)) {
        cat("  â†’ P-value < Î± â‡’ REJECT H0 â‡’ Stationarity suggested.\n")
      } else if (identical(adf_dec_ts, FALSE)) {
        cat("  â†’ P-value â‰¥ Î± â‡’ FAIL TO REJECT H0 â‡’ Possible unit root.\n")
      } else cat("  â†’ Inconclusive (p-value NA/Inf).\n")
      cat(" SUGGESTIONS:\n")
      cat("  â€¢ If ADF fails but KPSS rejects, prefer d=1 and re-test.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # 2) ADF (ur.df)
    cat(" 2) ADF â€” urca::ur.df (tau vs. critical)\n")
    if (is.null(st$ur)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  â€¢ ADF with explicit deterministic component and chosen lag order.\n")
      cat(" HYPOTHESES:\n")
      cat("  â€¢ H0: Unit root (non-stationary)\n")
      cat("  â€¢ Ha: Stationary\n")
      cat(sprintf(" DECISION RULE (Î±=%.2f, %s): Reject H0 if Tau-Obs < Tau-Crit.\n", alpha, alpha_col))
      cat(" SPECIFICATION:\n")
      cat(sprintf("  â€¢ Model type : %s   â€¢ Lags (k): %s\n", adf_type_ui, as.character(k_lags)))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  â€¢ Wrong type (none/drift/trend) or too-small k can bias inference.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  â€¢ Tau-Obs    : %s\n", fmt_num(tau_obs, 4)))
      cat(sprintf("  â€¢ Tau-Crit   : %s (%s)\n\n", fmt_num(tau_crit, 4), alpha_col))
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ur)) {
        cat("  â†’ Tau-Obs < Tau-Crit â‡’ REJECT H0 â‡’ Stationarity supported.\n")
      } else if (identical(adf_dec_ur, FALSE)) {
        cat("  â†’ Tau-Obs â‰¥ Tau-Crit â‡’ FAIL TO REJECT H0 â‡’ Possible unit root.\n")
      } else cat("  â†’ Inconclusive (tau/critical NA).\n")
      cat(" SUGGESTIONS:\n")
      cat("  â€¢ If residuals autocorrelate (Ljungâ€“Box), increase k or difference the series.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # 3) KPSS
    cat(" 3) KPSS â€” tseries::kpss.test\n")
    if (is.null(st$kpss)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  â€¢ Tests null of stationarity (level or trend); complements ADF/PP.\n")
      cat(" HYPOTHESES:\n")
      cat(sprintf("  â€¢ H0: Stationary around a %s\n", ifelse(kpss_null_ui == "tau", "trend", "level")))
      cat("  â€¢ Ha: Non-stationary (unit root)\n")
      cat(sprintf(" DECISION RULE (Î±=%.2f): Reject H0 if P-value < Î±.\n", alpha))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  â€¢ Sensitive to unremoved trend/seasonality; small-sample distortions.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  â€¢ KPSS Î·     : %s\n", fmt_num(kpss_stat, 4)))
      cat(sprintf("  â€¢ P-value    : %s\n\n", fmt_p(kpss_p)))
      cat(" DECISION:\n")
      if (isTRUE(kpss_reject)) {
        cat("  â†’ P-value < Î± â‡’ REJECT H0 â‡’ Evidence of NON-STATIONARITY.\n")
      } else if (identical(kpss_reject, FALSE)) {
        cat("  â†’ P-value â‰¥ Î± â‡’ FAIL TO REJECT H0 â‡’ Stationarity is plausible.\n")
      } else cat("  â†’ Inconclusive (p-value NA/Inf).\n")
      cat(" SUGGESTIONS:\n")
      cat("  â€¢ If KPSS rejects and ADF/PP donâ€™t, set d=1 (and D=1 if seasonal), then re-test.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # 4) PP
    cat(" 4) PHILLIPSâ€“PERRON â€” tseries::pp.test\n")
    if (is.null(st$pp)) {
      cat("    Not available.\n")
    } else {
      cat(" USE CASE:\n")
      cat("  â€¢ Unit-root test with nonparametric correction (robust to serial correlation/heteroskedasticity).\n")
      cat(" HYPOTHESES:\n")
      cat("  â€¢ H0: Unit root (non-stationary)\n")
      cat("  â€¢ Ha: Stationary\n")
      cat(sprintf(" DECISION RULE (Î±=%.2f): Reject H0 if P-value < Î±.\n", alpha))
      cat(" ASSUMPTIONS & CAVEATS:\n")
      cat("  â€¢ Low power near unit root; interpret with KPSS.\n\n")
      cat(" STATISTICS:\n")
      cat(sprintf("  â€¢ PP statistic : %s\n", fmt_num(pp_stat, 4)))
      cat(sprintf("  â€¢ P-value      : %s\n\n", fmt_p(pp_p)))
      cat(" DECISION:\n")
      if (isTRUE(pp_reject)) {
        cat("  â†’ P-value < Î± â‡’ REJECT H0 â‡’ Stationarity suggested.\n")
      } else if (identical(pp_reject, FALSE)) {
        cat("  â†’ P-value â‰¥ Î± â‡’ FAIL TO REJECT H0 â‡’ Possible unit root.\n")
      } else cat("  â†’ Inconclusive (p-value NA/Inf).\n")
      cat(" SUGGESTIONS:\n")
      cat("  â€¢ If PP & ADF fail but KPSS rejects, difference (d=1; D=1 if seasonal) and re-test.\n")
      cat("--------------------------------------------------------------------------\n")
    }
    
    # Synthesis
    cat(" SYNTHESIS & PRACTICAL RECOMMENDATIONS\n")
    if ((isTRUE(adf_dec_ts) || isTRUE(adf_dec_ur) || isTRUE(pp_reject)) && !isTRUE(kpss_reject)) {
      cat(" â€¢ Convergent STATIONARITY: use d=0; if seasonal, model with SARIMA terms rather than differencing more.\n")
    } else if ((identical(adf_dec_ts, FALSE) || identical(adf_dec_ur, FALSE) || identical(pp_reject, FALSE)) && isTRUE(kpss_reject)) {
      cat(" â€¢ Convergent UNIT ROOT: set d=1 (and D=1 if seasonal), then re-test before identification.\n")
    } else {
      cat(" â€¢ Mixed results: align deterministic spec (none/drift/trend), tune ADF lag k (check Ljungâ€“Box),\n")
      cat("   treat seasonality first (D=1 if needed), consider log/Boxâ€“Cox for variance, and check for breaks.\n")
    }
    cat("\n==========================================================================\n\n")
  })
  
  
  
 
  
  
  
  
  
  
  
  output$stationarity_interpretation <- renderPrint({
    req(stationarity())
    st <- stationarity()
    
    # ---- helpers ----
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0) a else b
    to_num <- function(x, d = NA_real_) {
      y <- suppressWarnings(as.numeric(x))
      ifelse(is.finite(y), y, d)
    }
    to_int <- function(x, d = NA_integer_) {
      y <- suppressWarnings(as.integer(x))
      ifelse(is.finite(y), y, d)
    }
    
    fmt_p <- if (exists("fmt_p", inherits = TRUE)) get("fmt_p") else function(p) {
      if (!is.finite(p)) return("NA")
      format.pval(p, digits = 4, eps = .Machine$double.eps)
    }
    fmt_num <- if (exists("fmt_num", inherits = TRUE)) get("fmt_num") else function(x, d = 4) {
      if (!is.finite(x)) return("NA")
      format(round(x, d), nsmall = d)
    }
    
    # ---- series used ----
    n_used <- if (!is.null(st$series)) length(st$series) else NA_integer_
    
    # Prefer stationarity() metadata when available
    adf_type_ui <- st$type_used %||% (input$adfTypeSt2 %||% "drift")
    alpha <- to_num(st$alpha_used, to_num(input$alphaSt2, 0.05))
    
    # fixed-lag (user-provided) metadata
    k_lags <- as.integer(to_num(st$k_used, to_num(input$LagOrderADFd2St, 10)))
    
    # auto-lag metadata (AIC among 0..Kmax)
    k_auto <- as.integer(to_num(st$k_auto, NA_real_))
    max_lag_auto <- as.integer(to_num(st$max_lag_auto, NA_real_))
    
    # KPSS null pairing (informational)
    kpss_null_ui <- if (adf_type_ui == "trend") "tau" else "mu"
    
    # Map for ur.df critical values
    tau_row <- switch(adf_type_ui, "none" = "tau1", "drift" = "tau2", "trend" = "tau3", "tau3")
    alpha_col <- switch(
      as.character(alpha),
      "0.01" = "1pct",
      "0.05" = "5pct",
      "0.1"  = "10pct",
      "0.10" = "10pct",
      "5pct"
    )
    
    # =========================
    # NEW: Python-like ADF (no k specified) + report chosen lag
    # tseries::adf.test default lag rule:
    #   k_default = trunc((n - 1)^(1/3))
    # =========================
    k_default_adf <- NA_integer_
    if (is.finite(n_used) && n_used >= 2) {
      k_default_adf <- as.integer(trunc((n_used - 1)^(1/3)))
      if (!is.finite(k_default_adf) || k_default_adf < 0L) k_default_adf <- NA_integer_
    }
    
    adf_auto_obj  <- NULL
    adf_auto_p    <- NA_real_
    adf_auto_stat <- NA_real_
    adf_auto_err  <- NULL
    
    # Run WITHOUT specifying k (Python-like)
    if (!is.null(st$series) && length(st$series) >= 10) {
      adf_auto_obj <- tryCatch(
        tseries::adf.test(st$series, alternative = input$alternd2St %||% "stationary"),
        error = function(e) { adf_auto_err <<- e$message; NULL }
      )
      if (!is.null(adf_auto_obj)) {
        adf_auto_p    <- to_num(adf_auto_obj$p.value)
        adf_auto_stat <- to_num(adf_auto_obj$statistic)
      }
    }
    
    # ---- fixed-lag ur.df tau & crit ----
    tau_obs <- NA_real_
    tau_crit <- NA_real_
    if (!is.null(st$ur)) {
      tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[tau_row]))
      if (!is.finite(tau_obs)) tau_obs <- suppressWarnings(as.numeric(st$ur@teststat[1]))
      
      cv <- tryCatch(st$ur@cval, error = function(e) NULL)
      if (!is.null(cv) && is.matrix(cv) &&
          tau_row %in% rownames(cv) && alpha_col %in% colnames(cv)) {
        tau_crit <- suppressWarnings(as.numeric(cv[tau_row, alpha_col]))
      }
    }
    
    # ---- auto-lag ur.df tau & crit ----
    tau_obs_auto <- NA_real_
    tau_crit_auto <- NA_real_
    if (!is.null(st$ur_auto)) {
      tau_obs_auto <- suppressWarnings(as.numeric(st$ur_auto@teststat[tau_row]))
      if (!is.finite(tau_obs_auto)) tau_obs_auto <- suppressWarnings(as.numeric(st$ur_auto@teststat[1]))
      
      cv2 <- tryCatch(st$ur_auto@cval, error = function(e) NULL)
      if (!is.null(cv2) && is.matrix(cv2) &&
          tau_row %in% rownames(cv2) && alpha_col %in% colnames(cv2)) {
        tau_crit_auto <- suppressWarnings(as.numeric(cv2[tau_row, alpha_col]))
      }
    }
    
    # ---- tseries numbers (your existing fixed-k ADF) ----
    adf_p    <- if (!is.null(st$adf))  to_num(st$adf$p.value)    else NA_real_
    adf_stat <- if (!is.null(st$adf))  to_num(st$adf$statistic)  else NA_real_
    
    kpss_p    <- if (!is.null(st$kpss)) to_num(st$kpss$p.value)   else NA_real_
    kpss_stat <- if (!is.null(st$kpss)) to_num(st$kpss$statistic) else NA_real_
    
    pp_p    <- if (!is.null(st$pp)) to_num(st$pp$p.value) else NA_real_
    pp_stat <- if (!is.null(st$pp)) to_num(st$pp$statistic) else NA_real_
    
    # ---- lags used by tests (best effort) ----
    adf_lags_used <- k_lags
    kpss_lags_used <- if (!is.null(st$kpss) && !is.null(st$kpss$parameter)) as.integer(to_num(st$kpss$parameter)) else NA_integer_
    pp_lags_used   <- if (!is.null(st$pp)   && !is.null(st$pp$parameter))   as.integer(to_num(st$pp$parameter))   else NA_integer_
    
    # ---- decisions ----
    adf_auto_dec_ts <- if (is.finite(adf_auto_p)) (adf_auto_p < alpha) else NA
    
    adf_dec_ts      <- if (is.finite(adf_p)) (adf_p < alpha) else NA
    adf_dec_ur      <- if (is.finite(tau_obs) && is.finite(tau_crit)) (tau_obs < tau_crit) else NA
    adf_dec_ur_auto <- if (is.finite(tau_obs_auto) && is.finite(tau_crit_auto)) (tau_obs_auto < tau_crit_auto) else NA
    
    kpss_reject <- if (is.finite(kpss_p)) (kpss_p < alpha) else NA
    pp_reject   <- if (is.finite(pp_p)) (pp_p < alpha) else NA
    
    # ---- HEADER ----
    cat("==========================================================================\n")
    cat("                 ACADEMIC REPORT: STATIONARITY ANALYSIS                   \n")
    cat("==========================================================================\n")
    cat(" Number of Observations Used: ", ifelse(is.finite(n_used), n_used, "NA"), "\n", sep = "")
    cat(" Significance Level (Î±): ", format(alpha, nsmall = 2), "\n", sep = "")
    cat("--------------------------------------------------------------------------\n")
    
    # ---- TEACHING NOTES: overview ----
    cat(" STATIONARITY ANALYSIS (overview):\n")
    cat(" â€¢ Stationarity in SARIMA usually means: mean/variance roughly stable over time and autocorrelation decays.\n")
    cat(" â€¢ ADF / PP: H0 = unit root (non-stationary). KPSS: H0 = stationary. They complement each other.\n")
    cat(" â€¢ Differencing guidance:\n")
    cat("    - Use d for non-seasonal trend; use D for seasonal unit roots.\n")
    cat("    - Avoid over-differencing: it can induce negative autocorrelation and inflate forecast variance.\n")
    cat(" â€¢ Deterministic terms (ur.df type):\n")
    cat("    - none: no intercept/trend; drift: intercept; trend: intercept + deterministic trend.\n")
    cat(" â€¢ Caution: structural breaks/outliers can make unit-root tests misleading. Always check plots.\n")
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 1A) Python-like ADF (tseries::adf.test with automatic k) ----
    cat(" 1A. ADF â€” tseries::adf.test (AUTO Lag : k)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(adf_auto_obj)) {
      cat("    Not available.\n")
      if (!is.null(adf_auto_err)) cat("    Reason: ", adf_auto_err, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" â€¢ H0: the series has a unit root (non-stationary)\n")
      cat(" â€¢ Ha: the series is stationary\n")
      cat(" â€¢ Reject H0 if P-value < Î±.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - Lag selection       : automatic (no k provided)\n")
      cat("    - Default lag formula : k = trunc((n - 1)^(1/3))\n")
      cat("    - n used              : ", ifelse(is.finite(n_used), n_used, "NA"), "\n", sep = "")
      cat("    - #Lags chosen (k)    : ", ifelse(is.finite(k_default_adf), k_default_adf, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic (DF) : ", fmt_num(adf_auto_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(adf_auto_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_auto_dec_ts)) {
        cat("  P-value < Î± â‡’ REJECT H0: Evidence suggests STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  This result mirrors common Python workflows: the ADF lag length is chosen automatically based on sample size.\n")
        cat("  Rejecting H0 suggests the series does not behave like a unit-root process under this default lag choice.\n")
        cat("  In SARIMA practice, this reduces the need for non-seasonal differencing (d), but you should still check seasonal\n")
        cat("  patterns (possibly D) and confirm with KPSS/PP plus ACF/PACF.\n")
      } else if (identical(adf_auto_dec_ts, FALSE)) {
        cat("  P-value â‰¥ Î± â‡’ FAIL TO REJECT H0: Evidence suggests NON-STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  With automatic lag choice, failing to reject H0 indicates a unit root remains plausible, so differencing is typically\n")
        cat("  justified (often d = 1). After differencing, re-run tests: if results flip to stationarity and residual diagnostics look\n")
        cat("  white-noise-like, you have a good basis for ARIMA modeling.\n")
      } else {
        cat("  ADF p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  When p-values are unavailable/non-finite, rely more on the ur.df tau/critical approach, KPSS/PP, and especially the time\n")
        cat("  plot + ACF/PACF. Also verify the series isnâ€™t constant and has enough variation after cleaning.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 1) ADF (tseries::adf.test) fixed k (your existing one) ----
    cat(" 1B. ADF â€” tseries::adf.test (FIXED k)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$adf)) {
      cat("    Not available.\n")
      if (!is.null(st$adf_error)) cat("    Reason: ", st$adf_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" â€¢ H0: the series has a unit root (non-stationary)\n")
      cat(" â€¢ Ha: the series is stationary\n")
      cat(" â€¢ Reject H0 if P-value < Î±.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - #Lags Used (k)      : ", ifelse(is.finite(adf_lags_used), adf_lags_used, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic (DF) : ", fmt_num(adf_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(adf_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ts)) {
        cat("  P-value < Î± â‡’ REJECT H0: Evidence suggests STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Under the chosen fixed lag k, the unit-root null is rejected. This supports treating the series as stationary after\n")
        cat("  accounting for autocorrelation up to k lags. If this disagrees with KPSS, treat evidence as mixed and validate with\n")
        cat("  residual diagnostics and forecast performance.\n")
      } else if (identical(adf_dec_ts, FALSE)) {
        cat("  P-value â‰¥ Î± â‡’ FAIL TO REJECT H0: Evidence suggests NON-STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  With the selected fixed lag, a unit root cannot be ruled out. Consider differencing (d) and then re-check ACF/PACF.\n")
        cat("  If the ACF still shows seasonal spikes at multiples of s, consider seasonal differencing (D).\n")
      } else {
        cat("  ADF p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  When ADF is inconclusive, rely on ur.df tau/critical, PP, and KPSS along with plots. In teaching settings, it helps to\n")
        cat("  compare fixed-k vs auto-k to show sensitivity to lag choice.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 2) ADF (urca::ur.df) fixed lag ----
    cat(" 2A. ADF â€” urca::ur.df (FIXED lags; tau vs. critical)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$ur)) {
      cat("    Not available.\n")
      if (!is.null(st$ur_error)) cat("    Reason: ", st$ur_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" â€¢ H0: the series has a unit root (non-stationary)\n")
      cat(" â€¢ Ha: the series is stationary\n")
      cat(" â€¢ Reject H0 if Tau-Observed < Tau-Critical.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - Model type          : ", adf_type_ui, "  (none/drift/trend)\n", sep = "")
      cat("    - #Lags Used (k)      : ", ifelse(is.finite(k_lags), k_lags, "NA"), "\n", sep = "")
      
      cat(" CRITICAL VALUE:\n")
      cat("    - Tau Critical        : ", fmt_num(tau_crit, 4), " (", alpha_col, ")\n\n", sep = "")
      
      cat(" STATISTICS:\n")
      cat("    - Tau Observed        : ", fmt_num(tau_obs, 4), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ur)) {
        cat("  Tau-Obs < Tau-Crit â‡’ REJECT H0: Stationarity supported.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  The ur.df version is useful for teaching because it explicitly shows the deterministic component and uses a tau statistic\n")
        cat("  compared to critical values. Rejection strengthens the case for d = 0, but always check if seasonality implies D > 0.\n")
      } else if (identical(adf_dec_ur, FALSE)) {
        cat("  Tau-Obs â‰¥ Tau-Crit â‡’ FAIL TO REJECT H0: Possible unit root.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Failing to reject here suggests non-stationarity under the chosen deterministic component and lag order. In practice, try\n")
        cat("  differencing and re-run tests; in teaching, compare type=drift vs type=trend to show how assumptions change conclusions.\n")
      } else {
        cat("  Tau or critical value missing; cannot form a decision.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If critical values are missing (package/version issues), use PP + KPSS and emphasize plot-based diagnostics.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 2A) ADF (urca::ur.df) automatic lag selection ----
    cat(" 2B. ADF â€” urca::ur.df (AUTOMATIC lags via AIC; tau vs. critical)\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$ur_auto)) {
      cat("    Not available.\n")
      if (!is.null(st$ur_auto_error)) cat("    Reason: ", st$ur_auto_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" â€¢ H0: the series has a unit root (non-stationary)\n")
      cat(" â€¢ Ha: the series is stationary\n")
      cat(" â€¢ Lags are selected automatically using AIC within 0..Kmax.\n")
      cat(" â€¢ Reject H0 if Tau-Observed < Tau-Critical.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - Model type          : ", adf_type_ui, "\n", sep = "")
      cat("    - Kmax searched       : ", ifelse(is.finite(max_lag_auto), max_lag_auto, "NA"), "\n", sep = "")
      cat("    - #Lags chosen (auto) : ", ifelse(is.finite(k_auto), k_auto, "NA"), "\n", sep = "")
      
      cat(" CRITICAL VALUE:\n")
      cat("    - Tau Critical        : ", fmt_num(tau_crit_auto, 4), " (", alpha_col, ")\n\n", sep = "")
      
      cat(" STATISTICS:\n")
      cat("    - Tau Observed        : ", fmt_num(tau_obs_auto, 4), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(adf_dec_ur_auto)) {
        cat("  Tau-Obs < Tau-Crit â‡’ REJECT H0: Stationarity supported.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  This is the most teachable/defensible ADF workflow: you set a maximum lag (Kmax) and let AIC pick the lag that best\n")
        cat("  explains autocorrelation without overfitting. Agreement with PP (reject unit root) and KPSS (do not reject stationarity)\n")
        cat("  is strong evidence for d = 0, subject to seasonal structure.\n")
      } else if (identical(adf_dec_ur_auto, FALSE)) {
        cat("  Tau-Obs â‰¥ Tau-Crit â‡’ FAIL TO REJECT H0: Possible unit root.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Even with AIC-selected lag, the unit-root null remains plausible. This supports differencing. In teaching, highlight that\n")
        cat("  lag choice matters because too few lags leave autocorrelation in errors; too many reduce power.\n")
      } else {
        cat("  Tau or critical value missing; cannot form a decision.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If tau/critical values canâ€™t be extracted, treat as supportive context and rely on the other tests + plots.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 3) KPSS ----
    cat(" 3. KPSS â€” tseries::kpss.test\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$kpss)) {
      cat("    Not available.\n")
      if (!is.null(st$kpss_error)) cat("    Reason: ", st$kpss_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" â€¢ H0: the series is stationary around a ", ifelse(kpss_null_ui == "tau", "trend", "level"), "\n", sep = "")
      cat(" â€¢ Ha: the series is non-stationary\n")
      cat(" â€¢ Reject H0 if P-value < Î±.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - #Lags Used          : ", ifelse(is.finite(kpss_lags_used), kpss_lags_used, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic (Î·)  : ", fmt_num(kpss_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(kpss_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(kpss_reject)) {
        cat("  P-value < Î± â‡’ REJECT H0: Evidence of NON-STATIONARITY.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  KPSS is the mirror-image of ADF/PP: it rejects stationarity. If ADF/PP fail to reject unit root AND KPSS rejects\n")
        cat("  stationarity, thatâ€™s convergent evidence for differencing. If KPSS conflicts with ADF, emphasize mixed evidence and\n")
        cat("  validate with residual diagnostics and forecast accuracy.\n")
      } else if (identical(kpss_reject, FALSE)) {
        cat("  P-value â‰¥ Î± â‡’ FAIL TO REJECT H0: Stationarity is plausible.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  Non-rejection supports stationarity around level/trend. In teaching, KPSS is great to show why â€˜fail to rejectâ€™ is not\n")
        cat("  â€˜prove stationarityâ€™, but combined with ADF/PP it builds a coherent story.\n")
      } else {
        cat("  KPSS p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If KPSS is unavailable/inconclusive, rely more on ADF/PP + plots and consider using multiple transformations.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- 4) Phillipsâ€“Perron ----
    cat(" 4. PHILLIPSâ€“PERRON â€” tseries::pp.test\n")
    cat("--------------------------------------------------------------------------\n")
    
    if (is.null(st$pp)) {
      cat("    Not available.\n")
      if (!is.null(st$pp_error)) cat("    Reason: ", st$pp_error, "\n", sep = "")
    } else {
      cat(" DECISION RULE:\n")
      cat(" â€¢ H0: the series has a unit root (non-stationary)\n")
      cat(" â€¢ Ha: the series is stationary\n")
      cat(" â€¢ Reject H0 if P-value < Î±.\n\n")
      
      cat(" SPECIFICATION:\n")
      cat("    - #Lags Used          : ", ifelse(is.finite(pp_lags_used), pp_lags_used, "NA"), "\n", sep = "")
      cat("    - Critical Value      : not printed (p-value based)\n\n")
      
      cat(" STATISTICS:\n")
      cat("    - Test Statistic      : ", fmt_num(pp_stat, 4), "\n", sep = "")
      cat("    - P-Value             : ", fmt_p(pp_p), "\n\n", sep = "")
      
      cat(" DECISION:\n")
      if (isTRUE(pp_reject)) {
        cat("  P-value < Î± â‡’ REJECT H0: Stationarity suggested.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  PP is a robust alternative to ADF that corrects for serial correlation/heteroskedasticity nonparametrically.\n")
        cat("  In teaching, itâ€™s useful to show that agreement between PP and ADF strengthens inference, while disagreement suggests\n")
        cat("  sensitivity to assumptions and motivates a conservative workflow.\n")
      } else if (identical(pp_reject, FALSE)) {
        cat("  P-value â‰¥ Î± â‡’ FAIL TO REJECT H0: Possible unit root.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  PP does not reject a unit root, supporting differencing. Re-test after differencing and check residual whiteness.\n")
      } else {
        cat("  PP p-value missing; decision is inconclusive.\n\n")
        cat(" CONCLUSION (teaching paragraph):\n")
        cat("  If PP is inconclusive, rely on the other tests + plots, and consider transformations (log/Box-Cox) before differencing.\n")
      }
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---- Final synthesis ----
    cat(" RECOMMENDATION (practical SARIMA workflow):\n")
    cat("--------------------------------------------------------------------------\n")
    
    cat(" â€¢ Step 1: Inspect time plot + ACF/PACF (look for slow decay and seasonal spikes).\n")
    cat(" â€¢ Step 2: Use evidence from ADF/PP (unit root) + KPSS (stationarity null) to decide d and D.\n")
    cat(" â€¢ Step 3: Apply minimal differencing; re-check tests and plots.\n")
    cat(" â€¢ Step 4: Fit SARIMA; verify residuals ~ white noise (Ljung-Box, residual ACF).\n")
    cat(" â€¢ Step 5: Prefer the model that passes diagnostics and forecasts well (not just lowest AIC).\n\n")
    
    # teaching: show how to interpret convergence
    if ((isTRUE(adf_auto_dec_ts) || isTRUE(adf_dec_ts) || isTRUE(adf_dec_ur) || isTRUE(adf_dec_ur_auto) || isTRUE(pp_reject)) && !isTRUE(kpss_reject)) {
      cat(" â€¢ Convergent evidence: STATIONARITY likely (consider d = 0; then evaluate seasonal differencing D).\n")
    } else if ((identical(adf_auto_dec_ts, FALSE) || identical(adf_dec_ts, FALSE) || identical(adf_dec_ur, FALSE) || identical(adf_dec_ur_auto, FALSE) || identical(pp_reject, FALSE)) && isTRUE(kpss_reject)) {
      cat(" â€¢ Convergent evidence: NON-STATIONARITY likely (difference: d and/or D; then re-test).\n")
    } else {
      cat(" â€¢ Mixed evidence: be conservative â€” try minimal differencing and validate using residual diagnostics + forecast accuracy.\n")
    }
    
    cat("\n==========================================================================\n\n")
  })
  
  
  
 
  diff_preview <- eventReactive(input$preview_diff, {
    s <- ts_train_test()
    x <- ts(c(as.numeric(s$ts_train), as.numeric(s$ts_test)), start = 1, frequency = frequency(s$ts_train))
    d <- as.numeric(input$d_preview)
    D <- as.numeric(input$D_preview)
    x2 <- x
    if (d > 0) x2 <- diff(x2, differences = d)
    if (D > 0) x2 <- diff(x2, lag = frequency(x), differences = D)
    x2
  })

  
  
  
  output$diff_plot <- renderPlot(
    {
      # =======================
      # Layout knobs (EDIT ME)
      # =======================
      LAG_MAX <- 40
      
      # When SPLIT (top + middle + (acf|pacf))
      # â†“â†“â†“ Reduce TOP, increase BOTTOM so ACF/PACF are readable
      H_TOP <- 0.7   # top: original series with split line
      H_MID <- 1.0   # middle: train-differenced series
      H_BOT <- 1.6   # bottom: ACF/PACF row
      
      # Width split between ACF and PACF
      W_LEFT  <- 1.0
      W_RIGHT <- 1.0
      
      # Panel styling knobs (teaching-friendly)
      TOP_TITLE_SIZE <- 11
      MID_TITLE_SIZE <- 12
      BOT_TITLE_SIZE <- 12
      
      TOP_MARGIN <- ggplot2::margin(t = 2, r = 6, b = 2, l = 6)
      MID_MARGIN <- ggplot2::margin(t = 6, r = 6, b = 6, l = 6)
      BOT_MARGIN <- ggplot2::margin(t = 6, r = 6, b = 6, l = 6)
      
      s <- ts_train_test()
      req(s$ts_train)
      
      d <- as.numeric(input$d_preview)
      D <- as.numeric(input$D_preview)
      
      has_test <- isTRUE(input$train_prop < 1) && length(s$ts_test) > 0
      
      # Full ORIGINAL series (no differencing)
      x_full_orig <- ts(
        c(as.numeric(s$ts_train), as.numeric(s$ts_test)),
        start = 1,
        frequency = frequency(s$ts_train)
      )
      
      # Differencing helper
      do_diff <- function(x) {
        x2 <- x
        if (d > 0) x2 <- diff(x2, differences = d)
        if (D > 0) x2 <- diff(x2, lag = frequency(x), differences = D)
        x2
      }
      
      # =========================
      # NO SPLIT: top reflects d,D
      # =========================
      if (!has_test) {
        x_full_diff <- do_diff(x_full_orig)
        
        p_top <- autoplot(x_full_diff) +
          ggtitle(paste0("Series preview (full), differenced (d=", d, ", D=", D, ")")) +
          xlab("Time") + ylab("Value") +
          theme(
            plot.title = element_text(size = MID_TITLE_SIZE),
            plot.margin = MID_MARGIN
          )
        
        p_acf  <- ggAcf(x_full_diff, lag.max = LAG_MAX) +
          ggtitle("ACF (full series, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        p_pacf <- ggPacf(x_full_diff, lag.max = LAG_MAX) +
          ggtitle("PACF (full series, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        (p_top / (p_acf | p_pacf)) +
          patchwork::plot_layout(heights = c(1.1, 1.0), widths = c(W_LEFT, W_RIGHT))
      } else {
        
        # =========================
        # SPLIT: top original + split line
        # =========================
        p_top <- autoplot(x_full_orig) +
          ggtitle("Original time series (no transformation) with Train/Test split") +
          xlab("Time") + ylab("Value") +
          theme(
            plot.title = element_text(size = TOP_TITLE_SIZE),
            plot.margin = TOP_MARGIN
          )
        
        split_time <- time(x_full_orig)[length(s$ts_train)]
        p_top <- p_top +
          geom_vline(xintercept = split_time, linetype = "dashed", color = "red") +
          annotate(
            "text",
            x = split_time,
            y = max(as.numeric(x_full_orig), na.rm = TRUE),
            label = "Train/Test split",
            vjust = -0.5, hjust = 0,
            color = "red",
            size = 3
          )
        
        # Middle: TRAIN-only differenced
        x_train_diff <- do_diff(s$ts_train)
        
        p_mid <- autoplot(x_train_diff) +
          ggtitle(paste0("Training portion only, differenced (d=", d, ", D=", D, ")")) +
          xlab("Time") + ylab("Differenced value") +
          theme(
            plot.title = element_text(size = MID_TITLE_SIZE),
            plot.margin = MID_MARGIN
          )
        
        # Bottom: ACF/PACF on TRAIN-diff
        p_acf <- ggAcf(x_train_diff, lag.max = LAG_MAX) +
          ggtitle("ACF (train only, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        p_pacf <- ggPacf(x_train_diff, lag.max = LAG_MAX) +
          ggtitle("PACF (train only, after differencing)") +
          theme(
            plot.title = element_text(size = BOT_TITLE_SIZE),
            plot.margin = BOT_MARGIN
          )
        
        bottom_row <- (p_acf | p_pacf) +
          patchwork::plot_layout(widths = c(W_LEFT, W_RIGHT))
        
        # IMPORTANT: Force row heights so top is NOT huge
        (p_top / p_mid / bottom_row) +
          patchwork::plot_layout(heights = c(H_TOP, H_MID, H_BOT))
      }
    },
    
    # =======================
    # Output device sizing
    # =======================
    width = local({
      W_PX <- 990   # overall width (EDIT ME)
      W_PX
    }),
    
    height = local({
      H_NO_SPLIT_PX <- 750   # overall height without split (EDIT ME)
      H_SPLIT_PX    <- 950   # overall height with split (EDIT ME)
      function() {
        s <- ts_train_test()
        has_test <- isTRUE(input$train_prop < 1) &&
          !is.null(s$ts_test) &&
          length(s$ts_test) > 0
        if (has_test) H_SPLIT_PX else H_NO_SPLIT_PX
      }
    })
  )
  
  
  
 
  
  output$diff_plot <- renderPlot(
    {
      s <- ts_train_test()
      req(s$ts_train)
      
      d <- as.numeric(input$d_preview)
      D <- as.numeric(input$D_preview)
      
      has_test <- isTRUE(input$train_prop < 1) && length(s$ts_test) > 0
      
      # Build full ORIGINAL series (no differencing)
      x_full_orig <- ts(
        c(as.numeric(s$ts_train), as.numeric(s$ts_test)),
        start = 1,
        frequency = frequency(s$ts_train)
      )
      
      # Differencing helper (applies to any ts)
      do_diff <- function(x) {
        x2 <- x
        if (d > 0) x2 <- diff(x2, differences = d)
        if (D > 0) x2 <- diff(x2, lag = frequency(x), differences = D)
        x2
      }
      
      # ===== If NO SPLIT: upper plot should reflect parameters (d, D) =====
      if (!has_test) {
        x_full_diff <- do_diff(x_full_orig)
        
        p_top <- autoplot(x_full_diff) +
          ggtitle(paste0("Series preview (full), differenced (d=", d, ", D=", D, ")")) +
          xlab("Time") + ylab("Value")
        
        p_acf  <- ggAcf(x_full_diff, lag.max = 40) +
          ggtitle("ACF (full series, after differencing)")
        
        p_pacf <- ggPacf(x_full_diff, lag.max = 40) +
          ggtitle("PACF (full series, after differencing)")
        
        return(p_top / (p_acf | p_pacf))
      }
      
      # ===== If SPLIT: keep top ORIGINAL + split, then show TRAIN-diff + ACF/PACF =====
      p_top <- autoplot(x_full_orig) +
        ggtitle("Original time series (no transformation) with Train/Test split") +
        xlab("Time") + ylab("Value")
      
      split_time <- time(x_full_orig)[length(s$ts_train)]
      p_top <- p_top +
        geom_vline(xintercept = split_time, linetype = "dashed", color = "red") +
        annotate(
          "text",
          x = split_time,
          y = max(as.numeric(x_full_orig), na.rm = TRUE),
          label = "Train/Test split",
          vjust = -0.5, hjust = 0,
          color = "red",
          size = 3
        )
      
      # TRAIN-only after differencing
      x_train_diff <- do_diff(s$ts_train)
      
      p_train <- autoplot(x_train_diff) +
        ggtitle(paste0("Training portion only, differenced (d=", d, ", D=", D, ")")) +
        xlab("Time") + ylab("Differenced value")
      
      p_acf <- ggAcf(x_train_diff, lag.max = 40) +
        ggtitle("ACF (train only, after differencing)")
      
      p_pacf <- ggPacf(x_train_diff, lag.max = 40) +
        ggtitle("PACF (train only, after differencing)")
      
      p_top / (p_train / (p_acf | p_pacf))
    },
    width  = 990,
    height = function() {
      s <- ts_train_test()
      has_test <- isTRUE(input$train_prop < 1) && !is.null(s$ts_test) && length(s$ts_test) > 0
      if (has_test) 1050 else 750
    }
  )
  
 
  
  
  
  
  output$apa_stationarity_paragraph <- renderPrint({
    req(stationarity(), prepared())
    st <- stationarity()
    s_per <- prepared()$freq
    adf_txt <- if (!is.null(st$adf)) paste0("An Augmented Dickeyâ€“Fuller test indicated ", ifelse(st$adf$p.value < 0.05, "stationarity", "non-stationarity"), ", ", fmt_p(st$adf$p.value), ". ") else ""
    kpss_txt <- if (!is.null(st$kpss)) paste0("A KPSS test suggested ", ifelse(st$kpss$p.value < 0.05, "non-stationarity", "stationarity"), ", ", fmt_p(st$kpss$p.value), ". ") else ""
    pp_txt <- if (!is.null(st$pp)) paste0("A Phillipsâ€“Perron test suggested ", ifelse(st$pp$p.value < 0.05, "stationarity", "non-stationarity"), ", ", fmt_p(st$pp$p.value), ". ") else ""
    cat(
      "APA-ready paragraph (edit differencing decisions as needed):\n\n",
      adf_txt, kpss_txt, pp_txt,
      "Based on combined evidence and inspection of differenced series plots, appropriate non-seasonal (d) and seasonal (D) differencing ",
      "were selected prior to fitting SARIMA models (season length s = ", s_per, ").\n",
      sep = ""
    )
  })

  # ---- Step 5 Auto-ARIMA ----

  # auto_fit <- eventReactive(input$fit_auto, {
  #   s <- ts_train_test()
  #   forecast::auto.arima(
  #     s$ts_train,
  #     seasonal = isTRUE(input$auto_seasonal),
  #     stepwise = isTRUE(input$auto_stepwise),
  #     approximation = isTRUE(input$auto_approx),
  #     allowmean = isTRUE(input$auto_allow_mean),
  #     allowdrift = isTRUE(input$auto_allow_mean),
  #     max.order = as.numeric(input$auto_max_order)
  #   )
  # })

  
  # ---- Step 5 Auto-ARIMA ----
  
  # auto_fit_rv <- reactiveVal(NULL)
  # 
  # observeEvent(input$fit_auto, {
  #   req(ts_train_test())
  #   
  #   # in case JS onclick didn't run (or for safety)
  #   shinyjs::show("auto_progress_wrap")
  #   shinyjs::disable("fit_auto")
  #   
  #   # ALWAYS clean up (even if auto.arima errors)
  #   on.exit({
  #     shinyjs::hide("auto_progress_wrap")
  #     shinyjs::enable("fit_auto")
  #   }, add = TRUE)
  #   
  #   s <- ts_train_test()
  #   
  #   fit <- tryCatch(
  #     forecast::auto.arima(
  #       s$ts_train,
  #       seasonal      = isTRUE(input$auto_seasonal),
  #       stepwise      = isTRUE(input$auto_stepwise),
  #       approximation = isTRUE(input$auto_approx),
  #       allowmean     = isTRUE(input$auto_allow_mean),
  #       allowdrift    = isTRUE(input$auto_allow_mean),
  #       max.order     = as.numeric(input$auto_max_order)
  #     ),
  #     error = function(e) {
  #       showNotification(paste("Auto-ARIMA failed:", e$message), type = "error", duration = NULL)
  #       NULL
  #     }
  #   )
  #   
  #   req(!is.null(fit))
  #   auto_fit_rv(fit)
  # })
  # 
  # # keep the same name your other code already uses
  # auto_fit <- reactive({
  #   req(auto_fit_rv())
  #   auto_fit_rv()
  # })
  
  
  
  
  # auto_fit_rv <- reactiveVal(NULL)
  # 
  # observeEvent(input$fit_auto, {
  #   req(ts_train_test())
  #   
  #   # Safety: in case the UI onclick didn't run (or user triggers from server)
  #   shinyjs::show("auto_progress_wrap")
  #   shinyjs::disable("fit_auto")
  #   shinyjs::runjs("$('#fit_auto').removeClass('btn-primary').addClass('btn-danger');")
  #   
  #   # ALWAYS clean up (even if auto.arima errors or req() stops)
  #   on.exit({
  #     shinyjs::hide("auto_progress_wrap")
  #     shinyjs::enable("fit_auto")
  #     shinyjs::runjs("$('#fit_auto').removeClass('btn-danger').addClass('btn-primary');")
  #   }, add = TRUE)
  #   
  #   s <- ts_train_test()
  #   
  #   fit <- tryCatch(
  #     forecast::auto.arima(
  #       s$ts_train,
  #       seasonal      = isTRUE(input$auto_seasonal),
  #       stepwise      = isTRUE(input$auto_stepwise),
  #       approximation = isTRUE(input$auto_approx),
  #       allowmean     = isTRUE(input$auto_allow_mean),
  #       allowdrift    = isTRUE(input$auto_allow_mean),
  #       max.order     = as.numeric(input$auto_max_order)
  #     ),
  #     error = function(e) {
  #       showNotification(
  #         paste("Auto-ARIMA failed:", e$message),
  #         type = "error",
  #         duration = NULL
  #       )
  #       NULL
  #     }
  #   )
  #   
  #   if (is.null(fit)) return()  # avoid req() stop noise; on.exit still runs
  #   auto_fit_rv(fit)
  # })
  # 
  # # keep the same name your other code already uses
  # auto_fit <- reactive({
  #   req(auto_fit_rv())
  #   auto_fit_rv()
  # })
  
  
  
  
  # auto_fit_rv <- reactiveVal(NULL)
  # 
  # observeEvent(input$fit_auto, {
  #   req(ts_train_test())
  #   
  #   # Safety: in case the UI onclick didn't run
  #   shinyjs::show("auto_progress_wrap")
  #   shinyjs::disable("fit_auto")
  #   shinyjs::runjs("$('#fit_auto').removeClass('blue-btn-1').addClass('red-btn-1');")
  #   
  #   # ALWAYS clean up (success, error, req stop)
  #   on.exit({
  #     shinyjs::hide("auto_progress_wrap")
  #     shinyjs::enable("fit_auto")
  #     shinyjs::runjs("$('#fit_auto').removeClass('red-btn-1').addClass('blue-btn-1');")
  #   }, add = TRUE)
  #   
  #   s <- ts_train_test()
  #   
  #   fit <- tryCatch(
  #     forecast::auto.arima(
  #       s$ts_train,
  #       seasonal      = isTRUE(input$auto_seasonal),
  #       stepwise      = isTRUE(input$auto_stepwise),
  #       approximation = isTRUE(input$auto_approx),
  #       allowmean     = isTRUE(input$auto_allow_mean),
  #       allowdrift    = isTRUE(input$auto_allow_mean),
  #       max.order     = as.numeric(input$auto_max_order)
  #     ),
  #     error = function(e) {
  #       showNotification(paste("Auto-ARIMA failed:", e$message), type = "error", duration = NULL)
  #       NULL
  #     }
  #   )
  #   
  #   if (is.null(fit)) return()
  #   auto_fit_rv(fit)
  # })
  # 
  # auto_fit <- reactive({
  #   req(auto_fit_rv())
  #   auto_fit_rv()
  # })
  
  
  
  auto_fit_rv <- reactiveVal(NULL)
  
  observeEvent(input$fit_auto, {
    req(ts_train_test())
    
    # Safety (if onclick didn't fire for some reason)
    shinyjs::runjs("setFitAutoBusy(true);")
    
    # ALWAYS clean up
    on.exit({
      shinyjs::runjs("setFitAutoBusy(false);")
    }, add = TRUE)
    
    s <- ts_train_test()
    
    fit <- tryCatch(
      forecast::auto.arima(
        s$ts_train,
        seasonal      = isTRUE(input$auto_seasonal),
        stepwise      = isTRUE(input$auto_stepwise),
        approximation = isTRUE(input$auto_approx),
        allowmean     = isTRUE(input$auto_allow_mean),
        allowdrift    = isTRUE(input$auto_allow_mean),
        max.order     = as.numeric(input$auto_max_order)
      ),
      error = function(e) {
        showNotification(paste("Auto-ARIMA failed:", e$message), type = "error", duration = NULL)
        NULL
      }
    )
    
    if (is.null(fit)) return()
    auto_fit_rv(fit)
  })
  
  auto_fit <- reactive({
    req(auto_fit_rv())
    auto_fit_rv()
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  auto_fc <- reactive({
    req(auto_fit(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    user_h <- if (!is.na(input$auto_h) && input$auto_h > 0) as.numeric(input$auto_h) else NA_real_
    if (s$test_n > 0) {
      h <- s$test_n
    } else {
      h <- if (!is.na(user_h)) user_h else max(1, frequency(s$ts_train))
    }
    fc <- forecast::forecast(auto_fit(), h = h)
    list(fc = fc, h = h, by = p$by)
  })

  output$auto_horizon_note <- renderPrint({
    req(ts_train_test(), auto_fc())
    s <- ts_train_test()
    if (s$test_n > 0) {
      cat("Validation mode: forecast horizon is forced to the test length (h =", s$test_n, ") to overlay the test period.\n")
    } else {
      cat("Future mode: no test set. Forecast horizon uses your 'Future horizon h' setting (or defaults to one seasonal cycle).\n")
    }
  })

  output$auto_model_spec <- renderPrint({
    req(auto_fit(), prepared())
    fit <- auto_fit()
    p <- prepared()
    cat("Auto-ARIMA selected model:\n")
    cat("- Specification:", as.character(fit), "\n")
    cat("- Seasonal period (s):", p$freq, "\n")
    cat("- Information criteria: AICc =", fmt_num(fit$aicc, 2), ", BIC =", fmt_num(fit$bic, 2), "\n")
  })

  output$auto_coef_table <- renderTable({ req(auto_fit()); coef_table(auto_fit()) }, rownames = FALSE)
  output$auto_resid_ts <- renderPlot({ req(auto_fit()); plot(residuals(auto_fit()), main = "Residuals (Auto-ARIMA)", ylab = "Residual", xlab = "Time") })
  output$auto_resid_acf <- renderPlot({ req(auto_fit()); plot(acf(residuals(auto_fit()), plot = FALSE), main = "Residual ACF (Auto-ARIMA)") })
  output$auto_resid_hist <- renderPlot({ req(auto_fit()); hist(residuals(auto_fit()), breaks = 30, main = "Residual histogram", xlab = "Residual") })
  output$auto_resid_qq <- renderPlot({ req(auto_fit()); qqnorm(residuals(auto_fit())); qqline(residuals(auto_fit())) })
  
  # Ljungâ€“Box p-values across lags (Auto-ARIMA)
  output$auto_resid_lb_pvals <- renderPlot({
    req(auto_fit())
    
    res <- residuals(auto_fit())
    res <- as.numeric(res)[is.finite(res)]
    
    # Use the same controls you already expose for diagnostics
    L_input <- suppressWarnings(as.integer(input$diag_lag))
    L       <- if (is.finite(L_input) && L_input > 0) L_input else 12L
    fitdf   <- length(coef(auto_fit()))
    alpha   <- suppressWarnings(as.numeric(input$alphaSt2)); if (!is.finite(alpha)) alpha <- 0.05
    
    N <- length(res)
    validate(need(N >= 8, "Too few residuals (N < 8) to compute Ljungâ€“Box p-values."))
    L <- max(1L, min(L, N - 1L))
    
    # Compute p-values at cumulative lags 1..L (omit k <= fitdf where df<=0)
    pvals <- rep(NA_real_, L)
    for (k in seq_len(L)) {
      if (k > fitdf) {
        bt <- tryCatch(stats::Box.test(res, lag = k, type = "Ljung-Box", fitdf = fitdf),
                       error = function(e) NULL)
        pvals[k] <- if (!is.null(bt)) as.numeric(bt$p.value) else NA_real_
      }
    }
    
    # Base R plotting to match your existing diagnostics
    plot(seq_len(L), pvals,
         type = "h", lwd = 2,
         xlab = "Lag (k)",
         ylab = "p-value  (Ljungâ€“Box up to lag k)",
         main = "Ljungâ€“Box p-values by lag (Auto-ARIMA)",
         ylim = c(0, 1))
    points(seq_len(L), pvals, pch = 16)
    abline(h = alpha, lty = 2)
    mtext(sprintf("alpha = %.3f,   fitdf = %d", alpha, fitdf), side = 3, line = 0.2, cex = 0.8)
    
    if (fitdf >= 1 && fitdf < L) {
      rect(xleft = 0.5, ybottom = -0.02, xright = fitdf + 0.5, ytop = 1.02,
           border = NA, col = grDevices::adjustcolor("gray", alpha.f = 0.15))
      text(x = (fitdf + 1) / 2, y = 0.95, labels = "df â‰¤ 0 (omitted)", cex = 0.8)
    }
  })
  
  
  
  
  
  
  
  
  #===============================================================
  #===============================================================
  #===============================================================
  
  
  
  # ============================================================
  # --- FIXED: Auto-ARIMA equation renderer (MathJax-safe) ---
  # ============================================================
  
  auto_equations <- reactive({
    req(auto_fit())
    fit <- auto_fit()
    
    # --- Orders from forecast::Arima (arma = c(p, q, P, Q, m, d, D)) ---
    arma <- fit$arma
    p <- arma[1]; q <- arma[2]; P <- arma[3]; Q <- arma[4]
    s <- ifelse(isTRUE(arma[5] > 0), arma[5], 1L)
    d <- arma[6]; D <- arma[7]
    
    coefs <- stats::coef(fit)
    nm    <- names(coefs)
    
    ip <- if (p > 0) seq_len(p) else integer(0)
    iq <- if (q > 0) seq_len(q) else integer(0)
    iP <- if (P > 0) seq_len(P) else integer(0)
    iQ <- if (Q > 0) seq_len(Q) else integer(0)
    
    # Intercept/mean (show only when meaningful)
    intercept_name <- intersect(c("intercept", "mean"), nm)
    intercept_val  <- if (length(intercept_name) > 0) unname(coefs[intercept_name[1]]) else NA_real_
    show_intercept <- is.finite(intercept_val) && abs(intercept_val) > 1e-8 && d == 0 && D == 0
    intercept_num  <- if (show_intercept) sprintf("%.3f", intercept_val) else ""
    
    # Drift (present only when differencing is used and auto.arima included it)
    drift_val <- if ("drift" %in% nm) unname(coefs["drift"]) else NA_real_
    show_drift <- is.finite(drift_val) && abs(drift_val) > 1e-8 && (d > 0 || D > 0)
    
    # MathJax wrappers
    tex_display <- function(x) paste0("\\[", x, "\\]")
    
    # Cosmetic cleanup for numeric line
    simplify_tex <- function(x) {
      x <- gsub("\\(1\\)", "", x)
      x <- gsub("\\s+", " ", x)
      x <- gsub("\\+\\s*\\+", "+", x)
      x <- gsub("\\+\\s*-", "-", x)
      x <- gsub("-\\s*\\+", "-", x)
      x <- gsub("-\\s*-", "+", x)
      x <- gsub("\\s*\\+\\s*0\\.000\\b", "", x)
      trimws(x)
    }
    
    # ---- Parameter-polynomial strings (symbolic) ----
    poly_param_ar  <- function() if (p == 0) "1" else paste0("1", paste0(" - \\phi_{", ip, "}L^{", ip, "}", collapse = ""))
    poly_param_sar <- function() if (P == 0) "1" else paste0("1", paste0(" - \\Phi_{", iP, "}L^{", s * iP, "}", collapse = ""))
    poly_param_ma  <- function() if (q == 0) "1" else paste0("1", paste0(" + \\theta_{", iq, "}L^{", iq, "}", collapse = ""))
    poly_param_sma <- function() if (Q == 0) "1" else paste0("1", paste0(" + \\Theta_{", iQ, "}L^{", s * iQ, "}", collapse = ""))
    
    # ---- Numeric polynomials (use estimated coefficients) ----
    poly_num_ar <- function() {
      if (p == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("ar", ip)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], ip[keep]), collapse = ""))
    }
    poly_num_sar <- function() {
      if (P == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("sar", iP)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iP
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], lags[keep]), collapse = ""))
    }
    poly_num_ma <- function() {
      if (q == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("ma", iq)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], iq[keep]), collapse = ""))
    }
    poly_num_sma <- function() {
      if (Q == 0) return("1")
      v <- suppressWarnings(unname(coefs[paste0("sma", iQ)]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iQ
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], lags[keep]), collapse = ""))
    }
    
    # Differencing operators (omit if exponent is zero)
    diff_part  <- if (d > 0) paste0("(1-L)^{", d, "}") else ""
    sdiff_part <- if (D > 0) paste0("(1-L^{", s, "})^{", D, "}") else ""
    
    # ---------- Line 1: General operator form ----------
    # \phi_p(L)\Phi_P(L^S)(1-L)^d(1-L^S)^D Y_t = c + \theta_q(L)\Theta_Q(L^S)\varepsilon_t (+ drift when appropriate)
    line1 <- paste0(
      "\\phi_p(L)\\,\\Phi_P(L^{S})\\,(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + \\theta_q(L)\\,\\Theta_Q(L^{S})\\varepsilon_t",
      if (show_drift) " + \\delta t" else ""
    )
    
    # ---------- Line 2: Expanded operator (summation) ----------
    line2 <- paste0(
      "\\left(1-\\sum_{i=1}^{p}\\phi_i L^{i}\\right)",
      "\\left(1-\\sum_{j=1}^{P}\\Phi_j L^{jS}\\right)",
      "(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + ",
      "\\left(1+\\sum_{i=1}^{q}\\theta_i L^{i}\\right)",
      "\\left(1+\\sum_{j=1}^{Q}\\Theta_j L^{jS}\\right)",
      "\\varepsilon_t",
      if (show_drift) " + \\delta t" else ""
    )
    
    # ---------- Line 3: Parameter-expanded polynomials ----------
    line3 <- paste0(
      "(", poly_param_ar(), ")",
      "(", poly_param_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = c + ",
      "(", poly_param_ma(), ")",
      "(", poly_param_sma(), ")\\varepsilon_t",
      if (show_drift) " + \\delta t" else ""
    )
    
    # ---------- Line 4: Numeric-expanded polynomials ----------
    rhs_intercept <- if (show_intercept) paste0(intercept_num, " + ") else ""
    line4 <- paste0(
      "(", poly_num_ar(), ")",
      "(", poly_num_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = ",
      rhs_intercept,
      "(", poly_num_ma(), ")",
      "(", poly_num_sma(), ")\\varepsilon_t",
      if (show_drift) paste0(" + ", sprintf("%.3f", drift_val), "t") else ""
    )
    line4 <- simplify_tex(line4)
    
    # ---------- Coefficient legend ----------
    coef_lines <- c()
    if (show_intercept) coef_lines <- c(coef_lines, paste0("c (intercept/mean) = ", sprintf("%.4f", intercept_val)))
    if (show_drift)     coef_lines <- c(coef_lines, paste0("drift (\\(\\delta\\)) = ", sprintf("%.4f", drift_val)))
    
    if (p > 0) {
      for (i in ip) {
        nm_i <- paste0("ar", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\phi_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (q > 0) {
      for (i in iq) {
        nm_i <- paste0("ma", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\theta_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (P > 0) {
      for (i in iP) {
        nm_i <- paste0("sar", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\Phi_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (Q > 0) {
      for (i in iQ) {
        nm_i <- paste0("sma", i)
        if (nm_i %in% nm && is.finite(coefs[nm_i])) {
          coef_lines <- c(coef_lines, paste0("\\(\\Theta_", i, "\\) = ", sprintf("%.4f", coefs[nm_i])))
        }
      }
    }
    if (length(coef_lines) == 0) coef_lines <- "No coefficients available."
    
    list(
      p = p, d = d, q = q, P = P, D = D, Q = Q, s = s,
      eq_general      = tex_display(line1),
      eq_expanded     = tex_display(line2),
      eq_line3        = tex_display(line3),
      eq_line4        = tex_display(line4),
      coef_lines      = coef_lines
    )
  })
  
  
  output$auto_model_equation <- renderUI({
    req(auto_equations())
    eq <- auto_equations()
    
    tagList(
      tags$div(
        style = "text-align:left;",
        tags$h4("Auto-ARIMA model"),
        tags$p(sprintf(
          "ARIMA(%d,%d,%d)%s",
          eq$p, eq$d, eq$q,
          if (eq$s > 1) sprintf(" Ã— (%d,%d,%d)[%d]", eq$P, eq$D, eq$Q, eq$s) else ""
        )),
        
        tags$h5("Estimated coefficients"),
        tags$ul(lapply(eq$coef_lines, function(x) tags$li(HTML(x)))),
        
        tags$br(), tags$hr(), tags$hr(),
        
        tags$h4("General SARIMA formulation"),
        HTML(eq$eq_general),
        
        tags$br(), tags$hr(), tags$hr(),
        
        tags$h4("Expanded operator form"),
        HTML(eq$eq_expanded),
        
        tags$br(), tags$hr(), tags$hr(),
        
        tags$h4("Numerical model"),
        HTML(eq$eq_line3),
        
        tags$br(), tags$hr(), tags$hr(),
        
        HTML(eq$eq_line4),
        
        tags$br(), tags$hr(), tags$hr()  # âœ… NO comma after this
      ),
      
      # Force MathJax typesetting for dynamically injected content
      tags$script(HTML("
      if (window.MathJax) {
        if (window.MathJax.Hub) { MathJax.Hub.Queue(['Typeset', MathJax.Hub]); }
        else if (window.MathJax.typesetPromise) { MathJax.typesetPromise(); }
      }
    "))
    )
  })
  
  
  # output$auto_model_equation <- renderUI({
  #   req(auto_equations())
  #   eq <- auto_equations()
  #   
  #   tagList(
  #     tags$div(
  #       style = "text-align:left;",
  #       tags$h4("Auto-ARIMA model"),
  #       tags$p(sprintf("ARIMA(%d,%d,%d)%s",
  #                      eq$p, eq$d, eq$q,
  #                      if (eq$s > 1) sprintf(" Ã— (%d,%d,%d)[%d]", eq$P, eq$D, eq$Q, eq$s) else "")),
  #       
  #       tags$h5("Estimated coefficients"),
  #       tags$ul(lapply(eq$coef_lines, function(x) tags$li(HTML(x)))),
  #       
  #       tags$br(),
  #       tags$hr(),
  #       tags$hr(),
  #       
  #       tags$h4("General SARIMA formulation"),
  #       HTML(eq$eq_general),
  #       
  #       tags$br(),
  #       tags$hr(),
  #       tags$hr(),
  #       
  #       tags$h4("Expanded operator form"),
  #       HTML(eq$eq_expanded),
  #       
  #       tags$br(),
  #       tags$hr(),
  #       tags$hr(),
  #       
  #       tags$h4("Numerical model"),
  #       HTML(eq$eq_line3),
  #       
  #       tags$br(),
  #       tags$hr(),
  #       tags$hr(),,
  #       
  #       # HTML("\\[\\text{------------}\\]"),
  #       HTML(eq$eq_line4),
  #       
  #       tags$br(),
  #       tags$hr(),
  #       tags$hr()
  #       
  #     ),
  #     
  #     # Force MathJax typesetting for dynamically injected content
  #     tags$script(HTML("
  #     if (window.MathJax) {
  #       if (window.MathJax.Hub) { MathJax.Hub.Queue(['Typeset', MathJax.Hub]); }
  #       else if (window.MathJax.typesetPromise) { MathJax.typesetPromise(); }
  #     }
  #   "))
  #   )
  # })
  
  
  
  
  
  
  
  
  #===============================================================
  #===============================================================
  #===============================================================
  
  
  # output$auto_diag_tests <- renderText({ req(auto_fit()); diag_tests_text(residuals(auto_fit()), lag = as.numeric(input$diag_lag), fitdf = length(coef(auto_fit()))) })

  
  output$auto_diag_tests <- renderText({
    req(auto_fit())
    res   <- residuals(auto_fit())
    L     <- as.integer(input$diag_lag %||% 12L)
    fitdf <- length(coef(auto_fit()))
    alpha <- to_num_safe(input$alphaSt2 %||% 0.05, 0.05)
    residual_diagnostics_report(res, L = L, fitdf = fitdf, alpha = alpha)
  })
  
  

  
  
  residual_diagnostics_report <- function(res, L = 12L, fitdf = 0L, alpha = 0.05) {
    # ---- Safe helpers (use local fallbacks if not already defined globally) ----
    if (!exists("fmt_p", inherits = TRUE)) {
      fmt_p <- function(p) {
        if (!is.finite(p)) return("NA")
        if (p < .001) "<0.001" else sprintf("%.6f", p)
      }
    }
    if (!exists("fmt_num", inherits = TRUE)) {
      fmt_num <- function(z, d = 6) ifelse(is.finite(z), sprintf(paste0("%.", d, "f"), z), "NA")
    }
    
    # ---- Sanitize inputs ----
    res   <- as.numeric(res)
    res   <- res[is.finite(res)]
    N     <- length(res)
    L     <- max(1L, as.integer(L))
    fitdf <- max(0L, as.integer(fitdf))
    alpha <- suppressWarnings(as.numeric(alpha)); if (!is.finite(alpha)) alpha <- 0.05
    if (N < 8) {
      return(
        "==========================================================================\n" %+%
          "                     RESIDUAL DIAGNOSTIC BATTERY                          \n" %+%
          "==========================================================================\n" %+%
          "Too few residuals (N < 8) to run the requested tests."
      )
    }
    
    # Convenience
    `%+%` <- function(a, b) paste0(a, b)
    df_lb <- max(L - fitdf, 1L)             # Ljungâ€“Box / Boxâ€“Pierce df after parameter adjustment
    cv_lb <- stats::qchisq(1 - alpha, df = df_lb)
    
    # ---- 1) Ljungâ€“Box (portmanteau for autocorrelation) ----
    lb <- tryCatch(stats::Box.test(res, lag = L, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
    lb_stat <- if (!is.null(lb)) as.numeric(lb$statistic) else NA_real_
    lb_p    <- if (!is.null(lb)) as.numeric(lb$p.value)   else NA_real_
    
    # ---- 2) Boxâ€“Pierce (classic portmanteau) ----
    bp <- tryCatch(stats::Box.test(res, lag = L, type = "Box-Pierce", fitdf = fitdf), error = function(e) NULL)
    bp_stat <- if (!is.null(bp)) as.numeric(bp$statistic) else NA_real_
    bp_p    <- if (!is.null(bp)) as.numeric(bp$p.value)   else NA_real_
    
    # ---- 3) Jarqueâ€“Bera (normality of residuals; large-sample Ï‡^2_2) ----
    jb <- if (requireNamespace("tseries", quietly = TRUE))
      tryCatch(tseries::jarque.bera.test(res), error = function(e) NULL) else NULL
    jb_stat <- if (!is.null(jb)) as.numeric(jb$statistic) else NA_real_
    jb_p    <- if (!is.null(jb)) as.numeric(jb$p.value)   else NA_real_
    cv_jb   <- stats::qchisq(1 - alpha, df = 2)  # asymptotic
    
    # ---- 4) Shapiroâ€“Wilk (normality; exact test for N in [3, 5000]) ----
    sw <- if (N >= 3 && N <= 5000)
      tryCatch(stats::shapiro.test(res), error = function(e) NULL) else NULL
    sw_W <- if (!is.null(sw)) as.numeric(sw$statistic) else NA_real_
    sw_p <- if (!is.null(sw)) as.numeric(sw$p.value)   else NA_real_
    
    # ---- 5) Engleâ€™s ARCH LM (conditional heteroskedasticity) ----
    arch_lags <- min(L, max(1L, floor(N/10)))
    arch <- if (requireNamespace("FinTS", quietly = TRUE))
      tryCatch(FinTS::ArchTest(res, lags = arch_lags), error = function(e) NULL) else NULL
    arch_stat <- if (!is.null(arch)) as.numeric(arch$statistic) else NA_real_
    arch_p    <- if (!is.null(arch)) as.numeric(arch$p.value)   else NA_real_
    cv_arch   <- stats::qchisq(1 - alpha, df = arch_lags)
    
    # ---- 6) Runs test (randomness / independence of signs) ----
    run <- if (requireNamespace("tseries", quietly = TRUE))
      tryCatch(tseries::runs.test(res), error = function(e) NULL) else NULL
    run_Z <- if (!is.null(run)) as.numeric(run$statistic) else NA_real_
    run_p <- if (!is.null(run)) as.numeric(run$p.value)   else NA_real_
    zcrit <- stats::qnorm(1 - alpha/2)  # two-sided
    
    # ---- 7) Andersonâ€“Darling for normality (tail-sensitive; optional) ----
    ad <- if (requireNamespace("nortest", quietly = TRUE))
      tryCatch(nortest::ad.test(res), error = function(e) NULL) else NULL
    ad_A2 <- if (!is.null(ad)) as.numeric(ad$statistic) else NA_real_
    ad_p  <- if (!is.null(ad)) as.numeric(ad$p.value)   else NA_real_
    
    # ---- 8) KPSS on residuals (should be stationary if model is adequate; optional) ----
    kpss_res <- if (requireNamespace("tseries", quietly = TRUE))
      tryCatch(tseries::kpss.test(res, null = "Level"), error = function(e) NULL) else NULL
    kpss_stat <- if (!is.null(kpss_res)) as.numeric(kpss_res$statistic) else NA_real_
    kpss_p    <- if (!is.null(kpss_res)) as.numeric(kpss_res$p.value)   else NA_real_
    
    # ---- Compose the academic-friendly text ----
    out <- c(
      "==========================================================================",
      "                     RESIDUAL DIAGNOSTIC BATTERY                          ",
      "==========================================================================",
      sprintf(" SAMPLE SIZE (residuals used): %d   |   Î±: %s   |   Lag (L): %d   |   fitdf: %d",
              N, fmt_num(alpha, 4), L, fitdf),
      "--------------------------------------------------------------------------",
      
      # Ljungâ€“Box
      "TEST 1: Ljungâ€“Box Portmanteau (autocorrelation)",
      " Purpose     : To determine whether any linear autocorrelation remains in the residuals up to lag L after fitting the SARIMA model.",
      "               Passing this test supports the idea that the model has successfully captured the serial dependence in the training data.",
      " Description : The Ljungâ€“Box statistic aggregates squared sample autocorrelations of the residuals across lags 1..L,",
      "               with a small-sample correction. Under the null hypothesis that residuals are white noise, Q follows",
      "               approximately a chi-square distribution with degrees of freedom equal to max(L âˆ’ fitdf, 1).",
      sprintf(" Statistic   : Q(LB) = %s  |  df = %d  |  p-value = %s", fmt_num(lb_stat, 4), df_lb, fmt_p(lb_p)),
      sprintf(" Critical    : Ï‡^2_(%d, 1-Î±) = %s", df_lb, fmt_num(cv_lb, 4)),
      sprintf(" Decision    : Reject H0 (white noise) if Q(LB) > Ï‡^2_(%d, 1-Î±) (equivalently, p < Î±).", df_lb),
      sprintf(" Result      : %s",
              if (!is.finite(lb_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (lb_p < alpha) {
                "Reject H0 â†’ residual autocorrelation detected."
              } else {
                "Fail to reject H0 â†’ residuals consistent with white noise."
              }),
      sprintf(" Conclusion  : %s",
              if (!is.finite(lb_p)) {
                "Because the test could not be evaluated, do not draw conclusions about left-over autocorrelation. Recheck model estimation and sample size."
              } else if (lb_p < alpha) {
                "There is statistical evidence of remaining serial correlation up to the chosen lag. This suggests the SARIMA orders may be underspecified (e.g., too few AR/MA or seasonal terms) or that differencing/seasonality was not fully addressed. Consider revisiting (p,d,q)(P,D,Q)m, increasing L modestly, or examining ACF/PACF of residuals to guide refinement."
              } else {
                "No material linear autocorrelation is detected at the examined lags. This supports the adequacy of the fitted orders for the training data and increases confidence that forecast errors are not biased by serial dependence left in the residuals."
              }),
      "--------------------------------------------------------------------------",
      
      # Boxâ€“Pierce
      "TEST 2: Boxâ€“Pierce Portmanteau (autocorrelation, classic)",
      " Purpose     : Same goal as Ljungâ€“Boxâ€”screen for any left-over autocorrelation up to lag Lâ€”using the original Boxâ€“Pierce statistic.",
      " Description : The Boxâ€“Pierce statistic is the uncorrected sum of squared residual autocorrelations over lags 1..L.",
      "               Under the white-noise null, it is approximately Ï‡^2 with df = max(L âˆ’ fitdf, 1).",
      sprintf(" Statistic   : Q(BP) = %s  |  df = %d  |  p-value = %s", fmt_num(bp_stat, 4), df_lb, fmt_p(bp_p)),
      sprintf(" Critical    : Ï‡^2_(%d, 1-Î±) = %s", df_lb, fmt_num(cv_lb, 4)),
      sprintf(" Decision    : Reject H0 if Q(BP) > Ï‡^2_(%d, 1-Î±) (equivalently, p < Î±).", df_lb),
      sprintf(" Result      : %s",
              if (!is.finite(bp_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (bp_p < alpha) {
                "Reject H0 â†’ residual autocorrelation detected (classic statistic)."
              } else {
                "Fail to reject H0 â†’ no strong evidence of residual autocorrelation."
              }),
      sprintf(" Conclusion  : %s",
              if (!is.finite(bp_p)) {
                "Since the test could not be computed, rely on Ljungâ€“Box and graphical diagnostics. If both are inconclusive, try a different L or expand the sample."
              } else if (bp_p < alpha) {
                "Autocorrelation persists by the Boxâ€“Pierce criterion. In practice, prioritize Ljungâ€“Box; if both agree, refine the model orders or differencing. If they disagree, prefer Ljungâ€“Box due to its small-sample correction."
              } else {
                "Results align with white-noise residuals by the Boxâ€“Pierce criterion. Together with Ljungâ€“Box, this strengthens the case that the fitted SARIMA captured the main serial structure."
              }),
      "--------------------------------------------------------------------------",
      
      # Jarqueâ€“Bera
      "TEST 3: Jarqueâ€“Bera (normality, large-sample Ï‡^2)",
      " Purpose     : Assess whether residuals are approximately normalâ€”important when using normal-based prediction intervals and likelihood-based inference.",
      " Description : The statistic combines squared residual skewness and excess kurtosis. Under normality (large N), JB ~ Ï‡^2 with 2 degrees of freedom.",
      sprintf(" Statistic   : JB = %s  |  df = 2  |  p-value = %s", fmt_num(jb_stat, 4), fmt_p(jb_p)),
      sprintf(" Critical    : Ï‡^2_(2, 1-Î±) = %s", fmt_num(cv_jb, 4)),
      " Decision    : Reject H0 (normality) if JB > Ï‡^2_(2, 1-Î±) (equivalently, p < Î±).",
      sprintf(" Result      : %s",
              if (!is.finite(jb_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (jb_p < alpha) {
                "Reject H0 â†’ residuals deviate from normality."
              } else {
                "Fail to reject H0 â†’ residual normality is plausible."
              }),
      sprintf(" Conclusion  : %s",
              if (!is.finite(jb_p)) {
                "Because the test could not be evaluated, rely on the QQ-plot and Shapiroâ€“Wilk (if available) to judge normality. Normality mainly affects interval calibration rather than point forecasts."
              } else if (jb_p < alpha) {
                "Non-normal residuals indicate skewness and/or heavy tails. Point forecasts remain unbiased if the mean is correctly specified, but nominal prediction intervals may undercover or overcover. Consider variance-stabilizing transforms (e.g., log/Boxâ€“Cox), robust inference, or heavier-tailed error models if tails matter."
              } else {
                "Residuals are consistent with normality at the chosen Î±. This supports the use of standard Gaussian prediction intervals and likelihood-based comparisons for competing SARIMA specifications."
              }),
      "--------------------------------------------------------------------------",
      
      # Shapiroâ€“Wilk
      "TEST 4: Shapiroâ€“Wilk (normality, small/medium samples)",
      " Purpose     : Provide a powerful small-sample test of normality when N â‰¤ 5000.",
      " Description : The W statistic compares ordered residuals to expected normal order statistics. Lower W indicates departure from normality.",
      sprintf(" Statistic   : W = %s  |  p-value = %s  |  Range: N âˆˆ [3, 5000]",
              fmt_num(sw_W, 4), if (N > 5000) "n/a (N>5000)" else fmt_p(sw_p)),
      " Critical    : R relies on p-value; explicit critical values are not printed.",
      " Decision    : Reject H0 (normality) if p < Î±.",
      sprintf(" Result      : %s",
              if (N > 5000) {
                "Omitted (Shapiroâ€“Wilk is defined for N â‰¤ 5000)."
              } else if (!is.finite(sw_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (sw_p < alpha) {
                "Reject H0 â†’ residuals deviate from normality."
              } else {
                "Fail to reject H0 â†’ residual normality is plausible."
              }),
      sprintf(" Conclusion  : %s",
              if (N > 5000) {
                "For large samples, rely on Jarqueâ€“Bera and visual diagnostics (histogram, QQ-plot)."
              } else if (!is.finite(sw_p)) {
                "Unable to conclude about normality from Shapiroâ€“Wilk. Cross-check with QQ-plot and Jarqueâ€“Bera before changing the model."
              } else if (sw_p < alpha) {
                "Evidence against normality in smaller samples warrants caution with Gaussian intervals. Inspect QQ-plots for systematic S-shapes (tails) or asymmetry (skew). Consider transformations or alternative error distributions if interval accuracy is a goal."
              } else {
                "Normality appears adequate by Shapiroâ€“Wilk. Combined with QQ-plot and JB, this supports the standard Gaussian assumptions used in SARIMA teaching examples."
              }),
      "--------------------------------------------------------------------------",
      
      # ARCH LM
      "TEST 5: Engleâ€™s ARCH LM (conditional heteroskedasticity)",
      sprintf(" Purpose     : Check whether residual variance changes over time (ARCH effects) up to %d lagsâ€”important when volatility clustering is present.", arch_lags),
      " Description : Regress squared residuals on their own lags and test whether lag coefficients are jointly zero. Under H0 (no ARCH), LM ~ Ï‡^2 with df equal to the lag count.",
      sprintf(" Statistic   : LM = %s  |  df = %d  |  p-value = %s", fmt_num(arch_stat, 4), arch_lags, fmt_p(arch_p)),
      sprintf(" Critical    : Ï‡^2_(%d, 1-Î±) = %s", arch_lags, fmt_num(cv_arch, 4)),
      " Decision    : Reject H0 (no ARCH) if LM > Ï‡^2_(lags, 1-Î±) (equivalently, p < Î±).",
      sprintf(" Result      : %s",
              if (is.null(arch)) {
                "Skipped (package 'FinTS' not installed)."
              } else if (!is.finite(arch_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (arch_p < alpha) {
                "Reject H0 â†’ ARCH present."
              } else {
                "Fail to reject H0 â†’ no strong evidence of ARCH."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(arch)) {
                "Install the 'FinTS' package to assess time-varying volatility rigorously. In the meantime, inspect a rolling variance plot; volatility clustering can bias interval calibration."
              } else if (!is.finite(arch_p)) {
                "ARCH could not be assessed; consider re-running with a different lag count or larger sample. Visual checks of squared residuals may still reveal volatility clusters."
              } else if (arch_p < alpha) {
                "Time-varying variance is indicated. If volatility matters (finance, energy), consider augmenting the mean model with a GARCH-type variance model or using heteroskedasticity-robust intervals. If mean forecasts are the sole target, point forecasts can still be useful but intervals should be treated with caution."
              } else {
                "No strong evidence of ARCH effects. Constant-variance assumptions used in basic SARIMA are reasonable for these residuals, improving confidence in prediction interval calibration."
              }),
      "--------------------------------------------------------------------------",
      
      # Runs test
      "TEST 6: Runs Test (randomness of signs)",
      " Purpose     : Evaluate whether positive and negative residuals occur in a random order.",
      "               Systematic alternation or clustering of signs may indicate remaining structure (e.g., nonlinearity or omitted seasonal effects).",
      " Description : Counts runs of consecutive positive/negative residuals. Under independence, the standardized count Z is approximately N(0,1).",
      sprintf(" Statistic   : Z = %s  |  p-value = %s  |  Two-sided z-crit = Â±%s",
              fmt_num(run_Z, 4), fmt_p(run_p), fmt_num(zcrit, 3)),
      " Critical    : Reject H0 if |Z| > z_crit (equivalently, p < Î±).",
      sprintf(" Result      : %s",
              if (is.null(run)) {
                "Skipped (package 'tseries' not installed)."
              } else if (!is.finite(run_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (run_p < alpha) {
                "Reject H0 â†’ residual signs are not random."
              } else {
                "Fail to reject H0 â†’ residual signs appear random."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(run)) {
                "Install 'tseries' to include the runs test in your diagnostic battery. Without it, rely on the residual time plot to spot sign clustering."
              } else if (!is.finite(run_p)) {
                "Because the statistic could not be computed, defer to visual checks. Persistent runs may point to nonlinearity or missing seasonal terms."
              } else if (run_p < alpha) {
                "Non-random sign patterns suggest unresolved structure (e.g., threshold dynamics or seasonal mismatches). Inspect seasonal plots and consider adding nonlinearity or revisiting seasonal differencing."
              } else {
                "Signs occur in a pattern consistent with randomness, which complements portmanteau tests by checking a simple, intuitive notion of independence."
              }),
      "--------------------------------------------------------------------------",
      
      # Andersonâ€“Darling (optional)
      "TEST 7: Andersonâ€“Darling (normality, tail-sensitive) [optional]",
      " Purpose     : Detect departures from normality with particular emphasis on the tailsâ€”useful when extremes matter for risk or service-level planning.",
      " Description : The AÂ² statistic compares the empirical CDF of residuals to the normal CDF, weighting discrepancies more heavily in the tails.",
      sprintf(" Statistic   : AÂ² = %s  |  p-value = %s", fmt_num(ad_A2, 4), if (!is.null(ad)) fmt_p(ad_p) else "n/a (package 'nortest' not installed)"),
      " Critical    : Decision by p-value (package provides the calibration).",
      sprintf(" Result      : %s",
              if (is.null(ad)) {
                "Skipped (package 'nortest' not installed)."
              } else if (!is.finite(ad_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (ad_p < alpha) {
                "Reject H0 â†’ tail behavior not normal."
              } else {
                "Fail to reject H0 â†’ tails are consistent with normality."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(ad)) {
                "If tail accuracy matters, consider installing 'nortest' or inspecting extreme quantiles in the QQ-plot. Heavy tails call for robust or heavy-tailed error models."
              } else if (!is.finite(ad_p)) {
                "Unable to assess tail behavior quantitatively. Rely on QQ-plots focusing on the extremes before modifying the model."
              } else if (ad_p < alpha) {
                "Evidence of tail non-normality suggests Gaussian prediction intervals may under- or over-cover in the extremes. Consider transformations, t-errors, or bootstrapped intervals if extreme events are decision-critical."
              } else {
                "Tail behavior looks compatible with normality, supporting standard Gaussian intervals for planning purposes."
              }),
      "--------------------------------------------------------------------------",
      
      # KPSS on residuals (optional)
      "TEST 8: KPSS on Residuals (level-stationarity) [optional]",
      " Purpose     : Verify that residuals are stationary around a fixed level (no unit root), as expected from a well-specified SARIMA model.",
      " Description : The KPSS statistic accumulates partial sums of residuals; large values indicate non-stationarity. The test is run with the 'Level' null.",
      sprintf(" Statistic   : KPSS = %s  |  p-value = %s", fmt_num(kpss_stat, 5),
              if (!is.null(kpss_res)) fmt_p(kpss_p) else "n/a (package 'tseries' not installed)"),
      " Critical    : Decision by p-value or package-reported thresholds.",
      sprintf(" Result      : %s",
              if (is.null(kpss_res)) {
                "Skipped (package 'tseries' not installed)."
              } else if (!is.finite(kpss_p)) {
                "Inconclusive (statistic/p-value unavailable)."
              } else if (kpss_p < alpha) {
                "Reject H0 â†’ residuals may contain non-stationary structure."
              } else {
                "Fail to reject H0 â†’ residuals behave as stationary noise."
              }),
      sprintf(" Conclusion  : %s",
              if (is.null(kpss_res)) {
                "Install 'tseries' to include KPSS on residuals. In its absence, rely on the residual ACF and time plot to confirm stationarity."
              } else if (!is.finite(kpss_p)) {
                "Stationarity of residuals could not be certified statistically. Check for slow drifts or level shifts; if present, revisit differencing or break handling."
              } else if (kpss_p < alpha) {
                "Some non-stationary behavior remains in the residuals, which can undermine the white-noise assumption and degrade forecast uncertainty estimates. Consider additional differencing, seasonal adjustments, or modeling identified breaks."
              } else {
                "Residuals appear stationary around a fixed mean, consistent with a correctly differenced and seasonally specified SARIMA model."
              }),
      
      "==========================================================================",
      "INTERPRETATION GUIDE",
      " â€¢ Good SARIMA residuals typically: (i) pass Ljungâ€“Box/Boxâ€“Pierce (no linear autocorrelation),",
      "   (ii) show no strong ARCH unless volatility modeling is intended, and (iii) are roughly normal",
      "   if you rely on Gaussian prediction intervals. When diagnostics fail, prefer changing the model",
      "   (orders, differencing, seasonality) rather than over-fitting residuals with ad-hoc fixes."
    )
    
    paste(out, collapse = "\n")
  }
  
  
 
  
  
  
  
  
  #===============================================================
  #===============================================================
  #===============================================================
  #===============================================================
  
  
  output$auto_forecast_plot <- renderPlot({
    req(auto_fc(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    fc <- auto_fc()$fc

    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")

    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    gg_forecast_plot(obs_df, s$train_n, fc_df, title = "Auto-ARIMA forecast (train/test + intervals)")
  })

  output$auto_forecast_table <- renderTable({ req(auto_fc()); head(forecast_table(auto_fc()$fc), 25) }, rownames = FALSE)

  output$auto_accuracy_table <- renderTable({
    req(auto_fc(), ts_train_test())
    s <- ts_train_test()
    if (s$test_n == 0) return(data.frame(message = "No test set (training = 100%). Reduce training to compute accuracy."))
    accuracy_df(s$ts_test, auto_fc()$fc$mean)
  }, rownames = FALSE)

  output$apa_auto_paragraph <- renderPrint({
    req(auto_fit(), auto_fc(), ts_train_test())
    fit <- auto_fit()
    s <- ts_train_test()
    fc <- auto_fc()$fc
    lag <- as.numeric(input$diag_lag)
    lb <- tryCatch(Box.test(residuals(fit), lag = lag, type = "Ljung-Box", fitdf = length(coef(fit))), error = function(e) NULL)
    acc_line <- ""
    if (s$test_n > 0) {
      acc <- accuracy_df(s$ts_test, fc$mean)
      rmse <- acc$Value[acc$Metric == "RMSE"]
      mae <- acc$Value[acc$Metric == "MAE"]
      acc_line <- paste0("Forecast accuracy on the holdout set was RMSE = ", fmt_num(rmse, 2), " and MAE = ", fmt_num(mae, 2), ". ")
    }
    lb_line <- if (!is.null(lb)) paste0("The Ljungâ€“Box test suggested ", ifelse(lb$p.value > 0.05, "no strong residual autocorrelation", "residual autocorrelation"), " (", fmt_p(lb$p.value), "). ") else ""
    cat(
      "APA-ready paragraph:\n\n",
      "An Auto-ARIMA procedure selected a seasonal ARIMA model (", as.character(fit), "). ",
      lb_line, acc_line,
      "Forecasts were generated with prediction intervals to quantify uncertainty.\n",
      sep = ""
    )
  })
  
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  
  

  # ---- Auto-ARIMA: academic conclusion (cached on Fit click) ----
  auto_conclusion_full_obj <- eventReactive(input$fit_auto, {
    req(auto_fit(), auto_fc(), auto_equations(), ts_train_test(), prepared())
    
    fit <- auto_fit()
    fc0 <- auto_fc()
    fc  <- fc0$fc
    eq  <- auto_equations()
    s   <- ts_train_test()
    p0  <- prepared()
    
    # ---- safe values
    n_train <- suppressWarnings(as.integer(s$train_n)); if (!is.finite(n_train)) n_train <- length(residuals(fit))
    n_test  <- suppressWarnings(as.integer(s$test_n));  if (!is.finite(n_test))  n_test  <- 0L
    N <- n_train + n_test
    
    L_in <- suppressWarnings(as.integer(input$diag_lag))
    L <- if (is.finite(L_in) && L_in > 0) L_in else 12L
    fitdf <- length(coef(fit))
    
    # ---- key stats
    AICc_val <- suppressWarnings(as.numeric(fit$aicc))
    BIC_val  <- suppressWarnings(as.numeric(fit$bic))
    AIC_val  <- suppressWarnings(as.numeric(fit$aic))
    
    # ---- residual tests (minimal, fast)
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    lb <- tryCatch(Box.test(res, lag = min(L, max(1L, floor(length(res) / 3))), type = "Ljung-Box", fitdf = fitdf),
                   error = function(e) NULL)
    
    # ---- accuracy (only if test exists)
    acc_line <- NULL
    if (n_test > 0) {
      acc <- tryCatch(accuracy_df(s$ts_test, fc$mean), error = function(e) NULL)
      if (!is.null(acc) && all(c("Metric", "Value") %in% names(acc))) {
        rmse <- acc$Value[acc$Metric == "RMSE"][1]
        mae  <- acc$Value[acc$Metric == "MAE"][1]
        mape <- acc$Value[acc$Metric == "MAPE"][1]
        acc_line <- tags$p(
          tags$b("Forecast accuracy (test set). "),
          HTML(paste0(
            "Over the holdout period (n = ", n_test, "), performance was RMSE = ",
            fmt_num(rmse, 3), ", MAE = ", fmt_num(mae, 3),
            if (is.finite(mape)) paste0(", MAPE = ", fmt_num(100 * mape, 2), "%") else "",
            "."
          ))
        )
      }
    }
    if (is.null(acc_line)) {
      acc_line <- tags$p(tags$b("Forecast accuracy. "),
                         "No holdout test set was detected; therefore, out-of-sample accuracy was not computed.")
    }
    
    # ---- horizon narrative (align with your Step 5 logic)
    horizon_txt <- if (n_test > 0) {
      paste0("Validation mode was used: the forecast horizon was forced to match the test length (h = ", n_test, ").")
    } else {
      paste0("Future mode was used: forecasts were produced beyond the training sample (h = ", fc0$h, ").")
    }
    
    # ---- â€œmodel stringâ€ consistent with your equation panel
    s_term <- if (is.finite(eq$s) && eq$s > 1) sprintf(" Ã— (%d,%d,%d)[%d]", eq$P, eq$D, eq$Q, eq$s) else ""
    model_str <- sprintf("ARIMA(%d,%d,%d)%s", eq$p, eq$d, eq$q, s_term)
    
    # ---- build tag UI (fast + correct MathJax)
    tagList(
      tags$h3("Auto-ARIMA: Full academic conclusion"),
      
      tags$h4("1. Objective and modelling context"),
      tags$p(
        "An automated ARIMA procedure was used to establish a reproducible baseline for linear time-series dynamics. ",
        "Auto-ARIMA searches across candidate ARIMA/SARIMA structures and selects a parsimonious specification based on information criteria, ",
        "subject to the user-defined search settings (e.g., stepwise/approximation and seasonal allowance)."
      ),
      
      tags$h4("2. Sample design"),
      tags$p(
        HTML(paste0(
          "The analysis used <b>N = ", N, "</b> observations (training <b>n = ", n_train,
          "</b>", if (n_test > 0) paste0(", test <b>n = ", n_test, "</b>") else "",
          "). The seasonal period used in the workflow was <b>s = ", p0$freq, "</b>."
        ))
      ),
      tags$p(tags$b("Forecast design. "), horizon_txt),
      
      tags$h4("3. Selected specification and fit"),
      tags$p(HTML(paste0("The selected model was <b>", as.character(fit), "</b> (reported as <b>", model_str, "</b> in order notation)."))),
      tags$ul(
        tags$li(HTML(paste0("AIC = <b>", fmt_num(AIC_val, 2), "</b>"))),
        tags$li(HTML(paste0("AICc = <b>", fmt_num(AICc_val, 2), "</b>"))),
        tags$li(HTML(paste0("BIC = <b>", fmt_num(BIC_val, 2), "</b>")))
      ),
      tags$p(
        "In academic reporting, these criteria support relative comparison among candidate models; lower values indicate improved parsimony-adjusted fit."
      ),
      
      tags$h4("4. Model equations (reporting-ready)"),
      tags$p(
        "For documentation and replication, the fitted model is expressed in standard SARIMA operator notation, followed by an expanded form ",
        "and a numerical representation using the estimated coefficients."
      ),
      tags$div(
        style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;text-align:left;",
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h5("General SARIMA formulation:"),
        HTML(eq$eq_general),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h5("Expanded operator form:"),
        HTML(eq$eq_expanded),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        tags$h5("Numerical model:"),
        HTML(eq$eq_line3),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
        
        HTML(eq$eq_line4),
        
        tags$br(),
        tags$hr(),
        tags$hr(),
      ),
      
      tags$h4("5. Residual diagnostics (adequacy of linear dynamics)"),
      tags$p(
        "Adequacy was evaluated using graphical diagnostics (residual series, ACF, histogram, Qâ€“Q plot) and formal residual tests. ",
        "A key criterion for ARIMA adequacy is that residuals approximate white noise (no remaining autocorrelation)."
      ),
      if (!is.null(lb)) {
        tags$p(HTML(paste0(
          "<b>Ljungâ€“Box test:</b> Q(", lb$parameter, ") = ", fmt_num(lb$statistic, 3),
          ", p ", fmt_p(lb$p.value), "."
        )))
      } else {
        tags$p(tags$b("Ljungâ€“Box test:"), " unavailable (insufficient residuals or test error).")
      },
      
      tags$h4("6. Forecasting and predictive performance"),
      acc_line,
      
      tags$h4("7. Overall conclusion and recommended next steps"),
      tags$p(
        "Overall, the Auto-ARIMA baseline provides a defensible benchmark for forecasting and for comparison against theory-guided manual SARIMA candidates. ",
        "If diagnostics suggest residual autocorrelation, a refined manual specification (guided by ACF/PACF after differencing) is recommended. ",
        "If volatility clustering is present (e.g., significant ARCH effects), ARIMA may be complemented by conditional variance modelling (e.g., GARCH)."
      )
    )
  })
  
  output$auto_conclusion_full <- renderUI({
    # Show a helpful message if user hasn't clicked Fit yet
    validate(need(input$fit_auto > 0, "Click â€œFit Auto-ARIMAâ€ to generate the full academic conclusion."))
    req(auto_conclusion_full_obj())
    
    # Force MathJax typesetting in the conclusion container
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "auto_conclusion_box")
    }, once = TRUE)
    
    auto_conclusion_full_obj()
  })
  
  
  
 
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  

  # ---- Step 6 Manual SARIMA ----

  output$manual_split_text <- renderPrint({
    req(ts_train_test(), prepared())
    s <- ts_train_test()
    df <- s$dfm
    train_n <- s$train_n
    test_n <- s$test_n
    x <- df$x

    cat("Train/Test split (Manual SARIMA)\n")
    cat("- Training proportion:", fmt_pct(as.numeric(input$train_prop)), "\n")
    cat("- Training size (n):", train_n, "\n")
    cat("- Test size (n):", test_n, "\n")
    if (test_n > 0) {
      cat("- Validation forecast horizon (h):", test_n, "(forced)\n\n")
    } else {
      cat("- Validation forecast horizon (h): none (future mode)\n\n")
    }

    cat("- Training range:", as.character(x[1]), "to", as.character(x[train_n]), "\n")
    if (test_n > 0) cat("- Test range:", as.character(x[train_n + 1]), "to", as.character(x[length(x)]), "\n")
  })

  output$manual_split_plot <- renderPlot({
    req(ts_train_test(), prepared())
    p <- prepared()
    s <- ts_train_test()
    df <- s$dfm
    df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test")
    split_df <- data.frame(xint = df$x[s$train_n])

    ggplot(df, aes(x = x, y = y_trans, color = set)) +
      geom_line(linewidth = 0.9) +
      geom_vline(data = split_df, aes(xintercept = xint), linetype = "dashed") +
      theme_minimal() +
      labs(title = "Train/Test split used for Manual SARIMA", x = p$x_label, y = "Value", color = NULL) +
      theme(legend.position = "bottom")
  })

  manual_fit <- eventReactive(input$fit_manual, {
    s <- ts_train_test()
    p <- prepared()
    period <- if (!is.na(input$s) && input$s >= 1) as.numeric(input$s) else p$freq
    forecast::Arima(
      s$ts_train,
      order = c(as.numeric(input$p), as.numeric(input$d), as.numeric(input$q)),
      seasonal = list(order = c(as.numeric(input$P), as.numeric(input$D), as.numeric(input$Q)), period = period),
      include.drift = isTRUE(input$manual_drift),
      include.mean = isTRUE(input$manual_drift)
    )
  })

  manual_fc <- reactive({
    req(manual_fit(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()

    # FIX v2 (core issue):
    # When a test set exists, we forecast exactly h = test_n so forecasts overlay the test period.
    user_h <- if (!is.na(input$manual_h) && input$manual_h > 0) as.numeric(input$manual_h) else NA_real_
    if (s$test_n > 0) {
      h <- s$test_n
    } else {
      h <- if (!is.na(user_h)) user_h else max(1, frequency(s$ts_train))
    }

    fc <- forecast::forecast(manual_fit(), h = h)
    list(fc = fc, h = h, by = p$by)
  })

  output$manual_horizon_note <- renderPrint({
    req(ts_train_test(), manual_fc())
    s <- ts_train_test()
    if (s$test_n > 0) {
      cat("Validation mode: forecast horizon is forced to the test length (h =", s$test_n, ") so the forecast overlays the test period.\n")
    } else {
      cat("Future mode: no test set. Horizon uses your 'Future horizon h' input (or defaults to one seasonal cycle).\n")
    }
  })

  output$manual_model_spec <- renderPrint({
    req(manual_fit(), prepared())
    p <- prepared()
    cat("Manual SARIMA model:\n")
    cat("- Non-seasonal (p,d,q): (", input$p, ",", input$d, ",", input$q, ")\n", sep = "")
    cat("- Seasonal (P,D,Q)[s]: (", input$P, ",", input$D, ",", input$Q, ")[", ifelse(is.na(input$s), p$freq, input$s), "]\n", sep = "")
    cat("- Drift/mean included:", isTRUE(input$manual_drift), "\n")
    cat("- AICc =", fmt_num(manual_fit()$aicc, 2), ", BIC =", fmt_num(manual_fit()$bic, 2), "\n")
  })

  output$manual_coef_table <- renderTable({ req(manual_fit()); coef_table(manual_fit()) }, rownames = FALSE)
  
  output$manual_resid_ts <- renderPlot({ req(manual_fit()); plot(residuals(manual_fit()), main = "Residuals (Manual SARIMA)", ylab = "Residual", xlab = "Time") })
  output$manual_resid_acf <- renderPlot({ req(manual_fit()); plot(acf(residuals(manual_fit()), plot = FALSE), main = "Residual ACF (Manual SARIMA)") })
 
  # output$manual_resid_hist <- renderPlot({ req(manual_fit()); hist(residuals(manual_fit()), breaks = 30, main = "Residual histogram", xlab = "Residual") })
  
  output$manual_resid_hist <- renderPlot({
    req(manual_fit())
    
    res <- residuals(manual_fit())
    res <- res[is.finite(res)]
    
    hist(
      res,
      breaks = 30,
      probability = TRUE,     # IMPORTANT: scale to density
      main = "Residual histogram with normal density",
      xlab = "Residual",
      col = "grey85",
      border = "white"
    )
    
    # Overlay normal density with same mean & sd as residuals
    x <- seq(min(res), max(res), length.out = 200)
    lines(
      x,
      dnorm(x, mean = mean(res), sd = sd(res)),
      col = "#fd5c63",        # blue
      lwd = 2
    )
  })
  
  
   output$manual_resid_qq <- renderPlot({ req(manual_fit()); qqnorm(residuals(manual_fit())); qqline(residuals(manual_fit())) })
  
  
  
  
  
  
  # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # --------------------------------------------- 
  
  
  
  
  
  # ============================================================
  # âœ… DIAGNOSTICS (COPY/PASTE COMPLETE SERVER CODE)
  # Fixes:
  # - NO more "valeur manquante lÃ  oÃ¹ TRUE/FALSE est requis"
  # - safe handling for NULL inputs (fit_manual, preset, sliders)
  # - Diagnostics-only Ljungâ€“Box p-values plot: manual_resid_lb_pvals_diag2
  # - Keeps Academic conclusion plot name unchanged: manual_resid_lb_pvals
  # - Only TWO plot sliders used: diag_plot_width, diag_plot_height
  # - Container width slider: diag_container_width_px controls the flex width
  #
  # REQUIRED UI:
  # - tabPanel("Diagnostics", uiOutput("diag_container_ui"))
  # - plus: tags$head(tags$style(HTML("body { overflow-x: auto; }")))
  # ============================================================
  
  `%||%` <- function(a, b) if (!is.null(a)) a else b
  
  # ---------- SAFE helpers (prevent logical(0) / NA in if/need) ----------
  safe_chr1 <- function(x, default) {
    if (is.null(x) || length(x) == 0 || is.na(x[1])) return(default)
    as.character(x[1])
  }
  
  safe_int1 <- function(x, default) {
    y <- suppressWarnings(as.integer(x))
    if (is.null(y) || length(y) == 0 || !is.finite(y[1])) return(default)
    y[1]
  }
  
  fit_manual_clicked <- function(input) {
    fm <- input$fit_manual
    isTRUE(!is.null(fm) && length(fm) > 0 && is.finite(fm) && fm > 0)
  }
  
  nice_par <- function() {
    par(mar = c(4, 4, 2.2, 1), mgp = c(2.2, 0.7, 0), las = 1)
  }
  
  # ---- Shared helpers ----
  get_diag_controls <- function(input) {
    L_input <- suppressWarnings(as.integer(input$diag_lag))
    L <- if (is.finite(L_input) && L_input > 0) L_input else 12L
    
    alpha <- suppressWarnings(as.numeric(input$alphaSt2))
    if (!is.finite(alpha) || alpha <= 0 || alpha >= 1) alpha <- 0.05
    
    list(L = L, alpha = alpha)
  }
  
  compute_lb_pvals <- function(res, L, fitdf) {
    res <- as.numeric(res)
    res <- res[is.finite(res)]
    
    N <- length(res)
    if (N < 8) return(list(pvals = numeric(0), L = 0L, N = N))
    
    L <- as.integer(L)
    L <- max(1L, min(L, N - 1L))
    
    pvals <- rep(NA_real_, L)
    for (k in seq_len(L)) {
      if (k > fitdf) {
        bt <- tryCatch(
          stats::Box.test(res, lag = k, type = "Ljung-Box", fitdf = fitdf),
          error = function(e) NULL
        )
        pvals[k] <- if (!is.null(bt)) as.numeric(bt$p.value) else NA_real_
      }
    }
    list(pvals = pvals, L = L, N = N)
  }
  
  plot_lb_pvals <- function(pvals, L, alpha, fitdf, main_title) {
    plot(seq_len(L), pvals,
         type = "h", lwd = 2,
         xlab = "Lag (k)",
         ylab = "p-value (Ljungâ€“Box up to lag k)",
         main = main_title,
         ylim = c(0, 1))
    points(seq_len(L), pvals, pch = 16)
    abline(h = alpha, lty = 2, col = "gray40")
    mtext(sprintf("alpha = %.3f, fitdf = %d", alpha, fitdf),
          side = 3, line = 0.2, cex = 0.85)
    
    if (is.finite(fitdf) && fitdf >= 1 && fitdf < L) {
      rect(xleft = 0.5, ybottom = -0.02, xright = fitdf + 0.5, ytop = 1.02,
           border = NA, col = grDevices::adjustcolor("gray", alpha.f = 0.15))
      text(x = (fitdf + 1) / 2, y = 0.95, labels = "df â‰¤ 0 (omitted)", cex = 0.8)
    }
  }
  
  
  
  
  output$manual_resid_lb_pvals_conclusion <- renderUI({
    validate(need(fit_manual_clicked(input),
                  "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    req(ts_train_test())
    
    fit   <- manual_fit()
    res   <- residuals(fit)
    fitdf <- length(coef(fit))
    
    ctrl <- get_diag_controls(input)
    out  <- compute_lb_pvals(res, L = ctrl$L, fitdf = fitdf)
    
    validate(need(out$N >= 8, "Too few residuals (N < 8) to interpret Ljungâ€“Box p-values."))
    validate(need(out$L >= 1, "No valid lags available for Ljungâ€“Box interpretation."))
    
    L     <- out$L
    alpha <- ctrl$alpha
    pvals <- out$pvals
    
    fmt_p <- function(p) {
      if (!is.finite(p)) return("NA")
      if (p < 0.001) return("< .001")
      paste0("= ", sub("^0\\.", ".", sprintf("%.3f", p)))
    }
    fmt_lags <- function(x) {
      if (length(x) == 0) return("none")
      if (length(x) <= 12) return(paste(x, collapse = ", "))
      paste0(paste(head(x, 8), collapse = ", "), ", â€¦, ", paste(tail(x, 3), collapse = ", "))
    }
    
    valid <- which(is.finite(pvals))
    
    # --- If no evaluable lags exist, wrap message + next steps in a callout ---
    if (length(valid) == 0) {
      return(
        callout(
          tagList(
            tags$h5(tags$strong("Interpretation and academic conclusion (Ljungâ€“Box p-values by lag)")),
            tags$p(
              tags$b("Interpretation (Ljungâ€“Box by lag). "),
              "No evaluable lags were available because the selected maximum lag L is not greater than the modelâ€™s effective parameter count (fitdf), ",
              "so the test degrees of freedom (k âˆ’ fitdf) are not positive."
            ),
            tags$p(tags$b("ACTIONABLE NEXT STEPS (What to do now):")),
            tags$ol(
              style = "margin-top:6px; margin-bottom:0; padding-left:18px;",
              tags$li("Increase the maximum lag L so that L > fitdf, then re-check the Ljungâ€“Box p-values by lag."),
              tags$li("If fitdf is large relative to the sample size, consider a more parsimonious SARIMA specification (fewer AR/MA terms)."),
              tags$li("Confirm adequacy using complementary diagnostics (residual ACF and out-of-sample forecast performance) rather than relying on Ljungâ€“Box alone.")
            )
          ),
          title = NULL,
          theme = "slate",
          body_is_html = FALSE
        )
      )
    }
    
    rej <- valid[pvals[valid] < alpha]
    
    n_valid   <- length(valid)
    n_rej     <- length(rej)
    pct_rej   <- round(100 * n_rej / n_valid, 1)
    first_rej <- if (n_rej > 0) rej[1] else NA_integer_
    last_rej  <- if (n_rej > 0) rej[length(rej)] else NA_integer_
    
    k_min <- valid[which.min(pvals[valid])]
    p_min <- pvals[k_min]
    
    # --- Seasonal pattern check: use frequency of the TRAINING TS, not residual vector ---
    s_obj <- ts_train_test()
    
    freq <- tryCatch({
      f <- stats::frequency(s_obj$ts_train)
      if (is.null(f) || length(f) == 0 || !is.finite(f) || f < 1) NA_integer_ else as.integer(f)
    }, error = function(e) NA_integer_)
    
    seasonal_lags <- if (is.finite(freq) && freq >= 2) seq.int(from = freq, to = L, by = freq) else integer(0)
    seasonal_rej  <- if (length(seasonal_lags)) intersect(rej, seasonal_lags) else integer(0)
    
    early_window_end <- min(L, max(fitdf + 5L, fitdf + if (length(seasonal_lags)) min(freq, 12L) else 5L))
    early_lags <- intersect(rej, seq.int(from = max(1L, fitdf + 1L), to = early_window_end))
    
    # Conclusion text logic + next steps
    if (n_rej == 0) {
      verdict <- paste0(
        "Across all evaluable lags (k = ", min(valid), "â€¦", max(valid), "), all p-values exceed Î± = ",
        sprintf("%.2f", alpha), ". Therefore, we fail to reject the null hypothesis of no residual autocorrelation ",
        "up to the tested lag range; the residuals are compatible with white noise (conditional on the fitted SARIMA structure)."
      )
      rec <- "No additional AR/MA (or seasonal AR/MA) structure is strongly indicated by the Ljungâ€“Box results alone; keep the current mean model unless other diagnostics disagree."
      
      next_steps <- list(
        "Retain the current differencing and AR/MA orders unless residual ACF/plots indicate otherwise.",
        "Verify that residual ACF has no systematic spikes and that other residual tests (normality/ARCH/runs) are acceptable.",
        "Proceed to forecasting evaluation: confirm stable holdout accuracy and sensible prediction intervals."
      )
    } else {
      pattern_hint <- if (length(seasonal_rej) > 0 && length(early_lags) == 0) {
        "The rejections concentrate at (or near) seasonal multiples, which is consistent with remaining seasonal dependence not fully captured by the current seasonal terms."
      } else if (length(early_lags) > 0 && length(seasonal_rej) == 0) {
        "The rejections appear at early lags, which is consistent with remaining short-run AR/MA dynamics (non-seasonal underfitting)."
      } else if (length(seasonal_rej) > 0 && length(early_lags) > 0) {
        "Rejections occur both at early lags and seasonal multiples, suggesting a combination of short-run and seasonal underfitting (or insufficient differencing)."
      } else {
        "Rejections occur at scattered lags, suggesting some remaining dependence that may be mild or localized but still detectable."
      }
      
      verdict <- paste0(
        "At Î± = ", sprintf("%.2f", alpha), ", ", n_rej, " out of ", n_valid, " evaluable lags (", pct_rej,
        "%) fall below the threshold (significant): lags {", fmt_lags(rej), "}. ",
        "The earliest rejection occurs at lag k = ", first_rej,
        if (!is.na(last_rej)) paste0(" (last at k = ", last_rej, "). ") else ". ",
        "The smallest p-value occurs at lag k = ", k_min, " (p ", fmt_p(p_min), "). ",
        pattern_hint
      )
      
      rec <- paste0(
        "Conclusion: the residuals are not fully white-noise across the tested range, so the current SARIMA specification likely leaves ",
        "some systematic autocorrelation unmodelled. Practically, refine (p, q) when early-lag rejections dominate; refine (P, Q) and/or revisit seasonal differencing D when rejections align with seasonal multiples."
      )
      
      # Tailor next steps based on detected pattern
      next_steps <- if (length(seasonal_rej) > 0 && length(early_lags) == 0) {
        list(
          "Prioritize seasonal structure: consider adjusting (P, Q) and confirm the seasonal period s is correctly specified.",
          "If seasonal persistence remains strong, reconsider seasonal differencing D (but avoid over-differencing).",
          "Refit candidate models and re-check residual ACF and Ljungâ€“Box p-values by lag until rejections largely disappear."
        )
      } else if (length(early_lags) > 0 && length(seasonal_rej) == 0) {
        list(
          "Prioritize short-run dynamics: adjust non-seasonal (p, q) guided by residual ACF/PACF patterns at low lags.",
          "Refit competing models and re-check Ljungâ€“Box p-values; aim for p-values mostly above Î± across lags.",
          "Validate changes using holdout forecast accuracy to ensure improvements are not purely in-sample."
        )
      } else {
        list(
          "Compare a small set of nearby SARIMA specifications (vary p/q and possibly P/Q) and select the most parsimonious model that improves residual whiteness.",
          "If rejections persist across many lags, revisit differencing choices (d, D) cautiously and reassess stationarity and residual diagnostics.",
          "Confirm adequacy with both diagnostics and holdout forecast performance (do not rely on Ljungâ€“Box alone)."
        )
      }
    }
    
    callout(
      tagList(
        tags$h5(tags$strong("Interpretation and academic conclusion (Ljungâ€“Box p-values by lag)")),
        
        tags$p(
          "The figure reports Ljungâ€“Box portmanteau test p-values computed cumulatively up to each lag k (x-axis), with p-values on the y-axis. ",
          "The horizontal reference line marks the chosen significance level Î±. ",
          "Lags k â‰¤ fitdf are omitted (or shown as non-evaluable) because the effective degrees of freedom for the test, (k âˆ’ fitdf), are not positive."
        ),
        
        tags$ul(
          style = "list-style-type:square; padding-left: 18px; line-height: 1.5;",
          tags$li(HTML(paste0("<b>Sample size (residuals):</b> N = ", out$N))),
          tags$li(HTML(paste0("<b>Maximum tested lag:</b> L = ", L, " (evaluable lags: ", n_valid, ")"))),
          tags$li(HTML(paste0("<b>Decision threshold:</b> Î± = ", sprintf("%.2f", alpha)))),
          tags$li(HTML(paste0("<b>Minimum p-value:</b> p ", fmt_p(p_min), " at lag k = ", k_min))),
          if (length(seasonal_lags)) tags$li(HTML(paste0(
            "<b>Seasonal period detected:</b> s = ", freq,
            " (seasonal multiples within range: {", fmt_lags(seasonal_lags), "})"
          ))) else NULL
        ),
        
        tags$p(HTML(paste0("<b>Results and conclusion.</b> ", verdict))),
        tags$p(HTML(paste0("<b>Implication for model adequacy.</b> ", rec))),
        
        tags$p(tags$b("ACTIONABLE NEXT STEPS (What to do now):")),
        tags$ol(
          style = "margin-top:6px; margin-bottom:0; padding-left:18px;",
          lapply(next_steps, tags$li)
        )
      ),
      title = NULL,
      theme = "blue",
      body_is_html = FALSE
    )
  })
  
  
 
  
  
  # ============================================================
  # Diagnostics plots (independent outputs)
  # ============================================================
  
  output$manual_resid_ts_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 3, "Not enough residuals to plot."))
    
    plot(res, type = "l",
         main = "Residuals over time",
         xlab = "Time", ylab = "Residual")
    abline(h = 0, col = "gray40", lty = 2)
  })
  
  output$manual_resid_acf_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for ACF."))
    
    plot(acf(res, plot = FALSE), main = "Residual ACF")
  })
  
  
  
  output$manual_resid_pacf_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for PACF."))
    
    plot(pacf(res, plot = FALSE), main = "Residual PACF")
  })
  
  
  output$manual_resid_hist_diag <- renderPlot({
    validate(need(fit_manual_clicked(input),
                  "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for histogram."))
    
    # Histogram on density scale
    hist(
      res,
      breaks = 30,
      probability = TRUE,      # IMPORTANT
      col = "gray85",
      border = "white",
      main = "Residual histogram with normal density",
      xlab = "Residual"
    )
    
    # Overlay fitted normal density
    x <- seq(min(res), max(res), length.out = 200)
    lines(
      x,
      dnorm(x, mean = mean(res), sd = sd(res)),
      col = "#CC5500",          # blue
      lwd = 2
    )
    
    # Optional legend (recommended for teaching)
    legend(
      "topright",
      legend = c("Residual density", "Normal density"),
      col = c("gray60", "#CC5500"),
      lwd = c(NA, 2),
      pch = c(15, NA),
      pt.cex = 1.5,
      bty = "n"
    )
  })
  

  
  output$manual_resid_qq_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    validate(need(length(res) >= 5, "Not enough residuals for Qâ€“Q plot."))
    
    qqnorm(res, main = "Normal Qâ€“Q")
    qqline(res, col = "red", lwd = 2)
  })
  
  output$manual_resid_fitted_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    fv  <- as.numeric(fitted(fit))
    ok  <- is.finite(res) & is.finite(fv)
    validate(need(sum(ok) >= 10, "Not enough valid points for residuals vs fitted."))
    
    plot(fv[ok], res[ok],
         pch = 16, cex = 0.7,
         col = grDevices::adjustcolor("steelblue", alpha.f = 0.7),
         main = "Residuals vs fitted",
         xlab = "Fitted values", ylab = "Residual")
    abline(h = 0, col = "gray40", lty = 2)
    if (sum(ok) > 20) {
      lines(stats::lowess(fv[ok], res[ok], f = 2/3), col = "tomato", lwd = 2)
    }
  })
  
  output$manual_resid_scale_diag <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res <- as.numeric(residuals(fit))
    fv  <- as.numeric(fitted(fit))
    ok  <- is.finite(res) & is.finite(fv)
    y   <- sqrt(abs(res))
    ok2 <- ok & is.finite(y)
    validate(need(sum(ok2) >= 10, "Not enough valid points for scale-location plot."))
    
    plot(fv[ok2], y[ok2],
         pch = 16, cex = 0.7,
         col = grDevices::adjustcolor("darkgreen", alpha.f = 0.65),
         main = "Scale-location (sqrt(|res|) vs fitted)",
         xlab = "Fitted values", ylab = expression(sqrt("|Residual|")))
    if (sum(ok2) > 20) {
      lines(stats::lowess(fv[ok2], y[ok2], f = 2/3), col = "tomato", lwd = 2)
    }
  })
  
  # ------------------------------------------------------------
  # NEW: Ljungâ€“Box p-values by lag (Diagnostics ONLY)
  # ------------------------------------------------------------
  output$manual_resid_lb_pvals_diag2 <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res   <- residuals(fit)
    fitdf <- length(coef(fit))
    
    ctrl <- get_diag_controls(input)
    out  <- compute_lb_pvals(res, L = ctrl$L, fitdf = fitdf)
    
    validate(need(out$N >= 8, "Too few residuals (N < 8) to compute Ljungâ€“Box p-values."))
    validate(need(out$L >= 1, "No valid lags available for Ljungâ€“Box p-values."))
    
    plot_lb_pvals(out$pvals, out$L, ctrl$alpha, fitdf,
                  main_title = "Ljungâ€“Box p-values by lag (Diagnostics)")
  })
  
  # ------------------------------------------------------------
  # Commentary (Diagnostics tab)
  # ------------------------------------------------------------
  output$manual_diag_commentary_diag <- renderPrint({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    
    res <- as.numeric(residuals(fit))
    res <- res[is.finite(res)]
    N   <- length(res)
    
    ctrl  <- get_diag_controls(input)
    fitdf <- length(coef(fit))
    
    if (N < 8) {
      cat("Diagnostics summary (Manual SARIMA)\n",
          "------------------------------------------------------------\n",
          "- Too few residuals to run diagnostics.\n", sep = "")
      return(invisible())
    }
    
    L2 <- max(1L, min(as.integer(ctrl$L), N - 1L))
    lb <- tryCatch(
      stats::Box.test(res, lag = L2, type = "Ljung-Box", fitdf = fitdf),
      error = function(e) NULL
    )
    
    cat("Diagnostics summary (Manual SARIMA)\n")
    cat("------------------------------------------------------------\n")
    if (!is.null(lb) && is.finite(lb$p.value)) {
      cat("Ljungâ€“Box (lag ", L2, ") p = ", signif(lb$p.value, 3),
          if (lb$p.value > ctrl$alpha) " -> no strong evidence of autocorrelation.\n"
          else " -> remaining autocorrelation; revise orders/differencing.\n",
          sep = "")
    } else {
      cat("Ljungâ€“Box unavailable.\n")
    }
    
    cat("\nNotes:\n")
    cat("- Use Residual ACF + Ljungâ€“Box together: spikes + small p-values suggest underfitting.\n")
    cat("- If Qâ€“Q shows heavy tails: intervals/inference may be optimistic.\n")
  })
  
  # ============================================================
  # KEEP: Academic conclusion plot output unchanged
  # ============================================================
  output$manual_resid_lb_pvals <- renderPlot({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) to generate diagnostics."))
    req(manual_fit())
    fit <- manual_fit()
    nice_par()
    
    res   <- residuals(fit)
    fitdf <- length(coef(fit))
    
    ctrl <- get_diag_controls(input)
    out  <- compute_lb_pvals(res, L = ctrl$L, fitdf = fitdf)
    
    validate(need(out$N >= 8, "Too few residuals (N < 8) to compute Ljungâ€“Box p-values."))
    validate(need(out$L >= 1, "No valid lags available for Ljungâ€“Box p-values."))
    
    plot_lb_pvals(out$pvals, out$L, ctrl$alpha, fitdf,
                  main_title = "Ljungâ€“Box p-values by lag (Manual SARIMA)")
  })
  
  # ============================================================
  # Layout builder + auto canvas sizing from ONLY plot width/height
  # ============================================================
  
  manual_diag_plot_map <- list(
    ts     = list(id = "manual_resid_ts_diag",        title = "Residuals over time"),
    acf    = list(id = "manual_resid_acf_diag",       title = "Residual ACF"),
    pacf   = list(id = "manual_resid_pacf_diag",      title = "Residual PACF"),
    hist   = list(id = "manual_resid_hist_diag",      title = "Residual histogram"),
    qq     = list(id = "manual_resid_qq_diag",        title = "Normal Qâ€“Q"),
    fitted = list(id = "manual_resid_fitted_diag",    title = "Residuals vs fitted"),
    scale  = list(id = "manual_resid_scale_diag",     title = "Scale-location"),
    lb     = list(id = "manual_resid_lb_pvals_diag2", title = "Ljungâ€“Box p-values by lag (Diagnostics)")
  )
  
  get_diag_plot_order <- reactive({
    sel <- input$diag_plots_selected
    if (is.null(sel) || length(sel) == 0) return(character(0))
    
    preset <- safe_chr1(input$diag_layout_preset, "preset_current")
    
    if (!identical(preset, "preset_custom")) {
      # default_order <- c("ts", "acf", "hist", "qq", "fitted", "scale", "lb")
      default_order <- c("ts", "acf", "pacf", "hist", "qq", "fitted", "scale", "lb")
      
      return(default_order[default_order %in% sel])
    }
    
    pos <- c(
      ts     = input$pos_ts,
      acf    = input$pos_acf,
      pacf   = input$pos_pacf,
      hist   = input$pos_hist,
      qq     = input$pos_qq,
      fitted = input$pos_fitted,
      scale  = input$pos_scale,
      lb     = input$pos_lb
    )
    pos <- pos[names(pos) %in% sel]
    pos_num <- suppressWarnings(as.numeric(pos))
    pos_num[!is.finite(pos_num)] <- 999
    ord <- order(pos_num, names(pos_num))
    names(pos_num)[ord]
  })
  
  diag_canvas_dims <- reactive({
    keys   <- get_diag_plot_order()
    preset <- safe_chr1(input$diag_layout_preset, "preset_current")
    
    pw <- safe_int1(input$diag_plot_width, 650L)
    ph <- safe_int1(input$diag_plot_height, 320L)
    
    # If you want to allow "auto width", set slider min >=300; we keep px always.
    if (pw < 300) pw <- 300L
    if (ph < 200) ph <- 200L
    
    ncol <- if (identical(preset, "preset_one_col") || identical(preset, "preset_custom")) 1L else 2L
    n <- length(keys)
    nrow <- if (n == 0) 1L else ceiling(n / ncol)
    
    pad_w <- 60L
    pad_h <- 110L
    
    canvas_w <- ncol * (pw + pad_w) + 40L
    canvas_h <- nrow * (ph + pad_h) + 40L
    
    list(w = canvas_w, h = canvas_h, pw = pw, ph = ph)
  })
  
  make_diag_plot_output <- function(plot_key, pw, ph) {
    info <- manual_diag_plot_map[[plot_key]]
    if (is.null(info)) return(NULL)
    
    tags$div(
      style = sprintf(
        "margin-bottom:14px; padding:10px; border:1px solid #eee; border-radius:10px; background:#fff; width:%dpx;",
        pw + 30
      ),
      tags$h5(info$title),
      plotOutput(info$id, width = pw, height = ph)
    )
  }
  
  output$manual_diag_plots_ui <- renderUI({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) first, then diagnostics will appear."))
    
    keys <- get_diag_plot_order()
    if (length(keys) == 0) {
      return(tags$div(
        style = "padding:10px;border:1px dashed #ccc;border-radius:10px;background:#fff;",
        tags$strong("No plots selected."),
        tags$p("Use the left panel to select plots.")
      ))
    }
    
    dims <- diag_canvas_dims()
    pw <- dims$pw
    ph <- dims$ph
    preset <- safe_chr1(input$diag_layout_preset, "preset_current")
    
    if (identical(preset, "preset_one_col") || identical(preset, "preset_custom")) {
      return(tagList(lapply(keys, function(k) make_diag_plot_output(k, pw, ph))))
    }
    
    left  <- keys[seq(1, length(keys), by = 2)]
    right <- keys[seq(2, length(keys), by = 2)]
    fluidRow(
      column(6, lapply(left,  function(k) make_diag_plot_output(k, pw, ph))),
      column(6, lapply(right, function(k) make_diag_plot_output(k, pw, ph)))
    )
  })
  
  output$manual_diag_canvas_ui <- renderUI({
    validate(need(fit_manual_clicked(input), "Click 'Fit' (Manual SARIMA) first, then diagnostics will appear."))
    
    dims <- diag_canvas_dims()
    keys <- get_diag_plot_order()
    if (length(keys) == 0) return(NULL)
    
    tags$div(
      style = sprintf("width:%dpx; min-height:%dpx; background:#fcfcfc;", dims$w, dims$h),
      uiOutput("manual_diag_plots_ui")
    )
  })
  
  # ============================================================
  # FULL Diagnostics container UI (slider-driven width)
  # ============================================================
  
  output$diag_container_ui <- renderUI({
    container_w <- safe_int1(input$diag_container_width_px, 1600L)
    if (container_w < 900) container_w <- 900L
    
    # keep selected values stable even if UI rebuilds
    preset_now <- safe_chr1(input$diag_layout_preset, "preset_current")
    sel_now    <- input$diag_plots_selected %||% c("ts","acf", "pacf", "hist","qq","lb","fitted","scale")
    pw_now     <- safe_int1(input$diag_plot_width, 450L)
    ph_now     <- safe_int1(input$diag_plot_height, 320L)
    show_conc  <- isTRUE(input$diag_show_conclusion %||% TRUE)
    
    tags$div(
      style = sprintf("
      display:flex;
      gap:12px;
      align-items:flex-start;
      width:%dpx;
      max-width:none;
    ", container_w),
      
      # Sidebar
      tags$div(
        style = "
        flex:0 0 220px;
        max-width:320px;
        border:1px solid #e5e5e5;
        border-radius:10px;
        padding:10px;
        background:#fff;
        max-height:85vh;
        overflow-y:auto;
      ",
        
        tags$h4("Diagnostics layout builder"),
        
        selectInput(
          "diag_layout_preset",
          "Layout preset",
          choices = c(
            "Current layout" = "preset_current",
            "Two columns"    = "preset_two_col",
            "Single column"  = "preset_one_col",
            "Custom order"   = "preset_custom"
          ),
          selected = preset_now
        ),
        
        tags$hr(),
        
        checkboxGroupInput(
          "diag_plots_selected",
          "Plots to display",
          choices = c(
            "Residuals over time"                          = "ts",
            "Residual ACF"                                 = "acf",
            "Residual PACF"                                = "pacf",
            "Residual histogram"                           = "hist",
            "Normal Q-Q"                                   = "qq",
            "Residuals vs fitted"                          = "fitted",
            "Scale-location (sqrt(|res|) vs fitted)"       = "scale",
            "Ljungâ€“Box p-values by lag"                    = "lb"
          ),
          selected = sel_now
        ),
        
        tags$hr(),
        
        sliderInput(
          "diag_container_width_px",
          "Container width (px)",
          min = 1000, max = 5000, value = container_w, step = 50
        ),
        # helpText("Controls the whole Diagnostics width (was width:100%). Scroll horizontally if needed."),
        
        tags$hr(),
        
        # ONLY TWO plot sliders
        sliderInput(
          "diag_plot_width",
          "Plot width (px)",
          min = 300, max = 2500, value = pw_now, step = 25
        ),
        sliderInput(
          "diag_plot_height",
          "Plot height (px)",
          min = 200, max = 1400, value = ph_now, step = 10
        ),
        
        tags$hr(),
        
        checkboxInput("diag_show_conclusion", "Show academic conclusion panel", value = show_conc),
        
        conditionalPanel(
          condition = "input.diag_layout_preset == 'preset_custom'",
          tags$h5("Custom positions (1 = first)"),
          helpText("Give each enabled plot a position. Ties are broken by name."),
          numericInput("pos_ts",     "Residuals over time position", value = safe_int1(input$pos_ts, 1L), min = 1, step = 1),
          numericInput("pos_acf",    "Residual ACF position",        value = safe_int1(input$pos_acf, 2L), min = 1, step = 1),
          numericInput("pos_hist",   "Histogram position",           value = safe_int1(input$pos_hist, 3L), min = 1, step = 1),
          numericInput("pos_qq",     "Q-Q position",                 value = safe_int1(input$pos_qq, 4L), min = 1, step = 1),
          numericInput("pos_fitted", "Residuals vs fitted position", value = safe_int1(input$pos_fitted, 5L), min = 1, step = 1),
          numericInput("pos_scale",  "Scale-location position",      value = safe_int1(input$pos_scale, 6L), min = 1, step = 1),
          numericInput("pos_lb",     "Ljungâ€“Box p-values position",  value = safe_int1(input$pos_lb, 7L), min = 1, step = 1)
        )
      ),
      
      # Right panel
      tags$div(
        style = "
        flex:1 1 auto;
        border:1px solid #e5e5e5;
        border-radius:10px;
        background:#fcfcfc;
        padding:10px;
        overflow:auto;
        max-height:85vh;
      ",
        
        tags$div(
          style = "margin-bottom:12px;",
          tags$h4("Residual diagnostics (Manual SARIMA)"),
          tags$p("Use container width + plot width/height. Scroll right/down to see everything.")
        ),
        
        uiOutput("manual_diag_canvas_ui"),
        
        conditionalPanel(
          condition = "input.diag_show_conclusion == true",
          tags$h4("Academic conclusion (Diagnostics)"),
          tags$div(
            style = "padding:10px;border:1px solid #e5e5e5;border-radius:10px;background:#ffffff;",
            verbatimTextOutput("manual_diag_commentary_diag")
          )
        )
      )
    )
  })
  
  
  
  
  
  
  
  
  # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # ---------------------------------------------   # --------------------------------------------- 
  # --------------------------------------------- 
  
  

  # Manual SARIMA residual tests (formatted)
  output$manual_diag_tests <- renderPrint({
    req(manual_fit())
    cat(
      residual_diagnostics_report_full(
        res   = residuals(manual_fit()),
        L     = suppressWarnings(as.integer(input$diag_lag %||% 12)),
        fitdf = length(coef(manual_fit())),
        alpha = to_num_safe(input$alphaSt2 %||% 0.05, 0.05)
      )
    )
  })
  
  
  residual_diagnostics_report_full <- function(res, L = 12L, fitdf = 0L, alpha = 0.05) {
    # sanitize
    res   <- as.numeric(res); res <- res[is.finite(res)]
    N     <- length(res)
    L     <- max(1L, as.integer(L))
    fitdf <- max(0L, as.integer(fitdf))
    alpha <- to_num_safe(alpha, 0.05)
    
    if (N < 8) {
      return(paste(
        "==========================================================================",
        "                    RESIDUAL DIAGNOSTIC BATTERY                           ",
        "==========================================================================",
        " Too few residuals (N < 8) to run the requested tests.",
        sep = "\n"
      ))
    }
    
    # convenience numbers
    df_lb  <- max(L - fitdf, 1L)
    cv_lb  <- stats::qchisq(1 - alpha, df = df_lb)
    cv_jb  <- stats::qchisq(1 - alpha, df = 2)
    arch_m <- min(L, max(1L, floor(N / 10)))
    zcrit  <- stats::qnorm(1 - alpha/2)
    
    # tests
    lb   <- tryCatch(stats::Box.test(res, lag = L, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
    bp   <- tryCatch(stats::Box.test(res, lag = L, type = "Box-Pierce", fitdf = fitdf), error = function(e) NULL)
    jb   <- if (requireNamespace("tseries", quietly = TRUE)) tryCatch(tseries::jarque.bera.test(res), error = function(e) NULL) else NULL
    sw   <- if (N >= 3 && N <= 5000) tryCatch(stats::shapiro.test(res), error = function(e) NULL) else NULL
    arch <- if (requireNamespace("FinTS", quietly = TRUE)) tryCatch(FinTS::ArchTest(res, lags = arch_m), error = function(e) NULL) else NULL
    run  <- if (requireNamespace("tseries", quietly = TRUE)) tryCatch(tseries::runs.test(res), error = function(e) NULL) else NULL
    ad   <- if (requireNamespace("nortest", quietly = TRUE)) tryCatch(nortest::ad.test(res), error = function(e) NULL) else NULL
    
    # pull numbers safely
    lb_stat  <- if (!is.null(lb))  as.numeric(lb$statistic) else NA_real_
    lb_p     <- if (!is.null(lb))  as.numeric(lb$p.value)   else NA_real_
    bp_stat  <- if (!is.null(bp))  as.numeric(bp$statistic) else NA_real_
    bp_p     <- if (!is.null(bp))  as.numeric(bp$p.value)   else NA_real_
    jb_stat  <- if (!is.null(jb))  as.numeric(jb$statistic) else NA_real_
    jb_p     <- if (!is.null(jb))  as.numeric(jb$p.value)   else NA_real_
    sw_W     <- if (!is.null(sw))  as.numeric(sw$statistic) else NA_real_
    sw_p     <- if (!is.null(sw))  as.numeric(sw$p.value)   else NA_real_
    arch_stat<- if (!is.null(arch))as.numeric(arch$statistic) else NA_real_
    arch_p   <- if (!is.null(arch))as.numeric(arch$p.value)    else NA_real_
    run_Z    <- if (!is.null(run)) as.numeric(run$statistic)  else NA_real_
    run_p    <- if (!is.null(run)) as.numeric(run$p.value)    else NA_real_
    ad_A2    <- if (!is.null(ad))  as.numeric(ad$statistic)   else NA_real_
    ad_p     <- if (!is.null(ad))  as.numeric(ad$p.value)     else NA_real_
    
    # flags for the overall conclusion
    lb_ok   <- is.finite(lb_p)   && lb_p   >= alpha
    bp_ok   <- is.finite(bp_p)   && bp_p   >= alpha
    norm_ok <- (is.finite(jb_p) && jb_p >= alpha) || (is.finite(sw_p) && sw_p >= alpha) || (is.finite(ad_p) && ad_p >= alpha)
    arch_ok <- is.null(arch) || (is.finite(arch_p) && arch_p >= alpha)
    runs_ok <- is.null(run)  || (is.finite(run_p)  && run_p  >= alpha)
    
    out <- c(
      "==========================================================================",
      "                     RESIDUAL DIAGNOSTIC BATTERY                          ",
      "==========================================================================",
      sprintf(" SAMPLE SIZE (residuals): %d   |   Î±: %s   |   Lag (L): %d   |   fitdf: %d",
              N, fmt_num(alpha, 4), L, fitdf),
      "--------------------------------------------------------------------------",
      
      # TEST 1: Ljungâ€“Box
      "TEST 1 â€” LJUNGâ€“BOX PORTMANTEAU (AUTOCORRELATION)",
      " Purpose: Detect remaining serial correlation up to lag L in the residuals of the fitted model.",
      " Description: The Ljungâ€“Box statistic sums squared sample autocorrelations with a small-sample",
      "  correction. After estimating ARMA/SARIMA parameters, the degrees of freedom are reduced by the",
      "  number of fitted coefficients (fitdf). Well-specified residuals should resemble white noise.",
      " â€¢ H0: Residuals are white noise (no serial correlation up to lag L).",
      " â€¢ Ha: Residuals are autocorrelated (model may be underspecified).",
      sprintf(" â†’ CRITERIA: Reject H0 if Q(LB) > Ï‡^2_(%d,1-Î±)  (equivalently p-value < Î±).", df_lb),
      " RESULT:",
      sprintf("  - Q(LB)          : %s", fmt_num(lb_stat, 4)),
      sprintf("  - df (L - fitdf) : %d", df_lb),
      sprintf("  - Ï‡^2 crit       : %s", fmt_num(cv_lb, 4)),
      sprintf("  - p-value        : %s", fmt_p(lb_p)),
      " DECISION & INTERPRETATION:",
      if (!is.finite(lb_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (lb_p < alpha) {
        "  Reject H0. The residuals still contain autocorrelation up to lag L. This suggests the model may be\n  missing AR/MA or seasonal terms, or that differencing is insufficient. Review ACF/PACF of residuals and\n  consider adjusting orders, seasonal components, or transformations."
      } else {
        "  Fail to reject H0. Residuals behave like white noise up to lag L. This supports the adequacy of the modelâ€™s\n  dynamic specification (orders), which is desirable before interpreting parameters or forecasting."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 2: Boxâ€“Pierce
      "TEST 2 â€” BOXâ€“PIERCE PORTMANTEAU (CLASSIC AUTOCORRELATION)",
      " Purpose: Older portmanteau test for residual autocorrelation; conceptually similar to Ljungâ€“Box.",
      " Description: Uses a simpler large-sample approximation without the Ljungâ€“Box small-sample correction.",
      "  It is less accurate in small samples but should broadly agree with Ljungâ€“Box when N is moderate/large.",
      " â€¢ H0: Residuals are white noise.",
      " â€¢ Ha: Residuals are autocorrelated.",
      sprintf(" â†’ CRITERIA: Reject H0 if Q(BP) > Ï‡^2_(%d,1-Î±)  (equivalently p-value < Î±).", df_lb),
      " RESULT:",
      sprintf("  - Q(BP)    : %s", fmt_num(bp_stat, 4)),
      sprintf("  - df       : %d", df_lb),
      sprintf("  - Ï‡^2 crit : %s", fmt_num(cv_lb, 4)),
      sprintf("  - p-value  : %s", fmt_p(bp_p)),
      " DECISION & INTERPRETATION:",
      if (!is.finite(bp_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (bp_p < alpha) {
        "  Reject H0. Autocorrelation remains. Combined with Ljungâ€“Box, this strengthens the case for revising the model."
      } else {
        "  Fail to reject H0. No strong evidence of residual autocorrelation by Boxâ€“Pierce."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 3: Jarqueâ€“Bera
      "TEST 3 â€” JARQUEâ€“BERA (NORMALITY: SKEWNESS & KURTOSIS)",
      " Purpose: Evaluate whether residuals are approximately normally distributed by combining deviations in skewness",
      "  and kurtosis. Normal residuals help ensure well-calibrated prediction intervals and valid t-statistics in",
      "  regression-type outputs.",
      " Description: Asymptotically follows Ï‡^2 with 2 df. Sensitive to heavy tails and skew.",
      " â€¢ H0: Residuals are normally distributed.",
      " â€¢ Ha: Residuals are not normal (skewed and/or heavy/light tails).",
      " â†’ CRITERIA: Reject H0 if JB > Ï‡^2_(2,1-Î±) (equivalently p-value < Î±).",
      " RESULT:",
      sprintf("  - JB statistic : %s", fmt_num(jb_stat, 4)),
      sprintf("  - Ï‡^2 crit    : %s", fmt_num(cv_jb, 4)),
      sprintf("  - p-value     : %s", fmt_p(jb_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(jb)) {
        "  Skipped: package 'tseries' not installed."
      } else if (!is.finite(jb_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (jb_p < alpha) {
        "  Reject H0. Residuals deviate from normality. Forecast means are still unbiased if the model is correct, but\n  interval forecasts may be miscalibrated. Consider transformations (e.g., log/Boxâ€“Cox), robust modeling, or\n  heavy-tailed error models (e.g., t innovations) if this materially affects your goals."
      } else {
        "  Fail to reject H0. Normality is plausible by JB, supporting standard interval calibration."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 4: Shapiroâ€“Wilk
      "TEST 4 â€” SHAPIROâ€“WILK (NORMALITY: SMALL/MEDIUM N)",
      " Purpose: Sensitive test for normality, recommended when sample size is small to moderate.",
      " Description: Based on correlation between ordered sample values and corresponding normal scores. Does not print a simple",
      "  critical value in base R; decisions are p-value based. Defined for 3 â‰¤ N â‰¤ 5000.",
      " â€¢ H0: Residuals come from a normal distribution.",
      " â€¢ Ha: Residuals are non-normal.",
      " â†’ CRITERIA: Reject H0 if p-value < Î±.",
      " RESULT:",
      sprintf("  - W statistic : %s", fmt_num(sw_W, 4)),
      sprintf("  - p-value     : %s", if (N > 5000) "n/a (N > 5000)" else fmt_p(sw_p)),
      " DECISION & INTERPRETATION:",
      if (N > 5000) {
        "  Omitted: Shapiroâ€“Wilk is defined only up to N = 5000. For large N, prefer visual tools (QQ plot) and JB."
      } else if (is.null(sw)) {
        "  Inconclusive: Shapiroâ€“Wilk did not run."
      } else if (!is.finite(sw_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (sw_p < alpha) {
        "  Reject H0. Residuals depart from normality. Inspect QQ plot to see whether tails or skew drive the result; the remedy\n  depends on whether the distribution is heavy-tailed, skewed, or affected by outliers/level shifts."
      } else {
        "  Fail to reject H0. Shapiroâ€“Wilk supports approximate normality."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 5: Engle ARCH LM
      "TEST 5 â€” ENGLE'S ARCH LM (TIME-VARYING VARIANCE)",
      sprintf(" Purpose: Detect ARCH effects (conditional heteroskedasticity) up to %d lags. If present, variance clusters over time,", arch_m),
      "  which violates the constant-variance assumption and can distort interval forecasts.",
      " Description: Regress squared residuals on their own lags; under H0, the LM statistic ~ Ï‡^2 with degrees of freedom equal",
      "  to the number of lags. Often used to motivate GARCH-type extensions.",
      " â€¢ H0: No ARCH effects (variance is constant over time).",
      " â€¢ Ha: ARCH effects present (variance changes with time).",
      sprintf(" â†’ CRITERIA: Reject H0 if LM > Ï‡^2_(%d,1-Î±) (equivalently p-value < Î±).", arch_m),
      " RESULT:",
      sprintf("  - LM statistic : %s", fmt_num(arch_stat, 4)),
      sprintf("  - df (lags)    : %d", arch_m),
      sprintf("  - Ï‡^2 crit     : %s", fmt_num(stats::qchisq(1 - alpha, df = arch_m), 4)),
      sprintf("  - p-value      : %s", fmt_p(arch_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(arch)) {
        "  Skipped: package 'FinTS' not installed. If volatility clustering is suspected (e.g., financial data), consider installing it."
      } else if (!is.finite(arch_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (arch_p < alpha) {
        "  Reject H0. Evidence of time-varying variance. Consider SARIMA + GARCH (or other conditional variance models) if volatility matters\n  for your application; otherwise, robust intervals or transformations can help."
      } else {
        "  Fail to reject H0. No strong evidence of ARCH effects; the constant variance assumption is reasonable."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 6: Runs test
      "TEST 6 â€” RUNS TEST (RANDOMNESS OF SIGNS)",
      " Purpose: Check whether residual signs (+/âˆ’) appear in random order. Non-random runs can indicate leftover structure",
      "  (e.g., bias, level shifts) even when autocorrelations are small.",
      " Description: Based on the number of sign runs compared with its expectation under randomness; large |Z| rejects randomness.",
      " â€¢ H0: Residual signs occur in random order (independent signs).",
      " â€¢ Ha: Residual signs are not random (patterns/clustering of signs).",
      sprintf(" â†’ CRITERIA: Reject H0 if |Z| > %s  (equivalently p-value < Î±).", fmt_num(zcrit, 3)),
      " RESULT:",
      sprintf("  - Z statistic : %s", fmt_num(run_Z, 4)),
      sprintf("  - p-value     : %s", fmt_p(run_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(run)) {
        "  Skipped: package 'tseries' not installed."
      } else if (!is.finite(run_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (run_p < alpha) {
        "  Reject H0. Residual signs are not random, hinting at systematic under- or over-prediction or structural change.\n  Inspect fitted vs. actual plots and consider adding trend/seasonal terms or handling breaks/outliers."
      } else {
        "  Fail to reject H0. Residual signs appear random, which is consistent with an unbiased model."
      },
      "--------------------------------------------------------------------------",
      
      # TEST 7: Andersonâ€“Darling
      "TEST 7 â€” ANDERSONâ€“DARLING (NORMALITY, TAIL-SENSITIVE)",
      " Purpose: Additional normality check that gives more weight to the tails than Shapiroâ€“Wilk/Jarqueâ€“Bera.",
      " Description: Often more sensitive to deviations in the extremes; useful when tail behavior matters for prediction intervals.",
      " â€¢ H0: Residuals are normally distributed.",
      " â€¢ Ha: Residuals are not normal.",
      " â†’ CRITERIA: Reject H0 if p-value < Î±.",
      " RESULT:",
      sprintf("  - A^2 statistic : %s", fmt_num(ad_A2, 4)),
      sprintf("  - p-value       : %s", fmt_p(ad_p)),
      " DECISION & INTERPRETATION:",
      if (is.null(ad)) {
        "  Skipped: package 'nortest' not installed."
      } else if (!is.finite(ad_p)) {
        "  Inconclusive: statistic or p-value unavailable."
      } else if (ad_p < alpha) {
        "  Reject H0. Tail behavior deviates from normality; extreme forecast errors may be more common than normal theory predicts."
      } else {
        "  Fail to reject H0. Normal tails are plausible by Andersonâ€“Darling."
      },
      
      "==========================================================================",
      "OVERALL CONCLUSION (HOW TO READ THESE TESTS TOGETHER)",
      if (!lb_ok || !bp_ok) {
        " Serial correlation is still present (one or both portmanteau tests rejected). Before relying on forecasts or coefficients,\n refine the SARIMA specification: check ACF/PACF of residuals, reconsider differencing (d/D), and try alternative AR/MA and\n seasonal orders until residual autocorrelation is removed."
      } else if (!arch_ok) {
        " Autocorrelation is under control, but variance likely varies over time (ARCH). For applications where interval accuracy matters,\n consider augmenting SARIMA with a volatility model (e.g., GARCH)."
      } else if (!norm_ok) {
        " Dynamics look adequate, but residuals deviate from normality. Forecast means remain useful; however, prediction intervals may\n need robust/bootstrapped methods, transformations, or heavy-tailed innovations."
      } else if (!runs_ok) {
        " No strong autocorrelation and variance looks stable, yet residual signs are not random. This can indicate bias or a structural\n feature not captured by the model. Inspect time plots/level shifts and consider adding trend/seasonal regressors or break handling."
      } else {
        " All core checks pass (no autocorrelation, no clear ARCH, normality plausible, signs random). Residual behavior is consistent with\n a well-specified SARIMA. Proceed to forecasting and keep monitoring residuals after re-estimation on new data."
      }
    )
    
    paste(out, collapse = "\n")
  }
  
  
  # --------------------------------------------- 
  # --------------------------------------------- 
  
  
  
  # ============================================================
  # --- MOD: Manual SARIMA equation renderer (FULL code) ---
  # ============================================================
  
  
  
  manual_equations <- reactive({
    req(manual_fit(), ts_train_test())
    
    fit   <- manual_fit()
    coefs <- coef(fit)
    
    # Orders
    p <- as.integer(input$p); d <- as.integer(input$d); q <- as.integer(input$q)
    P <- as.integer(input$P); D <- as.integer(input$D); Q <- as.integer(input$Q)
    
    # Seasonal period (never NA)
    s <- if (!is.na(input$s) && input$s >= 1) {
      as.integer(input$s)
    } else {
      f <- frequency(ts_train_test()$ts_train)
      if (is.na(f) || f < 1) 1L else as.integer(f)
    }
    
    ip <- if (p > 0) seq_len(p) else integer(0)
    iq <- if (q > 0) seq_len(q) else integer(0)
    iP <- if (P > 0) seq_len(P) else integer(0)
    iQ <- if (Q > 0) seq_len(Q) else integer(0)
    
    # Intercept/mean (show only if not ~0)
    intercept_name <- intersect(c("intercept", "mean"), names(coefs))
    intercept_val  <- if (length(intercept_name) > 0) unname(coefs[intercept_name[1]]) else 0
    show_intercept <- is.finite(intercept_val) && abs(intercept_val) > 1e-8
    intercept_num  <- if (show_intercept) sprintf("%.3f", intercept_val) else ""
    
    # Drift
    drift_sym <- if (isTRUE(input$manual_drift)) " + \\delta t" else ""
    drift_val <- if (isTRUE(input$manual_drift) && "drift" %in% names(coefs)) unname(coefs["drift"]) else NA_real_
    drift_num <- if (isTRUE(input$manual_drift) && is.finite(drift_val) && abs(drift_val) > 1e-8) {
      paste0(" + ", sprintf("%.3f", drift_val), "t")
    } else if (isTRUE(input$manual_drift)) {
      " + \\delta t"
    } else ""
    
    # MathJax display wrapper
    tex_display <- function(x) paste0("\\[", x, "\\]")
    
    # Cleanup for numeric line
    simplify_tex <- function(x) {
      x <- gsub("\\(1\\)", "", x)
      x <- gsub("\\s+", " ", x)
      x <- gsub("\\+\\s*\\+", "+", x)
      x <- gsub("\\+\\s*-", "-", x)
      x <- gsub("-\\s*\\+", "-", x)
      x <- gsub("-\\s*-", "+", x)
      x <- gsub("\\s*\\+\\s*0\\.000\\b", "", x)
      trimws(x)
    }
    
    # Parameter-polynomial strings (symbolic)
    poly_param_ar  <- function() if (p == 0) "1" else paste0("1", paste0(" - \\phi_{", ip, "}L^{", ip, "}", collapse = ""))
    poly_param_sar <- function() if (P == 0) "1" else paste0("1", paste0(" - \\Phi_{", iP, "}L^{", s * iP, "}", collapse = ""))
    poly_param_ma  <- function() if (q == 0) "1" else paste0("1", paste0(" + \\theta_{", iq, "}L^{", iq, "}", collapse = ""))
    poly_param_sma <- function() if (Q == 0) "1" else paste0("1", paste0(" + \\Theta_{", iQ, "}L^{", s * iQ, "}", collapse = ""))
    
    # Numeric-polynomial strings (from estimates)
    poly_num_ar <- function() {
      if (p == 0) return("1")
      nms <- paste0("ar", ip)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], ip[keep]), collapse = ""))
    }
    poly_num_sar <- function() {
      if (P == 0) return("1")
      nms <- paste0("sar", iP)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iP
      paste0("1", paste(sprintf(" %+.3fL^{%d}", -v[keep], lags[keep]), collapse = ""))
    }
    poly_num_ma <- function() {
      if (q == 0) return("1")
      nms <- paste0("ma", iq)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], iq[keep]), collapse = ""))
    }
    poly_num_sma <- function() {
      if (Q == 0) return("1")
      nms <- paste0("sma", iQ)
      v <- suppressWarnings(unname(coefs[nms]))
      keep <- is.finite(v)
      if (!any(keep)) return("1")
      lags <- s * iQ
      paste0("1", paste(sprintf(" %+.3fL^{%d}", v[keep], lags[keep]), collapse = ""))
    }
    
    # Differencing operators
    diff_part  <- if (d > 0) paste0("(1-L)^{", d, "}") else ""
    sdiff_part <- if (D > 0) paste0("(1-L^{", s, "})^{", D, "}") else ""
    
    # Line 1: General operator form
    line1 <- paste0(
      "\\phi_p(L)\\,\\Phi_P(L^{S})\\,(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + \\theta_q(L)\\,\\Theta_Q(L^{S})\\varepsilon_t", drift_sym
    )
    
    # Line 2: Expanded operator (summation)
    line2 <- paste0(
      "\\left(1-\\sum_{i=1}^{p}\\phi_i L^{i}\\right)",
      "\\left(1-\\sum_{j=1}^{P}\\Phi_j L^{jS}\\right)",
      "(1-L)^{d}(1-L^{S})^{D}Y_t",
      " = c + ",
      "\\left(1+\\sum_{i=1}^{q}\\theta_i L^{i}\\right)",
      "\\left(1+\\sum_{j=1}^{Q}\\Theta_j L^{jS}\\right)",
      "\\varepsilon_t", drift_sym
    )
    
    # Line 3: parameter-expanded polynomials
    line3 <- paste0(
      "(", poly_param_ar(), ")",
      "(", poly_param_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = c + ",
      "(", poly_param_ma(), ")",
      "(", poly_param_sma(), ")\\varepsilon_t",
      drift_sym
    )
    
    # Line 4: numeric-expanded polynomials
    rhs_intercept <- if (show_intercept) paste0(intercept_num, " + ") else ""
    line4 <- paste0(
      "(", poly_num_ar(), ")",
      "(", poly_num_sar(), ")",
      diff_part, sdiff_part,
      "Y_t = ",
      rhs_intercept,
      "(", poly_num_ma(), ")",
      "(", poly_num_sma(), ")\\varepsilon_t",
      drift_num
    )
    line4 <- simplify_tex(line4)
    
    # Time-domain (teaching form)
    ar_vals  <- if (p > 0) suppressWarnings(unname(coefs[paste0("ar", ip)])) else numeric(0)
    sar_vals <- if (P > 0) suppressWarnings(unname(coefs[paste0("sar", iP)])) else numeric(0)
    ma_vals  <- if (q > 0) suppressWarnings(unname(coefs[paste0("ma", iq)])) else numeric(0)
    sma_vals <- if (Q > 0) suppressWarnings(unname(coefs[paste0("sma", iQ)])) else numeric(0)
    
    keep_ar  <- is.finite(ar_vals)
    keep_sar <- is.finite(sar_vals)
    keep_ma  <- is.finite(ma_vals)
    keep_sma <- is.finite(sma_vals)
    
    td <- paste0(
      "Y_t = ",
      if (show_intercept) intercept_num else "0",
      if (p > 0 && any(keep_ar))  paste0(paste(sprintf(" %+.3fY_{t-%d}", ar_vals[keep_ar], ip[keep_ar]), collapse = "")) else "",
      if (P > 0 && any(keep_sar)) paste0(paste(sprintf(" %+.3fY_{t-%d}", sar_vals[keep_sar], (s * iP)[keep_sar]), collapse = "")) else "",
      if (q > 0 && any(keep_ma))  paste0(paste(sprintf(" %+.3f\\varepsilon_{t-%d}", ma_vals[keep_ma], iq[keep_ma]), collapse = "")) else "",
      if (Q > 0 && any(keep_sma)) paste0(paste(sprintf(" %+.3f\\varepsilon_{t-%d}", sma_vals[keep_sma], (s * iQ)[keep_sma]), collapse = "")) else "",
      " + \\varepsilon_t",
      if (d > 0 || D > 0) paste0(" \\\\ \\text{(with differencing: }(1-L)^{", d, "}(1-L^{", s, "})^{", D, "}\\text{)}") else ""
    )
    td <- simplify_tex(td)
    
    # ---------- Estimated coefficients (MathJax-friendly) ----------
    coef_lines <- c()
    
    if (show_intercept) {
      coef_lines <- c(coef_lines, paste0("\\(c\\) (intercept/mean) = ", sprintf("%.4f", intercept_val)))
    }
    if (isTRUE(input$manual_drift)) {
      if (is.finite(drift_val)) {
        coef_lines <- c(coef_lines, paste0("drift \\((\\delta)\\) = ", sprintf("%.4f", drift_val)))
      } else {
        coef_lines <- c(coef_lines, "drift \\((\\delta)\\) included (value not estimated explicitly)")
      }
    }
    
    if (p > 0) {
      for (i in ip) {
        nm <- paste0("ar", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("ar", i, ": \\(\\phi_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    if (q > 0) {
      for (i in iq) {
        nm <- paste0("ma", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("ma", i, ": \\(\\theta_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    if (P > 0) {
      for (i in iP) {
        nm <- paste0("sar", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("sar", i, ": \\(\\Phi_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    if (Q > 0) {
      for (i in iQ) {
        nm <- paste0("sma", i)
        if (nm %in% names(coefs) && is.finite(coefs[nm])) {
          coef_lines <- c(coef_lines, paste0("sma", i, ": \\(\\Theta_{", i, "}\\) = ", sprintf("%.4f", coefs[nm])))
        }
      }
    }
    
    if (length(coef_lines) == 0) coef_lines <- "No coefficients available."
    
    list(
      p = p, d = d, q = q, P = P, D = D, Q = Q, s = s,
      coef_lines   = coef_lines,
      eq_general   = tex_display(line1),
      eq_expanded  = tex_display(line2),
      eq_line3     = tex_display(line3),
      eq_line4     = tex_display(line4),
      eq_time_domain = tex_display(td)
    )
  })
  
  
  
  
  
 
  
  # ============================================================
  # --- MOD: Render the equation panel with LEFT alignment (CSS) and headings ---
  #   NOTE: Left alignment is done via an HTML wrapper div.
  # ============================================================
  
  # --- helper: scientific formatting (uppercase E), preserves NA ---
  fmt_sci <- function(x, digits = 4) {
    ifelse(is.na(x),
           NA_character_,
           toupper(formatC(x, format = "e", digits = digits)))
  }
  
  # --- helper: show scientific only when needed (tiny/huge), else fixed ---
  fmt_auto <- function(x, digits_fixed = 6, digits_sci = 4) {
    ifelse(
      is.na(x),
      NA_character_,
      ifelse(abs(x) > 0 & (abs(x) < 1e-4 | abs(x) >= 1e5),
             toupper(formatC(x, format = "e", digits = digits_sci)),
             formatC(x, format = "fg", digits = digits_fixed, flag = "#"))
    )
  }
  
  # Parameter significance table for Manual SARIMA (robust to tiny numbers)
  output$manual_param_table <- renderTable({
    req(manual_fit())
    fit <- manual_fit()
    
    # 1) Coefficients
    est <- tryCatch(stats::coef(fit), error = function(e) NULL)
    validate(need(!is.null(est) && length(est) > 0, "No estimated parameters available."))
    
    # 2) Covariance â†’ SE (robust fallbacks)
    V <- tryCatch(stats::vcov(fit), error = function(e) NULL)
    if (is.null(V)) V <- tryCatch(fit$var.coef, error = function(e) NULL)  # forecast::Arima stores var.coef
    se <- if (!is.null(V)) sqrt(diag(V)) else rep(NA_real_, length(est))
    
    # 3) Test stats and p-values (normal/Z approx)
    tst <- est / se
    pvl <- 2 * stats::pnorm(abs(tst), lower.tail = FALSE)
    
    # 4) Nice names (optional)
    s <- suppressWarnings(tryCatch(manual_equations()$s, error = function(e) NA_integer_))
    map_name <- function(nm) {
      nm <- gsub("^ar(\\d+)$", "AR{\\1}", nm, ignore.case = TRUE)
      nm <- gsub("^ma(\\d+)$", "MA{\\1}", nm, ignore.case = TRUE)
      if (isTRUE(!is.na(s))) {
        nm <- gsub("^sar\\d+$", paste0("SAR{", s, "}"), nm, ignore.case = TRUE)
        nm <- gsub("^sma\\d+$", paste0("SMA{", s, "}"), nm, ignore.case = TRUE)
      } else {
        nm <- gsub("^sar\\d+$", "SAR", nm, ignore.case = TRUE)
        nm <- gsub("^sma\\d+$", "SMA", nm, ignore.case = TRUE)
      }
      nm <- gsub("^intercept$", "Constant", nm, ignore.case = TRUE)
      nm <- gsub("^mean$",      "Constant", nm, ignore.case = TRUE)
      nm <- gsub("^drift$",     "Drift",    nm, ignore.case = TRUE)
      nm
    }
    
    df_num <- data.frame(
      Parameter        = vapply(names(est), map_name, character(1)),
      Value            = as.numeric(est),
      `Standard Error` = as.numeric(se),
      `t Statistic`    = as.numeric(tst),
      `P-Value`        = as.numeric(pvl),
      check.names = FALSE
    )
    
    # 5) Append variance (no significance test)
    sigma2 <- suppressWarnings(as.numeric(fit$sigma2))
    if (is.finite(sigma2)) {
      df_num <- rbind(
        df_num,
        data.frame(Parameter = "Variance",
                   Value = sigma2,
                   `Standard Error` = NA_real_,
                   `t Statistic` = NA_real_,
                   `P-Value` = NA_real_,
                   check.names = FALSE)
      )
    }
    
    # 6) FORMAT: keep numbers that need scientific notation in E form (e.g., 5.2E-12)
    df_out <- transform(
      df_num,
      Value            = fmt_auto(Value),
      `Standard Error` = fmt_auto(`Standard Error`),
      `t Statistic`    = fmt_auto(`t Statistic`),
      `P-Value`        = fmt_sci(`P-Value`, digits = 3)  # always scientific for p-values
    )
    
    df_out
  }, rownames = FALSE)
  
  
  
  # Goodness-of-fit table for Manual SARIMA
  output$manual_gof_table <- renderTable({
    req(manual_fit())
    
    fit <- manual_fit()
    
    # sample size and parameter count
    n <- tryCatch(length(residuals(fit)), error = function(e) NA_integer_)
    k <- tryCatch(length(coef(fit)),      error = function(e) NA_integer_)
    
    # AIC
    AIC_val <- suppressWarnings(tryCatch(stats::AIC(fit), error = function(e) NA_real_))
    
    # BIC (use generic first; if unavailable, compute from logLik)
    BIC_val <- suppressWarnings(tryCatch(stats::BIC(fit), error = function(e) NA_real_))
    if (!is.finite(BIC_val)) {
      ll <- suppressWarnings(tryCatch(as.numeric(logLik(fit)), error = function(e) NA_real_))
      if (is.finite(ll) && is.finite(k) && is.finite(n) && n > 0) {
        BIC_val <- (-2 * ll) + k * log(n)
      }
    }
    
    # AICc (use forecast::AICc if available; otherwise use formula)
    AICc_val <- suppressWarnings(tryCatch(forecast::AICc(fit), error = function(e) NA_real_))
    if (!is.finite(AICc_val) && is.finite(AIC_val) && is.finite(k) && is.finite(n) && (n - k - 1) > 0) {
      AICc_val <- AIC_val + (2 * k * (k + 1)) / (n - k - 1)
    }
    
    # Assemble table
    out <- data.frame(
      Metric = c("AIC", "AICc", "BIC"),
      Value  = c(AIC_val, AICc_val, BIC_val),
      check.names = FALSE
    )
    
    # Numeric formatting
    out$Value <- ifelse(is.na(out$Value), NA, signif(out$Value, 6))
    out
  }, rownames = FALSE)
  
  
  
  output$manual_model_equation <- renderUI({
    req(manual_equations())
    eq <- manual_equations()
    
    tagList(
      tags$div(
        style = "text-align:left;",
        
        tags$h4("Manual SARIMA model"),
        tags$p(sprintf("SARIMA(%d,%d,%d)(%d,%d,%d)[%d]", eq$p, eq$d, eq$q, eq$P, eq$D, eq$Q, eq$s)),
        
        tags$h5("Estimated coefficients"),
        tags$ul(lapply(eq$coef_lines, function(x) tags$li(HTML(x)))),
        
        ## parameter significance table
        tags$hr(),
        tags$h4("Table: Estimation Results"),
        tableOutput("manual_param_table"), 
        
        
        tags$hr(),
        tags$h4("Table: Goodness of Fit"),
        tableOutput("manual_gof_table"),
        
        tags$hr(),
        tags$h4("General SARIMA formulation"),
        HTML(eq$eq_general),
        
        tags$hr(),
        
        tags$h4("Expanded operator form"),
        HTML(eq$eq_expanded),
        
        tags$hr(),
        
        tags$h4("Numerical model"),
        HTML(eq$eq_line3),
        tags$hr(),
        HTML(eq$eq_line4),
        
        tags$hr(),
        
  
      ),
      
      # keep MathJax refresh
      tags$script(HTML("if (window.MathJax && MathJax.Hub) MathJax.Hub.Queue(['Typeset', MathJax.Hub]);"))
    )
  })
  
  
  
  
  
  # --- MOD: helper used above inside renderUI (place near other helpers or above output block) ---
  tex_display <- function(x) paste0("\\[", x, "\\]")
  
  
  

  # --------------------------------------------- 
  # --------------------------------------------- 
  
  output$manual_forecast_plot <- renderPlot({
    req(manual_fc(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    fc <- manual_fc()$fc

    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")

    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    gg_forecast_plot(obs_df, s$train_n, fc_df, title = "Manual SARIMA forecast (train/test + intervals)")
  })
  
  
  # --- "Conclusion" copies (same content, different output IDs) ---
  output$manual_forecast_plot_concl <- renderPlot({
    req(manual_fc(), ts_train_test(), prepared())
    s <- ts_train_test()
    p <- prepared()
    fc <- manual_fc()$fc
    
    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")
    
    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    gg_forecast_plot(obs_df, s$train_n, fc_df,
                     title = "Manual SARIMA forecast (train/test + intervals)")
  })
  
  
  # output$manual_forecast_table_concl <- renderTable({
  #   req(manual_fc())
  #   head(forecast_table(manual_fc()$fc), 25)
  # }, rownames = FALSE)
  
  
  # output$manual_forecast_table_concl <- renderTable({
  #   req(manual_fc())
  # 
  #   ft <- forecast_table(manual_fc()$fc)
  # 
  #   # Make sure we have an "h" column (optional, but nice)
  #   if (!"h" %in% names(ft)) ft <- cbind(h = seq_len(nrow(ft)), ft)
  # 
  #   # Show all horizons up to auto_h
  #   h_show <- if (!is.null(input$auto_h) && is.finite(input$auto_h)) input$auto_h else nrow(ft)
  #   ft <- ft[seq_len(min(nrow(ft), h_show)), , drop = FALSE]
  # 
  #   ft
  # }, rownames = FALSE)
  
  # output$manual_forecast_table_concl <- renderTable({
  #   req(manual_fc(), ts_train_test(), prepared())
  #   
  #   s <- ts_train_test()
  #   p <- prepared()
  #   fc <- manual_fc()$fc
  #   
  #   obs_df <- s$dfm[, c("x", "y_trans")]
  #   names(obs_df) <- c("x", "y")
  #   
  #   ft <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
  #   
  #   ft <- ft[, c("x", setdiff(names(ft), "x")), drop = FALSE]
  #   names(ft)[1] <- if (!is.null(p$by)) "date" else "index"
  #   if (inherits(ft[[1]], "Date")) ft[[1]] <- format(ft[[1]], "%d-%m-%Y")
  #   
  #   ft
  # }, rownames = FALSE)
  
  
  output$manual_forecast_table_concl <- renderTable({
    req(manual_fc(), ts_train_test(), prepared())
    
    s  <- ts_train_test()
    p  <- prepared()
    fc <- manual_fc()$fc
    
    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")
    
    ft <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    
    # Rename x -> date/index
    ft <- ft[, c("x", setdiff(names(ft), "x")), drop = FALSE]
    names(ft)[1] <- if (!is.null(p$by)) "date" else "index"
    if (inherits(ft[[1]], "Date")) ft[[1]] <- format(ft[[1]], "%d-%m-%Y")
    
    # Reorder: step first, then date/index
    second <- if ("date" %in% names(ft)) "date" else if ("index" %in% names(ft)) "index" else NULL
    if (!is.null(second) && "step" %in% names(ft)) {
      ft <- ft[, c("step", second, setdiff(names(ft), c("step", second))), drop = FALSE]
    }
    
    ft
  }, rownames = FALSE)
  
  
  
  # output$manual_forecast_table_concl <- DT::renderDataTable({
  #   req(manual_fc())
  #   ft <- forecast_table(manual_fc()$fc)
  #   if (!"h" %in% names(ft)) ft <- cbind(h = seq_len(nrow(ft)), ft)
  #   
  #   h_show <- if (!is.null(input$auto_h) && is.finite(input$auto_h)) input$auto_h else nrow(ft)
  #   ft <- ft[seq_len(min(nrow(ft), h_show)), , drop = FALSE]
  #   
  #   DT::datatable(ft,
  #                 options = list(pageLength = min(nrow(ft), h_show), paging = FALSE, scrollY = 400),
  #                 rownames = FALSE
  #   )
  # })
  
  
  
  
  output$manual_accuracy_table_concl <- renderTable({
    req(manual_fc(), ts_train_test())
    s <- ts_train_test()
    if (s$test_n == 0) {
      return(data.frame(message = "No test set (training = 100%). Reduce training to compute accuracy."))
    }
    accuracy_df(s$ts_test, manual_fc()$fc$mean)
  }, rownames = FALSE)
  
  
  
  # ---- Manual SARIMA: Original-scale plot (observed + forecast + CIs) ----
  output$manual_forecast_plot_original <- renderPlot({
    req(manual_fc(), ts_train_test(), prepared())
    
    s <- ts_train_test()
    p <- prepared()
    fc <- manual_fc()$fc
    
    # observed series on ORIGINAL scale
    validate(need("y_filled" %in% names(s$dfm), "Column y_filled not found in ts_train_test()$dfm."))
    obs_df <- s$dfm[, c("x", "y_filled")]
    names(obs_df) <- c("x", "y")
    
    # build forecast df (x alignment) from existing helper, then back-transform values
    fc_df <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
    
    # inverse transform helper (must match your global transform choice)
    inv <- function(z) {
      tr <- input$transform %||% "none"
      z <- as.numeric(z)
      
      if (tr == "none") return(z)
      
      if (tr == "log") {
        return(exp(z))
      }
      
      if (tr == "boxcox") {
        y0 <- prepared()$df$y_filled
        validate(need(all(y0 > 0, na.rm = TRUE), "Box-Cox inverse requires strictly positive original values."))
        
        lam <- input$lambda
        if (is.null(lam) || (length(lam) == 1 && is.na(lam))) {
          lam <- forecast::BoxCox.lambda(y0, method = "guerrero")
        } else {
          lam <- as.numeric(lam)
        }
        return(forecast::InvBoxCox(z, lam))
      }
      
      z
    }
    
    # back-transform forecast mean + intervals
    fc_df$mean <- inv(fc_df$mean)
    if ("lo80" %in% names(fc_df)) fc_df$lo80 <- inv(fc_df$lo80)
    if ("hi80" %in% names(fc_df)) fc_df$hi80 <- inv(fc_df$hi80)
    if ("lo95" %in% names(fc_df)) fc_df$lo95 <- inv(fc_df$lo95)
    if ("hi95" %in% names(fc_df)) fc_df$hi95 <- inv(fc_df$hi95)
    
    gg_forecast_plot(
      obs_df, s$train_n, fc_df,
      title = "Manual SARIMA forecast (original scale)"
    )
  })
  
  

  # output$manual_forecast_table <- renderTable({ req(manual_fc()); head(forecast_table(manual_fc()$fc), 25) }, rownames = FALSE)

  # output$manual_forecast_table <- renderTable({
  #   req(manual_fc())
  #   ft <- forecast_table(manual_fc()$fc)
  #   
  #   # add h column if forecast_table() doesn't include it
  #   if (!"h" %in% names(ft)) ft <- cbind(h = seq_len(nrow(ft)), ft)
  #   
  #   ft
  # }, rownames = FALSE)
  
  
  # output$manual_forecast_table <- renderTable({
  #   req(manual_fc(), ts_train_test(), prepared())
  #   
  #   s <- ts_train_test()
  #   p <- prepared()
  #   fc <- manual_fc()$fc
  #   
  #   # observed series (x is Date when your input has valid dates)
  #   obs_df <- s$dfm[, c("x", "y_trans")]
  #   names(obs_df) <- c("x", "y")
  #   
  #   # forecast table + aligned/extended x (dates)
  #   ft <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)
  #   
  #   # Put x first and rename it nicely
  #   ft <- ft[, c("x", setdiff(names(ft), "x")), drop = FALSE]
  #   names(ft)[1] <- if (!is.null(p$by)) "date" else "index"
  #   
  #   # Optional: format the date column (keeps continuation, just prettier)
  #   if (inherits(ft[[1]], "Date")) ft[[1]] <- format(ft[[1]], "%d-%m-%Y")
  #   
  #   ft
  # }, rownames = FALSE)
  
  
  output$manual_forecast_table <- renderTable({
    req(manual_fc(), ts_train_test(), prepared())
    
    s  <- ts_train_test()
    p  <- prepared()
    fc <- manual_fc()$fc
    
    # Use the same x (date) logic as your forecast plot
    obs_df <- s$dfm[, c("x", "y_trans")]
    names(obs_df) <- c("x", "y")
    
    ft <- plot_forecast_df(obs_df, s$train_n, fc, by = p$by)  # adds ft$x (dates/index)
    
    # Rename x to date (or index) and reorder: step first, date second
    if (inherits(ft$x, "Date")) {
      ft$date <- ft$x
      ft$date <- format(ft$date, "%d-%m-%Y")  # optional formatting
      second <- "date"
    } else {
      ft$index <- ft$x
      second <- "index"
    }
    ft$x <- NULL
    
    ft <- ft[, c("step", second, setdiff(names(ft), c("step", second))), drop = FALSE]
    
    ft
  }, rownames = FALSE)
  
  
  
  output$manual_accuracy_table <- renderTable({
    req(manual_fc(), ts_train_test())
    s <- ts_train_test()
    if (s$test_n == 0) return(data.frame(message = "No test set (training = 100%). Reduce training to compute accuracy."))
    accuracy_df(s$ts_test, manual_fc()$fc$mean)
  }, rownames = FALSE)

  output$apa_manual_paragraph <- renderPrint({
    req(manual_fit(), manual_fc(), ts_train_test())
    fit <- manual_fit()
    s <- ts_train_test()
    fc <- manual_fc()$fc
    lag <- as.numeric(input$diag_lag)
    lb <- tryCatch(Box.test(residuals(fit), lag = lag, type = "Ljung-Box", fitdf = length(coef(fit))), error = function(e) NULL)
    acc_line <- ""
    if (s$test_n > 0) {
      acc <- accuracy_df(s$ts_test, fc$mean)
      rmse <- acc$Value[acc$Metric == "RMSE"]
      mae <- acc$Value[acc$Metric == "MAE"]
      acc_line <- paste0("Forecast accuracy on the holdout set was RMSE = ", fmt_num(rmse, 2), " and MAE = ", fmt_num(mae, 2), ". ")
    }
    lb_line <- if (!is.null(lb)) paste0("The Ljungâ€“Box test suggested ", ifelse(lb$p.value > 0.05, "no strong residual autocorrelation", "residual autocorrelation"), " (", fmt_p(lb$p.value), "). ") else ""
    cat(
      "APA-ready paragraph:\n\n",
      "A manual seasonal ARIMA model was specified as (", input$p, ",", input$d, ",", input$q, ")(",
      input$P, ",", input$D, ",", input$Q, ")[", ifelse(is.na(input$s), frequency(s$ts_train), input$s), "]. ",
      lb_line, acc_line,
      "Forecasts were produced with prediction intervals to quantify uncertainty.\n",
      sep = ""
    )
  })
  
  
  
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  
  
  # ---- Manual SARIMA: academic conclusion (cached on Fit click) ----
  
  # =========================
  # Manual SARIMA: FULL academic conclusion object (robust + detailed)
  # =========================
  
 
  
  # ============================================================
  # CORRECTED STRUCTURE
  #   1) Define ALL report outputs ONCE (outside eventReactive)
  #   2) manual_conclusion_full_obj ONLY computes + returns tagList UI
  # ============================================================
  
  
  # ------------------------------------------------------------
  # (A) REPORT OUTPUTS (define ONCE, outside manual_conclusion_full_obj)
  # ------------------------------------------------------------
  
  # ---- A) Time series plot (dates + dashed split) ----
  output$manual_report_ts_plot <- renderPlot({
    req(manual_conclusion_full_obj())     # ensures this is shown after Fit Manual
    req(ts_train_test(), prepared())
    
    s <- ts_train_test()
    p <- prepared()
    
    df <- s$dfm
    validate(need(nrow(df) >= 3, "Not enough observations to plot the time series."))
    
    df$set <- ifelse(seq_len(nrow(df)) <= s$train_n, "Train", "Test/Future")
    
    has_test <- isTRUE(s$test_n > 0)
    x_split  <- if (has_test) df$x[s$train_n] else NA
    
    g <- ggplot(df, aes(x = x, y = y_trans, color = set)) +
      geom_line(linewidth = 0.9) +
      theme_minimal() +
      labs(
        title = "Observed time series (transformed)",
        x = p$x_label,
        y = "Value",
        color = NULL
      ) +
      theme(legend.position = "bottom")
    
    if (has_test && !is.na(x_split)) {
      g <- g + geom_vline(
        xintercept = as.numeric(x_split),
        linetype = "dashed",
        linewidth = 0.7,
        color = "gray40"
      )
    }
    
    if (inherits(df$x, "Date")) {
      g <- g + scale_x_date(labels = scales::date_format("%m-%Y"),
                            breaks = scales::pretty_breaks(n = 8))
    } else if (inherits(df$x, "POSIXt")) {
      g <- g + scale_x_datetime(labels = scales::date_format("%m-%Y"),
                                breaks = scales::pretty_breaks(n = 8))
    }
    
    g
  })
  
  
  # ---- NEW: Stationarity tests (ADF + PP + KPSS) + conclusion paragraph ----
  output$manual_report_stationarity <- renderUI({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    validate(need(requireNamespace("tseries", quietly = TRUE),
                  "Package 'tseries' is required for stationarity tests (ADF/PP/KPSS)."))
    
    s_obj <- ts_train_test()
    
    # Use training series for stationarity assessment
    x <- as.numeric(s_obj$ts_train)
    x <- x[is.finite(x)]
    validate(need(length(x) >= 10, "Not enough training observations to run stationarity tests (need \u2265 10)."))
    
    fmt_num <- function(z, d = 3) {
      z <- suppressWarnings(as.numeric(z))
      if (length(z) == 0 || !is.finite(z[1])) return("NA")
      formatC(z[1], format = "f", digits = d)
    }
    fmt_p <- function(p) {
      p <- suppressWarnings(as.numeric(p))
      if (length(p) == 0 || !is.finite(p[1])) return("NA")
      if (p[1] < .001) "p < .001" else paste0("p = ", sub("^0\\.", ".", sprintf("%.3f", p[1])))
    }
    
    # safe lag choice for ADF
    k_adf <- max(0, min(12, floor((length(x) - 1)^(1/3))))
    
    adf <- tryCatch(tseries::adf.test(x, k = k_adf), error = function(e) NULL)
    pp  <- tryCatch(tseries::pp.test(x, lshort = TRUE), error = function(e) NULL)
    kpss_level <- tryCatch(tseries::kpss.test(x, null = "Level", lshort = TRUE), error = function(e) NULL)
    kpss_trend <- tryCatch(tseries::kpss.test(x, null = "Trend", lshort = TRUE), error = function(e) NULL)
    
    rows <- list()
    add_row <- function(test, null_h, stat, pval, decision) {
      rows[[length(rows) + 1L]] <<- data.frame(
        Test = test,
        `H0 (null)` = null_h,
        Statistic = stat,
        `p-value` = pval,
        Decision = decision,
        check.names = FALSE
      )
    }
    
    # ADF: H0 = unit root (non-stationary); reject => stationarity evidence
    if (!is.null(adf)) {
      p <- adf$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 -> evidence for stationarity"
      else "Fail to reject H0 -> unit root plausible"
      add_row("ADF (Augmented Dickey-Fuller)", "Unit root (non-stationary)",
              fmt_num(unname(adf$statistic)), fmt_p(p), dec)
    } else {
      add_row("ADF (Augmented Dickey-Fuller)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # PP: H0 = unit root (non-stationary); reject => stationarity evidence
    if (!is.null(pp)) {
      p <- pp$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 -> evidence for stationarity"
      else "Fail to reject H0 -> unit root plausible"
      add_row("PP (Phillips-Perron)", "Unit root (non-stationary)",
              fmt_num(unname(pp$statistic)), fmt_p(p), dec)
    } else {
      add_row("PP (Phillips-Perron)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # KPSS(Level): H0 = level-stationary; reject => non-stationarity evidence
    if (!is.null(kpss_level)) {
      p <- kpss_level$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 -> evidence against stationarity"
      else "Fail to reject H0 -> stationarity plausible"
      add_row("KPSS (Level)", "Level-stationary",
              fmt_num(unname(kpss_level$statistic)), fmt_p(p), dec)
    } else {
      add_row("KPSS (Level)", "Level-stationary", "NA", "NA", "Not available")
    }
    
    # KPSS(Trend): H0 = trend-stationary
    if (!is.null(kpss_trend)) {
      p <- kpss_trend$p.value
      dec <- if (is.finite(p) && p < 0.05) "Reject H0 -> evidence against trend-stationarity"
      else "Fail to reject H0 -> trend-stationarity plausible"
      add_row("KPSS (Trend)", "Trend-stationary",
              fmt_num(unname(kpss_trend$statistic)), fmt_p(p), dec)
    } else {
      add_row("KPSS (Trend)", "Trend-stationary", "NA", "NA", "Not available")
    }
    
    st_df <- do.call(rbind, rows)
    
    # synthesis
    adf_p <- if (!is.null(adf)) adf$p.value else NA_real_
    pp_p  <- if (!is.null(pp))  pp$p.value  else NA_real_
    kL_p  <- if (!is.null(kpss_level)) kpss_level$p.value else NA_real_
    
    unit_root_rejected <- any(c(adf_p, pp_p) < 0.05, na.rm = TRUE)
    kpss_ok <- is.finite(kL_p) && kL_p >= 0.05
    
   
    
    conclusion <- if (unit_root_rejected && kpss_ok) {
      paste0(
        "<b>Conclusion (joint evidence at Î± = .05): Stationarity supported.</b><br><br>",
        
        "<b>What the tests indicate:</b>",
        "<ul style='margin-top:6px; margin-bottom:6px; padding-left:18px; list-style-type:square;'>",
        "<li>At least one unit-root test (ADF and/or PP) rejects the unit-root null (p &lt; .05), arguing against stochastic trend persistence.</li>",
        "<li>KPSS(Level) does not reject its null of level stationarity (p â‰¥ .05), providing corroboration from a test with the opposite null.</li>",
        "</ul>",
        
        "<b>Interpretation:</b> Taken together, this concordant pattern is consistent with a stationary series on the current scale, ",
        "so further differencing is not suggested by these diagnostics.<br><br>",
        
        "<b>Implication for SARIMA workflow:</b> Proceed to AR/MA and seasonal AR/MA order identification, and confirm adequacy using residual whiteness (e.g., Ljungâ€“Box) and holdout forecast performance.<br><br>",
        
        "<b>ACTIONABLE NEXT STEPS (What to do now):</b>",
        "<ol style='margin-top:6px; margin-bottom:0; padding-left:18px;'>",
        "<li>Keep differencing as-is (do not increase d or D based on these tests).</li>",
        "<li>Use ACF/PACF of the working series to propose candidate (p, q) and, when seasonality is present, (P, Q) at seasonal multiples.</li>",
        "<li>Fit candidate SARIMA models and verify residual adequacy: residual ACF should show no systematic spikes, and Ljungâ€“Box p-values should remain mostly above Î± across a reasonable lag range.</li>",
        "<li>Select the simplest model that yields approximately white-noise residuals and stable holdout forecast accuracy.</li>",
        "</ol>"
      )
      
    } else if (!unit_root_rejected && !kpss_ok) {
      paste0(
        "<b>Conclusion (joint evidence at Î± = .05): Non-stationarity supported.</b><br><br>",
        
        "<b>What the tests indicate:</b>",
        "<ul style='margin-top:6px; margin-bottom:6px; padding-left:18px; list-style-type:square;'>",
        "<li>ADF/PP do not reject the unit-root null (p â‰¥ .05), so stochastic non-stationarity remains plausible.</li>",
        "<li>KPSS(Level) rejects level stationarity (p &lt; .05), independently supporting instability in the level (mean).</li>",
        "</ul>",
        
        "<b>Interpretation:</b> This agreement across tests with opposing null hypotheses provides strong evidence that the working series is not yet stationary.<br><br>",
        
        "<b>Implication for SARIMA workflow:</b> Apply additional differencing (typically start with non-seasonal d = 1; consider seasonal D = 1 if persistence is concentrated at seasonal multiples), then reassess stationarity and continue identification on the differenced series.<br><br>",
        
        "<b>ACTIONABLE NEXT STEPS (What to do now):</b>",
        "<ol style='margin-top:6px; margin-bottom:0; padding-left:18px;'>",
        "<li>Increase differencing in a controlled way: first test non-seasonal differencing (d = 1) if not already applied.</li>",
        "<li>If seasonality is present and persistence appears at seasonal multiples, also test seasonal differencing (D = 1).</li>",
        "<li>After each differencing change, re-check: (i) time plot for stable level, (ii) ACF/PACF for faster decay (short-memory), and (iii) the same stationarity tests.</li>",
        "<li>Once the working series appears stationary, proceed to AR/MA and seasonal AR/MA order identification, then validate residual whiteness and holdout forecasting.</li>",
        "</ol>"
      )
      
    } else if (unit_root_rejected && !kpss_ok) {
      paste0(
        "<b>Conclusion (joint evidence at Î± = .05): Mixed evidence (interpret with caution).</b><br><br>",
        
        "<b>What the tests indicate:</b>",
        "<ul style='margin-top:6px; margin-bottom:6px; padding-left:18px; list-style-type:square;'>",
        "<li>ADF/PP reject the unit-root null (p &lt; .05), suggesting stationarity from the unit-root perspective.</li>",
        "<li>KPSS(Level) rejects level stationarity (p &lt; .05), indicating evidence against a stable mean from the opposite-null perspective.</li>",
        "</ul>",
        
        "<b>Interpretation:</b> Conflicts like this can occur under structural breaks, strong seasonality, near-unit-root dynamics, or finite-sample sensitivity.<br><br>",
        
        "<b>Implication for SARIMA workflow:</b> Do not rely on tests alone. Triangulate with time plots and ACF/PACF decay, and compare nearby differencing choices. Prefer the simplest specification that yields approximately white-noise residuals and stable out-of-sample forecasting.<br><br>",
        
        "<b>ACTIONABLE NEXT STEPS (What to do now):</b>",
        "<ol style='margin-top:6px; margin-bottom:0; padding-left:18px;'>",
        "<li>Inspect the time-series plot for level shifts/breaks and verify that the seasonal period and seasonal structure are correctly specified.</li>",
        "<li>Run a small sensitivity check around differencing (e.g., current d versus d+1; and, if seasonal persistence exists, current D versus D+1), watching for over-differencing symptoms (strong negative lag-1 autocorrelation, inflated variance).</li>",
        "<li>Fit a small set of competing SARIMA models and judge them using residual diagnostics (ACF + Ljungâ€“Box across lags) and holdout forecast accuracy.</li>",
        "<li>Retain the most parsimonious model that produces approximately white-noise residuals and stable predictive performance.</li>",
        "</ol>"
      )
      
    } else {
      paste0(
        "<b>Conclusion (joint evidence at Î± = .05): Inconclusive evidence.</b><br><br>",
        
        "<b>What the tests indicate:</b>",
        "<ul style='margin-top:6px; margin-bottom:6px; padding-left:18px; list-style-type:square;'>",
        "<li>ADF/PP do not reject a unit root (p â‰¥ .05), so non-stationarity cannot be ruled out.</li>",
        "<li>KPSS(Level) also does not reject stationarity (p â‰¥ .05), so stationarity remains plausible.</li>",
        "</ul>",
        
        "<b>Interpretation:</b> This pattern is common in finite samples or when the process is close to the unit-root boundary, where test power is limited.<br><br>",
        
        "<b>Implication for SARIMA workflow:</b> Complement these tests with differencing diagnostics and ACF/PACF behavior, and compare nearby settings (e.g., d = 0 vs d = 1, and D = 0 vs D = 1 when seasonality is present). Select the simplest configuration that yields stable plots, improved residual whiteness, and satisfactory holdout forecast accuracy.<br><br>",
        
        "<b>ACTIONABLE NEXT STEPS (What to do now):</b>",
        "<ol style='margin-top:6px; margin-bottom:0; padding-left:18px;'>",
        "<li>Compare nearby differencing choices (d = 0 vs d = 1; and D = 0 vs D = 1 if seasonality is present) rather than making large jumps.</li>",
        "<li>Use ACF/PACF decay and diagnostic plots to decide which option yields a clearer short-memory pattern.</li>",
        "<li>Fit candidate models under each differencing choice and choose the simplest one with acceptable residual whiteness (ACF + Ljungâ€“Box) and best holdout forecast performance.</li>",
        "<li>If ambiguity persists, consider whether structural breaks or changing variance could be driving inconsistent test behavior.</li>",
        "</ol>"
      )
    }
    
    
    
    
    
    # ---- Detailed academic paragraph (uses actual results) ----
    n_train <- length(x)
    
    adf_line <- if (!is.null(adf)) {
      paste0("ADF (k = ", k_adf, "): statistic = ", fmt_num(unname(adf$statistic)),
             ", ", fmt_p(adf$p.value), ". ")
    } else "ADF was not available. "
    
    pp_line <- if (!is.null(pp)) {
      paste0("PP: statistic = ", fmt_num(unname(pp$statistic)),
             ", ", fmt_p(pp$p.value), ". ")
    } else "PP was not available. "
    
    kpssL_line <- if (!is.null(kpss_level)) {
      paste0("KPSS(Level): statistic = ", fmt_num(unname(kpss_level$statistic)),
             ", ", fmt_p(kpss_level$p.value), ". ")
    } else "KPSS(Level) was not available. "
    
    kpssT_line <- if (!is.null(kpss_trend)) {
      paste0("KPSS(Trend): statistic = ", fmt_num(unname(kpss_trend$statistic)),
             ", ", fmt_p(kpss_trend$p.value), ". ")
    } else "KPSS(Trend) was not available. "
    
  
    
    academic_paragraph <- paste0(
      "Stationarity was assessed on the training portion (n = ", n_train, 
      ") because SARIMA identification and inference assume that, after any transformation and differencing, the series has a stable mean and autocovariance structure.",
      "<br>",
      
      "We applied two unit-root tests (ADF and Phillips-Perron), where H0 is a unit root (non-stationarity), and two KPSS tests, where H0 is stationarity (level- or trend-stationary).",
      "<br>",
      
      "<ul style='margin-top:0; margin-bottom:0; padding-left:18px; list-style-type:square;'>",
      "<li>", adf_line, "</li>",
      "<li>", pp_line, "</li>",
      "<li>", kpssL_line, "</li>",
      "<li>", kpssT_line, "</li>",
      "</ul>",
      "<br>",
      
      "Interpreting these jointly is important for teaching: when ADF/PP reject H0 while KPSS(Level) fails to reject, the evidence supports stationarity and suggests using minimal differencing (d = 0, and D = 0 unless seasonal non-stationarity is present).",
      "<br>",
      
      "When ADF/PP fail to reject and KPSS(Level) rejects, the evidence supports non-stationarity and motivates differencing (typically start with d = 1, and consider D = 1 if seasonal persistence at lag s is strong).",
      "<br>",
      
      "Mixed outcomes can arise from structural breaks, near-unit-root behavior, or limited power, so students should triangulate with time plots, ACF/PACF decay patterns, and ultimately residual whiteness after fitting."
    )
    
    
    
    # table renderer (HTML)
    html_tbl <- tags$table(
      class = "table table-striped table-condensed",
      tags$thead(tags$tr(lapply(names(st_df), tags$th))),
      tags$tbody(lapply(seq_len(nrow(st_df)), function(i) {
        tags$tr(lapply(st_df[i, , drop = FALSE], function(cell) {
          tags$td(HTML(as.character(cell)))
        }))
      }))
    )
    
    tagList(
      html_tbl,
      
      # tags$div(class = "callout callout-blue",
      #          tags$h5("Explicit stationarity conclusion (ADF / PP / KPSS by result)"),
      #          tags$p(HTML(stationarity_explicit_conclusion))),
      
      
      callout(
        academic_paragraph,
        title = "Academic interpretation.",
        theme = "blue",
        body_is_html = TRUE
      ),
      
      # tags$p(tags$b("Academic interpretation. "), HTML(academic_paragraph)),
      
      tags$br(),
      
      callout(
        conclusion,
        title = "Conclusion. ",
        theme = "orange",
        body_is_html = TRUE
      ),
      
      # tags$p(tags$b("Conclusion. "), conclusion)
    )
  })
  
  
  
  
  # ---- helper used by multiple outputs (define ONCE) ----
  apply_sarima_diffs_report <- function(y, d = 0L, D = 0L, s = 1L) {
    y <- as.numeric(y)
    y <- y[is.finite(y)]
    if (length(y) < 3) return(y)
    
    d <- as.integer(d); if (!is.finite(d) || d < 0) d <- 0L
    D <- as.integer(D); if (!is.finite(D) || D < 0) D <- 0L
    s <- as.integer(s); if (!is.finite(s) || s < 1) s <- 1L
    
    yy <- y
    
    if (D > 0 && s > 1) {
      for (i in seq_len(D)) {
        if (length(yy) <= s + 1) break
        yy <- diff(yy, lag = s)
      }
    }
    if (d > 0) {
      for (i in seq_len(d)) {
        if (length(yy) <= 2) break
        yy <- diff(yy, lag = 1)
      }
    }
    yy
  }
  
  
  # ---- B) Transformed training series vs differenced (d,D,s) ----
  output$manual_report_ts_trans_and_diff <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    df <- s_obj$dfm
    validate(need(nrow(df) >= 5, "Not enough observations to plot."))
    
    train_n <- s_obj$train_n
    has_test <- isTRUE(s_obj$test_n > 0)
    df_train <- if (has_test) df[seq_len(train_n), , drop = FALSE] else df
    
    validate(need(nrow(df_train) >= 5, "Not enough training observations to plot."))
    
    x_train <- df_train$x
    y_train <- df_train$y_trans
    
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y_train, d = input$d, D = input$D, s = s_use)
    validate(need(length(y_mod) >= 3, "Differencing left too few observations to plot."))
    
    x_mod <- tail(x_train, length(y_mod))
    
    plot_df <- rbind(
      data.frame(x = x_train, y = y_train, series = "Transformed (train)"),
      data.frame(x = x_mod,   y = y_mod,   series = paste0("Differenced (d=", input$d, ", D=", input$D, ", s=", s_use, ")"))
    )
    
    g <- ggplot(plot_df, aes(x = x, y = y, color = series)) +
      geom_line(linewidth = 0.9) +
      theme_minimal() +
      labs(
        title = "Training series: transformed vs differenced",
        x = p$x_label,
        y = "Value",
        color = NULL
      ) +
      theme(legend.position = "bottom")
    
    if (inherits(plot_df$x, "Date")) {
      g <- g + scale_x_date(labels = scales::date_format("%m-%Y"),
                            breaks = scales::pretty_breaks(n = 8))
    } else if (inherits(plot_df$x, "POSIXt")) {
      g <- g + scale_x_datetime(labels = scales::date_format("%m-%Y"),
                                breaks = scales::pretty_breaks(n = 8))
    }
    
    g
  })
  
  
  
  # ---- C) Seasonal subseries (TRAINING ONLY) ----
  output$manual_report_subseries <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    s_obj <- ts_train_test()
    
    x_train <- s_obj$ts_train
    validate(need(inherits(x_train, "ts"), "Training series is not a 'ts' object."))
    validate(need(stats::frequency(x_train) >= 2, "Seasonal subseries plot requires seasonal frequency (s) >= 2."))
    validate(need(length(x_train) >= 2 * stats::frequency(x_train),
                  "Need at least 2 seasonal cycles in the TRAINING set for a subseries plot."))
    
    forecast::ggsubseriesplot(x_train) +
      theme_minimal() +
      labs(title = "Seasonal subseries (training series)", x = "Seasonal period", y = "Value")
  })
  
  
  # ---- D) Seasonal box-plot (TRAINING ONLY) ----
  output$manual_report_seasonal_box <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    s_obj <- ts_train_test()
    
    x_train <- s_obj$ts_train
    validate(need(inherits(x_train, "ts"), "Training series is not a 'ts' object."))
    validate(need(stats::frequency(x_train) >= 2, "Seasonal box-plot requires seasonal frequency (s) >= 2."))
    validate(need(length(x_train) >= stats::frequency(x_train),
                  "Need at least 1 seasonal cycle in the TRAINING set for a box-plot."))
    
    df <- data.frame(
      value  = as.numeric(x_train),
      season = factor(stats::cycle(x_train), ordered = TRUE)
    )
    df <- df[is.finite(df$value), , drop = FALSE]
    validate(need(nrow(df) >= 5, "Not enough valid training observations for seasonal box-plot."))
    
    ggplot(df, aes(x = season, y = value)) +
      geom_boxplot(fill = "#2C7FB8", alpha = 0.45, outlier.alpha = 0.4) +
      theme_minimal() +
      labs(title = "Seasonal box-plot (training series)", x = "Seasonal period", y = "Value")
  })
  
  
  # ---- E) ACF / PACF of training series ----
  output$manual_report_acf <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    x <- ts_train_test()$ts_train
    validate(need(length(x) >= 5, "Not enough training observations for ACF."))
    
    forecast::ggAcf(x, lag.max = min(60, length(x) - 1)) +
      theme_minimal() +
      labs(title = "ACF (training)")
  })
  
  output$manual_report_pacf <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test())
    
    x <- ts_train_test()$ts_train
    validate(need(length(x) >= 5, "Not enough training observations for PACF."))
    
    forecast::ggPacf(x, lag.max = min(60, length(x) - 1)) +
      theme_minimal() +
      labs(title = "PACF (training)")
  })
  
  
  # ---- F) ACF / PACF of differenced series ----
  output$manual_report_acf_mod <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    y <- as.numeric(s_obj$ts_train)
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    
    validate(need(length(y_mod) >= 5, "Differencing left too few observations for ACF."))
    
    ts_mod <- ts(y_mod, frequency = p$freq)
    
    forecast::ggAcf(ts_mod, lag.max = min(60, length(ts_mod) - 1)) +
      theme_minimal() +
      labs(title = paste0("ACF (d=", input$d, ", D=", input$D, ", s=", s_use, ")"))
  })
  
  output$manual_report_pacf_mod <- renderPlot({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    y <- as.numeric(s_obj$ts_train)
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    
    validate(need(length(y_mod) >= 5, "Differencing left too few observations for PACF."))
    
    ts_mod <- ts(y_mod, frequency = p$freq)
    
    forecast::ggPacf(ts_mod, lag.max = min(60, length(ts_mod) - 1)) +
      theme_minimal() +
      labs(title = paste0("PACF (d=", input$d, ", D=", input$D, ", s=", s_use, ")"))
  })
  
  
  
  # ---- NEW: Stationarity tests on differenced/transformed series (d, D, s) ----
  
  
  
  
  
  #
  #
  #
  #
  #
  
  output$manual_report_stationarity_mod <- renderUI({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    validate(need(requireNamespace("tseries", quietly = TRUE),
                  "Package 'tseries' is required for stationarity tests (ADF/PP/KPSS)."))
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    # training series
    y <- as.numeric(s_obj$ts_train)
    y <- y[is.finite(y)]
    
    # apply differencing implied by current d, D, s
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    y_mod <- as.numeric(y_mod)
    y_mod <- y_mod[is.finite(y_mod)]
    
    validate(need(length(y_mod) >= 10,
                  "Not enough observations after differencing (d, D, s) to run stationarity tests (need â‰¥ 10)."))
    
    fmt_num <- function(z, d = 3) {
      z <- suppressWarnings(as.numeric(z))
      if (length(z) == 0 || !is.finite(z[1])) return("NA")
      formatC(z[1], format = "f", digits = d)
    }
    fmt_p <- function(pv) {
      pv <- suppressWarnings(as.numeric(pv))
      if (length(pv) == 0 || !is.finite(pv[1])) return("NA")
      if (pv[1] < .001) "p < .001" else paste0("p = ", sub("^0\\.", ".", sprintf("%.3f", pv[1])))
    }
    
    # safe lag choice for ADF (based on effective sample)
    k_adf <- max(0, min(12, floor((length(y_mod) - 1)^(1/3))))
    
    adf <- tryCatch(tseries::adf.test(y_mod, k = k_adf), error = function(e) NULL)
    pp  <- tryCatch(tseries::pp.test(y_mod, lshort = TRUE), error = function(e) NULL)
    kpss_level <- tryCatch(tseries::kpss.test(y_mod, null = "Level", lshort = TRUE), error = function(e) NULL)
    kpss_trend <- tryCatch(tseries::kpss.test(y_mod, null = "Trend", lshort = TRUE), error = function(e) NULL)
    
    rows <- list()
    add_row <- function(test, null_h, stat, pval, decision) {
      rows[[length(rows) + 1L]] <<- data.frame(
        Test = test,
        `H0 (null)` = null_h,
        Statistic = stat,
        `p-value` = pval,
        Decision = decision,
        check.names = FALSE
      )
    }
    
    # ADF
    if (!is.null(adf)) {
      pv <- adf$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence for stationarity"
      else "Fail to reject H0 â†’ unit root plausible"
      add_row("ADF (Augmented Dickeyâ€“Fuller)", "Unit root (non-stationary)",
              fmt_num(unname(adf$statistic)), fmt_p(pv), dec)
    } else {
      add_row("ADF (Augmented Dickeyâ€“Fuller)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # PP
    if (!is.null(pp)) {
      pv <- pp$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence for stationarity"
      else "Fail to reject H0 â†’ unit root plausible"
      add_row("PP (Phillipsâ€“Perron)", "Unit root (non-stationary)",
              fmt_num(unname(pp$statistic)), fmt_p(pv), dec)
    } else {
      add_row("PP (Phillipsâ€“Perron)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # KPSS Level
    if (!is.null(kpss_level)) {
      pv <- kpss_level$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence against stationarity"
      else "Fail to reject H0 â†’ stationarity plausible"
      add_row("KPSS (Level)", "Level-stationary",
              fmt_num(unname(kpss_level$statistic)), fmt_p(pv), dec)
    } else {
      add_row("KPSS (Level)", "Level-stationary", "NA", "NA", "Not available")
    }
    
    # KPSS Trend
    if (!is.null(kpss_trend)) {
      pv <- kpss_trend$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence against trend-stationarity"
      else "Fail to reject H0 â†’ trend-stationarity plausible"
      add_row("KPSS (Trend)", "Trend-stationary",
              fmt_num(unname(kpss_trend$statistic)), fmt_p(pv), dec)
    } else {
      add_row("KPSS (Trend)", "Trend-stationary", "NA", "NA", "Not available")
    }
    
    st_df <- do.call(rbind, rows)
    
    # synthesis
    adf_p <- if (!is.null(adf)) adf$p.value else NA_real_
    pp_p  <- if (!is.null(pp))  pp$p.value  else NA_real_
    kL_p  <- if (!is.null(kpss_level)) kpss_level$p.value else NA_real_
    
    unit_root_rejected <- any(c(adf_p, pp_p) < 0.05, na.rm = TRUE)
    kpss_ok <- is.finite(kL_p) && kL_p >= 0.05
    
    # ---- Detailed academic interpretation (single paragraph, uses computed results) ----
    n_before <- length(y)
    n_after  <- length(y_mod)
    
    adf_line <- if (!is.null(adf)) {
      paste0("ADF (k = ", k_adf, "): statistic = ", fmt_num(unname(adf$statistic)),
             ", ", fmt_p(adf$p.value), ". ")
    } else {
      "ADF was not available. "
    }
    
    pp_line <- if (!is.null(pp)) {
      paste0("PP: statistic = ", fmt_num(unname(pp$statistic)),
             ", ", fmt_p(pp$p.value), ". ")
    } else {
      "PP was not available. "
    }
    
    kpssL_line <- if (!is.null(kpss_level)) {
      paste0("KPSS(Level): statistic = ", fmt_num(unname(kpss_level$statistic)),
             ", ", fmt_p(kpss_level$p.value), ". ")
    } else {
      "KPSS(Level) was not available. "
    }
    
    kpssT_line <- if (!is.null(kpss_trend)) {
      paste0("KPSS(Trend): statistic = ", fmt_num(unname(kpss_trend$statistic)),
             ", ", fmt_p(kpss_trend$p.value), ". ")
    } else {
      "KPSS(Trend) was not available. "
    }
    
  
    academic_interpretation <- paste0(
      "<b>Purpose.</b> ",
      "This section evaluates whether the training series becomes stationary after applying the currently selected differencing orders, ",
      "because SARIMA identification and statistical inference assume a stationary working series once transformations and differencing have been applied.",
      "<br><br>",
      
      "<b>Sample size and differencing.</b> ",
      "The training sample contained n = ", n_before, " observations before differencing and n = ", n_after,
      " observations after applying (d = ", input$d, ", D = ", input$D, ", s = ", s_use, "). ",
      "This reduction reflects the loss of initial observations induced by differencing.",
      "<br><br>",
      
      "<b>Tests and null hypotheses.</b>",
      "<ul style='margin-top:6px; margin-bottom:6px; padding-left:18px; list-style-type:square;'>",
      "<li><b>Unit-root tests (ADF, Phillipsâ€“Perron):</b> ",
      "H0 states that the differenced series still contains a unit root and therefore remains non-stationary.</li>",
      "<li><b>KPSS tests (Level, Trend):</b> ",
      "H0 states that the series is stationary, either around a constant mean (level-stationary) or around a deterministic trend (trend-stationary).</li>",
      "</ul>",
      
      "<b>ADF lag specification.</b> ",
      "Because differencing reduces the effective sample size and may induce residual autocorrelation, ",
      "the ADF test used k = ", k_adf,
      " lagged differences to mitigate serial correlation in the test regression.",
      "<br><br>",
      
      "<b>Empirical results.</b>",
      "<ul style='margin-top:6px; margin-bottom:6px; padding-left:18px; list-style-type:square;'>",
      "<li>", adf_line, "</li>",
      "<li>", pp_line, "</li>",
      "<li>", kpssL_line, "</li>",
      "<li>", kpssT_line, "</li>",
      "</ul>",
      "<br>",
      
      "<b>Pedagogical interpretation.</b> ",
      "For teaching purposes, it is important to emphasize that the goal of differencing is not to force a particular p-value outcome, ",
      "but rather to remove long-memory trend or seasonal persistence so that the remaining dependence is short-memory and can be captured by AR and MA terms. ",
      "The ultimate validation is whether the fitted-model residuals behave approximately like white noise ",
      "and whether forecasting performance remains stable when evaluated on a holdout sample."
    )
    
    
    
    # academic_interpretation <- paste0(
    #   "This section evaluates whether the training series becomes stationary after applying the currently selected differencing orders, because SARIMA identification and statistical inference assume a stationary working series once transformations and differencing have been applied. ",
    #   "The training sample contained n = ", n_before, " observations before differencing and n = ", n_after,
    #   " observations after applying (d = ", input$d, ", D = ", input$D, ", s = ", s_use, "). ",
    #   "Two unit-root tests were usedâ€”ADF and Phillipsâ€“Perronâ€”where H0 states that the differenced series still contains a unit root (i.e., remains non-stationary). ",
    #   "Two KPSS tests were also usedâ€”KPSS(Level) and KPSS(Trend)â€”where H0 states that the series is stationary (level-stationary or trend-stationary, respectively). ",
    #   "Because differencing reduces the effective sample size, the ADF test used k = ", k_adf, " lagged differences to mitigate residual autocorrelation in the test regression. ",
    #   adf_line, pp_line, kpssL_line, kpssT_line,
    #   "For teaching, emphasize that the goal of differencing is not to force a particular p-value outcome but to remove long-memory trend/seasonal persistence so that the remaining dependence is short-memory and can be captured by AR and MA terms; the final check is whether fitted-model residuals behave like white noise and whether forecasting performance is stable on a holdout set."
    # )
    
    # ---- More detailed conclusion (conditional; still tied to synthesis flags) ----
    conclusion <- if (unit_root_rejected && kpss_ok) {
      paste0(
        "After applying differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), ",
        "ADF/PP reject the unit-root null (p < .05) while KPSS(Level) does not reject stationarity (p â‰¥ .05). ",
        "This pattern is consistent with a stationary series after differencing."
      )
    } else if (!unit_root_rejected && !kpss_ok) {
      paste0(
        "After differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), ",
        "ADF/PP do not reject a unit root (p â‰¥ .05) and KPSS(Level) rejects stationarity (p < .05). ",
        "This suggests the series may still be non-stationary (consider revising d/D or checking breaks/seasonality)."
      )
    } else if (unit_root_rejected && !kpss_ok) {
      paste0(
        "After differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), evidence is mixed: ",
        "ADF/PP suggest stationarity but KPSS(Level) rejects it. This can happen with breaks, strong seasonal effects, ",
        "or finite-sample sensitivity; complement with diagnostics/visual checks."
      )
    } else {
      paste0(
        "After differencing (d=", input$d, ", D=", input$D, ", s=", s_use, "), evidence is inconclusive: ",
        "ADF/PP do not reject a unit root while KPSS(Level) does not reject stationarity. ",
        "Use ACF/PACF of the differenced series and consider alternative lag choices or structural breaks."
      )
    }
    
  
    
    html_tbl <- tags$table(
      class = "table table-striped table-condensed",
      tags$thead(tags$tr(lapply(names(st_df), tags$th))),
      tags$tbody(lapply(seq_len(nrow(st_df)), function(i) {
        tags$tr(lapply(st_df[i, , drop = FALSE], function(cell) tags$td(HTML(as.character(cell)))))
      }))
    )
    
    tagList(
      tags$h4(tags$strong(paste0(
        "Stationarity assessment after differencing (d=", input$d,
        ", D=", input$D, ", s=", s_use, ")"
      ))),
      tags$p(
        "The same stationarity tests were re-applied to the training series after applying the current differencing settings to verify that the working series is stationary."
      ),
      tags$br(),
      html_tbl,
 
      callout(
        body  = academic_interpretation,
        title = "Academic interpretation (stationarity after differencing)",
        theme = "blue",
        body_is_html = TRUE
      ),
      
      
      callout(
        body  = conclusion,
        title = "Conclusion.",
        theme = "orange",
        body_is_html = TRUE
      ),
      
      
    )
  })
  
  
  
  
  #
  #
  #
  #
  #
  
  
  output$manual_report_stationarity_mod2 <- renderUI({
    req(manual_conclusion_full_obj())
    req(ts_train_test(), prepared())
    
    validate(need(requireNamespace("tseries", quietly = TRUE),
                  "Package 'tseries' is required for stationarity tests (ADF/PP/KPSS)."))
    
    s_obj <- ts_train_test()
    p <- prepared()
    
    # training series
    y <- as.numeric(s_obj$ts_train)
    y <- y[is.finite(y)]
    
    # apply differencing implied by current d, D, s
    s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
    y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
    y_mod <- as.numeric(y_mod)
    y_mod <- y_mod[is.finite(y_mod)]
    
    validate(need(length(y_mod) >= 10,
                  "Not enough observations after differencing (d, D, s) to run stationarity tests (need â‰¥ 10)."))
    
    fmt_num <- function(z, d = 3) {
      z <- suppressWarnings(as.numeric(z))
      if (length(z) == 0 || !is.finite(z[1])) return("NA")
      formatC(z[1], format = "f", digits = d)
    }
    fmt_p <- function(pv) {
      pv <- suppressWarnings(as.numeric(pv))
      if (length(pv) == 0 || !is.finite(pv[1])) return("NA")
      if (pv[1] < .001) "p < .001" else paste0("p = ", sub("^0\\.", ".", sprintf("%.3f", pv[1])))
    }
    
    # safe lag choice for ADF (based on effective sample)
    k_adf <- max(0, min(12, floor((length(y_mod) - 1)^(1/3))))
    
    adf <- tryCatch(tseries::adf.test(y_mod, k = k_adf), error = function(e) NULL)
    pp  <- tryCatch(tseries::pp.test(y_mod, lshort = TRUE), error = function(e) NULL)
    kpss_level <- tryCatch(tseries::kpss.test(y_mod, null = "Level", lshort = TRUE), error = function(e) NULL)
    kpss_trend <- tryCatch(tseries::kpss.test(y_mod, null = "Trend", lshort = TRUE), error = function(e) NULL)
    
    rows <- list()
    add_row <- function(test, null_h, stat, pval, decision) {
      rows[[length(rows) + 1L]] <<- data.frame(
        Test = test,
        `H0 (null)` = null_h,
        Statistic = stat,
        `p-value` = pval,
        Decision = decision,
        check.names = FALSE
      )
    }
    
    # ADF
    if (!is.null(adf)) {
      pv <- adf$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence for stationarity"
      else "Fail to reject H0 â†’ unit root plausible"
      add_row("ADF (Augmented Dickeyâ€“Fuller)", "Unit root (non-stationary)",
              fmt_num(unname(adf$statistic)), fmt_p(pv), dec)
    } else {
      add_row("ADF (Augmented Dickeyâ€“Fuller)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # PP
    if (!is.null(pp)) {
      pv <- pp$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence for stationarity"
      else "Fail to reject H0 â†’ unit root plausible"
      add_row("PP (Phillipsâ€“Perron)", "Unit root (non-stationary)",
              fmt_num(unname(pp$statistic)), fmt_p(pv), dec)
    } else {
      add_row("PP (Phillipsâ€“Perron)", "Unit root (non-stationary)", "NA", "NA", "Not available")
    }
    
    # KPSS Level
    if (!is.null(kpss_level)) {
      pv <- kpss_level$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence against stationarity"
      else "Fail to reject H0 â†’ stationarity plausible"
      add_row("KPSS (Level)", "Level-stationary",
              fmt_num(unname(kpss_level$statistic)), fmt_p(pv), dec)
    } else {
      add_row("KPSS (Level)", "Level-stationary", "NA", "NA", "Not available")
    }
    
    # KPSS Trend
    if (!is.null(kpss_trend)) {
      pv <- kpss_trend$p.value
      dec <- if (is.finite(pv) && pv < 0.05) "Reject H0 â†’ evidence against trend-stationarity"
      else "Fail to reject H0 â†’ trend-stationarity plausible"
      add_row("KPSS (Trend)", "Trend-stationary",
              fmt_num(unname(kpss_trend$statistic)), fmt_p(pv), dec)
    } else {
      add_row("KPSS (Trend)", "Trend-stationary", "NA", "NA", "Not available")
    }
    
    st_df <- do.call(rbind, rows)
    
    # synthesis flags
    adf_p <- if (!is.null(adf)) adf$p.value else NA_real_
    pp_p  <- if (!is.null(pp))  pp$p.value  else NA_real_
    kL_p  <- if (!is.null(kpss_level)) kpss_level$p.value else NA_real_
    
    unit_root_rejected <- any(c(adf_p, pp_p) < 0.05, na.rm = TRUE)
    kpss_ok <- is.finite(kL_p) && kL_p >= 0.05
    
    # sizes for interpretation
    n_before <- length(y)
    n_after  <- length(y_mod)
    
    # result lines (data-driven)
    adf_line <- if (!is.null(adf)) {
      paste0("ADF (k = ", k_adf, "): statistic = ", fmt_num(unname(adf$statistic)),
             ", ", fmt_p(adf$p.value))
    } else {
      "ADF: Not available"
    }
    
    pp_line <- if (!is.null(pp)) {
      paste0("PP: statistic = ", fmt_num(unname(pp$statistic)),
             ", ", fmt_p(pp$p.value))
    } else {
      "PP: Not available"
    }
    
    kpssL_line <- if (!is.null(kpss_level)) {
      paste0("KPSS(Level): statistic = ", fmt_num(unname(kpss_level$statistic)),
             ", ", fmt_p(kpss_level$p.value))
    } else {
      "KPSS(Level): Not available"
    }
    
    kpssT_line <- if (!is.null(kpss_trend)) {
      paste0("KPSS(Trend): statistic = ", fmt_num(unname(kpss_trend$statistic)),
             ", ", fmt_p(kpss_trend$p.value))
    } else {
      "KPSS(Trend): Not available"
    }
    
    # -------------- Organized Academic interpretation (â–  bullets) --------------
    intro_txt <- paste0(
      "This section re-applies stationarity tests after enforcing the currently selected differencing configuration ",
      "(d = ", input$d, ", D = ", input$D, ", s = ", s_use, "). ",
      "The training sample includes n = ", n_before, " observations before differencing and n = ", n_after,
      " observations after differencing. The purpose is to verify that the working series used for SARIMA identification is stationary."
    )
    
    interpretation_bullets <- list(
      paste0(
        "<b>Null hypotheses (what each test assumes):</b> ",
        "ADF and PP test <i>H0: unit root</i> (non-stationarity), so rejecting H0 supports stationarity. ",
        "KPSS tests <i>H0: stationarity</i> (level- or trend-stationary), so rejecting H0 provides evidence against stationarity."
      ),
      paste0(
        "<b>Observed results on the differenced series:</b> ",
        adf_line, "; ", pp_line, "; ", kpssL_line, "; ", kpssT_line, "."
      ),
      paste0(
        "<b>Why the ADF lag (k) matters:</b> ",
        "The ADF test used k = ", k_adf, " lagged differences based on the effective sample size. ",
        "Too small k can leave autocorrelation in the test regression (risking misleading inference), ",
        "while too large k reduces test power. This automatic choice is a practical default for teaching."
      )
    )
    
    # -------------- Organized Conclusion (â–  bullets; depends on synthesis flags) --------------
    conclusion_bullets <- if (unit_root_rejected && kpss_ok) {
      list(
        "<b>Decision:</b> Evidence is consistent with stationarity after differencing (unit-root tests reject H0 and KPSS(Level) does not reject stationarity).",
        "<b>Implication for differencing:</b> The current differencing orders (d and D) appear adequate; avoid further differencing to reduce over-differencing risk.",
        "<b>Next step:</b> Move to ACF/PACF-based identification of p, q, P, and Q on the differenced series, then validate with residual whiteness tests (e.g., Ljungâ€“Box) and forecasting performance."
      )
    } else if (!unit_root_rejected && !kpss_ok) {
      list(
        "<b>Decision:</b> Evidence suggests the series may still be non-stationary after the current differencing (unit-root tests do not reject; KPSS(Level) rejects stationarity).",
        "<b>Implication for differencing:</b> Revisit d and/or D: persistent dependence at small lags often motivates increasing d, whereas persistence at seasonal lags (multiples of s) motivates increasing D.",
        "<b>Teaching note:</b> If additional differencing does not resolve the issue, check for structural breaks, regime changes, or changing variance (which can mimic non-stationarity)."
      )
    } else if (unit_root_rejected && !kpss_ok) {
      list(
        "<b>Decision:</b> Mixed evidence (ADF/PP indicate stationarity, but KPSS(Level) rejects stationarity).",
        "<b>Interpretation:</b> This may occur under structural breaks, near-unit-root dynamics, or finite-sample sensitivityâ€”especially after differencing reduces sample size.",
        "<b>Next step:</b> Triangulate using time plots, ACF/PACF, and fitted-model residual diagnostics; prefer the simplest specification that yields approximately white-noise residuals and stable forecasts."
      )
    } else {
      list(
        "<b>Decision:</b> Inconclusive evidence (ADF/PP do not reject a unit root and KPSS(Level) does not reject stationarity).",
        "<b>Interpretation:</b> This often reflects limited power after differencing or a process near the unit-root boundary.",
        "<b>Next step:</b> Compare nearby differencing choices (e.g., d vs d+1 and/or D vs D+1 if seasonality is plausible), then choose the simplest setting that produces stable plots and white-noise residuals after fitting."
      )
    }
    
    # HTML table (as you already had)
    html_tbl <- tags$table(
      class = "table table-striped table-condensed",
      tags$thead(tags$tr(lapply(names(st_df), tags$th))),
      tags$tbody(lapply(seq_len(nrow(st_df)), function(i) {
        tags$tr(lapply(st_df[i, , drop = FALSE], function(cell) {
          tags$td(HTML(as.character(cell)))
        }))
      }))
    )
    
    # square-bullet helper
    square_ul <- function(items) {
      tags$ul(
        style = "list-style-type:square; padding-left: 18px; line-height: 1.55;",
        lapply(items, function(txt) tags$li(HTML(txt)))
      )
    }
    
    tagList(
      # tags$h4(tags$strong(paste0(
      #   "Stationarity assessment after differencing (d=", input$d,
      #   ", D=", input$D, ", s=", s_use, ")"
      # ))),
      
      # tags$p(intro_txt),
      # tags$br(),
      
      # html_tbl,
      
      
      callout(
        square_ul(interpretation_bullets),
        title = "Academic interpretation.",
        theme = "blue",
        body_is_html = FALSE
      ),
      
      callout(
        square_ul(conclusion_bullets),
        title = "Conclusion",
        theme = "orange",
        body_is_html = FALSE
      ),
    )
  })
  



  #
  #
  #
  #
  #
  
  
  
  
  
  
  # ------------------------------------------------------------
  # (B) manual_conclusion_full_obj (eventReactive) â€” UI builder ONLY
  # ------------------------------------------------------------
  manual_conclusion_full_obj <- eventReactive(input$fit_manual, {
    req(manual_fit(), manual_fc(), manual_equations(), ts_train_test())
    
    fit <- manual_fit()
    fc0 <- manual_fc()
    fc  <- fc0$fc
    eq  <- manual_equations()
    s   <- ts_train_test()
    
    # ---------- helpers (local + safe)
    `%||%` <- function(x, y) {
      if (is.null(x) || length(x) == 0 || all(is.na(x))) y else x
    }
    
    fmt_num_local <- function(x, d = 3) {
      if (length(x) == 0 || all(is.na(x))) return("NA")
      x <- suppressWarnings(as.numeric(x[1]))
      if (!is.finite(x)) return("NA")
      formatC(x, format = "f", digits = d)
    }
    fmt_p_local <- function(p) {
      if (length(p) == 0 || all(is.na(p))) return("NA")
      p <- suppressWarnings(as.numeric(p[1]))
      if (!is.finite(p)) return("NA")
      if (p < .001) "&lt; .001" else sprintf("= %.3f", p)
    }
    sig_stars <- function(p) {
      p <- suppressWarnings(as.numeric(p))
      if (!is.finite(p)) return("")
      if (p < .001) "***" else if (p < .01) "**" else if (p < .05) "*" else if (p < .10) "â€ " else ""
    }
    safe_len <- function(x) if (is.null(x)) 0L else length(x)
    
    html_table <- function(df) {
      if (is.null(df) || !is.data.frame(df) || nrow(df) == 0) {
        return(tags$em("Table unavailable."))
      }
      tags$table(
        class = "table table-striped table-condensed",
        tags$thead(tags$tr(lapply(names(df), function(nm) tags$th(nm)))),
        tags$tbody(
          lapply(seq_len(nrow(df)), function(i) {
            tags$tr(lapply(df[i, , drop = FALSE], function(cell) tags$td(HTML(as.character(cell)))))
          })
        )
      )
    }
    
    # ---------- sample sizes (safe)
    n_train <- suppressWarnings(as.integer(s$train_n))
    if (!is.finite(n_train) || n_train < 1) n_train <- tryCatch(length(residuals(fit)), error = function(e) 0L)
    
    n_test <- suppressWarnings(as.integer(s$test_n))
    if (!is.finite(n_test) || n_test < 0) n_test <- 0L
    
    N <- n_train + n_test
    
    # ---------- lag choice (safe)
    L_in <- suppressWarnings(as.integer(input$diag_lag))
    L <- if (is.finite(L_in) && L_in > 0) L_in else 12L
    
    # ============================================================
    # ---------- IC (safe + robust AICc fallback)
    # ============================================================
    AIC_val <- suppressWarnings(tryCatch(as.numeric(stats::AIC(fit)), error = function(e) NA_real_))
    BIC_val <- suppressWarnings(tryCatch(as.numeric(stats::BIC(fit)), error = function(e) NA_real_))
    
    AICc_val <- suppressWarnings(tryCatch(as.numeric(forecast::AICc(fit)), error = function(e) NA_real_))
    
    if (!is.finite(AICc_val) && is.finite(AIC_val)) {
      n_fit <- suppressWarnings(tryCatch(stats::nobs(fit), error = function(e) NA_integer_))
      if (!is.finite(n_fit) || n_fit <= 0) {
        r <- suppressWarnings(tryCatch(as.numeric(residuals(fit)), error = function(e) numeric(0)))
        n_fit <- sum(is.finite(r))
      }
      if (!is.finite(n_fit) || n_fit <= 0) n_fit <- n_train
      
      k <- suppressWarnings(tryCatch(length(stats::coef(fit)), error = function(e) NA_integer_))
      if (!is.finite(k) || k < 0) k <- 0L
      k <- k + 1L
      
      if (is.finite(n_fit) && n_fit > (k + 1)) {
        AICc_val <- AIC_val + (2 * k * (k + 1)) / (n_fit - k - 1)
      } else {
        AICc_val <- NA_real_
      }
    }
    
    ic_df <- data.frame(
      Criterion = c("AIC", "AICc", "BIC"),
      Value     = c(fmt_num_local(AIC_val, 2), fmt_num_local(AICc_val, 2), fmt_num_local(BIC_val, 2)),
      check.names = FALSE
    )
    
    # ---------- coefficients + significance (robust)
    est <- suppressWarnings(tryCatch(stats::coef(fit), error = function(e) NULL))
    V   <- suppressWarnings(tryCatch(stats::vcov(fit), error = function(e) NULL))
    if (is.null(V)) V <- suppressWarnings(tryCatch(fit$var.coef, error = function(e) NULL))
    
    coef_df <- NULL
    if (!is.null(est) && length(est) > 0) {
      est <- as.numeric(est)
      nm  <- names(stats::coef(fit))
      if (is.null(nm)) nm <- paste0("param_", seq_along(est))
      
      se <- rep(NA_real_, length(est))
      if (!is.null(V)) {
        dV <- tryCatch(diag(V), error = function(e) rep(NA_real_, length(est)))
        if (length(dV) == length(est)) se <- sqrt(pmax(dV, 0))
      }
      z  <- est / se
      p  <- 2 * stats::pnorm(-abs(z))
      
      coef_df <- data.frame(
        Term     = nm,
        Estimate = sprintf("%.6f", est),
        SE       = ifelse(is.finite(se), sprintf("%.6f", se), "NA"),
        `z/t`    = ifelse(is.finite(z),  sprintf("%.3f",  z),  "NA"),
        `p`      = ifelse(is.finite(p),  sprintf("%.3f",  p),  "NA"),
        Sig      = vapply(p, sig_stars, character(1)),
        check.names = FALSE
      )
    }
    
    n_sig <- if (!is.null(coef_df)) sum(suppressWarnings(as.numeric(coef_df$p)) < 0.05, na.rm = TRUE) else 0L
    
    # ---------- residuals (safe)
    res <- suppressWarnings(tryCatch(as.numeric(residuals(fit)), error = function(e) numeric(0)))
    res <- res[is.finite(res)]
    n_res <- length(res)
    
    fitdf <- if (!is.null(est)) length(est) else 0L
    
    lb_lag <- min(L, max(1L, floor(n_res / 3)))
    lb <- if (n_res >= 5) {
      tryCatch(stats::Box.test(res, lag = lb_lag, type = "Ljung-Box", fitdf = fitdf), error = function(e) NULL)
    } else NULL
    
    bp <- if (n_res >= 5) {
      tryCatch(stats::Box.test(res, lag = lb_lag, type = "Box-Pierce", fitdf = fitdf), error = function(e) NULL)
    } else NULL
    
    jb <- if (requireNamespace("tseries", quietly = TRUE) && n_res >= 5) {
      tryCatch(tseries::jarque.bera.test(res), error = function(e) NULL)
    } else NULL
    
    sw <- if (n_res >= 3 && n_res <= 5000) {
      tryCatch(stats::shapiro.test(res), error = function(e) NULL)
    } else NULL
    
    arch <- if (requireNamespace("FinTS", quietly = TRUE) && n_res >= 10) {
      tryCatch(FinTS::ArchTest(res, lags = min(12L, max(1L, floor(L / 2)))), error = function(e) NULL)
    } else NULL
    
    runs <- if (requireNamespace("tseries", quietly = TRUE) && n_res >= 10) {
      tryCatch(tseries::runs.test(res), error = function(e) NULL)
    } else NULL
    
    ad <- if (requireNamespace("nortest", quietly = TRUE) && n_res >= 8) {
      tryCatch(nortest::ad.test(res), error = function(e) NULL)
    } else NULL
    
    test_rows <- list()
    add_test <- function(name, stat, pval, note = "") {
      test_rows[[length(test_rows) + 1L]] <<- data.frame(
        Test = name,
        Statistic = if (is.null(stat)) "NA" else fmt_num_local(stat, 3),
        `p-value` = if (is.null(pval)) "NA" else fmt_p_local(pval),
        Interpretation = note,
        check.names = FALSE
      )
    }
    
    add_test(
      "Ljungâ€“Box (residuals)",
      if (!is.null(lb)) unname(lb$statistic) else NULL,
      if (!is.null(lb)) unname(lb$p.value) else NULL,
      if (!is.null(lb)) {
        if (is.finite(lb$p.value) && lb$p.value >= 0.05) "No evidence of remaining autocorrelation (white-noise compatible)."
        else "Evidence of remaining autocorrelation (model may be under-specified)."
      } else "Not available."
    )
    
    add_test(
      "Boxâ€“Pierce (residuals)",
      if (!is.null(bp)) unname(bp$statistic) else NULL,
      if (!is.null(bp)) unname(bp$p.value) else NULL,
      if (!is.null(bp)) {
        if (is.finite(bp$p.value) && bp$p.value >= 0.05) "Consistent with uncorrelated residuals."
        else "Suggests residual autocorrelation."
      } else "Not available."
    )
    
    add_test(
      "Jarqueâ€“Bera (normality)",
      if (!is.null(jb)) unname(jb$statistic) else NULL,
      if (!is.null(jb)) unname(jb$p.value) else NULL,
      if (!is.null(jb)) {
        if (is.finite(jb$p.value) && jb$p.value >= 0.05) "No evidence against normality."
        else "Residuals deviate from normality (common in real series)."
      } else "Package 'tseries' missing or test unavailable."
    )
    
    add_test(
      "Shapiroâ€“Wilk (normality)",
      if (!is.null(sw)) unname(sw$statistic) else NULL,
      if (!is.null(sw)) unname(sw$p.value) else NULL,
      if (!is.null(sw)) {
        if (is.finite(sw$p.value) && sw$p.value >= 0.05) "No evidence against normality."
        else "Evidence against normality."
      } else if (n_res > 5000) "Not computed (n > 5000)." else "Not available."
    )
    
    add_test(
      "ARCH LM (heteroskedasticity)",
      if (!is.null(arch)) unname(arch$statistic) else NULL,
      if (!is.null(arch)) unname(arch$p.value) else NULL,
      if (!is.null(arch)) {
        if (is.finite(arch$p.value) && arch$p.value >= 0.05) "No evidence of remaining ARCH effects."
        else "Evidence of ARCH effects â†’ consider GARCH for variance."
      } else "Package 'FinTS' missing or test unavailable."
    )
    
    add_test(
      "Runs test (randomness)",
      if (!is.null(runs)) unname(runs$statistic) else NULL,
      if (!is.null(runs)) unname(runs$p.value) else NULL,
      if (!is.null(runs)) {
        if (is.finite(runs$p.value) && runs$p.value >= 0.05) "No evidence against randomness."
        else "Evidence of non-randomness (structure may remain)."
      } else "Package 'tseries' missing or test unavailable."
    )
    
    add_test(
      "Andersonâ€“Darling (normality)",
      if (!is.null(ad)) unname(ad$statistic) else NULL,
      if (!is.null(ad)) unname(ad$p.value) else NULL,
      if (!is.null(ad)) {
        if (is.finite(ad$p.value) && ad$p.value >= 0.05) "No evidence against normality."
        else "Evidence against normality (sensitive in tails)."
      } else "Package 'nortest' missing or test unavailable."
    )
    
    tests_df <- if (length(test_rows)) do.call(rbind, test_rows) else data.frame()
    
    # ---------- forecast accuracy (safe)  [NOTE: this is on the model scale]
    acc_df <- NULL
    acc_sentence <- "No holdout test set was detected; therefore, out-of-sample accuracy was not computed."
    
    y_test <- s$ts_test
    has_test <- !is.null(y_test) && safe_len(y_test) > 0 && n_test > 0
    
    if (has_test) {
      y_test_num <- as.numeric(y_test)
      y_hat_num  <- suppressWarnings(tryCatch(as.numeric(fc$mean), error = function(e) rep(NA_real_, length(y_test_num))))
      h <- min(length(y_test_num), length(y_hat_num))
      if (h >= 1) {
        e <- y_test_num[seq_len(h)] - y_hat_num[seq_len(h)]
        rmse <- sqrt(mean(e^2, na.rm = TRUE))
        mae  <- mean(abs(e), na.rm = TRUE)
        mape <- mean(abs(e) / pmax(abs(y_test_num[seq_len(h)]), .Machine$double.eps), na.rm = TRUE)
        
        acc_df <- data.frame(
          Metric = c("RMSE", "MAE", "MAPE"),
          Value  = c(fmt_num_local(rmse, 3), fmt_num_local(mae, 3), paste0(fmt_num_local(100*mape, 2), "%")),
          check.names = FALSE
        )
        
        acc_sentence <- paste0(
          "Over the holdout period (test n = ", h, "), forecast performance was ",
          "RMSE = ", fmt_num_local(rmse, 3), ", ",
          "MAE = ", fmt_num_local(mae, 3), ", ",
          "MAPE = ", fmt_num_local(100*mape, 2), "%."
        )
      }
    }
    
    # ---------- horizon narrative
    horizon_txt <- if (has_test) {
      paste0("Validation mode was used: the forecast horizon was forced to match the test length (h = ", n_test, ").")
    } else {
      paste0("Future mode was used: forecasts were produced beyond the training sample (h = ", fc0$h, ").")
    }
    
    # ---------- model string
    season_txt <- suppressWarnings(as.integer(eq$s))
    s_txt <- if (is.finite(season_txt) && season_txt > 0) as.character(season_txt) else "s"
    
    model_str <- sprintf(
      "SARIMA(%d,%d,%d)(%d,%d,%d)[%s]",
      eq$p, eq$d, eq$q, eq$P, eq$D, eq$Q, s_txt
    )
    
    # ---------- diagnostic verdict
    lb_ok <- !is.null(lb) && is.finite(lb$p.value) && lb$p.value >= 0.05
    arch_ok <- is.null(arch) || (is.finite(arch$p.value) && arch$p.value >= 0.05)
    
    
    diag_verdict <- paste0(
      
      if (lb_ok) {
        paste0(
          "Residual autocorrelation was not statistically detected based on the Ljungâ€“Box test (p â‰¥ .05).<br><br>",
          "Conditional on the fitted SARIMA structure, the residuals are therefore consistent with a white-noise process. ",
          "This indicates that the mean equation adequately captures the linear serial dependence present in the data."
        )
      } else {
        paste0(
          "Residual autocorrelation may remain according to the Ljungâ€“Box test (p < .05).<br><br>",
          "This implies that the residuals exhibit systematic serial dependence beyond what is explained by the current SARIMA specification. ",
          "Such a pattern is consistent with potential underfitting of the mean equation, ",
          "for example due to insufficient AR/MA or seasonal AR/MA terms, ",
          "or an incomplete differencing structure."
        )
      },
      
      "<br><br>",
      
      if (arch_ok) {
        paste0(
          "No clear evidence of conditional heteroskedasticity (ARCH effects) was found ",
          "(or the ARCH LM test was not available).<br><br>",
          "This suggests that the residual variance is approximately constant over time, ",
          "making a homoskedastic innovation assumption reasonable for both inference and forecasting."
        )
      } else {
        paste0(
          "Statistically significant ARCH effects were detected, indicating time-varying conditional variance in the residuals.<br><br>",
          "In this case, extending the model with a volatility component (e.g., a GARCH specification) is recommended ",
          "to capture volatility clustering and to obtain reliable standard errors and prediction intervals."
        )
      },
      
      "<br><br>",
      
      paste0(
        "<b>Overall diagnostic assessment.</b> ",
        "Model adequacy should be judged jointly. ",
        "A satisfactory SARIMA specification is one in which residuals exhibit no systematic autocorrelation ",
        "and no strong evidence of conditional heteroskedasticity, ",
        "with final confirmation provided by residual diagnostics and stable out-of-sample forecast performance."
      )
    )
    
  
    
    # ============================================================
    # ---------- Inverse transform equation + bias-adjusted back-forecasts
    # ============================================================
    tr_global <- input$transform %||% "none"
    
    # lambda consistent with your transform step:
    # apply_transform() uses forecast::BoxCox.lambda(y, lower=0) when input$lambda is NA
    lambda_used <- NA_real_
    if (identical(tr_global, "boxcox")) {
      p_obj <- tryCatch(prepared(), error = function(e) NULL)
      lam_in <- input$lambda
      if (is.null(lam_in) || (length(lam_in) == 1 && is.na(lam_in))) {
        lambda_used <- tryCatch(
          forecast::BoxCox.lambda(p_obj$df$y_filled, lower = 0),
          error = function(e) NA_real_
        )
      } else {
        lambda_used <- suppressWarnings(as.numeric(lam_in))
      }
    }
    
    # Forecasts are on TRANSFORMED scale:
    mu_t <- suppressWarnings(as.numeric(fc$mean))
    
    # se can be NULL / missing; handle safely
    se_t <- tryCatch(as.numeric(fc$se), error = function(e) rep(NA_real_, length(mu_t)))
    if (length(se_t) != length(mu_t)) se_t <- rep(NA_real_, length(mu_t))
    var_t <- se_t^2  # forecast variance on transformed scale (when available)
    
    lo_t <- tryCatch(fc$lower, error = function(e) NULL)
    hi_t <- tryCatch(fc$upper, error = function(e) NULL)
    lvl_names <- tryCatch(colnames(fc$lower), error = function(e) NULL)
    
    inv_equation_html <- NULL
    inv_note_html <- NULL
    
    inv_mean <- mu_t
    inv_lo   <- lo_t
    inv_hi   <- hi_t
    
    tex_or_plain <- function(tex, plain) {
      if (exists("tex_display", mode = "function")) HTML(tex_display(tex)) else HTML(plain)
    }
    
    if (identical(tr_global, "log")) {
      
      # Always-available back-transform (median)
      inv_mean <- exp(mu_t)
      
      # Bias-adjusted mean where variance is available
      ok <- is.finite(var_t)
      inv_mean[ok] <- exp(mu_t[ok] + 0.5 * var_t[ok])
      
      # Interval bounds: back-transform quantiles
      if (!is.null(lo_t) && !is.null(hi_t)) {
        inv_lo <- exp(lo_t)
        inv_hi <- exp(hi_t)
      }
      
      inv_equation_html <- tex_or_plain(
        "y = \\exp(z) \\quad \\text{where } z = \\ln(y)",
        "y = exp(z), where z = log(y)"
      )
      inv_note_html <- HTML(
        "<span style='font-size:12px;color:#444;'>
        Point forecasts use <b>exp(Î¼ + 0.5Â·ÏƒÂ²)</b> when ÏƒÂ² is available; otherwise they fall back to <b>exp(Î¼)</b>.
        Interval bounds are back-transformed using <b>exp()</b>.
      </span>"
      )
      
    } else if (identical(tr_global, "boxcox")) {
      
      validate(need(is.finite(lambda_used), "Boxâ€“Cox lambda is missing/invalid; cannot compute inverse forecasts."))
      lam <- lambda_used
      
      # Always-available back-transform (median)
      inv_mean <- forecast::InvBoxCox(mu_t, lam)
      
      # Bias-adjusted mean where variance is available
      ok <- is.finite(var_t)
      inv_mean[ok] <- forecast::InvBoxCox(mu_t, lam)                              # forecast::InvBoxCox(mu_t[ok], lam, biasadj = TRUE, var = var_t[ok])
      
      if (!is.null(lo_t) && !is.null(hi_t)) {
        inv_lo <- tryCatch(forecast::InvBoxCox(lo_t, lam), error = function(e) lo_t)
        inv_hi <- tryCatch(forecast::InvBoxCox(hi_t, lam), error = function(e) hi_t)
      }

      
      if (is.finite(lam) && abs(lam) < 1e-6) {
        inv_equation_html <- tex_or_plain(
          "y = \\exp(z) \\quad (\\lambda \\approx 0)",
          "y = exp(z)  (lambda â‰ˆ 0)"
        )
      } else {
        inv_equation_html <- tex_or_plain(
          "y = (\\lambda z + 1)^{1/\\lambda}",
          "y = (lambda*z + 1)^(1/lambda)"
        )
      }
      
      inv_note_html <- HTML(paste0(
        "<span style='font-size:12px;color:#444;'>
        Î» used = <b>", if (is.finite(lambda_used)) formatC(lambda_used, digits = 4, format = "f") else "NA", "</b>.
        Point forecasts use <b>InvBoxCox(Î¼, Î», biasadj=TRUE, var=seÂ²)</b> when seÂ² is available; otherwise they fall back to <b>InvBoxCox(Î¼, Î»)</b>.
        Interval bounds are back-transformed using <b>InvBoxCox()</b>.
      </span>"
      ))
    }
    
    

    # Build an ORIGINAL-SCALE forecast table (bias-adjusted mean + back-transformed intervals)
    fc_orig_df <- data.frame(
      # Horizon = seq_along(inv_mean),
      Horizon = as.integer(seq_along(inv_mean)),
      Mean_original = as.numeric(inv_mean),
      stringsAsFactors = FALSE
    )
    
    if (!is.null(inv_lo) && !is.null(inv_hi) && !is.null(lvl_names)) {
      for (j in seq_along(lvl_names)) {
        lvl <- lvl_names[j]
        fc_orig_df[[paste0("Lo_", lvl)]] <- as.numeric(inv_lo[, j])
        fc_orig_df[[paste0("Hi_", lvl)]] <- as.numeric(inv_hi[, j])
      }
    }
    
    # format numeric columns for HTML display
    fc_orig_df_fmt <- fc_orig_df
    for (nm in names(fc_orig_df_fmt)) {
      if (is.numeric(fc_orig_df_fmt[[nm]])) {
        fc_orig_df_fmt[[nm]] <- ifelse(
          is.finite(fc_orig_df_fmt[[nm]]),
          sprintf("%.6f", fc_orig_df_fmt[[nm]]),
          "NA"
        )
      }
    }
    
    
    fc_orig_df_fmt <- fc_orig_df
    # âœ… force integer display for Horizon
    fc_orig_df_fmt$Horizon <- as.character(as.integer(fc_orig_df_fmt$Horizon))
    
    # format OTHER numeric columns to 6 decimals
    for (nm in setdiff(names(fc_orig_df_fmt), "Horizon")) {
      if (is.numeric(fc_orig_df_fmt[[nm]])) {
        fc_orig_df_fmt[[nm]] <- ifelse(
          is.finite(fc_orig_df_fmt[[nm]]),
          sprintf("%.6f", fc_orig_df_fmt[[nm]]),
          "NA"
        )
      }
    }
    
    
    output$manual_report_acf_pacf_interpretation <- renderUI({
      req(manual_conclusion_full_obj())
      req(ts_train_test(), prepared())
      
      s_obj <- ts_train_test()
      p <- prepared()
      
      # Differenced training series (same as in your plots)
      y <- as.numeric(s_obj$ts_train)
      y <- y[is.finite(y)]
      
      s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
      y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
      y_mod <- as.numeric(y_mod)
      y_mod <- y_mod[is.finite(y_mod)]
      
      validate(need(length(y_mod) >= 10, "Not enough observations after differencing to interpret ACF/PACF (need â‰¥ 10)."))
      
      # Compute ACF/PACF numerically (for interpretation)
      lag_max <- min(60L, length(y_mod) - 1L)
      acf_obj  <- stats::acf(y_mod, plot = FALSE, lag.max = lag_max)
      pacf_obj <- stats::pacf(y_mod, plot = FALSE, lag.max = lag_max)
      
      acf_vals  <- as.numeric(acf_obj$acf)[-1]     # drop lag 0
      pacf_vals <- as.numeric(pacf_obj$acf)
      lags <- seq_len(lag_max)
      
      # 95% significance band approximation
      n_eff <- length(y_mod)
      conf <- 1.96 / sqrt(n_eff)
      
      sig_acf  <- which(abs(acf_vals)  > conf)
      sig_pacf <- which(abs(pacf_vals) > conf)
      
      # A few helper summaries for teaching text
      first_sig_acf  <- if (length(sig_acf))  sig_acf[1]  else NA_integer_
      first_sig_pacf <- if (length(sig_pacf)) sig_pacf[1] else NA_integer_
      
      # seasonal spike detection (multiples of s)
      seasonal_lags <- if (is.finite(s_use) && s_use >= 2) {
        seq(s_use, lag_max, by = s_use)
      } else integer(0)
      
      sig_season_acf  <- intersect(sig_acf, seasonal_lags)
      sig_season_pacf <- intersect(sig_pacf, seasonal_lags)
      
      # "cutoff" heuristics (very simple, for students):
      # - PACF cutoff at p if first few lags significant then mostly not
      # - ACF cutoff at q similarly
      guess_cutoff <- function(sig_idx, max_k = 10L) {
        # returns last consecutive significant lag starting at 1 (common heuristic)
        if (length(sig_idx) == 0 || sig_idx[1] != 1) return(0L)
        k <- 1L
        while (k + 1L <= max_k && (k + 1L) %in% sig_idx) k <- k + 1L
        k
      }
      
      p_hint <- guess_cutoff(sig_pacf, max_k = 10L)
      q_hint <- guess_cutoff(sig_acf,  max_k = 10L)
      
      P_hint <- 0L
      Q_hint <- 0L
      if (length(seasonal_lags)) {
        # seasonal AR tends to show in PACF at s, 2s; seasonal MA in ACF at s, 2s
        if (length(sig_season_pacf)) P_hint <- length(sig_season_pacf[sig_season_pacf <= 2*s_use])
        if (length(sig_season_acf))  Q_hint <- length(sig_season_acf[sig_season_acf <= 2*s_use])
        P_hint <- min(P_hint, 2L)
        Q_hint <- min(Q_hint, 2L)
      }
      
      # Differencing sanity check hints:
      # Over-differencing often yields strong negative lag-1 ACF
      overdiff_flag <- is.finite(acf_vals[1]) && acf_vals[1] < -conf
      slow_decay_flag <- {
        # slow decay: many significant acf lags early on
        sum(abs(acf_vals[1:min(12, length(acf_vals))]) > conf, na.rm = TRUE) >= 6
      }
      
      # Build the academic paragraph (one paragraph, but detailed)
      paragraph <- paste0(
        "Figure E presents the ACF and PACF of the training series after applying the current differencing settings ",
        "(d = ", input$d, ", D = ", input$D, ", seasonal period s = ", s_use, "). ",
        "Interpreting these plots is central to SARIMA identification because the ACF summarizes the correlation structure across lags, ",
        "whereas the PACF summarizes partial correlations after controlling for intermediate lags. ",
        "Using the approximate 95% bounds (\u00B11.96/\u221A n, here about \u00B1", sprintf("%.3f", conf), "), the differenced series shows ",
        length(sig_acf), " significant ACF spike(s) and ", length(sig_pacf), " significant PACF spike(s) up to lag ", lag_max, ". ",
        if (is.finite(first_sig_acf)) paste0("The first significant ACF spike occurs at lag ", first_sig_acf, ", ") else "",
        if (is.finite(first_sig_pacf)) paste0("and the first significant PACF spike occurs at lag ", first_sig_pacf, ". ") else ". ",
        "A common teaching heuristic is that an MA(q) component is suggested when the ACF shows a short-run cutoff (a few early significant lags) while the PACF tapers, ",
        "whereas an AR(p) component is suggested when the PACF shows a short-run cutoff while the ACF tapers. ",
        "Based on consecutive early-lag significance, a reasonable starting point is p \u2248 ", p_hint, " (from the PACF) and q \u2248 ", q_hint, " (from the ACF), ",
        "which should be treated as initial candidates rather than final answers. ",
        if (length(seasonal_lags)) {
          paste0(
            "Seasonal structure is assessed at multiples of s (", s_use, "): the ACF has ",
            length(sig_season_acf), " significant seasonal spike(s) at {",
            if (length(sig_season_acf)) paste(sig_season_acf, collapse = ", ") else "none",
            "} and the PACF has ", length(sig_season_pacf), " significant seasonal spike(s) at {",
            if (length(sig_season_pacf)) paste(sig_season_pacf, collapse = ", ") else "none",
            "}. ",
            "In SARIMA terms, prominent spikes in the ACF at lag s tend to motivate a seasonal MA term (Q > 0), while prominent spikes in the PACF at lag s motivate a seasonal AR term (P > 0). ",
            "Accordingly, a practical starting guess is P \u2248 ", P_hint, " and Q \u2248 ", Q_hint, " (often 0â€“2 in applied work). "
          )
        } else "",
        if (overdiff_flag) {
          "Notably, the lag-1 ACF is strongly negative beyond the confidence bounds, which can be a warning sign of over-differencing; students should consider whether d or D could be reduced and then re-check stationarity and diagnostics. "
        } else "",
        if (slow_decay_flag) {
          "Conversely, if the ACF decays slowly with many significant early lags, this indicates remaining persistence and suggests that additional differencing (increasing d and/or D) or better seasonal handling may still be required before relying on ARMA orders. "
        } else "",
        "Finally, emphasize to students that ACF/PACF identification is not a mechanical rule: multiple nearby models (e.g., p \u2208 {",
        paste(unique(pmax(0, c(p_hint-1, p_hint, p_hint+1))), collapse = ", "),
        "} and q \u2208 {",
        paste(unique(pmax(0, c(q_hint-1, q_hint, q_hint+1))), collapse = ", "),
        "}, with small seasonal orders) should be compared using information criteria (AIC/AICc/BIC), ",
        "residual whiteness tests (Ljungâ€“Box), and out-of-sample accuracy to select the simplest model that yields approximately white-noise residuals and stable forecasts."
      )
      
      
      
      tagList(
        tags$p(tags$b("Academic interpretation & SARIMA guidance. "), paragraph)
      )
      
    })
    
    

    
    output$manual_report_acf_pacf_interpretation2 <- renderUI({
      req(manual_conclusion_full_obj())
      req(ts_train_test(), prepared())
      
      s_obj <- ts_train_test()
      p <- prepared()
      
      # ----------------------------
      # 1) Build working series
      # ----------------------------
      y <- as.numeric(s_obj$ts_train)
      y <- y[is.finite(y)]
      
      s_use <- if (is.null(input$s) || is.na(input$s)) p$freq else as.integer(input$s)
      
      y_mod <- apply_sarima_diffs_report(y, d = input$d, D = input$D, s = s_use)
      y_mod <- as.numeric(y_mod)
      y_mod <- y_mod[is.finite(y_mod)]
      
      validate(need(length(y_mod) >= 10,
                    "Not enough observations after differencing to interpret ACF/PACF (need â‰¥ 10)."))
      
      # ----------------------------
      # 2) Compute ACF/PACF
      # ----------------------------
      lag_max <- min(60L, length(y_mod) - 1L)
      acf_obj  <- stats::acf(y_mod, plot = FALSE, lag.max = lag_max)
      pacf_obj <- stats::pacf(y_mod, plot = FALSE, lag.max = lag_max)
      
      acf_vals  <- as.numeric(acf_obj$acf)[-1]  # drop lag 0
      pacf_vals <- as.numeric(pacf_obj$acf)
      lags <- seq_len(lag_max)
      
      n_eff <- length(y_mod)
      conf <- 1.96 / sqrt(n_eff)
      
      sig_acf  <- which(abs(acf_vals)  > conf)
      sig_pacf <- which(abs(pacf_vals) > conf)
      
      first_sig_acf  <- if (length(sig_acf))  sig_acf[1]  else NA_integer_
      first_sig_pacf <- if (length(sig_pacf)) sig_pacf[1] else NA_integer_
      
      # ----------------------------
      # 3) Seasonal spike detection
      # ----------------------------
      seasonal_lags <- if (is.finite(s_use) && s_use >= 2) {
        seq.int(from = s_use, to = lag_max, by = s_use)
      } else integer(0)
      
      sig_season_acf  <- intersect(sig_acf, seasonal_lags)
      sig_season_pacf <- intersect(sig_pacf, seasonal_lags)
      
      # Exclude seasonal multiples when guessing NON-seasonal p/q
      nonseason_sig_acf  <- setdiff(sig_acf, seasonal_lags)
      nonseason_sig_pacf <- setdiff(sig_pacf, seasonal_lags)
      
      # ----------------------------
      # 4) Improved cutoff heuristic for p/q
      #    - allows starting at lag 1 OR lag 2
      #    - ignores late isolated spikes
      # ----------------------------
      guess_cutoff_soft <- function(sig_idx, max_k = 10L, allow_start = 2L) {
        sig_idx <- sort(unique(sig_idx))
        sig_idx <- sig_idx[sig_idx <= max_k]
        
        if (length(sig_idx) == 0) return(0L)
        
        # Start at 1 if possible; otherwise allow start at 2 (or allow_start)
        start <- if (1L %in% sig_idx) 1L else if (allow_start %in% sig_idx) allow_start else sig_idx[1]
        
        # If earliest significant lag is "too late", no clear cutoff pattern
        if (start > allow_start) return(0L)
        
        k <- start
        while ((k + 1L) <= max_k && (k + 1L) %in% sig_idx) k <- k + 1L
        
        as.integer(k)
      }
      
      p_hint <- guess_cutoff_soft(nonseason_sig_pacf, max_k = 10L, allow_start = 2L)
      q_hint <- guess_cutoff_soft(nonseason_sig_acf,  max_k = 10L, allow_start = 2L)
      
      # ----------------------------
      # 5) Seasonal P/Q heuristic (keep simple, robust)
      #    - seasonal AR: PACF spike(s) at s, 2s
      #    - seasonal MA: ACF spike(s)  at s, 2s
      # ----------------------------
      P_hint <- 0L
      Q_hint <- 0L
      if (length(seasonal_lags)) {
        P_hint <- sum(sig_season_pacf %in% c(s_use, 2L * s_use))
        Q_hint <- sum(sig_season_acf  %in% c(s_use, 2L * s_use))
        P_hint <- min(P_hint, 2L)
        Q_hint <- min(Q_hint, 2L)
      }
      
      # ----------------------------
      # 6) Differencing sanity flags
      # ----------------------------
      overdiff_flag <- is.finite(acf_vals[1]) && acf_vals[1] < -conf
      slow_decay_flag <- {
        sum(abs(acf_vals[1:min(12, length(acf_vals))]) > conf, na.rm = TRUE) >= 6
      }
      
      fmt_lags <- function(v) {
        if (length(v) == 0) "none" else paste(v, collapse = ", ")
      }
      
      cand_p <- unique(pmax(0, c(p_hint - 1L, p_hint, p_hint + 1L)))
      cand_q <- unique(pmax(0, c(q_hint - 1L, q_hint, q_hint + 1L)))
      
      # ----------------------------
      # 7) Teaching narrative
      # ----------------------------
      intro_txt <- paste0(
        "Figure F presents the ACF and PACF of the training series after applying the current differencing settings ",
        "(d = ", input$d, ", D = ", input$D, ", seasonal period s = ", s_use, "). ",
        "These plots guide SARIMA identification because the ACF summarizes correlations across lags, while the PACF summarizes partial correlations after controlling intermediate lags. ",
        "Using the approximate 95% bounds (Â±1.96/âˆšn â‰ˆ Â±", sprintf("%.3f", conf), "), the differenced series shows ",
        length(sig_acf), " significant ACF spike(s) and ", length(sig_pacf), " significant PACF spike(s) up to lag ", lag_max, ". ",
        if (is.finite(first_sig_acf))  paste0("The first significant ACF spike occurs at lag ", first_sig_acf, ". ") else "",
        if (is.finite(first_sig_pacf)) paste0("The first significant PACF spike occurs at lag ", first_sig_pacf, ". ") else ""
      )
      
      main_guidance <- paste0(
        "Heuristic identification (initial candidates): an AR(p) component is often suggested when the PACF cuts off after a few early lags while the ACF tapers, ",
        "and an MA(q) component is often suggested when the ACF cuts off while the PACF tapers. ",
        "Using a robust early-lag heuristic (allowing a start at lag 1 or 2), a reasonable starting point is p â‰ˆ ", p_hint,
        " (from PACF) and q â‰ˆ ", q_hint, " (from ACF), computed from non-seasonal lags only. ",
        "These values should be treated as candidate specifications to be validated using diagnostics and forecasting performance."
      )
      
      seasonal_guidance <- if (length(seasonal_lags)) {
        paste0(
          "Seasonal lags occur at multiples of s = ", s_use, ". ",
          "Detected significant seasonal spikes: ACF seasonal lags = {", fmt_lags(sig_season_acf), "} and PACF seasonal lags = {", fmt_lags(sig_season_pacf), "}. ",
          "Interpretation: spikes in the ACF at lag s typically motivate a seasonal MA term (Q > 0), while spikes in the PACF at lag s motivate a seasonal AR term (P > 0). ",
          "Accordingly, a practical starting guess is P â‰ˆ ", P_hint, " and Q â‰ˆ ", Q_hint, " (often 0â€“2 in applied work)."
        )
      } else {
        "Seasonal interpretation is limited because s < 2 (or not finite), so seasonal lags cannot be evaluated reliably."
      }
      
      sanity_checks <- paste0(
        if (overdiff_flag) {
          "The lag-1 ACF is strongly negative beyond the confidence bounds, which is a classic warning sign of over-differencing. "
        } else "",
        if (slow_decay_flag) {
          "The ACF exhibits slow decay with many significant early lags, suggesting remaining persistence and a possible need to revisit differencing (increase d and/or D) or seasonal handling. "
        } else "",
        if (!overdiff_flag && !slow_decay_flag) {
          "No strong over-/under-differencing warning signs were detected by these simple heuristics; proceed to AR/MA order exploration and residual diagnostics."
        } else ""
      )
      
      model_selection <- paste0(
        "Recommended candidate search: start simple and iterate. Try p âˆˆ {", paste(cand_p, collapse = ", "),
        "} and q âˆˆ {", paste(cand_q, collapse = ", "),
        "} with small seasonal orders (P and Q typically 0â€“2). ",
        "Compare candidate models using information criteria (AIC/AICc/BIC), then confirm adequacy using residual diagnostics ",
        "(residual ACF/PACF and Ljungâ€“Box). If a test set exists, also compare out-of-sample accuracy. ",
        "Select the simplest model that yields approximately white-noise residuals and stable forecasts."
      )
      
      # ----------------------------
      # 8) More explicit What-to-do-next
      # ----------------------------
      has_seasonality_signal <- length(sig_season_acf) > 0 || length(sig_season_pacf) > 0
      low_lag_signal <- any(nonseason_sig_acf %in% 1:5) || any(nonseason_sig_pacf %in% 1:5)
      
      d_rec <- input$d
      D_rec <- input$D
      
      if (overdiff_flag) {
        d_rec <- max(0L, input$d - 1L)
        if (input$D > 0 && !has_seasonality_signal) D_rec <- max(0L, input$D - 1L)
      } else if (slow_decay_flag) {
        if (!has_seasonality_signal) {
          d_rec <- min(2L, input$d + 1L)
        } else {
          D_rec <- min(1L, input$D + 1L)
        }
      }
      
      p_grid <- sort(unique(pmax(0L, c(p_hint - 1L, p_hint, p_hint + 1L))))
      q_grid <- sort(unique(pmax(0L, c(q_hint - 1L, q_hint, q_hint + 1L))))
      P_grid <- sort(unique(pmax(0L, c(P_hint - 1L, P_hint, P_hint + 1L))))
      Q_grid <- sort(unique(pmax(0L, c(Q_hint - 1L, Q_hint, Q_hint + 1L))))
      
      P_grid <- P_grid[P_grid <= 2L]
      Q_grid <- Q_grid[Q_grid <= 2L]
      if (length(P_grid) == 0) P_grid <- 0L
      if (length(Q_grid) == 0) Q_grid <- 0L
      if (!has_seasonality_signal) {
        P_grid <- 0L
        Q_grid <- 0L
      }
      
      fmt_set <- function(v) paste(v, collapse = ", ")
      fmt_pairs <- function(mat) paste0("(", mat[, 1], ", ", mat[, 2], ")", collapse = "; ")
      
      try_first_nonseasonal <- unique(rbind(
        c(p_hint, q_hint),
        c(max(0L, p_hint - 1L), q_hint),
        c(p_hint, max(0L, q_hint - 1L)),
        c(pmin(5L, p_hint + 1L), q_hint),
        c(p_hint, pmin(5L, q_hint + 1L))
      ))
      
      try_first_seasonal <- unique(rbind(
        c(P_hint, Q_hint),
        c(0L, Q_hint),
        c(P_hint, 0L)
      ))
      try_first_seasonal[, 1] <- pmin(2L, pmax(0L, try_first_seasonal[, 1]))
      try_first_seasonal[, 2] <- pmin(2L, pmax(0L, try_first_seasonal[, 2]))
      if (!has_seasonality_signal) try_first_seasonal <- matrix(c(0L, 0L), ncol = 2)
      
      if (overdiff_flag) {
        next_steps_header <- "What to do next (Actionable steps â€” over-differencing suspected)."
        next_steps <- c(
          paste0(
            "Adjust differencing first: try (d, D) = (", d_rec, ", ", D_rec, ") ",
            "(current: d = ", input$d, ", D = ", input$D, "). Recompute ACF/PACF after this change."
          ),
          paste0(
            "Then test a small non-seasonal grid based on the early-lag cluster: p âˆˆ {", fmt_set(p_grid),
            "}, q âˆˆ {", fmt_set(q_grid), "}. Try-first (p,q): ", fmt_pairs(try_first_nonseasonal), "."
          ),
          paste0(
            "Only add seasonal terms if seasonal spikes persist: at s = ", s_use,
            ", test P âˆˆ {", fmt_set(P_grid), "}, Q âˆˆ {", fmt_set(Q_grid),
            "} (try-first (P,Q): ", fmt_pairs(try_first_seasonal), ")."
          ),
          "Confirm the final choice using residual ACF/PACF, Ljungâ€“Box p-values, and holdout forecast accuracy (if available)."
        )
      } else if (slow_decay_flag) {
        next_steps_header <- "What to do next (Actionable steps â€” remaining persistence suspected)."
        next_steps <- c(
          paste0(
            "Revise differencing and reassess: try (d, D) = (", d_rec, ", ", D_rec,
            ") (current: d = ", input$d, ", D = ", input$D, "). Then recompute ACF/PACF."
          ),
          paste0(
            "After persistence is reduced, test non-seasonal candidates: p âˆˆ {", fmt_set(p_grid),
            "}, q âˆˆ {", fmt_set(q_grid), "}. Try-first (p,q): ", fmt_pairs(try_first_nonseasonal), "."
          ),
          if (has_seasonality_signal) {
            paste0(
              "Because seasonal spikes are present, include seasonal candidates at s = ", s_use,
              ": P âˆˆ {", fmt_set(P_grid), "}, Q âˆˆ {", fmt_set(Q_grid),
              "} (try-first (P,Q): ", fmt_pairs(try_first_seasonal), ")."
            )
          } else {
            "Seasonal spikes are not prominent; start with (P,Q) = (0,0) and add seasonal terms only if residual diagnostics show seasonal structure."
          },
          "Select the most parsimonious model that yields approximately white-noise residuals and stable forecasts."
        )
      } else if (has_seasonality_signal && !low_lag_signal) {
        next_steps_header <- "What to do next (Actionable steps â€” mainly seasonal structure indicated)."
        next_steps <- c(
          paste0("Keep differencing as-is for now: (d, D) = (", input$d, ", ", input$D, ")."),
          paste0(
            "Prioritize seasonal orders at s = ", s_use, ": test P âˆˆ {", fmt_set(P_grid),
            "}, Q âˆˆ {", fmt_set(Q_grid), "} (try-first (P,Q): ", fmt_pairs(try_first_seasonal), ")."
          ),
          paste0(
            "Keep non-seasonal orders simple: start with (p,q) = (", p_hint, ", ", q_hint,
            ") and expand within p âˆˆ {", fmt_set(p_grid), "}, q âˆˆ {", fmt_set(q_grid), "} only if low-lag residual spikes remain."
          ),
          "Refit and confirm improvements at seasonal multiples in the residual ACF and via Ljungâ€“Box p-values."
        )
      } else if (low_lag_signal && !has_seasonality_signal) {
        next_steps_header <- "What to do next (Actionable steps â€” mainly short-run AR/MA structure indicated)."
        next_steps <- c(
          paste0("Keep differencing unchanged: (d, D) = (", input$d, ", ", input$D, ")."),
          paste0(
            "Focus on non-seasonal orders: test p âˆˆ {", fmt_set(p_grid), "}, q âˆˆ {", fmt_set(q_grid),
            "}. Try-first (p,q): ", fmt_pairs(try_first_nonseasonal), "."
          ),
          "Keep seasonal orders at (P,Q) = (0,0) initially; add seasonal terms only if seasonal spikes appear in the residual diagnostics.",
          "Choose the simplest model that yields white-noise residuals and improves holdout accuracy."
        )
      } else {
        next_steps_header <- "What to do next (Actionable steps â€” standard candidate testing)."
        next_steps <- c(
          paste0("Keep differencing as currently specified: (d, D) = (", input$d, ", ", input$D, ")."),
          paste0(
            "Start with non-seasonal candidates around the heuristic: p âˆˆ {", fmt_set(p_grid), "}, q âˆˆ {", fmt_set(q_grid),
            "}; begin at (p,q) = (", p_hint, ", ", q_hint, ") and try-first: ", fmt_pairs(try_first_nonseasonal), "."
          ),
          if (has_seasonality_signal) {
            paste0(
              "Add seasonal candidates at s = ", s_use, ": P âˆˆ {", fmt_set(P_grid), "}, Q âˆˆ {", fmt_set(Q_grid),
              "}; start at (P,Q) = (", P_hint, ", ", Q_hint, ") and try-first: ", fmt_pairs(try_first_seasonal), "."
            )
          } else {
            "Start with seasonal orders (P,Q) = (0,0) and only add seasonal terms if residual diagnostics show seasonal spikes."
          },
          "Compare models using AIC/AICc/BIC, then confirm adequacy using residual ACF/PACF and Ljungâ€“Box; prefer the simplest model with stable forecasting."
        )
      }
      
      # ----------------------------
      # 9) Render callout
      # ----------------------------
      callout(
        tagList(
          tags$p(tags$b("Academic interpretation & SARIMA guidance. "), intro_txt),
          
          tags$ul(
            style = "list-style-type:square; padding-left: 18px; line-height: 1.5;",
            tags$li(tags$b("Reading ACF/PACF for (p, q): "), main_guidance),
            tags$li(tags$b("Seasonal orders (P, Q) at multiples of s: "), seasonal_guidance),
            tags$li(tags$b("Differencing sanity checks (d, D): "), sanity_checks),
            tags$li(tags$b("Practical parameter-selection workflow: "), model_selection)
          ),
          
          tags$br(),
          tags$p(tags$b(next_steps_header)),
          tags$ol(
            style = "padding-left: 18px; line-height: 1.5;",
            lapply(next_steps, tags$li)
          )
        ),
        title = "Academic interpretation",
        theme = "blue",
        body_is_html = FALSE
      )
    })
    
    
 
    
    
    # ---------- build report UI (NO output$ definitions here)
    tagList(
      tags$h3("Manual SARIMA: Full academic conclusion (report-ready)"),
      
      # 1. Objective and modelling rationale
      tags$hr(), tags$br(),
      tags$h4(tags$strong("1. Objective, modelling philosophy, and Boxâ€“Jenkins framework")),
      callout(
        tagList(
          tags$p(
            "This analysis adopts the classical ",
            tags$b("Boxâ€“Jenkins methodology"),
            " to construct a manually specified seasonal ARIMA (SARIMA) model for the training series. ",
            "The primary objective is to model linear temporal dependenceâ€”including recurring seasonal patternsâ€”",
            "in a statistically principled, interpretable, and diagnostically transparent manner, ",
            "while providing a reliable foundation for forecasting."
          ),
          
          tags$p(
            "The Boxâ€“Jenkins approach is a systematic, likelihood-based framework for time-series modelling ",
            "that emphasizes iterative learning from the data. ",
            "Rather than treating model selection as a purely algorithmic exercise, ",
            "it combines statistical testing, graphical diagnostics, and parsimony considerations ",
            "to arrive at a model whose assumptions are empirically defensible."
          ),
          
          tags$p(
            "A central principle of the Boxâ€“Jenkins methodology is that valid statistical inference ",
            "and forecasting require a stationary working series. ",
            "Accordingly, transformations and differencing are applied first to remove stochastic trends ",
            "and seasonal persistence, after which short-memory dependence is modelled through ",
            "autoregressive (AR) and moving-average (MA) components."
          ),
          
          tags$p(tags$b("Within this framework, SARIMA modelling proceeds through the following ordered steps:")),
          
          tags$ol(
            style = "padding-left: 18px; line-height: 1.6;",
            
            tags$li(
              tags$b("Preliminary analysis and stationarity assessment. "),
              "Inspect the raw series using time plots and summary statistics, ",
              "apply variance-stabilizing transformations if needed, ",
              "and evaluate stationarity using unit-root and stationarity tests. ",
              "Non-seasonal (d) and seasonal (D) differencing are chosen to remove long-run ",
              "and seasonal persistence while avoiding over-differencing."
            ),
            
            tags$li(
              tags$b("Model identification. "),
              "Examine the ACF and PACF of the differenced series to propose candidate ",
              "non-seasonal orders (p, q) and seasonal orders (P, Q) at multiples of the seasonal period s. ",
              "Identification focuses on recognizing cutoff and decay patterns ",
              "consistent with AR and MA dynamics."
            ),
            
            tags$li(
              tags$b("Parameter estimation. "),
              "Estimate candidate SARIMA models using maximum likelihood, ",
              "assessing parameter significance, numerical stability, and overall fit. ",
              "Competing specifications are compared using information criteria ",
              "such as AIC, AICc, or BIC."
            ),
            
            tags$li(
              tags$b("Diagnostic checking. "),
              "Evaluate whether the fitted model adequately captures the dependence structure ",
              "by inspecting residual time plots, residual ACF/PACF, Ljungâ€“Box tests for autocorrelation, ",
              "normality diagnostics, and tests for conditional heteroskedasticity. ",
              "A satisfactory model yields residuals that behave approximately as white noise."
            ),
            
            tags$li(
              tags$b("Iteration and refinement. "),
              "If diagnostics indicate remaining structure or violations of assumptions, ",
              "revise differencing choices or AR/MA orders and repeat the identificationâ€“",
              "estimationâ€“diagnostic cycle until an adequate and parsimonious specification is obtained."
            ),
            
            tags$li(
              tags$b("Forecasting and validation. "),
              "Once a final model is selected, generate forecasts and assess predictive performance ",
              "using holdout samples or rolling-origin evaluation. ",
              "Forecast accuracy and stability provide the final validation of model adequacy."
            )
          ),
          
          tags$p(
            "By implementing the Boxâ€“Jenkins methodology explicitly, this report emphasizes ",
            "interpretability, diagnostic rigor, and methodological transparency. ",
            "This approach is particularly valuable in an academic and teaching context, ",
            "as each modelling decision can be traced back to observable features of the data ",
            "and formal statistical evidence."
          )
        ),
        title = "Objective, modelling philosophy, and Boxâ€“Jenkins framework",
        theme = "red",
        body_is_html = FALSE
      ),

      
      
      
      # 2. Data design and sample split
      tags$hr(), tags$br(),
      tags$h4(tags$strong("2. Data design and sample split")),
      tags$p(HTML(paste0(
        "The analysis used <b>N = ", N, "</b> observations (training <b>n = ", n_train, "</b>",
        if (has_test) paste0(", test <b>n = ", n_test, "</b>") else "",
        ")."
      ))),
      tags$p(tags$b("Forecast design. "), horizon_txt),
      
      # 3. Identification visuals (time series + ACF/PACF)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("3. Identification visuals (time series + ACF/PACF)")),
      tags$p(
        "The plots below summarize the observed series (with the train/test split, if applicable), ",
        "followed by ACF/PACF for the training series and for the differenced series implied by the chosen (d, D, s)."
      ),
      
      tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure A. Time series with split marker")),
      plotOutput("manual_report_ts_plot", height = 360),
      
      # 4. Stationarity assessment (ADF, KPSS, and Phillipsâ€“Perron)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("4. Stationarity assessment (ADF, KPSS, and Phillipsâ€“Perron)")),
      tags$p("Stationarity tests were applied to the training series to evaluate whether differencing is required before SARIMA identification and estimation."),
      tags$hr(),
      uiOutput("manual_report_stationarity"),
      
      # 5. Transformed series: differencing and seasonality
      tags$hr(), tags$br(),
      tags$h4(tags$strong("5. Transformed series: differencing and seasonality")),
      
      tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure B. Seasonal subseries")),
      plotOutput("manual_report_subseries", height = 360),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure C. Seasonal box-plot")),
      plotOutput("manual_report_seasonal_box", height = 360),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure D. Transformed training series and differenced (d, D, s) series")),
      plotOutput("manual_report_ts_trans_and_diff", height = 360),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure E. ACF and PACF (training series)")),
      fluidRow(
        column(6, plotOutput("manual_report_acf",  height = 280)),
        column(6, plotOutput("manual_report_pacf", height = 280))
      ),
      

      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Figure F. ACF and PACF (modified / differenced series using current d, D, s)")),
      fluidRow(
        column(6, plotOutput("manual_report_acf_mod",  height = 280)),
        column(6, plotOutput("manual_report_pacf_mod", height = 280))
      ),
      
      uiOutput("manual_report_acf_pacf_interpretation2"),
      
      tags$hr(), tags$br(),
      uiOutput("manual_report_stationarity_mod"),
      tags$hr(), tags$br(),
      uiOutput("manual_report_stationarity_mod2"),
      
      # 6. Final model specification and fit quality
      tags$hr(), tags$br(),
      tags$h4(tags$strong("6. Final model specification and fit quality")),
      tags$p(HTML(paste0(
        "The final manual specification was <b>", model_str, "</b>",
        if (isTRUE(input$manual_drift)) " including drift/mean." else " without drift/mean.",
        " Model adequacy was assessed using information criteria, coefficient inference, residual diagnostics, and forecast performance."
      ))),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Table A. Goodness-of-fit (information criteria)")),
      html_table(ic_df),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Table B. Parameter estimates and significance (approx. z/t tests)")),
      if (!is.null(coef_df)) html_table(coef_df) else tags$em("No coefficients available."),
      tags$p(HTML(paste0(
        "In total, <b>", n_sig, "</b> parameter(s) were significant at Î± = .05 (marked by *, **, ***)."
      ))),
      
      # 7. Model equations (replication-ready)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("7. Model equations (replication-ready)")),
      tags$p(
        "The fitted model is reported below in operator notation (general form), expanded form, and the numerical equation",
        " based on the estimated parameters."
      ),
      tags$div(
        style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;",
        
        tags$br(), tags$hr(), tags$hr(),
        tags$h5("General SARIMA formulation"),
        HTML(eq$eq_general),
        
        tags$br(), tags$hr(), tags$hr(),
        tags$h5("Expanded operator form"),
        HTML(eq$eq_expanded),
        
        tags$br(), tags$hr(), tags$hr(),
        tags$h5("Numerical model"),
        HTML(eq$eq_line3),
        
        tags$br(), tags$hr(), tags$hr(),
        HTML(eq$eq_line4),
        
        tags$br(), tags$hr(), tags$hr()
      ),
      
      # 8. Residual diagnostics (graphical evidence)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("8. Residual diagnostics (graphical evidence)")),
      tags$p(
        "Graphical diagnostics evaluate whether residuals resemble white noise (no systematic autocorrelation),",
        " approximate normality (Qâ€“Q and histogram), and stable variance."
      ),
      
      fluidRow(
        column(6, plotOutput("manual_resid_ts",   height = 280)),
        column(6, plotOutput("manual_resid_acf",  height = 280))
      ),
      fluidRow(
        column(6, plotOutput("manual_resid_hist", height = 280)),
        column(6, plotOutput("manual_resid_qq",   height = 280))
      ),
      
      tags$h5("Ljungâ€“Box p-values by lag"),
      plotOutput("manual_resid_lb_pvals", height = 280),
      uiOutput("manual_resid_lb_pvals_conclusion"),
      
      # 9. Residual tests (formal inference)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("9. Residual tests (formal inference)")),
      tags$p(
        "Formal tests complement the plots: Ljungâ€“Box/Boxâ€“Pierce assess remaining autocorrelation;",
        " Jarqueâ€“Bera/Shapiroâ€“Wilk/Andersonâ€“Darling assess normality;",
        " ARCH LM tests conditional heteroskedasticity; the runs test checks randomness."
      ),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Table C. Residual test summary")),
      html_table(tests_df),
      
      callout(diag_verdict,
              title = "Diagnostic synthesis. ",
              theme = "blue",
              body_is_html = TRUE
      ),
      

      # 10. Forecasting results and predictive performance
      tags$hr(), tags$br(),
      tags$h4(tags$strong("10. Forecasting results and predictive performance")),
      tags$p(acc_sentence),
      
      if (!is.null(acc_df)) tagList(
        tags$h5("Table D. Holdout accuracy (test set)"),
        html_table(acc_df)
      ) else NULL,
      
      tags$hr(),  tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Forecast plot")),
      # plotOutput("manual_forecast_plot", height = 420),
      plotOutput("manual_forecast_plot_concl", height = 420),
      
      tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Forecast table")),
      # tableOutput("manual_forecast_table"),
      
      tableOutput("manual_forecast_table_concl"),
      # DT::dataTableOutput("manual_forecast_table_concl"),
     
       tags$hr(), tags$br(),
      tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Accuracy table (your app output)")),
      # tableOutput("manual_accuracy_table"),
      tableOutput("manual_accuracy_table_concl"),

      # ---------- Back-transformed forecasts (original scale) + plot placeholder
      tags$hr(), tags$br(),
      tags$h4(tags$strong("10.B Back-transformed forecasts (original scale)")),
      if (!identical(tr_global, "none")) tagList(
        tags$p("Because the model was estimated on the transformed series, forecasts are reported below on the original measurement scale using an appropriate bias adjustment for the point forecasts."),
        tags$div(
          style = "padding:10px;border:1px solid #e5e5e5;border-radius:6px;background:#fcfcfc;",
          tags$h5("Inverse transform equation (simple form)"),
          inv_equation_html,
          tags$br(),
          inv_note_html
        ),
        
        tags$hr(), tags$br(),
        tags$h5(strong(" \u00A0\u00A0 \u25A0 \u00A0 Original-scale plot (observed + forecast + CIs)")),
        # NOTE: you must define output$manual_forecast_plot_original <- renderPlot(...) elsewhere in server
        plotOutput("manual_forecast_plot_original", height = 420),
        
        tags$hr(), tags$br(),
        tags$h5("Back-transformed forecast table (original scale)"),
        html_table(fc_orig_df_fmt)
      ) else tags$em("No transformation was applied; forecasts are already on the original scale."),
      
      # 11. Final conclusion (academic)
      tags$hr(), tags$br(),
      tags$h4(tags$strong("11. Final conclusion")),
      tags$p(
        "Overall, the manually specified SARIMA model provides a coherent and interpretable representation of seasonal linear dynamics,",
        " supported by information criteria, statistically interpretable parameters, and diagnostic checks.",
        " When diagnostics indicate remaining autocorrelation, refinement should prioritize revising differencing (d, D) and AR/MA orders guided by ACF/PACF and Ljungâ€“Box.",
        " When conditional heteroskedasticity is detected (ARCH LM), a volatility model (e.g., GARCH) should be added to the mean equation to better represent time-varying variance."
      ),
      tags$p(
        "For reporting, the results above provide the full chain of evidence typically expected in academic manuscripts:",
        " (i) specification + IC, (ii) parameter inference, (iii) equation reporting, (iv) residual validation with plots and tests, and (v) forecasting with accuracy assessment."
      ),
      
      tags$br(), tags$hr(), tags$br(), tags$br()
    )
  })
  
  
  
  
  
  
  
  
  # IMPORTANT: renderUI wrapper + MathJax re-typeset (this is what makes equations show correctly)
  output$manual_conclusion_full <- renderUI({
    ui <- manual_conclusion_full_obj()
    
    # Re-typeset MathJax after the UI is inserted into the DOM
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "manual_conclusion_box")
    }, once = TRUE)
    
    ui
  })
  
  
  
  output$manual_conclusion_full <- renderUI({
    validate(need(input$fit_manual > 0, "Click â€œFitâ€ in the Manual tab to generate the full academic conclusion."))
    req(manual_conclusion_full_obj())
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "manual_conclusion_box")
    }, once = TRUE)
    
    manual_conclusion_full_obj()
  })
  
  
  
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  #================================================================================================
  
  
  
  

  # ---- Step 7 Comparison & Paper builder ----

  comparison <- reactive({
    s <- ts_train_test()
    out <- data.frame(Model = character(0), AICc = numeric(0), BIC = numeric(0), Test_RMSE = numeric(0), Test_MAE = numeric(0), stringsAsFactors = FALSE)

    if (!is.null(input$fit_auto)) {
      fit <- tryCatch(auto_fit(), error = function(e) NULL)
      if (!is.null(fit)) {
        rmse <- NA_real_; mae <- NA_real_
        if (s$test_n > 0) {
          acc <- accuracy_df(s$ts_test, auto_fc()$fc$mean)
          rmse <- acc$Value[acc$Metric == "RMSE"]
          mae <- acc$Value[acc$Metric == "MAE"]
        }
        out <- rbind(out, data.frame(Model = "Auto-ARIMA", AICc = fit$aicc, BIC = fit$bic, Test_RMSE = rmse, Test_MAE = mae))
      }
    }

    if (!is.null(input$fit_manual)) {
      fit <- tryCatch(manual_fit(), error = function(e) NULL)
      if (!is.null(fit)) {
        rmse <- NA_real_; mae <- NA_real_
        if (s$test_n > 0) {
          acc <- accuracy_df(s$ts_test, manual_fc()$fc$mean)
          rmse <- acc$Value[acc$Metric == "RMSE"]
          mae <- acc$Value[acc$Metric == "MAE"]
        }
        out <- rbind(out, data.frame(Model = "Manual SARIMA", AICc = fit$aicc, BIC = fit$bic, Test_RMSE = rmse, Test_MAE = mae))
      }
    }
    out
  })

  output$comparison_table <- renderTable({
    df <- comparison()
    if (nrow(df) == 0) return(data.frame(message = "Fit Auto-ARIMA and/or Manual SARIMA to compare models."))
    df
  }, rownames = FALSE)

  output$comparison_interpretation <- renderPrint({
    df <- comparison()
    if (nrow(df) == 0) { cat("Fit models first to generate comparison interpretation.\n"); return() }
    cat("Interpretation guide:\n")
    cat("- Lower AICc/BIC indicates better in-sample trade-off (fit vs complexity).\n")
    cat("- Lower RMSE/MAE indicates better holdout forecast accuracy.\n\n")
    best <- df[order(df$Test_RMSE, df$AICc, na.last = TRUE), , drop = FALSE]
    cat("Top-ranked (by RMSE then AICc):", best$Model[1], "\n")
  })

  output$apa_methods_draft <- renderPrint({
    req(prepared())
    p <- prepared()
    df <- p$df
    n <- nrow(df)
    cat(
      "Methods (APA draft â€” edit names/unit and add study context):\n\n",
      "Time series analyses were conducted using R. The series consisted of ", n, " observations spanning ",
      format(min(df$date)), " to ", format(max(df$date)), " with a seasonal period of s = ", p$freq, ". ",
      "Missing values were handled using the ", input$missing_policy, " method. ",
      "Stationarity was assessed using the Augmented Dickeyâ€“Fuller (ADF), KPSS, and Phillipsâ€“Perron tests, and differencing decisions were informed by these tests alongside visual inspection of differenced series plots. ",
      "Seasonal ARIMA models were estimated using maximum likelihood as implemented in the forecast package.\n",
      sep = ""
    )
  })

  output$apa_results_draft <- renderPrint({
    cat(
      "Results (APA draft â€” refine after you finalize the model):\n\n",
      "Exploratory analysis suggested trend and seasonal dynamics in the series, motivating the evaluation of seasonal ARIMA models. ",
      "Model adequacy was evaluated via residual diagnostics, including the Ljungâ€“Box test for residual autocorrelation and additional normality and heteroskedasticity checks when available. ",
      "Forecast performance was evaluated using holdout accuracy metrics (e.g., RMSE and MAE) when a test set was available. ",
      "The final model specification, diagnostics, and forecast results are reported in the corresponding panels.\n",
      sep = ""
    )
  })

  observeEvent(input$refresh_all, { invisible(NULL) })
  
  
  
  
  
  
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  #
  #                          - D?d?log? -
  #
  # ====================================================================
  # ====================================================================
  # ==================================================================== 
  
  
  
  # helper used below (safe defaulting)
  # `%||%` <- function(a, b) if (is.null(a) || is.na(a) || identical(a, "")) b else a
  
  
  # ============================================================================
  # 0) SMALL HELPERS (safe input fallback + safe numeric)
  # ============================================================================
  `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0 && !all(is.na(a))) a else b
  to_num_safe <- function(v, default = NA_real_) {
    out <- suppressWarnings(as.numeric(v))
    if (length(out) == 0 || all(is.na(out)) || !is.finite(out[1])) default else out[1]
  }
  
  getPlotDim <- function(x, default = "100%") {
    if (is.null(x) || is.na(x) || identical(x, "")) return(default)
    if (is.numeric(x)) return(paste0(x, "px"))
    # accept strings like "800" or "100%" or "800px"
    xs <- as.character(x)
    if (grepl("^[0-9]+$", xs)) return(paste0(xs, "px"))
    xs
  }
  
  

  
  # helper: map input$plot_theme -> a ggplot2 theme object
  theme_picker <- function(key = "Minimal") {
    switch(key,
           "Minimal" = ggplot2::theme_minimal(),
           "Classic" = ggplot2::theme_classic(),
           "Light"   = ggplot2::theme_light(),
           "Dark"    = ggplot2::theme_dark(),
           "BW"      = ggplot2::theme_bw(),
           "Void"    = ggplot2::theme_void(),
           # default
           ggplot2::theme_gray()
    )
  }
  
  # common theming applied to ggplot objects
  add_theme <- function(g) {
    g +
      theme_picker(input$plot_theme) +
      ggplot2::theme(
        axis.text  = ggplot2::element_text(size = input$tickSize),
        axis.title = ggplot2::element_text(size = input$tickSize + 2),
        plot.title = ggplot2::element_text(hjust = 0.5)
      )
  }
  
  
  
  
  # Map the log checkbox to a simple flag
  values <- reactiveValues(islog = "No")
  observe({
    values$islog <- if (isTRUE(input$check_box)) "Yes" else "No"
  })
  
  # Core transformation helper (log, then D, then d)
  getMyData <- function(tsData, frequency, islog = "No", d_n = 0, DS_n = 0) {
    shiny::req(tsData)
    freq <- as.numeric(frequency)
    d_n  <- as.numeric(d_n)
    DS_n <- as.numeric(DS_n)
    
    working_ts <- if (identical(islog, "Yes")) log(tsData) else tsData
    
    # Seasonal differencing (D)
    if (!is.na(DS_n) && DS_n > 0 && !is.na(freq) && freq > 1) {
      working_ts <- diff(working_ts, lag = freq, differences = DS_n)
    }
    
    # Non-seasonal differencing (d)
    if (!is.na(d_n) && d_n > 0) {
      working_ts <- diff(working_ts, lag = 1, differences = d_n)
    }
    
    working_ts
  }
  
  # Base ts comes from your prepared() reactive
  # prepared() returns list(df=..., freq=..., by=..., x_label=...)
  # We'll use the filled values (before transform) to let the playground own the transforms
  ts_base <- reactive({
    p <- prepared()                                   # df/freq are defined here
    ts(p$df$y_filled, start = 1, frequency = p$freq)  # build a ts from the cleaned series
  })
  
  # Central reactive used by all (*) panels in this tab
  # ========= replace the whole myData_Choice() reactive with this =========
  myData_Choice <- reactive({
    req(prepared())
    base_ts <- ts_base()                 # full, cleaned & regularly spaced series (y_filled)
    
    # Figure out how many observations belong to the training window
    s <- ts_train_test()                 # has $train_n computed from input$train_prop
    train_n <- s$train_n
    
    # Choose full vs. training window based on the new checkbox
    if (isTRUE(input$use_train_explore) && is.finite(train_n) && train_n >= 2) {
      # keep start and frequency; truncate by index
      base_vec <- as.numeric(base_ts)
      base_vec <- base_vec[seq_len(min(train_n, length(base_vec)))]
      base_ts  <- ts(base_vec, start = start(base_ts), frequency = frequency(base_ts))
    }
    
    # Apply the Exploration controls (log / d / D) consistently to whatever window we chose
    getMyData(
      tsData    = base_ts,
      frequency = frequency(base_ts),
      islog     = values$islog,          # this already mirrors input$check_box via your observeEvent
      d_n       = input$d_n,
      DS_n      = input$DS_n
    )
  })
  
  
  

  # UI wrapper: uses textInput("plot_width"), textInput("plot_height")
  
  output$d_D_Log_ts_Choice_UI <- renderUI({
    plotOutput(
      "d_D_Log_ts_Choice",
      width  = getPlotDim(input$plot_width  %||% "800"),
      height = getPlotDim(input$plot_height %||% "500")
    )
  })
  
 
  
  # --- ggtsdisplay of the transformed series (time plot + ACF + PACF) ---
  output$d_D_Log_ts_Choice <- renderPlot({
    req(myData_Choice())
    p <- prepared()
    forecast::ggtsdisplay(
      myData_Choice(),
      main = "Diagnostics of transformed series (d/D/log)",
      xlab = p$x_label,
      ylab = "Transformed value"
    )
  }, res = 96)



  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  
  
  
  # map input$plot_theme to a ggplot theme
  theme_picker <- function(key = "Minimal") {
    switch(key,
           "Minimal" = ggplot2::theme_minimal(),
           "Classic" = ggplot2::theme_classic(),
           "Light"   = ggplot2::theme_light(),
           "Dark"    = ggplot2::theme_dark(),
           "BW"      = ggplot2::theme_bw(),
           "Void"    = ggplot2::theme_void(),
           ggplot2::theme_gray()  # default "Gray"
    )
  }
  
  # apply selected theme + common text sizes
  add_theme <- function(g) {
    g +
      theme_picker(input$plot_theme) +
      ggplot2::theme(
        axis.text  = ggplot2::element_text(size = input$tickSize),
        axis.title = ggplot2::element_text(size = input$tickSize + 2),
        plot.title = ggplot2::element_text(hjust = 0.5)
      )
  }
  
  # ---- UI wrapper so the plot can size dynamically ----
  output$tsPlot_Choice_UI <- renderUI({
    plotOutput(
      "tsPlot_Choice",
      width  = getPlotDim(input$plot_width  %||% "800"),
      height = getPlotDim(input$plot_height %||% "500")
    )
  })
  
  # ---- Color picker UI (already in your sidebar) ----
  output$ts_color_ui <- renderUI({
    tagList(
      tags$input(type = "color", id = "ts_line_color", value = "#2C7FB8"),
      tags$label("Series color", style = "color: #2C7FB8;"),
      br(), br(),
      tags$script(HTML("
      $(document).ready(function() {
        var el = document.getElementById('ts_line_color');
        if (el) Shiny.setInputValue('ts_line_color', el.value);
        $(document).on('input', '#ts_line_color', function() {
          Shiny.setInputValue(this.id, this.value);
        });
      });
    "))
    )
  })
  
 
  
  
  output$tsPlot_Choice <- renderPlot({
    req(myData_Choice())
    req(input$plot_type_choice)
    
    ts_obj <- myData_Choice()
    p      <- prepared()  # for x-axis label
    freq   <- tryCatch(stats::frequency(ts_obj), error = function(e) NA_real_)
    
    # ------------------------------------------------------------
    # ACF/PACF lag control (numericInput: St_Lag) â†’ S_Lag2
    # ------------------------------------------------------------
    S_Lag2 <- suppressWarnings(as.integer(input$St_Lag))
    if (!is.finite(S_Lag2) || S_Lag2 < 1) S_Lag2 <- 40L
    S_Lag2 <- max(1L, min(S_Lag2, length(ts_obj) - 1L))
    
    # ------------------------------------------------------------
    # âœ… DATE-AWARE helper: build plotting df using prepared()$df$x
    # and align it after differencing (d and D).
    # ------------------------------------------------------------
    df_ts <- function(z) {
      
      # base date/index from prepared()
      x_all <- p$df$x
      has_dates <- !is.null(x_all) &&
        (inherits(x_all, "Date") || inherits(x_all, "POSIXct") || inherits(x_all, "POSIXt"))
      
      # match the scope used by myData_Choice(): full vs train
      s <- ts_train_test()
      train_n <- s$train_n
      
      if (isTRUE(input$use_train_explore) && is.finite(train_n) && train_n >= 2) {
        x0 <- x_all[seq_len(min(train_n, length(x_all)))]
      } else {
        x0 <- x_all
      }
      
      # how many rows were dropped by differencing in getMyData()
      f0 <- as.numeric(p$freq)
      if (!is.finite(f0) || f0 < 1) f0 <- 1
      
      D <- suppressWarnings(as.integer(input$DS_n))
      d <- suppressWarnings(as.integer(input$d_n))
      if (!is.finite(D) || D < 0) D <- 0
      if (!is.finite(d) || d < 0) d <- 0
      
      drop_n <- 0L
      if (D > 0 && f0 > 1) drop_n <- drop_n + as.integer(D * f0)
      if (d > 0)           drop_n <- drop_n + as.integer(d)
      
      y <- as.numeric(z)
      
      if (has_dates) {
        # align x to differenced series
        if (length(x0) > drop_n) {
          x_use <- x0[(drop_n + 1L):length(x0)]
        } else {
          x_use <- x0
        }
        
        n <- min(length(x_use), length(y))
        data.frame(t = x_use[seq_len(n)], y = y[seq_len(n)])
      } else {
        data.frame(t = seq_along(y), y = y)
      }
    }
    
    k_ma  <- max(2L, as.integer(input$ma_k %||% 5))
    lag_m <- max(1L, as.integer(input$lag_m %||% 12))
    
    plt <- switch(
      input$plot_type_choice,
      
      "Line" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(
            size   = 0.9,
            colour = input$ts_line_color %||% "#2C7FB8"
          ) +
          ggplot2::labs(
            title = "Transformed series",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Points" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_point(size = 1) +
          ggplot2::labs(title = "Points", x = p$x_label, y = "Transformed value")
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Line + Points" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line() +
          ggplot2::geom_point(size = 0.9, alpha = 0.8) +
          ggplot2::labs(
            title = "Line + Points",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Smoothed (LOESS)" = {
        ddf <- df_ts(ts_obj)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(alpha = 0.4) +
          ggplot2::geom_smooth(method = "loess", se = FALSE, span = 0.2) +
          ggplot2::labs(
            title = "LOESS smooth",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Moving average" = {
        ddf <- df_ts(ts_obj)
        
        ma <- stats::filter(ddf$y, rep(1 / k_ma, k_ma), sides = 2)
        ddf$ma <- as.numeric(ma)
        
        g <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(alpha = 0.4) +
          ggplot2::geom_line(ggplot2::aes(y = ma), size = 1) +
          ggplot2::labs(
            title = sprintf("Moving average (k = %d)", k_ma),
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        apply_smart_date_axis(g, ddf)
      },
      
      "Cumulative sum" = {
        d <- df_ts(ts_obj); d$cum <- cumsum(d$y)
        ggplot2::ggplot(d, ggplot2::aes(t, cum)) +
          ggplot2::geom_line() +
          ggplot2::labs(title = "Cumulative sum", x = p$x_label, y = "Cumulative value")
      },
      
      "Seasonal plot" = {
        validate(need(is.finite(freq) && freq > 1, "Seasonal plot requires frequency > 1."))
        forecast::ggseasonplot(ts_obj, year.labels = TRUE) +
          ggplot2::labs(title = "Seasonal plot", x = p$x_label, y = "Value")
      },
      
      "Seasonal subseries" = {
        validate(need(is.finite(freq) && freq > 1, "Seasonal subseries requires frequency > 1."))
        forecast::ggsubseriesplot(ts_obj) +
          ggplot2::labs(title = "Seasonal subseries", x = p$x_label, y = "Value")
      },
      
      "Polar seasonal" = {
        validate(need(is.finite(freq) && freq > 1, "Polar seasonal requires frequency > 1."))
        forecast::ggseasonplot(ts_obj, polar = TRUE) +
          ggplot2::labs(title = "Polar seasonal plot", x = p$x_label, y = "Value")
      },
      
      "Seasonal boxplot" = {
        validate(need(is.finite(freq) && freq > 1, "Seasonal boxplot requires frequency > 1."))
        d <- if (inherits(ts_obj, "ts")) data.frame(season = stats::cycle(ts_obj), y = as.numeric(ts_obj))
        else data.frame(season = factor(1), y = as.numeric(ts_obj))
        ggplot2::ggplot(d, ggplot2::aes(x = factor(season), y = y)) +
          ggplot2::geom_boxplot() +
          ggplot2::labs(title = "Seasonal boxplot", x = "Season", y = "Value")
      },
      
      "Classical decomposition (additive)" = {
        validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
        dc <- stats::decompose(ts_obj, type = "additive")
        forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (additive)")
      },
      
      "Classical decomposition (multiplicative)" = {
        validate(need(is.finite(freq) && freq > 1, "Classical decomposition requires frequency > 1."))
        dc <- stats::decompose(ts_obj, type = "multiplicative")
        forecast::autoplot(dc) + ggplot2::labs(title = "Classical decomposition (multiplicative)")
      },
      
      "STL decomposition" = {
        validate(need(is.finite(freq) && freq > 1, "STL decomposition requires frequency > 1."))
        decomp <- stats::stl(ts_obj, s.window = "periodic")
        forecast::autoplot(decomp) + ggplot2::labs(title = "STL decomposition")
      },
      
      "Histogram" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
          ggplot2::geom_histogram(bins = 30) +
          ggplot2::labs(title = "Histogram", x = "Value", y = "Count")
      },
      
      "Density" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(x)) +
          ggplot2::geom_density() +
          ggplot2::labs(title = "Density", x = "Value", y = "Density")
      },
      
      "QQ plot" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        ggplot2::ggplot(data.frame(x = xx), ggplot2::aes(sample = x)) +
          ggplot2::stat_qq() +
          ggplot2::stat_qq_line() +
          ggplot2::labs(title = "Normal Q-Q plot", x = "Theoretical quantiles", y = "Sample quantiles")
      },
      
      "Lag-1 scatter" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        validate(need(length(xx) >= 2, "Not enough data for lag-1 scatter."))
        d <- data.frame(x = xx[-length(xx)], y = xx[-1])
        ggplot2::ggplot(d, ggplot2::aes(x, y)) +
          ggplot2::geom_point() +
          ggplot2::geom_smooth(method = "lm", se = FALSE) +
          ggplot2::labs(title = "Lag-1 scatter", x = "y(t-1)", y = "y(t)")
      },
      
      "Lag plot (1..m)" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        validate(need(length(xx) > (lag_m + 1), "Increase data or reduce m for lag plots."))
        forecast::gglagplot(ts_obj, lags = lag_m) +
          ggplot2::labs(title = sprintf("Lag plot (1..%d)", lag_m))
      },
      
      # ======================
      # ACF/PACF (uses S_Lag2)
      # ======================
      "ACF" = {
        forecast::ggAcf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "ACF")
      },
      
      "PACF" = {
        forecast::ggPacf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "PACF")
      },
      
      "ACF+PACF" = {
        p_acf  <- add_theme(forecast::ggAcf(ts_obj,  lag.max = S_Lag2) + ggplot2::labs(title = "ACF"))
        p_pacf <- add_theme(forecast::ggPacf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "PACF"))
        (p_acf / p_pacf) + patchwork::plot_layout(heights = c(1, 1))
      },
      
      "Time + ACF+PACF" = {
        
        ddf <- df_ts(ts_obj)
        
        p_time <- ggplot2::ggplot(ddf, ggplot2::aes(t, y)) +
          ggplot2::geom_line(
            size   = 1,
            colour = input$ts_line_color %||% "#2C7FB8"
          ) +
          ggplot2::labs(
            title = "Time plot",
            x     = p$x_label,
            y     = "Transformed value"
          )
        
        p_time <- apply_smart_date_axis(p_time, ddf)
        
        p_acf  <- forecast::ggAcf(ts_obj,  lag.max = S_Lag2) + ggplot2::labs(title = "ACF")
        p_pacf <- forecast::ggPacf(ts_obj, lag.max = S_Lag2) + ggplot2::labs(title = "PACF")
        
        p_time <- add_theme(p_time)
        p_acf  <- add_theme(p_acf)
        p_pacf <- add_theme(p_pacf)
        
        (p_time / (p_acf | p_pacf)) +
          patchwork::plot_layout(heights = c(1.3, 1))
      },
      
      "Periodogram" = {
        xx <- as.numeric(stats::na.omit(ts_obj))
        validate(need(length(xx) >= 8, "Need at least 8 observations for a periodogram."))
        
        taper <- suppressWarnings(as.numeric(input$stp_spec_taper %||% 0.1))
        if (!is.finite(taper)) taper <- 0.1
        
        sp <- tryCatch(
          stats::spec.pgram(xx, detrend = TRUE, taper = taper, plot = FALSE),
          error = function(e) e
        )
        validate(need(!inherits(sp, "error"), paste("spec.pgram failed:", sp$message)))
        
        d <- data.frame(freq = sp$freq, spec = as.numeric(sp$spec))
        d <- d[is.finite(d$freq) & is.finite(d$spec), , drop = FALSE]
        validate(need(nrow(d) > 1, "Periodogram returned no finite values (check data/transform)."))
        
        ggplot2::ggplot(d, ggplot2::aes(freq, spec)) +
          ggplot2::geom_line(linewidth = 1, colour = input$ts_line_color %||% "#2C7FB8") +
          ggplot2::labs(title = "Periodogram", x = "Frequency", y = "Spectral density") +
          ggplot2::scale_x_continuous()
      }
    )
    
    # apply theme (for plain ggplot outputs only)
    if (inherits(plt, "ggplot")) {
      plt <- add_theme(plt)
    }
    
    print(plt)
  }, res = 96)
  
  

  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  

    # ---- UI wrapper (dynamic size) ----
  output$difference2ACFPACF_UI <- renderUI({
    plotOutput(
      "difference2ACFPACF",
      width  = getPlotDim(input$plot_width  %||% 900),
      height = getPlotDim(input$plot_height %||% 700)
    )
  })
  

  
  # ---- Combined ACF + PACF (stacked) ----
  
  
  plot_pylike_corr <- function(x, type = c("acf", "pacf"), lag.max = 50, tickSize = 11) {
    type <- match.arg(type)
    x <- as.numeric(na.omit(x))
    n <- length(x)
    stopifnot(n > 3)
    
    # compute acf/pacf without plotting
    obj <- if (type == "acf") stats::acf(x, lag.max = lag.max, plot = FALSE)
    else               stats::pacf(x, lag.max = lag.max, plot = FALSE)
    
    vals <- as.numeric(obj$acf)
    lags <- as.numeric(obj$lag)
    
    # statsmodels-style: usually start at lag 1 for ACF
    if (type == "acf") {
      keep <- lags > 0
      lags <- lags[keep]
      vals <- vals[keep]
    }
    
    df <- data.frame(lag = lags, val = vals)
    
    # common CI band (very similar visually to Python defaults)
    ci <- 1.96 / sqrt(n)
    
    ggplot(df, aes(x = lag, y = val)) +
      geom_hline(yintercept = 0, linewidth = 0.4) +
      geom_ribbon(aes(ymin = -ci, ymax = ci), alpha = 0.2) +
      geom_segment(aes(xend = lag, yend = 0), linewidth = 0.8) +
      geom_point(size = 2) +
      coord_cartesian(ylim = c(-1, 1)) +
      labs(
        title = if (type == "acf") "Autocorrelation" else "Partial Autocorrelation",
        x = "Lag",
        y = toupper(type)
      ) +
      theme_classic(base_size = tickSize) +
      theme(
        plot.title = element_text(hjust = 0.5, face = "bold"),
        panel.border = element_rect(fill = NA, linewidth = 0.4)
      )
  }
  
 
  
  output$difference2ACFPACF <- renderPlot({
    req(myData_Choice())
    
    tick <- as.numeric(input$tickSize %||% 11)
    ts_obj <- myData_Choice()
    
    # --- lag control (numericInput: St_Lag) -> S_Lag2 ---
    S_Lag2 <- suppressWarnings(as.integer(input$St_Lag))
    if (!is.finite(S_Lag2) || S_Lag2 < 1) S_Lag2 <- 40L
    S_Lag2 <- max(1L, min(S_Lag2, length(ts_obj) - 1L))
    
    p1 <- plot_pylike_corr(ts_obj, "acf",  lag.max = S_Lag2, tickSize = tick) +
      ggplot2::labs(title = "Autocorrelation of Sales")
    
    p2 <- plot_pylike_corr(ts_obj, "pacf", lag.max = S_Lag2, tickSize = tick) +
      ggplot2::labs(title = "Partial Autocorrelation of Sales")
    
    gridExtra::grid.arrange(p1, p2, ncol = 1, top = "ACF & PACF of transformed series")
  }, res = 96)
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  output$teststationarited3St <- renderPrint({
    # ---------- Helpers ----------
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0 && !all(is.na(a))) a else b
    to_num_safe <- function(v, default = NA_real_) {
      out <- suppressWarnings(as.numeric(v))
      if (length(out) == 0 || all(is.na(out)) || !is.finite(out[1])) default else out[1]
    }
    to_int_safe <- function(v, default = 0L) {
      out <- suppressWarnings(as.integer(v))
      if (length(out) == 0 || is.na(out[1]) || !is.finite(out[1])) default else out[1]
    }
    safe_head_tail <- function(x, n = 5) {
      x <- as.numeric(x); x <- x[is.finite(x)]
      if (length(x) == 0) return(list(head = numeric(0), tail = numeric(0)))
      list(head = head(x, n), tail = tail(x, n))
    }
    tau_row_for <- function(type_in) switch(type_in, "none"="tau1", "drift"="tau2", "trend"="tau3", "tau3")
    cval_pick_safe <- function(cval_obj, row, col) {
      if (is.null(cval_obj)) return(NA_real_)
      ans <- NA_real_
      if (is.matrix(cval_obj)) {
        if (!missing(row) && !missing(col) && row %in% rownames(cval_obj) && col %in% colnames(cval_obj)) {
          ans <- suppressWarnings(as.numeric(cval_obj[row, col]))
        } else if (!missing(col) && col %in% colnames(cval_obj)) {
          ans <- suppressWarnings(as.numeric(cval_obj[1, col]))
        } else {
          ans <- suppressWarnings(as.numeric(cval_obj[1, 1]))
        }
      } else {
        nm <- names(cval_obj)
        if (!is.null(nm) && col %in% nm) ans <- suppressWarnings(as.numeric(cval_obj[[col]]))
        if (!is.finite(ans) && length(cval_obj) >= 3) {
          if (identical(col, "10pct")) ans <- suppressWarnings(as.numeric(cval_obj[1]))
          if (identical(col, "5pct"))  ans <- suppressWarnings(as.numeric(cval_obj[2]))
          if (identical(col, "1pct"))  ans <- suppressWarnings(as.numeric(cval_obj[3]))
        }
        if (!is.finite(ans)) ans <- suppressWarnings(as.numeric(cval_obj[1]))
      }
      ans
    }
    fmt_p <- function(p) {
      if (!is.finite(p)) return("NA")
      if (p < .001) "<0.001" else sprintf("%.6f", p)
    }
    fmt_num <- function(z, d=6) ifelse(is.finite(z), sprintf(paste0("%.", d ,"f"), z), "NA")
    tick <- function(ok) if (isTRUE(ok)) "[âœ“]" else "[X]"
    warn <- function(ok) if (isTRUE(ok)) "[âœ“]" else "[!]"
    qmark <- function(ok) if (isTRUE(ok)) "[âœ“]" else "[?]"
    
    # ---------- Inputs (from your UI) ----------
    alt_in  <- input$alternd2St %||% input$alternSt       # "stationary", "explosive", "regression"
    lag_in  <- input$LagOrderADFd2St %||% input$LagOrderADFSt
    a_in    <- input$alphaSt2
    type_in <- input$adfTypeSt2                            # "none", "drift", "trend"
    
    # Transformation flags (provenance)
    d_in   <- input$d_n  %||% NA
    D_in   <- input$DS_n %||% NA
    log_in <- input$check_box %||% FALSE
    
    # ---------- Data ----------
    req(myData_Choice())
    x_raw <- myData_Choice()
    na_before <- sum(is.na(x_raw))
    x_class <- paste(class(x_raw), collapse = ", ")
    x_freq  <- if (inherits(x_raw, "ts")) tryCatch(stats::frequency(x_raw), error = function(e) NA_integer_) else NA_integer_
    x <- as.numeric(stats::na.omit(x_raw))
    N <- length(x)
    
    # ---------- Hyper-parameters ----------
    k <- to_int_safe(lag_in, default = 0L); if (!is.finite(k) || k < 0) k <- 0L
    alpha_raw <- as.character(a_in)
    alpha_val <- to_num_safe(alpha_raw, default = 0.05)
    alpha_col <- switch(alpha_raw, "0.01"="1pct", "0.05"="5pct", "0.1"="10pct", "0.10"="10pct",
                        "1pct"="1pct", "5pct"="5pct", "10pct"="10pct", "5pct")
    tau_row <- tau_row_for(type_in)
    
    # ---------- Sanity checks ----------
    if (N < 5) {
      cat("==========================================================================\n")
      cat("                         ADF UNIT ROOT DIAGNOSTIC                         \n")
      cat("==========================================================================\n")
      cat("CRITICAL ERROR: Too few observations (N < 5). Provide more data.\n")
      return(invisible(NULL))
    }
    if (!is.finite(stats::sd(x)) || stats::sd(x) == 0) {
      cat("==========================================================================\n")
      cat("                         ADF UNIT ROOT DIAGNOSTIC                         \n")
      cat("==========================================================================\n")
      cat("CRITICAL ERROR: Series is constant/invalid (sd = 0 or NA). Check transforms.\n")
      return(invisible(NULL))
    }
    
    # ---------- Package check ----------
    if (!requireNamespace("urca", quietly = TRUE) || !requireNamespace("tseries", quietly = TRUE)) {
      cat("==========================================================================\n")
      cat("                         ADF UNIT ROOT DIAGNOSTIC                         \n")
      cat("==========================================================================\n")
      cat("ERROR: Please install.packages(c('urca','tseries')) to run ADF/KPSS.\n")
      return(invisible(NULL))
    }
    
    # ---------- Common quantities ----------
    m_mean <- mean(x, na.rm = TRUE)
    m_sd   <- stats::sd(x, na.rm = TRUE)
    lb_lag <- max(1L, min(10L, floor(N / 5)))
    
    # ---------- Core ADF (urca) for chosen type & k ----------
    ur  <- tryCatch(urca::ur.df(x, type = type_in, lags = k), error = function(e) NULL)
    tau_obs  <- if (!is.null(ur)) suppressWarnings(as.numeric(ur@teststat[tau_row])) else NA_real_
    if (!is.finite(tau_obs) && !is.null(ur)) tau_obs <- suppressWarnings(as.numeric(ur@teststat[1]))
    tau_crit <- if (!is.null(ur)) cval_pick_safe(ur@cval, tau_row, alpha_col) else NA_real_
    adf_ts <- if (N > (k + 10)) tryCatch(tseries::adf.test(x, alternative = alt_in, k = k),
                                         error = function(e) NULL) else NULL
    adf_p  <- if (!is.null(adf_ts)) to_num_safe(adf_ts$p.value) else NA_real_
    lb_main <- if (!is.null(ur)) stats::Box.test(ur@res, lag = lb_lag, type = "Ljung-Box") else NULL
    lb_stat<- if (!is.null(lb_main)) to_num_safe(lb_main$statistic) else NA_real_
    lb_p   <- if (!is.null(lb_main)) to_num_safe(lb_main$p.value) else NA_real_
    
    adf_ok_vals <- is.finite(tau_obs) && is.finite(tau_crit)
    adf_stationary <- adf_ok_vals && (tau_obs < tau_crit)
    
    # ---------- KPSS (full sample) ----------
    kpss_type <- if (type_in == "trend") "Trend" else "Level"
    kpss_ts   <- tryCatch(tseries::kpss.test(x, null = kpss_type), error = function(e) NULL)
    kpss_p    <- if (!is.null(kpss_ts)) to_num_safe(kpss_ts$p.value) else NA_real_
    kpss_uc   <- tryCatch(urca::ur.kpss(x, type = if (type_in == "trend") "tau" else "mu"),
                          error = function(e) NULL)
    eta_obs_uc  <- if (!is.null(kpss_uc)) to_num_safe(kpss_uc@teststat) else NA_real_
    eta_col     <- if (alpha_val <= 0.01) "1pct" else if (alpha_val <= 0.05) "5pct" else "10pct"
    eta_crit_uc <- if (!is.null(kpss_uc)) cval_pick_safe(kpss_uc@cval, 1, eta_col) else NA_real_
    kpss_by_p   <- is.finite(kpss_p)     && (kpss_p < alpha_val)
    kpss_by_eta <- is.finite(eta_obs_uc) && is.finite(eta_crit_uc) && (eta_obs_uc > eta_crit_uc)
    kpss_stationary <- !(kpss_by_p || kpss_by_eta)
    
    # ---------- Structural break (Pettitt) ----------
    pett_U <- pett_p <- NA_real_; pett_cp <- NA_integer_
    if (requireNamespace("trend", quietly = TRUE)) {
      pet <- tryCatch(trend::pettitt.test(x), error = function(e) NULL)
      if (!is.null(pet)) {
        pett_U <- to_num_safe(pet$statistic)
        pett_p <- to_num_safe(pet$p.value)
        # trend::pettitt.test typically returns estimate (break index); guard for NA
        pett_cp <- to_int_safe(pet$estimate[1], default = NA_integer_)
        if (!is.finite(pett_cp)) {
          # conservative fallback: midpoint (only if needed)
          pett_cp <- as.integer(floor(N/2))
        }
        if (pett_cp < 2L || pett_cp > (N - 2L)) pett_cp <- NA_integer_  # unusable splits
      }
    }
    
    # ---------- KPSS by segments (if break usable) ----------
    seg1_p <- seg2_p <- NA_real_
    if (is.finite(pett_cp)) {
      if (pett_cp >= 8 && (N - pett_cp) >= 8) {
        seg1 <- tryCatch(tseries::kpss.test(x[seq_len(pett_cp)], null = kpss_type), error = function(e) NULL)
        seg2 <- tryCatch(tseries::kpss.test(x[(pett_cp + 1L):N], null = kpss_type), error = function(e) NULL)
        if (!is.null(seg1)) seg1_p <- to_num_safe(seg1$p.value)
        if (!is.null(seg2)) seg2_p <- to_num_safe(seg2$p.value)
      }
    }
    
    # ---------- Phase 0: k* scan & spec sensitivity ----------
    # k* = smallest k such that Ljungâ€“Box p-value on ADF residuals > alpha, for the user-chosen type_in
    k_grid <- 0L:min(12L, max(1L, floor(N/10)))
    lbp_by_k <- rep(NA_real_, length(k_grid))
    for (i in seq_along(k_grid)) {
      kk <- k_grid[i]
      ur_i <- tryCatch(urca::ur.df(x, type = type_in, lags = kk), error = function(e) NULL)
      lb_i <- if (!is.null(ur_i)) tryCatch(stats::Box.test(ur_i@res, lag = lb_lag, type = "Ljung-Box"), error = function(e) NULL) else NULL
      lbp_by_k[i] <- if (!is.null(lb_i)) to_num_safe(lb_i$p.value) else NA_real_
    }
    k_suggest <- NA_integer_
    idx_ok <- which(is.finite(lbp_by_k) & lbp_by_k > alpha_val)
    if (length(idx_ok) > 0) k_suggest <- k_grid[min(idx_ok)] else k_suggest <- k
    
    # Spec sensitivity across types for k = selected and k = k_suggest
    types <- c("none","drift","trend")
    spec_line <- function(kk) {
      for (tp in types) {
        tau_row_tp <- tau_row_for(tp)
        ur_tp <- tryCatch(urca::ur.df(x, type = tp, lags = kk), error = function(e) NULL)
        tau_tp  <- if (!is.null(ur_tp)) suppressWarnings(as.numeric(ur_tp@teststat[tau_row_tp])) else NA_real_
        if (!is.finite(tau_tp) && !is.null(ur_tp)) tau_tp <- suppressWarnings(as.numeric(ur_tp@teststat[1]))
        crit_tp <- if (!is.null(ur_tp)) cval_pick_safe(ur_tp@cval, tau_row_tp, alpha_col) else NA_real_
        lb_tp   <- if (!is.null(ur_tp)) tryCatch(stats::Box.test(ur_tp@res, lag = lb_lag, type = "Ljung-Box"), error = function(e) NULL) else NULL
        lbp_tp  <- if (!is.null(lb_tp)) to_num_safe(lb_tp$p.value) else NA_real_
        adf_dec <- if (is.finite(tau_tp) && is.finite(crit_tp) && (tau_tp < crit_tp)) "ADF=STATIONARY" else "ADF=NON-STATIONARY"
        cat(sprintf("     %s type=%-5s | tau=%s | crit=%s | %s | LB p=%s\n",
                    tick(is.finite(lbp_tp) && lbp_tp > alpha_val),
                    tp,
                    fmt_num(tau_tp, 4),
                    fmt_num(crit_tp, 4),
                    adf_dec,
                    fmt_num(lbp_tp, 4)))
      }
    }
    
    # ---------- Agreement & flags ----------
    agreement <- (adf_stationary && kpss_stationary) || (!adf_stationary && !kpss_stationary)
    
    # ---------- HEADER ----------
    cat("==========================================================================\n")
    cat("                        ADF UNIT ROOT DIAGNOSTIC                          \n")
    cat("==========================================================================\n")
    cat(sprintf(" MODEL TYPE : %-10s | SAMPLE SIZE (N) : %s\n", toupper(type_in), N))
    cat(sprintf(" LAG ORDER  : %-10s | SIGNIFICANCE (Î±) : %s\n", k, fmt_num(alpha_val, 4)))
    cat(sprintf(" MOMENTS    : Mean: %s | Std.Dev: %s\n",
                fmt_num(m_mean, 4), fmt_num(m_sd, 4)))
    cat("--------------------------------------------------------------------------\n")
    cat(" TRANSFORMATION PROVENANCE (what ALL tests use):\n")
    cat(sprintf(" [ ] Source object class           : %s\n", x_class))
    cat(sprintf(" [ ] Frequency (if ts)             : %s\n", ifelse(is.finite(x_freq), x_freq, "NA")))
    cat(sprintf(" [ ] NA count before na.omit       : %s\n", na_before))
    cat(sprintf(" [ ] Transformation inputs (UI)    : log=%s | d=%s | D=%s\n",
                ifelse(isTRUE(log_in),"ON","OFF"), as.character(d_in), as.character(D_in)))
    ht <- safe_head_tail(x, 5)
    cat(sprintf(" [ ] First 5 values used in tests  : %s\n", paste(round(ht$head, 4), collapse = ", ")))
    cat(sprintf(" [ ] Last  5 values used in tests  : %s\n\n", paste(round(ht$tail, 4), collapse = ", ")))
    
    # ---------- PHASE 0 ----------
    cat("==========================================================================\n")
    cat("PHASE 0: DECISION AID (Lag + Spec Sensitivity)\n")
    cat("==========================================================================\n")
    cat(sprintf(" â€¢ Ljung-Box reference lag used in scan : %d  ; (LB lag = min(10, floor(N/5))\n", lb_lag))
    cat(sprintf(" [!] Suggested k* (scan)                : %s  (smallest k with Ljung-Box p-value > alpha (whiter residuals))\n",
                ifelse(is.finite(k_suggest), k_suggest, "NA")))
    if (is.finite(k_suggest) && k_suggest != k) {
      cat(sprintf(" [!] You selected k=%d. Consider trying k=%d and re-running.\n", k, k_suggest))
    } else {
      cat(sprintf(" [âœ“] You selected k=%d. This already meets the LB>Î± rule-of-thumb.\n", k))
    }
    cat("--------------------------------------------------------------------------\n")
    cat(" ADF SPEC SENSITIVITY (ur.df):\n")
    cat("   (Prefer: LB ok + stable decision across types)\n")
    cat(sprintf("  â€¢ k=%d\n", k)); spec_line(k)
    if (is.finite(k_suggest) && k_suggest != k) {
      cat(sprintf("  â€¢ k=%d\n", k_suggest)); spec_line(k_suggest)
    }
    cat("--------------------------------------------------------------------------\n")
    
    # ---------- PHASE 1 ----------
    cat("==========================================================================\n")
    cat("PHASE 1: ADF UNIT ROOT TEST\n")
    cat("==========================================================================\n")
    cat(" â€¢ H0: The series has a Unit Root (Non-Stationary).\n")
    cat(" â€¢ Ha: The series is Stationary (Mean Reverting).\n")
    cat(sprintf(" -> CRITERIA: Reject H0 if Tau-Obs (%s) < Tau-Crit (%s)\n",
                fmt_num(tau_obs, 4), fmt_num(tau_crit, 4)))
    cat("\n RESULT:\n")
    cat(sprintf("  - Tau Observed : %s \n", fmt_num(tau_obs, 6)))
    cat(sprintf("  - Tau Critical : %s \n", fmt_num(tau_crit, 2)))
    cat(sprintf("  - P-Value (Ref): %s \n", ifelse(is.finite(adf_p), fmt_p(adf_p), "NA")))
    cat("\n DECISION:\n")
    if (adf_ok_vals && adf_stationary) {
      cat("  -> REJECT H0: Evidence suggests the series is STATIONARY.\n")
    } else if (adf_ok_vals && !adf_stationary) {
      cat("  -> FAIL TO REJECT H0: Evidence suggests the series is NON-STATIONARY.\n")
    } else {
      cat("  -> INCONCLUSIVE: Missing statistic/critical value; regression may be ill-conditioned.\n")
    }
    
    # ---------- PHASE 2 ----------
    cat("\n==========================================================================\n")
    cat("PHASE 2: RESIDUAL DIAGNOSTICS (LJUNG-BOX)\n")
    cat("==========================================================================\n")
    cat(" â€¢ H0: Residuals are White Noise (No Autocorrelation).\n")
    cat(" â€¢ Ha: Residuals are Correlated (Lags are insufficient).\n")
    cat(sprintf(" -> CRITERIA: Reject H0 if P-Value (%s) < Î± (%s)\n", fmt_num(lb_p, 6), fmt_num(alpha_val, 4)))
    cat("\n RESULT:\n")
    cat(sprintf("  - LB Statistic : %s \n", fmt_num(lb_stat, 6)))
    cat(sprintf("  - LB P-Value   : %s \n", fmt_num(lb_p, 6)))
    cat(sprintf("  - LB Lag used  : %d \n", lb_lag))
    cat("    itâ€™s normal to choose LB lag by a rule-of-thumb (like min(10, floor(N/5)) \n")
    cat("\n DECISION:\n")
    if (is.finite(lb_p)) {
      if (lb_p > alpha_val) cat("  -> FAIL TO REJECT H0: Residuals are White Noise. [ADF more reliable]\n")
      else                  cat("  -> REJECT H0: Residual autocorrelation remains; increase k or difference.\n")
    } else {
      cat("  -> INCONCLUSIVE: Ljungâ€“Box p-value is NA.\n")
    }
    
    # ---------- PHASE 3A ----------
    cat("\n==========================================================================\n")
    cat("PHASE 3: KPSS + STRUCTURAL BREAK (Pettitt) + KPSS SEGMENTS\n")
    cat("==========================================================================\n\n")
    cat("PHASE 3A: KPSS (Stationarity Confirmation)\n")
    cat(sprintf(" â€¢ H0: The series is Stationary around a %s.\n", if (kpss_type=="Trend") "Trend" else "Level"))
    cat(" â€¢ Ha: The series is Non-Stationary.\n")
    cat(sprintf(" â€¢ CRITERIA (p-value) : Reject H0 if p-value (%s) < Î± (%s)\n",
                ifelse(is.finite(kpss_p), fmt_num(kpss_p, 6), "NA"), fmt_num(alpha_val,4)))
    cat(sprintf(" â€¢ CRITERIA (eta)     : Reject H0 if Eta-Obs (%s) > Eta-Crit (%s)  [urca]\n",
                fmt_num(eta_obs_uc, 6), fmt_num(eta_crit_uc, 6)))
    cat("\n RESULT:\n")
    cat(sprintf("  - Eta (Observed value) [urca]   : %s \n", fmt_num(eta_obs_uc, 5)))
    cat(sprintf("  - Eta (Critical value) [urca]   : %s \n", fmt_num(eta_crit_uc, 3)))
    cat(sprintf("  - p-value (one-tailed) [tseries]: %s \n", ifelse(is.finite(kpss_p), fmt_num(kpss_p, 6), "NA")))
    cat(sprintf("  - Eta (Observed) [tseries, FYI] : %s \n", fmt_num(eta_obs_uc, 5)))
    cat("\n DECISION:\n")
    if (kpss_stationary) cat("  -> FAIL TO REJECT H0: Stationarity supported by KPSS.\n")
    else                 cat("  -> REJECT H0: Non-stationarity indicated by KPSS.\n")
    
    # ---------- PHASE 3B ----------
    cat("--------------------------------------------------------------------------\n")
    cat("PHASE 3B: STRUCTURAL BREAK CHECK (Pettitt) + KPSS SEGMENT CHECK\n")
    cat(" â€¢ Goal: Detect a single change-point (median shift) that can distort KPSS.\n")
    cat(" â€¢ If a break exists, we re-run KPSS before/after the break.\n")
    cat(sprintf(" â€¢ Pettitt p-value: %s | Î±: %s\n\n", ifelse(is.finite(pett_p), fmt_num(pett_p, 6), "NA"), fmt_num(alpha_val, 4)))
    cat(" RESULT:\n")
    cat(sprintf("  - Break index (estimate): %s \n", ifelse(is.finite(pett_cp), pett_cp, "NA")))
    cat(sprintf("  - Pettitt statistic     : %s \n", fmt_num(pett_U, 0)))
    cat(sprintf("  - Pettitt p-value       : %s \n", ifelse(is.finite(pett_p), fmt_num(pett_p, 6), "NA")))
    cat("\n DECISION:\n")
    if (is.finite(pett_p)) {
      if (pett_p < alpha_val) cat("  -> REJECT H0: Break detected. Full-sample KPSS/ADF may be contaminated.\n")
      else                    cat("  -> FAIL TO REJECT H0: No strong single break detected.\n")
    } else {
      cat("  -> INCONCLUSIVE: Pettitt p-value NA.\n")
    }
    
    # ---------- PHASE 3C ----------
    cat("--------------------------------------------------------------------------\n")
    cat("PHASE 3C: KPSS RE-CHECK BY SEGMENTS\n")
    cat("  â€¢ Segment 1 = [1 .. break]\n")
    cat("  â€¢ Segment 2 = [break+1 .. N]\n")
    cat(sprintf("  - KPSS p-value (Segment 1): %s\n", ifelse(is.finite(seg1_p), fmt_num(seg1_p, 6), "NA")))
    cat(sprintf("  - KPSS p-value (Segment 2): %s\n", ifelse(is.finite(seg2_p), fmt_num(seg2_p, 6), "NA")))
    cat("\n INTERPRETATION:\n")
    if (is.finite(seg1_p) && is.finite(seg2_p)) {
      if (seg1_p >= alpha_val && seg2_p >= alpha_val)
        cat("  [âœ“] Both segments look stationary by KPSS.\n      -> Full-sample non-stationarity may be break-driven.\n")
      else if (seg1_p < alpha_val && seg2_p < alpha_val)
        cat("  [X] Both segments look non-stationary by KPSS.\n")
      else
        cat("  [?] Mixed evidence: one segment stationary, the other not.\n")
    } else {
      cat("  [?] Segment KPSS not available (short segments or missing package).\n")
    }
    
    # ---------- PHASE 4: Final verdict & advice ----------
    cat("\n==========================================================================\n")
    cat("PHASE 4: FINAL ACADEMIC VERDICT & ADVICE\n")
    cat("==========================================================================\n")
    if (adf_stationary && kpss_stationary) {
      cat(" [âœ“] VERDICT: CONVERGENT STATIONARITY (ADF & KPSS agree; residuals likely white).\n")
      cat("     ADVICE: Proceed with SARIMA identification with d=0 (choose D via seasonality), then residual checks.\n")
    } else if (!adf_stationary && !kpss_stationary) {
      cat(" [X] VERDICT: CONVERGENT NON-STATIONARITY (ADF & KPSS agree).\n")
      cat("     ADVICE: Difference the series (d=1). If seasonal (mâ‰¥2), consider D=1, then re-run tests.\n")
    } else {
      cat(" [?] VERDICT: CONFLICTING RESULTS (ADF vs KPSS).\n")
      cat("     ADVICE: Near-unit-root, trend-vs-drift mismatch, or break contamination are common causes.\n")
      cat("             Use PHASE 0 to pick k/type with LB ok and stable decisions; consider seasonal differencing and break handling.\n")
    }
    
    # ---------- Technical appendix: ADF regression coefficients ----------
    cat("\n TECHNICAL APPENDIX (ADF Regression Coefficients):\n")
    if (!is.null(ur) && !is.null(ur@testreg)) {
      cf <- tryCatch(coef(summary(ur@testreg)), error = function(e) NULL)
      if (!is.null(cf)) {
        printCoefmat(cf, digits = 7, signif.stars = FALSE, P.values = TRUE, has.Pvalue = TRUE)
      } else {
        cat("  (coefficients unavailable)\n")
      }
    } else {
      cat("  (ADF regression unavailable)\n")
    }
    
    # ---------- PHASE 5: Evidence snapshot & checklist ----------
    cat("\n==========================================================================\n")
    cat("PHASE 5: POST-SUMMARY (Academic-quality snapshot)\n")
    cat("==========================================================================\n")
    cat(" EVIDENCE SNAPSHOT (All key outcomes in one place):\n")
    cat(sprintf(" [ ] N (effective sample size)              : %s\n", N))
    cat(sprintf(" [ ] Model type (ADF)                       : %s  (tau row: %s)\n", tolower(type_in), tau_row))
    cat(sprintf(" [ ] Lag order (k)                          : %s\n", k))
    cat(sprintf(" [ ] Alpha (Î±)                              : %s\n", fmt_num(alpha_val, 4)))
    cat(sprintf(" [ ] Tau-Observed (urca)                    : %s\n", fmt_num(tau_obs, 6)))
    cat(sprintf(" [ ] Tau-Critical (urca, %s)                  : %s\n", alpha_col, fmt_num(tau_crit, 6)))
    cat(sprintf(" [ ] ADF p-value (tseries reference)        : %s\n", ifelse(is.finite(adf_p), fmt_num(adf_p, 6), "NA")))
    cat(sprintf(" [ ] Ljung-Box p-value (residuals)          : %s\n", fmt_num(lb_p, 6)))
    cat(sprintf(" [ ] KPSS Eta observed (urca)               : %s\n", fmt_num(eta_obs_uc, 6)))
    cat(sprintf(" [ ] KPSS Eta critical (urca, %s)             : %s\n", eta_col, fmt_num(eta_crit_uc, 6)))
    cat(sprintf(" [ ] KPSS p-value (one-tailed, tseries)     : %s\n", ifelse(is.finite(kpss_p), fmt_num(kpss_p, 6), "NA")))
    cat(sprintf(" [!] Suggested k* (scan)                     : %s\n", ifelse(is.finite(k_suggest), k_suggest, "NA")))
    cat("--------------------------------------------------------------------------\n")
    cat(" CHECKLIST (Academic-quality acceptance criteria):\n")
    cat(sprintf(" [ ] Tests run on transformed series (x=myData_Choice) : %s YES (same x used everywhere)\n", tick(TRUE)))
    cat(sprintf(" [ ] Variance usable (sd>0)                          : %s SATISFIED\n", tick(TRUE)))
    cat(sprintf(" [ ] Tau is finite and usable                        : %s %s\n", tick(is.finite(tau_obs)), ifelse(is.finite(tau_obs),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] Tau critical value extracted                    : %s %s\n", tick(is.finite(tau_crit)), ifelse(is.finite(tau_crit),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] Residuals pass Ljung-Box (white noise)          : %s %s\n", tick(is.finite(lb_p) && lb_p > alpha_val), ifelse(is.finite(lb_p) && lb_p > alpha_val,"SATISFIED","CHECK")))
    cat(sprintf(" [ ] KPSS Eta observed & critical are usable         : %s %s\n", tick(is.finite(eta_obs_uc) && is.finite(eta_crit_uc)), ifelse(is.finite(eta_obs_uc) && is.finite(eta_crit_uc),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] KPSS p-value is usable                          : %s %s\n", tick(is.finite(kpss_p)), ifelse(is.finite(kpss_p),"SATISFIED","CHECK")))
    cat(sprintf(" [ ] Sample size adequacy                            : %s STRONG\n", tick(N >= 50)))
    cat(sprintf(" [ ] Lag order reasonable relative to N              : %s %s\n", tick(k <= max(12L, floor(N/10))), ifelse(k <= max(12L, floor(N/10)),"OK","LARGE")))
    cat(sprintf(" [ ] Seasonal differencing indicated (UI D>0)         : %s %s\n", warn(isTRUE(to_int_safe(D_in,0L) > 0)), ifelse(isTRUE(to_int_safe(D_in,0L) > 0),"YES","NO / UNKNOWN")))
    cat(sprintf(" [ ] ADF alternative mode (Stationary/Explosive)      : %s\n", paste0(ifelse(is.null(alt_in),"NA",alt_in))))
    cat(sprintf(" [ ] ADF & KPSS agreement                             : %s %s\n",
                qmark(agreement), ifelse(agreement,"AGREEMENT","CONFLICT")))
    cat("     [?] NOTE: conflicts are common with near-unit-root series, trend vs drift mismatch,\n")
    cat("         structural breaks (Pettitt), or missing seasonal differencing.\n")
    cat("--------------------------------------------------------------------------\n")
    cat(" STRUCTURAL BREAK SUMMARY (Pettitt):\n")
    cat(sprintf(" [ ] Pettitt p-value : %s  (Reject H0 if < Î±)\n", ifelse(is.finite(pett_p), fmt_num(pett_p, 6), "NA")))
    cat("--------------------------------------------------------------------------\n")
    cat("==========================================================================\n")
    cat(" ACTIONABLE NEXT STEPS (What to do now):\n")
    cat("==========================================================================\n")
    cat(sprintf(" %s [1] RESIDUAL AUTOCORRELATION CHECK\n", tick(is.finite(lb_p) && lb_p > alpha_val)))
    cat("     â€¢ Ljung-Box is acceptable â†’ ADF regression is less likely biased.\n")
    cat(" [?] [2] RESOLVE ADF vs KPSS CONFLICT\n")
    cat("     â€¢ Use PHASE 0 'ADF SPEC SENSITIVITY' to pick the type with LB ok and stable decision.\n")
    cat("     â€¢ Try ADF model type variants: none / drift / trend (match KPSS Level vs Trend).\n")
    cat("     â€¢ If Pettitt indicates a break: split sample and re-test.\n")
    cat("     â€¢ If series is seasonal: test after seasonal differencing (D=1) + maybe log.\n")
    cat("     â€¢ Consider variance stabilization: log or Box-Cox (if positive data).\n")
    cat(" [!] [3] SEASONALITY SANITY (especially for AirPassengers-like series)\n")
    if (is.finite(x_freq) && x_freq >= 2) {
      cat(sprintf("     â€¢ Detected frequency=%d â†’ seasonality is plausible.\n", x_freq))
    } else {
      cat("     â€¢ Frequency unknown â†’ inspect ACF/PACF for seasonal spikes.\n")
    }
    cat(" [âœ“] [4] EXPLOSIVE MODE NOTE\n")
    cat(sprintf("     â€¢ %s\n", ifelse(identical(alt_in,"explosive"),
                                      "Explosive alternative was requested; interpret ADF accordingly.",
                                      "Not in explosive mode â†’ standard stationarity workflow applies.")))
    cat("\n PRACTICAL MODELING PATH (for your Shiny workflow):\n")
    if (!adf_stationary || !kpss_stationary) {
      cat(" [X] Apply differencing (d and/or D) â†’ re-run ADF/KPSS â†’ then identify ARMA.\n")
    } else {
      cat(" [âœ“] Keep d=0 (and decide D via seasonality) â†’ SARIMA identification and residual diagnostics.\n")
    }
    cat("--------------------------------------------------------------------------\n")
  })
  
  
 
  

  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  
  
  output$CHECKLIST <- renderPrint({
    
    # ============================================================================
    # 0) SMALL HELPERS
    # ============================================================================
    `%||%` <- function(a, b) if (!is.null(a) && length(a) > 0 && !all(is.na(a))) a else b
    
    to_num_safe <- function(v, default = NA_real_) {
      out <- suppressWarnings(as.numeric(v))
      if (length(out) == 0 || all(is.na(out)) || !is.finite(out[1])) default else out[1]
    }
    
    to_int_safe <- function(v, default = 0L) {
      out <- suppressWarnings(as.integer(v))
      if (length(out) == 0 || is.na(out[1]) || !is.finite(out[1])) default else out[1]
    }
    
    safe_head_tail <- function(x, n = 5) {
      x <- as.numeric(x)
      x <- x[is.finite(x)]
      if (length(x) == 0) return(list(head = numeric(0), tail = numeric(0)))
      list(head = head(x, n), tail = tail(x, n))
    }
    
    # Robust extractor for urca @cval (vector OR matrix; row/col name variations)
    get_uc_cval <- function(cv, key) {
      if (is.null(cv) || is.null(key) || !nzchar(key)) return(NA_real_)
      
      if (is.matrix(cv)) {
        if (!is.null(colnames(cv)) && key %in% colnames(cv)) return(as.numeric(cv[1, key]))
        if (!is.null(rownames(cv)) && key %in% rownames(cv)) return(as.numeric(cv[key, 1]))
        
        if (!is.null(colnames(cv))) {
          m <- which(grepl(key, colnames(cv), fixed = TRUE))
          if (length(m) > 0) return(as.numeric(cv[1, m[1]]))
        }
        if (!is.null(rownames(cv))) {
          m <- which(grepl(key, rownames(cv), fixed = TRUE))
          if (length(m) > 0) return(as.numeric(cv[m[1], 1]))
        }
        return(NA_real_)
      }
      
      nm <- names(cv)
      if (!is.null(nm) && key %in% nm) return(as.numeric(cv[[key]]))
      if (!is.null(nm)) {
        m <- which(grepl(key, nm, fixed = TRUE))
        if (length(m) > 0) return(as.numeric(cv[[m[1]]]))
      }
      NA_real_
    }
    
    # ============================================================================
    # 1) INPUT COLLECTION (supports either naming convention in your UI)
    # ============================================================================
    alt_in  <- input$alternd2St %||% input$alternSt
    lag_in  <- input$LagOrderADFd2St %||% input$LagOrderADFSt
    a_in    <- input$alphaSt2
    type_in <- input$adfTypeSt2
    
    # Optional transformation UI inputs (informational only)
    d_in   <- input$d_n  %||% input$d  %||% NA
    D_in   <- input$DS_n %||% input$D  %||% NA
    log_in <- input$check_box %||% input$islog %||% FALSE
    
    req(myData_Choice())
    
    if (is.null(alt_in) || is.null(lag_in) || is.null(a_in) || is.null(type_in)) {
      cat("==========================================================================\n")
      cat(" [!] INPUT ERROR: One or more inputs are NULL (likely UI/server ID mismatch)\n")
      cat("     Needed inputs:\n")
      cat("       - alternative : input$alternd2St OR input$alternSt\n")
      cat("       - lag         : input$LagOrderADFd2St OR input$LagOrderADFSt\n")
      cat("       - alpha       : input$alphaSt2\n")
      cat("       - adf type    : input$adfTypeSt2\n")
      cat("==========================================================================\n")
      return(invisible(NULL))
    }
    
    # ============================================================================
    # 2) DATA PREP
    # ============================================================================
    x_raw <- myData_Choice()
    na_before <- sum(is.na(x_raw))
    
    x_class <- paste(class(x_raw), collapse = ", ")
    x_freq  <- NA_integer_
    if (inherits(x_raw, "ts")) x_freq <- tryCatch(stats::frequency(x_raw), error = function(e) NA_integer_)
    
    x <- as.numeric(stats::na.omit(x_raw))
    valid_N <- length(x)
    
    k <- to_int_safe(lag_in, default = 0L)
    if (!is.finite(k) || k < 0) k <- 0L
    
    alpha_raw <- as.character(a_in)
    alpha_val <- to_num_safe(alpha_raw, default = 0.05)
    
    alpha_col <- switch(alpha_raw,
                        "0.01" = "1pct",
                        "0.05" = "5pct",
                        "0.1"  = "10pct",
                        "0.10" = "10pct",
                        "1pct" = "1pct",
                        "5pct" = "5pct",
                        "10pct"= "10pct",
                        "5pct")
    
    tau_row <- switch(type_in,
                      "none"  = "tau1",
                      "drift" = "tau2",
                      "trend" = "tau3",
                      "tau3")
    
    D_ui <- to_int_safe(D_in, default = 0L)
    seasonality_resolved <- isTRUE(D_ui > 0L)
    
    # Quick sanity exits (still only printing the 3 sections)
    if (valid_N < 5 || !is.finite(stats::sd(x)) || stats::sd(x) == 0) {
      cat("==========================================================================\n")
      cat(" CHECKLIST\n")
      cat("==========================================================================\n\n")
      cat(sprintf(" [ ] N (effective)                    : %d\n", valid_N))
      cat(sprintf(" [ ] Variance usable (sd>0)           : %s\n",
                  ifelse(is.finite(stats::sd(x)) && stats::sd(x) > 0, "[âœ“]", "[!]")))
      cat("--------------------------------------------------------------------------\n")
      cat(" FINAL ACADEMIC ADVICE\n")
      cat("--------------------------------------------------------------------------\n\n")
      if (valid_N < 5) {
        cat(" [!] Too few observations after transformation. Provide more data points.\n")
      } else {
        cat(" [!] Series is constant/invalid after transformation (sd=0/NA).\n")
        cat("     Fix data quality or transformation pipeline in myData_Choice().\n")
      }
      cat("--------------------------------------------------------------------------\n")
      cat(" ACTIONABLE NEXT STEPS\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" [!] [1] Verify myData_Choice() returns the transformed series (log/d/D).\n")
      cat(" [!] [2] Print/plot the transformed series to confirm it is not constant.\n")
      cat(" [!] [3] Re-run tests after fixing the above.\n")
      cat("==========================================================================\n")
      return(invisible(NULL))
    }
    
    # ============================================================================
    # 3) PREDECLARE OUTPUTS
    # ============================================================================
    res_urca <- NULL
    res_tseries <- list(p.value = NA_real_)
    lb_test <- list(statistic = NA_real_, p.value = NA_real_)
    lb_lag <- NA_integer_
    
    res_kpss_ts <- list(statistic = NA_real_, p.value = NA_real_)
    res_kpss_uc <- NULL
    
    tau_obs <- NA_real_
    tau_crit <- NA_real_
    
    eta_obs_uc <- NA_real_
    eta_crit_uc <- NA_real_
    eta_obs_ts <- NA_real_
    eta_p_one <- NA_real_
    eta_col <- NA_character_
    
    pettitt_res <- list(statistic = NA_real_, p.value = NA_real_, estimate = NULL)
    
    is_stationary <- FALSE
    kpss_stationary <- FALSE
    agreement_safe <- FALSE
    lb_white_safe <- FALSE
    
    # ============================================================================
    # 4) COMPUTE TESTS (no verbose phases; we only use results for the 3 outputs)
    # ============================================================================
    tryCatch({
      
      if (!requireNamespace("urca", quietly = TRUE)) stop("Package 'urca' missing. install.packages('urca')")
      if (!requireNamespace("tseries", quietly = TRUE)) stop("Package 'tseries' missing. install.packages('tseries')")
      
      # ADF (urca)
      res_urca <- urca::ur.df(x, type = type_in, lags = k)
      
      tau_obs <- suppressWarnings(as.numeric(res_urca@teststat[tau_row]))
      if (!is.finite(tau_obs)) {
        tau_obs_fallback <- suppressWarnings(as.numeric(res_urca@teststat[1]))
        if (is.finite(tau_obs_fallback)) tau_obs <- tau_obs_fallback
      }
      tau_crit <- suppressWarnings(as.numeric(res_urca@cval[tau_row, alpha_col]))
      
      # ADF p-value reference (tseries)
      if (valid_N > (k + 10)) {
        res_tseries <- tseries::adf.test(x, alternative = alt_in, k = k)
      }
      
      # Ljung-Box on ADF residuals
      lb_lag <- max(1L, min(10L, floor(valid_N / 5)))
      lb_test <- Box.test(res_urca@res, lag = lb_lag, type = "Ljung-Box")
      
      # KPSS (tseries p-value, urca cvals)
      kpss_type <- if (type_in == "trend") "Trend" else "Level"
      res_kpss_ts <- tseries::kpss.test(x, null = kpss_type)
      eta_obs_ts  <- to_num_safe(res_kpss_ts$statistic)
      eta_p_one   <- to_num_safe(res_kpss_ts$p.value)
      
      kpss_type_urca <- if (type_in == "trend") "tau" else "mu"
      res_kpss_uc    <- urca::ur.kpss(x, type = kpss_type_urca)
      
      eta_obs_uc <- suppressWarnings(as.numeric(res_kpss_uc@teststat))
      
      eta_col <- switch(alpha_raw,
                        "0.01" = "1pct",
                        "0.05" = "5pct",
                        "0.1"  = "10pct",
                        "0.10" = "10pct",
                        "1pct" = "1pct",
                        "5pct" = "5pct",
                        "10pct"= "10pct",
                        "5pct")
      
      eta_crit_uc <- suppressWarnings(get_uc_cval(res_kpss_uc@cval, eta_col))
      
      # Optional Pettitt
      if (requireNamespace("trend", quietly = TRUE)) {
        pettitt_res <- tryCatch(trend::pettitt.test(x),
                                error = function(e) list(statistic = NA_real_, p.value = NA_real_, estimate = NULL))
      }
      
      # Decisions
      tau_ok <- is.finite(tau_obs) && is.finite(tau_crit)
      lb_p   <- to_num_safe(lb_test$p.value)
      lb_ok  <- is.finite(lb_p)
      
      is_stationary <- isTRUE(tau_ok) && (tau_obs < tau_crit)
      
      # KPSS rejects stationarity if p<alpha OR eta_obs>eta_crit (when available)
      kpss_reject_by_p   <- is.finite(eta_p_one) && (eta_p_one < alpha_val)
      kpss_reject_by_eta <- is.finite(eta_obs_uc) && is.finite(eta_crit_uc) && (eta_obs_uc > eta_crit_uc)
      kpss_stationary <- !(kpss_reject_by_p || kpss_reject_by_eta)
      
      lb_white_safe <- lb_ok && (lb_p > alpha_val)
      
      agreement_safe <- (isTRUE(is_stationary) && isTRUE(kpss_stationary)) ||
        (isTRUE(!is_stationary) && isTRUE(!kpss_stationary))
      
    }, error = function(e) {
      cat("==========================================================================\n")
      cat(" CHECKLIST\n")
      cat("==========================================================================\n")
      cat(" [!] Execution error while computing tests:\n")
      cat("     ", e$message, "\n", sep = "")
      cat("--------------------------------------------------------------------------\n")
      cat(" FINAL ACADEMIC ADVICE\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" [!] Install/enable required packages and re-run.\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" ACTIONABLE NEXT STEPS\n")
      cat("--------------------------------------------------------------------------\n")
      cat(" [!] [1] install.packages('urca') and install.packages('tseries')\n")
      cat(" [!] [2] Re-run after verifying myData_Choice() returns a numeric/ts vector.\n")
      cat("==========================================================================\n")
      return(invisible(NULL))
    })
    
    # ============================================================================
    # 5) OUTPUT ONLY: CHECKLIST, FINAL ACADEMIC ADVICE, ACTIONABLE NEXT STEPS
    # ============================================================================
    lb_p <- to_num_safe(lb_test$p.value)
    adf_p <- to_num_safe(res_tseries$p.value)
    pett_p <- to_num_safe(pettitt_res$p.value)
    
    # --------------------
    # CHECKLIST
    # --------------------
    cat("==========================================================================\n")
    cat(" CHECKLIST\n")
    cat("==========================================================================\n")
    
    # ht <- safe_head_tail(x, 5)
    

    # Key decisions summary (compact)
    cat(sprintf(" [ ] ADF decision (reject unit root => stationary) : %s\n",
                ifelse(isTRUE(is_stationary), "[âœ“] STATIONARY", "[X] NON-STATIONARY")))
    cat(sprintf(" [ ] KPSS decision (fail reject => stationary)     : %s\n",
                ifelse(isTRUE(kpss_stationary), "[âœ“] STATIONARY", "[X] NON-STATIONARY")))
    cat(sprintf(" [ ] ADF vs KPSS agreement                         : %s\n",
                ifelse(isTRUE(agreement_safe), "[âœ“] AGREEMENT", "[?] CONFLICT")))
    cat(sprintf(" [ ] Residual whiteness (LB (Ljungâ€“Box) p>Î±)       : %s\n",
                ifelse(is.finite(lb_p) && lb_p > alpha_val, "[âœ“] OK", ifelse(is.finite(lb_p), "[X] FAIL", "[?] UNKNOWN"))))
    cat(sprintf(" [ ] Seasonal differencing indicated (UI D>0)      : %s\n",
                ifelse(isTRUE(seasonality_resolved), "[âœ“] YES", "[!] NO / UNKNOWN")))
    cat(sprintf(" [ ] Pettitt break check available                 : %s\n",
                ifelse(requireNamespace("trend", quietly = TRUE), "[âœ“] YES", "[!] NO (trend pkg missing)")))
    # if (requireNamespace("trend", quietly = TRUE)) {
    #   cat(sprintf(" [ ] Pettitt p-value                               : %.6f\n", pett_p))
    # }
    
    cat("\n")
    
    # --------------------
    # FINAL ACADEMIC ADVICE
    # --------------------
    cat("==========================================================================\n")
    cat(" FINAL ACADEMIC ADVICE\n")
    cat("==========================================================================\n")
    cat("\n")
    # Explain conflict in a compact, decision-useful way
    if (isTRUE(agreement_safe) && isTRUE(is_stationary) && isTRUE(kpss_stationary)) {
      cat(" [âœ“] Strong evidence of stationarity (I(0)) from BOTH ADF and KPSS.\n")
      if (!(is.finite(lb_p) && lb_p > alpha_val)) {
        cat(" [!] But residual autocorrelation suggests your ADF lag may be too small.\n")
        cat("     Treat the ADF conclusion as less reliable until LB passes.\n")
      } else {
        cat(" [âœ“] Residuals are consistent with a well-specified ADF regression.\n")
      }
      cat("     Academic implication: proceed with ARMA/ARIMA using d=0 (and D as already applied).\n")
      
    } else if (isTRUE(agreement_safe) && !isTRUE(is_stationary) && !isTRUE(kpss_stationary)) {
      cat(" [X] Strong evidence of a unit root (non-stationarity) from BOTH tests.\n")
      cat("     Academic implication: apply differencing (d=1) and re-test.\n")
      if (is.finite(x_freq) && x_freq > 1 && !isTRUE(seasonality_resolved)) {
        cat(" [!] Seasonal frequency detected; consider seasonal differencing (D=1) before increasing k.\n")
      }
      
    } else {
      cat(" [?] ADF and KPSS are in conflict.\n")
      cat("     This is common when the series is near-unit-root, trend-stationary vs difference-stationary,\n")
      cat("     has structural breaks, seasonality not properly removed, or lag k is mis-specified.\n")
      
      if (requireNamespace("trend", quietly = TRUE) && is.finite(pett_p) && pett_p < alpha_val) {
        cat(" [!] Pettitt suggests a structural break (p < Î±). Breaks often cause ADF/KPSS disagreement.\n")
      }
      
      if (is.finite(x_freq) && x_freq > 1 && !isTRUE(seasonality_resolved)) {
        cat(" [!] Seasonal frequency detected but seasonal differencing is NOT indicated (D=0).\n")
        cat("     Unremoved seasonality often triggers KPSS non-stationarity while ADF looks borderline.\n")
      }
      
      if (is.finite(lb_p) && lb_p <= alpha_val) {
        cat(" [!] Ljung-Box fails => ADF regression residuals are autocorrelated; your ADF decision is less trustworthy.\n")
      }
      
      cat("     Academic implication: be conservativeâ€”prefer differencing (and/or D=1 if seasonal), then re-test.\n")
    }
    
    cat(sprintf("\n (Numbers) ADF tau=%.6f | tau_crit=%.6f | ADF p(ref)=%.6f\n", tau_obs, tau_crit, adf_p))
    cat(sprintf("           KPSS eta_obs=%.6f | eta_crit=%.6f | KPSS p=%.6f\n", eta_obs_uc, eta_crit_uc, eta_p_one))
    cat(sprintf("           LB (the Ljungâ€“Box Q test) p=%.6f (lag=%s)\n", lb_p, ifelse(is.finite(lb_lag), as.character(lb_lag), "NA")))
    cat("            |__ itâ€™s normal to choose LB lag by a rule-of-thumb (like min(10, floor(N/5)) \n")
    cat("\n")
    
    # --------------------
    # ACTIONABLE NEXT STEPS
    # --------------------
    cat("==========================================================================\n")
    cat(" ACTIONABLE NEXT STEPS\n")
    cat("==========================================================================\n")
    
    
    # [1] Residual autocorrelation
    cat("\n")
    if (is.finite(lb_p) && lb_p <= alpha_val) {
      cat(" [X] [1] FIX RESIDUAL AUTOCORRELATION (LB failed)\n")
      cat("     â€¢ Increase k gradually (k+1, k+2) and re-run.\n")
      cat("     â€¢ If k becomes large vs N, prefer (d=1) and/or (D=1 if seasonal) instead of pushing k.\n")
    } else if (is.finite(lb_p) && lb_p > alpha_val) {
      cat(" [âœ“] [1] RESIDUALS LOOK OK (LB passed)\n")
      cat("     â€¢ Your ADF regression is less likely biased by autocorrelation.\n")
    } else {
      cat(" [?] [1] RESIDUAL DIAGNOSTICS INCONCLUSIVE\n")
      cat("     â€¢ LB p-value is NA/Inf. Reduce k and re-run; verify x is not pathological.\n")
    }
    
    # [2] Agreement vs conflict
    cat("\n")
    if (!isTRUE(agreement_safe)) {
      cat(" [?] [2] RESOLVE THE ADF vs KPSS CONFLICT\n")
      cat("     â€¢ Re-test ADF with model types: none / drift / trend (choose what your plot suggests).\n")
      cat("     â€¢ If seasonal frequency exists, try D=1 (seasonal differencing) before debating k.\n")
      cat("     â€¢ If series is strictly positive, try log or Box-Cox for variance stabilization.\n")
      if (requireNamespace("trend", quietly = TRUE)) {
        if (is.finite(pett_p) && pett_p < alpha_val) {
          cat("     â€¢ Break detected: split sample around the break and re-run KPSS/ADF on each segment.\n")
        } else {
          cat("     â€¢ No strong break evidence at Î±: focus on model type (trend/drift) + seasonality + k.\n")
        }
      } else {
        cat("     â€¢ Install 'trend' to check breaks: install.packages('trend')\n")
      }
    } else {
      cat(" [âœ“] [2] TESTS AGREE â€” MOVE FORWARD\n")
      cat("     â€¢ Use this decision to pick d (and D if seasonal) for ARIMA/SARIMA modeling.\n")
    }
    
    # [3] Seasonality sanity with required rule: [âœ“] if resolved, else [!]
    cat("\n")
    season_tag <- if (isTRUE(seasonality_resolved)) "[âœ“]" else "[!]"
    cat(sprintf(" %s [3] SEASONALITY SANITY\n", season_tag))
    if (is.finite(x_freq) && x_freq > 1) {
      cat(sprintf("     â€¢ Frequency=%d detected.\n", x_freq))
      if (isTRUE(seasonality_resolved)) {
        cat("     â€¢ D>0 in UI indicates seasonality treatment is ON (as long as myData_Choice() applies it).\n")
      } else {
        cat("     â€¢ Consider D=1 if ACF shows seasonal spikes at lag = frequency, 2*frequency, ...\n")
      }
    } else {
      cat("     â€¢ Frequency not available: rely on plot/ACF to decide if seasonal differencing is needed.\n")
    }
    
    # [4] Explosive note
    cat("\n")
    if (identical(as.character(alt_in), "explosive")) {
      cat(" [!] [4] EXPLOSIVE MODE NOTE\n")
      cat("     â€¢ KPSS is not an explosive test. Use tseries ADF p-value + plots.\n")
    } else {
      cat(" [âœ“] [4] EXPLOSIVE MODE NOTE\n")
      cat("     â€¢ Standard stationarity workflow applies.\n")
    }
    
    
    
    # --------------------------------------------------------------------------
    # EXTRA ACTIONABLE NEXT STEPS (more complete workflow)
    # --------------------------------------------------------------------------
    
    # [5] Choose ADF model type systematically (avoid random picking)
    cat("\n")
    cat(" [!] [5] CHOOSE ADF MODEL TYPE SYSTEMATICALLY (avoid mis-specification)\n")
    cat("     â€¢ Use your time plot:\n")
    cat("       - Clear deterministic trend  â†’ set type='trend'\n")
    cat("       - No clear trend, non-zero mean â†’ set type='drift'\n")
    cat("       - Mean around ~0 (rare)      â†’ set type='none'\n")
    cat("     â€¢ Wrong type_in is a top cause of ADF vs KPSS conflict.\n")
    
    # [6] Lag strategy: use Ljung-Box as your guardrail
    cat("\n")
    cat(" [!] [6] USE LB AS A LAG-SELECTION GUARDRAIL\n")
    cat("     â€¢ Increase k until LB p-value > Î± (residuals approx. white).\n")
    cat("     â€¢ Stop increasing k if N becomes too small relative to k (risk: N <= k+10).\n")
    cat("     â€¢ If you hit that risk, prefer differencing (d or D) instead of more k.\n")
    
    # [7] Seasonality protocol (if frequency known)
    cat("\n")
    if (is.finite(x_freq) && x_freq > 1) {
      cat(" [!] [7] SEASONALITY PROTOCOL (freq detected)\n")
      cat("     â€¢ Check ACF for spikes at seasonal lags: freq, 2*freq, ...\n")
      if (isTRUE(seasonality_resolved)) {
        cat("     [âœ“] D>0 indicated â†’ ensure myData_Choice() truly applied seasonal differencing.\n")
      } else {
        cat("     [X] D=0 indicated â†’ if seasonal spikes exist, set D=1 and re-test.\n")
      }
    }
    
    # [8] Break protocol (if Pettitt available)
    cat("\n")
    if (requireNamespace("trend", quietly = TRUE)) {
      cat(" [!] [8] BREAK PROTOCOL (Pettitt)\n")
      if (is.finite(pett_p) && (pett_p < alpha_val)) {
        cat("     [!] Break detected â†’ do this:\n")
        cat("       1) Split the series around the estimated break index.\n")
        cat("       2) Re-run KPSS/ADF on each segment.\n")
        cat("       3) If segments are stationary but full sample is not â†’ break-driven non-stationarity.\n")
      } else {
        cat("     [âœ“] No strong single-break evidence at Î±.\n")
        cat("     â€¢ If conflict persists, consider multiple breaks or gradual regime changes.\n")
      }
    } else {
      cat(" [!] [8] BREAK PROTOCOL (Pettitt)\n")
      cat("     [!] trend package not installed â†’ install.packages('trend') to enable break diagnostics.\n")
    }
    
    # [9] Conservative â€œdefault safe choiceâ€ rule (useful in teaching apps)
    cat("\n")
    cat(" [!] [9] DEFAULT SAFE CHOICE (when unsure)\n")
    cat("     â€¢ If ADF/KPSS conflict persists after fixing seasonality + lag:\n")
    cat("       - Prefer differencing (d=1) (and D=1 if seasonal) then re-test.\n")
    cat("     â€¢ This reduces the chance of building ARMA on a near-integrated series.\n")
    
    # [10] Sanity check transformations inside myData_Choice()
    cat("\n")
    cat(" [!] [10] TRANSFORMATION SANITY INSIDE myData_Choice()\n")
    cat("     â€¢ Ensure the same transformed object is returned for ALL downstream tests.\n")
    cat("     â€¢ Avoid mixing ts and numeric conversions before applying frequency-based operations.\n")
    cat("     â€¢ After log, verify positivity and handle zeros (e.g., log1p) if needed.\n")
    
    
    cat("==========================================================================\n\n")
    
    # --------------------------------------------------------------------------
    # EXTRA FINAL ACADEMIC ADVICE (more complete decision logic)
    # --------------------------------------------------------------------------
    
    # Power / sample size warnings (high impact)
    if (valid_N < 30) {
      cat(" [!] Power warning: with N < 30, ADF/KPSS can be unstable (low power / size distortions).\n")
      if (valid_N < 15) {
        cat("     [X] N < 15 is very weak for reliable inference; treat conclusions as provisional.\n")
      } else {
        cat("     [?] N is borderline; combine with plots + conservative transformations.\n")
      }
    } else {
      cat(" [âœ“] Sample size is generally adequate for classical stationarity tests.\n")
    }
    
    # Lag-vs-N safety
    if (valid_N <= (k + 10)) {
      cat(" [!] Lag risk: k is large relative to N (N <= k+10). Regression-based tests may misbehave.\n")
      cat("     Action: reduce k OR increase N, and prefer differencing/seasonal differencing over huge k.\n")
    } else {
      cat(" [âœ“] Lag order looks safe relative to N.\n")
    }
    
    # Model-type specification advice (none/drift/trend)
    cat(" [!] Model-type (none/drift/trend) matters:\n")
    cat("     â€¢ If the series has a visible non-zero mean but no deterministic trend â†’ prefer 'drift'.\n")
    cat("     â€¢ If the series has a clear deterministic trend â†’ prefer 'trend'.\n")
    cat("     â€¢ If the series oscillates around zero (rare in real data) â†’ 'none'.\n")
    
    # Seasonality: warn if frequency exists but D not indicated
    if (is.finite(x_freq) && x_freq > 1 && !isTRUE(seasonality_resolved)) {
      cat(" [!] Seasonality risk: frequency suggests seasonality, but D=0 in UI.\n")
      cat("     Missing seasonal differencing can cause KPSS to reject stationarity and/or ADF to look borderline.\n")
    } else if (is.finite(x_freq) && x_freq > 1 && isTRUE(seasonality_resolved)) {
      cat(" [âœ“] Seasonality flag: D>0 in UI indicates seasonal treatment is intended.\n")
    }
    
    # Structural break contamination (Pettitt)
    if (requireNamespace("trend", quietly = TRUE) && is.finite(pett_p) && (pett_p < alpha_val)) {
      cat(" [!] Structural break contamination: Pettitt indicates a change-point (p < Î±).\n")
      cat("     ADF/KPSS disagreements are common under breaks; consider segment tests or break-aware models.\n")
    }
    
    # Near-unit-root / borderline zone heuristic
    # (We don't have direct 'borderline' threshold universally, so we use agreement + p-values)
    if (!isTRUE(agreement_safe) && is.finite(adf_p) && is.finite(eta_p_one)) {
      if (adf_p > 0.01 && adf_p < 0.10 && eta_p_one > 0.01 && eta_p_one < 0.10) {
        cat(" [?] Near-unit-root zone: both tests are near typical cutoffs.\n")
        cat("     Treat the series as highly persistent; prefer conservative differencing and validate by forecasting performance.\n")
      }
    }
    
    # Explosive alternative caveat (important correctness note)
    if (identical(as.character(alt_in), "explosive")) {
      cat(" [!] Explosive caveat: urca tau critical values are for the usual left-tail unit-root framework.\n")
      cat("     For explosive detection, rely primarily on tseries::adf.test p-value (right-tail) + plots.\n")
    }
    
    
    cat("==========================================================================\n\n")
    
    # Practical path
    cat(" PRACTICAL MODELING PATH:\n")
    if (isTRUE(is_stationary) && is.finite(lb_p) && (lb_p > alpha_val)) {
      cat(" [âœ“] Treat as I(0): identify ARMA on current series â†’ fit â†’ residual analysis.\n")
    } else if (!isTRUE(is_stationary)) {
      cat(" [X] Treat as I(1): apply differencing (d and/or D) â†’ re-test â†’ then identify ARMA.\n")
    } else {
      cat(" [?] Borderline/mixed: prefer conservative differencing and validate with residual diagnostics.\n")
    }
    
    cat("==========================================================================\n\n")
    
    
    
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  # ====================================================================
  # ====================================================================
  # ====================================================================
  #
  #                          - HELP -
  #
  # ====================================================================
  # ====================================================================
  # ====================================================================
  
  
  
  
  # ---- Roadmap Detailed & teaching notes ----
  
  
  output$roadmap_Detailed_Ang_ui <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      tags$hr(),
      
      tags$p(
        "Below is a ",
        tags$b("practical, SARIMA Modeling roadmap"),
      ),
      
      tags$hr(),
      
      tags$h4("[0] - Set the stage: define the modeling problem"),
      
      tags$h5("What students do"),
      tags$ul(
        tags$li("Define the ", tags$b("response series"), " (y_t) (what you forecast)."),
        tags$li("Define the ", tags$b("time index"), " (daily/weekly/monthly), and confirm itâ€™s consistent."),
        tags$li(
          "Define the ", tags$b("forecast task"), ":",
          tags$ul(
            tags$li("horizon (e.g., 12 months ahead),"),
            tags$li("evaluation scheme (rolling-origin or simple train/test split),"),
            tags$li("loss metric (MAE/RMSE/MAPE/sMAPE).")
          )
        ),
        tags$li(
          "Decide whether youâ€™ll model in:",
          tags$ul(
            tags$li(tags$b("levels"), " (raw data),"),
            tags$li(tags$b("log-levels"), " (common if variance grows with level),"),
            tags$li(tags$b("Boxâ€“Cox"), " transformed space (more general).")
          )
        )
      ),
      
      tags$h5("What they write (paper)"),
      tags$p(
        tags$b("Methods (Data & Objective). "),
        "â€œWe modeled the univariate time series (y_t) observed at a [monthly] frequency from [start] to [end] (n=...). ",
        "The objective was to forecast (h=...) steps ahead. Model performance was evaluated using [metric(s)] under a ",
        "[train/test or rolling-origin] evaluation design.â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("SARIMA assumes ", tags$b("regular spacing"), "; irregular timestamps need fixing before anything else."),
        tags$li("SARIMA models ", tags$b("one series"), " (no predictors). If you have external regressors, thatâ€™s SARIMAX.")
      ),
      
      tags$hr(),
      
      tags$h4("[1] - Describe the data: sample size, missing values, descriptive statistics"),
      
      tags$h5("What students do"),
      tags$ol(
        tags$li(
          "Report:",
          tags$ul(
            tags$li("sample size (n),"),
            tags$li("start/end dates,"),
            tags$li("frequency,"),
            tags$li("number/percent missing values.")
          )
        ),
        tags$li(
          "Handle missingness:",
          tags$ul(
            tags$li("If rare and random: impute (linear interpolation, seasonal interpolation)."),
            tags$li("If many: reconsider the series, frequency, or data source.")
          )
        ),
        tags$li(
          "Descriptive stats:",
          tags$ul(
            tags$li("mean, median, sd, min/max,"),
            tags$li("maybe skewness/kurtosis,"),
            tags$li("and seasonal summaries (e.g., average by month).")
          )
        )
      ),
      
      tags$h5("What they write (APA-style)"),
      tags$p(
        tags$b("Results (Data description). "),
        "â€œThe series contained (n=...) observations spanning [dates] at a [frequency] frequency. ",
        "Missing values accounted for (...%) of observations (k=... points). Missing observations were handled using ",
        "[method], selected because [reason]. The distribution of (y_t) showed a mean of (...) (SD=(...)), median (...), ",
        "and range ([...,...]).â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("Donâ€™t â€œsilentlyâ€ imputeâ€”", tags$b("always justify"), " it."),
        tags$li("If you log-transform, describe the transformed series stats too.")
      ),
      
      tags$hr(),
      
      tags$h4("[2] - Explore visually: trend/seasonality/outliers; report observations"),
      
      tags$h5("What students do"),
      tags$p("Make plots and annotate:"),
      tags$ul(
        tags$li(tags$b("Line plot"), " of (y_t)."),
        tags$li(tags$b("Seasonal plot"), " (e.g., month-of-year lines)."),
        tags$li(tags$b("Boxplot by season"), " (month/quarter/week)."),
        tags$li(
          tags$b("Outlier check"), ":",
          tags$ul(
            tags$li("z-scores, IQR rule, or robust methods,"),
            tags$li("but also context (holidays, policy changes, measurement glitches).")
          )
        )
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Results (Exploratory analysis). "),
        "â€œVisual inspection indicated [an upward/downward] trend and recurring seasonal fluctuations with period (s=...). ",
        "Variability appeared [constant/increasing with level], suggesting [no transformation / log transformation]. ",
        "Several potential outliers were observed around [dates], likely associated with [context], and were ",
        "[retained/adjusted] because [reason].â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("Outliers arenâ€™t automatically â€œbadâ€â€”they might be real events that your forecast must respect."),
        tags$li("If variance grows with level, SARIMA often behaves better after a ", tags$b("log"), " or ", tags$b("Boxâ€“Cox"), " transform.")
      ),
      
      tags$hr(),
      
      tags$h4("[3] - Decompose: justify additive vs multiplicative; use STL when robust needed"),
      
      tags$h5("What students do"),
      tags$p("Perform decomposition to separate:"),
      tags$ul(
        tags$li("trend,"),
        tags$li("seasonality,"),
        tags$li("remainder.")
      ),
      
      tags$p(tags$b("Choose model form:")),
      tags$ul(
        tags$li(tags$b("Additive:"), " (y_t = T_t + S_t + e_t). Use when seasonal amplitude is roughly constant."),
        tags$li(tags$b("Multiplicative:"), " (y_t = T_t Ã— S_t Ã— e_t). Use when seasonal amplitude grows with the level (often solved by log transform â†’ additive in log space).")
      ),
      
      tags$p(tags$b("Use STL decomposition when:")),
      tags$ul(
        tags$li("seasonality changes slowly over time,"),
        tags$li("you want robustness to outliers.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Decomposition). "),
        "â€œWe assessed additive versus multiplicative structure by examining whether seasonal amplitude scaled with the series level. ",
        "Because [seasonal variation was approximately constant / increased with level], we used an [additive model / log transformation] ",
        "and decomposed the series using [classical decomposition / STL]. STL was selected due to its robustness to outliers and its flexibility ",
        "in modeling evolving seasonality.â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("â€œMultiplicative seasonalityâ€ and â€œlog transformâ€ are basically best friends."),
        tags$li("STL decomposition is descriptive; SARIMA fitting still needs stationarity checks.")
      ),
      
      tags$hr(),
      
      tags$h4("[4] - Check stationarity: ADF/KPSS/PP; justify differencing (d and D)"),
      tags$p("SARIMA needs stationarity ", tags$b("after differencing"), "."),
      
      tags$h5("What students do"),
      tags$ol(
        tags$li("Define seasonal period (s) (e.g., 12 for monthly, 7 for daily-with-weekly seasonality)."),
        tags$li(
          "Test stationarity on:",
          tags$ul(
            tags$li("original series,"),
            tags$li("after ", tags$b("regular differencing"), " ((1-B)^d),"),
            tags$li("after ", tags$b("seasonal differencing"), " ((1-B^s)^D),"),
            tags$li("and sometimes after both.")
          )
        )
      ),
      
      tags$h5("Stationarity tests: what they do, H0/Ha, and how to conclude"),
      tags$ul(
        
        tags$li(
          tags$b("ADF test (Augmented Dickeyâ€“Fuller)"),
          tags$ul(
            tags$li(tags$b("What it does:"), " tests whether the series behaves like it has a ", tags$b("unit root"),
                    " (a stochastic trend), which implies non-stationarity; the test estimates a regression where lagged differences are added to handle autocorrelation."),
            tags$li(tags$b("H0:"), " the series has a unit root (non-stationary; shocks have permanent effects)."),
            tags$li(tags$b("Ha:"), " the series does not have a unit root (stationary around a mean or around a deterministic trend, depending on the ADF specification)."),
            tags$li(tags$b("Conclusion sentence template:"), " â€œThe ADF test yielded p = [p-value]; therefore, at Î± = [alpha] we ",
                    tags$b("[reject / fail to reject]"), " H0 that the series contains a unit root. This implies the series is ",
                    tags$b("[stationary / non-stationary]"), " under the ADF framework, so we ",
                    tags$b("[did not apply additional differencing / applied]"), " [d=â€¦] regular and/or [D=â€¦] seasonal differencing to obtain an approximately stationary series suitable for SARIMA estimation.â€")
          )
        ),
        
        tags$li(
          tags$b("KPSS test (Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin)"),
          tags$ul(
            tags$li(tags$b("What it does:"), " tests stationarity by examining whether the cumulative sum of residuals (from a level or trend regression) is too large; it is designed as a complement to ADF by flipping the null hypothesis."),
            tags$li(tags$b("H0:"), " the series is stationary (level-stationary, or trend-stationary if a trend is included)."),
            tags$li(tags$b("Ha:"), " the series is non-stationary (contains a unit root or otherwise violates stationarity)."),
            tags$li(tags$b("Conclusion sentence template:"), " â€œThe KPSS test produced p = [p-value]; thus, at Î± = [alpha] we ",
                    tags$b("[reject / fail to reject]"), " H0 of stationarity. This indicates the series is ",
                    tags$b("[not stationary / consistent with stationarity]"), " in the KPSS sense, which ",
                    tags$b("[supports applying / does not require]"), " additional differencing; we therefore selected differencing orders [d=â€¦] and [D=â€¦] and rechecked stationarity on the transformed series.â€")
          )
        ),
        
        tags$li(
          tags$b("PP test (Phillipsâ€“Perron)"),
          tags$ul(
            tags$li(tags$b("What it does:"), " tests for a unit root like ADF, but uses a nonparametric correction for autocorrelation and heteroskedasticity in the errors (instead of adding many lagged difference terms)."),
            tags$li(tags$b("H0:"), " the series has a unit root (non-stationary)."),
            tags$li(tags$b("Ha:"), " the series does not have a unit root (stationary)."),
            tags$li(tags$b("Conclusion sentence template:"), " â€œThe PP test returned p = [p-value]; accordingly, at Î± = [alpha] we ",
                    tags$b("[reject / fail to reject]"), " H0 of a unit root. Interpreted alongside ADF and KPSS results, this suggests the series is ",
                    tags$b("[stationary / non-stationary]"), " after applying [d=â€¦] regular and [D=â€¦] seasonal differences, supporting the use of SARIMA on the differenced series.â€")
          )
        )
      ),
      
      tags$p(
        tags$b("How to interpret ADF/KPSS/PP together (the logic students should write).")
      ),
      tags$ul(
        tags$li(tags$b("Best-case agreement:"), " ADF/PP reject unit root (small p) and KPSS fails to reject stationarity (large p) â†’ strong evidence of stationarity."),
        tags$li(tags$b("Clear non-stationarity:"), " ADF/PP fail to reject unit root (large p) and KPSS rejects stationarity (small p) â†’ strong evidence you need differencing."),
        tags$li(tags$b("Conflicts happen:"), " when tests disagree, prioritize the combination of evidence: plots + ACF behavior + results after differencing, and report that conclusions were based on the converging pattern rather than a single p-value.")
      ),
      
      tags$p(tags$b("Differencing logic:")),
      tags$ul(
        tags$li("Choose ", tags$b("d"), " to remove trend / unit root."),
        tags$li("Choose ", tags$b("D"), " to remove seasonal unit root."),
        tags$li("Stop as soon as stationarity is reasonable; avoid over-differencing.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Stationarity and differencing). "),
        "â€œStationarity was assessed using ADF, KPSS, and PP tests to triangulate evidence because the tests use different null hypotheses. ",
        "Based on the combined results and visual diagnostics, we selected [d=...] regular differences and [D=...] seasonal differences with seasonal period (s=...). ",
        "This differencing order was chosen to remove [trend/seasonal unit root] while avoiding over-differencing, and stationarity was re-evaluated on the transformed series before fitting SARIMA models.â€"
      ),
      
      tags$h5("Pitfalls (classic)"),
      tags$ul(
        tags$li(
          tags$b("Over-differencing"),
          " causes:",
          tags$ul(
            tags$li("strong negative lag-1 autocorrelation,"),
            tags$li("inflated variance,"),
            tags$li("messier forecasts.")
          )
        ),
        tags$li("D is usually ", tags$b("0 or 1"), " in real life. If you need (D=2), the series may be weird or the seasonal period is wrong.")
      ),
      
      tags$hr(),
      
      tags$h4("[5] - Fit a baseline model: Auto-ARIMA to obtain a strong starting SARIMA"),
      
      tags$h5("What students do"),
      tags$ul(
        tags$li("Use an ", tags$b("auto-ARIMA"), " procedure (AICc-based or similar) to propose: ((p,d,q)(P,D,Q)_s)."),
        tags$li(
          "Keep track of:",
          tags$ul(
            tags$li("transformations used,"),
            tags$li("constraints (max p/q etc.),"),
            tags$li("whether stepwise search was used.")
          )
        ),
        tags$li(tags$b("Important:"), " Auto-ARIMA gives a baseline, not truth carved into granite.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Baseline model). "),
        "â€œA baseline SARIMA model was selected using an automated information-criterion approach (minimizing AICc) over candidate orders ((p,q,P,Q)) ",
        "subject to [bounds]. The chosen baseline specification was SARIMA((p,d,q)(P,D,Q)_s), which served as the reference model for subsequent theory-driven refinement.â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("Auto-ARIMA can pick models that are statistically fine but ", tags$b("hard to interpret"), " or slightly unstable."),
        tags$li("If your evaluation is forecast-focused, itâ€™s okay to prefer ", tags$b("simpler"), " models with similar accuracy.")
      ),
      
      tags$hr(),
      
      tags$h4("[6] - Fit a theory-driven model: Manual SARIMA using ACF/PACF + tests"),
      
      tags$h5("What students do"),
      tags$p("Using the differenced series (after chosen (d, D)):"),
      tags$ol(
        tags$li("Plot ", tags$b("ACF/PACF"), "."),
        tags$li(
          "Propose candidate structures:",
          tags$ul(
            tags$li(
              "Nonseasonal:",
              tags$ul(
                tags$li("AR(p): PACF cuts off around p; ACF tails."),
                tags$li("MA(q): ACF cuts off around q; PACF tails.")
              )
            ),
            tags$li(
              "Seasonal:",
              tags$ul(
                tags$li("seasonal AR(P): PACF spikes at lags (s, 2s, ...)."),
                tags$li("seasonal MA(Q): ACF spikes at lags (s, 2s, ...).")
              )
            )
          )
        ),
        tags$li("Fit a ", tags$b("small set"), " of plausible candidates (e.g., 3â€“8 models)."),
        tags$li(
          "Use tests/criteria:",
          tags$ul(
            tags$li("AICc/BIC,"),
            tags$li("parameter significance (with caution),"),
            tags$li("stability/invertibility checks.")
          )
        )
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Methods (Theory-driven model building). "),
        "â€œCandidate SARIMA structures were proposed based on ACF/PACF behavior of the differenced series. Spikes at [lags] suggested nonseasonal [AR/MA] components, ",
        "while prominent autocorrelation at multiples of (s) indicated seasonal [AR/MA] terms. Several candidate models were fitted and compared using [AICc/BIC], with final selection also considering parsimony and diagnostic adequacy.â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("ACF/PACF heuristics are ", tags$b("guides"), ", not commandments."),
        tags$li("Donâ€™t brute-force 200 models and pretend itâ€™s â€œtheory-driven.â€ Pick a ", tags$b("small, reasoned set"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[7] - Diagnose & compare: residual tests + forecast accuracy; choose final model"),
      
      tags$h5("What students do"),
      tags$p(tags$b("Residual diagnostics (must-do):")),
      tags$ul(
        tags$li("Residual time plot (should look like noise)."),
        tags$li("Residual ACF (no big spikes)."),
        tags$li(tags$b("Ljungâ€“Box test"), " for residual autocorrelation."),
        tags$li("Normality checks (QQ plot; Shapiro-Wilk is too sensitive for big n)."),
        tags$li("Check heteroskedasticity (variance changing over time).")
      ),
      
      tags$p(tags$b("Forecast evaluation (must-do):")),
      tags$ul(
        tags$li("Holdout or rolling cross-validation."),
        tags$li("Metrics: MAE/RMSE; MAPE only if data never near zero."),
        tags$li(
          "Compare:",
          tags$ul(
            tags$li("baseline auto-ARIMA,"),
            tags$li("manual SARIMA candidates,"),
            tags$li("maybe a simple benchmark (seasonal naive).")
          )
        )
      ),
      
      tags$p(tags$b("Model choice rule (healthy):")),
      tags$ul(
        tags$li("Must pass diagnostics reasonably well."),
        tags$li("Must beat naive benchmark."),
        tags$li("Prefer simpler model if accuracy is essentially tied.")
      ),
      
      tags$h5("What they write"),
      tags$p(
        tags$b("Results (Model diagnostics and performance). "),
        "â€œResidual diagnostics indicated approximate white-noise behavior: residual autocorrelations were small and the Ljungâ€“Box test was [non-significant/significant] at (Î±=...). ",
        "Forecast performance over the evaluation window showed MAE=(...) and RMSE=(...), outperforming the baseline and benchmark models. Based on diagnostic adequacy and predictive performance, the final selected model was SARIMA((p,d,q)(P,D,Q)_s).â€"
      ),
      
      tags$h5("Pitfalls"),
      tags$ul(
        tags$li("A model with great AIC but autocorrelated residuals is basically ", tags$i("lying to you politely"), "."),
        tags$li("If residuals are non-normal, forecasts can still be good; the bigger issue is ", tags$b("autocorrelation"), " left in residuals.")
      ),
      
      tags$hr(),
      
      tags$h4("[8] - Write your paper: use APA paragraphs in each step; assemble Methods/Results"),
      
      tags$h5("What students do (assembly checklist)"),
      tags$p(tags$b("Methods section")),
      tags$ul(
        tags$li("Data (source, frequency, missing handling, transformation)."),
        tags$li("Exploratory approach (plots used, decomposition method)."),
        tags$li("Stationarity tests and differencing decisions."),
        tags$li("Baseline (auto-ARIMA settings)."),
        tags$li("Manual model selection rationale (ACF/PACF + candidates)."),
        tags$li("Diagnostics and evaluation scheme.")
      ),
      
      tags$p(tags$b("Results section")),
      tags$ul(
        tags$li("Data summary + key visual observations."),
        tags$li("Decomposition findings (trend/seasonality statements)."),
        tags$li("Stationarity test outcomes and chosen (d, D)."),
        tags$li("Final model parameters."),
        tags$li("Diagnostics results and accuracy results."),
        tags$li("Forecast plot + table of errors.")
      ),
      
      tags$h5("What they write (APA structure guidance)"),
      tags$ul(
        tags$li("Keep each subsection as: ", tags$b("What we did â†’ Why â†’ What we found â†’ What we concluded"), "."),
        tags$li("Use past tense for Methods, results-oriented past tense for Results."),
        tags$li("Put the math in-line sparingly; put full model spec once, clearly.")
      ),
      
      tags$hr(),
      
      tags$h4("A clean â€œdeliverable packageâ€ students should submit"),
      tags$ul(
        tags$li(
          "A notebook/script that:",
          tags$ul(
            tags$li("loads data,"),
            tags$li("handles missingness,"),
            tags$li("performs EDA plots,"),
            tags$li("decomposition,"),
            tags$li("stationarity tests,"),
            tags$li("baseline auto-ARIMA,"),
            tags$li("manual candidates,"),
            tags$li("diagnostics,"),
            tags$li("evaluation,"),
            tags$li("and final forecast.")
          )
        ),
        tags$li(
          "A short paper with:",
          tags$ul(
            tags$li("Methods + Results sections aligned to steps 1â€“7,"),
            tags$li("figures: time plot, decomposition, ACF/PACF, residual ACF, forecast plot,"),
            tags$li("a table comparing candidate models (AICc + metrics).")
          )
        )
      ),
      
      tags$hr(),
      
    )
  })
  
  
  
  
  #=============================================================================
  #=============================================================================
  #=============================================================================
  
  
  
  output$roadmap_Detailed_Fr_ui <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      tags$hr(),
      
      tags$p(
        "Ci-dessous, une ",
        tags$b("feuille de route pratique de modÃ©lisation SARIMA"),
        "."
      ),
      
      tags$hr(),
      
      tags$h4("[0] - PrÃ©parer le terrain : dÃ©finir le problÃ¨me de modÃ©lisation"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ul(
        tags$li("DÃ©finir la ", tags$b("sÃ©rie rÃ©ponse"), " (y_t) (ce que lâ€™on prÃ©voit)."),
        tags$li("DÃ©finir lâ€™", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vÃ©rifier quâ€™il est cohÃ©rent."),
        tags$li(
          "DÃ©finir la ", tags$b("tÃ¢che de prÃ©vision"), " :",
          tags$ul(
            tags$li("horizon (ex. : 12 mois Ã  lâ€™avance),"),
            tags$li("schÃ©ma dâ€™Ã©valuation (origine glissante / rolling-origin ou simple dÃ©coupage apprentissage/test),"),
            tags$li("mÃ©trique de perte (MAE/RMSE/MAPE/sMAPE).")
          )
        ),
        tags$li(
          "DÃ©cider si lâ€™on modÃ©lise en :",
          tags$ul(
            tags$li(tags$b("niveaux"), " (donnÃ©es brutes),"),
            tags$li(tags$b("log-niveaux"), " (frÃ©quent si la variance augmente avec le niveau),"),
            tags$li("espace transformÃ© ", tags$b("Boxâ€“Cox"), " (plus gÃ©nÃ©ral).")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent (papier)"),
      tags$p(
        tags$b("MÃ©thodes (DonnÃ©es & Objectif). "),
        "Â« Nous avons modÃ©lisÃ© la sÃ©rie temporelle univariÃ©e (y_t) observÃ©e Ã  une frÃ©quence [mensuelle] de [dÃ©but] Ã  [fin] (n=...). ",
        "Lâ€™objectif Ã©tait de prÃ©voir Ã  un horizon de (h=...) pas. La performance du modÃ¨le a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide de [mÃ©trique(s)] selon un protocole ",
        "[apprentissage/test ou origine glissante]. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("SARIMA suppose un ", tags$b("espacement rÃ©gulier"), " ; des timestamps irrÃ©guliers doivent Ãªtre corrigÃ©s avant toute chose."),
        tags$li("SARIMA modÃ©lise ", tags$b("une seule sÃ©rie"), " (sans prÃ©dicteurs). Avec des variables explicatives, on parle plutÃ´t de SARIMAX.")
      ),
      
      tags$hr(),
      
      tags$h4("[1] - DÃ©crire les donnÃ©es : taille dâ€™Ã©chantillon, valeurs manquantes, statistiques descriptives"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ol(
        tags$li(
          "Rapporter :",
          tags$ul(
            tags$li("taille dâ€™Ã©chantillon (n),"),
            tags$li("dates de dÃ©but/fin,"),
            tags$li("frÃ©quence,"),
            tags$li("nombre/pourcentage de valeurs manquantes.")
          )
        ),
        tags$li(
          "GÃ©rer le manque :",
          tags$ul(
            tags$li("Sâ€™il est rare et alÃ©atoire : imputer (interpolation linÃ©aire, interpolation saisonniÃ¨re)."),
            tags$li("Sâ€™il est important : reconsidÃ©rer la sÃ©rie, la frÃ©quence ou la source de donnÃ©es.")
          )
        ),
        tags$li(
          "Statistiques descriptives :",
          tags$ul(
            tags$li("moyenne, mÃ©diane, Ã©cart-type, min/max,"),
            tags$li("Ã©ventuellement asymÃ©trie (skewness) / kurtosis,"),
            tags$li("et rÃ©sumÃ©s saisonniers (ex. : moyenne par mois).")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent (style APA)"),
      tags$p(
        tags$b("RÃ©sultats (Description des donnÃ©es). "),
        "Â« La sÃ©rie contient (n=...) observations couvrant [dates] Ã  une frÃ©quence [frÃ©quence]. ",
        "Les valeurs manquantes reprÃ©sentaient (...%) des observations (k=... points). Les observations manquantes ont Ã©tÃ© traitÃ©es par ",
        "[mÃ©thode], choisie car [raison]. La distribution de (y_t) prÃ©sentait une moyenne de (...) (ET=(...)), une mÃ©diane (...), ",
        "et un intervalle ([...,...]). Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Ne pas imputer Â« silencieusement Â» â€” ", tags$b("toujours justifier"), "."),
        tags$li("Si une transformation logarithmique est appliquÃ©e, dÃ©crire aussi les statistiques de la sÃ©rie transformÃ©e.")
      ),
      
      tags$hr(),
      
      tags$h4("[2] - Explorer visuellement : tendance/saisonnalitÃ©/valeurs aberrantes ; rapporter les observations"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("Produire des graphiques et les commenter :"),
      tags$ul(
        tags$li(tags$b("Courbe"), " de (y_t)."),
        tags$li(tags$b("Graphique saisonnier"), " (ex. : lignes par mois de lâ€™annÃ©e)."),
        tags$li(tags$b("BoÃ®te Ã  moustaches par saison"), " (mois/trimestre/semaine)."),
        tags$li(
          tags$b("DÃ©tection dâ€™outliers"), " :",
          tags$ul(
            tags$li("z-scores, rÃ¨gle IQR, ou mÃ©thodes robustes,"),
            tags$li("mais aussi le contexte (fÃªtes, changements de politique, erreurs de mesure).")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("RÃ©sultats (Analyse exploratoire). "),
        "Â« Lâ€™inspection visuelle a indiquÃ© une tendance [haussiÃ¨re/baissiÃ¨re] et des fluctuations saisonniÃ¨res rÃ©currentes de pÃ©riode (s=...). ",
        "La variabilitÃ© semblait [constante/augmenter avec le niveau], suggÃ©rant [aucune transformation / une transformation logarithmique]. ",
        "Plusieurs valeurs potentiellement aberrantes ont Ã©tÃ© observÃ©es autour de [dates], probablement liÃ©es Ã  [contexte], et ont Ã©tÃ© ",
        "[conservÃ©es/ajustÃ©es] car [raison]. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Les outliers ne sont pas automatiquement Â« mauvais Â» : ils peuvent correspondre Ã  des Ã©vÃ©nements rÃ©els que la prÃ©vision doit respecter."),
        tags$li("Si la variance augmente avec le niveau, SARIMA se comporte souvent mieux aprÃ¨s une transformation ", tags$b("log"), " ou ", tags$b("Boxâ€“Cox"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[3] - DÃ©composer : justifier additif vs multiplicatif ; utiliser STL si robustesse nÃ©cessaire"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("RÃ©aliser une dÃ©composition pour sÃ©parer :"),
      tags$ul(
        tags$li("tendance,"),
        tags$li("saisonnalitÃ©,"),
        tags$li("reste (bruit).")
      ),
      
      tags$p(tags$b("Choisir la forme du modÃ¨le :")),
      tags$ul(
        tags$li(tags$b("Additive :"), " (y_t = T_t + S_t + e_t). Ã€ utiliser lorsque lâ€™amplitude saisonniÃ¨re est Ã  peu prÃ¨s constante."),
        tags$li(tags$b("Multiplicative :"), " (y_t = T_t Ã— S_t Ã— e_t). Ã€ utiliser lorsque lâ€™amplitude saisonniÃ¨re augmente avec le niveau (souvent rÃ©solu par log â†’ additif en espace log).")
      ),
      
      tags$p(tags$b("Utiliser la dÃ©composition STL lorsque :")),
      tags$ul(
        tags$li("la saisonnalitÃ© Ã©volue lentement au fil du temps,"),
        tags$li("on souhaite une robustesse aux outliers.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (DÃ©composition). "),
        "Â« Nous avons Ã©valuÃ© une structure additive versus multiplicative en examinant si lâ€™amplitude saisonniÃ¨re Ã©voluait avec le niveau de la sÃ©rie. ",
        "Comme [la variation saisonniÃ¨re Ã©tait approximativement constante / augmentait avec le niveau], nous avons utilisÃ© [un modÃ¨le additif / une transformation logarithmique] ",
        "et dÃ©composÃ© la sÃ©rie via [dÃ©composition classique / STL]. STL a Ã©tÃ© retenue pour sa robustesse aux valeurs aberrantes et sa flexibilitÃ© ",
        "dans la modÃ©lisation dâ€™une saisonnalitÃ© Ã©volutive. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Â« Saison multiplicative Â» et Â« transformation log Â» sont pratiquement meilleurs amis."),
        tags$li("La dÃ©composition STL est descriptive ; lâ€™estimation SARIMA nÃ©cessite toujours des vÃ©rifications de stationnaritÃ©.")
      ),
      
      tags$hr(),
      
      tags$h4("[4] - VÃ©rifier la stationnaritÃ© : ADF/KPSS/PP ; justifier la diffÃ©renciation (d et D)"),
      tags$p("SARIMA requiert la stationnaritÃ© ", tags$b("aprÃ¨s diffÃ©renciation"), "."),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ol(
        tags$li("DÃ©finir la pÃ©riode saisonniÃ¨re (s) (ex. : 12 pour des donnÃ©es mensuelles, 7 pour des donnÃ©es quotidiennes avec saisonnalitÃ© hebdomadaire)."),
        tags$li(
          "Tester la stationnaritÃ© sur :",
          tags$ul(
            tags$li("la sÃ©rie originale,"),
            tags$li("aprÃ¨s ", tags$b("diffÃ©renciation ordinaire"), " ((1-B)^d),"),
            tags$li("aprÃ¨s ", tags$b("diffÃ©renciation saisonniÃ¨re"), " ((1-B^s)^D),"),
            tags$li("et parfois aprÃ¨s les deux.")
          )
        )
      ),
      
      tags$h5("Tests de stationnaritÃ© : rÃ´le, H0/Ha, et conclusion"),
      tags$ul(
        tags$li(
          tags$b("Test ADF (Augmented Dickeyâ€“Fuller)"),
          tags$ul(
            tags$li(tags$b("RÃ´le :"), " tester si la sÃ©rie se comporte comme si elle avait une ", tags$b("racine unitaire"),
                    " (tendance stochastique), impliquant la non-stationnaritÃ© ; le test estime une rÃ©gression oÃ¹ des diffÃ©rences retardÃ©es sont ajoutÃ©es pour gÃ©rer lâ€™autocorrÃ©lation."),
            tags$li(tags$b("H0 :"), " la sÃ©rie a une racine unitaire (non-stationnaire ; les chocs ont des effets permanents)."),
            tags$li(tags$b("Ha :"), " la sÃ©rie nâ€™a pas de racine unitaire (stationnaire autour dâ€™une moyenne ou autour dâ€™une tendance dÃ©terministe, selon la spÃ©cification ADF)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " Â« Le test ADF a donnÃ© p = [p-value] ; ainsi, au seuil Î± = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 (racine unitaire). Cela implique que la sÃ©rie est ",
                    tags$b("[stationnaire / non-stationnaire]"), " selon lâ€™ADF ; nous ",
                    tags$b("[nâ€™avons pas appliquÃ© de diffÃ©renciation supplÃ©mentaire / avons appliquÃ©]"), " une diffÃ©renciation ordinaire [d=â€¦] et/ou saisonniÃ¨re [D=â€¦] afin dâ€™obtenir une sÃ©rie approximativement stationnaire adaptÃ©e Ã  lâ€™estimation SARIMA. Â»")
          )
        ),
        tags$li(
          tags$b("Test KPSS (Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin)"),
          tags$ul(
            tags$li(tags$b("RÃ´le :"), " tester la stationnaritÃ© en examinant si la somme cumulÃ©e des rÃ©sidus (dâ€™une rÃ©gression de niveau ou de tendance) est trop importante ; câ€™est un complÃ©ment Ã  lâ€™ADF en inversant lâ€™hypothÃ¨se nulle."),
            tags$li(tags$b("H0 :"), " la sÃ©rie est stationnaire (stationnaire en niveau, ou stationnaire en tendance si une tendance est incluse)."),
            tags$li(tags$b("Ha :"), " la sÃ©rie est non-stationnaire (contient une racine unitaire ou viole la stationnaritÃ©)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " Â« Le test KPSS a donnÃ© p = [p-value] ; au seuil Î± = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 de stationnaritÃ©. Cela indique que la sÃ©rie est ",
                    tags$b("[non stationnaire / compatible avec la stationnaritÃ©]"), " au sens KPSS ; cela ",
                    tags$b("[soutient lâ€™application / ne nÃ©cessite pas]"), " dâ€™une diffÃ©renciation additionnelle. Nous avons donc retenu [d=â€¦] et [D=â€¦] puis revÃ©rifiÃ© la stationnaritÃ© sur la sÃ©rie transformÃ©e. Â»")
          )
        ),
        tags$li(
          tags$b("Test PP (Phillipsâ€“Perron)"),
          tags$ul(
            tags$li(tags$b("RÃ´le :"), " tester une racine unitaire comme lâ€™ADF, mais en utilisant une correction non paramÃ©trique de lâ€™autocorrÃ©lation et de lâ€™hÃ©tÃ©roscÃ©dasticitÃ© (au lieu dâ€™ajouter de nombreux retards)."),
            tags$li(tags$b("H0 :"), " la sÃ©rie a une racine unitaire (non-stationnaire)."),
            tags$li(tags$b("Ha :"), " la sÃ©rie nâ€™a pas de racine unitaire (stationnaire)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " Â« Le test PP a donnÃ© p = [p-value] ; ainsi, au seuil Î± = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 de racine unitaire. InterprÃ©tÃ© avec lâ€™ADF et le KPSS, cela suggÃ¨re que la sÃ©rie est ",
                    tags$b("[stationnaire / non-stationnaire]"), " aprÃ¨s application de [d=â€¦] diffÃ©renciations ordinaires et [D=â€¦] diffÃ©renciations saisonniÃ¨res ; cela soutient lâ€™usage dâ€™un SARIMA sur la sÃ©rie diffÃ©renciÃ©e. Â»")
          )
        )
      ),
      
      tags$p(tags$b("InterprÃ©ter ADF/KPSS/PP ensemble (logique Ã  Ã©crire).")),
      tags$ul(
        tags$li(tags$b("Accord idÃ©al :"), " ADF/PP rejettent la racine unitaire (p petit) et KPSS ne rejette pas la stationnaritÃ© (p grand) â†’ forte Ã©vidence de stationnaritÃ©."),
        tags$li(tags$b("Non-stationnaritÃ© claire :"), " ADF/PP ne rejettent pas la racine unitaire (p grand) et KPSS rejette la stationnaritÃ© (p petit) â†’ forte Ã©vidence quâ€™une diffÃ©renciation est nÃ©cessaire."),
        tags$li(tags$b("Conflits :"), " lorsque les tests divergent, sâ€™appuyer sur lâ€™ensemble des preuves : graphiques + comportement de lâ€™ACF + rÃ©sultats aprÃ¨s diffÃ©renciation, et indiquer que la conclusion repose sur la convergence des indices plutÃ´t que sur une seule p-value.")
      ),
      
      tags$p(tags$b("Logique de diffÃ©renciation :")),
      tags$ul(
        tags$li("Choisir ", tags$b("d"), " pour Ã©liminer la tendance / racine unitaire."),
        tags$li("Choisir ", tags$b("D"), " pour Ã©liminer la racine unitaire saisonniÃ¨re."),
        tags$li("Sâ€™arrÃªter dÃ¨s que la stationnaritÃ© est raisonnable ; Ã©viter la sur-diffÃ©renciation.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (StationnaritÃ© et diffÃ©renciation). "),
        "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide des tests ADF, KPSS et PP afin de trianguler lâ€™Ã©vidence, ces tests ayant des hypothÃ¨ses nulles diffÃ©rentes. ",
        "Sur la base des rÃ©sultats combinÃ©s et des diagnostics visuels, nous avons retenu [d=...] diffÃ©renciations ordinaires et [D=...] diffÃ©renciations saisonniÃ¨res avec une pÃ©riode saisonniÃ¨re (s=...). ",
        "Ce choix visait Ã  supprimer [tendance/racine unitaire saisonniÃ¨re] tout en Ã©vitant la sur-diffÃ©renciation ; la stationnaritÃ© a ensuite Ã©tÃ© rÃ©Ã©valuÃ©e sur la sÃ©rie transformÃ©e avant dâ€™ajuster les modÃ¨les SARIMA. Â»"
      ),
      
      tags$h5("PiÃ¨ges (classiques)"),
      tags$ul(
        tags$li(
          tags$b("Sur-diffÃ©renciation"),
          " provoque :",
          tags$ul(
            tags$li("forte autocorrÃ©lation nÃ©gative au retard 1,"),
            tags$li("variance gonflÃ©e,"),
            tags$li("prÃ©visions plus instables.")
          )
        ),
        tags$li("En pratique, D vaut souvent ", tags$b("0 ou 1"), ". Si (D=2) est nÃ©cessaire, la sÃ©rie est atypique ou la pÃ©riode saisonniÃ¨re est mal spÃ©cifiÃ©e.")
      ),
      
      tags$hr(),
      
      tags$h4("[5] - Ajuster un modÃ¨le de rÃ©fÃ©rence : Auto-ARIMA pour obtenir un bon point de dÃ©part SARIMA"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ul(
        tags$li("Utiliser une procÃ©dure ", tags$b("auto-ARIMA"), " (AICc ou similaire) pour proposer : ((p,d,q)(P,D,Q)_s)."),
        tags$li(
          "Documenter :",
          tags$ul(
            tags$li("les transformations utilisÃ©es,"),
            tags$li("les contraintes (max p/q, etc.),"),
            tags$li("si une recherche stepwise a Ã©tÃ© utilisÃ©e.")
          )
        ),
        tags$li(tags$b("Important :"), " Auto-ARIMA donne une base solide, pas une vÃ©ritÃ© gravÃ©e dans le marbre.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (ModÃ¨le de rÃ©fÃ©rence). "),
        "Â« Un modÃ¨le SARIMA de rÃ©fÃ©rence a Ã©tÃ© sÃ©lectionnÃ© via une procÃ©dure automatisÃ©e basÃ©e sur un critÃ¨re dâ€™information (minimisation de lâ€™AICc) parmi des ordres candidats ((p,q,P,Q)) ",
        "sous contraintes [bornes]. La spÃ©cification retenue Ã©tait SARIMA((p,d,q)(P,D,Q)_s), utilisÃ©e comme modÃ¨le de rÃ©fÃ©rence pour des ajustements ultÃ©rieurs guidÃ©s par la thÃ©orie. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Auto-ARIMA peut sÃ©lectionner des modÃ¨les statistiquement corrects mais ", tags$b("difficiles Ã  interprÃ©ter"), " ou lÃ©gÃ¨rement instables."),
        tags$li("Si lâ€™objectif est la prÃ©vision, il est acceptable de prÃ©fÃ©rer des modÃ¨les ", tags$b("plus simples"), " Ã  prÃ©cision comparable.")
      ),
      
      tags$hr(),
      
      tags$h4("[6] - Ajuster un modÃ¨le guidÃ© par la thÃ©orie : SARIMA manuel via ACF/PACF + tests"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("Ã€ partir de la sÃ©rie diffÃ©renciÃ©e (aprÃ¨s choix de (d, D)) :"),
      tags$ol(
        tags$li("Tracer ", tags$b("ACF/PACF"), "."),
        tags$li(
          "Proposer des structures candidates :",
          tags$ul(
            tags$li(
              "Non saisonnier :",
              tags$ul(
                tags$li("AR(p) : la PACF se coupe autour de p ; lâ€™ACF dÃ©croÃ®t."),
                tags$li("MA(q) : lâ€™ACF se coupe autour de q ; la PACF dÃ©croÃ®t.")
              )
            ),
            tags$li(
              "Saisonnier :",
              tags$ul(
                tags$li("AR saisonnier (P) : pics PACF aux retards (s, 2s, ...)."),
                tags$li("MA saisonnier (Q) : pics ACF aux retards (s, 2s, ...).")
              )
            )
          )
        ),
        tags$li("Ajuster un ", tags$b("petit ensemble"), " de candidats plausibles (ex. : 3â€“8 modÃ¨les)."),
        tags$li(
          "Comparer via :",
          tags$ul(
            tags$li("AICc/BIC,"),
            tags$li("significativitÃ© des paramÃ¨tres (avec prudence),"),
            tags$li("stabilitÃ© / inversibilitÃ©.")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (Construction guidÃ©e par la thÃ©orie). "),
        "Â« Les structures SARIMA candidates ont Ã©tÃ© proposÃ©es dâ€™aprÃ¨s le comportement ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. Des pics aux retards [lags] suggÃ©raient des composantes non saisonniÃ¨res [AR/MA], ",
        "tandis que des autocorrÃ©lations aux multiples de (s) indiquaient des termes saisonniers [AR/MA]. Plusieurs modÃ¨les ont Ã©tÃ© ajustÃ©s et comparÃ©s via [AICc/BIC], la sÃ©lection finale tenant compte de la parcimonie et de lâ€™adÃ©quation diagnostique. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Les heuristiques ACF/PACF sont des ", tags$b("guides"), ", pas des commandements."),
        tags$li("Ã‰viter de brute-forcer 200 modÃ¨les puis dâ€™appeler Ã§a Â« thÃ©orie Â». PrÃ©fÃ©rer un ", tags$b("petit ensemble raisonnÃ©"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[7] - Diagnostiquer & comparer : tests des rÃ©sidus + prÃ©cision de prÃ©vision ; choisir le modÃ¨le final"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p(tags$b("Diagnostics des rÃ©sidus (indispensable) :")),
      tags$ul(
        tags$li("Courbe des rÃ©sidus (doit ressembler Ã  du bruit)."),
        tags$li("ACF des rÃ©sidus (pas de gros pics)."),
        tags$li(tags$b("Test de Ljungâ€“Box"), " pour lâ€™autocorrÃ©lation des rÃ©sidus."),
        tags$li("VÃ©rification de normalitÃ© (QQ-plot ; Shapiro-Wilk est trop sensible pour grands n)."),
        tags$li("VÃ©rifier lâ€™hÃ©tÃ©roscÃ©dasticitÃ© (variance changeante).")
      ),
      
      tags$p(tags$b("Ã‰valuation de la prÃ©vision (indispensable) :")),
      tags$ul(
        tags$li("Ã‰chantillon test ou validation croisÃ©e rolling."),
        tags$li("MÃ©triques : MAE/RMSE ; MAPE seulement si la sÃ©rie nâ€™est jamais proche de zÃ©ro."),
        tags$li(
          "Comparer :",
          tags$ul(
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats SARIMA manuels,"),
            tags$li("Ã©ventuellement un benchmark simple (naÃ¯f saisonnier).")
          )
        )
      ),
      
      tags$p(tags$b("RÃ¨gle de choix (saine) :")),
      tags$ul(
        tags$li("Doit passer les diagnostics de faÃ§on raisonnable."),
        tags$li("Doit battre le benchmark naÃ¯f."),
        tags$li("PrÃ©fÃ©rer le modÃ¨le le plus simple si la prÃ©cision est quasi identique.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("RÃ©sultats (Diagnostics et performance). "),
        "Â« Les diagnostics des rÃ©sidus indiquaient un comportement proche du bruit blanc : les autocorrÃ©lations rÃ©siduelles Ã©taient faibles et le test de Ljungâ€“Box Ã©tait [non significatif/significatif] au seuil (Î±=...). ",
        "La performance de prÃ©vision sur la fenÃªtre dâ€™Ã©valuation donnait MAE=(...) et RMSE=(...), surpassant les modÃ¨les de rÃ©fÃ©rence et de benchmark. Sur la base de lâ€™adÃ©quation diagnostique et de la performance prÃ©dictive, le modÃ¨le final retenu Ã©tait SARIMA((p,d,q)(P,D,Q)_s). Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Un modÃ¨le avec un excellent AIC mais des rÃ©sidus autocorrÃ©lÃ©s te ", tags$i("raconte une belle histoire"), " â€” mais fausse."),
        tags$li("Des rÃ©sidus non normaux peuvent encore donner de bonnes prÃ©visions ; le problÃ¨me majeur est lâ€™", tags$b("autocorrÃ©lation"), " rÃ©siduelle.")
      ),
      
      tags$hr(),
      
      tags$h4("[8] - RÃ©diger le rapport : paragraphes APA Ã  chaque Ã©tape ; assembler MÃ©thodes/RÃ©sultats"),
      
      tags$h5("Ce que les Ã©tudiants font (checklist dâ€™assemblage)"),
      tags$p(tags$b("Section MÃ©thodes")),
      tags$ul(
        tags$li("DonnÃ©es (source, frÃ©quence, traitement du manque, transformation)."),
        tags$li("Approche exploratoire (graphiques, dÃ©composition)."),
        tags$li("Tests de stationnaritÃ© et choix de diffÃ©renciation."),
        tags$li("Baseline (paramÃ¨tres auto-ARIMA)."),
        tags$li("Justification de la sÃ©lection manuelle (ACF/PACF + candidats)."),
        tags$li("Diagnostics et protocole dâ€™Ã©valuation.")
      ),
      
      tags$p(tags$b("Section RÃ©sultats")),
      tags$ul(
        tags$li("RÃ©sumÃ© des donnÃ©es + observations visuelles clÃ©s."),
        tags$li("RÃ©sultats de dÃ©composition (tendance/saisonnalitÃ©)."),
        tags$li("RÃ©sultats des tests de stationnaritÃ© et choix (d, D)."),
        tags$li("ParamÃ¨tres du modÃ¨le final."),
        tags$li("Diagnostics et mÃ©triques de prÃ©cision."),
        tags$li("Graphique de prÃ©vision + tableau dâ€™erreurs.")
      ),
      
      tags$h5("Guidance (structure APA)"),
      tags$ul(
        tags$li("Pour chaque sous-section : ", tags$b("Ce quâ€™on a fait â†’ Pourquoi â†’ Ce quâ€™on a observÃ© â†’ Conclusion"), "."),
        tags$li("PassÃ© pour MÃ©thodes ; passÃ© orientÃ© rÃ©sultats pour RÃ©sultats."),
        tags$li("Ã‰crire les maths avec parcimonie ; donner la spÃ©cification complÃ¨te du modÃ¨le une seule fois, clairement.")
      ),
      
      tags$hr(),
      
      tags$h4("Un Â« pack livrable Â» propre que les Ã©tudiants doivent rendre"),
      tags$ul(
        tags$li(
          "Un notebook/script qui :",
          tags$ul(
            tags$li("charge les donnÃ©es,"),
            tags$li("traite les valeurs manquantes,"),
            tags$li("rÃ©alise lâ€™EDA (graphiques),"),
            tags$li("dÃ©composition,"),
            tags$li("tests de stationnaritÃ©,"),
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats manuels,"),
            tags$li("diagnostics,"),
            tags$li("Ã©valuation,"),
            tags$li("prÃ©vision finale.")
          )
        ),
        tags$li(
          "Un court rapport avec :",
          tags$ul(
            tags$li("MÃ©thodes + RÃ©sultats alignÃ©s aux Ã©tapes 1â€“7,"),
            tags$li("figures : courbe temporelle, dÃ©composition, ACF/PACF, ACF des rÃ©sidus, graphique de prÃ©vision,"),
            tags$li("tableau comparatif des modÃ¨les candidats (AICc + mÃ©triques).")
          )
        )
      ),
      
      tags$hr()
    )
  })
  
  
  
  
  
  
  
  
  
  #=============================================================================
  #=============================================================================
  #=============================================================================
  
  
  
  
  output$roadmap_Detailed_Fr_ui2 <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      # --- Minimal styling for callouts & details ---
      tags$style(HTML("
      .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:6px; margin:10px 0;}
      .callout.warn {border-left-color:#E45756; background:#fff7f7;}
      .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
      details {background:#ffffff;border:1px solid #e5e5e5;border-radius:8px;padding:8px 12px;margin:12px 0;}
      details > summary {cursor:pointer;font-weight:600;}
      code, kbd {background:#f3f3f3; padding:0 3px; border-radius:3px;}
      .tiny {font-size: 90%;}
    ")),
      
      tags$hr(),
      tags$p(
        "Ci-dessous, une ",
        tags$b("feuille de route pratique de modÃ©lisation SARIMA"),
        " â€” enrichie de dÃ©finitions simples, exemples et rÃ¨gles pratiques."
      ),
      tags$hr(),
      
      # ===================== [0] =====================
      tags$h4("[0] - PrÃ©parer le terrain : dÃ©finir le problÃ¨me de modÃ©lisation"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ul(
        tags$li("DÃ©finir la ", tags$b("sÃ©rie rÃ©ponse"), " ", tags$code("y_t"), " (ce que lâ€™on prÃ©voit)."),
        tags$li("DÃ©finir lâ€™", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vÃ©rifier sa rÃ©gularitÃ©."),
        tags$li(
          "DÃ©finir la ", tags$b("tÃ¢che de prÃ©vision"), " :",
          tags$ul(
            tags$li(tags$b("horizon h"), " (ex. : 12 mois Ã  lâ€™avance)"),
            tags$li("schÃ©ma dâ€™Ã©valuation (", tags$b("origine glissante"), " / rolling-origin ou split apprentissage/test)"),
            tags$li("mÃ©trique de perte (", tags$b("MAE / RMSE / MAPE / sMAPE"), ").")
          )
        ),
        tags$li(
          "DÃ©cider lâ€™Ã©chelle de modÃ©lisation :",
          tags$ul(
            tags$li(tags$b("niveaux"), " (donnÃ©es brutes)"),
            tags$li(tags$b("log-niveaux"), " (si la variance augmente avec le niveau)"),
            tags$li("espace transformÃ© ", tags$b("Boxâ€“Cox"), " (plus gÃ©nÃ©ral).")
          )
        )
      ),
      
      tags$details(
        tags$summary("DÃ©finitions clÃ©s (simples)"),
        tags$ul(
          tags$li(tags$b("SÃ©rie univariÃ©e :"), " une seule valeur par date (ex. ventes mensuelles)."),
          tags$li(tags$b("FrÃ©quence :"), " espacement des observations (jour, semaine, mois, trimestreâ€¦)."),
          tags$li(tags$b("Horizon h :"), " combien de pas dans le futur on prÃ©voit (ex. h=12 â‡’ 12 mois)."),
          tags$li(tags$b("Rolling-origin :"), " on dÃ©cale le point de dÃ©part, on re-fit Ã  chaque fois et on moyenne les erreurs."),
          tags$li(tags$b("SARIMA :"), " ARIMA avec composantes saisonniÃ¨res. Notation ", tags$code("SARIMA((p,d,q)(P,D,Q)_s)"), ".")
        ),
        tags$div(class="callout ok",
                 tags$b("En clair :"),
                 " posez clairement ", tags$em("quoi"), " prÃ©voir, ", tags$em("sur quelle Ã©chelle"), " et ", tags$em("comment juger la qualitÃ©"), ".")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent (papier)"),
      tags$p(
        tags$b("MÃ©thodes (DonnÃ©es & Objectif). "),
        "Â« Nous avons modÃ©lisÃ© la sÃ©rie temporelle univariÃ©e (", tags$code("y_t"), ") observÃ©e Ã  une frÃ©quence [mensuelle] de [dÃ©but] Ã  [fin] (n=...). ",
        "Lâ€™objectif Ã©tait de prÃ©voir Ã  un horizon (h=...) pas. La performance a Ã©tÃ© Ã©valuÃ©e via [mÃ©trique(s)] selon un protocole ",
        "[apprentissage/test ou origine glissante]. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("SARIMA suppose un ", tags$b("espacement rÃ©gulier"), " ; corriger toute irrÃ©gularitÃ© avant tout."),
        tags$li("SARIMA modÃ©lise ", tags$b("une seule sÃ©rie"), " (sans prÃ©dicteurs). Avec des variables explicatives â†’ SARIMAX.")
      ),
      
      tags$hr(),
      
      # ===================== [1] =====================
      tags$h4("[1] - DÃ©crire les donnÃ©es : taille dâ€™Ã©chantillon, manque, descriptives"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ol(
        tags$li(
          "Rapporter :",
          tags$ul(
            tags$li("taille dâ€™Ã©chantillon (n)"),
            tags$li("dates de dÃ©but/fin"),
            tags$li("frÃ©quence"),
            tags$li("nombre / pourcentage de valeurs manquantes")
          )
        ),
        tags$li(
          "GÃ©rer le manque :",
          tags$ul(
            tags$li("Peu et alÃ©atoire : imputer (interpolation linÃ©aire ou saisonniÃ¨re)."),
            tags$li("Beaucoup : envisager autre frÃ©quence, autre source ou expliquer les limites.")
          )
        ),
        tags$li(
          "Statistiques descriptives :",
          tags$ul(
            tags$li("moyenne, mÃ©diane, Ã©cart-type, min/max"),
            tags$li("asymÃ©trie (skewness) / kurtosis (si utile)"),
            tags$li("rÃ©sumÃ©s saisonniers (ex. moyenne par mois).")
          )
        )
      ),
      
      tags$details(
        tags$summary("DÃ©finitions manque & interprÃ©tations"),
        tags$ul(
          tags$li(tags$b("MCAR :"), " manquants complÃ¨tement alÃ©atoires â€” lâ€™imputation simple est OK."),
          tags$li(tags$b("MAR :"), " manquants dÃ©pendant dâ€™autres variables observÃ©es â€” justifier la mÃ©thode."),
          tags$li(tags$b("MNAR :"), " manquants dÃ©pendant de la valeur elle-mÃªme â€” signaler le biais potentiel.")
        ),
        tags$div(class="callout warn",
                 tags$b("RÃ¨gle pratique :"),
                 " documentez lâ€™imputation et testez la sensibilitÃ© (avec/sans imputation).")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent (style APA)"),
      tags$p(
        tags$b("RÃ©sultats (Description des donnÃ©es). "),
        "Â« La sÃ©rie contient (n=...) observations couvrant [dates] Ã  une frÃ©quence [frÃ©quence]. ",
        "Les valeurs manquantes reprÃ©sentaient (...%) (k=...). Elles ont Ã©tÃ© traitÃ©es par [mÃ©thode], choisie car [raison]. ",
        "La distribution de ", tags$code("y_t"), " prÃ©sentait une moyenne (...) (ET (...)), une mÃ©diane (...), et un intervalle ([...,...]). Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Ne pas imputer Â« silencieusement Â» â€” ", tags$b("toujours justifier"), "."),
        tags$li("Si log-transformÃ©e, rapporter aussi les statistiques sur lâ€™Ã©chelle transformÃ©e.")
      ),
      
      tags$hr(),
      
      # ===================== [2] =====================
      tags$h4("[2] - Explorer visuellement : tendance, saisonnalitÃ©, outliers"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("Produire et commenter :"),
      tags$ul(
        tags$li(tags$b("Courbe"), " de ", tags$code("y_t"), "."),
        tags$li(tags$b("Graphique saisonnier"), " (ex. lignes par mois)."),
        tags$li(tags$b("BoÃ®te Ã  moustaches par saison"), " (mois/trimestre/semaine)."),
        tags$li(
          tags$b("DÃ©tection dâ€™outliers :"),
          tags$ul(
            tags$li("rÃ¨gle IQR, z-scores, mÃ©thodes robustes"),
            tags$li("contexte (fÃªtes, ruptures de politique, erreurs de mesure)")
          )
        )
      ),
      
      tags$details(
        tags$summary("Outliers : types & conduite"),
        tags$ul(
          tags$li(tags$b("AO (Additive Outlier) :"), " un pic isolÃ©."),
          tags$li(tags$b("LS (Level Shift) :"), " changement de niveau persistant."),
          tags$li(tags$b("TC (Temporary Change) :"), " choc transitoire sâ€™Ã©teignant progressivement.")
        ),
        tags$div(class="callout ok",
                 tags$b("En clair :"),
                 " un outlier nâ€™est pas Â« faux Â» par dÃ©faut. Sâ€™il reflÃ¨te un Ã©vÃ¨nement rÃ©el Ã  reproduire, on ", tags$em("le garde"), ". Sinon, on lâ€™ajuste et on documente.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("RÃ©sultats (Analyse exploratoire). "),
        "Â« Lâ€™inspection visuelle a indiquÃ© une tendance [haussiÃ¨re/baissiÃ¨re] et des fluctuations saisonniÃ¨res de pÃ©riode (s=...). ",
        "La variabilitÃ© semblait [constante/augmenter avec le niveau], suggÃ©rant [aucune transformation / log]. ",
        "Des valeurs potentiellement aberrantes autour de [dates], liÃ©es Ã  [contexte], ont Ã©tÃ© ",
        "[conservÃ©es/ajustÃ©es] car [raison]. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Les outliers rÃ©els doivent souvent Ãªtre conservÃ©s (la prÃ©vision doit les anticiper)."),
        tags$li("Si la variance augmente avec le niveau : essayer ", tags$b("log"), " ou ", tags$b("Boxâ€“Cox"), ".")
      ),
      
      tags$hr(),
      
      # ===================== [3] =====================
      tags$h4("[3] - DÃ©composer : additif vs multiplicatif ; STL si robustesse"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("DÃ©composer pour sÃ©parer : tendance, saisonnalitÃ©, bruit."),
      
      tags$p(tags$b("Choisir la forme :")),
      tags$ul(
        tags$li(tags$b("Additive :"), " ", tags$code("y_t = T_t + S_t + e_t"), " si lâ€™amplitude saisonniÃ¨re est Ã  peu prÃ¨s constante."),
        tags$li(tags$b("Multiplicative :"), " ", tags$code("y_t = T_t Ã— S_t Ã— e_t"), " si lâ€™amplitude augmente avec le niveau (devenir additif aprÃ¨s log).")
      ),
      
      tags$p(tags$b("Utiliser STL lorsque :")),
      tags$ul(
        tags$li("la saisonnalitÃ© Ã©volue lentement"),
        tags$li("on souhaite une robustesse aux outliers")
      ),
      
      tags$details(
        tags$summary("En clair & exemples"),
        tags$div(class="callout ok",
                 tags$b("Exemple :"),
                 " ventes mensuelles qui doublent en dÃ©cembre chaque annÃ©e â†’ amplitude saisonniÃ¨re croÃ®t avec le niveau â†’ ", tags$em("log + additif en espace log"), ".")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (DÃ©composition). "),
        "Â« Nous avons comparÃ© structure additive vs multiplicative selon lâ€™amplitude saisonniÃ¨re. ",
        "Comme [constante / croissante], nous avons utilisÃ© [additif / log] et dÃ©composÃ© via [classique / STL]. STL retenue pour robustesse et flexibilitÃ©. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Multiplicatif â†” log : bons amis."),
        tags$li("STL est descriptive ; SARIMA exige encore la stationnaritÃ©.")
      ),
      
      tags$hr(),
      
      # ===================== [4] =====================
      tags$h4("[4] - StationnaritÃ© : ADF / KPSS / PP ; justifier d et D"),
      tags$p("SARIMA requiert la stationnaritÃ© ", tags$b("aprÃ¨s diffÃ©renciation"), "."),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ol(
        tags$li("Fixer la pÃ©riode saisonniÃ¨re ", tags$code("s"), " (12 mensuel, 4 trimestriel, 7 quotidien avec hebdo, etc.)."),
        tags$li("Tester sur : sÃ©rie brute â†’ aprÃ¨s ", tags$b("diffÃ©rence ordinaire"), " ", tags$code("(1-B)^d"), " â†’ aprÃ¨s ", tags$b("diffÃ©rence saisonniÃ¨re"), " ", tags$code("(1-B^s)^D"), " â†’ (Ã©ventuellement) les deux.")
      ),
      
      tags$details(
        tags$summary("Tests (version accessible)"),
        tags$ul(
          tags$li(tags$b("ADF (Augmented Dickeyâ€“Fuller)"),
                  ": H0 = racine unitaire (non-stationnaire). ",
                  "Rejeter H0 â‡’ stationnaritÃ© plausible."),
          tags$li(tags$b("KPSS (Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin)"),
                  ": H0 = stationnaritÃ©. ",
                  "Rejeter H0 â‡’ non-stationnaire."),
          tags$li(tags$b("PP (Phillipsâ€“Perron)"),
                  ": comme ADF (H0 racine unitaire) mais corrige lâ€™autocorrÃ©lation/hÃ©tÃ©roscÃ©dasticitÃ© diffÃ©remment.")
        ),
        tags$div(class="callout ok",
                 tags$b("Lecture combinÃ©e :"),
                 " ADF/PP rejettent & KPSS ne rejette pas â†’ stationnaire. ",
                 "ADF/PP ne rejettent pas & KPSS rejette â†’ diffÃ©rencier.")
      ),
      
      tags$h5("Logique de diffÃ©renciation"),
      tags$ul(
        tags$li("Choisir ", tags$b("d"), " pour supprimer tendance/racine unitaire."),
        tags$li("Choisir ", tags$b("D"), " pour supprimer racine unitaire saisonniÃ¨re."),
        tags$li("Sâ€™arrÃªter dÃ¨s que la stationnaritÃ© est raisonnable (Ã©viter la sur-diffÃ©renciation).")
      ),
      
      tags$details(
        tags$summary("Arbre dÃ©cisionnel rapide (d, D)"),
        tags$ul(
          tags$li(tags$b("Ã‰tape 1 :"), " si forte saisonnalitÃ© â†’ essayer ", tags$code("D=1"), " (", tags$code("âˆ‡_s"), "), retester."),
          tags$li(tags$b("Ã‰tape 2 :"), " si tendance rÃ©siduelle â†’ ", tags$code("d=1"), ", retester."),
          tags$li(tags$b("Ã‰tape 3 :"), " si ACF lag 1 trÃ¨s nÃ©gatif â†’ probable sur-diffÃ©renciation (rÃ©duire d/D).")
        ),
        tags$div(class="callout warn",
                 tags$b("Pratique :"),
                 " en applications courantes, ", tags$code("D âˆˆ {0,1}"), " suffit. Si ", tags$code("D=2"), " semble nÃ©cessaire, re-vÃ©rifier ", tags$code("s"), ".")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (StationnaritÃ© et diffÃ©renciation). "),
        "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e via ADF, KPSS et PP. ",
        "Selon lâ€™ensemble des preuves (tests + graphiques), nous avons retenu [d=...] et [D=...] avec ", tags$code("s=..."), 
        ". Nous avons Ã©vitÃ© la sur-diffÃ©renciation et re-testÃ© la stationnaritÃ© avant lâ€™ajustement SARIMA. Â»"
      ),
      
      tags$hr(),
      
      # ===================== [5] =====================
      tags$h4("[5] - ModÃ¨le de rÃ©fÃ©rence : Auto-ARIMA pour un bon dÃ©part"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ul(
        tags$li("Utiliser ", tags$b("auto-ARIMA"), " (AICc/BIC) pour proposer ", tags$code("((p,d,q)(P,D,Q)_s)"), "."),
        tags$li("Documenter : transformations (log/Boxâ€“Cox), bornes (max p/q/P/Q), option ", tags$em("stepwise"), ", etc."),
        tags$li(tags$b("Important :"), " auto-ARIMA donne une base, pas un verdict.")
      ),
      
      tags$details(
        tags$summary("Notes utiles"),
        tags$ul(
          tags$li("Si la variance est instable, estimer avec ", tags$code("lambda"), " (Boxâ€“Cox) et prÃ©voir sur lâ€™Ã©chelle dâ€™origine."),
          tags$li("Comparer avec des benchmarks (naÃ¯f, SNAIVE, drift).")
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (ModÃ¨le de rÃ©fÃ©rence). "),
        "Â« Un SARIMA de rÃ©fÃ©rence a Ã©tÃ© choisi par minimisation de lâ€™AICc parmi des ordres candidats, ",
        "avec contraintes [bornes]. La spÃ©cification retenue : ", tags$code("SARIMA((p,d,q)(P,D,Q)_s)"), ". Â»"
      ),
      
      tags$hr(),
      
      # ===================== [6] =====================
      tags$h4("[6] - ModÃ¨le guidÃ© par la thÃ©orie : ACF/PACF + tests"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("Ã€ partir de la sÃ©rie diffÃ©renciÃ©e (", tags$code("d, D"), ") :"),
      tags$ol(
        tags$li("Tracer ", tags$b("ACF/PACF"), "."),
        tags$li("Proposer 3â€“8 modÃ¨les plausibles (non saisonniers et saisonniers)."),
        tags$li("Comparer : AICc/BIC, significativitÃ© (avec prudence), stabilitÃ©/inversibilitÃ©.")
      ),
      
      tags$details(
        tags$summary("Cheat-sheet ACF/PACF"),
        tags$ul(
          tags$li(tags$b("AR(p) :"), " PACF se coupe â‰ˆ p ; ACF dÃ©croÃ®t."),
          tags$li(tags$b("MA(q) :"), " ACF se coupe â‰ˆ q ; PACF dÃ©croÃ®t."),
          tags$li(tags$b("Saisonnier AR(P) :"), " pics PACF aux ", tags$code("s, 2s, ..."), "."),
          tags$li(tags$b("Saisonnier MA(Q) :"), " pics ACF aux ", tags$code("s, 2s, ..."), ".")
        ),
        tags$div(class="callout ok",
                 tags$b("Astuce :"),
                 " privilÃ©gier les modÃ¨les ", tags$em("parcimonieux"), " qui passent les diagnostics.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (Construction guidÃ©e par la thÃ©orie). "),
        "Â« Les structures SARIMA candidates ont Ã©tÃ© proposÃ©es Ã  partir de lâ€™ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. ",
        "Plusieurs modÃ¨les ont Ã©tÃ© ajustÃ©s et comparÃ©s via [AICc/BIC], la sÃ©lection finale tenant compte de la parcimonie et de lâ€™adÃ©quation diagnostique. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("ACF/PACF sont des guides, pas des commandements."),
        tags$li("Ã‰viter de brute-forcer des centaines de modÃ¨les : rester dans un petit ensemble raisonnÃ©.")
      ),
      
      tags$hr(),
      
      # ===================== [7] =====================
      tags$h4("[7] - Diagnostiquer & comparer : rÃ©sidus + prÃ©cision ; choisir le final"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p(tags$b("Diagnostics des rÃ©sidus :")),
      tags$ul(
        tags$li("Courbe des rÃ©sidus (doit ressembler Ã  du bruit)."),
        tags$li("ACF des rÃ©sidus (pas de gros pics)."),
        tags$li(tags$b("Ljungâ€“Box"), " (H0 : pas dâ€™autocorrÃ©lation globale)."),
        tags$li("QQ-plot (normalitÃ© : utile mais non cruciale pour la prÃ©vision)."),
        tags$li("HÃ©tÃ©roscÃ©dasticitÃ© (variance changeante).")
      ),
      
      tags$details(
        tags$summary("ParamÃ©trer Ljungâ€“Box & lire les rÃ©sultats"),
        tags$ul(
          tags$li(tags$b("Choix du lag m :"), " souvent ", tags$code("m â‰ˆ 2s") , " (s saison) ou ", tags$code("m â‰ˆ 10*log10(n)"), " pour non saisonnier."),
          tags$li(tags$b("Lecture :"), " p-value grande â‡’ OK ; p-value petite â‡’ spÃ©cification incomplÃ¨te (ajouter AR/MA, revoir d/D).")
        )
      ),
      
      tags$p(tags$b("Ã‰valuation de la prÃ©vision :")),
      tags$ul(
        tags$li("Split test ou validation croisÃ©e rolling."),
        tags$li("MÃ©triques : ", tags$b("MAE / RMSE"), " (MAPE seulement si la sÃ©rie nâ€™est jamais proche de zÃ©ro)."),
        tags$li("Comparer : baseline auto-ARIMA, candidats manuels, benchmark naÃ¯f (souvent SNAIVE).")
      ),
      
      tags$p(tags$b("RÃ¨gle de choix :")),
      tags$ul(
        tags$li("Diagnostics raisonnablement passÃ©s."),
        tags$li("Batte le benchmark naÃ¯f."),
        tags$li("Ã€ prÃ©cision proche, prÃ©fÃ©rer le plus simple.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("RÃ©sultats (Diagnostics et performance). "),
        "Â« Les rÃ©sidus se comportent comme un bruit blanc (ACF sans pics) et le test de Ljungâ€“Box est [non significatif/significatif] Ã  (Î±=...). ",
        "Sur lâ€™Ã©chantillon dâ€™Ã©valuation : MAE=(...) et RMSE=(...), meilleurs que les benchmarks. ",
        "Le modÃ¨le final retenu : ", tags$code("SARIMA((p,d,q)(P,D,Q)_s)"), ". Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Un AIC excellent avec des rÃ©sidus autocorrÃ©lÃ©s ", tags$i("raconte une belle histoireâ€¦ fausse"), "."),
        tags$li("Des rÃ©sidus non normaux peuvent quand mÃªme bien prÃ©voir ; lâ€™autocorrÃ©lation rÃ©siduelle est le vrai problÃ¨me.")
      ),
      
      tags$hr(),
      
      # ===================== [8] =====================
      tags$h4("[8] - RÃ©diger : paragraphes APA & structure"),
      
      tags$h5("Checklist dâ€™assemblage"),
      tags$p(tags$b("Section MÃ©thodes")),
      tags$ul(
        tags$li("DonnÃ©es (source, frÃ©quence, manque, transformation)"),
        tags$li("EDA (graphiques), dÃ©composition"),
        tags$li("Tests de stationnaritÃ© et choix d/D"),
        tags$li("Baseline auto-ARIMA"),
        tags$li("SÃ©lection guidÃ©e par ACF/PACF"),
        tags$li("Diagnostics & protocole dâ€™Ã©valuation (rolling/split)")
      ),
      tags$p(tags$b("Section RÃ©sultats")),
      tags$ul(
        tags$li("RÃ©sumÃ© des donnÃ©es + points visuels clÃ©s"),
        tags$li("DÃ©composition (tendance/saisonnalitÃ©)"),
        tags$li("Tests de stationnaritÃ© + choix (d, D)"),
        tags$li("ParamÃ¨tres du modÃ¨le final"),
        tags$li("Diagnostics + mÃ©triques (MAE, RMSE, etc.)"),
        tags$li("Graphique de prÃ©vision + tableau dâ€™erreurs")
      ),
      tags$h5("Guidance (APA)"),
      tags$ul(
        tags$li("Pour chaque sous-section : ", tags$b("Ce quâ€™on a fait â†’ Pourquoi â†’ Ce quâ€™on a observÃ© â†’ Conclusion"), "."),
        tags$li("PassÃ© pour MÃ©thodes ; passÃ© orientÃ© rÃ©sultats pour RÃ©sultats."),
        tags$li("Donner la spÃ©cification complÃ¨te une seule fois, clairement.")
      ),
      
      tags$hr(),
      
      # ===================== Livrables =====================
      tags$h4("Livrables attendus (pack propre)"),
      tags$ul(
        tags$li(
          "Notebook/script :",
          tags$ul(
            tags$li("chargement & manque"),
            tags$li("EDA (graphiques)"),
            tags$li("dÃ©composition"),
            tags$li("tests de stationnaritÃ©"),
            tags$li("baseline auto-ARIMA"),
            tags$li("candidats manuels"),
            tags$li("diagnostics"),
            tags$li("Ã©valuation"),
            tags$li("prÃ©vision finale")
          )
        ),
        tags$li(
          "Court rapport :",
          tags$ul(
            tags$li("MÃ©thodes + RÃ©sultats (Ã©tapes 1â€“7)"),
            tags$li("Figures : courbe, dÃ©composition, ACF/PACF, ACF rÃ©sidus, prÃ©vision"),
            tags$li("Tableau comparatif (AICc + mÃ©triques)")
          )
        )
      ),
      
      tags$hr(),
      
      # ===================== Annexes pÃ©dagogiques =====================
      tags$h3("Annexes â€” mini-cours & dÃ©finitions"),
      
      tags$details(
        tags$summary("[A] Notation & rappel SARIMA (sans douleur)"),
        tags$div(
          class="callout",
          tags$p(tags$b("OpÃ©rateurs & diffÃ©rences")),
          tags$ul(
            tags$li(tags$code("B"), ": opÃ©rateur de retard (", tags$code("B y_t = y_{t-1}"), ")."),
            tags$li(tags$code("âˆ‡ = 1 - B"), " : diffÃ©rence ordinaire (", tags$code("âˆ‡ y_t = y_t - y_{t-1}"), ")."),
            tags$li(tags$code("âˆ‡_s = 1 - B^s"), " : diffÃ©rence saisonniÃ¨re (pÃ©riode ", tags$code("s"), ").")
          ),
          tags$p(tags$b("ModÃ¨le SARIMA((p,d,q)(P,D,Q)", tags$sub("s"), ")")),
          tags$ul(
            tags$li(tags$code("Ï†(B) = 1 - Ï†_1 B - ... - Ï†_p B^p"), " (AR non saisonnier)"),
            tags$li(tags$code("Î¸(B) = 1 + Î¸_1 B + ... + Î¸_q B^q"), " (MA non saisonnier)"),
            tags$li(tags$code("Î¦(B^s) = 1 - Î¦_1 B^s - ... - Î¦_P B^{Ps}"), " (AR saisonnier)"),
            tags$li(tags$code("Î˜(B^s) = 1 + Î˜_1 B^s - ... - Î˜_Q B^{Qs}"), " (MA saisonnier)")
          ),
          tags$p(class="tiny", "Ã‰criture compacte : ",
                 tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t,  Îµ_t ~ w.n.(0, Ïƒ^2)"))
        )
      ),
      
      tags$details(
        tags$summary("[B] Transformations (log, Boxâ€“Cox) & inverse"),
        tags$ul(
          tags$li(tags$b("Log :"), " utile si la variabilitÃ© croÃ®t avec le niveau ; gÃ©rer les zÃ©ros avec ", tags$code("log(y + c)"), "."),
          tags$li(tags$b("Boxâ€“Cox :"), " ", tags$code("y^(Î») = (y^Î» - 1)/Î»"), " si ", tags$code("Î» â‰  0"), " ; ", tags$code("log(y)"), " si ", tags$code("Î» = 0"), ".")
        ),
        tags$p(tags$b("Inverse Boxâ€“Cox :")),
        tags$ul(
          tags$li(tags$code("y = (Î» * y^(Î») + 1)^(1/Î»)"), " si ", tags$code("Î» â‰  0")),
          tags$li(tags$code("y = exp(y^(Î»))"), " si ", tags$code("Î» = 0"))
        ),
        tags$div(class="callout warn",
                 tags$b("Comparer les erreurs sur lâ€™Ã©chelle dâ€™origine"),
                 " (aprÃ¨s transformation inverse).")
      ),
      
      tags$details(
        tags$summary("[C] Benchmarks & mÃ©triques (quand et pourquoi)"),
        tags$ul(
          tags$li(tags$b("NaÃ¯f :"), " ", tags$code("Å·_{t+1|t} = y_t"), " â€” base absolue."),
          tags$li(tags$b("Drift :"), " ", tags$code("Å·_{t+h|t} = y_t + h*(y_t - y_1)/(t-1)"), " â€” tendance linÃ©aire."),
          tags$li(tags$b("SNAIVE :"), " ", tags$code("Å·_{t+h|t} = y_{t+h-s}"), " â€” saisonnalitÃ© rÃ©currente.")
        ),
        tags$ul(
          tags$li(tags$b("MAE :"), " robuste, lisible en unitÃ©s de la sÃ©rie."),
          tags$li(tags$b("RMSE :"), " punit fort les grosses erreurs (utile si coÃ»t convexe)."),
          tags$li(tags$b("MAPE :"), " Ã©viter si valeurs proches de 0."),
          tags$li(tags$b("sMAPE :"), " alternative symÃ©trique, prudence si faible signal.")
        ),
        tags$div(class="callout ok",
                 tags$b("Bon rÃ©flexe :"),
                 " toujours comparer au moins au SNAIVE + rapporter MAE & RMSE.")
      ),
      
      tags$details(
        tags$summary("[D] Validation par origine glissante (schÃ©ma)"),
        tags$ol(
          tags$li("Choisir origine ", tags$code("T0"), " et horizon ", tags$code("h")),
          tags$li("Ajuster sur [1..T0], prÃ©voir [T0+1..T0+h], mesurer lâ€™erreur"),
          tags$li("Avancer lâ€™origine et rÃ©pÃ©ter"),
          tags$li("AggrÃ©ger les erreurs (MAE/RMSE) sur les folds")
        ),
        tags$pre("
for (origin in origins) {
  fit <- Arima(y[1:origin], order=c(p,d,q), seasonal=c(P,D,Q), lambda=lambda)
  fc  <- forecast(fit, h=h)
  err <- accuracy(fc, y[(origin+1):(origin+h)])
  collect(err)
}
summary_errors <- aggregate_metrics(...)
")
      ),
      
      tags$details(
        tags$summary("[E] Erreurs frÃ©quentes & anti-patterns"),
        tags$ul(
          tags$li("Laisser auto-ARIMA choisir d/D sans rÃ©flexion prÃ©alable."),
          tags$li("Ignorer les benchmarks â†’ impossible de qualifier Â« bon Â»."),
          tags$li("Comparer des AIC sur Ã©chelles diffÃ©rentes (log vs niveau) sans prÃ©caution."),
          tags$li("Ã‰valuer uniquement in-sample (optimisme)."),
          tags$li("Tester trop de modÃ¨les (data snooping).")
        )
      ),
      
      tags$details(
        tags$summary("[F] Mini-FAQ"),
        tags$ul(
          tags$li(tags$b("Trous longs ?"), " Envisager frÃ©quence plus faible, autre source, ou modÃ©liser une rupture (intervention)."),
          tags$li(tags$b("Plusieurs saisonnalitÃ©s ?"), " SARIMA gÃ¨re une saisonnalitÃ© ; voir TBATS/ETS-complexe/Ã©tat espace."),
          tags$li(tags$b("Variables explicatives ?"), " Passer Ã  SARIMAX ou modÃ¨les dâ€™Ã©tat (rÃ©gressions avec erreurs ARIMA).")
        )
      ),
      
      tags$hr()
    )
  })
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
 
  output$roadmap_Detailed_Fr_ui3 <- renderUI({
    tags$div(
      style = "background:#f7f7f7;padding:14px;border-radius:8px;",
      
      tags$hr(),
      
      tags$p(
        "Ci-dessous, une ",
        tags$b("feuille de route pratique de modÃ©lisation SARIMA"),
        "."
      ),
      
      tags$hr(),
      
      # EncadrÃ©: dÃ©finitions/notations (collapsible)
      tags$details(
        tags$summary(tags$b("EncadrÃ© â€” DÃ©finitions, notations et rappels utiles")),
        tags$ul(
          tags$li(
            tags$b("Notation SARIMA : "), 
            tags$code("SARIMA((p,d,q)(P,D,Q))"),
            " avec saisonnalitÃ© de pÃ©riode ",
            tags$code("s"),
            "."
          ),
          tags$li(
            tags$b("Forme opÃ©rateur (backshift B) :")
          ),
          tags$ul(
            tags$li(
              tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
              " avec innovations ",
              tags$code("Îµ_t ~ w.n.(0, Ïƒ^2)")
            ),
            tags$li(
              tags$code("Ï†(B) = 1 - Ï†1 B - ... - Ï†p B^p"),
              "; ",
              tags$code("Î¸(B) = 1 + Î¸1 B + ... + Î¸q B^q")
            ),
            tags$li(
              tags$code("Î¦(B^s) = 1 - Î¦1 B^s - ... - Î¦P B^{Ps}"),
              "; ",
              tags$code("Î˜(B^s) = 1 + Î˜1 B^s + ... + Î˜Q B^{Qs}")
            ),
            tags$li(
              tags$code("âˆ‡^d = (1 - B)^d"),
              " ; ",
              tags$code("âˆ‡_s^D = (1 - B^s)^D")
            )
          ),
          tags$li(
            tags$b("StationnaritÃ©/inversibilitÃ© : "),
            "racinaires de ",
            tags$code("Ï†(B)"),
            " et ",
            tags$code("Î¦(B^s)"),
            " hors du cercle unitÃ© ; idem pour ",
            tags$code("Î¸(B)"),
            " et ",
            tags$code("Î˜(B^s)"),
            " (invertibilitÃ©)."
          ),
          tags$li(
            tags$b("ACF/PACF : "),
            "ACF tronquÃ©e â‰ˆ MA ; PACF tronquÃ©e â‰ˆ AR ; pics aux multiples de ",
            tags$code("s"),
            " â†’ composantes saisonniÃ¨res."
          ),
          tags$li(
            tags$b("CritÃ¨res dâ€™info : "),
            tags$code("AIC = -2â„“ + 2k"),
            ", ",
            tags$code("BIC = -2â„“ + k ln(n)"),
            ", ",
            tags$code("AICc = AIC + (2k(k+1))/(n-k-1)"),
            " (prÃ©fÃ©rer plus petit)."
          ),
          tags$li(
            tags$b("MÃ©triques dâ€™erreur : "),
            tags$code("MAE"),
            ", ",
            tags$code("RMSE"),
            ", ",
            tags$code("MAPE/sMAPE"),
            " (Ã©viter MAPE prÃ¨s de zÃ©ro)."
          ),
          tags$li(
            tags$b("Transformations : "),
            tags$code("log"),
            " (stabilise variance, multiplicatif â†’ additif), ",
            tags$code("Boxâ€“Cox"),
            " (paramÃ¨tre ",
            tags$code("Î»"),
            ", inclut log si ",
            tags$code("Î» = 0"),
            ")."
          ),
          tags$li(
            tags$b("Sur-/sous-diffÃ©renciation : "),
            "viser le minimum de ",
            tags$code("d"),
            " et ",
            tags$code("D"),
            " assurant une stationnaritÃ© raisonnable (Ã©viter ",
            tags$code("ACF"),
            " trÃ¨s nÃ©gative au lag 1)."
          )
        )
      ),
      
      tags$h4("[0] - PrÃ©parer le terrain : dÃ©finir le problÃ¨me de modÃ©lisation"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ul(
        tags$li("DÃ©finir la ", tags$b("sÃ©rie rÃ©ponse"), " (y_t) (ce que lâ€™on prÃ©voit)."),
        tags$li("DÃ©finir lâ€™", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vÃ©rifier quâ€™il est cohÃ©rent."),
        tags$li(
          "DÃ©finir la ", tags$b("tÃ¢che de prÃ©vision"), " :",
          tags$ul(
            tags$li("horizon (ex. : 12 mois Ã  lâ€™avance),"),
            tags$li("schÃ©ma dâ€™Ã©valuation (origine glissante / rolling-origin ou simple dÃ©coupage apprentissage/test),"),
            tags$li("mÃ©trique de perte (MAE/RMSE/MAPE/sMAPE).")
          )
        ),
        tags$li(
          "DÃ©cider si lâ€™on modÃ©lise en :",
          tags$ul(
            tags$li(tags$b("niveaux"), " (donnÃ©es brutes),"),
            tags$li(tags$b("log-niveaux"), " (frÃ©quent si la variance augmente avec le niveau),"),
            tags$li("espace transformÃ© ", tags$b("Boxâ€“Cox"), " (plus gÃ©nÃ©ral).")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent (papier)"),
      tags$p(
        tags$b("MÃ©thodes (DonnÃ©es & Objectif). "),
        "Â« Nous avons modÃ©lisÃ© la sÃ©rie temporelle univariÃ©e (y_t) observÃ©e Ã  une frÃ©quence [mensuelle] de [dÃ©but] Ã  [fin] (n=...). ",
        "Lâ€™objectif Ã©tait de prÃ©voir Ã  un horizon de (h=...) pas. La performance du modÃ¨le a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide de [mÃ©trique(s)] selon un protocole ",
        "[apprentissage/test ou origine glissante]. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("SARIMA suppose un ", tags$b("espacement rÃ©gulier"), " ; des timestamps irrÃ©guliers doivent Ãªtre corrigÃ©s avant toute chose."),
        tags$li("SARIMA modÃ©lise ", tags$b("une seule sÃ©rie"), " (sans prÃ©dicteurs). Avec des variables explicatives, on parle plutÃ´t de SARIMAX.")
      ),
      
      tags$hr(),
      
      tags$h4("[1] - DÃ©crire les donnÃ©es : taille dâ€™Ã©chantillon, valeurs manquantes, statistiques descriptives"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ol(
        tags$li(
          "Rapporter :",
          tags$ul(
            tags$li("taille dâ€™Ã©chantillon (n),"),
            tags$li("dates de dÃ©but/fin,"),
            tags$li("frÃ©quence,"),
            tags$li("nombre/pourcentage de valeurs manquantes.")
          )
        ),
        tags$li(
          "GÃ©rer le manque :",
          tags$ul(
            tags$li("Sâ€™il est rare et alÃ©atoire : imputer (interpolation linÃ©aire, interpolation saisonniÃ¨re)."),
            tags$li("Sâ€™il est important : reconsidÃ©rer la sÃ©rie, la frÃ©quence ou la source de donnÃ©es.")
          )
        ),
        tags$li(
          "Statistiques descriptives :",
          tags$ul(
            tags$li("moyenne, mÃ©diane, Ã©cart-type, min/max,"),
            tags$li("Ã©ventuellement asymÃ©trie (skewness) / kurtosis,"),
            tags$li("et rÃ©sumÃ©s saisonniers (ex. : moyenne par mois).")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent (style APA)"),
      tags$p(
        tags$b("RÃ©sultats (Description des donnÃ©es). "),
        "Â« La sÃ©rie contient (n=...) observations couvrant [dates] Ã  une frÃ©quence [frÃ©quence]. ",
        "Les valeurs manquantes reprÃ©sentaient (...%) des observations (k=... points). Les observations manquantes ont Ã©tÃ© traitÃ©es par ",
        "[mÃ©thode], choisie car [raison]. La distribution de (y_t) prÃ©sentait une moyenne de (...) (ET=(...)), une mÃ©diane (...), ",
        "et un intervalle ([...,...]). Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Ne pas imputer Â« silencieusement Â» â€” ", tags$b("toujours justifier"), "."),
        tags$li("Si une transformation logarithmique est appliquÃ©e, dÃ©crire aussi les statistiques de la sÃ©rie transformÃ©e.")
      ),
      
      tags$hr(),
      
      tags$h4("[2] - Explorer visuellement : tendance/saisonnalitÃ©/valeurs aberrantes ; rapporter les observations"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("Produire des graphiques et les commenter :"),
      tags$ul(
        tags$li(tags$b("Courbe"), " de (y_t)."),
        tags$li(tags$b("Graphique saisonnier"), " (ex. : lignes par mois de lâ€™annÃ©e)."),
        tags$li(tags$b("BoÃ®te Ã  moustaches par saison"), " (mois/trimestre/semaine)."),
        tags$li(
          tags$b("DÃ©tection dâ€™outliers"), " :",
          tags$ul(
            tags$li("z-scores, rÃ¨gle IQR, ou mÃ©thodes robustes,"),
            tags$li("mais aussi le contexte (fÃªtes, changements de politique, erreurs de mesure).")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("RÃ©sultats (Analyse exploratoire). "),
        "Â« Lâ€™inspection visuelle a indiquÃ© une tendance [haussiÃ¨re/baissiÃ¨re] et des fluctuations saisonniÃ¨res rÃ©currentes de pÃ©riode (s=...). ",
        "La variabilitÃ© semblait [constante/augmenter avec le niveau], suggÃ©rant [aucune transformation / une transformation logarithmique]. ",
        "Plusieurs valeurs potentiellement aberrantes ont Ã©tÃ© observÃ©es autour de [dates], probablement liÃ©es Ã  [contexte], et ont Ã©tÃ© ",
        "[conservÃ©es/ajustÃ©es] car [raison]. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Les outliers ne sont pas automatiquement Â« mauvais Â» : ils peuvent correspondre Ã  des Ã©vÃ©nements rÃ©els que la prÃ©vision doit respecter."),
        tags$li("Si la variance augmente avec le niveau, SARIMA se comporte souvent mieux aprÃ¨s une transformation ", tags$b("log"), " ou ", tags$b("Boxâ€“Cox"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[3] - DÃ©composer : justifier additif vs multiplicatif ; utiliser STL si robustesse nÃ©cessaire"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("RÃ©aliser une dÃ©composition pour sÃ©parer :"),
      tags$ul(
        tags$li("tendance,"),
        tags$li("saisonnalitÃ©,"),
        tags$li("reste (bruit).")
      ),
      
      tags$p(tags$b("Choisir la forme du modÃ¨le :")),
      tags$ul(
        tags$li(tags$b("Additive :"), " (y_t = T_t + S_t + e_t). Ã€ utiliser lorsque lâ€™amplitude saisonniÃ¨re est Ã  peu prÃ¨s constante."),
        tags$li(tags$b("Multiplicative :"), " (y_t = T_t Ã— S_t Ã— e_t). Ã€ utiliser lorsque lâ€™amplitude saisonniÃ¨re augmente avec le niveau (souvent rÃ©solu par log â†’ additif en espace log).")
      ),
      
      tags$p(tags$b("Utiliser la dÃ©composition STL lorsque :")),
      tags$ul(
        tags$li("la saisonnalitÃ© Ã©volue lentement au fil du temps,"),
        tags$li("on souhaite une robustesse aux outliers.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (DÃ©composition). "),
        "Â« Nous avons Ã©valuÃ© une structure additive versus multiplicative en examinant si lâ€™amplitude saisonniÃ¨re Ã©voluait avec le niveau de la sÃ©rie. ",
        "Comme [la variation saisonniÃ¨re Ã©tait approximativement constante / augmentait avec le niveau], nous avons utilisÃ© [un modÃ¨le additif / une transformation logarithmique] ",
        "et dÃ©composÃ© la sÃ©rie via [dÃ©composition classique / STL]. STL a Ã©tÃ© retenue pour sa robustesse aux valeurs aberrantes et sa flexibilitÃ© ",
        "dans la modÃ©lisation dâ€™une saisonnalitÃ© Ã©volutive. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Â« Saison multiplicative Â» et Â« transformation log Â» sont pratiquement meilleurs amis."),
        tags$li("La dÃ©composition STL est descriptive ; lâ€™estimation SARIMA nÃ©cessite toujours des vÃ©rifications de stationnaritÃ©.")
      ),
      
      tags$hr(),
      
      tags$h4("[4] - VÃ©rifier la stationnaritÃ© : ADF/KPSS/PP ; justifier la diffÃ©renciation (d et D)"),
      tags$p("SARIMA requiert la stationnaritÃ© ", tags$b("aprÃ¨s diffÃ©renciation"), "."),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ol(
        tags$li("DÃ©finir la pÃ©riode saisonniÃ¨re (s) (ex. : 12 pour des donnÃ©es mensuelles, 7 pour des donnÃ©es quotidiennes avec saisonnalitÃ© hebdomadaire)."),
        tags$li(
          "Tester la stationnaritÃ© sur :",
          tags$ul(
            tags$li("la sÃ©rie originale,"),
            tags$li("aprÃ¨s ", tags$b("diffÃ©renciation ordinaire"), " ((1-B)^d),"),
            tags$li("aprÃ¨s ", tags$b("diffÃ©renciation saisonniÃ¨re"), " ((1-B^s)^D),"),
            tags$li("et parfois aprÃ¨s les deux.")
          )
        )
      ),
      
      tags$h5("Tests de stationnaritÃ© : rÃ´le, H0/Ha, et conclusion"),
      tags$ul(
        tags$li(
          tags$b("Test ADF (Augmented Dickeyâ€“Fuller)"),
          tags$ul(
            tags$li(tags$b("RÃ´le :"), " tester si la sÃ©rie se comporte comme si elle avait une ", tags$b("racine unitaire"),
                    " (tendance stochastique), impliquant la non-stationnaritÃ© ; le test estime une rÃ©gression oÃ¹ des diffÃ©rences retardÃ©es sont ajoutÃ©es pour gÃ©rer lâ€™autocorrÃ©lation."),
            tags$li(tags$b("H0 :"), " la sÃ©rie a une racine unitaire (non-stationnaire ; les chocs ont des effets permanents)."),
            tags$li(tags$b("Ha :"), " la sÃ©rie nâ€™a pas de racine unitaire (stationnaire autour dâ€™une moyenne ou autour dâ€™une tendance dÃ©terministe, selon la spÃ©cification ADF)."),
            tags$li(tags$b("Phrase-type de conclusion :"), " Â« Le test ADF a donnÃ© p = [p-value] ; ainsi, au seuil Î± = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0 (racine unitaire). Cela implique que la sÃ©rie est ",
                    tags$b("[stationnaire / non-stationnaire]"), " selon lâ€™ADF ; nous ",
                    tags$b("[nâ€™avons pas appliquÃ© de diffÃ©renciation supplÃ©mentaire / avons appliquÃ©]"),
                    " une diffÃ©renciation ordinaire [d=â€¦] et/ou saisonniÃ¨re [D=â€¦] afin dâ€™obtenir une sÃ©rie approximativement stationnaire adaptÃ©e Ã  lâ€™estimation SARIMA. Â»")
          )
        ),
        tags$li(
          tags$b("Test KPSS (Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin)"),
          tags$ul(
            tags$li(tags$b("RÃ´le :"), " tester la stationnaritÃ© en examinant si la somme cumulÃ©e des rÃ©sidus (dâ€™une rÃ©gression de niveau ou de tendance) est trop importante ; complÃ©ment Ã  lâ€™ADF (H0 inversÃ©e)."),
            tags$li(tags$b("H0 :"), " la sÃ©rie est stationnaire (niveau, ou tendance si incluse)."),
            tags$li(tags$b("Ha :"), " la sÃ©rie est non-stationnaire."),
            tags$li(tags$b("Phrase-type :"), " Â« Le test KPSS a donnÃ© p = [p-value] ; au seuil Î± = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"), " H0. Cela indique que la sÃ©rie est ",
                    tags$b("[non stationnaire / compatible avec la stationnaritÃ©]"),
                    " ; cela ",
                    tags$b("[soutient / ne nÃ©cessite pas]"),
                    " une diffÃ©renciation additionnelle. Â»")
          )
        ),
        tags$li(
          tags$b("Test PP (Phillipsâ€“Perron)"),
          tags$ul(
            tags$li(tags$b("RÃ´le :"), " racine unitaire comme lâ€™ADF, correction non paramÃ©trique de lâ€™autocorrÃ©lation/hÃ©tÃ©roscÃ©dasticitÃ©."),
            tags$li(tags$b("H0 :"), " racine unitaire (non-stationnaire)."),
            tags$li(tags$b("Ha :"), " stationnaritÃ©."),
            tags$li(tags$b("Phrase-type :"), " Â« Le test PP a donnÃ© p = [p-value] ; au seuil Î± = [alpha], nous ",
                    tags$b("[rejetons / ne rejetons pas]"),
                    " H0. InterprÃ©tÃ© avec lâ€™ADF et le KPSS, cela suggÃ¨re que la sÃ©rie est ",
                    tags$b("[stationnaire / non-stationnaire]"),
                    " aprÃ¨s application de [d=â€¦] et [D=â€¦]. Â»")
          )
        )
      ),
      
      tags$p(tags$b("InterprÃ©ter ADF/KPSS/PP ensemble (logique Ã  Ã©crire).")),
      tags$ul(
        tags$li(tags$b("Accord idÃ©al :"), " ADF/PP rejettent (p petit) et KPSS ne rejette pas (p grand) â†’ forte Ã©vidence de stationnaritÃ©."),
        tags$li(tags$b("Non-stationnaritÃ© claire :"), " ADF/PP ne rejettent pas (p grand) et KPSS rejette (p petit) â†’ diffÃ©renciation nÃ©cessaire."),
        tags$li(tags$b("Conflits :"), " sâ€™appuyer sur graphiques + ACF + tests aprÃ¨s diffÃ©renciation ; Ã©viter de se baser sur une seule p-value.")
      ),
      
      tags$p(tags$b("Logique de diffÃ©renciation :")),
      tags$ul(
        tags$li("Choisir ", tags$b("d"), " pour Ã©liminer la tendance."),
        tags$li("Choisir ", tags$b("D"), " pour Ã©liminer la saisonnalitÃ© stochastique (racine unitaire saisonniÃ¨re)."),
        tags$li("Sâ€™arrÃªter dÃ¨s que la stationnaritÃ© est raisonnable ; Ã©viter la sur-diffÃ©renciation.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (StationnaritÃ© et diffÃ©renciation). "),
        "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e via ADF, KPSS et PP. Sur la base des rÃ©sultats combinÃ©s et des diagnostics visuels, ",
        "nous avons retenu [d=...] et [D=...] avec pÃ©riode saisonniÃ¨re (s=...). La stationnaritÃ© a Ã©tÃ© revÃ©rifiÃ©e sur la sÃ©rie transformÃ©e avant ajustement SARIMA. Â»"
      ),
      
      tags$h5("PiÃ¨ges (classiques)"),
      tags$ul(
        tags$li(
          tags$b("Sur-diffÃ©renciation"),
          " â†’ forte autocorrÃ©lation nÃ©gative au lag 1, variance gonflÃ©e, prÃ©visions instables."
        ),
        tags$li("En pratique, D vaut souvent ", tags$b("0 ou 1"), ". Si (D=2) est nÃ©cessaire, questionner la pÃ©riode saisonniÃ¨re ou la sÃ©rie.")
      ),
      
      tags$hr(),
      
      tags$h4("[5] - Ajuster un modÃ¨le de rÃ©fÃ©rence : Auto-ARIMA pour obtenir un bon point de dÃ©part SARIMA"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$ul(
        tags$li("Utiliser une procÃ©dure ", tags$b("auto-ARIMA"), " (AICc ou similaire) pour proposer : ((p,d,q)(P,D,Q)_s)."),
        tags$li(
          "Documenter :",
          tags$ul(
            tags$li("les transformations utilisÃ©es,"),
            tags$li("les contraintes (max p/q, etc.),"),
            tags$li("si une recherche stepwise a Ã©tÃ© utilisÃ©e.")
          )
        ),
        tags$li(tags$b("Important :"), " Auto-ARIMA donne une base solide, pas une vÃ©ritÃ© gravÃ©e dans le marbre.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (ModÃ¨le de rÃ©fÃ©rence). "),
        "Â« Un SARIMA de rÃ©fÃ©rence a Ã©tÃ© sÃ©lectionnÃ© via minimisation de lâ€™AICc parmi des ordres ((p,q,P,Q)) sous contraintes. ",
        "La spÃ©cification retenue Ã©tait SARIMA((p,d,q)(P,D,Q)_s), utilisÃ©e comme base pour des ajustements guidÃ©s par la thÃ©orie. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Auto-ARIMA peut sÃ©lectionner des modÃ¨les ", tags$b("difficiles Ã  interprÃ©ter"), " ou lÃ©gÃ¨rement instables."),
        tags$li("Pour la prÃ©vision, privilÃ©gier des modÃ¨les ", tags$b("plus simples"), " Ã  prÃ©cision comparable.")
      ),
      
      tags$hr(),
      
      tags$h4("[6] - Ajuster un modÃ¨le guidÃ© par la thÃ©orie : SARIMA manuel via ACF/PACF + tests"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p("Ã€ partir de la sÃ©rie diffÃ©renciÃ©e (aprÃ¨s choix de (d, D)) :"),
      tags$ol(
        tags$li("Tracer ", tags$b("ACF/PACF"), "."),
        tags$li(
          "Proposer des structures candidates :",
          tags$ul(
            tags$li(
              "Non saisonnier :",
              tags$ul(
                tags$li("AR(p) : la PACF se coupe autour de p ; lâ€™ACF dÃ©croÃ®t."),
                tags$li("MA(q) : lâ€™ACF se coupe autour de q ; la PACF dÃ©croÃ®t.")
              )
            ),
            tags$li(
              "Saisonnier :",
              tags$ul(
                tags$li("AR saisonnier (P) : pics PACF aux retards (s, 2s, ...)."),
                tags$li("MA saisonnier (Q) : pics ACF aux retards (s, 2s, ...).")
              )
            )
          )
        ),
        tags$li("Ajuster un ", tags$b("petit ensemble"), " de candidats plausibles (ex. : 3â€“8 modÃ¨les)."),
        tags$li(
          "Comparer via :",
          tags$ul(
            tags$li("AICc/BIC,"),
            tags$li("significativitÃ© des paramÃ¨tres (avec prudence),"),
            tags$li("stabilitÃ© / inversibilitÃ©.")
          )
        )
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("MÃ©thodes (Construction guidÃ©e par la thÃ©orie). "),
        "Â« Les structures SARIMA candidates ont Ã©tÃ© proposÃ©es dâ€™aprÃ¨s le comportement ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. Des pics aux retards [lags] suggÃ©raient des composantes non saisonniÃ¨res [AR/MA], ",
        "tandis que des autocorrÃ©lations aux multiples de (s) indiquaient des termes saisonniers [AR/MA]. Plusieurs modÃ¨les ont Ã©tÃ© ajustÃ©s et comparÃ©s via [AICc/BIC], la sÃ©lection finale tenant compte de la parcimonie et de lâ€™adÃ©quation diagnostique. Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Les heuristiques ACF/PACF sont des ", tags$b("guides"), ", pas des commandements."),
        tags$li("Ã‰viter de brute-forcer 200 modÃ¨les puis dâ€™appeler Ã§a Â« thÃ©orie Â». PrÃ©fÃ©rer un ", tags$b("petit ensemble raisonnÃ©"), ".")
      ),
      
      tags$hr(),
      
      tags$h4("[7] - Diagnostiquer & comparer : tests des rÃ©sidus + prÃ©cision de prÃ©vision ; choisir le modÃ¨le final"),
      
      tags$h5("Ce que les Ã©tudiants font"),
      tags$p(tags$b("Diagnostics des rÃ©sidus (indispensable) :")),
      tags$ul(
        tags$li("Courbe des rÃ©sidus (doit ressembler Ã  du bruit)."),
        tags$li("ACF des rÃ©sidus (pas de gros pics)."),
        tags$li(tags$b("Test de Ljungâ€“Box"), " pour lâ€™autocorrÃ©lation des rÃ©sidus."),
        tags$li("VÃ©rification de normalitÃ© (QQ-plot ; Shapiro-Wilk est trop sensible pour grands n)."),
        tags$li("VÃ©rifier lâ€™hÃ©tÃ©roscÃ©dasticitÃ© (variance changeante).")
      ),
      
      tags$p(tags$b("Ã‰valuation de la prÃ©vision (indispensable) :")),
      tags$ul(
        tags$li("Ã‰chantillon test ou validation croisÃ©e rolling."),
        tags$li("MÃ©triques : MAE/RMSE ; MAPE seulement si la sÃ©rie nâ€™est jamais proche de zÃ©ro."),
        tags$li(
          "Comparer :",
          tags$ul(
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats SARIMA manuels,"),
            tags$li("Ã©ventuellement un benchmark simple (naÃ¯f saisonnier).")
          )
        )
      ),
      
      tags$p(tags$b("RÃ¨gle de choix (saine) :")),
      tags$ul(
        tags$li("Doit passer les diagnostics de faÃ§on raisonnable."),
        tags$li("Doit battre le benchmark naÃ¯f."),
        tags$li("PrÃ©fÃ©rer le modÃ¨le le plus simple si la prÃ©cision est quasi identique.")
      ),
      
      tags$h5("Ce quâ€™ils Ã©crivent"),
      tags$p(
        tags$b("RÃ©sultats (Diagnostics et performance). "),
        "Â« Les diagnostics des rÃ©sidus indiquaient un comportement proche du bruit blanc : les autocorrÃ©lations rÃ©siduelles Ã©taient faibles et le test de Ljungâ€“Box Ã©tait [non significatif/significatif] au seuil (Î±=...). ",
        "La performance de prÃ©vision sur la fenÃªtre dâ€™Ã©valuation donnait MAE=(...) et RMSE=(...), surpassant les modÃ¨les de rÃ©fÃ©rence et de benchmark. Sur la base de lâ€™adÃ©quation diagnostique et de la performance prÃ©dictive, le modÃ¨le final retenu Ã©tait SARIMA((p,d,q)(P,D,Q)_s). Â»"
      ),
      
      tags$h5("PiÃ¨ges"),
      tags$ul(
        tags$li("Un modÃ¨le avec un excellent AIC mais des rÃ©sidus autocorrÃ©lÃ©s te ", tags$i("raconte une belle histoire"), " â€” mais fausse."),
        tags$li("Des rÃ©sidus non normaux peuvent encore donner de bonnes prÃ©visions ; le problÃ¨me majeur est lâ€™", tags$b("autocorrÃ©lation"), " rÃ©siduelle.")
      ),
      
      tags$hr(),
      
      tags$h4("[8] - RÃ©diger le rapport : paragraphes APA Ã  chaque Ã©tape ; assembler MÃ©thodes/RÃ©sultats"),
      
      tags$h5("Ce que les Ã©tudiants font (checklist dâ€™assemblage)"),
      tags$p(tags$b("Section MÃ©thodes")),
      tags$ul(
        tags$li("DonnÃ©es (source, frÃ©quence, traitement du manque, transformation)."),
        tags$li("Approche exploratoire (graphiques, dÃ©composition)."),
        tags$li("Tests de stationnaritÃ© et choix de diffÃ©renciation."),
        tags$li("Baseline (paramÃ¨tres auto-ARIMA)."),
        tags$li("Justification de la sÃ©lection manuelle (ACF/PACF + candidats)."),
        tags$li("Diagnostics et protocole dâ€™Ã©valuation.")
      ),
      
      tags$p(tags$b("Section RÃ©sultats")),
      tags$ul(
        tags$li("RÃ©sumÃ© des donnÃ©es + observations visuelles clÃ©s."),
        tags$li("RÃ©sultats de dÃ©composition (tendance/saisonnalitÃ©)."),
        tags$li("RÃ©sultats des tests de stationnaritÃ© et choix (d, D)."),
        tags$li("ParamÃ¨tres du modÃ¨le final."),
        tags$li("Diagnostics et mÃ©triques de prÃ©cision."),
        tags$li("Graphique de prÃ©vision + tableau dâ€™erreurs.")
      ),
      
      tags$h5("Guidance (structure APA)"),
      tags$ul(
        tags$li("Pour chaque sous-section : ", tags$b("Ce quâ€™on a fait â†’ Pourquoi â†’ Ce quâ€™on a observÃ© â†’ Conclusion"), "."),
        tags$li("PassÃ© pour MÃ©thodes ; passÃ© orientÃ© rÃ©sultats pour RÃ©sultats."),
        tags$li("Ã‰crire les maths avec parcimonie ; donner la spÃ©cification complÃ¨te du modÃ¨le une seule fois, clairement.")
      ),
      
      tags$hr(),
      
      tags$h4("Un Â« pack livrable Â» propre que les Ã©tudiants doivent rendre"),
      tags$ul(
        tags$li(
          "Un notebook/script qui :",
          tags$ul(
            tags$li("charge les donnÃ©es,"),
            tags$li("traite les valeurs manquantes,"),
            tags$li("rÃ©alise lâ€™EDA (graphiques),"),
            tags$li("dÃ©composition,"),
            tags$li("tests de stationnaritÃ©,"),
            tags$li("baseline auto-ARIMA,"),
            tags$li("candidats manuels,"),
            tags$li("diagnostics,"),
            tags$li("Ã©valuation,"),
            tags$li("prÃ©vision finale.")
          )
        ),
        tags$li(
          "Un court rapport avec :",
          tags$ul(
            tags$li("MÃ©thodes + RÃ©sultats alignÃ©s aux Ã©tapes 1â€“7,"),
            tags$li("figures : courbe temporelle, dÃ©composition, ACF/PACF, ACF des rÃ©sidus, graphique de prÃ©vision,"),
            tags$li("tableau comparatif des modÃ¨les candidats (AICc + mÃ©triques).")
          )
        )
      ),
      
      tags$hr()
    )
  })
  
  
  
   
  
  
  
  
  
  # --- Roadmap slider navigation (Prev/Next) ---
  observeEvent(input$road_prev, {
    cur <- input$roadmap_step
    if (is.null(cur)) cur <- 0
    updateSliderInput(session, "roadmap_step", value = max(0, as.integer(cur) - 1L))
  }, ignoreInit = TRUE)
  
  observeEvent(input$road_next, {
    cur <- input$roadmap_step
    if (is.null(cur)) cur <- 0
    updateSliderInput(session, "roadmap_step", value = min(10, as.integer(cur) + 1L))
  }, ignoreInit = TRUE)
  
  # =========================
  # Roadmap UI (controls)
  # =========================
  output$roadmap_Detailed_Fr_ui4 <- renderUI({
    
    tags$div(
      class = "road-shell",
      style = "background:#f7f7f7;padding:14px;border-radius:10px;",
      
      tags$style(HTML("
.road-shell {background:#f7f7f7;padding:14px;border-radius:12px;border:1px solid #ececec;}
      .road-title {margin:0 0 6px 0;font-size:22px;font-weight:800;letter-spacing:.2px;}
      .road-sub {margin:0 0 12px 0;color:#555;line-height:1.45;}
      .road-nav {display:flex;gap:10px;align-items:center;flex-wrap:wrap;position:sticky;top:0;z-index:50;background:#f7f7f7;padding:10px 0 8px 0;border-bottom:1px solid #ececec;}
      .road-nav .btn {min-width:46px;border-radius:10px;padding:6px 12px;}
      .road-nav .btn:focus {outline:none;box-shadow:0 0 0 3px rgba(76,120,168,.25);}
      .road-nav .form-group {margin-bottom:0;}
      /* Slider polish (Shiny uses ionRangeSlider) */
      .road-shell .irs--shiny .irs-bar {background:#4C78A8;}
      .road-shell .irs--shiny .irs-handle>i:first-child {background:#4C78A8;}
      .road-shell .irs--shiny .irs-from,
      .road-shell .irs--shiny .irs-to,
      .road-shell .irs--shiny .irs-single {background:#4C78A8;}
      @media (max-width: 900px) {
        .road-nav {gap:8px;}
        .road-nav .irs {width:100% !important;}
        .road-nav .form-group {width:100%;}
      }
      .road-card {background:#fff;border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin-top:14px;box-shadow:0 2px 10px rgba(0,0,0,.03);}
      .step-header {display:flex;align-items:center;justify-content:space-between;gap:10px;margin-bottom:8px;}
      .step-badge {display:inline-block;font-weight:800;font-size:12px;letter-spacing:.3px;text-transform:uppercase;padding:4px 10px;border-radius:999px;background:#eef4fb;color:#254b74;border:1px solid #d9e7f6;}
      .step-hint {color:#666;font-size:12px;}
      details {background:#ffffff;border:1px solid #eaeaea;border-radius:12px;padding:0;margin:10px 0;overflow:hidden;}
      details > summary {cursor:pointer;font-weight:700;padding:10px 12px;list-style:none;display:flex;align-items:center;justify-content:space-between;gap:12px;background:linear-gradient(180deg,#ffffff 0%,#fbfbfb 100%);}
      details > summary::-webkit-details-marker {display:none;}
      details > summary:after {content:'â–¸';font-size:16px;color:#666;transform:rotate(0deg);transition:transform .12s ease;}
      details[open] > summary:after {transform:rotate(90deg);}
      details:hover {border-color:#dcdcdc;}
      details[open] {border-color:#d9e7f6;box-shadow:0 2px 10px rgba(76,120,168,.08);}
      .callout {border-left:5px solid #4C78A8;background:#fafafa;padding:12px 12px;border-radius:10px;margin:10px 0;}
      .callout.warn {border-left-color:#E45756;background:#fff7f7;}
      .callout.ok {border-left-color:#72B7B2;background:#f7fffb;}
      .callout.deliver {border-left-color:#54A24B; background:#f6fff6;}
      .callout.checklist {border-left-color:#F2CF5B;background:#fffdf4;}
      .checklist-title {display:flex;align-items:center;gap:8px;margin-bottom:6px;}
      .checklist-icon {font-weight:800;}
      code {background:#f3f3f3;padding:0 4px;border-radius:4px;}
      .progress {height:10px;border-radius:999px;background:#ececec;overflow:hidden;margin:10px 0 0 0;}
      .progress-bar {border-radius:999px;}")),
      
      tags$h3(class="road-title", "Feuille de route SARIMA (version pÃ©dagogique)"),
      tags$p(class="road-sub",
             "Utilisez le curseur pour passer dâ€™une Ã©tape Ã  lâ€™autre. Chaque Ã©tape contient : Actions â†’ Ã€ Ã©crire (APA) â†’ PiÃ¨ges."),
      
      tags$div(
        class = "road-nav",
        actionButton("road_prev", "â—€", class = "btn btn-default"),
        sliderInput(
          "roadmap_step", label = NULL,
          min = 0, max = 10, value = 0, step = 1, width = "520px"
        ),
        actionButton("road_next", "â–¶", class = "btn btn-default"),
        tags$span(style="color:#666;", "Astuce : gardez les blocs repliÃ©s pour Ã©viter toute scroll.")
      ),
      
      # Progress bar (pure UI, updated via re-render of content)
      shiny::uiOutput("roadmap_step_content")
    )
  })
  
  # =========================
  # Roadmap UI (content)
  # =========================
  output$roadmap_step_content <- renderUI({
    
    # ========= Helpers =========
    D <- function(title, ...) {
      tags$details(
        tags$summary(title),
        tags$div(class = "road-scroll", ...)
      )
    }
    UL <- function(...) tags$ul(...)
    OL <- function(...) tags$ol(...)
    P  <- function(...) tags$p(...)
    B  <- function(...) tags$b(...)
    C  <- function(...) tags$code(...)
    H5 <- function(...) tags$h5(style="margin-top:10px;margin-bottom:6px;", ...)
    
    # ========= Checklist helpers (UI only) =========
    # These are intentionally simple visual checklists (no reactive logic).
    # Pedagogical goal: help students translate â€œread/explainâ€ into
    # concrete actions they can verify before moving to the next step.
    CheckItem <- function(...) {
      tags$li(
        tags$span(class = "chkbox", "â˜"),
        tags$span(...)
      )
    }
    Checklist <- function(...) {
      tags$div(
        class = "callout checklist",
        tags$div(
          class = "checklist-title",
          tags$span(class = "checklist-icon", "â˜‘"),
          tags$b("Checklist Ã©tudiant")
        ),
        tags$ul(class = "chk", ...)
      )
    }
    
    
    Deliverables <- function(...) {
      tags$div(
        class = "callout deliver",
        tags$b("Sorties attendues (Ã  conserver pour le rapport)"),
        tags$ul(...)
      )
    }
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    # ========= CSS (internal scroll so the page stays short) =========
    css <- tags$style(HTML("
.road-card {background:#fff;border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin-top:14px;box-shadow:0 2px 10px rgba(0,0,0,.03);}
    .step-header {display:flex;align-items:center;justify-content:space-between;gap:10px;margin-bottom:8px;}
    .step-badge {display:inline-block;font-weight:800;font-size:12px;letter-spacing:.3px;text-transform:uppercase;padding:4px 10px;border-radius:999px;background:#eef4fb;color:#254b74;border:1px solid #d9e7f6;}
    .step-hint {color:#666;font-size:12px;}
    details {background:#ffffff;border:1px solid #eaeaea;border-radius:12px;padding:0;margin:10px 0;overflow:hidden;}
    details > summary {cursor:pointer;font-weight:700;padding:10px 12px;list-style:none;display:flex;align-items:center;justify-content:space-between;gap:12px;background:linear-gradient(180deg,#ffffff 0%,#fbfbfb 100%);}
    details > summary::-webkit-details-marker {display:none;}
    details > summary:after {content:'â–¸';font-size:16px;color:#666;transform:rotate(0deg);transition:transform .12s ease;}
    details[open] > summary:after {transform:rotate(90deg);}
    details:hover {border-color:#dcdcdc;}
    details[open] {border-color:#d9e7f6;box-shadow:0 2px 10px rgba(76,120,168,.08);}
    .road-scroll {max-height: 62vh; overflow-y: auto; padding:10px 12px 12px 12px; padding-right: 14px;}
    .road-scroll::-webkit-scrollbar {width: 10px;}
    .road-scroll::-webkit-scrollbar-thumb {background: #e0e0e0; border-radius: 999px; border: 3px solid #fff;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:12px 12px; border-radius:10px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
      .callout.deliver {border-left-color:#54A24B; background:#f6fff6;}
    .callout.checklist {border-left-color:#F2CF5B; background:#fffdf4;}
    .checklist-title {display:flex; align-items:center; gap:8px; margin-bottom:6px;}
    .checklist-icon {font-weight:800;}
    code {background:#f3f3f3; padding:0 4px; border-radius:4px;}
    .progress {height:10px; border-radius:999px; background:#ececec; overflow:hidden; margin:10px 0 0 0;}
    .progress-bar {border-radius:999px;}
    /* Checklist: checkbox-style bullets */
    ul.chk {padding-left: 0; margin: 8px 0 0 0;}
    ul.chk li {list-style: none; margin: 7px 0; display:flex; align-items:flex-start; gap:8px;}
    .chkbox {display:inline-block; width: 18px; font-weight: 800; margin-top: 1px;}"))
    
    # ========= Step logic =========
    cur <- input$roadmap_step
    if (is.null(cur) || !is.finite(cur)) cur <- 0
    cur <- as.integer(cur)
    
    step_names <- c(
      "AperÃ§u & notations (glossaire + lecture du modÃ¨le)",
      "Ã‰tape 0 â€” DÃ©finir le problÃ¨me de modÃ©lisation",
      "Ã‰tape 1 â€” DÃ©crire les donnÃ©es (qualitÃ©, manquants, descriptifs)",
      "Ã‰tape 2 â€” Explorer visuellement (EDA) : tendance/saison/outliers",
      "Ã‰tape 3 â€” DÃ©composer : additif vs multiplicatif, STL, robustesse",
      "Ã‰tape 4 â€” StationnaritÃ© & diffÃ©renciation : ADF / KPSS / PP (d, D)",
      "Ã‰tape 5 â€” Baseline : Auto-ARIMA (point de dÃ©part, pas un dogme)",
      "Ã‰tape 6 â€” SARIMA manuel : ACF/PACF + candidats raisonnÃ©s",
      "Ã‰tape 7 â€” Diagnostics & comparaison : rÃ©sidus + performance prÃ©vision",
      "Ã‰tape 8 â€” RÃ©daction : MÃ©thodes/RÃ©sultats (APA) + livrables propres",
      "Annexes â€” Formules, checklists, templates, interprÃ©tations rapides"
    )
    
    pct <- round(100 * cur / 10)
    progress_ui <- tags$div(
      class="progress",
      tags$div(
        class="progress-bar",
        role="progressbar",
        `aria-valuenow`=pct, `aria-valuemin`="0", `aria-valuemax`="100",
        style = paste0("width:", pct, "%;")
      )
    )
    
    make_step <- function(title, actions_ui, apa_ui, pitfalls_ui, header_ui = NULL) {
      step_badge <- if (isTRUE(cur == 0L)) "AperÃ§u" else paste0("Ã‰tape ", cur, "/10")
      tags$div(
        class = "road-card",
        if (!is.null(header_ui)) header_ui,
        tags$div(
          class = "step-header",
          tags$span(class = "step-badge", step_badge),
          tags$span(class = "step-hint", "DÃ©pliez un bloc Ã  la fois : Actions â†’ APA â†’ PiÃ¨ges.")
        ),
        tags$h4(title),
        D("1) Ce que lâ€™Ã©tudiant fait (procÃ©dure + dÃ©finitions + objectifs)", actions_ui),
        D("2) Ce quâ€™il Ã©crit (APA) + conclusion & signification", apa_ui),
        D("3) PiÃ¨ges + comment les Ã©viter (avec interprÃ©tation)", pitfalls_ui)
      )
    }
    
    # ========= Pages =========
    pages <- vector("list", length = 11)
    
    # (0) AperÃ§u
    pages[[1]] <- make_step(
      step_names[1],
      
      actions_ui = tagList(
        callout(
          B("Objectif global : "),
          "construire un modÃ¨le SARIMA interprÃ©table et surtout ",
          B("prÃ©dictif"), " : il doit passer les diagnostics rÃ©siduels et battre un benchmark simple.",
          type="ok"
        ),
        
        Checklist(
          CheckItem("Identifier clairement la sÃ©rie y_t (ce que vous cherchez Ã  prÃ©voir), prÃ©ciser son unitÃ©, sa source et le contexte dâ€™application (ex. ventes mensuelles, dÃ©bit quotidien, tempÃ©rature horaire)."),
          CheckItem("Fixer la pÃ©riode saisonniÃ¨re s Ã  partir du contexte et vÃ©rifier quâ€™elle est cohÃ©rente avec lâ€™Ã©chantillonnage (ex. s=12 pour mensuel, s=7 pour hebdomadaire, s=4 pour trimestriel)."),
          CheckItem("Lire la forme gÃ©nÃ©rale du SARIMA et expliquer le rÃ´le de chaque bloc : diffÃ©renciation (d, D) pour stationnariser, puis composantes AR/MA (p, q, P, Q) pour modÃ©liser la dÃ©pendance restante."),
          CheckItem("Ã‰noncer des critÃ¨res de validation explicites : rÃ©sidus â‰ˆ bruit blanc (ACF rÃ©sidus + Ljungâ€“Box), performance horsâ€‘Ã©chantillon (train/test ou rolling-origin) et parcimonie (le plus simple qui marche)."),
          CheckItem("Choisir un benchmark (naÃ¯f / drift / SNAIVE), lâ€™Ã©crire noir sur blanc et expliquer pourquoi il est pertinent : sans repÃ¨re, on ne peut pas juger la valeur ajoutÃ©e dâ€™un SARIMA.")
        ),
        
        Deliverables(
          tags$li("Une fiche â€œNotations & objectifsâ€ : y_t, unitÃ© de temps, pÃ©riode saisonniÃ¨re s, et le rÃ´le de (p,d,q)(P,D,Q)[s]."),
          tags$li("Un protocole de validation Ã©crit (train/test ou rolling-origin) + la mÃ©trique principale choisie (MAE/RMSE, etc.)."),
          tags$li("Un benchmark explicite (naÃ¯f / drift / SNAIVE) qui servira de rÃ©fÃ©rence tout au long du projet.")
        ),
        
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Notations essentielles (dÃ©finitions)")),
          
          tags$ul(
            tags$li(tags$b("SÃ©rie temporelle"),
                    " : suite ordonnÃ©e dâ€™observations indexÃ©es par le temps ",
                    tags$code("y_t"), "."),
            
            tags$li(tags$b("FrÃ©quence / pÃ©riode saisonniÃ¨re"),
                    " : nombre de pas par cycle saisonnier, notÃ© ",
                    tags$code("s"),
                    " (ex. mensuel s = 12 ; quotidien avec saison hebdo s = 7)."),
            
            tags$li(tags$b("OpÃ©rateur de retard (backshift)"),
                    " : ", tags$code("B y_t = y_{t-1}"), "."),
            
            tags$li(tags$b("DiffÃ©renciation ordinaire"),
                    " : ", tags$code("âˆ‡ y_t = (1-B)y_t = y_t - y_{t-1}"),
                    " ; appliquÃ©e ", tags$code("d"),
                    " fois â†’ supprimer tendance / racine unitaire non saisonniÃ¨re."),
            
            tags$li(tags$b("DiffÃ©renciation saisonniÃ¨re"),
                    " : ", tags$code("âˆ‡_s y_t = (1-B^s)y_t = y_t - y_{t-s}"),
                    " ; appliquÃ©e ", tags$code("D"),
                    " fois â†’ supprimer racine unitaire saisonniÃ¨re."),
            
            tags$li(tags$b("Innovations / bruit blanc"),
                    " : ", tags$code("Îµ_t ~ w.n.(0, ÏƒÂ²)"),
                    " signifie des chocs non autocorrÃ©lÃ©s (moyenne 0, variance constante).")
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Forme gÃ©nÃ©rale du modÃ¨le SARIMA (Ã  comprendre, pas Ã  mÃ©moriser)")),
          
          tags$ul(
            tags$li(
              "Ã‰criture compacte : ",
              tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t")
            ),
            tags$li(
              tags$b("InterprÃ©tation : "),
              "aprÃ¨s diffÃ©renciations (d, D), on explique la dynamique restante par des composantes AR/MA ",
              "non saisonniÃ¨res (p,q) et saisonniÃ¨res (P,Q)."
            )
          )
        ),
        
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Ce que signifie â€œbon modÃ¨leâ€ (dÃ©finition opÃ©rationnelle)")),
          
          tags$ol(
            tags$li(
              tags$b("RÃ©sidus ~ bruit blanc"),
              " : pas dâ€™autocorrÃ©lation rÃ©siduelle (Ljungâ€“Box non significatif)."
            ),
            tags$li(
              tags$b("Performance out-of-sample"),
              " : MAE/RMSE meilleurs que benchmark (naÃ¯f / SNAIVE)."
            ),
            tags$li(
              tags$b("Parcimonie"),
              " : modÃ¨le le plus simple possible Ã  performance comparable."
            )
          )
        ),
        
  
        
        # === ADD: Glossaire Ã©tendu, critÃ¨res info, estimation ===
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Glossaire Ã©tendu (ajouts importants)")),
          
          tags$ul(
            tags$li(
              tags$b("PolynÃ´mes AR/MA"), " : ",
              tags$code("Ï†(B) = 1 - Ï†_1 B - ... - Ï†_p B^p"), ", ",
              tags$code("Î¸(B) = 1 + Î¸_1 B + ... + Î¸_q B^q"), "; saisonnier ",
              tags$code("Î¦(B^s) = 1 - Î¦_1 B^s - ... - Î¦_P B^{Ps}"), ", ",
              tags$code("Î˜(B^s) = 1 + Î˜_1 B^s + ... + Î˜_Q B^{Qs}"), "."
            ),
            
            tags$li(
              tags$b("StabilitÃ© / causalitÃ© (AR)"), " : toutes les racines de ",
              tags$code("Ï†(z)=0"), " et ", tags$code("Î¦(z^s)=0"),
              " sont ", tags$b("hors"), " du cercle unitÃ© â†’ processus stationnaire."
            ),
            
            tags$li(
              tags$b("InversibilitÃ© (MA)"), " : racines de ",
              tags$code("Î¸(z)=0"), " et ", tags$code("Î˜(z^s)=0"),
              " hors du cercle unitÃ© â†’ reprÃ©sentation AR(âˆž) bien dÃ©finie."
            ),
            
            tags$li(
              tags$b("Constante / drift"), " : une constante dans un ARIMA avec ",
              tags$code("d=1"),
              " implique une ", tags$b("pente moyenne"),
              " (drift) aprÃ¨s diffÃ©renciation ; le terme est souvent notÃ© ",
              tags$code("c"),
              " et la tendance moyenne vaut environ ",
              tags$code("c"),
              " par pas."
            ),
            
            tags$li(
              tags$b("ReprÃ©sentation Ã©tatâ€“espace"), " : tout ARIMA/SARIMA peut Ãªtre Ã©crit sous forme Ã©tatâ€“espace ",
              "et estimÃ©/filtrÃ© par Kalman (utile pour manquants et lissage)."
            ),
            
            tags$li(
              tags$b("PrÃ©vision : point vs intervalle vs densitÃ©"),
              " : point = ", tags$code("Å·"),
              " ; intervalle = incertitude (80% / 95%) ; densitÃ© = distribution prÃ©dictive complÃ¨te."
            )
          )
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("CritÃ¨res dâ€™information (dÃ©finitions)")),
          
          tags$ul(
            tags$li(
              tags$b("AIC"), " : ",
              tags$code("AIC = -2 \\log L + 2k"),
              " (", tags$code("k"), " = nb paramÃ¨tres estimÃ©s)."
            ),
            tags$li(
              tags$b("AICc"),
              " : correction petits Ã©chantillons â†’ prÃ©fÃ©rable si ",
              tags$code("n/k"), " nâ€™est pas grand."
            ),
            tags$li(
              tags$b("BIC"), " : ",
              tags$code("BIC = -2 \\log L + k \\log n"),
              " ; pÃ©nalise plus la complexitÃ© (favorise parcimonie)."
            )
          )
        ),
        
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Estimation (comment sont estimÃ©s les paramÃ¨tres)")),
          
          tags$ul(
            tags$li(
              tags$b("MLE vs CSS+MLE"),
              " : estimation par maximum de vraisemblance (souvent via optim) ; ",
              "CSS (Conditional Sum of Squares) pour initialiser, puis MLE pour affiner."
            ),
            tags$li(
              tags$b("Ã‰carts-types et tests z"),
              " : reportez estimations Â± SE, z et p pour lâ€™interprÃ©tation des coefficients."
            )
          )
        ),
        

      ),
      
      apa_ui = tagList(
        H5("Phrase APA (modÃ¨le + notations)"),
        P("Â« Nous avons ajustÃ© un modÃ¨le SARIMA afin de capturer la dÃ©pendance temporelle et la saisonnalitÃ© de la sÃ©rie ",
          C("y_t"), ". La spÃ©cification gÃ©nÃ©rale est ", C("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
          " avec ", C("Îµ_t"), " un bruit blanc. Le choix de (d, D) a Ã©tÃ© justifiÃ© par des tests de stationnaritÃ© (ADF/KPSS/PP) et des diagnostics. Â»"),
        
        H5("Conclusion & signification (Ã  expliciter)"),
        UL(
          tags$li(B("Conclusion type : "), "Â« Le modÃ¨le final est adÃ©quat Â»"),
          tags$li(B("Signification : "), "Â« (i) il ne laisse pas dâ€™information autocorrÃ©lÃ©e dans les rÃ©sidus, ",
                  "(ii) il gÃ©nÃ©ralise bien sur une fenÃªtre future, ",
                  "(iii) il est suffisamment simple pour Ãªtre stable et reproductible. Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        H5("PiÃ¨ges classiques"),
        UL(
          tags$li(B("Confondre AIC faible et bon modÃ¨le"), " : un AIC trÃ¨s bas avec rÃ©sidus autocorrÃ©lÃ©s = modÃ¨le mal spÃ©cifiÃ©."),
          tags$li(B("Oublier le benchmark"), " : sans SNAIVE/naÃ¯f, impossible de dire si SARIMA apporte rÃ©ellement quelque chose."),
          tags$li(B("Surcharger le modÃ¨le"), " : trop de paramÃ¨tres â†’ instabilitÃ©, intervalles de prÃ©vision peu fiables.")
        )
      )
    )
    
    # (1) Ã‰tape 0 â€” DÃ©finition du problÃ¨me
    pages[[2]] <- make_step(
      step_names[2],
      
      actions_ui = tagList(
        callout(
          B("But : "),
          "dÃ©finir un problÃ¨me de prÃ©vision mesurable (horizon, mÃ©triques, protocole).",
          type="info"
        ),
        
        Checklist(
          CheckItem("DÃ©finir la variable y_t (cible) et la frÃ©quence temporelle (jour, semaine, mois) sans ambiguite."),
          CheckItem("Fixer lâ€™horizon h en fonction de lâ€™usage reel (decision, planification, stock, etc.)."),
          CheckItem("Choisir un protocole dâ€™evaluation temporelle (train/test ou rolling-origin) et expliquer pourquoi."),
          CheckItem("Choisir des metriques (MAE + RMSE recommande) et justifier leur interpretation."),
          CheckItem("Decider si une transformation (log / Box-Cox) est necessaire et noter la raison.")
        ),
        
        Deliverables(
          tags$li("Un Ã©noncÃ© clair du problÃ¨me : â€œJe prÃ©vois y_t Ã  horizon h pour [usage concret]â€."),
          tags$li("Une dÃ©cision sur la stratÃ©gie dâ€™Ã©valuation (split chronologique ou rolling) + justification (Ã©viter la fuite dâ€™information)."),
          tags$li("Une liste courte de mÃ©triques retenues + interprÃ©tation attendue (erreur moyenne, pÃ©nalisation des grosses erreurs).")
        ),
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("DÃ©finitions (ce que chaque terme veut dire)")),
          
          tags$ul(
            tags$li(
              tags$b("SÃ©rie rÃ©ponse"), " ", tags$code("y_t"),
              " : variable Ã  prÃ©dire (univariÃ©e)."
            ),
            tags$li(
              tags$b("Horizon"), " ", tags$code("h"),
              " : nombre de pas Ã  prÃ©voir (ex. h = 12 mois)."
            ),
            tags$li(
              tags$b("Origine de prÃ©vision"),
              " : dernier temps observÃ© Ã  partir duquel on prÃ©voit."
            ),
            tags$li(
              tags$b("Protocole train/test"),
              " : sÃ©paration temporelle (jamais mÃ©langer le futur dans lâ€™entraÃ®nement)."
            ),
            tags$li(
              tags$b("Rolling-origin / validation temporelle"),
              " : on rÃ©pÃ¨te des prÃ©visions Ã  diffÃ©rentes origines pour estimer la performance moyenne."
            ),
            tags$li(
              tags$b("SARIMA vs SARIMAX"),
              " : SARIMA nâ€™utilise pas de variables explicatives ; SARIMAX inclut des rÃ©gressions exogÃ¨nes."
            )
          )
        ),
        
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Choisir les mÃ©triques (dÃ©finitions + quand utiliser)")),
          
          tags$ul(
            tags$li(
              tags$b("MAE"),
              " : moyenne des erreurs absolues ",
              tags$code("mean(|y-Å·|)"),
              " â†’ robuste, facile Ã  interprÃ©ter (unitÃ© de y)."
            ),
            tags$li(
              tags$b("RMSE"),
              " : racine de lâ€™erreur quadratique moyenne ",
              tags$code("sqrt(mean((y-Å·)^2))"),
              " â†’ pÃ©nalise plus les grosses erreurs."
            ),
            tags$li(
              tags$b("MAPE"),
              " : ",
              tags$code("mean(|(y-Å·)/y|)"),
              " â†’ Ã©viter si y proche de 0 (explose)."
            ),
            tags$li(
              tags$b("sMAPE"),
              " : alternative plus stable prÃ¨s de 0 : ",
              tags$code("mean(2|y-Å·|/(|y|+|Å·|))"),
              "."
            )
          )
        ),
        
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Transformation (dÃ©finitions + justification)")),
          
          tags$ul(
            tags$li(
              tags$b("Niveaux"),
              " : modÃ¨le sur les valeurs brutes."
            ),
            tags$li(
              tags$b("Log-niveaux"),
              " : utile si la variance augmente avec le niveau ; convertit souvent multiplicatif â†’ additif."
            ),
            tags$li(
              tags$b("Boxâ€“Cox"),
              " : transformation paramÃ©trique (Î») pour stabiliser la variance et amÃ©liorer la normalitÃ© : ",
              tags$code("y^(Î») = (y^Î» - 1)/Î»"),
              " (Î» â‰  0), et log si Î» = 0."
            )
          )
        ),
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("ProcÃ©dure minimale (checklist)")),
          
          tags$ol(
            tags$li("Fixer la frÃ©quence et la pÃ©riode saisonniÃ¨re ", tags$code("s"), "."),
            tags$li("Fixer lâ€™horizon ", tags$code("h"),
                    " et les fenÃªtres train/test (ou rolling-origin)."),
            tags$li("Choisir MAE + RMSE (recommandÃ©) ; documenter les raisons."),
            tags$li("DÃ©cider de la transformation (aucune / log / Boxâ€“Cox) et la justifier.")
          )
        ),
        
        
        
        # === ADD: prÃ©cisions pratiques, mÃ©triques complÃ©mentaires, transformations ===
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("PrÃ©cisions supplÃ©mentaires (dÃ©finitions pratiques)")),
          
          tags$ul(
            tags$li(
              tags$b("Horizon multi-pas"),
              " : ", tags$code("h > 1"),
              " â†’ la performance peut dÃ©croÃ®tre avec lâ€™horizon ; rapporter MAE/RMSE par ",
              tags$code("h"), " si possible."
            ),
            tags$li(
              tags$b("FenÃªtre dâ€™entraÃ®nement"),
              " : ",
              tags$b("expansive"),
              " (on ne jette jamais dâ€™anciens points) ou ",
              tags$b("glissante"),
              " (fenÃªtre fixe) ; documenter le choix."
            ),
            tags$li(
              tags$b("ReproductibilitÃ©"),
              " : fixer les graines alÃ©atoires, consigner les versions des packages, chemins de donnÃ©es."
            ),
            tags$li(
              tags$b("PrÃ©vision hiÃ©rarchique"),
              " (annexe) : si agrÃ©gations (mois â†’ trimestres), noter la cohÃ©rence temporelle."
            )
          )
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("MÃ©triques supplÃ©mentaires (quand utiles)")),
          
          tags$ul(
            tags$li(
              tags$b("MASE"),
              " : erreur absolue mise Ã  lâ€™Ã©chelle par le naÃ¯f saisonnier â†’ comparable entre sÃ©ries."
            ),
            tags$li(
              tags$b("WAPE"),
              " : ", tags$code("sum(|y-Å·|) / sum(|y|)"),
              " ; lisible comme % dâ€™erreur agrÃ©gÃ©e."
            ),
            tags$li(
              tags$b("Pinball loss (quantiles)"),
              " : utile si vous prÃ©disez des quantiles (intervalles asymÃ©triques)."
            )
          )
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Transformations complÃ©mentaires")),
          
          tags$ul(
            tags$li(
              tags$b("Yeoâ€“Johnson"),
              " : alternative Ã  Boxâ€“Cox qui gÃ¨re les valeurs â‰¤ 0."
            ),
            tags$li(
              tags$b("Stabilisation de variance"),
              " : vÃ©rifier la relation niveauâ€“variance ",
              "(nuage de points moyenne locale vs Ã©cart-type)."
            )
          )
        ),
        
        
      ),
      
      apa_ui = tagList(
        H5("MÃ©thodes (APA) â€” modÃ¨le de phrase complet"),
        P("Â« Nous avons modÃ©lisÃ© la sÃ©rie temporelle univariÃ©e ", C("y_t"),
          " observÃ©e Ã  une frÃ©quence [..] (pÃ©riode saisonniÃ¨re s=[..]). ",
          "Lâ€™objectif Ã©tait de produire des prÃ©visions Ã  horizon ", C("h"), "=[..]. ",
          "La performance a Ã©tÃ© Ã©valuÃ©e sur une fenÃªtre future selon [split temporel / rolling-origin] ",
          "Ã  lâ€™aide de [MAE, RMSE]. Une transformation [aucune / log / Boxâ€“Cox] a Ã©tÃ© appliquÃ©e afin de [stabiliser la variance / linÃ©ariser la saisonnalitÃ©]. Â»"),
        
        H5("Conclusion & signification (comment lâ€™expliquer)"),
        UL(
          tags$li(B("Conclusion : "), "Â« Notre problÃ¨me est bien dÃ©fini (h, mÃ©triques, protocole). Â»"),
          tags$li(B("Signification : "), "Â« Toute comparaison de modÃ¨les devient juste : mÃªme horizon, mÃªme protocole, mÃªmes mÃ©triques. Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Fuite temporelle"), " : utiliser des informations du futur (mauvais split) â†’ performance artificiellement Ã©levÃ©e."),
          tags$li(B("MÃ©trique mal choisie"), " : MAPE avec yâ‰ˆ0 â†’ conclusions fausses."),
          tags$li(B("Horizon incohÃ©rent"), " : un modÃ¨le bon Ã  h=1 peut Ãªtre mauvais Ã  h=12 ; fixer lâ€™horizon selon lâ€™usage rÃ©el.")
        )
      )
    )
    
    # (2) Ã‰tape 1 â€” Description des donnÃ©es
    pages[[3]] <- make_step(
      step_names[3],
      
      actions_ui = tagList(
        callout(B("But : "), "dÃ©crire la qualitÃ© des donnÃ©es et rendre le pipeline reproductible.", type="info"),
        
        Checklist(
          CheckItem("Verifier que lâ€™index temporel est regulier (pas manquants/dupliques, ordre correct)."),
          CheckItem("Rapporter n, date debut/fin, frequence, et la couverture temporelle."),
          CheckItem("Quantifier les manquants (k et %) et choisir une strategie (interpolation, saisonniere, Kalman) avec justification."),
          CheckItem("Produire un resume statistique (moyenne, mediane, ET, min/max) et un resume saisonnier (par mois/semaine)."),
          CheckItem("Documenter toute correction (doublons, valeurs aberrantes evidentes) pour garantir la reproductibilite.")
        ),
        
        Deliverables(
          tags$li("Un rÃ©sumÃ© qualitÃ© des donnÃ©es : N, dates dÃ©but/fin, frÃ©quence, valeurs manquantes, doublons, pÃ©riodes irrÃ©guliÃ¨res."),
          tags$li("Une stratÃ©gie documentÃ©e pour les manquants/outliers (suppression, interpolation, NA-LOCF, winsorisation) + justification."),
          tags$li("Des descriptifs simples : moyenne/variance, quantiles, min/max, et un rappel de lâ€™unitÃ© de mesure.")
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Ce quâ€™il faut rapporter (dÃ©finitions)")),
          
          tags$ul(
            tags$li(tags$b("n"), " : nombre total dâ€™observations disponibles."),
            tags$li(tags$b("Couverture"), " : date de dÃ©but et de fin."),
            tags$li(tags$b("FrÃ©quence"), " : pÃ©riodicitÃ© (mensuel / hebdomadaire / quotidien)."),
            tags$li(tags$b("Manquants"), " : nombre ", tags$code("k"),
                    " et pourcentage ", tags$code("k/n"), ".")
          )
        ),
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Valeurs manquantes : types + implications")),
          
          tags$ul(
            tags$li(
              tags$b("MCAR"),
              " (Missing Completely At Random) : manquants indÃ©pendants â†’ imputation plus dÃ©fendable."
            ),
            tags$li(
              tags$b("MAR"),
              " (Missing At Random conditionnel) : dÃ©pend dâ€™autres informations â†’ imputation possible mais Ã  justifier."
            ),
            tags$li(
              tags$b("MNAR"),
              " (Missing Not At Random) : dÃ©pend de la valeur elle-mÃªme â†’ risque de biais important."
            )
          )
        ),
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("StratÃ©gies de traitement (quand et pourquoi)")),
          
          tags$ul(
            tags$li(
              tags$b("Interpolation linÃ©aire"),
              " : si manquants rares et absence de ruptures."
            ),
            tags$li(
              tags$b("Interpolation saisonniÃ¨re"),
              " : si saisonnalitÃ© stable (ex. moyenne du mÃªme mois)."
            ),
            tags$li(
              tags$b("ModÃ¨le dâ€™Ã©tat / Kalman"),
              " : pour une imputation probabiliste cohÃ©rente avec la dynamique."
            ),
            tags$li(
              tags$b("Suppression"),
              " : uniquement si extrÃªmement rare et sans impact sur la continuitÃ© temporelle."
            )
          )
        ),
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Descriptifs pertinents (au-delÃ  de la moyenne)")),
          
          tags$ul(
            tags$li("Moyenne, mÃ©diane, Ã©cart-type, min/max (niveau)."),
            tags$li("AsymÃ©trie (skewness) et kurtosis si utile."),
            tags$li(
              "RÃ©sumÃ© saisonnier (ex. moyenne par mois) pour documenter la saisonnalitÃ©."
            )
          )
        ),
        
        
        # === ADD: qualitÃ© index & manquants pratiques ===
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("QualitÃ© de lâ€™index temporel (dÃ©finitions)")),
          
          tags$ul(
            tags$li(
              tags$b("RÃ©gularitÃ©"),
              " : pas manquants ou dupliquÃ©s ; cadence constante."
            ),
            tags$li(
              tags$b("Fuseau / DST"),
              " : donnÃ©es horaires â†’ attention aux heures manquantes ou dupliquÃ©es (changement dâ€™heure)."
            ),
            tags$li(
              tags$b("Doublons et dÃ©sordre temporel"),
              " : Ã  corriger avant tout calcul dâ€™ACF."
            )
          )
        ),
        
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Manquants â€” remarques pratiques")),
          
          tags$ul(
            tags$li(
              tags$b("Kalman / StructTS"),
              " : imputation probabiliste cohÃ©rente avec la dynamique ARIMA."
            ),
            tags$li(
              tags$b("Imputation â€œsaison identiqueâ€"),
              " : moyenne ou mÃ©diane du mÃªme mois / jour si saisonnalitÃ© stable."
            ),
            tags$li(
              tags$b("ZÃ©ros structurels"),
              " : distinguer zÃ©ro rÃ©el et manquant imputÃ© Ã  0 (Ã  documenter explicitement)."
            )
          )
        ),
        
        
      ),
      
      apa_ui = tagList(
        H5("RÃ©sultats (APA) â€” description"),
        P("Â« La sÃ©rie contient ", C("n"), "=[..] observations couvrant [..] Ã  [..] Ã  une frÃ©quence [..]. ",
          "Les valeurs manquantes reprÃ©sentaient [..]% (k=[..]) et ont Ã©tÃ© traitÃ©es par [..], ",
          "choisie car [manquants rares / saisonnalitÃ© stable / continuitÃ© nÃ©cessaire]. ",
          "La sÃ©rie prÃ©sentait une moyenne de [..] (ET=[..]) et une mÃ©diane [..]. Â»"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "Â« Les donnÃ©es sont suffisamment propres pour SARIMA Â» (ou non)."),
          tags$li(B("Signification : "),
                  "si lâ€™index est rÃ©gulier et que les manquants sont gÃ©rÃ©s explicitement, ",
                  "les hypothÃ¨ses du modÃ¨le (espacement rÃ©gulier) deviennent plausibles.")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Imputation silencieuse"), " : toujours documenter mÃ©thode + raison."),
          tags$li(B("Timestamps irrÃ©guliers"), " : SARIMA suppose une grille rÃ©guliÃ¨re ; corriger avant toute estimation."),
          tags$li(B("Changement de dÃ©finition de la variable"), " : ex. changement de mesure â†’ rupture structurelle Ã  traiter.")
        )
      )
    )
    
    # (3) Ã‰tape 2 â€” EDA
    pages[[4]] <- make_step(
      step_names[4],
      
      actions_ui = tagList(
        callout(B("But : "), "comprendre la structure (tendance/saison/ruptures/outliers) avant dâ€™ajuster SARIMA.", type="info"),
        
        Checklist(
          CheckItem("Tracer la serie y_t et annoter tendance, saisonnalite, ruptures possibles et changements de variance."),
          CheckItem("Construire au moins un graphique saisonnier (seasonal plot ou subseries) pour comprendre la forme par saison."),
          CheckItem("Identifier les outliers (dates) et formuler une hypothese (evenement reel vs erreur)."),
          CheckItem("Decider et documenter le traitement des outliers (conserver/corriger/imputer) et tester lâ€™impact sur lâ€™analyse."),
          CheckItem("Noter ce que lâ€™EDA implique pour la suite: transformation possible, differenciation probable, et presence de ruptures.")
        ),
        
        Deliverables(
          tags$li("Graphiques EDA : sÃ©rie brute, zooms, saisonnalitÃ© (par cycle), et repÃ©rage dâ€™anomalies (pics/creux)."),
          tags$li("Une hypothÃ¨se argumentÃ©e sur tendance et saisonnalitÃ© (prÃ©sentes ? stables ? changeantes ?)."),
          tags$li("Une premiÃ¨re lecture dâ€™autocorrÃ©lation (ACF/PACF exploratoires) sans conclure trop vite sur p/q.")
        ),
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("DÃ©finitions utiles (ce quâ€™on cherche)")),
          
          tags$ul(
            tags$li(
              tags$b("Tendance"),
              " : Ã©volution de long terme (dÃ©terministe ou stochastique)."
            ),
            tags$li(
              tags$b("SaisonnalitÃ©"),
              " : motif pÃ©riodique de pÃ©riode ", tags$code("s"),
              " (ex. 12)."
            ),
            tags$li(
              tags$b("Rupture structurelle"),
              " : changement durable de niveau, de tendance ou de variance ",
              "(ex. politique, crise)."
            ),
            tags$li(
              tags$b("Outlier"),
              " : valeur atypique ponctuelle ; peut Ãªtre rÃ©elle (fÃªtes) ou une erreur."
            )
          )
        ),
        
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Graphiques recommandÃ©s + leur but")),
          
          tags$ul(
            tags$li(
              tags$b("Courbe "), tags$code("y_t"),
              " : visualiser tendance, variance et ruptures."
            ),
            tags$li(
              tags$b("Seasonal plot"),
              " : comparer la forme saisonniÃ¨re dâ€™une annÃ©e Ã  lâ€™autre."
            ),
            tags$li(
              tags$b("Boxplots par saison"),
              " : dÃ©tecter asymÃ©trie et outliers par mois ou par semaine."
            ),
            tags$li(
              tags$b("ACF brute"),
              " (optionnel) : repÃ©rer dÃ©pendances fortes et saisonnalitÃ©."
            )
          )
        ),
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Outliers : procÃ©dure raisonnable")),
          
          tags$ol(
            tags$li("RepÃ©rer visuellement (dates concernÃ©es)."),
            tags$li("Proposer une hypothÃ¨se (Ã©vÃ©nement rÃ©el ? erreur ?)."),
            tags$li("DÃ©cider : conserver / corriger / imputer (et justifier)."),
            tags$li("Documenter lâ€™impact (le modÃ¨le change-t-il beaucoup ?).")
          )
        ),
        
        
        # === ADD: outils EDA supplÃ©mentaires & typologie outliers ===
        

        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Outils EDA supplÃ©mentaires")),
          
          tags$ul(
            tags$li(
              tags$b("PÃ©riodogramme / spectre"),
              " : met en Ã©vidence des frÃ©quences saisonniÃ¨res inattendues."
            ),
            tags$li(
              tags$b("Seasonal subseries plot"),
              " : visualise la forme saisonniÃ¨re par mois / semaine."
            ),
            tags$li(
              tags$b("Nuage niveauâ€“variance"),
              " : aide au choix log / Boxâ€“Cox (variance croÃ®t avec le niveau ?)."
            )
          )
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Types dâ€™outliers (interventions)")),
          
          tags$ul(
            tags$li(tags$b("AO"), " : Additive Outlier (pic ponctuel)."),
            tags$li(tags$b("IO"), " : Innovation Outlier (choc qui diffuse)."),
            tags$li(tags$b("LS"), " : Level Shift (changement de niveau)."),
            tags$li(tags$b("TC"), " : Temporary Change (effet transitoire).")
          )
        ),
        
        
        
      ),
      
      apa_ui = tagList(
        H5("RÃ©sultats (APA) â€” EDA"),
        P("Â« Lâ€™inspection visuelle a mis en Ã©vidence une tendance [..] et une saisonnalitÃ© rÃ©currente de pÃ©riode s=[..]. ",
          "La variance semblait [constante / croissante avec le niveau], motivant [aucune transformation / log / Boxâ€“Cox]. ",
          "Des valeurs atypiques autour de [dates] ont Ã©tÃ© [conservÃ©es/traitÃ©es] car [Ã©vÃ©nement rÃ©el / erreur probable]. Â»"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "Â« La structure (tendance/saison/variance/outliers) est comprise Â»"),
          tags$li(B("Signification : "),
                  "cela guide directement le choix transformation + diffÃ©renciations (d, D) et Ã©vite dâ€™ajuster un SARIMA â€œÃ  lâ€™aveugleâ€.")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Confondre saisonnalitÃ© et tendance"), " : une moyenne croissante ET une saisonnalitÃ© stable sont deux composantes distinctes."),
          tags$li(B("Retirer des points rÃ©els"), " : si lâ€™outlier correspond Ã  un Ã©vÃ©nement rÃ©current (fÃªtes), il doit rester."),
          tags$li(B("Ignorer une rupture"), " : un SARIMA â€œmoyenneâ€ une structure qui a changÃ© â†’ mauvais futur.")
        )
      )
    )
    
    # (4) Ã‰tape 3 â€” DÃ©composition
    pages[[5]] <- make_step(
      step_names[5],
      
      actions_ui = tagList(
        callout(B("But : "), "sÃ©parer tendance/saison/bruit pour motiver la forme (additive vs multiplicative).", type="info"),
        
        Checklist(
          CheckItem("Comparer visuellement une hypothese additive vs multiplicative (amplitude saisonniere constante vs proportionnelle au niveau)."),
          CheckItem("Tester lâ€™idee de transformation log/Box-Cox si la variance augmente avec le niveau."),
          CheckItem("Realiser une decomposition (classique ou STL) et commenter la tendance, la saisonnalite et le residu."),
          CheckItem("Verifier si la saisonnalite semble stable ou evolutive (argument pour STL)."),
          CheckItem("Ecrire clairement ce que la decomposition suggere pour d, D, et pour lâ€™echelle de modelisation.")
        ),
        
        Deliverables(
          tags$li("Une dÃ©composition (STL ou Ã©quivalent) + conclusion : additif vs multiplicatif, et stabilitÃ© de la saisonnalitÃ©."),
          tags$li("Une dÃ©cision de transformation (log / Boxâ€“Cox) si variance non constante + note sur la reconversion des prÃ©visions."),
          tags$li("Une interprÃ©tation du â€œresteâ€ (rÃ©sidu) : signal non expliquÃ© vs bruit (est-ce encore structurÃ© ?).")
        ),
        
        
        H5("DÃ©composition : dÃ©finitions"),
        UL(
          tags$li(B("Additive"), " : ", C("y_t = T_t + S_t + e_t"),
                  " (amplitude saisonniÃ¨re ~ constante)."),
          tags$li(B("Multiplicative"), " : ", C("y_t = T_t Ã— S_t Ã— e_t"),
                  " (amplitude saisonniÃ¨re augmente avec le niveau)."),
          tags$li(B("Log"), " : si multiplicatif, log transforme souvent en additif : ",
                  C("log(y_t) = log(T_t) + log(S_t) + log(e_t)"), "."),
          tags$li(B("STL"), " : Seasonal-Trend decomposition using Loess ; flexible, possible robuste aux outliers.")
        ),
        
        H5("Pourquoi STL ? (objectif dÃ©taillÃ©)"),
        UL(
          tags$li("Quand la saisonnalitÃ© change lentement au fil du temps (non parfaitement rÃ©pÃ©titive)."),
          tags$li("Quand on veut rÃ©duire lâ€™influence des outliers sur lâ€™estimation saison/tendance."),
          tags$li("Quand on veut une lecture pÃ©dagogique claire (tendance vs saison vs rÃ©sidu).")
        ),
        
        H5("Ce que la dÃ©composition ne remplace pas"),
        UL(
          tags$li("Elle ne prouve pas la stationnaritÃ© : SARIMA exige une sÃ©rie stationnaire aprÃ¨s diffÃ©renciation."),
          tags$li("Elle ne choisit pas automatiquement (p,q,P,Q) : ACF/PACF + diagnostics restent nÃ©cessaires.")
        ),
        
        # === ADD: paramÃ¨tres STL & rÃ¨gles pratiques ===
        H5("ParamÃ¨tres STL (lecture pÃ©dagogique)"),
        UL(
          tags$li(B("s.window"), " : lissage saisonnier (", C("periodic"), " = saison constante; entier = Ã©volutive)."),
          tags$li(B("t.window"), " : lissage de la tendance (fenÃªtre LOESS)."),
          tags$li(B("robust"), " : rÃ©duit lâ€™influence des outliers (itÃ©rations avec poids).")
        ),
        H5("Additif vs multiplicatif (rÃ¨gle pratique)"),
        UL(
          tags$li("Amplitude saisonniÃ¨re ~ proportionnelle au niveau â†’ penser ", B("log"), " ou modÃ¨le multiplicatif."),
          tags$li("Amplitude ~ constante â†’ additif sur niveaux.")
        )
      ),
      
      apa_ui = tagList(
        H5("MÃ©thodes (APA) â€” DÃ©composition"),
        P("Â« Nous avons Ã©tudiÃ© une structure additive vs multiplicative en Ã©valuant si lâ€™amplitude saisonniÃ¨re variait avec le niveau. ",
          "Comme [..], nous avons retenu [modÃ¨le additif / transformation log] et rÃ©alisÃ© une dÃ©composition via [classique / STL]. ",
          "STL a Ã©tÃ© privilÃ©giÃ©e pour sa flexibilitÃ© (saisonnalitÃ© Ã©volutive) et sa robustesse aux valeurs atypiques. Â»"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "Â« Le choix additif/multiplicatif est justifiÃ© Â»"),
          tags$li(B("Signification : "),
                  "on Ã©vite des rÃ©sidus hÃ©tÃ©roscÃ©dastiques et on amÃ©liore la stabilitÃ© de lâ€™estimation SARIMA.")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("DÃ©composition â‰  stationnaritÃ©"), " : aprÃ¨s dÃ©composition, on doit encore tester/choisir d et D."),
          tags$li(B("Oublier lâ€™Ã©chelle"), " : si vous modÃ©lisez log(y), les prÃ©visions doivent Ãªtre reconverties (avec prudence)."),
          tags$li(B("Confondre bruit et structure"), " : des motifs rÃ©siduels persistants suggÃ¨rent que la saison/tendance nâ€™a pas Ã©tÃ© correctement capturÃ©e.")
        )
      )
    )
    
    # (5) Ã‰tape 4 â€” StationnaritÃ© (trÃ¨s dÃ©taillÃ© : ADF/KPSS/PP + â€¦)
    pages[[6]] <- make_step(
      step_names[6],
      
      actions_ui = tagList(
        callout(
          B("IdÃ©e centrale : "),
          "Dans un SARIMA, on nâ€™essaie pas de modÃ©liser directement une sÃ©rie â€˜qui dÃ©riveâ€™ : on cherche dâ€™abord Ã  obtenir une sÃ©rie stationnaire (au moins approximativement) via la diffÃ©renciation. Les tests ADF, PP et KPSS ne sont pas des â€œjugesâ€ absolus, mais des indices complÃ©mentaires qui aident Ã  justifier les choix (d, D) de faÃ§on argumentÃ©e.",
          type = "ok"
        ),
        
        Checklist(
          CheckItem("DÃ©finir la stationnaritÃ© avec vos mots (moyenne/variance stables; dÃ©pendance qui ne change pas au cours du temps)."),
          CheckItem("Appliquer ADF, KPSS et PP sur la sÃ©rie brute, puis Ã©crire clairement H0 et Ha pour chacun (ils ne testent pas la mÃªme chose)."),
          CheckItem("Proposer d et D de maniÃ¨re progressive (essayer d=1 puis D=1 si nÃ©cessaire) et re-tester aprÃ¨s chaque transformation."),
          CheckItem("Surveiller les signes de surâ€‘diffÃ©renciation (ACF lag 1 trÃ¨s nÃ©gative, variance gonflÃ©e, dynamique artificielle)."),
          CheckItem("Justifier le choix final (d, D, s) par convergence : tests + graphiques + ACF/PACF, pas par une seule pâ€‘value.")
        ),
        
        Deliverables(
          tags$li("RÃ©sultats ADF/KPSS/PP (brut puis aprÃ¨s diffÃ©renciation) + dÃ©cision sur d et D, justifiÃ©e par critÃ¨res et plots."),
          tags$li("Graphiques de la sÃ©rie diffÃ©renciÃ©e (et Ã©ventuellement ACF/PACF sur sÃ©rie stationnaire) pour confirmer la dÃ©cision."),
          tags$li("Un avertissement Ã©crit sur le surâ€‘diffÃ©renciage (perte dâ€™information, ACF nÃ©gative forte au lag 1, etc.).")
        ),
        
        
        
        

        
        
        # =========================
        # StationnaritÃ© & tests
        # =========================
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("DÃ©finition : stationnaritÃ© (ce que cela veut dire)")),
          tags$ul(
            tags$li(
              tags$b("StationnaritÃ© faible (covariance-stationnaire)"),
              " : moyenne constante, variance constante, et autocovariance dÃ©pend uniquement du retard (pas de t)."
            ),
            tags$li(
              tags$b("Non-stationnaritÃ©"),
              " : tendance stochastique (racine unitaire), variance changeante, ou saisonnalitÃ© non traitÃ©e."
            ),
            tags$li(
              tags$b("Racine unitaire"),
              " : choc permanent (effet ne sâ€™Ã©teint pas), typique dâ€™un processus I(1)."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("DiffÃ©renciation : rÃ´le (d vs D)")),
          tags$ul(
            tags$li(
              tags$b("d"),
              " enlÃ¨ve la racine unitaire non saisonniÃ¨re / tendance stochastique : ",
              tags$code("(1-B)^d"), "."
            ),
            tags$li(
              tags$b("D"),
              " enlÃ¨ve la racine unitaire saisonniÃ¨re : ",
              tags$code("(1-B^s)^D"), "."
            ),
            tags$li(
              tags$b("RÃ¨gle pratique"),
              " : d âˆˆ {0,1,2} (souvent 0â€“1) ; D âˆˆ {0,1} (rarement 2)."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test ADF (Augmented Dickeyâ€“Fuller) â€” dÃ©finition & objectif")),
          tags$ul(
            tags$li(
              tags$b("But"),
              " : tester si la sÃ©rie contient une racine unitaire (non-stationnaire) en prÃ©sence dâ€™autocorrÃ©lation."
            ),
            tags$li(
              tags$b("RÃ©gression (intuition)"),
              " : on teste si le coefficient de ",
              tags$code("y_{t-1}"),
              " est compatible avec une racine unitaire aprÃ¨s ajout de retards de Î”y pour â€œabsorberâ€ lâ€™autocorrÃ©lation."
            ),
            tags$li(
              tags$b("HypothÃ¨ses"),
              " : ",
              tags$b("H0"), " = racine unitaire (non-stationnaire) ; ",
              tags$b("Ha"), " = stationnaire (autour dâ€™une moyenne ou dâ€™une tendance selon la spÃ©cification)."
            ),
            tags$li(
              tags$b("InterprÃ©tation p-value"),
              " : p petit â†’ rejet H0 â†’ stationnaritÃ© (au sens ADF). ",
              "p grand â†’ on ne rejette pas â†’ diffÃ©renciation probablement nÃ©cessaire."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Test ADF (Augmented Dickeyâ€“Fuller) â€” dÃ©finition complÃ¨te et opÃ©rationnelle")),
              
              tags$ul(
                
                tags$li(
                  tags$b("DÃ©finition"),
                  " : le test ADF est un test de ",
                  tags$b("racine unitaire"),
                  " permettant dâ€™Ã©valuer si une sÃ©rie temporelle est ",
                  tags$b("non-stationnaire"),
                  " en raison dâ€™une tendance stochastique (chocs permanents)."
                ),
                
                tags$li(
                  tags$b("But"),
                  " : dÃ©terminer si les chocs ont un effet ",
                  tags$b("transitoire"),
                  " (stationnaritÃ©) ou ",
                  tags$b("permanent"),
                  " (racine unitaire), afin de dÃ©cider sâ€™il faut ",
                  tags$b("diffÃ©rencier"),
                  " la sÃ©rie."
                ),
                
                tags$li(
                  tags$b("Quand lâ€™utiliser"),
                  " : en phase dâ€™EDA et avant tout ARIMA/SARIMA, pour guider le choix de ",
                  tags$code("d"),
                  " (et indirectement ",
                  tags$code("D"),
                  "), toujours en complÃ©ment dâ€™ACF, KPSS et inspection graphique."
                ),
                
                tags$li(
                  tags$b("HypothÃ¨ses"),
                  " : ",
                  tags$b("H0"),
                  " = la sÃ©rie contient une racine unitaire (non-stationnaire) ; ",
                  tags$b("Ha"),
                  " = la sÃ©rie est stationnaire (autour dâ€™une moyenne ou dâ€™une tendance dÃ©terministe)."
                ),
                
                tags$li(
                  tags$b("Statistique / idÃ©e"),
                  " : le test repose sur la rÃ©gression ",
                  tags$code("Î”y_t = Î± + Î²t + Î³y_{t-1} + Î£Î´_i Î”y_{t-i} + Îµ_t"),
                  " et consiste Ã  tester si ",
                  tags$code("Î³ = 0"),
                  ". Les retards de Î”y servent Ã  Ã©liminer lâ€™autocorrÃ©lation rÃ©siduelle."
                ),
                
                tags$li(
                  tags$b("SpÃ©cification du test"),
                  " : trois versions existent â€” ",
                  tags$b("sans constante"),
                  ", ",
                  tags$b("avec constante (drift)"),
                  ", ou ",
                  tags$b("avec constante + tendance"),
                  ". Le choix dÃ©pend du graphe de la sÃ©rie (moyenne â‰  0 ? tendance visible ?)."
                ),
                
                tags$li(
                  tags$b("RÃ¨gle de dÃ©cision"),
                  " : si la statistique ADF est suffisamment nÃ©gative (p-value < Î±), on ",
                  tags$b("rejette H0"),
                  " â†’ absence de racine unitaire au sens du test."
                ),
                
                tags$li(
                  tags$b("InterprÃ©tation (sens Ã©conomique/statistique)"),
                  " : ",
                  tags$b("rejet de H0"),
                  " â†’ les chocs sâ€™Ã©teignent â†’ modÃ¨le en niveaux ou ARMA possible ; ",
                  tags$b("non-rejet"),
                  " â†’ chocs persistants â†’ diffÃ©renciation recommandÃ©e."
                ),
                
                tags$li(
                  tags$b("Ce que Ã§a implique pour vos choix"),
                  " : ",
                  "â€¢ ADF rejette H0 â†’ ",
                  tags$code("d = 0"),
                  " plausible ; ",
                  "â€¢ ADF ne rejette pas â†’ essayer ",
                  tags$code("d = 1"),
                  " puis retester ; ",
                  "â€¢ ne jamais choisir ",
                  tags$code("d"),
                  " sur la seule base dâ€™un test."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter"),
                  " : prÃ©ciser la version du test (drift/tendance), la statistique ADF, ",
                  "la p-value et la conclusion quant Ã  la stationnaritÃ©."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter en format APA"),
                  " : ",
                  tags$i(
                    "Â« Un test de Dickeyâ€“Fuller augmentÃ© a Ã©tÃ© conduit afin dâ€™Ã©valuer la stationnaritÃ© de la sÃ©rie. "
                  ),
                  tags$i(
                    "Le test nâ€™a pas permis de rejeter lâ€™hypothÃ¨se de racine unitaire, "
                  ),
                  tags$i(
                    "ADF = âˆ’2.11, p = .24, suggÃ©rant la nÃ©cessitÃ© dâ€™une diffÃ©renciation. Â»"
                  ),
                  " (adapter la formulation selon le rejet ou non de H0)."
                ),
                
                tags$li(
                  tags$b("Limites / piÃ¨ges"),
                  " : faible puissance sur petits Ã©chantillons ; ",
                  "sensibilitÃ© au nombre de retards et Ã  la spÃ©cification ; ",
                  "mauvaise performance en prÃ©sence de ruptures structurelles ; ",
                  tags$b("ne jamais interprÃ©ter isolÃ©ment"),
                  " (toujours confronter Ã  KPSS, PP et aux graphiques)."
                )
              )
            ),
            
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test KPSS â€” dÃ©finition & objectif (inverse de lâ€™ADF)")),
          tags$ul(
            tags$li(
              tags$b("But"),
              " : tester si la sÃ©rie est stationnaire (niveau ou tendance)."
            ),
            tags$li(
              tags$b("HypothÃ¨ses"),
              " : ",
              tags$b("H0"), " = stationnaire ; ",
              tags$b("Ha"), " = non-stationnaire (racine unitaire / stationnaritÃ© violÃ©e)."
            ),
            tags$li(
              tags$b("InterprÃ©tation"),
              " : p petit â†’ rejet H0 â†’ non-stationnaire. p grand â†’ compatible stationnaritÃ©."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Test KPSS â€” dÃ©finition complÃ¨te")),
              
              tags$ul(
                
                tags$li(
                  tags$b("DÃ©finition"),
                  " : le test KPSS (Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin) est un test de ",
                  tags$b("stationnaritÃ©"),
                  " qui Ã©value si une sÃ©rie est stationnaire autour dâ€™un niveau ou dâ€™une tendance."
                ),
                
                tags$li(
                  tags$b("But"),
                  " : vÃ©rifier si lâ€™hypothÃ¨se de stationnaritÃ© est compatible avec les donnÃ©es, ",
                  "en complÃ©ment des tests de racine unitaire (ADF, PP)."
                ),
                
                tags$li(
                  tags$b("Quand lâ€™utiliser"),
                  " : en ",
                  tags$b("complÃ©ment systÃ©matique"),
                  " de lâ€™ADF/PP pour Ã©viter les conclusions biaisÃ©es basÃ©es sur un seul test."
                ),
                
                tags$li(
                  tags$b("HypothÃ¨ses"),
                  " : ",
                  tags$b("H0"),
                  " = la sÃ©rie est stationnaire (niveau ou tendance) ; ",
                  tags$b("Ha"),
                  " = la sÃ©rie nâ€™est pas stationnaire (stationnaritÃ© violÃ©e)."
                ),
                
                tags$li(
                  tags$b("Statistique / idÃ©e"),
                  " : la statistique KPSS mesure lâ€™ampleur de la ",
                  tags$b("somme cumulÃ©e des rÃ©sidus"),
                  " dâ€™une rÃ©gression de la sÃ©rie sur une constante (ou constante + tendance). ",
                  "Une dÃ©rive importante indique une non-stationnaritÃ©."
                ),
                
                tags$li(
                  tags$b("RÃ¨gle de dÃ©cision"),
                  " : ",
                  tags$b("p petite"),
                  " â†’ rejet de H0 â†’ non-stationnaritÃ© ; ",
                  tags$b("p grande"),
                  " â†’ compatibilitÃ© avec la stationnaritÃ©."
                ),
                
                tags$li(
                  tags$b("InterprÃ©tation (sens)"),
                  " : contrairement Ã  lâ€™ADF, ",
                  tags$b("KPSS inverse la logique"),
                  " : ici, rejeter H0 signifie que la sÃ©rie nâ€™est probablement pas stationnaire."
                ),
                
                tags$li(
                  tags$b("Ce que Ã§a implique pour vos choix"),
                  " : si KPSS rejette H0 â†’ diffÃ©renciation recommandÃ©e (",
                  tags$code("d"),
                  " ou ",
                  tags$code("D"),
                  "). Si KPSS ne rejette pas â†’ pas de diffÃ©renciation supplÃ©mentaire nÃ©cessaire."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter"),
                  " : prÃ©ciser le type de stationnaritÃ© testÃ©e (niveau ou tendance), ",
                  "la statistique KPSS, la p-value et la conclusion."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter en format APA"),
                  " : ",
                  tags$i("Â« Un test KPSS nâ€™a pas rejetÃ© lâ€™hypothÃ¨se de stationnaritÃ©, "),
                  tags$i("KPSS = 0.21, p = .10, indiquant que la sÃ©rie est compatible "),
                  tags$i("avec une stationnaritÃ© autour dâ€™un niveau. Â»"),
                  " (adapter selon rÃ©sultats)."
                ),
                
                tags$li(
                  tags$b("Limites / piÃ¨ges"),
                  " : sensible au choix du paramÃ¨tre de lissage (bandwidth) ; ",
                  "peut sur-rejeter sur grands Ã©chantillons ; ",
                  "ne dÃ©tecte pas explicitement les ruptures structurelles."
                )
              )
            ),
            
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test PP (Phillipsâ€“Perron) â€” dÃ©finition & objectif")),
          tags$ul(
            tags$li(
              tags$b("But"),
              " : test de racine unitaire comme ADF, mais corrige lâ€™autocorrÃ©lation et lâ€™hÃ©tÃ©roscÃ©dasticitÃ© autrement ",
              "(correction non-paramÃ©trique)."
            ),
            tags$li(
              tags$b("HypothÃ¨ses"),
              " : ",
              tags$b("H0"), " = racine unitaire ; ",
              tags$b("Ha"), " = stationnaire."
            ),
            tags$li(
              tags$b("Pourquoi utile"),
              " : complÃ©ment de robustesse ; si ADF et PP convergent, confiance accrue."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Test PP (Phillipsâ€“Perron) â€” dÃ©finition complÃ¨te")),
              
              tags$ul(
                
                tags$li(
                  tags$b("DÃ©finition"),
                  " : le test Phillipsâ€“Perron est un test de ",
                  tags$b("racine unitaire"),
                  " similaire Ã  lâ€™ADF, mais qui corrige lâ€™autocorrÃ©lation et ",
                  "lâ€™hÃ©tÃ©roscÃ©dasticitÃ© de maniÃ¨re non paramÃ©trique."
                ),
                
                tags$li(
                  tags$b("But"),
                  " : tester la prÃ©sence dâ€™une racine unitaire de faÃ§on plus robuste ",
                  "aux violations des hypothÃ¨ses classiques."
                ),
                
                tags$li(
                  tags$b("Quand lâ€™utiliser"),
                  " : comme ",
                  tags$b("test de robustesse"),
                  " en complÃ©ment de lâ€™ADF, notamment si lâ€™autocorrÃ©lation ou ",
                  "lâ€™hÃ©tÃ©roscÃ©dasticitÃ© sont suspectÃ©es."
                ),
                
                tags$li(
                  tags$b("HypothÃ¨ses"),
                  " : ",
                  tags$b("H0"),
                  " = prÃ©sence dâ€™une racine unitaire (non-stationnaire) ; ",
                  tags$b("Ha"),
                  " = sÃ©rie stationnaire."
                ),
                
                tags$li(
                  tags$b("Statistique / idÃ©e"),
                  " : basÃ© sur la mÃªme rÃ©gression que lâ€™ADF, ",
                  "mais ajuste la statistique de test via une estimation ",
                  tags$b("non paramÃ©trique"),
                  " de la variance longue."
                ),
                
                tags$li(
                  tags$b("RÃ¨gle de dÃ©cision"),
                  " : ",
                  tags$b("p petite"),
                  " â†’ rejet de H0 â†’ stationnaritÃ© ; ",
                  tags$b("p grande"),
                  " â†’ racine unitaire probable."
                ),
                
                tags$li(
                  tags$b("InterprÃ©tation (sens)"),
                  " : mÃªme logique que lâ€™ADF, mais plus robuste aux dÃ©pendances complexes."
                ),
                
                tags$li(
                  tags$b("Ce que Ã§a implique pour vos choix"),
                  " : convergence ADF + PP â†’ forte confiance dans la dÃ©cision sur ",
                  tags$code("d"),
                  " ; divergence â†’ prudence et analyse complÃ©mentaire."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter"),
                  " : indiquer quâ€™il sâ€™agit dâ€™un test PP, la statistique, la p-value ",
                  "et la conclusion."
                ),
                
                tags$li(
                  tags$b("Comment le rapporter en format APA"),
                  " : ",
                  tags$i("Â« Le test de Phillipsâ€“Perron a rejetÃ© lâ€™hypothÃ¨se de racine unitaire, "),
                  tags$i("PP = âˆ’3.42, p = .01, suggÃ©rant une stationnaritÃ© de la sÃ©rie. Â»")
                ),
                
                tags$li(
                  tags$b("Limites / piÃ¨ges"),
                  " : choix du paramÃ¨tre de lissage non trivial ; ",
                  "peut Ãªtre instable sur petits Ã©chantillons ; ",
                  "ne remplace pas lâ€™analyse graphique."
                )
              )
            ),
            
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Comment conclure en combinant ADF/KPSS/PP (logique complÃ¨te)")),
          tags$ol(
            tags$li(
              tags$b("StationnaritÃ© forte : "),
              "ADF/PP rejettent H0 (p petit) ET KPSS ne rejette pas (p grand)."
            ),
            tags$li(
              tags$b("Non-stationnaritÃ© forte : "),
              "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."
            ),
            tags$li(
              tags$b("Conflit : "),
              "les tests divergent â†’ regarder graphiques, ACF, rÃ©sultats aprÃ¨s une diffÃ©rence, ",
              "et justifier par convergence dâ€™indices (pas une seule p-value)."
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Comment conclure en combinant ADF / KPSS / PP (logique complÃ¨te)")),
              
              tags$ol(
                
                tags$li(
                  tags$b("StationnaritÃ© forte"),
                  " : ADF et PP ",
                  tags$b("rejettent"),
                  " lâ€™hypothÃ¨se de racine unitaire (p petites) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("ne rejette pas"),
                  " lâ€™hypothÃ¨se de stationnaritÃ©."
                ),
                
                tags$li(
                  tags$b("Non-stationnaritÃ© forte"),
                  " : ADF et PP ",
                  tags$b("ne rejettent pas"),
                  " (p grandes) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("rejette"),
                  " la stationnaritÃ©."
                ),
                
                tags$li(
                  tags$b("Cas intermÃ©diaire / conflit"),
                  " : les tests divergent â†’ examiner graphiques, ACF, rÃ©sultats aprÃ¨s ",
                  "une ou plusieurs diffÃ©renciations, et justifier la dÃ©cision par ",
                  tags$b("convergence dâ€™indices"),
                  " (jamais une seule p-value)."
                ),
                
                tags$li(
                  tags$b("DÃ©cision pratique"),
                  " : appliquer la ",
                  tags$b("diffÃ©renciation minimale"),
                  " nÃ©cessaire pour obtenir une stationnaritÃ© raisonnable ",
                  "(Ã©viter la sur-diffÃ©renciation)."
                ),
                
                tags$li(
                  tags$b("Principe clÃ©"),
                  " : les tests sont des ",
                  tags$b("outils dâ€™aide Ã  la dÃ©cision"),
                  ", pas des rÃ¨gles automatiques."
                )
              )
            ),
            
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Comment conclure en combinant ADF / KPSS / PP (logique complÃ¨te et dÃ©taillÃ©e)")),
              
              tags$ol(
                
                tags$li(
                  tags$b("Principe gÃ©nÃ©ral"),
                  " : aucun test nâ€™est fiable isolÃ©ment. ",
                  "La conclusion doit reposer sur la ",
                  tags$b("cohÃ©rence"),
                  " entre tests (ADF, PP, KPSS), graphiques (sÃ©rie, ACF), ",
                  "et parcimonie des transformations."
                ),
                
                tags$li(
                  tags$b("Rappel des logiques opposÃ©es"),
                  " : ADF et PP testent la ",
                  tags$b("prÃ©sence dâ€™une racine unitaire"),
                  " (H0 = non-stationnaritÃ©), ",
                  "alors que KPSS teste la ",
                  tags$b("stationnaritÃ©"),
                  " (H0 = stationnaire). ",
                  "Ils sont donc ",
                  tags$b("complÃ©mentaires"),
                  " par construction."
                ),
                
                tags$li(
                  tags$b("Cas 1 â€” StationnaritÃ© forte (convergence totale)"),
                  " : ",
                  tags$b("ADF et PP rejettent H0"),
                  " (p petites) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("ne rejette pas"),
                  " H0. ",
                  "â†’ Conclusion : sÃ©rie stationnaire â†’ ",
                  tags$code("d = 0"),
                  " (et ",
                  tags$code("D = 0"),
                  " si pas de saisonnalitÃ©)."
                ),
                
                tags$li(
                  tags$b("Cas 2 â€” Non-stationnaritÃ© forte (convergence inverse)"),
                  " : ",
                  tags$b("ADF et PP ne rejettent pas"),
                  " (p grandes) ",
                  tags$b("ET"),
                  " KPSS ",
                  tags$b("rejette"),
                  " la stationnaritÃ©. ",
                  "â†’ Conclusion : racine unitaire claire â†’ ",
                  tags$code("d = 1"),
                  " recommandÃ© (puis retester)."
                ),
                
                tags$li(
                  tags$b("Cas 3 â€” ADF/PP rejettent mais KPSS rejette aussi"),
                  " : situation frÃ©quente sur grands Ã©chantillons. ",
                  "â†’ Possible ",
                  tags$b("stationnaritÃ© autour dâ€™une tendance"),
                  " ou ",
                  tags$b("rupture structurelle"),
                  ". Examiner graphiques, tester ADF avec tendance, ",
                  "ou prÃ©fÃ©rer une diffÃ©renciation prudente."
                ),
                
                tags$li(
                  tags$b("Cas 4 â€” ADF/PP ne rejettent pas mais KPSS ne rejette pas"),
                  " : tests peu informatifs (faible puissance). ",
                  "â†’ Examiner la sÃ©rie visuellement, tester aprÃ¨s ",
                  tags$code("d = 1"),
                  ", et privilÃ©gier la solution ",
                  tags$b("la plus parcimonieuse"),
                  "."
                ),
                
                tags$li(
                  tags$b("Cas 5 â€” DÃ©saccord ADF vs PP"),
                  " : indÃ©cision liÃ©e Ã  lâ€™autocorrÃ©lation ou Ã  lâ€™hÃ©tÃ©roscÃ©dasticitÃ©. ",
                  "â†’ Donner plus de poids au PP (plus robuste) ",
                  "et confronter avec KPSS et ACF."
                ),
                
                tags$li(
                  tags$b("Logique opÃ©rationnelle recommandÃ©e"),
                  " : (1) tester sur la sÃ©rie brute ; ",
                  "(2) essayer ",
                  tags$code("d = 1"),
                  " si nÃ©cessaire ; ",
                  "(3) retester systÃ©matiquement ; ",
                  "(4) sâ€™arrÃªter dÃ¨s quâ€™une stationnaritÃ© ",
                  tags$b("raisonnable"),
                  " est atteinte."
                ),
                
                tags$li(
                  tags$b("Principe de parcimonie"),
                  " : toujours appliquer la ",
                  tags$b("diffÃ©renciation minimale"),
                  " compatible avec la stationnaritÃ©. ",
                  "La sur-diffÃ©renciation dÃ©grade les prÃ©visions."
                ),
                
                tags$li(
                  tags$b("RÃ´le clÃ© des graphiques"),
                  " : ACF, sÃ©rie temporelle, et rÃ©sidus aprÃ¨s diffÃ©renciation ",
                  "sont indispensables pour confirmer ou infirmer ",
                  "les conclusions issues des tests."
                ),
                
                tags$li(
                  tags$b("Conclusion scientifique attendue"),
                  " : la dÃ©cision finale doit Ãªtre ",
                  tags$b("argumentÃ©e"),
                  " par la convergence des tests, ",
                  "lâ€™inspection graphique et la logique Ã©conomique, ",
                  "pas par une seule p-value."
                )
              )
            ),
            
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Combiner ADF / KPSS / PP â€” tableau dÃ©taillÃ© de dÃ©cision (stationnaritÃ©)")),
              
              tags$table(
                class = "table table-sm table-bordered",
                tags$thead(
                  tags$tr(
                    tags$th("ADF / PP (H0 = racine unitaire)"),
                    tags$th("KPSS (H0 = stationnaire)"),
                    tags$th("Lecture statistique"),
                    tags$th("Diagnostic Ã©conomÃ©trique"),
                    tags$th("Conclusion sur la sÃ©rie"),
                    tags$th("Action recommandÃ©e"),
                    tags$th("Commentaires pÃ©dagogiques / piÃ¨ges")
                  )
                ),
                tags$tbody(
                  
                  tags$tr(
                    tags$td("Rejet clair (p â‰ª 5 %)"),
                    tags$td("Non-rejet (p â‰« 5 %)"),
                    tags$td("Convergence forte des tests"),
                    tags$td("StationnaritÃ© confirmÃ©e"),
                    tags$td("SÃ©rie stationnaire"),
                    tags$td("Aucune diffÃ©renciation (d = 0)"),
                    tags$td("Cas idÃ©al. Ne pas diffÃ©rencier inutilement.")
                  ),
                  
                  tags$tr(
                    tags$td("Non-rejet (p â‰« 5 %)"),
                    tags$td("Rejet clair (p â‰ª 5 %)"),
                    tags$td("Convergence forte"),
                    tags$td("Racine unitaire non saisonniÃ¨re"),
                    tags$td("SÃ©rie non stationnaire"),
                    tags$td("Essayer d = 1"),
                    tags$td("Cas le plus frÃ©quent en pratique.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet"),
                    tags$td("Rejet"),
                    tags$td("RÃ©sultats contradictoires"),
                    tags$td("StationnaritÃ© autour dâ€™une tendance"),
                    tags$td("Stationnaire aprÃ¨s retrait de tendance"),
                    tags$td("d = 0 + tendance dÃ©terministe"),
                    tags$td("Souvent dÃ» Ã  une mauvaise spÃ©cification du test ADF.")
                  ),
                  
                  tags$tr(
                    tags$td("Non-rejet"),
                    tags$td("Non-rejet"),
                    tags$td("Manque de puissance"),
                    tags$td("Inconclusif"),
                    tags$td("DÃ©cision incertaine"),
                    tags$td("Sâ€™appuyer sur EDA + ACF"),
                    tags$td("Typique des petits Ã©chantillons ou sÃ©ries trÃ¨s bruitÃ©es.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet marginal (p â‰ˆ 5â€“10 %)"),
                    tags$td("Rejet marginal"),
                    tags$td("FrontiÃ¨re statistique"),
                    tags$td("StationnaritÃ© douteuse"),
                    tags$td("Zone grise"),
                    tags$td("Tester d = 1 puis comparer"),
                    tags$td("Ne jamais dÃ©cider sur une seule p-value.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet uniquement avec trend"),
                    tags$td("Rejet sans trend"),
                    tags$td("SensibilitÃ© Ã  la spÃ©cification"),
                    tags$td("Tendance dÃ©terministe probable"),
                    tags$td("Stationnaire autour dâ€™une tendance"),
                    tags$td("Inclure tendance, Ã©viter d"),
                    tags$td("Comparer systÃ©matiquement drift vs trend.")
                  ),
                  
                  tags$tr(
                    tags$td("Non-rejet sur sÃ©rie brute"),
                    tags$td("Rejet sur sÃ©rie brute"),
                    tags$td("Non-stationnaritÃ© dÃ©tectÃ©e"),
                    tags$td("Racine unitaire I(1)"),
                    tags$td("Non stationnaire"),
                    tags$td("DiffÃ©rencier (d = 1)"),
                    tags$td("DÃ©cision standard avant ARMA.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet aprÃ¨s d = 1"),
                    tags$td("Non-rejet aprÃ¨s d = 1"),
                    tags$td("Convergence aprÃ¨s transformation"),
                    tags$td("StationnaritÃ© atteinte"),
                    tags$td("SÃ©rie I(1) confirmÃ©e"),
                    tags$td("Conserver d = 1"),
                    tags$td("Ne pas essayer d = 2 par automatisme.")
                  ),
                  
                  tags$tr(
                    tags$td("Rejet trÃ¨s fort"),
                    tags$td("Rejet trÃ¨s fort"),
                    tags$td("Violation des hypothÃ¨ses"),
                    tags$td("Rupture structurelle probable"),
                    tags$td("StationnaritÃ© instable"),
                    tags$td("Tester Zivotâ€“Andrews"),
                    tags$td("Les tests standards supposent paramÃ¨tres constants.")
                  ),
                  
                  tags$tr(
                    tags$td("RÃ©sultats instables selon retard"),
                    tags$td("RÃ©sultats instables"),
                    tags$td("SensibilitÃ© aux choix techniques"),
                    tags$td("DÃ©cision fragile"),
                    tags$td("Incertitude mÃ©thodologique"),
                    tags$td("Documenter + convergence dâ€™indices"),
                    tags$td("La justification Ã©crite est essentielle ici.")
                  )
                  
                )
              )
            ),
            
            tags$details(
              class = "defs-details",
              tags$summary(tags$span("Comment conclure en combinant ADF / KPSS / PP â€” version pÃ©dagogique")),
              
              tags$p(
                "Ce tableau ne doit pas Ãªtre lu comme une rÃ¨gle mÃ©canique. ",
                "Il sert Ã  comprendre ",
                tags$b("la logique sous-jacente"),
                " Ã  la combinaison des tests de stationnaritÃ©, ",
                "et Ã  apprendre ",
                tags$b("comment raisonner"),
                " lorsque les rÃ©sultats sont ambigus."
              ),
              
              tags$table(
                class = "table table-sm table-bordered",
                tags$thead(
                  tags$tr(
                    tags$th("Ce que disent les tests"),
                    tags$th("Ce que cela signifie vraiment"),
                    tags$th("Comment raisonner"),
                    tags$th("DÃ©cision raisonnable"),
                    tags$th("Message pÃ©dagogique clÃ©")
                  )
                ),
                tags$tbody(
                  
                  tags$tr(
                    tags$td("ADF et PP rejettent clairement ; KPSS ne rejette pas"),
                    tags$td(
                      "Les tests qui ",
                      tags$b("cherchent une racine unitaire"),
                      " nâ€™en trouvent pas, et le test qui ",
                      tags$b("suppose la stationnaritÃ©"),
                      " est cohÃ©rent avec cette hypothÃ¨se."
                    ),
                    tags$td(
                      "Toutes les sources dâ€™information convergent. ",
                      "Il nâ€™y a aucun signal fort de non-stationnaritÃ©."
                    ),
                    tags$td("ConsidÃ©rer la sÃ©rie comme stationnaire (d = 0)"),
                    tags$td(
                      "Ne pas diffÃ©rencier une sÃ©rie dÃ©jÃ  stationnaire : ",
                      tags$b("la parcimonie est une vertu.")
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF et PP ne rejettent pas ; KPSS rejette clairement"),
                    tags$td(
                      "Les tests indiquent quâ€™un choc a ",
                      tags$b("un effet persistant"),
                      " et que la stationnaritÃ© est violÃ©e."
                    ),
                    tags$td(
                      "Il existe une forte probabilitÃ© de ",
                      tags$b("racine unitaire non saisonniÃ¨re"),
                      "."
                    ),
                    tags$td("DiffÃ©rencier une fois (d = 1)"),
                    tags$td(
                      "Câ€™est le ",
                      tags$b("cas standard"),
                      " des sÃ©ries Ã©conomiques et financiÃ¨res."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF/PP rejettent, mais KPSS rejette aussi"),
                    tags$td(
                      "Les tests ne sont pas en dÃ©saccord par hasard : ",
                      "ils ",
                      tags$b("ne testent pas la mÃªme chose"),
                      "."
                    ),
                    tags$td(
                      "Souvent, la sÃ©rie est stationnaire ",
                      tags$b("autour dâ€™une tendance dÃ©terministe"),
                      ", mal prise en compte."
                    ),
                    tags$td("Utiliser d = 0 avec une tendance dÃ©terministe"),
                    tags$td(
                      "DiffÃ©rencier ici serait une ",
                      tags$b("erreur conceptuelle"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF/PP ne rejettent pas ; KPSS ne rejette pas"),
                    tags$td(
                      "Les tests manquent de puissance ou la sÃ©rie est trÃ¨s bruitÃ©e."
                    ),
                    tags$td(
                      "Aucune conclusion statistique forte nâ€™est possible ",
                      "sur la seule base des tests."
                    ),
                    tags$td("Sâ€™appuyer sur EDA, ACF, contexte"),
                    tags$td(
                      "Les tests ne remplacent ",
                      tags$b("ni lâ€™analyse graphique"),
                      " ni le raisonnement."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("RÃ©sultats sensibles Ã  la spÃ©cification (constante / tendance)"),
                    tags$td(
                      "La dÃ©cision dÃ©pend du modÃ¨le utilisÃ© pour tester la stationnaritÃ©."
                    ),
                    tags$td(
                      "Comparer les rÃ©sultats avec et sans tendance, ",
                      "et vÃ©rifier la cohÃ©rence avec les graphiques."
                    ),
                    tags$td("Choisir la spÃ©cification la plus cohÃ©rente"),
                    tags$td(
                      "Une p-value nâ€™a de sens ",
                      tags$b("que dans un modÃ¨le bien spÃ©cifiÃ©"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("AprÃ¨s diffÃ©renciation : ADF/PP rejettent, KPSS ne rejette plus"),
                    tags$td(
                      "La diffÃ©renciation a supprimÃ© la racine unitaire."
                    ),
                    tags$td(
                      "La sÃ©rie diffÃ©renciÃ©e est maintenant stationnaire."
                    ),
                    tags$td("Conserver d = 1"),
                    tags$td(
                      "DiffÃ©rencier plus serait ",
                      tags$b("contre-productif"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("ADF/PP et KPSS rejettent trÃ¨s fortement"),
                    tags$td(
                      "Les hypothÃ¨ses des tests (paramÃ¨tres constants) sont probablement violÃ©es."
                    ),
                    tags$td(
                      "Suspecter une ",
                      tags$b("rupture structurelle"),
                      " ou un changement de rÃ©gime."
                    ),
                    tags$td("Tester une rupture (ex. Zivotâ€“Andrews)"),
                    tags$td(
                      "Les tests classiques ",
                      tags$b("ne voient pas les ruptures"),
                      "."
                    )
                  ),
                  
                  tags$tr(
                    tags$td("RÃ©sultats instables selon les retards choisis"),
                    tags$td(
                      "La dÃ©cision est fragile statistiquement."
                    ),
                    tags$td(
                      "Ne pas automatiser la dÃ©cision ; ",
                      "documenter le raisonnement."
                    ),
                    tags$td("DÃ©cision argumentÃ©e, pas automatique"),
                    tags$td(
                      "En pratique, ",
                      tags$b("on justifie plus quâ€™on ne tranche"),
                      "."
                    )
                  )
                  
                )
              ),
              
              tags$p(
                tags$b("Message final Ã  retenir : "),
                "ADF, KPSS et PP ne sont pas des oracles. ",
                "Ils fournissent des ",
                tags$b("indices complÃ©mentaires"),
                ". ",
                "La bonne dÃ©cision repose sur la ",
                tags$b("convergence des tests"),
                ", lâ€™EDA et le raisonnement Ã©conomique/statistique."
              )
            ),
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("ProcÃ©dure recommandÃ©e (pas Ã  pas)")),
          tags$ol(
            tags$li("Fixer ", tags$b("s"), " (pÃ©riode saisonniÃ¨re) Ã  partir du contexte et de lâ€™EDA."),
            tags$li("Tester ADF/KPSS/PP sur la sÃ©rie brute."),
            tags$li("Essayer d = 1 si nÃ©cessaire, retester."),
            tags$li("Essayer D = 1 si saisonnalitÃ© / racine saisonniÃ¨re, retester."),
            tags$li("Sâ€™arrÃªter dÃ¨s que stationnaritÃ© â€œraisonnableâ€ ; Ã©viter sur-diffÃ©renciation.")
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Sur-diffÃ©renciation : dÃ©finition + symptÃ´mes")),
          tags$ul(
            tags$li(
              tags$b("DÃ©finition"),
              " : appliquer trop de diffÃ©rences â†’ on introduit une dynamique artificielle."
            ),
            tags$li(
              tags$b("SymptÃ´mes frÃ©quents"),
              " : ACF au lag 1 trÃ¨s nÃ©gative, variance gonflÃ©e, prÃ©visions erratiques, paramÃ¨tres instables."
            ),
            tags$li(
              tags$b("ConsÃ©quence"),
              " : intervalles de prÃ©vision plus larges et modÃ¨le moins fiable."
            )
          )
        ),
        
        
        
        
        

        # === ADD: tests/bonnes pratiques complÃ©mentaires ===
        

        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Tests et notions complÃ©mentaires")),
          
          tags$ul(
            tags$li(
              tags$b("Tendance dÃ©terministe vs racine unitaire"),
              " : on peut prÃ©fÃ©rer un ARIMA avec ",
              tags$code("d = 0"),
              " et une tendance ",
              tags$b("dÃ©terministe"),
              " (rÃ©gression + ARMA sur rÃ©sidus) si la tendance semble stable."
            ),
            tags$li(
              tags$b("Racine unitaire saisonniÃ¨re (HEGY)"),
              " : (annexe) test dÃ©diÃ© aux racines Ã  ",
              tags$code("Â±1, Â±i"),
              " pour ",
              tags$code("s = 4, 12"),
              " ; utile si la saisonnalitÃ© stochastique domine.",
              
              tags$details(
                class = "defs-details",
                tags$summary(tags$span("Test HEGY â€” racines unitaires saisonniÃ¨res (dÃ©finition complÃ¨te)")),
                
                tags$ul(
                  
                  tags$li(
                    tags$b("DÃ©finition"),
                    " : le test HEGY (Hyllebergâ€“Engleâ€“Grangerâ€“Yoo) est un test de ",
                    tags$b("racines unitaires saisonniÃ¨res"),
                    " qui permet dâ€™identifier si une sÃ©rie prÃ©sente des racines unitaires ",
                    tags$b("non saisonniÃ¨res"),
                    " et/ou ",
                    tags$b("saisonniÃ¨res"),
                    " (ex. annuelle, semi-annuelle, trimestrielle)."
                  ),
                  
                  tags$li(
                    tags$b("But"),
                    " : dÃ©terminer si la non-stationnaritÃ© provient dâ€™une ",
                    tags$b("tendance stochastique"),
                    ", dâ€™une ",
                    tags$b("saisonnalitÃ© stochastique"),
                    ", ou des deux."
                  ),
                  
                  tags$li(
                    tags$b("Quand lâ€™utiliser"),
                    " : lorsque la sÃ©rie prÃ©sente une ",
                    tags$b("saisonnalitÃ© marquÃ©e"),
                    " et que lâ€™on suspecte une ",
                    tags$b("racine unitaire saisonniÃ¨re"),
                    " (ex. sÃ©ries mensuelles ou trimestrielles avec saisonnalitÃ© instable)."
                  ),
                  
                  tags$li(
                    tags$b("HypothÃ¨ses"),
                    " : ",
                    tags$b("H0"),
                    " = prÃ©sence dâ€™une ou plusieurs racines unitaires (aux frÃ©quences ",
                    tags$code("Â±1, Â±i"),
                    " selon ",
                    tags$code("s"),
                    ") ; ",
                    tags$b("Ha"),
                    " = absence de racine unitaire Ã  ces frÃ©quences."
                  ),
                  
                  tags$li(
                    tags$b("Statistique / idÃ©e"),
                    " : la sÃ©rie est rÃ©Ã©crite de faÃ§on Ã  isoler les composantes associÃ©es ",
                    "aux diffÃ©rentes frÃ©quences saisonniÃ¨res, puis des tests t et F sont ",
                    "appliquÃ©s sur les coefficients correspondants."
                  ),
                  
                  tags$li(
                    tags$b("RÃ¨gle de dÃ©cision"),
                    " : rejet de H0 pour une frÃ©quence donnÃ©e â†’ pas de racine unitaire ",
                    "Ã  cette frÃ©quence ; non-rejet â†’ racine unitaire prÃ©sente."
                  ),
                  
                  tags$li(
                    tags$b("InterprÃ©tation (sens)"),
                    " : si une racine unitaire saisonniÃ¨re est dÃ©tectÃ©e, une ",
                    tags$b("diffÃ©renciation saisonniÃ¨re"),
                    " (",
                    tags$code("D = 1"),
                    ") est gÃ©nÃ©ralement justifiÃ©e."
                  ),
                  
                  tags$li(
                    tags$b("Ce que Ã§a implique pour vos choix"),
                    " : HEGY aide Ã  dÃ©cider entre ",
                    tags$b("diffÃ©renciation ordinaire"),
                    " (",
                    tags$code("d"),
                    ") et ",
                    tags$b("diffÃ©renciation saisonniÃ¨re"),
                    " (",
                    tags$code("D"),
                    "), et Ã  Ã©viter des choix arbitraires."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter"),
                    " : prÃ©ciser la pÃ©riodicitÃ© ",
                    tags$code("s"),
                    ", les frÃ©quences testÃ©es, les statistiques de test et les conclusions ",
                    "pour chaque racine saisonniÃ¨re."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter en format APA"),
                    " : ",
                    tags$i("Â« Un test HEGY a Ã©tÃ© rÃ©alisÃ© afin dâ€™Ã©valuer la prÃ©sence de racines "),
                    tags$i("unitaires saisonniÃ¨res dans la sÃ©rie mensuelle. "),
                    tags$i("Les rÃ©sultats indiquent une racine unitaire saisonniÃ¨re annuelle "),
                    tags$i("(p < .05), justifiant lâ€™application dâ€™une diffÃ©renciation saisonniÃ¨re. Â»")
                  ),
                  
                  tags$li(
                    tags$b("Limites / piÃ¨ges"),
                    " : test complexe et moins connu ; ",
                    "puissance limitÃ©e sur petits Ã©chantillons ; ",
                    "sensible au choix des retards ; ",
                    "peu implÃ©mentÃ© dans les logiciels standards."
                  )
                )
              ),
              
            ),
            tags$li(
              tags$b("Zivotâ€“Andrews"),
              " : (annexe) test de racine unitaire avec rupture structurelle endogÃ¨ne possible.",
              
              tags$details(
                class = "defs-details",
                tags$summary(tags$span("Test de Zivotâ€“Andrews â€” racine unitaire avec rupture endogÃ¨ne (dÃ©finition complÃ¨te)")),
                
                tags$ul(
                  
                  tags$li(
                    tags$b("DÃ©finition"),
                    " : le test de Zivotâ€“Andrews est un test de ",
                    tags$b("racine unitaire"),
                    " qui autorise une ",
                    tags$b("rupture structurelle endogÃ¨ne"),
                    " (date inconnue) dans la sÃ©rie."
                  ),
                  
                  tags$li(
                    tags$b("But"),
                    " : distinguer une vÃ©ritable racine unitaire dâ€™une ",
                    tags$b("non-stationnaritÃ© apparente"),
                    " due Ã  une rupture de niveau ou de tendance."
                  ),
                  
                  tags$li(
                    tags$b("Quand lâ€™utiliser"),
                    " : lorsque la sÃ©rie montre un ",
                    tags$b("changement brutal"),
                    " (crise, rÃ©forme, choc externe) et que lâ€™ADF classique semble indiquer ",
                    "une racine unitaire."
                  ),
                  
                  tags$li(
                    tags$b("HypothÃ¨ses"),
                    " : ",
                    tags$b("H0"),
                    " = racine unitaire sans rupture ; ",
                    tags$b("Ha"),
                    " = stationnaritÃ© avec une rupture structurelle (niveau et/ou tendance)."
                  ),
                  
                  tags$li(
                    tags$b("Statistique / idÃ©e"),
                    " : le test estime successivement une ADF pour chaque date de rupture ",
                    "possible, puis retient la statistique la plus dÃ©favorable Ã  H0 ",
                    "(rupture endogÃ¨ne)."
                  ),
                  
                  tags$li(
                    tags$b("RÃ¨gle de dÃ©cision"),
                    " : si la statistique dÃ©passe la valeur critique â†’ rejet de H0 â†’ ",
                    "stationnaritÃ© avec rupture."
                  ),
                  
                  tags$li(
                    tags$b("InterprÃ©tation (sens)"),
                    " : rejet de H0 signifie que la sÃ©rie est ",
                    tags$b("stationnaire conditionnellement"),
                    " Ã  une rupture, et quâ€™une diffÃ©renciation nâ€™est pas forcÃ©ment nÃ©cessaire."
                  ),
                  
                  tags$li(
                    tags$b("Ce que Ã§a implique pour vos choix"),
                    " : possibilitÃ© de conserver ",
                    tags$code("d = 0"),
                    " et dâ€™introduire une ",
                    tags$b("variable muette de rupture"),
                    " plutÃ´t que de diffÃ©rencier."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter"),
                    " : indiquer le type de rupture (niveau / tendance), la date estimÃ©e ",
                    "et la conclusion sur la stationnaritÃ©."
                  ),
                  
                  tags$li(
                    tags$b("Comment le rapporter en format APA"),
                    " : ",
                    tags$i("Â« Un test de Zivotâ€“Andrews a mis en Ã©vidence une rupture "),
                    tags$i("structurelle endogÃ¨ne en 2008. Le test rejette lâ€™hypothÃ¨se "),
                    tags$i("de racine unitaire (p < .05), suggÃ©rant une stationnaritÃ© "),
                    tags$i("conditionnelle Ã  cette rupture. Â»")
                  ),
                  
                  tags$li(
                    tags$b("Limites / piÃ¨ges"),
                    " : autorise une seule rupture ; ",
                    "puissance limitÃ©e si plusieurs ruptures ; ",
                    "valeurs critiques spÃ©cifiques ; ",
                    "ne remplace pas lâ€™analyse Ã©conomique du contexte."
                  )
                )
              ),
              
              
            )
          )
        ),
        
        
        
        # H5("Bonnes pratiques de diffÃ©renciation"),
        # UL(
        #   tags$li(B("Au plus une diffÃ©rence"), " : commencer par ", C("d=1"), " ou ", C("D=1"),
        #           " ; ", B("Ã©viter"), " ", C("d=2"), " sauf preuves fortes."),
        #   tags$li(B("Sur-diffÃ©renciation : "), "ACF lag 1 trÃ¨s nÃ©gative, variance gonflÃ©e, MA artificiel â†’ revenir en arriÃ¨re.")
        # )
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Bonnes pratiques de diffÃ©renciation")),
          
          tags$ul(
            tags$li(
              tags$b("Au plus une diffÃ©rence"),
              " : commencer par ",
              tags$code("d = 1"),
              " ou ",
              tags$code("D = 1"),
              " ; ",
              tags$b("Ã©viter"),
              " ",
              tags$code("d = 2"),
              " sauf preuves fortes."
            ),
            tags$li(
              tags$b("Sur-diffÃ©renciation"),
              " : ACF au lag 1 trÃ¨s nÃ©gative, variance gonflÃ©e, MA artificiel â†’ revenir en arriÃ¨re."
            )
          )
        ),
        
      ),
      
      apa_ui = tagList(
        H5("MÃ©thodes (APA) â€” Tests & choix de (d, D)"),
        P("Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide des tests ADF, KPSS et PP afin de trianguler lâ€™Ã©vidence, ces tests ayant des hypothÃ¨ses nulles diffÃ©rentes. ",
          "Les rÃ©sultats ont Ã©tÃ© examinÃ©s sur la sÃ©rie originale puis aprÃ¨s diffÃ©renciations ordinaires et saisonniÃ¨res. ",
          "Sur la base de lâ€™ensemble des indices (tests + diagnostics visuels), nous avons retenu d=[..] et D=[..] avec s=[..], ",
          "afin dâ€™obtenir une sÃ©rie approximativement stationnaire adaptÃ©e Ã  lâ€™estimation SARIMA, tout en Ã©vitant la sur-diffÃ©renciation. Â»"),
        
        H5("Conclusion test (prÃªte Ã  remplir) + signification"),
        UL(
          tags$li(B("ADF : "), "p=[..] â†’ ", B("[rejeter / ne pas rejeter]"),
                  " H0 (racine unitaire). ",
                  B("Signification : "),
                  "si rejet â†’ la sÃ©rie est compatible stationnaritÃ© (au sens ADF) ; sinon â†’ diffÃ©renciation probablement nÃ©cessaire."),
          tags$li(B("KPSS : "), "p=[..] â†’ ", B("[rejeter / ne pas rejeter]"),
                  " H0 (stationnaritÃ©). ",
                  B("Signification : "),
                  "si rejet â†’ non-stationnaritÃ© (donc d/D Ã  augmenter ou transformation/rupture Ã  traiter)."),
          tags$li(B("PP : "), "p=[..] â†’ ", B("[rejeter / ne pas rejeter]"),
                  " H0 (racine unitaire). ",
                  B("Signification : "),
                  "confirme ou nuance ADF ; convergence ADF+PP renforce la conclusion.")
        ),
        
        H5("Conclusion finale (d, D) + ce que cela implique pour SARIMA"),
        UL(
          tags$li(B("Conclusion : "), "Â« Nous retenons d=[..], D=[..], s=[..]. Â»"),
          tags$li(B("Signification : "),
                  "Â« le SARIMA sera estimÃ© sur la sÃ©rie diffÃ©renciÃ©e ; les paramÃ¨tres AR/MA dÃ©crivent la dynamique ",
                  "restante aprÃ¨s retrait de la tendance et/ou de la saisonnalitÃ© non stationnaire. Â»")
        ),
        
        # === ADD: points Ã  expliciter
        H5("Ã€ expliciter (rappel)"),
        UL(
          tags$li("PrÃ©ciser si une constante/drift est incluse et Ã  quel niveau (avant/aprÃ¨s diffÃ©renciation)."),
          tags$li("Documenter toute rupture suspectÃ©e et ses consÃ©quences sur le choix de ", C("d, D"), ".")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Choisir d et D â€œpar habitudeâ€"), " : toujours justifier par tests + EDA."),
          tags$li(B("Ignorer une rupture structurelle"), " : les tests peuvent â€œcrier non-stationnaireâ€ alors quâ€™un changement de rÃ©gime est en cause."),
          tags$li(B("InterprÃ©ter p-value comme preuve absolue"), " : ce sont des indices ; en conflit, on sâ€™appuie sur convergence des preuves.")
        )
      )
    )
    
    # (6) Ã‰tape 5 â€” Auto-ARIMA baseline
    pages[[7]] <- make_step(
      step_names[7],
      
      actions_ui = tagList(
        callout(B("But : "), "obtenir un point de dÃ©part compÃ©titif, puis vÃ©rifier/affiner.", type="info"),
        
        Checklist(
          CheckItem("Executer auto-ARIMA avec des bornes raisonnables sur p,q,P,Q et noter le critere (AICc) utilise."),
          CheckItem("Enregistrer le modele baseline (ordres + presence drift/constante) pour comparaison ulterieure."),
          CheckItem("Verifier diagnostics residuels (ACF residus, Ljung-Box) avant de le considerer â€˜acceptableâ€™."),
          CheckItem("Evaluer la performance sur la fenetre test (MAE/RMSE) et comparer au benchmark naif/SNAIVE."),
          CheckItem("Decider si vous cherchez une version plus parcimonieuse (BIC plus faible ou meme performance avec moins de parametres).")
        ),
        
        Deliverables(
          tags$li("Le modÃ¨le auto.arima retenu (ordres, paramÃ¨tres) + critÃ¨res (AICc/BIC) + limites (point de dÃ©part, pas une vÃ©ritÃ©)."),
          tags$li("Comparaison contre le benchmark (au minimum) sur la pÃ©riode test, avec tableau de mÃ©triques et commentaire."),
          tags$li("Diagnostics rÃ©siduels essentiels : ACF des rÃ©sidus + Ljungâ€“Box + commentaire (bruit blanc ou non).")
        ),
        
        
        H5("DÃ©finition : auto-ARIMA (ce que fait rÃ©ellement lâ€™algorithme)"),
        UL(
          tags$li("Explore un ensemble de modÃ¨les candidats (p,q,P,Q) sous contraintes."),
          tags$li("Choisit souvent via minimisation ", B("AICc"),
                  " (AIC corrigÃ© petits Ã©chantillons)."),
          tags$li("Peut utiliser recherche stepwise (rapide) ou plus exhaustive (plus coÃ»teuse).")
        ),
        
        H5("Pourquoi AICc ? (objectif)"),
        UL(
          tags$li("Compromis entre qualitÃ© dâ€™ajustement et complexitÃ© (pÃ©nalise les paramÃ¨tres)."),
          tags$li("AICc est prÃ©fÃ©rable Ã  AIC quand n nâ€™est pas trÃ¨s grand par rapport au nombre de paramÃ¨tres.")
        ),
        
        H5("ProcÃ©dure propre"),
        OL(
          tags$li("Fixer d/D (ou laisser recommander via ndiffs/nsdiffs, mais valider)."),
          tags$li("Fixer bornes max p/q/P/Q ; documenter."),
          tags$li("Sauvegarder le modÃ¨le baseline (pour comparaison)."),
          tags$li("VÃ©rifier diagnostics rÃ©siduels + performance sur test.")
        ),
        
        # === ADD: dÃ©tails de recherche & critÃ¨res multiples ===
        H5("DÃ©tails de recherche"),
        UL(
          tags$li(B("Stepwise vs exhaustive"), " : stepwise = rapide, peut rater un optimum global ; exhaustive = coÃ»teux mais plus fiable."),
          tags$li(B("Contraintes"), " : imposer ", C("p,q,P,Q \u2264"), " bornes raisonnables ; forcer stabilitÃ©/inversibilitÃ©."),
          tags$li(B("drift/constante"), " : tester versions avec et sans drift lorsque ", C("d=1"), ".")
        ),
        H5("CritÃ¨res multiples"),
        UL(
          tags$li("Comparer AICc ", B("et"), " BIC ; en cas de quasi-Ã©galitÃ© â†’ choisir le plus parcimonieux.")
        )
      ),
      
      apa_ui = tagList(
        H5("MÃ©thodes (APA) â€” baseline"),
        P("Â« Un modÃ¨le SARIMA de rÃ©fÃ©rence a Ã©tÃ© sÃ©lectionnÃ© via une procÃ©dure auto-ARIMA basÃ©e sur un critÃ¨re dâ€™information (minimisation de lâ€™AICc) parmi des ordres candidats sous contraintes [..]. ",
          "La spÃ©cification obtenue a Ã©tÃ© utilisÃ©e comme baseline, puis comparÃ©e Ã  des modÃ¨les manuels plus parcimonieux sur la base des diagnostics et de la performance de prÃ©vision. Â»"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "Â« Auto-ARIMA fournit une baseline solide Â»"),
          tags$li(B("Signification : "), "Â« on a un repÃ¨re : tout modÃ¨le final doit faire au moins aussi bien. Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("ModÃ¨le â€œtrop complexeâ€"), " : stepwise peut sÃ©lectionner des ordres Ã©levÃ©s â†’ instabilitÃ©, interprÃ©tation difficile."),
          tags$li(B("AICc excellent mais rÃ©sidus mauvais"), " : diagnostics priment."),
          tags$li(B("Oublier la parcimonie"), " : si deux modÃ¨les prÃ©disent pareil, garder le plus simple.")
        )
      )
    )
    
    # (7) Ã‰tape 6 â€” SARIMA manuel
    pages[[8]] <- make_step(
      step_names[8],
      
      actions_ui = tagList(
        callout(B("But : "), "proposer un petit ensemble raisonnÃ© de candidats via ACF/PACF.", type="info"),
        
        Checklist(
          CheckItem("Tracer ACF/PACF de la serie differenciee (apres choix d et D) et identifier les pics significatifs."),
          CheckItem("Proposer un petit ensemble de candidats (3 a 8) en justifiant p,q,P,Q par les motifs ACF/PACF (y compris aux multiples de s)."),
          CheckItem("Ajuster chaque candidat, relever AICc/BIC, et verifier stabilite/inversibilite si possible."),
          CheckItem("Comparer sur diagnostics residuels ET performance predictive (pas seulement AICc)."),
          CheckItem("Garder le modele le plus simple qui passe diagnostics et bat le benchmark.")
        ),
        
        Deliverables(
          tags$li("Une liste courte de candidats SARIMA manuels (2â€“6 modÃ¨les) + rationale ACF/PACF + parcimonie."),
          tags$li("Un tableau comparatif (AICc/BIC + diagnostics + performance test) pour choisir un modÃ¨le final."),
          tags$li("Lâ€™Ã©quation du modÃ¨le final en trois versions : gÃ©nÃ©rale â†’ estimÃ©e â†’ estimÃ©e avec valeurs numÃ©riques.")
        ),
        
        
        H5("DÃ©finitions : ACF / PACF (ce que mesurent ces courbes)"),
        UL(
          tags$li(B("ACF"), " : corrÃ©lation entre ", C("y_t"), " et ", C("y_{t-k}"),
                  " â†’ suggÃ¨re MA(q) si coupure nette vers q."),
          tags$li(B("PACF"), " : corrÃ©lation â€œpureâ€ au retard k une fois les retards <k contrÃ´lÃ©s ",
                  "â†’ suggÃ¨re AR(p) si coupure nette vers p.")
        ),
        
        H5("Heuristiques (non saisonnier)"),
        UL(
          tags$li(B("AR(p)"), " : PACF se coupe ~p ; ACF dÃ©croÃ®t."),
          tags$li(B("MA(q)"), " : ACF se coupe ~q ; PACF dÃ©croÃ®t."),
          tags$li(B("ARMA"), " : ACF et PACF dÃ©croissent (pas de coupure franche).")
        ),
        
        H5("Heuristiques saisonniÃ¨res (multiples de s)"),
        UL(
          tags$li(B("SAR(P)"), " : pics PACF Ã  s, 2s, ..."),
          tags$li(B("SMA(Q)"), " : pics ACF Ã  s, 2s, ...")
        ),
        
        H5("ProcÃ©dure recommandÃ©e (petit nombre de modÃ¨les)"),
        OL(
          tags$li("Construire 3 Ã  8 candidats (parcimonieux)."),
          tags$li("Ajuster et comparer AICc/BIC."),
          tags$li("VÃ©rifier stabilitÃ©/inversibilitÃ©."),
          tags$li("Retenir ceux qui passent diagnostics + prÃ©vision.")
        ),
        
        # === ADD: conception de candidats & lecture fine ===
        H5("Conception de candidats (rappels utiles)"),
        UL(
          tags$li(B("Limiter le set"), " : 3â€“8 modÃ¨les max, justifiÃ©s par ACF/PACF."),
          tags$li(B("StabilitÃ©/inversibilitÃ©"), " : vÃ©rifier racines des polynÃ´mes AR/MA (hors cercle unitÃ©)."),
          tags$li(B("drift/constante"), " : inclure/exclure et comparer au niveau AICc/BIC + diagnostics.")
        ),
        H5("Lecture fine ACF/PACF"),
        UL(
          tags$li("Pics Ã  ", C("s, 2s, 3s"), " dans lâ€™ACF â†’ penser ", B("SMA(Q)"), "."),
          tags$li("Pics Ã  ", C("s, 2s"), " dans la PACF â†’ penser ", B("SAR(P)"), "."),
          tags$li("Queue AR (dÃ©croissance gÃ©omÃ©trique) vs coupure MA (aprÃ¨s q).")
        ),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Ã‰tapes dÃ©taillÃ©es de choix de s, d, D, p, q, P, Q (mÃ©thode complÃ¨te SARIMA)")),
          
          tags$ol(
            
            tags$li(
              tags$b("Identifier la pÃ©riode saisonniÃ¨re s (fondation du modÃ¨le)"),
              " : ",
              tags$b("avant toute modÃ©lisation"),
              ", dÃ©terminer la pÃ©riodicitÃ© naturelle de la sÃ©rie Ã  partir du contexte ",
              "(mensuel â†’ s = 12, hebdomadaire â†’ s = 7, trimestriel â†’ s = 4, horaire â†’ s = 24, etc.). ",
              "Confirmer empiriquement avec lâ€™EDA : rÃ©pÃ©titions visuelles, ",
              "pics rÃ©guliers dans lâ€™ACF aux lags ",
              tags$code("s, 2s, 3s"),
              ". Une mauvaise valeur de ",
              tags$code("s"),
              " invalide tout le modÃ¨le SARIMA."
            ),
            
            tags$li(
              tags$b("Stabiliser la variance si nÃ©cessaire (prÃ©-traitement)"),
              " : examiner la relation niveauâ€“variance. ",
              "Si la variance augmente avec le niveau, appliquer une ",
              tags$b("transformation"),
              " (log ou Boxâ€“Cox) ",
              tags$b("avant"),
              " la diffÃ©renciation. ",
              "Objectif : rendre la dynamique plus additive et les rÃ©sidus plus homogÃ¨nes."
            ),
            
            tags$li(
              tags$b("Tester et choisir D : diffÃ©renciation saisonniÃ¨re"),
              " : le paramÃ¨tre ",
              tags$code("D"),
              " sert Ã  Ã©liminer une ",
              tags$b("racine unitaire saisonniÃ¨re"),
              ". Indices typiques : ",
              "ACF trÃ¨s Ã©levÃ©e aux multiples de ",
              tags$code("s"),
              ", saisonnalitÃ© qui dÃ©rive dans le temps. ",
              "En pratique, essayer ",
              tags$code("D = 1"),
              " (",
              tags$b("rarement 2"),
              "), puis retester la stationnaritÃ©. ",
              "Une diffÃ©renciation saisonniÃ¨re inutile complique inutilement le modÃ¨le."
            ),
            
            tags$li(
              tags$b("Tester et choisir d : diffÃ©renciation ordinaire"),
              " : le paramÃ¨tre ",
              tags$code("d"),
              " Ã©limine la ",
              tags$b("tendance stochastique"),
              " (racine unitaire non saisonniÃ¨re). ",
              "Sâ€™appuyer sur ADF / PP (H0 = racine unitaire) et KPSS (H0 = stationnaire). ",
              "En pratique, essayer ",
              tags$code("d = 1"),
              " si nÃ©cessaire, puis ",
              tags$b("sâ€™arrÃªter dÃ¨s que la stationnaritÃ© est raisonnable"),
              ". ",
              tags$b("Ã‰viter d = 2"),
              " sauf justification solide."
            ),
            
            tags$li(
              tags$b("ContrÃ´ler la sur-diffÃ©renciation"),
              " : une sur-diffÃ©renciation se manifeste par une ",
              tags$b("ACF trÃ¨s nÃ©gative au lag 1"),
              ", une variance gonflÃ©e et des prÃ©visions instables. ",
              "Si observÃ©, ",
              tags$b("revenir en arriÃ¨re"),
              " et rÃ©duire ",
              tags$code("d"),
              " ou ",
              tags$code("D"),
              "."
            ),
            
            tags$li(
              tags$b("Tracer ACF et PACF sur la sÃ©rie diffÃ©renciÃ©e"),
              " : lâ€™identification de ",
              tags$code("p, q, P, Q"),
              " se fait ",
              tags$b("uniquement aprÃ¨s"),
              " le choix dÃ©finitif de ",
              tags$code("d"),
              " et ",
              tags$code("D"),
              ". ",
              "Examiner sÃ©parÃ©ment les ",
              tags$b("lags courts"),
              " (non saisonniers) et les ",
              tags$b("multiples de s"),
              " (saisonniers)."
            ),
            
            tags$li(
              tags$b("Choisir p et q (partie non saisonniÃ¨re)"),
              " : utiliser les heuristiques classiques : ",
              tags$b("AR(p)"),
              " â†’ coupure nette de la PACF ; ",
              tags$b("MA(q)"),
              " â†’ coupure nette de lâ€™ACF ; ",
              "ARMA â†’ dÃ©croissance progressive des deux. ",
              "Limiter gÃ©nÃ©ralement ",
              tags$code("p, q â‰¤ 2"),
              "."
            ),
            
            tags$li(
              tags$b("Choisir P et Q (partie saisonniÃ¨re)"),
              " : analyser les pics aux lags ",
              tags$code("s, 2s, â€¦"),
              ". ",
              "Pics dans la ",
              tags$b("PACF"),
              " â†’ ",
              tags$code("P"),
              " ; pics dans lâ€™",
              tags$b("ACF"),
              " â†’ ",
              tags$code("Q"),
              ". ",
              "En pratique, ",
              tags$code("P, Q âˆˆ {0,1}"),
              " suffisent dans la majoritÃ© des cas."
            ),
            
            tags$li(
              tags$b("Construire un ensemble restreint de modÃ¨les candidats"),
              " : proposer ",
              tags$b("3 Ã  8 modÃ¨les"),
              " plausibles, en faisant varier un paramÃ¨tre Ã  la fois. ",
              "Chaque candidat doit Ãªtre ",
              tags$b("explicitement justifiÃ©"),
              " par les motifs observÃ©s dans lâ€™ACF/PACF."
            ),
            
            tags$li(
              tags$b("Ajuster les modÃ¨les et filtrer par faisabilitÃ©"),
              " : pour chaque candidat, relever ",
              tags$b("AICc/BIC"),
              ", vÃ©rifier la convergence, et si possible la ",
              tags$b("stationnaritÃ© et lâ€™inversibilitÃ©"),
              ". ",
              "Un modÃ¨le numÃ©riquement instable doit Ãªtre Ã©cartÃ©."
            ),
            
            tags$li(
              tags$b("Filtrer par diagnostics rÃ©siduels (critÃ¨re bloquant)"),
              " : conserver uniquement les modÃ¨les dont les rÃ©sidus sont ",
              tags$b("compatibles avec un bruit blanc"),
              " : ACF des rÃ©sidus â‰ˆ 0 et test de Ljungâ€“Box non significatif. ",
              "Un bon AIC ne compense jamais des rÃ©sidus autocorrÃ©lÃ©s."
            ),
            
            tags$li(
              tags$b("Comparer la performance prÃ©visionnelle"),
              " : Ã©valuer les modÃ¨les restants ",
              tags$b("hors-Ã©chantillon"),
              " (split temporel ou rolling-origin) avec MAE/RMSE/MASE, ",
              "et comparer systÃ©matiquement Ã  un ",
              tags$b("benchmark"),
              " (naÃ¯f, drift ou SNAIVE)."
            ),
            
            tags$li(
              tags$b("Choisir le modÃ¨le final (principe de parcimonie)"),
              " : retenir le modÃ¨le ",
              tags$b("le plus simple"),
              " qui passe les diagnostics, ",
              tags$b("bat le benchmark"),
              " et prÃ©sente une performance stable. ",
              "La justification doit reposer sur ",
              tags$b("la convergence des indices"),
              ", pas sur un seul critÃ¨re."
            )
          )
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Choix de s, d, D, p, q, P, Q â€” synthÃ¨se mÃ©thodologique (tableaux)")),
          
          ## ===== TABLE 1 : s =====
          tags$h5("1) Choisir la pÃ©riode saisonniÃ¨re s"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Ã‰lÃ©ment"),
                tags$th("Ce quâ€™on regarde"),
                tags$th("DÃ©cision")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("Contexte"),
                tags$td("FrÃ©quence naturelle des donnÃ©es (mensuel, hebdo, etc.)"),
                tags$td("Fixer s (ex. mensuel â†’ s = 12)")
              ),
              tags$tr(
                tags$td("EDA / ACF"),
                tags$td("Motifs rÃ©pÃ©titifs, pics ACF Ã  s, 2s, 3s"),
                tags$td("Confirmer ou ajuster s")
              )
            )
          ),
          
          ## ===== TABLE 2 : transformation =====
          tags$h5("2) Stabilisation de la variance (optionnel)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Indice"),
                tags$th("Diagnostic"),
                tags$th("Action")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("Variance â†‘ avec niveau"),
                tags$td("Nuage niveauâ€“variance, rÃ©sidus hÃ©tÃ©rogÃ¨nes"),
                tags$td("Log ou Boxâ€“Cox (avant diffÃ©renciation)")
              ),
              tags$tr(
                tags$td("Variance stable"),
                tags$td("Dispersion homogÃ¨ne"),
                tags$td("Pas de transformation")
              )
            )
          ),
          
          ## ===== TABLE 3 : D =====
          tags$h5("3) Choisir D (diffÃ©renciation saisonniÃ¨re)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Indice"),
                tags$th("Ce que Ã§a signifie"),
                tags$th("DÃ©cision")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("ACF forte Ã  s, 2s"),
                tags$td("Racine unitaire saisonniÃ¨re"),
                tags$td("Essayer D = 1")
              ),
              tags$tr(
                tags$td("SaisonnalitÃ© stable"),
                tags$td("Motif dÃ©terministe"),
                tags$td("D = 0")
              ),
              tags$tr(
                tags$td("D = 2"),
                tags$td("TrÃ¨s rare"),
                tags$td("Ã€ Ã©viter sauf preuve forte")
              )
            )
          ),
          
          ## ===== TABLE 4 : d =====
          tags$h5("4) Choisir d (diffÃ©renciation ordinaire)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Tests / indices"),
                tags$th("Conclusion"),
                tags$th("Action")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("ADF/PP non significatifs + KPSS significatif"),
                tags$td("Racine unitaire non saisonniÃ¨re"),
                tags$td("Essayer d = 1")
              ),
              tags$tr(
                tags$td("ADF/PP significatifs + KPSS non significatif"),
                tags$td("StationnaritÃ© raisonnable"),
                tags$td("d = 0")
              ),
              tags$tr(
                tags$td("ACF lag 1 trÃ¨s nÃ©gative"),
                tags$td("Sur-diffÃ©renciation"),
                tags$td("RÃ©duire d")
              )
            )
          ),
          
          ## ===== TABLE 5 : p / q =====
          tags$h5("5) Choisir p et q (partie non saisonniÃ¨re)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Motif ACF / PACF"),
                tags$th("InterprÃ©tation"),
                tags$th("Choix suggÃ©rÃ©")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("PACF coupÃ©e, ACF dÃ©croissante"),
                tags$td("AR(p)"),
                tags$td("p = ordre de coupure")
              ),
              tags$tr(
                tags$td("ACF coupÃ©e, PACF dÃ©croissante"),
                tags$td("MA(q)"),
                tags$td("q = ordre de coupure")
              ),
              tags$tr(
                tags$td("ACF et PACF dÃ©croissantes"),
                tags$td("ARMA"),
                tags$td("p, q petits (â‰¤ 2)")
              )
            )
          ),
          
          ## ===== TABLE 6 : P / Q =====
          tags$h5("6) Choisir P et Q (partie saisonniÃ¨re)"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("Motif aux lags s, 2s"),
                tags$th("InterprÃ©tation"),
                tags$th("Choix suggÃ©rÃ©")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("Pics PACF Ã  s"),
                tags$td("SAR(P)"),
                tags$td("P = 1 (souvent suffisant)")
              ),
              tags$tr(
                tags$td("Pics ACF Ã  s"),
                tags$td("SMA(Q)"),
                tags$td("Q = 1 (souvent suffisant)")
              )
            )
          ),
          
          ## ===== TABLE 7 : sÃ©lection finale =====
          tags$h5("7) SÃ©lection finale des modÃ¨les"),
          tags$table(
            class = "table table-sm table-bordered",
            tags$thead(
              tags$tr(
                tags$th("CritÃ¨re"),
                tags$th("RÃ´le"),
                tags$th("RÃ¨gle")
              )
            ),
            tags$tbody(
              tags$tr(
                tags$td("AICc / BIC"),
                tags$td("Filtrage initial"),
                tags$td("Comparer modÃ¨les plausibles uniquement")
              ),
              tags$tr(
                tags$td("Diagnostics rÃ©siduels"),
                tags$td("CritÃ¨re bloquant"),
                tags$td("RÃ©sidus ~ bruit blanc")
              ),
              tags$tr(
                tags$td("Performance prÃ©visionnelle"),
                tags$td("DÃ©cision finale"),
                tags$td("Battre le benchmark")
              ),
              tags$tr(
                tags$td("Parcimonie"),
                tags$td("Choix final"),
                tags$td("Le plus simple Ã  perf comparable")
              )
            )
          )
        ),
        

        
        # tags$details(
        #   class = "defs-details",
        #   tags$summary(tags$span("Arbre dÃ©cisionnel â€” choix de p,d,q,P,D,Q (SARIMA)")),
        #   tags$div(
        #     style = "padding:10px 12px; background:#fff; overflow-x:auto;",
        #     DiagrammeR::grVizOutput("pdqpDQ_tree", height = "2000px")
        #   )
        # ),
        
        
      ),
      
      apa_ui = tagList(
        H5("MÃ©thodes (APA) â€” sÃ©lection manuelle"),
        P("Â« Les structures candidates ont Ã©tÃ© proposÃ©es sur la base des schÃ©mas ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. ",
          "Des autocorrÃ©lations aux multiples de s indiquaient des termes saisonniers, tandis que la dynamique de court terme guidait les ordres non saisonniers. ",
          "Un ensemble restreint de modÃ¨les (n=[..]) a Ã©tÃ© ajustÃ© et comparÃ© via AICc/BIC et diagnostics rÃ©siduels, en privilÃ©giant la parcimonie. Â»"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "Â« Le modÃ¨le final est soutenu par la structure ACF/PACF et les diagnostics. Â»"),
          tags$li(B("Signification : "), "Â« on rÃ©duit le risque de sur-ajustement en limitant les candidats. Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Brute-force massif"), " : tester 200 modÃ¨les puis choisir le plus petit AICc = data snooping."),
          tags$li(B("SurinterprÃ©ter ACF/PACF"), " : ce sont des guides, pas des preuves."),
          tags$li(B("Ignorer lâ€™inversibilitÃ©/stabilitÃ©"), " : paramÃ¨tres instables â†’ prÃ©visions incohÃ©rentes.")
        )
      )
    )
    
    # (8) Ã‰tape 7 â€” Diagnostics & comparaison
    pages[[9]] <- make_step(
      step_names[9],
      
      actions_ui = tagList(
        callout(B("But : "), "valider que le modÃ¨le explique toute la dÃ©pendance et prÃ©dit bien.", type="ok"),
        
        Checklist(
          CheckItem("Examiner les residus: courbe temporelle, ACF residus, et Ljung-Box a plusieurs lags L."),
          CheckItem("Verifier quâ€™il nâ€™y a pas de structure residuelle (p-value Ljung-Box non significative) et ajuster si necessaire."),
          CheckItem("Evaluer la prediction hors-echantillon (MAE/RMSE/MASE) avec le meme horizon et le meme protocole pour tous les modeles."),
          CheckItem("Comparer explicitement au benchmark (naif/SNAIVE) et conclure sur la valeur ajoutee."),
          CheckItem("Documenter toute violation (ARCH, rupture, non-normalite) et expliquer lâ€™impact sur IC et interpretation.")
        ),
        
        Deliverables(
          tags$li("Un rapport de diagnostics : rÃ©sidus (plots), tests (Ljungâ€“Box, normalitÃ©), et dÃ©cision finale (OK / Ã  revoir)."),
          tags$li("Une Ã©valuation prÃ©visionnelle : erreurs sur test + inspection visuelle des prÃ©visions (niveau, saisonnalitÃ©, turning points)."),
          tags$li("Une conclusion de sÃ©lection : pourquoi ce modÃ¨le est retenu et quels compromis il implique (simplicitÃ© vs performance).")
        ),
        
        
        # H5("Diagnostics rÃ©siduels : dÃ©finitions & buts"),
        
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Diagnostics rÃ©siduels : dÃ©finitions & buts")),
          
          tags$ul(
            
            tags$li(
              tags$b("DÃ©finition"),
              " : les diagnostics rÃ©siduels consistent Ã  analyser les ",
              tags$b("rÃ©sidus du modÃ¨le"),
              " (observÃ© âˆ’ ajustÃ©) afin de vÃ©rifier que le modÃ¨le a correctement ",
              tags$b("capturÃ© toute la structure"),
              " de la sÃ©rie."
            ),
            
            tags$li(
              tags$b("IdÃ©e centrale"),
              " : un bon modÃ¨le de sÃ©rie temporelle laisse des rÃ©sidus qui se comportent ",
              "comme un ",
              tags$b("bruit blanc"),
              " : imprÃ©visibles, non autocorrÃ©lÃ©s, centrÃ©s et de variance stable."
            ),
            
            tags$li(
              tags$b("But principal"),
              " : vÃ©rifier que le modÃ¨le est ",
              tags$b("adÃ©quat"),
              " pour la prÃ©vision et lâ€™infÃ©rence, et quâ€™il nâ€™existe ",
              tags$b("aucune structure systÃ©matique non expliquÃ©e"),
              " dans les rÃ©sidus."
            ),
            
            tags$li(
              tags$b("Ce quâ€™on vÃ©rifie â€” indÃ©pendance"),
              " : absence dâ€™autocorrÃ©lation rÃ©siduelle (ACF des rÃ©sidus â‰ˆ 0), ",
              "confirmÃ©e par des tests globaux comme ",
              tags$b("Ljungâ€“Box"),
              "."
            ),
            
            tags$li(
              tags$b("Ce quâ€™on vÃ©rifie â€” centrage"),
              " : moyenne des rÃ©sidus proche de 0, indiquant lâ€™absence de biais systÃ©matique."
            ),
            
            tags$li(
              tags$b("Ce quâ€™on vÃ©rifie â€” variance"),
              " : variance approximativement constante dans le temps ",
              "(pas dâ€™hÃ©tÃ©roscÃ©dasticitÃ© marquÃ©e)."
            ),
            
            tags$li(
              tags$b("Ce quâ€™on vÃ©rifie â€” distribution"),
              " : distribution des rÃ©sidus approximativement normale ",
              "(utile surtout pour les intervalles de confiance et les tests)."
            ),
            
            tags$li(
              tags$b("Pourquoi câ€™est indispensable"),
              " : un modÃ¨le peut avoir un bon ",
              tags$b("AIC/BIC"),
              " ou une bonne performance apparente, ",
              tags$b("tout en Ã©tant mal spÃ©cifiÃ©"),
              " si les rÃ©sidus montrent encore de la dÃ©pendance."
            ),
            
            tags$li(
              tags$b("Lien avec la prÃ©vision"),
              " : si les rÃ©sidus ne sont pas du bruit blanc, ",
              tags$b("il reste de lâ€™information prÃ©dictible"),
              " â†’ les prÃ©visions sont sous-optimales."
            ),
            
            tags$li(
              tags$b("Lien avec la validation"),
              " : les diagnostics rÃ©siduels constituent un ",
              tags$b("critÃ¨re de validation interne"),
              " complÃ©mentaire Ã  la performance hors-Ã©chantillon."
            ),
            
            tags$li(
              tags$b("Conclusion attendue"),
              " : un modÃ¨le nâ€™est jugÃ© ",
              tags$b("acceptable"),
              " que si ses rÃ©sidus sont compatibles avec un bruit blanc ",
              "et que les Ã©ventuelles violations sont faibles et discutÃ©es."
            )
          )
        ),
        
        UL(
          tags$li(B("RÃ©sidus"), " : ", C("e_t = y_t - Å·_t"),
                  " (ou rÃ©sidus dâ€™innovation selon lâ€™implÃ©mentation)."),
          tags$li(B("Bruit blanc"), " : absence dâ€™autocorrÃ©lation rÃ©siduelle â†’ le modÃ¨le a capturÃ© la structure temporelle."),
          tags$li(B("Ljungâ€“Box"), " : test global dâ€™autocorrÃ©lation des rÃ©sidus jusquâ€™Ã  un lag L.")
        ),
        
        
        
        
        # H5("Test de Ljungâ€“Box (dÃ©finition + interprÃ©tation)"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Test de Ljungâ€“Box â€” dÃ©finition & interprÃ©tation")),
          
          tags$ul(
            
            tags$li(
              tags$b("DÃ©finition"),
              " : le test de Ljungâ€“Box est un test global dâ€™",
              tags$b("autocorrÃ©lation"),
              " qui permet de vÃ©rifier si une sÃ©rie (en pratique : les ",
              tags$b("rÃ©sidus dâ€™un modÃ¨le"),
              ") est compatible avec un ",
              tags$b("bruit blanc"),
              "."
            ),
            
            tags$li(
              tags$b("But"),
              " : tester simultanÃ©ment lâ€™absence dâ€™autocorrÃ©lation ",
              "aux ",
              tags$b("premiers retards"),
              " (lags), plutÃ´t que lag par lag."
            ),
            
            tags$li(
              tags$b("Quand lâ€™utiliser"),
              " : aprÃ¨s lâ€™estimation dâ€™un modÃ¨le ARIMA/SARIMA, ",
              "comme ",
              tags$b("diagnostic rÃ©siduel principal"),
              ", pour vÃ©rifier que toute la dÃ©pendance temporelle ",
              "a bien Ã©tÃ© capturÃ©e."
            ),
            
            tags$li(
              tags$b("HypothÃ¨ses"),
              " : ",
              tags$b("H0"),
              " = absence dâ€™autocorrÃ©lation jusquâ€™au lag considÃ©rÃ© ",
              "(rÃ©sidus ~ bruit blanc) ; ",
              tags$b("Ha"),
              " = prÃ©sence dâ€™au moins une autocorrÃ©lation non nulle."
            ),
            
            tags$li(
              tags$b("Statistique / idÃ©e"),
              " : la statistique de Ljungâ€“Box agrÃ¨ge les ",
              tags$b("autocorrÃ©lations empiriques"),
              " des rÃ©sidus jusquâ€™au lag ",
              tags$code("h"),
              ", avec une correction de taille dâ€™Ã©chantillon ",
              "(plus fiable que le test de Boxâ€“Pierce)."
            ),
            
            tags$li(
              tags$b("Choix du lag"),
              " : souvent ",
              tags$code("h = 12"),
              " ou ",
              tags$code("h = 24"),
              " pour des donnÃ©es mensuelles ; ",
              "le lag doit Ãªtre ",
              tags$b("supÃ©rieur"),
              " Ã  ",
              tags$code("p + q + P + Q"),
              "."
            ),
            
            tags$li(
              tags$b("RÃ¨gle de dÃ©cision"),
              " : ",
              tags$b("p-value grande"),
              " (ex. > 0.05) â†’ on ",
              tags$b("ne rejette pas H0"),
              " â†’ rÃ©sidus compatibles avec un bruit blanc ; ",
              tags$b("p-value petite"),
              " â†’ autocorrÃ©lation rÃ©siduelle â†’ modÃ¨le insuffisant."
            ),
            
            tags$li(
              tags$b("InterprÃ©tation (sens)"),
              " : ",
              tags$b("rejeter H0"),
              " signifie quâ€™il reste de la ",
              tags$b("structure temporelle non expliquÃ©e"),
              " â†’ le modÃ¨le peut Ãªtre amÃ©liorÃ© (ajout de termes AR/MA, ",
              "diffÃ©renciation, transformation)."
            ),
            
            tags$li(
              tags$b("Ce que Ã§a implique pour vos choix"),
              " : si le test Ã©choue, revoir ",
              tags$code("p, q, P, Q"),
              ", la diffÃ©renciation, ou la transformation ; ",
              "si le test est satisfaisant, le modÃ¨le passe ",
              "un ",
              tags$b("critÃ¨re clÃ© de validation interne"),
              "."
            ),
            
            tags$li(
              tags$b("Comment le rapporter"),
              " : indiquer le lag utilisÃ©, la statistique de Ljungâ€“Box ",
              "et la p-value, en prÃ©cisant quâ€™il sâ€™agit dâ€™un test ",
              "sur les rÃ©sidus."
            ),
            
            tags$li(
              tags$b("Comment le rapporter en format APA"),
              " : ",
              tags$i("Â« Un test de Ljungâ€“Box appliquÃ© aux rÃ©sidus du modÃ¨le "),
              tags$i("nâ€™a pas mis en Ã©vidence dâ€™autocorrÃ©lation rÃ©siduelle significative "),
              tags$i("(Q(12) = 9.84, p = .63), suggÃ©rant des rÃ©sidus compatibles "),
              tags$i("avec un bruit blanc. Â»"),
              " (adapter le lag et les valeurs)."
            ),
            
            tags$li(
              tags$b("Limites / piÃ¨ges"),
              " : sensible au choix du lag ; ",
              "sur-rejet possible sur grands Ã©chantillons ; ",
              "ne garantit pas la ",
              tags$b("normalitÃ©"),
              " des rÃ©sidus ; ",
              "doit toujours Ãªtre interprÃ©tÃ© conjointement avec ",
              "lâ€™ACF des rÃ©sidus et les graphiques."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("But"), " : tester si les autocorrÃ©lations rÃ©siduelles jusquâ€™Ã  L sont globalement nulles."),
          tags$li(B("HypothÃ¨ses"), " : ", B("H0"), " = pas dâ€™autocorrÃ©lation rÃ©siduelle ; ", B("Ha"), " = autocorrÃ©lation rÃ©siduelle prÃ©sente."),
          tags$li(B("Conclusion"), " : p petit â†’ rejet H0 â†’ modÃ¨le incomplet (ajuster p/q/P/Q ou d/D)."),
          tags$li(B("Signification pratique"), " : si autocorrÃ©lation rÃ©siduelle reste, vos intervalles/prÃ©visions sont souvent trop optimistes.")
        ),
        
        
        
        # H5("NormalitÃ© & hÃ©tÃ©roscÃ©dasticitÃ© (Ã  quoi Ã§a sert vraiment)"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("NormalitÃ© & hÃ©tÃ©roscÃ©dasticitÃ© â€” Ã  quoi Ã§a sert vraiment")),
          
          tags$ul(
            
            tags$li(
              tags$b("IdÃ©e gÃ©nÃ©rale"),
              " : la normalitÃ© et lâ€™hÃ©tÃ©roscÃ©dasticitÃ© concernent la ",
              tags$b("distribution"),
              " des rÃ©sidus, ",
              tags$b("pas leur dÃ©pendance temporelle"),
              ". Elles sont secondaires par rapport Ã  lâ€™absence dâ€™autocorrÃ©lation."
            ),
            
            tags$li(
              tags$b("NormalitÃ© â€” dÃ©finition"),
              " : les rÃ©sidus sont dits normaux sâ€™ils suivent approximativement ",
              "une loi normale centrÃ©e, ce qui est une hypothÃ¨se classique des modÃ¨les ARIMA."
            ),
            
            tags$li(
              tags$b("Ã€ quoi sert la normalitÃ©"),
              " : principalement Ã  garantir la validitÃ© des ",
              tags$b("tests statistiques"),
              " (z, t) et des ",
              tags$b("intervalles de confiance"),
              " des paramÃ¨tres et des prÃ©visions."
            ),
            
            tags$li(
              tags$b("Ce qui est vraiment important"),
              " : pour la ",
              tags$b("prÃ©vision"),
              ", une lÃ©gÃ¨re non-normalitÃ© est gÃ©nÃ©ralement ",
              tags$b("peu problÃ©matique"),
              ", surtout sur grands Ã©chantillons."
            ),
            
            tags$li(
              tags$b("Quand la normalitÃ© devient critique"),
              " : petits Ã©chantillons, ",
              "prÃ©sence dâ€™outliers sÃ©vÃ¨res, ",
              "ou lorsque lâ€™on interprÃ¨te finement les ",
              tags$b("p-values"),
              " et les intervalles."
            ),
            
            tags$li(
              tags$b("Comment lâ€™Ã©valuer"),
              " : histogramme des rÃ©sidus, ",
              tags$b("QQ-plot"),
              ", tests formels (Shapiroâ€“Wilk), ",
              "Ã  interprÃ©ter avec prudence."
            ),
            
            tags$li(
              tags$b("HÃ©tÃ©roscÃ©dasticitÃ© â€” dÃ©finition"),
              " : la variance des rÃ©sidus ",
              tags$b("nâ€™est pas constante"),
              " dans le temps (volatilitÃ© variable)."
            ),
            
            tags$li(
              tags$b("Ã€ quoi sert la variance constante"),
              " : elle garantit des ",
              tags$b("incertitudes de prÃ©vision bien calibrÃ©es"),
              " et des Ã©carts-types de paramÃ¨tres interprÃ©tables."
            ),
            
            tags$li(
              tags$b("Quand lâ€™hÃ©tÃ©roscÃ©dasticitÃ© est problÃ©matique"),
              " : en prÃ©sence de ",
              tags$b("volatilitÃ© persistante"),
              " (effets ARCH/GARCH), ",
              "ou si les intervalles de prÃ©vision semblent irrÃ©alistes."
            ),
            
            tags$li(
              tags$b("Comment lâ€™Ã©valuer"),
              " : graphique des rÃ©sidus vs temps ou vs valeurs ajustÃ©es, ",
              "tests ARCH, inspection visuelle avant tout."
            ),
            
            tags$li(
              tags$b("Ce que Ã§a implique pour vos choix"),
              " : non-normalitÃ© ou hÃ©tÃ©roscÃ©dasticitÃ© modÃ©rÃ©e â†’ ",
              tags$b("acceptable"),
              " ; violations sÃ©vÃ¨res â†’ envisager ",
              "transformation (log, Boxâ€“Cox), ",
              "modÃ¨les Ã  variance conditionnelle, ",
              "ou discussion explicite des limites."
            ),
            
            tags$li(
              tags$b("Erreur frÃ©quente"),
              " : rejeter un bon modÃ¨le ",
              tags$b("uniquement"),
              " parce que la normalitÃ© nâ€™est pas parfaite, ",
              "alors que les rÃ©sidus sont non autocorrÃ©lÃ©s."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : en sÃ©ries temporelles, ",
              tags$b("lâ€™indÃ©pendance des rÃ©sidus est prioritaire"),
              "; la normalitÃ© et la variance constante servent surtout ",
              "Ã  ",
              tags$b("qualifier lâ€™incertitude"),
              " et Ã  affiner lâ€™interprÃ©tation."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("NormalitÃ©"), " : utile pour lâ€™interprÃ©tation probabiliste (IC) ; pas toujours critique si objectif = point forecast."),
          tags$li(B("ARCH / variance changeante"), " : peut rendre les IC sous-estimÃ©s ; si fort, envisager modÃ¨les de variance (GARCH) selon le cours.")
        ),
        
        
        
        # H5("Ã‰valuation prÃ©vision (dÃ©finition + protocole)"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Ã‰valuation prÃ©visionnelle â€” dÃ©finition & protocole")),
          
          tags$ul(
            
            tags$li(
              tags$b("DÃ©finition"),
              " : lâ€™Ã©valuation prÃ©visionnelle consiste Ã  mesurer la ",
              tags$b("qualitÃ© des prÃ©visions"),
              " dâ€™un modÃ¨le sur des ",
              tags$b("donnÃ©es futures non utilisÃ©es"),
              " lors de lâ€™estimation."
            ),
            
            tags$li(
              tags$b("But"),
              " : vÃ©rifier la ",
              tags$b("capacitÃ© rÃ©elle de gÃ©nÃ©ralisation"),
              " du modÃ¨le, câ€™est-Ã -dire sa performance ",
              tags$b("hors-Ã©chantillon"),
              ", et Ã©viter le sur-ajustement."
            ),
            
            tags$li(
              tags$b("Principe fondamental"),
              " : en sÃ©ries temporelles, ",
              tags$b("le futur ne doit jamais Ãªtre utilisÃ© pour prÃ©dire le passÃ©"),
              " â†’ toute Ã©valuation doit respecter lâ€™ordre temporel."
            ),
            
            tags$li(
              tags$b("Split temporel (train / test)"),
              " : on sÃ©pare la sÃ©rie en une partie ",
              tags$b("train"),
              " (passÃ©) et une partie ",
              tags$b("test"),
              " (futur). ",
              "Le modÃ¨le est estimÃ© sur train et Ã©valuÃ© sur test."
            ),
            
            tags$li(
              tags$b("Quand utiliser le split simple"),
              " : sÃ©ries longues et stables, ",
              "objectif principal = ",
              tags$b("prÃ©vision opÃ©rationnelle"),
              ", protocole simple et lisible."
            ),
            
            tags$li(
              tags$b("Rolling-origin (validation temporelle)"),
              " : on rÃ©pÃ¨te des prÃ©visions Ã  partir de ",
              tags$b("plusieurs origines"),
              " temporelles successives, ",
              "en avanÃ§ant la fenÃªtre dâ€™entraÃ®nement."
            ),
            
            tags$li(
              tags$b("IntÃ©rÃªt du rolling-origin"),
              " : fournit une estimation ",
              tags$b("plus robuste"),
              " de la performance moyenne et de sa variabilitÃ©, ",
              "surtout lorsque la sÃ©rie Ã©volue dans le temps."
            ),
            
            tags$li(
              tags$b("FenÃªtres dâ€™entraÃ®nement"),
              " : ",
              tags$b("expansive"),
              " (on ajoute les nouvelles observations au train) ou ",
              tags$b("glissante"),
              " (taille fixe) ; le choix doit Ãªtre ",
              tags$b("documentÃ©"),
              "."
            ),
            
            tags$li(
              tags$b("Benchmark (modÃ¨le de rÃ©fÃ©rence)"),
              " : modÃ¨le simple servant de ",
              tags$b("point de comparaison"),
              " (naÃ¯f, drift, SNAIVE). ",
              "Un modÃ¨le complexe nâ€™a de valeur que sâ€™il ",
              tags$b("bat le benchmark"),
              "."
            ),
            
            tags$li(
              tags$b("Pourquoi le benchmark est indispensable"),
              " : sans rÃ©fÃ©rence, une erreur faible ",
              tags$b("nâ€™a pas de sens"),
              ". Le benchmark fixe le ",
              tags$b("niveau minimal acceptable"),
              " de performance."
            ),
            
            tags$li(
              tags$b("Lien avec les mÃ©triques"),
              " : la performance est Ã©valuÃ©e Ã  lâ€™aide de mÃ©triques ",
              "(MAE, RMSE, etc.) calculÃ©es ",
              tags$b("uniquement sur les prÃ©visions hors-Ã©chantillon"),
              "."
            ),
            
            tags$li(
              tags$b("Ce que Ã§a implique pour vos choix"),
              " : privilÃ©gier le modÃ¨le ",
              tags$b("le plus simple"),
              " qui bat le benchmark, ",
              "avec une performance stable sur plusieurs origines."
            ),
            
            tags$li(
              tags$b("Erreur frÃ©quente"),
              " : choisir un modÃ¨le uniquement sur ",
              tags$b("AIC/BIC"),
              " ou sur lâ€™ajustement in-sample, ",
              "sans Ã©valuation prÃ©visionnelle."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : un bon modÃ¨le de prÃ©vision est celui qui ",
              tags$b("prÃ©dit mieux que le naÃ¯f"),
              ", de faÃ§on stable, ",
              "en respectant strictement la chronologie."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Split temporel"), " : entraÃ®ner sur le passÃ©, tester sur le futur."),
          tags$li(B("Rolling-origin"), " : rÃ©pÃ©ter sur plusieurs origines â†’ estimation plus robuste."),
          tags$li(B("Benchmark"), " : naÑ—f / drift / SNAIVE. Un SARIMA utile doit battre au moins SNAIVE Ã  lâ€™horizon cible.")
        ),
        
        
        
        # === ADD: diagnostics additionnels & comparaison ===
        
        
        # H5("Diagnostics additionnels"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Diagnostics additionnels â€” quand et pourquoi les utiliser")),
          
          tags$ul(
            
            tags$li(
              tags$b("Boxâ€“Pierce vs Ljungâ€“Box"),
              " : deux tests globaux dâ€™autocorrÃ©lation. ",
              tags$b("Ljungâ€“Box"),
              " est une version corrigÃ©e pour petits Ã©chantillons ",
              "et doit Ãªtre ",
              tags$b("prÃ©fÃ©rÃ©e en pratique"),
              ". Boxâ€“Pierce est aujourdâ€™hui surtout historique."
            ),
            
            tags$li(
              tags$b("NormalitÃ© rÃ©siduelle â€” QQ-plot"),
              " : le ",
              tags$b("Qâ€“Q plot"),
              " compare la distribution empirique des rÃ©sidus ",
              "Ã  une loi normale. ",
              "DÃ©viations dans les queues â†’ outliers ou asymÃ©trie."
            ),
            
            tags$li(
              tags$b("NormalitÃ© rÃ©siduelle â€” tests formels"),
              " : tests comme ",
              tags$b("Jarqueâ€“Bera"),
              " ou Shapiroâ€“Wilk peuvent Ãªtre utilisÃ©s, ",
              "mais ils sont ",
              tags$b("trÃ¨s sensibles"),
              " sur grands Ã©chantillons."
            ),
            
            tags$li(
              tags$b("Ã€ quoi sert vraiment la normalitÃ©"),
              " : utile surtout pour la ",
              tags$b("validitÃ© des intervalles de confiance"),
              " et des tests sur les paramÃ¨tres ; ",
              tags$b("secondaire"),
              " si lâ€™objectif principal est la ",
              tags$b("prÃ©vision ponctuelle"),
              "."
            ),
            
            tags$li(
              tags$b("HÃ©tÃ©roscÃ©dasticitÃ© / effets ARCH"),
              " : variance rÃ©siduelle non constante dans le temps, ",
              "souvent visible par des ",
              tags$b("paquets de volatilitÃ©"),
              "."
            ),
            
            tags$li(
              tags$b("Comment dÃ©tecter les effets ARCH"),
              " : examiner lâ€™",
              tags$b("ACF des rÃ©sidus au carrÃ©"),
              " et utiliser des tests ARCH. ",
              "AutocorrÃ©lation significative â†’ variance conditionnelle."
            ),
            
            tags$li(
              tags$b("Que faire si effets ARCH forts"),
              " : discuter des limites du modÃ¨le ARIMA, ",
              "envisager une ",
              tags$b("transformation"),
              " ou des modÃ¨les Ã  ",
              tags$b("variance conditionnelle"),
              " (ex. GARCH), ou limiter lâ€™analyse Ã  la moyenne."
            ),
            
            tags$li(
              tags$b("SignificativitÃ© des coefficients"),
              " : rapporter systÃ©matiquement ",
              tags$b("estimations"),
              ", ",
              tags$b("Ã©carts-types"),
              ", ",
              tags$b("statistiques z"),
              " et ",
              tags$b("p-values"),
              "."
            ),
            
            tags$li(
              tags$b("InterprÃ©tation de la non-significativitÃ©"),
              " : un coefficient non significatif ",
              tags$b("nâ€™invalide pas automatiquement"),
              " le modÃ¨le si la performance prÃ©dictive est bonne."
            ),
            
            tags$li(
              tags$b("Principe de parcimonie"),
              " : si plusieurs coefficients sont non significatifs ",
              "et que leur suppression ",
              tags$b("ne dÃ©grade pas la performance"),
              ", prÃ©fÃ©rer le modÃ¨le ",
              tags$b("plus simple"),
              "."
            ),
            
            tags$li(
              tags$b("Erreur frÃ©quente"),
              " : Ã©liminer des termes uniquement sur la base des p-values ",
              "sans vÃ©rifier lâ€™impact sur les ",
              tags$b("diagnostics rÃ©siduels"),
              " et la ",
              tags$b("performance hors-Ã©chantillon"),
              "."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : ces diagnostics sont ",
              tags$b("complÃ©mentaires"),
              ". Ils affinent lâ€™interprÃ©tation et la discussion, ",
              "mais ne doivent jamais primer sur ",
              tags$b("lâ€™absence dâ€™autocorrÃ©lation rÃ©siduelle"),
              " et la ",
              tags$b("performance prÃ©visionnelle"),
              "."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Boxâ€“Pierce vs Ljungâ€“Box"), " : prÃ©fÃ©rer Ljungâ€“Box (meilleure petite taille)."),
          tags$li(B("NormalitÃ© rÃ©siduelle"), " : Qâ€“Q plot, Jarqueâ€“Bera ; utile pour IC mais secondaire si but = point forecast."),
          tags$li(B("HÃ©tÃ©roscÃ©dasticitÃ© / ARCH"), " : tester ACF des rÃ©sidus au carrÃ© ; si fort â†’ discuter modÃ¨les de variance (annexe)."),
          tags$li(B("SignificativitÃ© des coefficients"), " : rapporter est., SE, z, p ; supprimer termes non significatifs si performance constante.")
        ),
        
        
        
        # H5("Comparaison de modÃ¨les"),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Comparaison de modÃ¨les â€” principes, outils et dÃ©cision")),
          
          tags$ul(
            
            tags$li(
              tags$b("Objectif"),
              " : comparer plusieurs modÃ¨les candidats afin de retenir celui qui est ",
              tags$b("le plus pertinent"),
              " selon des critÃ¨res Ã  la fois ",
              tags$b("statistiques"),
              " et ",
              tags$b("prÃ©dictifs"),
              "."
            ),
            
            tags$li(
              tags$b("Principe gÃ©nÃ©ral"),
              " : la comparaison doit Ãªtre ",
              tags$b("multicritÃ¨re"),
              " : aucun indicateur (AIC, RMSE, p-value) nâ€™est suffisant pris isolÃ©ment."
            ),
            
            tags$li(
              tags$b("Tableau rÃ©capitulatif â€” rÃ´le"),
              " : synthÃ©tiser les informations clÃ©s de chaque modÃ¨le dans un ",
              tags$b("format lisible"),
              " pour faciliter une dÃ©cision argumentÃ©e."
            ),
            
            tags$li(
              tags$b("CritÃ¨res dâ€™information (AICc / BIC)"),
              " : mesurent le compromis ajustement / complexitÃ© ; ",
              tags$b("AICc"),
              " prÃ©fÃ©rable en petits Ã©chantillons, ",
              tags$b("BIC"),
              " plus sÃ©vÃ¨re et orientÃ© parcimonie."
            ),
            
            tags$li(
              tags$b("Diagnostics rÃ©siduels â€” Ljungâ€“Box"),
              " : vÃ©rifier lâ€™absence dâ€™autocorrÃ©lation rÃ©siduelle ; ",
              "un modÃ¨le qui Ã©choue au Ljungâ€“Box ",
              tags$b("ne doit pas Ãªtre retenu"),
              ", mÃªme sâ€™il a un bon AIC."
            ),
            
            tags$li(
              tags$b("Performance prÃ©visionnelle"),
              " : comparer ",
              tags$b("MAE / RMSE / MASE"),
              " calculÃ©es hors-Ã©chantillon ; ",
              "elles mesurent directement la ",
              tags$b("qualitÃ© des prÃ©visions"),
              "."
            ),
            
            tags$li(
              tags$b("Nombre de paramÃ¨tres"),
              " : indicateur de ",
              tags$b("complexitÃ©"),
              " ; Ã  performance comparable, ",
              tags$b("prÃ©fÃ©rer le modÃ¨le le plus simple"),
              "."
            ),
            
            tags$li(
              tags$b("Logique de dÃ©cision recommandÃ©e"),
              " : Ã©liminer dâ€™abord les modÃ¨les ",
              tags$b("mal diagnostiquÃ©s"),
              ", puis comparer la performance prÃ©visionnelle, ",
              "et enfin arbitrer par la parcimonie."
            ),
            
            tags$li(
              tags$b("Test de Dieboldâ€“Mariano (annexe)"),
              " : test statistique permettant de comparer ",
              tags$b("formellement"),
              " deux sÃ©ries dâ€™erreurs de prÃ©vision issues de ",
              tags$b("deux modÃ¨les concurrents"),
              "."
            ),
            
            tags$li(
              tags$b("HypothÃ¨ses du test DM"),
              " : ",
              tags$b("H0"),
              " = performances prÃ©dictives Ã©quivalentes ; ",
              tags$b("Ha"),
              " = diffÃ©rence significative de performance."
            ),
            
            tags$li(
              tags$b("Quand utiliser le test DM"),
              " : lorsque deux modÃ¨les ont des performances proches ",
              "et que lâ€™on souhaite une ",
              tags$b("validation statistique"),
              " de la diffÃ©rence observÃ©e."
            ),
            
            tags$li(
              tags$b("InterprÃ©tation du test DM"),
              " : p-value petite â†’ diffÃ©rence significative ; ",
              "p-value grande â†’ performances statistiquement comparables."
            ),
            
            tags$li(
              tags$b("Limites du test DM"),
              " : dÃ©pend du choix de la fonction de perte ; ",
              "sensible Ã  lâ€™horizon et Ã  lâ€™autocorrÃ©lation des erreurs ; ",
              tags$b("ne remplace pas"),
              " lâ€™analyse globale."
            ),
            
            tags$li(
              tags$b("Erreur frÃ©quente"),
              " : choisir un modÃ¨le uniquement parce quâ€™il a ",
              tags$b("le plus petit AIC"),
              " ou la ",
              tags$b("plus petite RMSE"),
              ", sans vÃ©rifier diagnostics et stabilitÃ©."
            ),
            
            tags$li(
              tags$b("Conclusion pratique"),
              " : retenir le modÃ¨le qui ",
              tags$b("passe les diagnostics"),
              ", ",
              tags$b("bat le benchmark"),
              ", et offre le ",
              tags$b("meilleur compromis"),
              " entre performance, robustesse et simplicitÃ©."
            )
          )
        ),
        
        
        
        UL(
          tags$li(B("Tableau rÃ©capitulatif"), " : AICc/BIC, Ljungâ€“Box (p), MAE/RMSE/MASE, nb de paramÃ¨tres."),
          tags$li(B("Test de Dieboldâ€“Mariano"), " : (annexe) comparer formellement 2 sÃ©ries dâ€™erreurs prÃ©dictives.")
        ),
        
        tags$details(
          class = "defs-details",
          tags$summary(tags$span("Arbre dÃ©cisionnel complet â€” diagnostics â†’ actions (Steps)")),
          
          tags$ol(
            
            tags$li(
              tags$b("Ã‰tape 1 â€” AutocorrÃ©lation rÃ©siduelle (prioritaire)"),
              " : examiner lâ€™ACF des rÃ©sidus et le test de ",
              tags$b("Ljungâ€“Box"),
              "."
            ),
            
            tags$li(
              tags$b("Si autocorrÃ©lation significative"),
              " : le modÃ¨le est ",
              tags$b("insuffisant"),
              " â†’ ",
              "ajuster ",
              tags$code("p, q, P, Q"),
              ", revoir la diffÃ©renciation ",
              tags$code("d / D"),
              ", ou la transformation. ",
              tags$b("Ne pas passer aux Ã©tapes suivantes"),
              " tant que ce point nâ€™est pas rÃ©solu."
            ),
            
            tags$li(
              tags$b("Si pas dâ€™autocorrÃ©lation rÃ©siduelle"),
              " : les rÃ©sidus sont compatibles avec un ",
              tags$b("bruit blanc"),
              " â†’ passer Ã  lâ€™Ã©tape suivante."
            ),
            
            tags$li(
              tags$b("Ã‰tape 2 â€” Performance prÃ©visionnelle"),
              " : Ã©valuer les erreurs ",
              tags$b("hors-Ã©chantillon"),
              " (split temporel ou rolling-origin) ",
              "et comparer au ",
              tags$b("benchmark"),
              "."
            ),
            
            tags$li(
              tags$b("Si le modÃ¨le ne bat pas le benchmark"),
              " : complexitÃ© ",
              tags$b("injustifiÃ©e"),
              " â†’ simplifier le modÃ¨le, ",
              "ou prÃ©fÃ©rer le benchmark."
            ),
            
            tags$li(
              tags$b("Si le modÃ¨le bat le benchmark"),
              " : performance prÃ©dictive acceptable â†’ continuer."
            ),
            
            tags$li(
              tags$b("Ã‰tape 3 â€” StabilitÃ© de la performance"),
              " : vÃ©rifier la ",
              tags$b("robustesse"),
              " des mÃ©triques sur plusieurs origines ",
              "(rolling-origin)."
            ),
            
            tags$li(
              tags$b("Si performance instable"),
              " : modÃ¨le trop sensible â†’ ",
              "simplifier, rÃ©duire le nombre de paramÃ¨tres, ",
              "ou revoir la fenÃªtre dâ€™entraÃ®nement."
            ),
            
            tags$li(
              tags$b("Ã‰tape 4 â€” NormalitÃ© des rÃ©sidus (secondaire)"),
              " : examiner histogramme et ",
              tags$b("Qâ€“Q plot"),
              "."
            ),
            
            tags$li(
              tags$b("Si non-normalitÃ© modÃ©rÃ©e"),
              " : gÃ©nÃ©ralement ",
              tags$b("acceptable"),
              " si lâ€™objectif est la ",
              tags$b("prÃ©vision ponctuelle"),
              ". Mentionner la limitation."
            ),
            
            tags$li(
              tags$b("Si non-normalitÃ© sÃ©vÃ¨re"),
              " : envisager transformation (log, Boxâ€“Cox), ",
              "ou discuter lâ€™impact sur les intervalles de confiance."
            ),
            
            tags$li(
              tags$b("Ã‰tape 5 â€” HÃ©tÃ©roscÃ©dasticitÃ© / effets ARCH"),
              " : examiner la variance des rÃ©sidus dans le temps ",
              "et lâ€™ACF des rÃ©sidus au carrÃ©."
            ),
            
            tags$li(
              tags$b("Si effets ARCH faibles"),
              " : gÃ©nÃ©ralement ",
              tags$b("tolÃ©rables"),
              " pour la moyenne conditionnelle."
            ),
            
            tags$li(
              tags$b("Si effets ARCH forts"),
              " : discuter lâ€™usage de modÃ¨les Ã  ",
              tags$b("variance conditionnelle"),
              " (ex. GARCH) ",
              "ou limiter lâ€™analyse aux prÃ©visions de moyenne."
            ),
            
            tags$li(
              tags$b("Ã‰tape 6 â€” SignificativitÃ© des coefficients"),
              " : examiner estimations, ",
              tags$b("SE"),
              ", ",
              tags$b("z"),
              " et ",
              tags$b("p-values"),
              "."
            ),
            
            tags$li(
              tags$b("Si coefficients non significatifs"),
              " : tester leur suppression ",
              tags$b("si et seulement si"),
              " la performance et les diagnostics ",
              tags$b("restent inchangÃ©s"),
              "."
            ),
            
            tags$li(
              tags$b("Ã‰tape 7 â€” Parcimonie et comparaison finale"),
              " : comparer les modÃ¨les candidats via ",
              tags$b("AICc/BIC"),
              ", performance prÃ©visionnelle et simplicitÃ©."
            ),
            
            tags$li(
              tags$b("DÃ©cision finale"),
              " : retenir le modÃ¨le qui ",
              tags$b("passe tous les diagnostics bloquants"),
              ", ",
              tags$b("bat le benchmark"),
              ", et offre le ",
              tags$b("meilleur compromis"),
              " entre performance, stabilitÃ© et interprÃ©tabilitÃ©."
            ),
            
            tags$li(
              tags$b("Principe clÃ© Ã  retenir"),
              " : les diagnostics guident des ",
              tags$b("actions concrÃ¨tes"),
              ", pas des dÃ©cisions automatiques. ",
              "La justification doit toujours Ãªtre ",
              tags$b("argumentÃ©e"),
              "."
            )
          )
        ),
        
        # tags$details(
        #   class = "defs-details",
        #   tags$summary(tags$span("Arbre dÃ©cisionnel complet â€” diagnostics â†’ actions (Graph)")),
        #   tags$div(
        #     style = "padding:10px 12px; background:#fff;",
        #     DiagrammeR::grVizOutput("diag_tree", height = "1500px")
        #   )
        # ),
        
      ),
      
      apa_ui = tagList(
        H5("RÃ©sultats (APA) â€” diagnostics"),
        P("Â« Les diagnostics rÃ©siduels indiquaient un comportement proche du bruit blanc : lâ€™ACF des rÃ©sidus ne montrait pas de pics substantiels et le test de Ljungâ€“Box Ã©tait [non significatif/significatif] au seuil Î±=[..]. ",
          "La performance de prÃ©vision sur la fenÃªtre dâ€™Ã©valuation donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. Â»"),
        
        H5("Conclusion & signification (diagnostics + performance)"),
        UL(
          tags$li(B("Conclusion : "), "Â« Le modÃ¨le est acceptable Â» si Ljungâ€“Box non significatif ET benchmark battu."),
          tags$li(B("Signification : "),
                  "Â« le modÃ¨le capte la structure temporelle (rÃ©sidus ~ bruit) et apporte un gain prÃ©dictif rÃ©el (out-of-sample). Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Bon AIC mais Ljungâ€“Box significatif"), " : modÃ¨le incomplet â†’ ne pas valider."),
          tags$li(B("Se focaliser sur la normalitÃ©"), " : prioritÃ© = absence dâ€™autocorrÃ©lation rÃ©siduelle."),
          tags$li(B("Comparer des modÃ¨les sur des horizons diffÃ©rents"), " : toujours mÃªme h, mÃªme protocole.")
        )
      )
    )
    
    # (9) Ã‰tape 8 â€” RÃ©daction
    pages[[10]] <- make_step(
      step_names[10],
      
      actions_ui = tagList(
        callout(B("But : "), "Ã©crire un rapport clair, reproductible, alignÃ© aux Ã©tapes 0â€“7.", type="info"),
        
        Checklist(
          CheckItem("Rediger une section Methodes qui suit exactement le pipeline: donnees -> EDA -> stationnarite -> selection -> diagnostics -> prevision."),
          CheckItem("Inclure figures indispensables: serie, decomposition, ACF/PACF, residus, previsions + intervalles."),
          CheckItem("Inclure un tableau de comparaison (AICc/BIC, Ljung-Box, MAE/RMSE, benchmark, nb parametres)."),
          CheckItem("Preciser lâ€™echelle (niveau/log/Box-Cox) et expliquer toute reconversion des previsions."),
          CheckItem("Ajouter un encadre limites + pistes (ruptures, SARIMAX, GARCH) et assurer la reproductibilite (versions).")
        ),
        
        Deliverables(
          tags$li("Une section MÃ©thodes (donnÃ©es, split, transformations, tests, choix dâ€™ordres) rÃ©digÃ©e proprement."),
          tags$li("Une section RÃ©sultats (modÃ¨le final, coefficients, diagnostics, performance, figures) + discussion/limites."),
          tags$li("Un paquet de livrables : figures lÃ©gendÃ©es, tableau des paramÃ¨tres, Ã©quations, et un appendice â€œreproductibilitÃ©â€.")
        ),
        
        
        H5("Structure APA recommandÃ©e (dÃ©finition)"),
        UL(
          tags$li(B("MÃ©thodes"), " : ce que vous avez fait et pourquoi (donnÃ©es â†’ EDA â†’ stationnaritÃ© â†’ modÃ¨les â†’ Ã©valuation)."),
          tags$li(B("RÃ©sultats"), " : ce que vous avez observÃ© (stats, figures, tests, mÃ©triques, modÃ¨le final)."),
          tags$li(B("Discussion"), " (optionnel) : limites (ruptures, horizon, incertitudes) + pistes (SARIMAX/GARCH).")
        ),
        
        H5("Pack livrable propre (checklist)"),
        UL(
          tags$li("Notebook/script reproductible (import â†’ nettoyage â†’ EDA â†’ tests â†’ modÃ¨les â†’ diagnostics â†’ prÃ©visions)."),
          tags$li("Figures : sÃ©rie, dÃ©composition, ACF/PACF, rÃ©sidus (ACF + Ljungâ€“Box), prÃ©visions + IC."),
          tags$li("Tableau : candidats vs AICc/BIC vs Ljungâ€“Box vs MAE/RMSE vs benchmark.")
        ),
        
        # === ADD: rapporter correctement les prÃ©visions ===
        H5("Rapporter correctement les prÃ©visions"),
        UL(
          tags$li(B("Niveau de couverture"), " : prÃ©ciser 80% et/ou 95% ; indiquer si log-Ã©chelle a Ã©tÃ© reconvertie."),
          tags$li(B("Biais de reconversion (logâ†’niveau)"), " : mentionner correction ",
                  C("exp(\\hat{y}) \\times exp(\\hat{\\sigma}^2/2)"), " si utilisÃ©e."),
          tags$li(B("ReproductibilitÃ©"), " : versions R/packages, seed, chemin des donnÃ©es, date dâ€™extraction.")
        )
      ),
      
      apa_ui = tagList(
        H5("Phrase finale (APA) â€” modÃ¨le final + interprÃ©tation"),
        P("Â« Sur la base de lâ€™adÃ©quation diagnostique et de la performance prÃ©dictive, le modÃ¨le final retenu Ã©tait SARIMA((p,d,q)(P,D,Q)_s). ",
          "Les rÃ©sidus Ã©tant compatibles avec un bruit blanc, nous concluons que la structure temporelle principale a Ã©tÃ© capturÃ©e. ",
          "Les prÃ©visions produites Ã  horizon h=[..] amÃ©liorent le benchmark [..] selon MAE/RMSE, ce qui soutient lâ€™usage du modÃ¨le pour lâ€™application ciblÃ©e. Â»"),
        
        H5("Conclusion & signification"),
        UL(
          tags$li(B("Conclusion : "), "Â« Le rapport est alignÃ©, justifiÃ©, reproductible. Â»"),
          tags$li(B("Signification : "),
                  "Â« un lecteur externe peut reproduire vos rÃ©sultats et comprendre chaque choix (transformation, d/D, sÃ©lection, diagnostics). Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Ne pas relier choix â†’ preuves"), " : chaque dÃ©cision doit Ãªtre liÃ©e Ã  EDA/tests/diagnostics."),
          tags$li(B("Trop de texte, pas assez de figures"), " : en sÃ©ries temporelles, les figures sont des rÃ©sultats."),
          tags$li(B("Oublier de prÃ©ciser lâ€™Ã©chelle"), " : niveau vs log vs Boxâ€“Cox et reconversion des prÃ©visions.")
        )
      )
    )
    
    # (10) Annexes
    pages[[11]] <- make_step(
      step_names[11],
      
      actions_ui = tagList(
        Checklist(
          CheckItem("Reconnaitre et pouvoir ecrire les trois benchmarks (naif, drift, SNAIVE) et expliquer quand chacun est approprie."),
          CheckItem("Savoir lire rapidement un resultat ADF/KPSS/PP et traduire la conclusion en choix de d et D."),
          CheckItem("Savoir expliquer ce que signifie Ljung-Box significatif (structure residuelle) et quelle action entreprendre."),
          CheckItem("Memoriser les formules utiles (AIC/AICc/BIC, Ljung-Box, operateurs de differenciation) et leur interpretation."),
          CheckItem("Identifier quand il faut sortir du cadre SARIMA (exogenes, multiples saisonnalites, ruptures, variance conditionnelle).")
        ),
        
        Deliverables(
          tags$li("Des gabarits prÃªts Ã  copier : phrases APA, tableaux de rÃ©sultats, checklists, et rappels de formules."),
          tags$li("Une mini â€œboÃ®te Ã  outilsâ€ : lecture rapide ACF/PACF, dÃ©cisions d/D, et actions si diagnostics Ã©chouent."),
          tags$li("Une liste de signaux â€œSARIMA insuffisantâ€ + pistes alternatives (SARIMAX, ETS/TBATS, modÃ¨les Ã  hÃ©tÃ©roscÃ©dasticitÃ©, etc.).")
        ),
        
        
        H5("Benchmarks (dÃ©finitions)"),
        UL(
          tags$li(B("NaÃ¯f"), " : ", C("Å·_{t+1|t} = y_t"), " (persistance)."),
          tags$li(B("Drift"), " : extrapolation linÃ©aire moyenne."),
          tags$li(B("SNAIVE"), " : rÃ©pÃ¨te la derniÃ¨re valeur de la mÃªme saison : ", C("Å·_{t+h|t} = y_{t+h-s}"), ".")
        ),
        
        H5("RÃ¨gles dâ€™interprÃ©tation ultra rapides"),
        UL(
          tags$li(B("ADF/PP rejettent"), " + ", B("KPSS ne rejette pas"), " â†’ stationnaritÃ© plausible."),
          tags$li(B("ADF/PP ne rejettent pas"), " + ", B("KPSS rejette"), " â†’ diffÃ©renciation nÃ©cessaire."),
          tags$li(B("Ljungâ€“Box significatif"), " â†’ il reste de la structure â†’ rÃ©viser le modÃ¨le.")
        ),
        
        # === ADD: formules utiles & pistes avancÃ©es ===
        H5("Formules utiles (mÃ©mo)"),
        UL(
          tags$li(B("CritÃ¨res dâ€™info"), " : ",
                  C("AIC=-2\\log L+2k"), ", ",
                  C("AICc= AIC + \\frac{2k(k+1)}{n-k-1}"), ", ",
                  C("BIC=-2\\log L+k\\log n"), "."),
          tags$li(B("MASE"), " : ", C("\\frac{\\frac{1}{T}\\sum_{t}|e_t|}{\\frac{1}{T-s}\\sum_{t}|y_t-y_{t-s}|}"), " (pour pÃ©riodicitÃ© ", C("s"), ")."),
          tags$li(B("Ljungâ€“Box"), " : ", C("Q^* = n(n+2)\\sum_{k=1}^{L} \\frac{\\hat{\\rho}_k^2}{n-k}"),
                  " ~ ", C("\\chi^2"), " sous ", C("H_0"), " avec ddl â‰ˆ ", C("L - p - q - (P+Q)"), "."),
          tags$li(B("Backshift & diff."), " : ",
                  C("\\nabla=(1-B)"), ", ", C("\\nabla_s=(1-B^s)"), ", ",
                  C("\\nabla^d \\nabla_s^D y_t"), " pour stationnariser.")
        ),
        
        H5("Ã‰quation SARIMA en opÃ©rateurs (forme compacte)"),
        P("Cette Ã©criture est utile parce quâ€™elle montre clairement : (i) comment la diffÃ©renciation rend la sÃ©rie stationnaire, et (ii) comment les polynÃ´mes AR/MA dÃ©crivent la dÃ©pendance restante."),
        UL(
          tags$li("Forme gÃ©nÃ©rale : ",
                  C("\\Phi(B^s)\\,\\phi(B)\\,(1-B)^d(1-B^s)^D\\,y_t = \\Theta(B^s)\\,\\theta(B)\\,\\varepsilon_t")),
          tags$li(B("PolynÃ´mes non saisonniers"), " : ",
                  C("\\phi(B)=1-\\phi_1B-\\cdots-\\phi_pB^p"), " et ",
                  C("\\theta(B)=1+\\theta_1B+\\cdots+\\theta_qB^q"), "."),
          tags$li(B("PolynÃ´mes saisonniers"), " : ",
                  C("\\Phi(B^s)=1-\\Phi_1B^s-\\cdots-\\Phi_PB^{Ps}"), " et ",
                  C("\\Theta(B^s)=1+\\Theta_1B^s+\\cdots+\\Theta_QB^{Qs}"), "."),
          tags$li(B("Erreur"), " : ", C("\\varepsilon_t"), " est un bruit blanc (moyenne 0, variance constante, pas dâ€™autocorrÃ©lation).")
        ),
        
        H5("ACF / PACF (rappel express)"),
        UL(
          tags$li(B("ACF"), " : corrÃ©lation entre ", C("y_t"), " et ", C("y_{t-k}"), " (au lag ", C("k"), "). Elle aide Ã  dÃ©tecter une structure MA et la prÃ©sence de saisonnalitÃ© (pics aux multiples de ", C("s"), ")."),
          tags$li(B("PACF"), " : corrÃ©lation â€œpureâ€ entre ", C("y_t"), " et ", C("y_{t-k}"), " aprÃ¨s avoir contrÃ´lÃ© les lags intermÃ©diaires. Elle aide Ã  dÃ©tecter une structure AR."),
          tags$li(B("Avertissement"), " : lire ACF/PACF sur une sÃ©rie non stationnaire conduit souvent Ã  des ordres trop grands ; faites la diffÃ©renciation avant dâ€™interprÃ©ter les coupures.")
        ),
        
        H5("Pistes avancÃ©es (pour lâ€™enseignant)"),
        UL(
          tags$li(B("SARIMAX / rÃ©gression dynamique"), " : variables exogÃ¨nes, prÃ©-blanchiment, fonctions de transfert."),
          tags$li(B("Ruptures/Interventions"), " : dummies LS/TC, estimation avec rÃ©gresseurs."),
          tags$li(B("Multiples saisonnalitÃ©s"), " : TBATS/ETS-MS si prÃ©sence de s multiples.")
        )
      ),
      
      apa_ui = tagList(
        H5("Template â€œConclusion tests â†’ choix (d,D)â€ (copier-coller)"),
        P("Â« Les tests ADF/PP et KPSS ont Ã©tÃ© interprÃ©tÃ©s conjointement. ",
          "Comme [ADF/PP: rejettent/ne rejettent pas] la racine unitaire et [KPSS: rejette/ne rejette pas] la stationnaritÃ©, ",
          "nous concluons que la sÃ©rie est [stationnaire/non-stationnaire] au sens des diagnostics combinÃ©s. ",
          "Nous retenons donc d=[..] et D=[..] (s=[..]) pour obtenir une sÃ©rie stationnaire pour lâ€™estimation SARIMA. Â»"),
        
        H5("Signification (traduction simple)"),
        UL(
          tags$li("Â« d et D disent combien de fois on doit â€œretirerâ€ une tendance et une saisonnalitÃ© non stationnaire. Â»"),
          tags$li("Â« Ensuite, p/q/P/Q dÃ©crivent la dÃ©pendance restante (mÃ©moire) dans la sÃ©rie transformÃ©e. Â»")
        )
      ),
      
      pitfalls_ui = tagList(
        UL(
          tags$li(B("Croire quâ€™un test â€œdÃ©cideâ€ seul"), " : toujours trianguler avec EDA + ACF + comportement aprÃ¨s diffÃ©renciation."),
          tags$li(B("Oublier la finalitÃ©"), " : prÃ©vision (out-of-sample) + diagnostics passent avant lâ€™esthÃ©tique dâ€™un AIC."),
          tags$li(B("Ne pas documenter"), " : un bon modÃ¨le non documentÃ© = inutilisable dans un cours/rapport.")
        )
      )
    )
    
    # ========= Output =========
    tagList(
      css,
      tags$h4(style="margin-top:12px;", paste0("Page ", cur, "/10 â€” ", step_names[cur + 1L])),
      progress_ui,
      pages[[cur + 1L]]
    )
  })
  
  
  
  
  
  
  #======================================================================================================
  #======================================================================================================
  #======================================================================================================
  
  
  
  
  
  
  
  # ============================================================
  # UI (add this where you want the roadmap to appear)
  # ============================================================
  # uiOutput("roadmap_Detailed_Fr_ui")
  
  
  # ============================================================
  # SERVER (FULL COPY-PASTE) â€” Roadmap SARIMA FR + Slider + Collapsibles
  # Put this inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui5 <- renderUI({
    
    # ----------------------------
    # Helpers: nested collapsibles
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    
    # Big blocks per step
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1")
    # Sub-blocks inside big blocks
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2")
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, example = NULL, formula = NULL, notes = NULL, open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 tags$p(tags$b("DÃ©finition : "), definition),
                 if (!is.null(purpose)) tags$p(tags$b("But / utilitÃ© : "), purpose) else NULL,
                 if (!is.null(formula)) tags$p(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example)) tags$p(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(notes))   tags$p(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name, purpose, H0, H1,
                     statistic = NULL, interpretation = NULL, conclusion = NULL, caveats = NULL, open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 tags$p(tags$b("But / utilitÃ© : "), purpose),
                 tags$p(tags$b("H0 : "), H0),
                 tags$p(tags$b("H1 : "), H1),
                 if (!is.null(statistic))      tags$p(tags$b("Statistique (idÃ©e) : "), statistic) else NULL,
                 if (!is.null(interpretation)) tags$p(tags$b("InterprÃ©tation : "), interpretation) else NULL,
                 if (!is.null(conclusion))     tags$p(tags$b("Conclusion + sens : "), conclusion) else NULL,
                 if (!is.null(caveats))        tags$p(tags$b("PiÃ¨ges / limites : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .eq {font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step builder
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] PrÃ©parer le terrain : dÃ©finir le problÃ¨me",
        "[1] DÃ©crire les donnÃ©es : n, manque, descriptives",
        "[2] Explorer visuellement : tendance, saison, outliers",
        "[3] DÃ©composer : additif vs multiplicatif, STL",
        "[4] StationnaritÃ© : ADF/KPSS/PP, choisir d & D",
        "[5] ModÃ¨le de rÃ©fÃ©rence : Auto-ARIMA (AICc)",
        "[6] ModÃ¨le guidÃ© par thÃ©orie : ACF/PACF + candidats",
        "[7] Diagnostiquer & comparer : rÃ©sidus + prÃ©cision",
        "[8] RÃ©diger le rapport : MÃ©thodes/RÃ©sultats + livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "DonnÃ©es", "Ã‰valuation"),
        c("QualitÃ© donnÃ©es", "Manquants", "Stat descriptives"),
        c("Graphiques", "SaisonnalitÃ©", "Anomalies"),
        c("Tendance", "Saison", "STL"),
        c("StationnaritÃ©", "DiffÃ©renciation", "Tests"),
        c("Auto-ARIMA", "AICc/BIC", "Baseline"),
        c("ACF/PACF", "Candidats", "Parcimonie"),
        c("Diagnostics", "Ljungâ€“Box", "Forecast accuracy"),
        c("APA", "SynthÃ¨se", "Livrables")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ------------------------------------------------------------
    # CONTENT (extremely detailed but organized via collapsibles)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # ============== STEP 0 ==============
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Avant toute SARIMA, on fige exactement : la sÃ©rie cible (y_t), le calendrier (frÃ©quence rÃ©guliÃ¨re), lâ€™horizon, le protocole dâ€™Ã©valuation et la (les) mÃ©triques. ",
                          "Sans Ã§a, on obtient des modÃ¨les Â« corrects Â» mais inutilisables.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Checklist opÃ©rationnelle", open = TRUE,
                            tags$ul(
                              tags$li("DÃ©finir la ", tags$b("sÃ©rie rÃ©ponse"), " : ", tags$code("y_t"), " (ce que lâ€™on prÃ©voit)."),
                              tags$li("DÃ©finir lâ€™", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vÃ©rifier la ", tags$b("rÃ©gularitÃ©"), " (pas de trous ni doublons)."),
                              tags$li("DÃ©finir la ", tags$b("tÃ¢che de prÃ©vision"), " : horizon ", tags$code("h"), ", protocole (train/test ou rolling-origin), mÃ©trique(s) (MAE/RMSE/MAPE/sMAPE)."),
                              tags$li("Choisir lâ€™Ã©chelle : niveaux / log / Boxâ€“Cox (et justifier)."),
                              tags$li("DÃ©finir le benchmark : naÃ¯f (et naÃ¯f saisonnier si saison).")
                            )
                          ),
                          
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM(
                              "SÃ©rie rÃ©ponse (y_t)",
                              "Variable temporelle univariÃ©e que lâ€™on veut expliquer et prÃ©voir. Chaque observation correspond Ã  un instant t.",
                              purpose="DÃ©termine lâ€™objet du modÃ¨le (la cible) et le type de prÃ©vision produit.",
                              formula="y_t",
                              notes="SARIMA classique est univariÃ© (pas de prÃ©dicteurs)."
                            ),
                            TERM(
                              "Indice temporel & frÃ©quence",
                              "Lâ€™index temporel est la sÃ©quence des dates/temps. La frÃ©quence est lâ€™espacement rÃ©gulier (jour, semaine, moisâ€¦).",
                              purpose="SARIMA suppose des intervalles constants ; la frÃ©quence fixe la saisonnalitÃ© (ex : s=12 en mensuel).",
                              notes="Si timestamps irrÃ©guliers â†’ rÃ©Ã©chantillonnage/agrÃ©gation avant SARIMA."
                            ),
                            TERM(
                              "Horizon de prÃ©vision (h)",
                              "Nombre de pas dans le futur Ã  prÃ©dire.",
                              purpose="DÃ©termine ce quâ€™on considÃ¨re Â« bon Â» (court terme vs long terme).",
                              example="h=12 (12 mois dâ€™avance) ; h=7 (7 jours).",
                              formula="h"
                            ),
                            TERM(
                              "Protocole train/test",
                              "DÃ©coupage temporel oÃ¹ lâ€™on entraÃ®ne sur le passÃ© et on Ã©value sur le futur (jamais lâ€™inverse).",
                              purpose="Ã‰valuer la gÃ©nÃ©ralisation sur des dates non vues.",
                              notes="On Ã©vite le mÃ©lange temporel qui crÃ©erait une fuite dâ€™information."
                            ),
                            TERM(
                              "Rolling-origin (origine glissante)",
                              "Ã‰valuation rÃ©pÃ©tÃ©e oÃ¹ lâ€™origine de prÃ©vision avance : on rÃ©-entraÃ®ne/actualise puis on prÃ©dit.",
                              purpose="Mieux reflÃ©ter une utilisation rÃ©elle (le modÃ¨le vit dans le temps).",
                              notes="Plus coÃ»teux, plus robuste que 1 seul split."
                            ),
                            TERM(
                              "MAE",
                              "Moyenne des valeurs absolues des erreurs.",
                              purpose="Lisible, robuste aux gros outliers par rapport Ã  RMSE.",
                              formula="MAE = mean(|y_t - Å·_t|)"
                            ),
                            TERM(
                              "RMSE",
                              "Racine de la moyenne des erreurs quadratiques.",
                              purpose="PÃ©nalise fortement les grandes erreurs.",
                              formula="RMSE = sqrt(mean((y_t - Å·_t)^2))"
                            ),
                            TERM(
                              "MAPE",
                              "Erreur absolue en pourcentage moyen.",
                              purpose="InterprÃ©tation en % quand y_t est strictement positif et loin de 0.",
                              formula="MAPE = mean(|(y_t-Å·_t)/y_t|) Ã— 100",
                              notes="Instable si y_t â‰ˆ 0."
                            ),
                            TERM(
                              "sMAPE",
                              "Version symÃ©trisÃ©e du MAPE : normalise par (|y|+|Å·|).",
                              purpose="RÃ©duit certains problÃ¨mes du MAPE.",
                              formula="sMAPE = mean( 2|y-Å·|/(|y|+|Å·|) ) Ã— 100"
                            ),
                            TERM(
                              "Transformation log",
                              "Transformer y_t en log(y_t) (si y_t>0).",
                              purpose="Stabiliser une variance qui augmente avec le niveau ; transformer multiplicatif â†’ additif.",
                              notes="Toujours expliquer comment on revient Ã  lâ€™Ã©chelle originale."
                            ),
                            TERM(
                              "Boxâ€“Cox",
                              "Famille de transformations paramÃ©trÃ©es (Î») incluant log comme cas particulier.",
                              purpose="Stabiliser variance et amÃ©liorer normalitÃ©/linÃ©aritÃ© des rÃ©sidus.",
                              formula="BC(y; Î») = (y^Î» - 1)/Î» ; log(y) si Î»â†’0"
                            ),
                            TERM(
                              "SARIMA vs SARIMAX",
                              "SARIMA : ARIMA saisonnier univariÃ©. SARIMAX : SARIMA avec variables exogÃ¨nes (X).",
                              purpose="Clarifier si on modÃ©lise uniquement y_t ou y_t avec prÃ©dicteurs.",
                              notes="Si vous avez des covariables â†’ SARIMAX (ou autre modÃ¨le)."
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent (papier)", open = FALSE,
                          S("Template MÃ©thodes â€” DonnÃ©es & Objectif", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (DonnÃ©es & Objectif). "),
                              "Â« Nous avons modÃ©lisÃ© la sÃ©rie temporelle univariÃ©e ", tags$code("y_t"),
                              " observÃ©e Ã  une frÃ©quence [..] de [dÃ©but] Ã  [fin] (n=[..]). ",
                              "Lâ€™objectif Ã©tait de prÃ©voir Ã  un horizon h=[..] pas. ",
                              "La performance a Ã©tÃ© Ã©valuÃ©e avec [MAE/RMSE/â€¦] selon [split temporel / rolling-origin]. ",
                              "Une transformation [aucune / log / Boxâ€“Cox (Î»=[..])] a Ã©tÃ© utilisÃ©e pour [raison]. Â»"
                            )
                          ),
                          S("Conclusion + sens (Ã  Ã©crire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "on fixe y_t, la frÃ©quence, h, le protocole et les mÃ©triques."),
                              tags$li(tags$b("Sens : "), "on rend la modÃ©lisation reproductible ; toute comparaison de modÃ¨les devient valide.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("SARIMA suppose un ", tags$b("espacement rÃ©gulier"), " ; timestamps irrÃ©guliers = problÃ¨me de base."),
                            tags$li("Ne pas confondre une bonne courbe in-sample avec une bonne ", tags$b("performance out-of-sample"), "."),
                            tags$li("MAPE si y_t proche de 0 : souvent une mauvaise idÃ©e."),
                            tags$li("Transformer sans expliquer lâ€™inversion (retour Ã  lâ€™Ã©chelle originale).")
                          )
                        )
        ))
      }
      
      # ============== STEP 1 ==============
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Un SARIMA est aussi bon que vos donnÃ©es : n, dates, frÃ©quence, manque et descriptives doivent Ãªtre rapportÃ©s proprement.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Checklist opÃ©rationnelle", open = TRUE,
                            tags$ol(
                              tags$li("Rapporter : n, dÃ©but/fin, frÃ©quence, % manquants."),
                              tags$li("Diagnostiquer le manque (rare/important ; alÃ©atoire/systÃ©matique)."),
                              tags$li("Traiter : interpolation linÃ©aire/saisonniÃ¨re, ou autre mÃ©thode justifiÃ©e."),
                              tags$li("Calculer descriptives : moyenne, mÃ©diane, ET, min/max, skewness, kurtosis, rÃ©sumÃ©s saisonniers.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("n (taille dâ€™Ã©chantillon)", "Nombre dâ€™observations disponibles.", purpose="Impact direct sur la stabilitÃ© de lâ€™estimation et la fiabilitÃ© des tests."),
                            TERM("Valeur manquante", "Observation absente (NA) sur une date attendue.", purpose="Les NA peuvent casser lâ€™ajustement SARIMA si non traitÃ©s."),
                            TERM("Manque MCAR/MAR/MNAR",
                                 "MCAR: manque complÃ¨tement alÃ©atoire. MAR: manque dÃ©pend dâ€™observables. MNAR: dÃ©pend de la valeur manquante elle-mÃªme.",
                                 purpose="Aide Ã  justifier lâ€™imputation et ses limites.",
                                 notes="En pratique en sÃ©ries temporelles, le manque est souvent structurel (pannes, jours fÃ©riÃ©s, etc.)."),
                            TERM("Interpolation linÃ©aire",
                                 "Imputation par une ligne entre points observÃ©s.",
                                 purpose="Simple, efficace si trous courts et pas de rupture.",
                                 notes="Ã€ Ã©viter si longues pÃ©riodes manquantes."),
                            TERM("Interpolation saisonniÃ¨re",
                                 "Imputation en respectant la saisonnalitÃ© (ex : remplacer un mois manquant par moyenne des mÃªmes mois).",
                                 purpose="Mieux quand la saison est forte.",
                                 notes="Justifier la mÃ©thode ; vÃ©rifier quâ€™elle nâ€™invente pas une saison artificielle."),
                            TERM("Moyenne", "Somme / n.", purpose="Centre de la distribution.", formula="mean(y)"),
                            TERM("MÃ©diane", "Valeur centrale (50e percentile).", purpose="Centre robuste aux outliers."),
                            TERM("Ã‰cart-type (ET)", "Mesure de dispersion autour de la moyenne.", purpose="Quantifie variabilitÃ©.", formula="sd(y)"),
                            TERM("Skewness", "AsymÃ©trie de la distribution.", purpose="DÃ©crit si la masse est tirÃ©e vers la gauche/droite."),
                            TERM("Kurtosis", "Ã‰paisseur des queues (tail heaviness).", purpose="Indique prÃ©sence de valeurs extrÃªmes plus frÃ©quentes.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent (APA)", open = FALSE,
                          S("Template RÃ©sultats â€” Description des donnÃ©es", open = TRUE,
                            tags$p(
                              tags$b("RÃ©sultats (Description des donnÃ©es). "),
                              "Â« La sÃ©rie contient n=[..] observations couvrant [dates] Ã  une frÃ©quence [..]. ",
                              "Les valeurs manquantes reprÃ©sentaient [..]% (k=[..]). Elles ont Ã©tÃ© traitÃ©es via [mÃ©thode] car [raison]. ",
                              "La distribution de ", tags$code("y_t"),
                              " prÃ©sentait une moyenne de [..] (ET=[..]), une mÃ©diane [..], et un intervalle [min,max]. ",
                              "Descriptives saisonniÃ¨res (ex : par mois) : [rÃ©sumÃ©]. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "donnÃ©es dÃ©crites + manque traitÃ© et justifiÃ©."),
                              tags$li(tags$b("Sens : "), "le lecteur comprend la fiabilitÃ© des estimations et la comparabilitÃ© des rÃ©sultats.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer Â« en silence Â» : toujours documenter et justifier."),
                            tags$li("Confondre absence de date et NA : parfois la date nâ€™existe pas (frÃ©quence mal dÃ©finie)."),
                            tags$li("Si log/Boxâ€“Cox : rapporter descriptives aussi sur la sÃ©rie transformÃ©e (au moins briÃ¨vement).")
                          )
                        )
        ))
      }
      
      # ============== STEP 2 ==============
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Les graphiques servent Ã  dÃ©tecter tendance/saison/outliers et Ã  justifier transformations + diffÃ©renciation.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Graphiques Ã  produire", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Courbe temporelle"), " de ", tags$code("y_t"), " (et de log(y_t) si pertinent)."),
                              tags$li(tags$b("Graphique saisonnier"), " (lignes par annÃ©e, couleur par mois, ou seasonal plot)."),
                              tags$li(tags$b("Boxplots par saison"), " (mois/trimestre/semaine)."),
                              tags$li(tags$b("DÃ©tection dâ€™outliers"), " (z-score, IQR, robuste + contexte).")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("Tendance", "Ã‰volution de long terme (hausse/baisse) distincte de la saison.", purpose="Guider d (diffÃ©renciation non saisonniÃ¨re)."),
                            TERM("SaisonnalitÃ©", "Motif qui se rÃ©pÃ¨te Ã  pÃ©riode fixe s (ex : 12 mois).", purpose="Guider D (diffÃ©renciation saisonniÃ¨re) et P/Q.", formula="s"),
                            TERM("Outlier (valeur aberrante)", "Observation atypique par rapport au comportement habituel.", purpose="DÃ©cider : conserver/ajuster/modÃ©liser.",
                                 notes="Un outlier peut Ãªtre un Ã©vÃ©nement rÃ©el (promo, crise) â†’ souvent Ã  conserver."),
                            TERM("Z-score", "Mesure dâ€™Ã©cart en nombre dâ€™ET par rapport Ã  la moyenne.", purpose="RepÃ©rer des points trÃ¨s Ã©loignÃ©s.",
                                 formula="z = (y - mean)/sd", notes="Peu robuste si distribution non gaussienne."),
                            TERM("RÃ¨gle IQR", "Outlier si hors [Q1 âˆ’ 1.5Ã—IQR, Q3 + 1.5Ã—IQR].", purpose="RepÃ©rage robuste.", notes="Ã€ interprÃ©ter avec contexte.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template RÃ©sultats â€” EDA", open = TRUE,
                            tags$p(
                              tags$b("RÃ©sultats (Analyse exploratoire). "),
                              "Â« Lâ€™inspection visuelle indique une tendance [..] et une saisonnalitÃ© de pÃ©riode s=[..]. ",
                              "La variabilitÃ© semblait [constante / croÃ®tre avec le niveau], suggÃ©rant [aucune / log / Boxâ€“Cox]. ",
                              "Des valeurs potentiellement aberrantes autour de [dates] ont Ã©tÃ© [conservÃ©es/ajustÃ©es] car [raison + contexte]. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "tendance/saison/outliers documentÃ©s."),
                              tags$li(tags$b("Sens : "), "on justifie les Ã©tapes suivantes (dÃ©composition, diffÃ©renciation, choix s).")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Supprimer des outliers automatiquement (perte dâ€™Ã©vÃ©nements rÃ©els)."),
                            tags$li("Ignorer que variance â†‘ avec niveau (souvent log/Boxâ€“Cox aide)."),
                            tags$li("Lire la saisonnalitÃ© sur une sÃ©rie trop courte (risque de fausse saison).")
                          )
                        )
        ))
      }
      
      # ============== STEP 3 ==============
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "La dÃ©composition est descriptive : elle clarifie tendance/saison et aide Ã  dÃ©cider additif vs multiplicatif (souvent via log).",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Objectif + choix de forme", open = TRUE,
                            tags$ul(
                              tags$li("DÃ©composer en tendance, saisonnalitÃ©, reste (bruit)."),
                              tags$li("Choisir additif vs multiplicatif selon amplitude saisonniÃ¨re."),
                              tags$li("Utiliser STL si saison Ã©volutive ou outliers.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("DÃ©composition additive",
                                 "y_t = T_t + S_t + e_t.",
                                 purpose="Quand lâ€™amplitude saisonniÃ¨re est Ã  peu prÃ¨s constante.",
                                 formula="y_t = T_t + S_t + e_t"),
                            TERM("DÃ©composition multiplicative",
                                 "y_t = T_t Ã— S_t Ã— e_t.",
                                 purpose="Quand lâ€™amplitude saisonniÃ¨re augmente avec le niveau.",
                                 formula="y_t = T_t Ã— S_t Ã— e_t",
                                 notes="Souvent : log(y_t) transforme le multiplicatif en additif."),
                            TERM("STL",
                                 "Seasonal-Trend decomposition using Loess.",
                                 purpose="Robuste, flexible ; accepte une saisonnalitÃ© qui change lentement.",
                                 notes="TrÃ¨s utile en pratique ; reste descriptif (SARIMA nÃ©cessite stationnaritÃ© via diffÃ©renciation).")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” DÃ©composition", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (DÃ©composition). "),
                              "Â« Nous avons Ã©valuÃ© une structure additive vs multiplicative en examinant lâ€™Ã©volution de lâ€™amplitude saisonniÃ¨re avec le niveau. ",
                              "Comme [..], nous avons utilisÃ© [additif / log puis additif] et dÃ©composÃ© via [classique / STL]. ",
                              "STL a Ã©tÃ© retenue pour sa robustesse aux valeurs aberrantes et sa capacitÃ© Ã  modÃ©liser une saisonnalitÃ© Ã©volutive. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "forme (additive/multiplicative) + mÃ©thode (STL/...) justifiÃ©es."),
                              tags$li(tags$b("Sens : "), "on comprend la structure du signal, ce qui guide transformation et diffÃ©renciation.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Prendre STL comme preuve de stationnaritÃ© (non : câ€™est descriptif)."),
                            tags$li("Oublier que multiplicatif â†” log (ils sont meilleurs amis)."),
                            tags$li("DÃ©composer une sÃ©rie avec frÃ©quence mal spÃ©cifiÃ©e (s incorrect).")
                          )
                        )
        ))
      }
      
      # ============== STEP 4 ==============
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "SARIMA exige que la sÃ©rie soit approximativement stationnaire aprÃ¨s diffÃ©renciation : on choisit d (tendance) et D (saisonnier) en combinant tests + graphiques.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("DÃ©finir la saison (s) + appliquer la diffÃ©renciation", open = TRUE,
                            tags$ul(
                              tags$li("Fixer la pÃ©riode saisonniÃ¨re ", tags$code("s"), " (ex : 12 mensuel, 7 hebdo sur quotidien, 4 trimestriel)."),
                              tags$li("Tester stationnaritÃ© sur : original, aprÃ¨s âˆ‡^d, aprÃ¨s âˆ‡_s^D, et parfois aprÃ¨s les deux."),
                              tags$li("Sâ€™arrÃªter dÃ¨s que stationnaritÃ© raisonnable ; Ã©viter sur-diffÃ©renciation.")
                            )
                          ),
                          
                          S("DÃ©finitions indispensables", open = FALSE,
                            TERM("StationnaritÃ© (faible)",
                                 "Moyenne et variance constantes, autocovariance dÃ©pend seulement du retard.",
                                 purpose="ARMA/SARIMA supposent cette stabilitÃ© aprÃ¨s diffÃ©renciation."),
                            TERM("DiffÃ©renciation ordinaire (d)",
                                 "âˆ‡y_t = y_t - y_{t-1} ; appliquÃ©e d fois.",
                                 purpose="Supprime tendance stochastique (unit root non saisonnier).",
                                 formula="(1-B)^d y_t"),
                            TERM("DiffÃ©renciation saisonniÃ¨re (D)",
                                 "âˆ‡_s y_t = y_t - y_{t-s} ; appliquÃ©e D fois.",
                                 purpose="Supprime racine unitaire saisonniÃ¨re.",
                                 formula="(1-B^s)^D y_t"),
                            TERM("Sur-diffÃ©renciation",
                                 "DiffÃ©rencier trop (d ou D trop grand).",
                                 purpose="Ã€ Ã©viter : dÃ©grade variance/structure et rend le modÃ¨le instable.",
                                 notes="SymptÃ´me typique : ACF trÃ¨s nÃ©gative au lag 1.")
                          ),
                          
                          S("Tests (trÃ¨s dÃ©taillÃ©s, chacun cliquable)", open = FALSE,
                            TEST(
                              name="ADF â€” Augmented Dickeyâ€“Fuller",
                              purpose="DÃ©tecter une racine unitaire (tendance stochastique). On modÃ©lise Î”y_t en fonction de y_{t-1} + retards de Î”y pour absorber lâ€™autocorrÃ©lation.",
                              H0="La sÃ©rie a une racine unitaire â†’ non-stationnaire (les chocs ont des effets persistants).",
                              H1="La sÃ©rie est stationnaire (autour dâ€™une moyenne ou dâ€™une tendance dÃ©terministe selon spÃ©cification).",
                              statistic="Test sur le coefficient de y_{t-1} dans la rÃ©gression ADF (valeurs critiques non standard).",
                              interpretation="p petit â†’ rejet H0 â†’ stationnaritÃ© plausible. p grand â†’ non-rejet â†’ diffÃ©renciation probablement nÃ©cessaire.",
                              conclusion="Si ADF rejette aprÃ¨s (d,D), cela soutient que la sÃ©rie diffÃ©renciÃ©e convient Ã  un SARIMA : les dÃ©pendances restantes peuvent Ãªtre capturÃ©es par AR/MA.",
                              caveats="SensibilitÃ© au choix (drift/trend) et au nombre de retards ; ruptures structurelles peuvent tromper le test."
                            ),
                            TEST(
                              name="KPSS â€” Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin",
                              purpose="ComplÃ©ment de lâ€™ADF : ici la stationnaritÃ© est lâ€™hypothÃ¨se nulle. On mesure si une marche alÃ©atoire rÃ©siduelle est trop forte.",
                              H0="La sÃ©rie est stationnaire (en niveau) ou stationnaire autour dâ€™une tendance (selon version).",
                              H1="La sÃ©rie est non-stationnaire.",
                              statistic="Statistique basÃ©e sur la somme cumulÃ©e des rÃ©sidus + estimation de variance longue.",
                              interpretation="p petit â†’ rejet H0 â†’ non-stationnaire. p grand â†’ compatible avec stationnaritÃ©.",
                              conclusion="KPSS non-significatif aprÃ¨s diffÃ©renciation renforce lâ€™idÃ©e que la transformation a stabilisÃ© la sÃ©rie.",
                              caveats="Choix de bande passante/variance longue ; ruptures â†’ faux rejets."
                            ),
                            TEST(
                              name="PP â€” Phillipsâ€“Perron",
                              purpose="Test de racine unitaire comme ADF mais avec corrections non paramÃ©triques pour autocorrÃ©lation/hÃ©tÃ©roscÃ©dasticitÃ© (au lieu dâ€™ajouter beaucoup de retards).",
                              H0="Racine unitaire â†’ non-stationnaire.",
                              H1="Stationnaire.",
                              statistic="Statistique similaire Ã  DF avec correction de variance.",
                              interpretation="Concordance ADF + PP = argument plus solide ; dÃ©saccord = vÃ©rifier spÃ©cification et diagnostics.",
                              conclusion="Rejet H0 par PP aprÃ¨s (d,D) = cohÃ©rent avec une sÃ©rie diffÃ©renciÃ©e stationnaire, prÃªte pour SARIMA.",
                              caveats="Comme ADF : dÃ©pend de drift/trend ; breaks peuvent biaiser."
                            )
                          ),
                          
                          S("InterprÃ©ter ADF/KPSS/PP ensemble (logique de conclusion)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Accord stationnaire : "), "ADF/PP rejettent (p petit) + KPSS ne rejette pas (p grand) â†’ stationnaritÃ© fortement plausible."),
                              tags$li(tags$b("Accord non-stationnaire : "), "ADF/PP ne rejettent pas (p grand) + KPSS rejette (p petit) â†’ diffÃ©renciation nÃ©cessaire."),
                              tags$li(tags$b("Conflits : "), "se reposer sur convergence : graphiques + ACF + rÃ©sultats aprÃ¨s diffÃ©renciation. Ã‰crire que la dÃ©cision repose sur lâ€™ensemble des indices (pas une seule p-value).")
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” StationnaritÃ© & diffÃ©renciation", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (StationnaritÃ© & diffÃ©renciation). "),
                              "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e par ADF, KPSS et PP afin de trianguler lâ€™Ã©vidence (hypothÃ¨ses nulles diffÃ©rentes). ",
                              "Sur la base des tests, des diagnostics visuels et de lâ€™ACF, nous avons retenu d=[..] et D=[..] avec pÃ©riode saisonniÃ¨re s=[..]. ",
                              "Ce choix vise Ã  supprimer tendance et/ou racine unitaire saisonniÃ¨re tout en Ã©vitant la sur-diffÃ©renciation ; la stationnaritÃ© a Ã©tÃ© revÃ©rifiÃ©e aprÃ¨s transformation. Â»"
                            )
                          ),
                          S("Conclusion + sens (Ã  Ã©crire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "d=[..], D=[..], s=[..] retenus."),
                              tags$li(tags$b("Sens : "), "le SARIMA expliquera la dÃ©pendance restante (AR/MA) sur une sÃ©rie stabilisÃ©e (stationnaire) â€” donc des paramÃ¨tres interprÃ©tables et des prÃ©visions plus fiables.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li(tags$b("Sur-diffÃ©renciation : "), "ACF lag1 trÃ¨s nÃ©gative, variance gonflÃ©e, prÃ©visions instables."),
                            tags$li("D vaut souvent 0 ou 1 ; si D=2, vÃ©rifier s et la qualitÃ© des donnÃ©es."),
                            tags$li("Oublier de tester avec/sans trend/drift : peut inverser la conclusion.")
                          )
                        )
        ))
      }
      
      # ============== STEP 5 ==============
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Auto-ARIMA fournit une baseline (bon point de dÃ©part), pas une vÃ©ritÃ© absolue. On documente critÃ¨res, contraintes et transformations.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("ProcÃ©dure", open = TRUE,
                            tags$ul(
                              tags$li("Lancer auto-ARIMA (souvent AICc) pour proposer ", tags$code("(p,d,q)(P,D,Q)[s]"), "."),
                              tags$li("Documenter : transformations, contraintes max p/q/P/Q, stepwise vs exhaustive."),
                              tags$li("Garder une baseline + la comparer au manuel + benchmark naÃ¯f.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("AIC / AICc / BIC",
                                 "CritÃ¨res dâ€™information : compromis ajustement vs complexitÃ© (pÃ©nalisation). AICc corrige AIC pour petits Ã©chantillons.",
                                 purpose="Comparer des modÃ¨les sur la mÃªme sÃ©rie (mÃªme transformation) en pÃ©nalisant la complexitÃ©.",
                                 notes="Un meilleur AICc nâ€™assure pas de meilleurs forecasts out-of-sample."),
                            TERM("Stepwise",
                                 "Recherche heuristique qui explore un sous-ensemble de modÃ¨les pour aller vite.",
                                 purpose="AccÃ©lÃ©rer la sÃ©lection quand lâ€™espace des modÃ¨les est grand.",
                                 notes="Peut rater le meilleur modÃ¨le global, mais donne souvent une bonne baseline.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” ModÃ¨le de rÃ©fÃ©rence", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (Baseline). "),
                              "Â« Un modÃ¨le SARIMA de rÃ©fÃ©rence a Ã©tÃ© sÃ©lectionnÃ© via une procÃ©dure automatisÃ©e basÃ©e sur la minimisation de lâ€™AICc parmi des ordres candidats sous contraintes [..]. ",
                              "La spÃ©cification retenue Ã©tait SARIMA((p,d,q)(P,D,Q)[s]) et a servi de point de dÃ©part pour des ajustements ultÃ©rieurs guidÃ©s par les diagnostics. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "baseline dÃ©finie et reproductible."),
                              tags$li(tags$b("Sens : "), "point de comparaison : on nâ€™Ã©value pas le manuel Â« dans le vide Â».")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Croire auto-ARIMA Â« final Â» : toujours vÃ©rifier diagnostics et performance."),
                            tags$li("Choisir uniquement AICc sans test out-of-sample."),
                            tags$li("Comparer des modÃ¨les sur des sÃ©ries transformÃ©es diffÃ©remment (incomparable).")
                          )
                        )
        ))
      }
      
      # ============== STEP 6 ==============
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "ACF/PACF guident la proposition de quelques modÃ¨les plausibles (3â€“8). On privilÃ©gie parcimonie + diagnostics propres.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("ProcÃ©dure guidÃ©e par ACF/PACF", open = TRUE,
                            tags$ol(
                              tags$li("Travailler sur la sÃ©rie diffÃ©renciÃ©e (aprÃ¨s choix de d et D)."),
                              tags$li("Tracer ACF et PACF."),
                              tags$li("Proposer quelques candidats (p,q,P,Q) plausibles."),
                              tags$li("Ajuster, comparer (AICc/BIC) + stabilitÃ©/inversibilitÃ© + diagnostics.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("ACF",
                                 "Fonction dâ€™autocorrÃ©lation : corr(y_t, y_{t-k}).",
                                 purpose="Identifier composantes MA (coupure) et saisonnalitÃ© (pics aux multiples de s).",
                                 notes="Sur sÃ©rie stationnaire (souvent aprÃ¨s diffÃ©renciation)."),
                            TERM("PACF",
                                 "AutocorrÃ©lation partielle : corr(y_t, y_{t-k} | lags intermÃ©diaires).",
                                 purpose="Identifier composantes AR (coupure)."),
                            TERM("AR(p)",
                                 "ModÃ¨le auto-rÃ©gressif : y_t dÃ©pend de ses p retards.",
                                 purpose="Capturer persistance / inertie.",
                                 formula="y_t = c + Î£ Ï†_i y_{t-i} + Îµ_t"),
                            TERM("MA(q)",
                                 "Moyenne mobile : y_t dÃ©pend des q erreurs passÃ©es.",
                                 purpose="Capturer chocs transitoires.",
                                 formula="y_t = c + Îµ_t + Î£ Î¸_i Îµ_{t-i}"),
                            TERM("Saisonnier P/Q",
                                 "Composantes AR/MA aux multiples de s.",
                                 purpose="Capturer dÃ©pendances qui reviennent chaque saison (ex : annÃ©e sur annÃ©e).",
                                 notes="Pics Ã  s, 2s, 3sâ€¦ dans ACF/PACF.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” Construction guidÃ©e", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (GuidÃ©e par ACF/PACF). "),
                              "Â« Les structures candidates ont Ã©tÃ© proposÃ©es dâ€™aprÃ¨s lâ€™ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. ",
                              "Des motifs aux faibles retards suggÃ©raient des termes non saisonniers (p,q), tandis que des pics aux multiples de s suggÃ©raient des termes saisonniers (P,Q). ",
                              "Un petit ensemble de modÃ¨les plausibles a Ã©tÃ© ajustÃ© et comparÃ© via [AICc/BIC] et diagnostics, en privilÃ©giant la parcimonie. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "liste de candidats raisonnÃ©s + justification ACF/PACF."),
                              tags$li(tags$b("Sens : "), "on limite le sur-ajustement et on garde une interprÃ©tabilitÃ© pÃ©dagogique.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Bruteforce de centaines de modÃ¨les (pas Â« thÃ©orie Â»)."),
                            tags$li("Lire ACF/PACF sur sÃ©rie non stationnaire."),
                            tags$li("Oublier stabilitÃ©/inversibilitÃ© : un modÃ¨le peut fitter mais Ãªtre instable.")
                          )
                        )
        ))
      }
      
      # ============== STEP 7 ==============
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Le modÃ¨le final doit : (1) rÃ©sidus ~ bruit blanc (pas dâ€™autocorrÃ©lation), (2) battre un benchmark, (3) rester simple si performance similaire.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Diagnostics rÃ©sidus (indispensable)", open = TRUE,
                            tags$ul(
                              tags$li("Tracer rÃ©sidus (aspect bruit)."),
                              tags$li("ACF rÃ©sidus (pas de pics majeurs)."),
                              tags$li(tags$b("Ljungâ€“Box"), " : tester lâ€™autocorrÃ©lation rÃ©siduelle."),
                              tags$li("NormalitÃ© (QQ-plot ; Shapiro-Wilk trop sensible si grand n)."),
                              tags$li("HÃ©tÃ©roscÃ©dasticitÃ© / ARCH (si finance).")
                            )
                          ),
                          
                          S("Tests & dÃ©finitions (cliquables)", open = FALSE,
                            TERM("RÃ©sidu", "r_t = y_t âˆ’ Å·_t (erreur in-sample).", purpose="Les rÃ©sidus doivent Ãªtre Â« bruit blanc Â» pour un modÃ¨le bien spÃ©cifiÃ©.", formula="r_t = y_t - Å·_t"),
                            TERM("Bruit blanc", "SÃ©rie de moyenne 0, variance constante, sans autocorrÃ©lation significative.", purpose="Cible des diagnostics rÃ©siduels."),
                            TEST(
                              name="Ljungâ€“Box",
                              purpose="VÃ©rifier si les rÃ©sidus prÃ©sentent encore de lâ€™autocorrÃ©lation (globalement jusquâ€™Ã  un lag L).",
                              H0="Pas dâ€™autocorrÃ©lation rÃ©siduelle jusquâ€™au lag L (rÃ©sidus compatibles bruit blanc).",
                              H1="AutocorrÃ©lation rÃ©siduelle prÃ©sente.",
                              statistic="Q(L) agrÃ¨ge les autocorrÃ©lations rÃ©siduelles ; p-value associÃ©e.",
                              interpretation="p â‰¥ Î± : pas dâ€™Ã©vidence forte dâ€™autocorrÃ©lation ; p < Î± : structure restante â†’ revoir (p,q,P,Q,d,D).",
                              conclusion="Si non significatif, cela soutient que le SARIMA a capturÃ© la dÃ©pendance temporelle pertinente ; sinon, le modÃ¨le est incomplet.",
                              caveats="Choix de L important ; trop grand L peut sur-dÃ©tecter ; dÃ©pend du fitdf."
                            ),
                            TEST(
                              name="Jarqueâ€“Bera (optionnel)",
                              purpose="Tester si la distribution des rÃ©sidus est proche dâ€™une normale (skewness + kurtosis).",
                              H0="RÃ©sidus ~ normale.",
                              H1="RÃ©sidus non normaux.",
                              interpretation="Souvent rejetÃ© en pratique (queues Ã©paisses). La non-normalitÃ© nâ€™est pas toujours critique pour la prÃ©vision.",
                              conclusion="Si rejet, on interprÃ¨te : queues Ã©paisses possibles â†’ intervalles de prÃ©vision peuvent Ãªtre optimistes si on suppose normalitÃ©.",
                              caveats="TrÃ¨s sensible avec grands Ã©chantillons."
                            )
                          ),
                          
                          S("Ã‰valuation prÃ©vision (indispensable)", open = FALSE,
                            tags$ul(
                              tags$li("Utiliser test set ou rolling-origin."),
                              tags$li("MÃ©triques : MAE/RMSE (MAPE si y jamais proche de 0)."),
                              tags$li("Comparer : baseline auto-ARIMA, manuel, benchmark naÃ¯f (et naÃ¯f saisonnier).")
                            )
                          ),
                          
                          S("RÃ¨gle saine de sÃ©lection finale", open = FALSE,
                            tags$ul(
                              tags$li("Diagnostics OK (rÃ©sidus ~ bruit blanc)."),
                              tags$li("Performance > benchmark naÃ¯f."),
                              tags$li("Si performances proches : choisir le modÃ¨le le plus simple.")
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template RÃ©sultats â€” Diagnostics & performance", open = TRUE,
                            tags$p(
                              tags$b("RÃ©sultats (Diagnostics & performance). "),
                              "Â« Les diagnostics rÃ©siduels suggÃ©raient un comportement proche du bruit blanc : lâ€™ACF des rÃ©sidus ne montrait pas de pics marquÃ©s, et le test de Ljungâ€“Box Ã©tait [non significatif/significatif] (Î±=[..]). ",
                              "Sur la fenÃªtre dâ€™Ã©valuation, la performance de prÃ©vision donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. ",
                              "Le modÃ¨le final retenu Ã©tait SARIMA((p,d,q)(P,D,Q)[s]) sur la base de lâ€™adÃ©quation diagnostique et de la performance prÃ©dictive. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "modÃ¨le final + mÃ©triques + diagnostics prÃ©sentÃ©s."),
                              tags$li(tags$b("Sens : "), "un SARIMA nâ€™est Â« bon Â» que sâ€™il gÃ©nÃ©ralise ET laisse des rÃ©sidus sans structure temporelle.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Choisir AIC excellent mais rÃ©sidus autocorrÃ©lÃ©s (modÃ¨le incomplet)."),
                            tags$li("Sur-interprÃ©ter la non-normalitÃ© : lâ€™autocorrÃ©lation rÃ©siduelle est plus grave pour la prÃ©vision."),
                            tags$li("Comparer des modÃ¨les avec des splits temporels diffÃ©rents.")
                          )
                        )
        ))
      }
      
      # ============== STEP 8 ==============
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Votre rapport doit Ãªtre alignÃ© sur le pipeline : MÃ©thodes (ce que vous avez fait + pourquoi) puis RÃ©sultats (ce que vous avez observÃ© + conclusion).",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Checklist MÃ©thodes", open = TRUE,
                            tags$ul(
                              tags$li("DonnÃ©es : source, dates, frÃ©quence, manque, transformation."),
                              tags$li("EDA : graphiques + dÃ©composition."),
                              tags$li("StationnaritÃ© : tests + choix (d,D,s)."),
                              tags$li("Baseline auto-ARIMA (critÃ¨re/contraintes)."),
                              tags$li("Candidats manuels (ACF/PACF + parcimonie)."),
                              tags$li("Diagnostics et protocole dâ€™Ã©valuation.")
                            )
                          ),
                          S("Checklist RÃ©sultats", open = TRUE,
                            tags$ul(
                              tags$li("Description des donnÃ©es + observations clÃ©s."),
                              tags$li("DÃ©composition : tendance/saison."),
                              tags$li("Tests stationnaritÃ© + d/D retenus."),
                              tags$li("ParamÃ¨tres modÃ¨le final."),
                              tags$li("Diagnostics + mÃ©triques + figure de prÃ©vision."),
                              tags$li("Tableau comparatif (AICc + erreurs).")
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Structure APA (ultra pratique)", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Pour chaque sous-section : "), "Ce quâ€™on a fait â†’ Pourquoi â†’ Ce quâ€™on observe â†’ Conclusion."),
                              tags$li("Temps verbal : passÃ© en MÃ©thodes, passÃ© orientÃ© rÃ©sultats en RÃ©sultats."),
                              tags$li("Ã‰crire la spÃ©cification complÃ¨te une fois clairement : ", tags$code("SARIMA((p,d,q)(P,D,Q)[s])"), ".")
                            ),
                            S("Ã‰quation SARIMA (notation)", open = FALSE,
                              tags$ul(
                                tags$li(
                                  tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
                                  " avec innovations ",
                                  tags$code("Îµ_t ~ w.n.(0, Ïƒ^2)")
                                )
                              ),
                              tags$p(class="small",
                                     "InterprÃ©tation : aprÃ¨s diffÃ©renciation (âˆ‡^d et âˆ‡_s^D), la dÃ©pendance restante est modÃ©lisÃ©e par des polynÃ´mes AR (Ï†, Î¦) et MA (Î¸, Î˜).")
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "rapport structurÃ© = reproductible + pÃ©dagogique."),
                              tags$li(tags$b("Sens : "), "le lecteur peut refaire exactement vos Ã©tapes et comprendre vos choix.")
                            )
                          )
                        ),
                        
                        D("Pack livrable attendu", open = FALSE,
                          tags$ul(
                            tags$li(
                              tags$b("Notebook/script : "),
                              tags$ul(
                                tags$li("chargement + nettoyage + frÃ©quence"),
                                tags$li("manquants + transformations"),
                                tags$li("EDA + dÃ©composition"),
                                tags$li("tests stationnaritÃ© + choix d/D/s"),
                                tags$li("auto-ARIMA baseline"),
                                tags$li("candidats manuels"),
                                tags$li("diagnostics + Ã©valuation"),
                                tags$li("prÃ©vision finale + intervalles")
                              )
                            ),
                            tags$li(
                              tags$b("Rapport court : "),
                              tags$ul(
                                tags$li("MÃ©thodes/RÃ©sultats alignÃ©s Ã©tapes 0â€“7"),
                                tags$li("figures : sÃ©rie, dÃ©composition, ACF/PACF, rÃ©sidus, prÃ©vision"),
                                tags$li("tableau : AICc + MAE/RMSE (candidats)")
                              )
                            )
                          )
                        )
        ))
      }
      
      # fallback (should never happen)
      tags$div(class="road-card", "Ã‰tape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (trÃ¨s dÃ©taillÃ©e) â€” FR"),
                          tags$p(class="road-sub",
                                 "Naviguez par Ã©tape avec le slider. Ouvrez seulement ce dont vous avez besoin via les sections repliables.")
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Ã‰tape (utilisez le slider â€” pas besoin de dÃ©filer)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               # Step content
               step_content(k)
      )
    )
  })
  

  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  # ============================================================
  # UI (add this where you want the roadmap to appear)
  # ============================================================
  # uiOutput("roadmap_Detailed_Fr_ui")
  
  
  # ============================================================
  # SERVER (FULL COPY-PASTE) â€” Roadmap SARIMA FR + Slider + Collapsibles
  # Put this inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui6 <- renderUI({
    
    # ----------------------------
    # Helpers: nested collapsibles
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    
    # Big blocks per step
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1")
    # Sub-blocks inside big blocks
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2")
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, example = NULL, formula = NULL, notes = NULL, open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 tags$p(tags$b("DÃ©finition : "), definition),
                 if (!is.null(purpose)) tags$p(tags$b("But / utilitÃ© : "), purpose) else NULL,
                 if (!is.null(formula)) tags$p(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example)) tags$p(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(notes))   tags$p(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name, purpose, H0, H1,
                     statistic = NULL, interpretation = NULL, conclusion = NULL, caveats = NULL, open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 tags$p(tags$b("But / utilitÃ© : "), purpose),
                 tags$p(tags$b("H0 : "), H0),
                 tags$p(tags$b("H1 : "), H1),
                 if (!is.null(statistic))      tags$p(tags$b("Statistique (idÃ©e) : "), statistic) else NULL,
                 if (!is.null(interpretation)) tags$p(tags$b("InterprÃ©tation : "), interpretation) else NULL,
                 if (!is.null(conclusion))     tags$p(tags$b("Conclusion + sens : "), conclusion) else NULL,
                 if (!is.null(caveats))        tags$p(tags$b("PiÃ¨ges / limites : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .eq {font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step builder
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] PrÃ©parer le terrain : dÃ©finir le problÃ¨me",
        "[1] DÃ©crire les donnÃ©es : n, manque, descriptives",
        "[2] Explorer visuellement : tendance, saison, outliers",
        "[3] DÃ©composer : additif vs multiplicatif, STL",
        "[4] StationnaritÃ© : ADF/KPSS/PP, choisir d & D",
        "[5] ModÃ¨le de rÃ©fÃ©rence : Auto-ARIMA (AICc)",
        "[6] ModÃ¨le guidÃ© par thÃ©orie : ACF/PACF + candidats",
        "[7] Diagnostiquer & comparer : rÃ©sidus + prÃ©cision",
        "[8] RÃ©diger le rapport : MÃ©thodes/RÃ©sultats + livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "DonnÃ©es", "Ã‰valuation"),
        c("QualitÃ© donnÃ©es", "Manquants", "Stat descriptives"),
        c("Graphiques", "SaisonnalitÃ©", "Anomalies"),
        c("Tendance", "Saison", "STL"),
        c("StationnaritÃ©", "DiffÃ©renciation", "Tests"),
        c("Auto-ARIMA", "AICc/BIC", "Baseline"),
        c("ACF/PACF", "Candidats", "Parcimonie"),
        c("Diagnostics", "Ljungâ€“Box", "Forecast accuracy"),
        c("APA", "SynthÃ¨se", "Livrables")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ------------------------------------------------------------
    # CONTENT (extremely detailed but organized via collapsibles)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # ============== STEP 0 ==============
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Avant toute SARIMA, on fige exactement : la sÃ©rie cible (y_t), le calendrier (frÃ©quence rÃ©guliÃ¨re), lâ€™horizon, le protocole dâ€™Ã©valuation et la (les) mÃ©triques. ",
                          "Sans Ã§a, on obtient des modÃ¨les Â« corrects Â» mais inutilisables.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Checklist opÃ©rationnelle", open = TRUE,
                            tags$ul(
                              tags$li("DÃ©finir la ", tags$b("sÃ©rie rÃ©ponse"), " : ", tags$code("y_t"), " (ce que lâ€™on prÃ©voit)."),
                              tags$li("DÃ©finir lâ€™", tags$b("indice temporel"), " (quotidien/hebdomadaire/mensuel) et vÃ©rifier la ", tags$b("rÃ©gularitÃ©"), " (pas de trous ni doublons)."),
                              tags$li("DÃ©finir la ", tags$b("tÃ¢che de prÃ©vision"), " : horizon ", tags$code("h"), ", protocole (train/test ou rolling-origin), mÃ©trique(s) (MAE/RMSE/MAPE/sMAPE)."),
                              tags$li("Choisir lâ€™Ã©chelle : niveaux / log / Boxâ€“Cox (et justifier)."),
                              tags$li("DÃ©finir le benchmark : naÃ¯f (et naÃ¯f saisonnier si saison).")
                            )
                          ),
                          
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM(
                              "SÃ©rie rÃ©ponse (y_t)",
                              "Variable temporelle univariÃ©e que lâ€™on veut expliquer et prÃ©voir. Chaque observation correspond Ã  un instant t.",
                              purpose="DÃ©termine lâ€™objet du modÃ¨le (la cible) et le type de prÃ©vision produit.",
                              formula="y_t",
                              notes="SARIMA classique est univariÃ© (pas de prÃ©dicteurs)."
                            ),
                            TERM(
                              "Indice temporel & frÃ©quence",
                              "Lâ€™index temporel est la sÃ©quence des dates/temps. La frÃ©quence est lâ€™espacement rÃ©gulier (jour, semaine, moisâ€¦).",
                              purpose="SARIMA suppose des intervalles constants ; la frÃ©quence fixe la saisonnalitÃ© (ex : s=12 en mensuel).",
                              notes="Si timestamps irrÃ©guliers â†’ rÃ©Ã©chantillonnage/agrÃ©gation avant SARIMA."
                            ),
                            TERM(
                              "Horizon de prÃ©vision (h)",
                              "Nombre de pas dans le futur Ã  prÃ©dire.",
                              purpose="DÃ©termine ce quâ€™on considÃ¨re Â« bon Â» (court terme vs long terme).",
                              example="h=12 (12 mois dâ€™avance) ; h=7 (7 jours).",
                              formula="h"
                            ),
                            TERM(
                              "Protocole train/test",
                              "DÃ©coupage temporel oÃ¹ lâ€™on entraÃ®ne sur le passÃ© et on Ã©value sur le futur (jamais lâ€™inverse).",
                              purpose="Ã‰valuer la gÃ©nÃ©ralisation sur des dates non vues.",
                              notes="On Ã©vite le mÃ©lange temporel qui crÃ©erait une fuite dâ€™information."
                            ),
                            TERM(
                              "Rolling-origin (origine glissante)",
                              "Ã‰valuation rÃ©pÃ©tÃ©e oÃ¹ lâ€™origine de prÃ©vision avance : on rÃ©-entraÃ®ne/actualise puis on prÃ©dit.",
                              purpose="Mieux reflÃ©ter une utilisation rÃ©elle (le modÃ¨le vit dans le temps).",
                              notes="Plus coÃ»teux, plus robuste que 1 seul split."
                            ),
                            TERM(
                              "MAE",
                              "Moyenne des valeurs absolues des erreurs.",
                              purpose="Lisible, robuste aux gros outliers par rapport Ã  RMSE.",
                              formula="MAE = mean(|y_t - Å·_t|)"
                            ),
                            TERM(
                              "RMSE",
                              "Racine de la moyenne des erreurs quadratiques.",
                              purpose="PÃ©nalise fortement les grandes erreurs.",
                              formula="RMSE = sqrt(mean((y_t - Å·_t)^2))"
                            ),
                            TERM(
                              "MAPE",
                              "Erreur absolue en pourcentage moyen.",
                              purpose="InterprÃ©tation en % quand y_t est strictement positif et loin de 0.",
                              formula="MAPE = mean(|(y_t-Å·_t)/y_t|) Ã— 100",
                              notes="Instable si y_t â‰ˆ 0."
                            ),
                            TERM(
                              "sMAPE",
                              "Version symÃ©trisÃ©e du MAPE : normalise par (|y|+|Å·|).",
                              purpose="RÃ©duit certains problÃ¨mes du MAPE.",
                              formula="sMAPE = mean( 2|y-Å·|/(|y|+|Å·|) ) Ã— 100"
                            ),
                            TERM(
                              "Transformation log",
                              "Transformer y_t en log(y_t) (si y_t>0).",
                              purpose="Stabiliser une variance qui augmente avec le niveau ; transformer multiplicatif â†’ additif.",
                              notes="Toujours expliquer comment on revient Ã  lâ€™Ã©chelle originale."
                            ),
                            TERM(
                              "Boxâ€“Cox",
                              "Famille de transformations paramÃ©trÃ©es (Î») incluant log comme cas particulier.",
                              purpose="Stabiliser variance et amÃ©liorer normalitÃ©/linÃ©aritÃ© des rÃ©sidus.",
                              formula="BC(y; Î») = (y^Î» - 1)/Î» ; log(y) si Î»â†’0"
                            ),
                            TERM(
                              "SARIMA vs SARIMAX",
                              "SARIMA : ARIMA saisonnier univariÃ©. SARIMAX : SARIMA avec variables exogÃ¨nes (X).",
                              purpose="Clarifier si on modÃ©lise uniquement y_t ou y_t avec prÃ©dicteurs.",
                              notes="Si vous avez des covariables â†’ SARIMAX (ou autre modÃ¨le)."
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent (papier)", open = FALSE,
                          S("Template MÃ©thodes â€” DonnÃ©es & Objectif", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (DonnÃ©es & Objectif). "),
                              "Â« Nous avons modÃ©lisÃ© la sÃ©rie temporelle univariÃ©e ", tags$code("y_t"),
                              " observÃ©e Ã  une frÃ©quence [..] de [dÃ©but] Ã  [fin] (n=[..]). ",
                              "Lâ€™objectif Ã©tait de prÃ©voir Ã  un horizon h=[..] pas. ",
                              "La performance a Ã©tÃ© Ã©valuÃ©e avec [MAE/RMSE/â€¦] selon [split temporel / rolling-origin]. ",
                              "Une transformation [aucune / log / Boxâ€“Cox (Î»=[..])] a Ã©tÃ© utilisÃ©e pour [raison]. Â»"
                            )
                          ),
                          S("Conclusion + sens (Ã  Ã©crire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "on fixe y_t, la frÃ©quence, h, le protocole et les mÃ©triques."),
                              tags$li(tags$b("Sens : "), "on rend la modÃ©lisation reproductible ; toute comparaison de modÃ¨les devient valide.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("SARIMA suppose un ", tags$b("espacement rÃ©gulier"), " ; timestamps irrÃ©guliers = problÃ¨me de base."),
                            tags$li("Ne pas confondre une bonne courbe in-sample avec une bonne ", tags$b("performance out-of-sample"), "."),
                            tags$li("MAPE si y_t proche de 0 : souvent une mauvaise idÃ©e."),
                            tags$li("Transformer sans expliquer lâ€™inversion (retour Ã  lâ€™Ã©chelle originale).")
                          )
                        )
        ))
      }
      
      # ============== STEP 1 ==============
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Un SARIMA est aussi bon que vos donnÃ©es : n, dates, frÃ©quence, manque et descriptives doivent Ãªtre rapportÃ©s proprement.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Checklist opÃ©rationnelle", open = TRUE,
                            tags$ol(
                              tags$li("Rapporter : n, dÃ©but/fin, frÃ©quence, % manquants."),
                              tags$li("Diagnostiquer le manque (rare/important ; alÃ©atoire/systÃ©matique)."),
                              tags$li("Traiter : interpolation linÃ©aire/saisonniÃ¨re, ou autre mÃ©thode justifiÃ©e."),
                              tags$li("Calculer descriptives : moyenne, mÃ©diane, ET, min/max, skewness, kurtosis, rÃ©sumÃ©s saisonniers.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("n (taille dâ€™Ã©chantillon)", "Nombre dâ€™observations disponibles.", purpose="Impact direct sur la stabilitÃ© de lâ€™estimation et la fiabilitÃ© des tests."),
                            TERM("Valeur manquante", "Observation absente (NA) sur une date attendue.", purpose="Les NA peuvent casser lâ€™ajustement SARIMA si non traitÃ©s."),
                            TERM("Manque MCAR/MAR/MNAR",
                                 "MCAR: manque complÃ¨tement alÃ©atoire. MAR: manque dÃ©pend dâ€™observables. MNAR: dÃ©pend de la valeur manquante elle-mÃªme.",
                                 purpose="Aide Ã  justifier lâ€™imputation et ses limites.",
                                 notes="En pratique en sÃ©ries temporelles, le manque est souvent structurel (pannes, jours fÃ©riÃ©s, etc.)."),
                            TERM("Interpolation linÃ©aire",
                                 "Imputation par une ligne entre points observÃ©s.",
                                 purpose="Simple, efficace si trous courts et pas de rupture.",
                                 notes="Ã€ Ã©viter si longues pÃ©riodes manquantes."),
                            TERM("Interpolation saisonniÃ¨re",
                                 "Imputation en respectant la saisonnalitÃ© (ex : remplacer un mois manquant par moyenne des mÃªmes mois).",
                                 purpose="Mieux quand la saison est forte.",
                                 notes="Justifier la mÃ©thode ; vÃ©rifier quâ€™elle nâ€™invente pas une saison artificielle."),
                            TERM("Moyenne", "Somme / n.", purpose="Centre de la distribution.", formula="mean(y)"),
                            TERM("MÃ©diane", "Valeur centrale (50e percentile).", purpose="Centre robuste aux outliers."),
                            TERM("Ã‰cart-type (ET)", "Mesure de dispersion autour de la moyenne.", purpose="Quantifie variabilitÃ©.", formula="sd(y)"),
                            TERM("Skewness", "AsymÃ©trie de la distribution.", purpose="DÃ©crit si la masse est tirÃ©e vers la gauche/droite."),
                            TERM("Kurtosis", "Ã‰paisseur des queues (tail heaviness).", purpose="Indique prÃ©sence de valeurs extrÃªmes plus frÃ©quentes.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent (APA)", open = FALSE,
                          S("Template RÃ©sultats â€” Description des donnÃ©es", open = TRUE,
                            tags$p(
                              tags$b("RÃ©sultats (Description des donnÃ©es). "),
                              "Â« La sÃ©rie contient n=[..] observations couvrant [dates] Ã  une frÃ©quence [..]. ",
                              "Les valeurs manquantes reprÃ©sentaient [..]% (k=[..]). Elles ont Ã©tÃ© traitÃ©es via [mÃ©thode] car [raison]. ",
                              "La distribution de ", tags$code("y_t"),
                              " prÃ©sentait une moyenne de [..] (ET=[..]), une mÃ©diane [..], et un intervalle [min,max]. ",
                              "Descriptives saisonniÃ¨res (ex : par mois) : [rÃ©sumÃ©]. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "donnÃ©es dÃ©crites + manque traitÃ© et justifiÃ©."),
                              tags$li(tags$b("Sens : "), "le lecteur comprend la fiabilitÃ© des estimations et la comparabilitÃ© des rÃ©sultats.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer Â« en silence Â» : toujours documenter et justifier."),
                            tags$li("Confondre absence de date et NA : parfois la date nâ€™existe pas (frÃ©quence mal dÃ©finie)."),
                            tags$li("Si log/Boxâ€“Cox : rapporter descriptives aussi sur la sÃ©rie transformÃ©e (au moins briÃ¨vement).")
                          )
                        )
        ))
      }
      
      # ============== STEP 2 ==============
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Les graphiques servent Ã  dÃ©tecter tendance/saison/outliers et Ã  justifier transformations + diffÃ©renciation.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Graphiques Ã  produire", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Courbe temporelle"), " de ", tags$code("y_t"), " (et de log(y_t) si pertinent)."),
                              tags$li(tags$b("Graphique saisonnier"), " (lignes par annÃ©e, couleur par mois, ou seasonal plot)."),
                              tags$li(tags$b("Boxplots par saison"), " (mois/trimestre/semaine)."),
                              tags$li(tags$b("DÃ©tection dâ€™outliers"), " (z-score, IQR, robuste + contexte).")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("Tendance", "Ã‰volution de long terme (hausse/baisse) distincte de la saison.", purpose="Guider d (diffÃ©renciation non saisonniÃ¨re)."),
                            TERM("SaisonnalitÃ©", "Motif qui se rÃ©pÃ¨te Ã  pÃ©riode fixe s (ex : 12 mois).", purpose="Guider D (diffÃ©renciation saisonniÃ¨re) et P/Q.", formula="s"),
                            TERM("Outlier (valeur aberrante)", "Observation atypique par rapport au comportement habituel.", purpose="DÃ©cider : conserver/ajuster/modÃ©liser.",
                                 notes="Un outlier peut Ãªtre un Ã©vÃ©nement rÃ©el (promo, crise) â†’ souvent Ã  conserver."),
                            TERM("Z-score", "Mesure dâ€™Ã©cart en nombre dâ€™ET par rapport Ã  la moyenne.", purpose="RepÃ©rer des points trÃ¨s Ã©loignÃ©s.",
                                 formula="z = (y - mean)/sd", notes="Peu robuste si distribution non gaussienne."),
                            TERM("RÃ¨gle IQR", "Outlier si hors [Q1 âˆ’ 1.5Ã—IQR, Q3 + 1.5Ã—IQR].", purpose="RepÃ©rage robuste.", notes="Ã€ interprÃ©ter avec contexte.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template RÃ©sultats â€” EDA", open = TRUE,
                            tags$p(
                              tags$b("RÃ©sultats (Analyse exploratoire). "),
                              "Â« Lâ€™inspection visuelle indique une tendance [..] et une saisonnalitÃ© de pÃ©riode s=[..]. ",
                              "La variabilitÃ© semblait [constante / croÃ®tre avec le niveau], suggÃ©rant [aucune / log / Boxâ€“Cox]. ",
                              "Des valeurs potentiellement aberrantes autour de [dates] ont Ã©tÃ© [conservÃ©es/ajustÃ©es] car [raison + contexte]. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "tendance/saison/outliers documentÃ©s."),
                              tags$li(tags$b("Sens : "), "on justifie les Ã©tapes suivantes (dÃ©composition, diffÃ©renciation, choix s).")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Supprimer des outliers automatiquement (perte dâ€™Ã©vÃ©nements rÃ©els)."),
                            tags$li("Ignorer que variance â†‘ avec niveau (souvent log/Boxâ€“Cox aide)."),
                            tags$li("Lire la saisonnalitÃ© sur une sÃ©rie trop courte (risque de fausse saison).")
                          )
                        )
        ))
      }
      
      # ============== STEP 3 ==============
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "La dÃ©composition est descriptive : elle clarifie tendance/saison et aide Ã  dÃ©cider additif vs multiplicatif (souvent via log).",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Objectif + choix de forme", open = TRUE,
                            tags$ul(
                              tags$li("DÃ©composer en tendance, saisonnalitÃ©, reste (bruit)."),
                              tags$li("Choisir additif vs multiplicatif selon amplitude saisonniÃ¨re."),
                              tags$li("Utiliser STL si saison Ã©volutive ou outliers.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("DÃ©composition additive",
                                 "y_t = T_t + S_t + e_t.",
                                 purpose="Quand lâ€™amplitude saisonniÃ¨re est Ã  peu prÃ¨s constante.",
                                 formula="y_t = T_t + S_t + e_t"),
                            TERM("DÃ©composition multiplicative",
                                 "y_t = T_t Ã— S_t Ã— e_t.",
                                 purpose="Quand lâ€™amplitude saisonniÃ¨re augmente avec le niveau.",
                                 formula="y_t = T_t Ã— S_t Ã— e_t",
                                 notes="Souvent : log(y_t) transforme le multiplicatif en additif."),
                            TERM("STL",
                                 "Seasonal-Trend decomposition using Loess.",
                                 purpose="Robuste, flexible ; accepte une saisonnalitÃ© qui change lentement.",
                                 notes="TrÃ¨s utile en pratique ; reste descriptif (SARIMA nÃ©cessite stationnaritÃ© via diffÃ©renciation).")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” DÃ©composition", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (DÃ©composition). "),
                              "Â« Nous avons Ã©valuÃ© une structure additive vs multiplicative en examinant lâ€™Ã©volution de lâ€™amplitude saisonniÃ¨re avec le niveau. ",
                              "Comme [..], nous avons utilisÃ© [additif / log puis additif] et dÃ©composÃ© via [classique / STL]. ",
                              "STL a Ã©tÃ© retenue pour sa robustesse aux valeurs aberrantes et sa capacitÃ© Ã  modÃ©liser une saisonnalitÃ© Ã©volutive. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "forme (additive/multiplicative) + mÃ©thode (STL/...) justifiÃ©es."),
                              tags$li(tags$b("Sens : "), "on comprend la structure du signal, ce qui guide transformation et diffÃ©renciation.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Prendre STL comme preuve de stationnaritÃ© (non : câ€™est descriptif)."),
                            tags$li("Oublier que multiplicatif â†” log (ils sont meilleurs amis)."),
                            tags$li("DÃ©composer une sÃ©rie avec frÃ©quence mal spÃ©cifiÃ©e (s incorrect).")
                          )
                        )
        ))
      }
      
      # ============== STEP 4 ==============
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "SARIMA exige que la sÃ©rie soit approximativement stationnaire aprÃ¨s diffÃ©renciation : on choisit d (tendance) et D (saisonnier) en combinant tests + graphiques.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("DÃ©finir la saison (s) + appliquer la diffÃ©renciation", open = TRUE,
                            tags$ul(
                              tags$li("Fixer la pÃ©riode saisonniÃ¨re ", tags$code("s"), " (ex : 12 mensuel, 7 hebdo sur quotidien, 4 trimestriel)."),
                              tags$li("Tester stationnaritÃ© sur : original, aprÃ¨s âˆ‡^d, aprÃ¨s âˆ‡_s^D, et parfois aprÃ¨s les deux."),
                              tags$li("Sâ€™arrÃªter dÃ¨s que stationnaritÃ© raisonnable ; Ã©viter sur-diffÃ©renciation.")
                            )
                          ),
                          
                          S("DÃ©finitions indispensables", open = FALSE,
                            TERM("StationnaritÃ© (faible)",
                                 "Moyenne et variance constantes, autocovariance dÃ©pend seulement du retard.",
                                 purpose="ARMA/SARIMA supposent cette stabilitÃ© aprÃ¨s diffÃ©renciation."),
                            TERM("DiffÃ©renciation ordinaire (d)",
                                 "âˆ‡y_t = y_t - y_{t-1} ; appliquÃ©e d fois.",
                                 purpose="Supprime tendance stochastique (unit root non saisonnier).",
                                 formula="(1-B)^d y_t"),
                            TERM("DiffÃ©renciation saisonniÃ¨re (D)",
                                 "âˆ‡_s y_t = y_t - y_{t-s} ; appliquÃ©e D fois.",
                                 purpose="Supprime racine unitaire saisonniÃ¨re.",
                                 formula="(1-B^s)^D y_t"),
                            TERM("Sur-diffÃ©renciation",
                                 "DiffÃ©rencier trop (d ou D trop grand).",
                                 purpose="Ã€ Ã©viter : dÃ©grade variance/structure et rend le modÃ¨le instable.",
                                 notes="SymptÃ´me typique : ACF trÃ¨s nÃ©gative au lag 1.")
                          ),
                          
                          S("Tests (trÃ¨s dÃ©taillÃ©s, chacun cliquable)", open = FALSE,
                            TEST(
                              name="ADF â€” Augmented Dickeyâ€“Fuller",
                              purpose="DÃ©tecter une racine unitaire (tendance stochastique). On modÃ©lise Î”y_t en fonction de y_{t-1} + retards de Î”y pour absorber lâ€™autocorrÃ©lation.",
                              H0="La sÃ©rie a une racine unitaire â†’ non-stationnaire (les chocs ont des effets persistants).",
                              H1="La sÃ©rie est stationnaire (autour dâ€™une moyenne ou dâ€™une tendance dÃ©terministe selon spÃ©cification).",
                              statistic="Test sur le coefficient de y_{t-1} dans la rÃ©gression ADF (valeurs critiques non standard).",
                              interpretation="p petit â†’ rejet H0 â†’ stationnaritÃ© plausible. p grand â†’ non-rejet â†’ diffÃ©renciation probablement nÃ©cessaire.",
                              conclusion="Si ADF rejette aprÃ¨s (d,D), cela soutient que la sÃ©rie diffÃ©renciÃ©e convient Ã  un SARIMA : les dÃ©pendances restantes peuvent Ãªtre capturÃ©es par AR/MA.",
                              caveats="SensibilitÃ© au choix (drift/trend) et au nombre de retards ; ruptures structurelles peuvent tromper le test."
                            ),
                            TEST(
                              name="KPSS â€” Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin",
                              purpose="ComplÃ©ment de lâ€™ADF : ici la stationnaritÃ© est lâ€™hypothÃ¨se nulle. On mesure si une marche alÃ©atoire rÃ©siduelle est trop forte.",
                              H0="La sÃ©rie est stationnaire (en niveau) ou stationnaire autour dâ€™une tendance (selon version).",
                              H1="La sÃ©rie est non-stationnaire.",
                              statistic="Statistique basÃ©e sur la somme cumulÃ©e des rÃ©sidus + estimation de variance longue.",
                              interpretation="p petit â†’ rejet H0 â†’ non-stationnaire. p grand â†’ compatible avec stationnaritÃ©.",
                              conclusion="KPSS non-significatif aprÃ¨s diffÃ©renciation renforce lâ€™idÃ©e que la transformation a stabilisÃ© la sÃ©rie.",
                              caveats="Choix de bande passante/variance longue ; ruptures â†’ faux rejets."
                            ),
                            TEST(
                              name="PP â€” Phillipsâ€“Perron",
                              purpose="Test de racine unitaire comme ADF mais avec corrections non paramÃ©triques pour autocorrÃ©lation/hÃ©tÃ©roscÃ©dasticitÃ© (au lieu dâ€™ajouter beaucoup de retards).",
                              H0="Racine unitaire â†’ non-stationnaire.",
                              H1="Stationnaire.",
                              statistic="Statistique similaire Ã  DF avec correction de variance.",
                              interpretation="Concordance ADF + PP = argument plus solide ; dÃ©saccord = vÃ©rifier spÃ©cification et diagnostics.",
                              conclusion="Rejet H0 par PP aprÃ¨s (d,D) = cohÃ©rent avec une sÃ©rie diffÃ©renciÃ©e stationnaire, prÃªte pour SARIMA.",
                              caveats="Comme ADF : dÃ©pend de drift/trend ; breaks peuvent biaiser."
                            )
                          ),
                          
                          S("InterprÃ©ter ADF/KPSS/PP ensemble (logique de conclusion)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Accord stationnaire : "), "ADF/PP rejettent (p petit) + KPSS ne rejette pas (p grand) â†’ stationnaritÃ© fortement plausible."),
                              tags$li(tags$b("Accord non-stationnaire : "), "ADF/PP ne rejettent pas (p grand) + KPSS rejette (p petit) â†’ diffÃ©renciation nÃ©cessaire."),
                              tags$li(tags$b("Conflits : "), "se reposer sur convergence : graphiques + ACF + rÃ©sultats aprÃ¨s diffÃ©renciation. Ã‰crire que la dÃ©cision repose sur lâ€™ensemble des indices (pas une seule p-value).")
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” StationnaritÃ© & diffÃ©renciation", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (StationnaritÃ© & diffÃ©renciation). "),
                              "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e par ADF, KPSS et PP afin de trianguler lâ€™Ã©vidence (hypothÃ¨ses nulles diffÃ©rentes). ",
                              "Sur la base des tests, des diagnostics visuels et de lâ€™ACF, nous avons retenu d=[..] et D=[..] avec pÃ©riode saisonniÃ¨re s=[..]. ",
                              "Ce choix vise Ã  supprimer tendance et/ou racine unitaire saisonniÃ¨re tout en Ã©vitant la sur-diffÃ©renciation ; la stationnaritÃ© a Ã©tÃ© revÃ©rifiÃ©e aprÃ¨s transformation. Â»"
                            )
                          ),
                          S("Conclusion + sens (Ã  Ã©crire)", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "d=[..], D=[..], s=[..] retenus."),
                              tags$li(tags$b("Sens : "), "le SARIMA expliquera la dÃ©pendance restante (AR/MA) sur une sÃ©rie stabilisÃ©e (stationnaire) â€” donc des paramÃ¨tres interprÃ©tables et des prÃ©visions plus fiables.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li(tags$b("Sur-diffÃ©renciation : "), "ACF lag1 trÃ¨s nÃ©gative, variance gonflÃ©e, prÃ©visions instables."),
                            tags$li("D vaut souvent 0 ou 1 ; si D=2, vÃ©rifier s et la qualitÃ© des donnÃ©es."),
                            tags$li("Oublier de tester avec/sans trend/drift : peut inverser la conclusion.")
                          )
                        )
        ))
      }
      
      # ============== STEP 5 ==============
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Auto-ARIMA fournit une baseline (bon point de dÃ©part), pas une vÃ©ritÃ© absolue. On documente critÃ¨res, contraintes et transformations.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("ProcÃ©dure", open = TRUE,
                            tags$ul(
                              tags$li("Lancer auto-ARIMA (souvent AICc) pour proposer ", tags$code("(p,d,q)(P,D,Q)[s]"), "."),
                              tags$li("Documenter : transformations, contraintes max p/q/P/Q, stepwise vs exhaustive."),
                              tags$li("Garder une baseline + la comparer au manuel + benchmark naÃ¯f.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("AIC / AICc / BIC",
                                 "CritÃ¨res dâ€™information : compromis ajustement vs complexitÃ© (pÃ©nalisation). AICc corrige AIC pour petits Ã©chantillons.",
                                 purpose="Comparer des modÃ¨les sur la mÃªme sÃ©rie (mÃªme transformation) en pÃ©nalisant la complexitÃ©.",
                                 notes="Un meilleur AICc nâ€™assure pas de meilleurs forecasts out-of-sample."),
                            TERM("Stepwise",
                                 "Recherche heuristique qui explore un sous-ensemble de modÃ¨les pour aller vite.",
                                 purpose="AccÃ©lÃ©rer la sÃ©lection quand lâ€™espace des modÃ¨les est grand.",
                                 notes="Peut rater le meilleur modÃ¨le global, mais donne souvent une bonne baseline.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” ModÃ¨le de rÃ©fÃ©rence", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (Baseline). "),
                              "Â« Un modÃ¨le SARIMA de rÃ©fÃ©rence a Ã©tÃ© sÃ©lectionnÃ© via une procÃ©dure automatisÃ©e basÃ©e sur la minimisation de lâ€™AICc parmi des ordres candidats sous contraintes [..]. ",
                              "La spÃ©cification retenue Ã©tait SARIMA((p,d,q)(P,D,Q)[s]) et a servi de point de dÃ©part pour des ajustements ultÃ©rieurs guidÃ©s par les diagnostics. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "baseline dÃ©finie et reproductible."),
                              tags$li(tags$b("Sens : "), "point de comparaison : on nâ€™Ã©value pas le manuel Â« dans le vide Â».")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Croire auto-ARIMA Â« final Â» : toujours vÃ©rifier diagnostics et performance."),
                            tags$li("Choisir uniquement AICc sans test out-of-sample."),
                            tags$li("Comparer des modÃ¨les sur des sÃ©ries transformÃ©es diffÃ©remment (incomparable).")
                          )
                        )
        ))
      }
      
      # ============== STEP 6 ==============
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "ACF/PACF guident la proposition de quelques modÃ¨les plausibles (3â€“8). On privilÃ©gie parcimonie + diagnostics propres.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("ProcÃ©dure guidÃ©e par ACF/PACF", open = TRUE,
                            tags$ol(
                              tags$li("Travailler sur la sÃ©rie diffÃ©renciÃ©e (aprÃ¨s choix de d et D)."),
                              tags$li("Tracer ACF et PACF."),
                              tags$li("Proposer quelques candidats (p,q,P,Q) plausibles."),
                              tags$li("Ajuster, comparer (AICc/BIC) + stabilitÃ©/inversibilitÃ© + diagnostics.")
                            )
                          ),
                          S("DÃ©finitions (cliquables)", open = FALSE,
                            TERM("ACF",
                                 "Fonction dâ€™autocorrÃ©lation : corr(y_t, y_{t-k}).",
                                 purpose="Identifier composantes MA (coupure) et saisonnalitÃ© (pics aux multiples de s).",
                                 notes="Sur sÃ©rie stationnaire (souvent aprÃ¨s diffÃ©renciation)."),
                            TERM("PACF",
                                 "AutocorrÃ©lation partielle : corr(y_t, y_{t-k} | lags intermÃ©diaires).",
                                 purpose="Identifier composantes AR (coupure)."),
                            TERM("AR(p)",
                                 "ModÃ¨le auto-rÃ©gressif : y_t dÃ©pend de ses p retards.",
                                 purpose="Capturer persistance / inertie.",
                                 formula="y_t = c + Î£ Ï†_i y_{t-i} + Îµ_t"),
                            TERM("MA(q)",
                                 "Moyenne mobile : y_t dÃ©pend des q erreurs passÃ©es.",
                                 purpose="Capturer chocs transitoires.",
                                 formula="y_t = c + Îµ_t + Î£ Î¸_i Îµ_{t-i}"),
                            TERM("Saisonnier P/Q",
                                 "Composantes AR/MA aux multiples de s.",
                                 purpose="Capturer dÃ©pendances qui reviennent chaque saison (ex : annÃ©e sur annÃ©e).",
                                 notes="Pics Ã  s, 2s, 3sâ€¦ dans ACF/PACF.")
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template MÃ©thodes â€” Construction guidÃ©e", open = TRUE,
                            tags$p(
                              tags$b("MÃ©thodes (GuidÃ©e par ACF/PACF). "),
                              "Â« Les structures candidates ont Ã©tÃ© proposÃ©es dâ€™aprÃ¨s lâ€™ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. ",
                              "Des motifs aux faibles retards suggÃ©raient des termes non saisonniers (p,q), tandis que des pics aux multiples de s suggÃ©raient des termes saisonniers (P,Q). ",
                              "Un petit ensemble de modÃ¨les plausibles a Ã©tÃ© ajustÃ© et comparÃ© via [AICc/BIC] et diagnostics, en privilÃ©giant la parcimonie. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "liste de candidats raisonnÃ©s + justification ACF/PACF."),
                              tags$li(tags$b("Sens : "), "on limite le sur-ajustement et on garde une interprÃ©tabilitÃ© pÃ©dagogique.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Bruteforce de centaines de modÃ¨les (pas Â« thÃ©orie Â»)."),
                            tags$li("Lire ACF/PACF sur sÃ©rie non stationnaire."),
                            tags$li("Oublier stabilitÃ©/inversibilitÃ© : un modÃ¨le peut fitter mais Ãªtre instable.")
                          )
                        )
        ))
      }
      
      # ============== STEP 7 ==============
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Le modÃ¨le final doit : (1) rÃ©sidus ~ bruit blanc (pas dâ€™autocorrÃ©lation), (2) battre un benchmark, (3) rester simple si performance similaire.",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Diagnostics rÃ©sidus (indispensable)", open = TRUE,
                            tags$ul(
                              tags$li("Tracer rÃ©sidus (aspect bruit)."),
                              tags$li("ACF rÃ©sidus (pas de pics majeurs)."),
                              tags$li(tags$b("Ljungâ€“Box"), " : tester lâ€™autocorrÃ©lation rÃ©siduelle."),
                              tags$li("NormalitÃ© (QQ-plot ; Shapiro-Wilk trop sensible si grand n)."),
                              tags$li("HÃ©tÃ©roscÃ©dasticitÃ© / ARCH (si finance).")
                            )
                          ),
                          
                          S("Tests & dÃ©finitions (cliquables)", open = FALSE,
                            TERM("RÃ©sidu", "r_t = y_t âˆ’ Å·_t (erreur in-sample).", purpose="Les rÃ©sidus doivent Ãªtre Â« bruit blanc Â» pour un modÃ¨le bien spÃ©cifiÃ©.", formula="r_t = y_t - Å·_t"),
                            TERM("Bruit blanc", "SÃ©rie de moyenne 0, variance constante, sans autocorrÃ©lation significative.", purpose="Cible des diagnostics rÃ©siduels."),
                            TEST(
                              name="Ljungâ€“Box",
                              purpose="VÃ©rifier si les rÃ©sidus prÃ©sentent encore de lâ€™autocorrÃ©lation (globalement jusquâ€™Ã  un lag L).",
                              H0="Pas dâ€™autocorrÃ©lation rÃ©siduelle jusquâ€™au lag L (rÃ©sidus compatibles bruit blanc).",
                              H1="AutocorrÃ©lation rÃ©siduelle prÃ©sente.",
                              statistic="Q(L) agrÃ¨ge les autocorrÃ©lations rÃ©siduelles ; p-value associÃ©e.",
                              interpretation="p â‰¥ Î± : pas dâ€™Ã©vidence forte dâ€™autocorrÃ©lation ; p < Î± : structure restante â†’ revoir (p,q,P,Q,d,D).",
                              conclusion="Si non significatif, cela soutient que le SARIMA a capturÃ© la dÃ©pendance temporelle pertinente ; sinon, le modÃ¨le est incomplet.",
                              caveats="Choix de L important ; trop grand L peut sur-dÃ©tecter ; dÃ©pend du fitdf."
                            ),
                            TEST(
                              name="Jarqueâ€“Bera (optionnel)",
                              purpose="Tester si la distribution des rÃ©sidus est proche dâ€™une normale (skewness + kurtosis).",
                              H0="RÃ©sidus ~ normale.",
                              H1="RÃ©sidus non normaux.",
                              interpretation="Souvent rejetÃ© en pratique (queues Ã©paisses). La non-normalitÃ© nâ€™est pas toujours critique pour la prÃ©vision.",
                              conclusion="Si rejet, on interprÃ¨te : queues Ã©paisses possibles â†’ intervalles de prÃ©vision peuvent Ãªtre optimistes si on suppose normalitÃ©.",
                              caveats="TrÃ¨s sensible avec grands Ã©chantillons."
                            )
                          ),
                          
                          S("Ã‰valuation prÃ©vision (indispensable)", open = FALSE,
                            tags$ul(
                              tags$li("Utiliser test set ou rolling-origin."),
                              tags$li("MÃ©triques : MAE/RMSE (MAPE si y jamais proche de 0)."),
                              tags$li("Comparer : baseline auto-ARIMA, manuel, benchmark naÃ¯f (et naÃ¯f saisonnier).")
                            )
                          ),
                          
                          S("RÃ¨gle saine de sÃ©lection finale", open = FALSE,
                            tags$ul(
                              tags$li("Diagnostics OK (rÃ©sidus ~ bruit blanc)."),
                              tags$li("Performance > benchmark naÃ¯f."),
                              tags$li("Si performances proches : choisir le modÃ¨le le plus simple.")
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Template RÃ©sultats â€” Diagnostics & performance", open = TRUE,
                            tags$p(
                              tags$b("RÃ©sultats (Diagnostics & performance). "),
                              "Â« Les diagnostics rÃ©siduels suggÃ©raient un comportement proche du bruit blanc : lâ€™ACF des rÃ©sidus ne montrait pas de pics marquÃ©s, et le test de Ljungâ€“Box Ã©tait [non significatif/significatif] (Î±=[..]). ",
                              "Sur la fenÃªtre dâ€™Ã©valuation, la performance de prÃ©vision donnait MAE=[..] et RMSE=[..], surpassant le benchmark [..]. ",
                              "Le modÃ¨le final retenu Ã©tait SARIMA((p,d,q)(P,D,Q)[s]) sur la base de lâ€™adÃ©quation diagnostique et de la performance prÃ©dictive. Â»"
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "modÃ¨le final + mÃ©triques + diagnostics prÃ©sentÃ©s."),
                              tags$li(tags$b("Sens : "), "un SARIMA nâ€™est Â« bon Â» que sâ€™il gÃ©nÃ©ralise ET laisse des rÃ©sidus sans structure temporelle.")
                            )
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Choisir AIC excellent mais rÃ©sidus autocorrÃ©lÃ©s (modÃ¨le incomplet)."),
                            tags$li("Sur-interprÃ©ter la non-normalitÃ© : lâ€™autocorrÃ©lation rÃ©siduelle est plus grave pour la prÃ©vision."),
                            tags$li("Comparer des modÃ¨les avec des splits temporels diffÃ©rents.")
                          )
                        )
        ))
      }
      
      # ============== STEP 8 ==============
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("IdÃ©e centrale : "),
                          "Votre rapport doit Ãªtre alignÃ© sur le pipeline : MÃ©thodes (ce que vous avez fait + pourquoi) puis RÃ©sultats (ce que vous avez observÃ© + conclusion).",
                          type="ok"
                        ),
                        
                        D("Ce que les Ã©tudiants font", open = TRUE,
                          S("Checklist MÃ©thodes", open = TRUE,
                            tags$ul(
                              tags$li("DonnÃ©es : source, dates, frÃ©quence, manque, transformation."),
                              tags$li("EDA : graphiques + dÃ©composition."),
                              tags$li("StationnaritÃ© : tests + choix (d,D,s)."),
                              tags$li("Baseline auto-ARIMA (critÃ¨re/contraintes)."),
                              tags$li("Candidats manuels (ACF/PACF + parcimonie)."),
                              tags$li("Diagnostics et protocole dâ€™Ã©valuation.")
                            )
                          ),
                          S("Checklist RÃ©sultats", open = TRUE,
                            tags$ul(
                              tags$li("Description des donnÃ©es + observations clÃ©s."),
                              tags$li("DÃ©composition : tendance/saison."),
                              tags$li("Tests stationnaritÃ© + d/D retenus."),
                              tags$li("ParamÃ¨tres modÃ¨le final."),
                              tags$li("Diagnostics + mÃ©triques + figure de prÃ©vision."),
                              tags$li("Tableau comparatif (AICc + erreurs).")
                            )
                          )
                        ),
                        
                        D("Ce quâ€™ils Ã©crivent", open = FALSE,
                          S("Structure APA (ultra pratique)", open = TRUE,
                            tags$ul(
                              tags$li(tags$b("Pour chaque sous-section : "), "Ce quâ€™on a fait â†’ Pourquoi â†’ Ce quâ€™on observe â†’ Conclusion."),
                              tags$li("Temps verbal : passÃ© en MÃ©thodes, passÃ© orientÃ© rÃ©sultats en RÃ©sultats."),
                              tags$li("Ã‰crire la spÃ©cification complÃ¨te une fois clairement : ", tags$code("SARIMA((p,d,q)(P,D,Q)[s])"), ".")
                            ),
                            S("Ã‰quation SARIMA (notation)", open = FALSE,
                              tags$ul(
                                tags$li(
                                  tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
                                  " avec innovations ",
                                  tags$code("Îµ_t ~ w.n.(0, Ïƒ^2)")
                                )
                              ),
                              tags$p(class="small",
                                     "InterprÃ©tation : aprÃ¨s diffÃ©renciation (âˆ‡^d et âˆ‡_s^D), la dÃ©pendance restante est modÃ©lisÃ©e par des polynÃ´mes AR (Ï†, Î¦) et MA (Î¸, Î˜).")
                            )
                          ),
                          S("Conclusion + sens", open = FALSE,
                            tags$ul(
                              tags$li(tags$b("Conclusion : "), "rapport structurÃ© = reproductible + pÃ©dagogique."),
                              tags$li(tags$b("Sens : "), "le lecteur peut refaire exactement vos Ã©tapes et comprendre vos choix.")
                            )
                          )
                        ),
                        
                        D("Pack livrable attendu", open = FALSE,
                          tags$ul(
                            tags$li(
                              tags$b("Notebook/script : "),
                              tags$ul(
                                tags$li("chargement + nettoyage + frÃ©quence"),
                                tags$li("manquants + transformations"),
                                tags$li("EDA + dÃ©composition"),
                                tags$li("tests stationnaritÃ© + choix d/D/s"),
                                tags$li("auto-ARIMA baseline"),
                                tags$li("candidats manuels"),
                                tags$li("diagnostics + Ã©valuation"),
                                tags$li("prÃ©vision finale + intervalles")
                              )
                            ),
                            tags$li(
                              tags$b("Rapport court : "),
                              tags$ul(
                                tags$li("MÃ©thodes/RÃ©sultats alignÃ©s Ã©tapes 0â€“7"),
                                tags$li("figures : sÃ©rie, dÃ©composition, ACF/PACF, rÃ©sidus, prÃ©vision"),
                                tags$li("tableau : AICc + MAE/RMSE (candidats)")
                              )
                            )
                          )
                        )
        ))
      }
      
      # fallback (should never happen)
      tags$div(class="road-card", "Ã‰tape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (trÃ¨s dÃ©taillÃ©e) â€” FR"),
                          tags$p(class="road-sub",
                                 "Naviguez par Ã©tape avec le slider. Ouvrez seulement ce dont vous avez besoin via les sections repliables.")
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Ã‰tape (utilisez le slider â€” pas besoin de dÃ©filer)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               # Step content
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  # ============================================================
  # Ø®Ø§Ø±Ø·Ø© Ø·Ø±ÙŠÙ‚ SARIMA (Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰) â€” Ø´Ø±ÙŠØ· ØªÙ…Ø±ÙŠØ± + Ø£Ù‚Ø³Ø§Ù… Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø·ÙŠ
  # Ù…Ù†Ø¸Ù…Ø© Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ø®Ø·ÙˆØ©:
  # Ø§Ù„Ù‡Ø¯Ù â†’ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© â†’ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø§Ù„ØºØ±Ø¶/Ù…ØªÙ‰/ÙØ±Ø¶ÙŠØ§Øª/Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø±) â†’ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± â†’ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª â†’ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
  #
  # Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
  # 1) ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… UI:   uiOutput("roadmap_Detailed_Ar_ui")
  # 2) ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù… server(): Ø§Ù†Ø³Ø® ÙƒÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø£Ø¯Ù†Ø§Ù‡ Ø¯Ø§Ø®Ù„ server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Ar_ui <- renderUI({
    
    # ----------------------------
    # Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¨Ù†Ø§Ø¡ Ø£Ù‚Ø³Ø§Ù… Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø·ÙŠ (Accordion)
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # Ù…Ø³ØªÙˆÙ‰ 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # Ù…Ø³ØªÙˆÙ‰ 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL, notes = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 tags$p(tags$b("Ø§Ù„ØªØ¹Ø±ÙŠÙ: "), definition),
                 if (!is.null(purpose))  tags$p(tags$b("Ø§Ù„ØºØ±Ø¶/Ø§Ù„ÙØ§Ø¦Ø¯Ø©: "), purpose) else NULL,
                 if (!is.null(criteria)) tags$p(tags$b("Ù…Ø¹Ø§ÙŠÙŠØ±/Ù…Ø¤Ø´Ø±Ø§Øª: "), criteria) else NULL,
                 if (!is.null(formula))  tags$p(tags$b("Ø§Ù„ØªØ±Ù…ÙŠØ²/Ø§Ù„ØµÙŠØºØ©: "), tags$code(formula)) else NULL,
                 if (!is.null(example))  tags$p(tags$b("Ù…Ø«Ø§Ù„: "), example) else NULL,
                 if (!is.null(notes))    tags$p(tags$b("Ù…Ù„Ø§Ø­Ø¸Ø§Øª: "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 tags$p(tags$b("Ø§Ù„ØºØ±Ø¶ (Ø¨ØªÙØµÙŠÙ„): "), purpose),
                 tags$p(tags$b("Ù…ØªÙ‰ Ù†Ø³ØªØ®Ø¯Ù…Ù‡: "), when_to_use),
                 tags$p(tags$b("Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„ØµÙØ±ÙŠØ© H0: "), H0),
                 tags$p(tags$b("Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø© H1: "), H1),
                 if (!is.null(statistic))      tags$p(tags$b("Ø§Ù„Ø¥Ø­ØµØ§Ø¡/Ø§Ù„ÙÙƒØ±Ø©: "), statistic) else NULL,
                 if (!is.null(decision_rule))  tags$p(tags$b("Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù‚Ø±Ø§Ø±: "), decision_rule) else NULL,
                 if (!is.null(interpretation)) tags$p(tags$b("Ø§Ù„ØªÙØ³ÙŠØ± (Ø§Ù„Ù…Ø¹Ù†Ù‰): "), interpretation) else NULL,
                 if (!is.null(reporting))      tags$p(tags$b("ÙƒÙŠÙÙŠØ© Ø§Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: "), reporting) else NULL,
                 if (!is.null(caveats))        tags$p(tags$b("Ø­Ø¯ÙˆØ¯/Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø©: "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø¸Ù‡Ø± ÙˆØ§Ù„Ø³Ù„ÙˆÙƒ)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px; direction: rtl; showing: block;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-right:4px;}
    details.acc.term, details.acc.test {margin:8px 12px 8px 0;}
    .callout {border-right:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-right-color:#E45756; background:#fff7f7;}
    .callout.ok {border-right-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px; direction:ltr; unicode-bidi: plaintext;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-left:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 18px 6px 0;}
    .tight ol {margin: 6px 18px 6px 0;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø®Ø·ÙˆØ§Øª + Ø´Ø§Ø±Ø§Øª
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] ØªØ£Ø·ÙŠØ± Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙˆØ§Ù„ØªØ­Ù‚Ù‚ (Validation)",
        "[1] Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ø¶ÙŠØ± (NAØŒ Ø§Ù„ØªÙˆØ§ØªØ±ØŒ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©)",
        "[2] Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ØµØ±ÙŠ (Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©ØŒ Ø§Ù„ØªØ¨Ø§ÙŠÙ†)",
        "[3] Ø§Ù„ØªÙÙƒÙŠÙƒ/Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª (STLØŒ Ø¬Ù…Ø¹ÙŠ/Ø¶Ø±Ø¨ÙŠ)",
        "[4] Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙˆØ§Ù„ÙØ±Ù‚ (Ø§Ø®ØªÙŠØ§Ø± d Ùˆ D Ùˆ s) + Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª",
        "[5] Ø®Ø· Ø£Ø³Ø§Ø³ (Naive / Auto-ARIMA) + Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±",
        "[6] Ø§Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙŠØ¯ÙˆÙŠ (ACF/PACF) + Ù‚Ø§Ø¦Ù…Ø© Ù†Ù…Ø§Ø°Ø¬ Ù…Ø±Ø´Ø­Ø©",
        "[7] Ø§Ù„ØªØ´Ø®ÙŠØµ ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ø¨ÙˆØ§Ù‚ÙŠ + Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤)",
        "[8] Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬: Ø§Ù„Ø®Ù„Ø§ØµØ© ÙˆÙ…Ø¹Ù†Ø§Ù‡Ø§ ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Ø§Ù„Ù‡Ø¯Ù", "Ø§Ù„Ø£ÙÙ‚", "Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„", "Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"),
        c("Ø§Ù„ØªÙˆØ§ØªØ±", "Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ©", "Ø§Ù„Ø´ÙˆØ§Ø°", "Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª"),
        c("Ø§Ù„Ø±Ø³ÙˆÙ…", "Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©", "Ø§Ù„ØªØ¨Ø§ÙŠÙ†", "Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"),
        c("STL", "Ø¬Ù…Ø¹ÙŠ/Ø¶Ø±Ø¨ÙŠ", "Ø§Ù„Ø¨Ù†ÙŠØ©"),
        c("ADF/KPSS/PP", "d/D/s", "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±"),
        c("Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³", "AICc/BIC", "Naive"),
        c("ACF/PACF", "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ ÙÙŠ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª", "Ù…Ø±Ø´Ø­Ø§Øª"),
        c("Ljungâ€“Box", "ARCH", "Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©", "Ø§Ù„Ø¯Ù‚Ø©"),
        c("ØªÙ„Ø®ÙŠØµ", "Ø§Ø³ØªÙ†ØªØ§Ø¬", "Ø§Ù„Ù…Ø¹Ù†Ù‰", "Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ø¥Ø¹Ø§Ø¯Ø©")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    criteria_block <- function(title, ...) {
      tags$div(class="box",
               tags$h5(title),
               ...
      )
    }
    
    # ------------------------------------------------------------
    # Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ§Øª (Ù…Ù†Ø¸Ù… Ù„Ù„ØºØ§ÙŠØ©)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =======================
      # (0) ØªØ£Ø·ÙŠØ± Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
      # =======================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "ØªØ­Ø¯ÙŠØ¯ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ù‚Ø© (Ø§Ù„Ø³Ù„Ø³Ù„Ø©ØŒ Ø§Ù„ØªÙˆØ§ØªØ±ØŒ Ø§Ù„Ø£ÙÙ‚ØŒ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ØŒ ÙˆØ®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³)ØŒ Ù„Ø£Ù† Ø£ÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø¯ÙˆÙ† Ø°Ù„Ùƒ ØªÙƒÙˆÙ† ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚Ø©.",
                                type="ok"
                        ),
                        
                        D("Ø§Ù„Ù‡Ø¯Ù", open = TRUE,
                          tags$ul(
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù ", tags$code("y_t"), " ÙˆÙˆØ­Ø¯Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ ÙˆØ§Ù„ØªÙˆØ§ØªØ± (Ø´Ø¨ÙƒØ© Ø²Ù…Ù†ÙŠØ© Ù…Ù†ØªØ¸Ù…Ø©)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤ ", tags$code("h"), " Ø¨Ù…Ø§ ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¹Ù„ÙŠ."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªØ­Ù‚Ù‚: ØªÙ‚Ø³ÙŠÙ… Ø²Ù…Ù†ÙŠ Train/Test Ø£Ùˆ Ø£ØµÙ„ Ù…ØªØ­Ø±Ùƒ (Rolling-origin)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³: MAE/RMSE (ÙˆMAPE/sMAPE Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³: Naive ÙˆNaive Ù…ÙˆØ³Ù…ÙŠ Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ù…ÙˆØ³Ù…ÙŠØ©.")
                          )
                        ),
                        
                        D("Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 â€” ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ§ØªØ± ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© (s)",
                                                  tags$ul(
                                                    tags$li("ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¬Ù…ÙŠØ¹: ÙŠÙˆÙ…ÙŠ/Ø£Ø³Ø¨ÙˆØ¹ÙŠ/Ø´Ù‡Ø±ÙŠ..."),
                                                    tags$li("Ø§Ø´ØªÙ‚Ø§Ù‚ ", tags$code("s"), " Ù…Ù† Ø§Ù„ØªÙ‚ÙˆÙŠÙ…: Ø´Ù‡Ø±ÙŠ s=12ØŒ Ø±Ø¨Ø¹ Ø³Ù†ÙˆÙŠ s=4ØŒ ÙŠÙˆÙ…ÙŠ Ù…Ø¹ Ø£Ø³Ø¨ÙˆØ¹ÙŠ s=7."),
                                                    tags$li("Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„ÙÙˆØ§ØµÙ„ ÙˆØ¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªÙˆØ§Ø±ÙŠØ® Ù…ÙƒØ±Ø±Ø©.")
                                                  )
                                   ),
                                   criteria_block("A2 â€” Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªØ­Ù‚Ù‚",
                                                  tags$ul(
                                                    tags$li(tags$b("ØªÙ‚Ø³ÙŠÙ… Ø²Ù…Ù†ÙŠ: "), "Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§Ø¶ÙŠ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„."),
                                                    tags$li(tags$b("Rolling-origin: "), "ØªÙƒØ±Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù†Ø¯ Ø¹Ø¯Ø© Ù†Ù‚Ø§Ø· Ø£ØµÙ„ Ù„Ù‚ÙŠØ§Ø³ Ø£Ø¯Ø§Ø¡ Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§Ù‹."),
                                                    tags$li("Ø­Ø¬Ù… Ù†Ø§ÙØ°Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙŠÙÙØ¶Ù„ Ø£Ù† ÙŠØºØ·ÙŠ Ù…ÙˆØ³Ù…Ø§Ù‹ ÙƒØ§Ù…Ù„Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†.")
                                                  )
                                   ),
                                   criteria_block("A3 â€” Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE: "), "Ø³Ù‡Ù„ Ø§Ù„ØªÙØ³ÙŠØ± ÙˆÙ…ØªÙŠÙ† Ù†Ø³Ø¨ÙŠØ§Ù‹."),
                                                    tags$li(tags$b("RMSE: "), "ÙŠØ¹Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø´Ø¯Ø©."),
                                                    tags$li(tags$b("MAPE: "), "ÙŠÙØ³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ… Ù…ÙˆØ¬Ø¨Ø© ÙˆØ¨Ø¹ÙŠØ¯Ø© Ø¹Ù† Ø§Ù„ØµÙØ±."),
                                                    tags$li(tags$b("sMAPE: "), "Ø¨Ø¯ÙŠÙ„ Ù†Ø³Ø¨ÙŠ Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹ Ù…Ù† MAPE.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø± (Ø§Ø®ØªÙŠØ§Ø±Ø§Øª ÙˆØ§Ø¶Ø­Ø©)", open = TRUE,
                          tags$ul(
                            tags$li(tags$b("Ø§Ù„Ø£ÙÙ‚ h: "), "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù‚Ø±Ø§Ø±/Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ù‚ØµÙŠØ±/Ø·ÙˆÙŠÙ„)."),
                            tags$li(tags$b("Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„: "), "Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©ØŒ Rolling-origin Ø£ÙØ¶Ù„Ø› ÙˆØ¥Ù„Ø§ ØªÙ‚Ø³ÙŠÙ… Ø²Ù…Ù†ÙŠ ÙˆØ§Ø¶Ø­."),
                            tags$li(tags$b("Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³: "), "Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ MAE + RMSE Ù„ØªØ¬Ù†Ø¨ Ø±Ø¤ÙŠØ© Ø£Ø­Ø§Ø¯ÙŠØ©."),
                            tags$li(tags$b("Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³: "), "Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙÙˆÙ‚ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„ÙŠÙ‡ ÙØ§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙÙŠØ¯ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø©.")
                          )
                        )
        ))
      }
      
      # =======================
      # (1) Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      # =======================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "Ø¬Ø¹Ù„ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù…Ø°Ø¬Ø©: Ø§Ù†ØªØ¸Ø§Ù… Ø²Ù…Ù†ÙŠØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ©ØŒ ÙÙ‡Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©ØŒ ÙˆØªØ¨Ø±ÙŠØ± Ø£ÙŠ ØªØ­ÙˆÙŠÙ„.",
                                type="ok"
                        ),
                        
                        D("Ø§Ù„Ù‡Ø¯Ù", open = TRUE,
                          tags$ul(
                            tags$li("Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ¹Ø¯Ù… Ø§Ù„ØªÙƒØ±Ø§Ø±."),
                            tags$li("Ù‚ÙŠØ§Ø³ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ© (ÙƒÙ…Ù‘Ø§Ù‹ ÙˆØ¨Ù†ÙŠØ©Ù‹) ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø±Ø±."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (Ø®Ø·Ø£ Ù‚ÙŠØ§Ø³ Ø£Ù… Ø­Ø¯Ø« Ø­Ù‚ÙŠÙ‚ÙŠ)."),
                            tags$li("Ø§Ø®ØªÙŠØ§Ø± ØªØ­ÙˆÙŠÙ„ (log/Boxâ€“Cox) Ø¹Ù†Ø¯ ØªØºÙŠØ± Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰.")
                          )
                        ),
                        
                        D("Ù…ØµØ·Ù„Ø­Ø§Øª (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø·ÙŠ)", open = FALSE,
                          TERM("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ© (NA)",
                               "Ù…Ø´Ø§Ù‡Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ø¹Ù†Ø¯ Ø²Ù…Ù† ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø£Ù† ØªÙˆØ¬Ø¯ ÙÙŠÙ‡ Ù‚ÙŠÙ…Ø©.",
                               purpose="ÙˆØ¬ÙˆØ¯ NA Ù‚Ø¯ ÙŠÙ…Ù†Ø¹ ØªÙ‚Ø¯ÙŠØ± SARIMA Ø£Ùˆ ÙŠØ³Ø¨Ø¨ Ø§Ù†Ø­ÙŠØ§Ø²Ø§Ù‹.",
                               criteria="Ø§Ù„Ø£Ù‡Ù… Ù„ÙŠØ³ Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·ØŒ Ø¨Ù„ Ø·ÙˆÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª ÙˆØªÙˆØ§ØªØ±Ù‡Ø§."),
                          TERM("Ø§Ù„Ø¥Ø­Ù„Ø§Ù„/Ø§Ù„Ø¥ÙƒÙ…Ø§Ù„ (Imputation)",
                               "ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø¨Ù‚ÙŠÙ… Ù…Ø­ØªÙ…Ù„Ø©.",
                               purpose="Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù†Ù…Ø°Ø¬Ø©.",
                               criteria="Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø©: Ø·Ø±Ù‚ Ø¨Ø³ÙŠØ·Ø© Ù‚Ø¯ ØªÙƒÙÙŠØ› Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©: ØªØªØ·Ù„Ø¨ ØªØ¨Ø±ÙŠØ±Ø§Ù‹ Ù‚ÙˆÙŠØ§Ù‹."),
                          TERM("Ù‚ÙŠÙ…Ø© Ø´Ø§Ø°Ø© (Outlier)",
                               "Ù‚ÙŠÙ…Ø© ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ø¹Ø§Ù….",
                               purpose="Ù‚Ø¯ ØªØ´ÙˆÙ‡ ACF/PACF ÙˆØ§Ù„ØªÙ‚Ø¯ÙŠØ±.",
                               criteria="Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø®Ø·Ø£ â†’ ØªØµØ­ÙŠØ­/Ø¥Ø²Ø§Ù„Ø©Ø› Ø¥Ø°Ø§ Ø­Ø¯Ø«Ø§Ù‹ Ø­Ù‚ÙŠÙ‚ÙŠØ§Ù‹ â†’ ØªÙØ­ÙØ¸ ÙˆØªÙØ´Ø±Ø­.")
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø±", open = TRUE,
                          tags$ul(
                            tags$li(tags$b("Ø§Ù„Ø¥Ø­Ù„Ø§Ù„: "),
                                    "ÙØ¬ÙˆØ§Øª Ù‚ØµÙŠØ±Ø© â†’ Ø§Ø³ØªÙŠÙØ§Ø¡ Ø®Ø·ÙŠØ› Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ© â†’ Ø§Ø³ØªÙŠÙØ§Ø¡ Ù…ÙˆØ³Ù…ÙŠØ› ÙØ¬ÙˆØ§Øª Ø·ÙˆÙŠÙ„Ø© â†’ Ø§Ù„Ø­Ø°Ø± Ø§Ù„Ø´Ø¯ÙŠØ¯ ÙˆØ±Ø¨Ù…Ø§ ØªØºÙŠÙŠØ± Ø§Ù„ØªÙˆØ§ØªØ±/Ø§Ù„Ù…ØµØ¯Ø±."),
                            tags$li(tags$b("Ø§Ù„Ø´ÙˆØ§Ø°: "),
                                    "ØªÙ‚ÙŠÙŠÙ… Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚Ø› Ù„Ø§ ØªØ­Ø°Ù ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ø§ Ù‚Ø¯ ÙŠÙ…Ø«Ù„ Ø­Ø¯Ø«Ø§Ù‹ ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ø­ØªØ±Ø§Ù…Ù‡."),
                            tags$li(tags$b("Ø§Ù„ØªØ­ÙˆÙŠÙ„: "),
                                    "Ø¥Ø°Ø§ Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙŠØ²Ø¯Ø§Ø¯ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ â†’ log/Boxâ€“Cox Ù…Ù†Ø§Ø³Ø¨.")
                          )
                        )
        ))
      }
      
      # =======================
      # (2) Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ØµØ±ÙŠ
      # =======================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ÙˆØªØºÙŠØ± Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ù‚Ø·ÙˆØ¹ (breaks) Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙˆØ§Ù„ÙØ±Ù‚ ÙˆØ§Ø®ØªÙŠØ§Ø± s.",
                                type="ok"
                        ),
                        
                        D("Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© + Ù…Ø¹Ø§ÙŠÙŠØ±Ù‡Ø§", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø²Ù…Ù†ÙŠ",
                                                  tags$ul(
                                                    tags$li("Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ø¶Ø­ Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰ â†’ d ØºØ§Ù„Ø¨Ø§Ù‹ > 0."),
                                                    tags$li("Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: Ù‚ÙØ²Ø© Ø¯Ø§Ø¦Ù…Ø©/ØªØ­ÙˆÙ„ Ù†Ø¸Ø§Ù… â†’ Ù‚Ø¯ ÙŠÙ„Ø²Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚Ø·Ø¹ (Ù„ÙŠØ³ SARIMA ÙˆØ­Ø¯Ù‡ Ø¯Ø§Ø¦Ù…Ø§Ù‹).")
                                                  )
                                   ),
                                   criteria_block("A2 â€” Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©",
                                                  tags$ul(
                                                    tags$li("Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: Ù†Ù…Ø· Ù…ØªÙƒØ±Ø± + Ù‚Ù…Ù… ÙÙŠ ACF Ø¹Ù†Ø¯ s,2s,... â†’ Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ©."),
                                                    tags$li("Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: boxplots Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ ØªÙØ¸Ù‡Ø± Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø«Ø§Ø¨ØªØ©.")
                                                  )
                                   ),
                                   criteria_block("A3 â€” Ø§Ù„ØªØ¨Ø§ÙŠÙ†",
                                                  tags$ul(
                                                    tags$li("Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: Ø§ØªØ³Ø§Ø¹ Ø§Ù„ØªØ°Ø¨Ø°Ø¨ ÙŠØ²Ø¯Ø§Ø¯ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ â†’ log/Boxâ€“Cox."),
                                                    tags$li("Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: ØªØ¨Ø§ÙŠÙ† Ø«Ø§Ø¨Øª ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ â†’ Ù„Ø§ ØªØ­ÙˆÙŠÙ„ ØºØ§Ù„Ø¨Ø§Ù‹.")
                                                  )
                                   )
                          )
                        )
        ))
      }
      
      # =======================
      # (3) Ø§Ù„ØªÙÙƒÙŠÙƒ
      # =======================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "ØªÙÙƒÙŠÙƒ ÙˆØµÙÙŠ Ù„Ù„Ø§ØªØ¬Ø§Ù‡/Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©/Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ù„ØªØ¨Ø±ÙŠØ± Ø¬Ù…Ø¹ÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ø¶Ø±Ø¨ÙŠ ÙˆÙ„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø¨Ù†ÙŠØ©.",
                                type="ok"
                        ),
                        
                        D("Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆÙ…Ø¹Ø§ÙŠÙŠØ±", open = TRUE,
                          TERM("ØªÙÙƒÙŠÙƒ Ø¬Ù…Ø¹ÙŠ",
                               "y_t = T_t + S_t + e_t",
                               purpose="Ù…Ù†Ø§Ø³Ø¨ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø´Ø¨Ù‡ Ø«Ø§Ø¨ØªØ©.",
                               criteria="Ù‚Ù…Ù…/Ù‚ÙŠØ¹Ø§Ù† Ù…ÙˆØ³Ù…ÙŠØ© Ù„Ø§ ØªÙƒØ¨Ø± Ù…Ø¹ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰.",
                               formula="y_t = T_t + S_t + e_t"),
                          TERM("ØªÙÙƒÙŠÙƒ Ø¶Ø±Ø¨ÙŠ",
                               "y_t = T_t Ã— S_t Ã— e_t",
                               purpose="Ù…Ù†Ø§Ø³Ø¨ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ØªÙƒØ¨Ø± Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰.",
                               criteria="Ù‚Ù…Ù…/Ù‚ÙŠØ¹Ø§Ù† Ù…ÙˆØ³Ù…ÙŠØ© Ø£ÙƒØ¨Ø± Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø£ÙƒØ¨Ø±.",
                               formula="y_t = T_t Ã— S_t Ã— e_t",
                               notes="ØºØ§Ù„Ø¨Ø§Ù‹ log(y) ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø¬Ù…Ø¹ÙŠØ©."),
                          TERM("STL",
                               "ØªÙÙƒÙŠÙƒ Ù…ÙˆØ³Ù…ÙŠ-Ø§ØªØ¬Ø§Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Loess.",
                               purpose="Ù…Ø±Ù† ÙˆÙ…ØªÙŠÙ† Ø¹Ù†Ø¯ ØªØºÙŠØ± Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø£Ùˆ ÙˆØ¬ÙˆØ¯ Ø´ÙˆØ§Ø°.",
                               criteria="Ù…ÙˆØ³Ù…ÙŠØ© ØºÙŠØ± Ø«Ø§Ø¨ØªØ© ØªÙ…Ø§Ù…Ø§Ù‹ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† Ø£Ùˆ Ø´ÙˆØ§Ø° ÙˆØ§Ø¶Ø­Ø©.")
                        )
        ))
      }
      
      # =======================
      # (4) Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© + Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (ØªÙØµÙŠÙ„ ÙƒØ¨ÙŠØ±)
      # =======================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "Ø§Ø®ØªÙŠØ§Ø± d Ùˆ D Ùˆ s Ø¨Ø­ÙŠØ« ØªØµØ¨Ø­ Ø§Ù„Ø³Ù„Ø³Ù„Ø© (Ø¨Ø¹Ø¯ Ø§Ù„ÙØ±Ù‚) Ù…Ø³ØªÙ‚Ø±Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ØŒ ÙˆÙ‡Ùˆ Ø´Ø±Ø· Ø£Ø³Ø§Ø³ÙŠ Ù„Ù…Ù„Ø§Ø¡Ù…Ø© SARIMA.",
                                type="ok"
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ø®ØªÙŠØ§Ø± s Ùˆ d Ùˆ D", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("Ø§Ø®ØªÙŠØ§Ø± s",
                                                  tags$ul(
                                                    tags$li("Ù…Ù† Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø£ÙˆÙ„Ø§Ù‹ (Ø´Ù‡Ø±ÙŠ 12ØŒ Ø£Ø³Ø¨ÙˆØ¹ÙŠ 52ØŒ ÙŠÙˆÙ…ÙŠ-Ø£Ø³Ø¨ÙˆØ¹ÙŠ 7)."),
                                                    tags$li("Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: Ù‚Ù…Ù… ACF Ø¹Ù†Ø¯ s,2s,... ÙˆÙ†Ù…Ø· Ù…ÙˆØ³Ù…ÙŠ ÙˆØ§Ø¶Ø­.")
                                                  )
                                   ),
                                   criteria_block("Ø§Ø®ØªÙŠØ§Ø± D (ÙØ±Ù‚ Ù…ÙˆØ³Ù…ÙŠ)",
                                                  tags$ul(
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ© ÙˆÙ…Ø³ØªÙ…Ø±Ø© â†’ D=1 ØºØ§Ù„Ø¨Ø§Ù‹ ÙƒØ§ÙÙ."),
                                                    tags$li("ØªØ¬Ù†Ø¨ D=2 Ø¥Ù„Ø§ Ù†Ø§Ø¯Ø±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ ÙˆÙ…Ø¹ ØªØ¨Ø±ÙŠØ± Ù‚ÙˆÙŠ.")
                                                  )
                                   ),
                                   criteria_block("Ø§Ø®ØªÙŠØ§Ø± d (ÙØ±Ù‚ ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ)",
                                                  tags$ul(
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø§ØªØ¬Ø§Ù‡ Ø¹Ø´ÙˆØ§Ø¦ÙŠ (unit root) â†’ d=1 ØºØ§Ù„Ø¨Ø§Ù‹."),
                                                    tags$li("ØªØ¬Ù†Ø¨ d=2 Ø¥Ù„Ø§ Ù†Ø§Ø¯Ø±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø§Ù„ØºØ±Ø¶ + Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø±)", open = TRUE,
                          
                          TEST(
                            name="ADF â€” Ø¯ÙŠÙƒÙŠ-ÙÙˆÙ„Ø± Ø§Ù„Ù…ÙØ¹Ø²Ù‘ÙŽØ²",
                            purpose=paste(
                              "Ø§Ù„ØºØ±Ø¶ Ù‡Ùˆ ÙƒØ´Ù ÙˆØ¬ÙˆØ¯ Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ (Unit Root) Ø£ÙŠ Ø¹Ø¯Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ù† Ù†ÙˆØ¹ Ø§ØªØ¬Ø§Ù‡ Ø¹Ø´ÙˆØ§Ø¦ÙŠ. ",
                              "ÙŠØ®ØªØ¨Ø± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø³Ù„ÙˆÙƒ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙŠØ´Ø¨Ù‡ Ø§Ù„Ù…Ø´ÙŠ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØŒ ÙˆÙŠØ¶ÙŠÙ ÙØ±ÙˆÙ‚Ø§Ù‹ Ù…ØªØ£Ø®Ø±Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ."
                            ),
                            when_to_use="Ù„Ø§Ø®ØªÙŠØ§Ø± d ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ù„ÙØ±Ù‚ Ø£ØµØ¨Ø­Øª Ø£Ù‚Ø±Ø¨ Ù„Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            H0="ÙŠÙˆØ¬Ø¯ Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ â†’ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©.",
                            H1="Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø© (Ø­ÙˆÙ„ Ù…ØªÙˆØ³Ø· Ø£Ùˆ Ø­ÙˆÙ„ Ø§ØªØ¬Ø§Ù‡ Ù…Ø­Ø¯Ø¯ Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯).",
                            statistic="Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù…Ù„ y_{t-1} ÙÙŠ Ù…Ø¹Ø§Ø¯Ù„Ø© ADF Ù…Ø¹ ÙØ±ÙˆÙ‚ Ù…ØªØ£Ø®Ø±Ø©.",
                            decision_rule="Ø¥Ø°Ø§ p < 0.05 â†’ Ù†Ø±ÙØ¶ H0 (Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø­ØªÙ…Ù„Ø©). Ø¥Ø°Ø§ p â‰¥ 0.05 â†’ Ù„Ø§ Ù†Ø±ÙØ¶ H0 (Ù‚Ø¯ ØªØ­ØªØ§Ø¬ ÙØ±Ù‚Ø§Ù‹ Ø¥Ø¶Ø§ÙÙŠØ§Ù‹).",
                            interpretation="Ø±ÙØ¶ H0 Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ (d,D) ÙŠØ¹Ù†ÙŠ Ø£Ù† Ù†Ù…Ø°Ø¬Ø© ARMA (ÙˆÙ…Ù† Ø«Ù… SARIMA) Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù…ÙÙØ±Ù‘ÙŽÙ‚Ø© Ø£ØµØ¨Ø­Øª Ù…Ù†Ø·Ù‚ÙŠØ©.",
                            reporting="Ø§Ø°ÙƒØ± Ù‡Ù„ Ø£Ø¯Ø±Ø¬Øª drift/trendØŒ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¨Ø·Ø§Ø¡Ø§ØªØŒ p-value ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø­ÙˆÙ„ d.",
                            caveats="Ø­Ø³Ø§Ø³ Ù„Ø§Ø®ØªÙŠØ§Ø± drift/trend ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¨Ø·Ø§Ø¡Ø§ØªØ› ÙˆØ§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ù‚Ø¯ ØªØ¶Ù„Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±."
                          ),
                          
                          TEST(
                            name="KPSS â€” Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙƒÙØ±Ø¶ÙŠØ© ØµÙØ±ÙŠØ©",
                            purpose=paste(
                              "Ø§Ù„ØºØ±Ø¶ Ù‡Ùˆ ÙØ­Øµ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ø£Ù† H0 Ù‡Ù†Ø§ Ù‡ÙŠ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©. ",
                              "Ù‡Ø°Ø§ ÙŠØ¹Ø§ÙƒØ³ ADF ÙˆÙŠÙØ³ØªØ®Ø¯Ù… Ù„Ù„ØªØ«Ù„ÙŠØ« (triangulation) Ø¹Ù†Ø¯Ù…Ø§ ØªØ®ØªÙ„Ù Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª."
                            ),
                            when_to_use="Ù„ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ÙØ±Ù‚ ÙˆÙ„ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ ADF/PP.",
                            H0="Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø© (Ù…Ø³ØªÙˆÙ‰ Ø£Ùˆ Ø­ÙˆÙ„ Ø§ØªØ¬Ø§Ù‡ Ø­Ø³Ø¨ Ø§Ù„Ù†Ø³Ø®Ø©).",
                            H1="Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©.",
                            statistic="Ø¥Ø­ØµØ§Ø¡ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹ ØªØ±Ø§ÙƒÙ…ÙŠ Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± ÙˆØªÙ‚Ø¯ÙŠØ± ØªØ¨Ø§ÙŠÙ† Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø¯.",
                            decision_rule="Ø¥Ø°Ø§ p < 0.05 â†’ Ù†Ø±ÙØ¶ H0 (Ø¹Ø¯Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©). Ø¥Ø°Ø§ p â‰¥ 0.05 â†’ Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            interpretation="Ø¥Ø°Ø§ KPSS Ù„Ø§ ÙŠØ±ÙØ¶ Ø¨Ø¹Ø¯ Ø§Ù„ÙØ±Ù‚ ÙÙ‡Ø°Ø§ ÙŠØ¯Ø¹Ù… Ø£Ù† Ø§Ù„ÙØ±Ù‚ ÙƒØ§Ù† ÙƒØ§ÙÙŠØ§Ù‹Ø› ÙˆØ¥Ø°Ø§ Ø±ÙØ¶ ÙÙ‚Ø¯ ØªØ­ØªØ§Ø¬ d/D Ø£Ùˆ ØªÙˆØ¬Ø¯ Ù‚Ø·ÙˆØ¹.",
                            reporting="Ø­Ø¯Ø¯ Ù†Ø³Ø®Ø© Level/TrendØŒ p-value ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬.",
                            caveats="ÙŠØªØ£Ø«Ø± Ø¨Ø®ÙŠØ§Ø±Ø§Øª ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø¯ ÙˆØ¨Ø§Ù„Ù‚Ø·ÙˆØ¹ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©."
                          ),
                          
                          TEST(
                            name="PP â€” ÙÙŠÙ„ÙŠØ¨Ø³-Ø¨ÙŠØ±ÙˆÙ† (Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ Ø¨ØªØµØ­ÙŠØ­ ØºÙŠØ± Ù…Ø¹Ù„Ù…ÙŠ)",
                            purpose="Ù…Ø«Ù„ ADF Ù„ÙƒÙ†Ù‡ ÙŠØµØ­Ø­ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ/ØªØºØ§ÙŠØ± Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø·Ø±ÙŠÙ‚Ø© ØºÙŠØ± Ù…Ø¹Ù„Ù…ÙŠØ© Ø¨Ø¯Ù„ Ø¥Ø¶Ø§ÙØ© Ø¥Ø¨Ø·Ø§Ø¡Ø§Øª ÙƒØ«ÙŠØ±Ø©.",
                            when_to_use="ÙƒÙ…ÙƒÙ…Ù„ Ù„Ù€ ADF Ø®ØµÙˆØµØ§Ù‹ Ø¹Ù†Ø¯Ù…Ø§ ØªØ´Ùƒ Ø¨ÙˆØ¬ÙˆØ¯ ØªØºØ§ÙŠØ± ØªØ¨Ø§ÙŠÙ† Ø£Ùˆ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ ADF.",
                            H0="ÙŠÙˆØ¬Ø¯ Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ â†’ Ø¹Ø¯Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            H1="Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            statistic="Ø¥Ø­ØµØ§Ø¡ DF Ù…Ø¹ ØªØµØ­ÙŠØ­ Ù„Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ.",
                            decision_rule="p < 0.05 â†’ Ø±ÙØ¶ H0 â†’ Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø­ØªÙ…Ù„Ø©.",
                            interpretation="ØªÙˆØ§ÙÙ‚ ADF ÙˆPP ÙŠØ¹Ø·ÙŠ Ø«Ù‚Ø© Ø£Ø¹Ù„Ù‰Ø› Ø§Ø®ØªÙ„Ø§ÙÙ‡Ù…Ø§ ÙŠØ³ØªØ¯Ø¹ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ÙØ­Øµ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ØªØ´Ø®ÙŠØµØ§Øª.",
                            reporting="Ø£Ø¨Ù„Øº Ø¹Ù† p-value ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¶Ù…Ù† Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„/Ø§Ù„ÙØ±Ù‚.",
                            caveats="Ø­Ø³Ø§Ø³ Ù„Ù„Ù‚Ø·ÙˆØ¹ØŒ ÙˆÙŠØªØ£Ø«Ø± Ø¨Ø¥Ø¯Ø±Ø§Ø¬ drift/trend."
                          )
                        ),
                        
                        D("Ù‚ÙˆØ§Ø¹Ø¯ Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± (d,D)", open = TRUE,
                          tags$ul(
                            tags$li(tags$b("Ø£ÙØ¶Ù„ Ø§ØªÙØ§Ù‚: "), "ADF/PP ÙŠØ±ÙØ¶Ø§Ù† Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ÙˆØ­Ø¯ÙˆÙŠ (p ØµØºÙŠØ±) ÙˆKPSS Ù„Ø§ ÙŠØ±ÙØ¶ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© (p ÙƒØ¨ÙŠØ±)."),
                            tags$li(tags$b("Ø¹Ø¯Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙˆØ§Ø¶Ø­Ø©: "), "ADF/PP Ù„Ø§ ÙŠØ±ÙØ¶Ø§Ù† ÙˆKPSS ÙŠØ±ÙØ¶."),
                            tags$li(tags$b("ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ÙØ±Ù‚: "), "Ø¥Ø°Ø§ Ø¸Ù‡Ø±Øª ACF Ø³Ù„Ø¨ÙŠØ© Ù‚ÙˆÙŠØ© Ø¹Ù†Ø¯ lag1 Ø¨Ø¹Ø¯ Ø§Ù„ÙØ±Ù‚ â†’ d ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹.")
                          )
                        )
        ))
      }
      
      # =======================
      # (5) Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³
      # =======================
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "Ø¨Ù†Ø§Ø¡ Ø®Ø· Ø£Ø³Ø§Ø³ ÙˆØ§Ø¶Ø­ (Naive/Naive Ù…ÙˆØ³Ù…ÙŠ) + Ù†Ù…ÙˆØ°Ø¬ Auto-ARIMA Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙƒØ±Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.",
                                type="ok"
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("AICc/BIC",
                                                  tags$ul(
                                                    tags$li("Ø§Ù„Ø£ÙØ¶Ù„ÙŠØ© Ù„Ù€ AICc Ù„Ù„ØªÙ†Ø¨Ø¤ ØºØ§Ù„Ø¨Ø§Ù‹Ø› BIC Ø£ÙƒØ«Ø± ØµØ±Ø§Ù…Ø© ÙÙŠ Ù…Ø¹Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ¹Ù‚ÙŠØ¯."),
                                                    tags$li("Ø¥Ø°Ø§ Î”AICc < 2 â†’ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙ‚Ø§Ø±Ø¨Ø© â†’ Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¨Ø³Ø·.")
                                                  )
                                   ),
                                   criteria_block("Ø§Ù„Ø£Ù‡Ù… Ù…Ù† AICc",
                                                  tags$ul(
                                                    tags$li("ØªØ´Ø®ÙŠØµ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ (Ljungâ€“Box) + Ø£Ø¯Ø§Ø¡ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø¹ÙŠÙ†Ø©."),
                                                    tags$li("Ø§Ù„ØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Naive/Naive Ù…ÙˆØ³Ù…ÙŠ Ø´Ø±Ø· Ø¹Ù…Ù„ÙŠ Ù‚ÙˆÙŠ.")
                                                  )
                                   )
                          )
                        )
        ))
      }
      
      # =======================
      # (6) ACF/PACF
      # =======================
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ø¬Ù…ÙˆØ¹Ø© ØµØºÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† (3â€“8) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ACF/PACF Ø«Ù… Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆÙÙ‚ Ù…Ø¹Ø§ÙŠÙŠØ± ÙˆØ§Ø¶Ø­Ø©.",
                                type="ok"
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± ØªØ­Ø¯ÙŠØ¯ p,q,P,Q", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ p,q",
                                                  tags$ul(
                                                    tags$li("PACF ØªÙ‚Ø·Ø¹ Ø¨Ø¹Ø¯ p ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ â†’ AR(p) Ù…Ø±Ø´Ø­."),
                                                    tags$li("ACF ØªÙ‚Ø·Ø¹ Ø¨Ø¹Ø¯ q ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ â†’ MA(q) Ù…Ø±Ø´Ø­."),
                                                    tags$li("Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ØµØºÙŠØ±Ø© Ù…Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø¶Ø±ÙˆØ±Ø©.")
                                                  )
                                   ),
                                   criteria_block("Ù…ÙˆØ³Ù…ÙŠ P,Q",
                                                  tags$ul(
                                                    tags$li("Ù‚Ù…Ù… PACF Ø¹Ù†Ø¯ s â†’ P=1 Ù…Ø±Ø´Ø­."),
                                                    tags$li("Ù‚Ù…Ù… ACF Ø¹Ù†Ø¯ s â†’ Q=1 Ù…Ø±Ø´Ø­."),
                                                    tags$li("ØºØ§Ù„Ø¨Ø§Ù‹ P,Q âˆˆ {0,1}.")
                                                  )
                                   )
                          )
                        )
        ))
      }
      
      # =======================
      # (7) Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
      # =======================
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "ØªØ£ÙƒÙŠØ¯ Ø£Ù† Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© Ø²Ù…Ù†ÙŠØ© (â‰ˆ Ø¶ÙˆØ¶Ø§Ø¡ Ø¨ÙŠØ¶Ø§Ø¡) ÙˆØ£Ù† Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ØªØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³.",
                                type="ok"
                        ),
                        
                        D("Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ (ØªÙØµÙŠÙ„)", open = TRUE,
                          TEST(
                            name="Ljungâ€“Box",
                            purpose="Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ø°Ø§ØªÙŠØ© ÙÙŠ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ø­ØªÙ‰ Ø±ØªØ¨Ø© L ØªØ³Ø§ÙˆÙŠ ØµÙØ±Ø§Ù‹ Ø¨Ø´ÙƒÙ„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ. Ø¥Ø°Ø§ Ø±ÙÙØ¶ H0 ÙÙ‡Ù†Ø§Ùƒ Ø¨Ù†ÙŠØ© Ø²Ù…Ù†ÙŠØ© ØºÙŠØ± Ù…ÙÙØ³Ù‘ÙŽØ±Ø© ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.",
                            when_to_use="Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨Ø¹Ø¯ Ù…Ù„Ø§Ø¡Ù…Ø© SARIMA.",
                            H0="Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ ÙÙŠ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ø­ØªÙ‰ L.",
                            H1="ÙŠÙˆØ¬Ø¯ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ ÙÙŠ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ.",
                            decision_rule="p â‰¥ 0.05 â†’ Ù…Ù‚Ø¨ÙˆÙ„ ØºØ§Ù„Ø¨Ø§Ù‹. p < 0.05 â†’ Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (p/q/P/Q Ø£Ùˆ d/D).",
                            interpretation="Ø±ÙØ¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ±Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø²Ù…Ù†ÙŠØ© ÙÙŠ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ â†’ ØªÙ†Ø¨Ø¤Ø§Øª Ø£Ù‚Ù„ Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©.",
                            caveats="Ø§Ø®ØªÙŠØ§Ø± L Ù…Ù‡Ù…ØŒ ÙˆÙ…Ø¹ n ÙƒØ¨ÙŠØ± ÙŠØµØ¨Ø­ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø³Ø§Ø³Ø§Ù‹."
                          ),
                          TEST(
                            name="ARCH LM",
                            purpose="ÙƒØ´Ù ØªÙƒØªÙ„ Ø§Ù„ØªØ°Ø¨Ø°Ø¨ (ØªØºØ§ÙŠØ± ØªØ¨Ø§ÙŠÙ† Ø´Ø±Ø·ÙŠ). Ù…Ù‡Ù… Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø§Ù„ÙŠØ© Ø£Ùˆ ÙŠØ¸Ù‡Ø± ØªØºÙŠØ± ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†.",
                            when_to_use="Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨ØªØºÙŠØ± Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø£Ùˆ ÙÙŠ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ù…Ø§Ù„ÙŠØ©.",
                            H0="Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ£Ø«ÙŠØ±Ø§Øª ARCH.",
                            H1="ØªÙˆØ¬Ø¯ ØªØ£Ø«ÙŠØ±Ø§Øª ARCH.",
                            decision_rule="p < 0.05 â†’ ÙÙƒØ± ÙÙŠ GARCH/Ù†Ù…Ø°Ø¬Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ†.",
                            caveats="ÙŠØªØ£Ø«Ø± Ø¨Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¨Ø·Ø§Ø¡Ø§Øª ÙˆÙˆØ¬ÙˆØ¯ Ø´ÙˆØ§Ø°."
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", open = TRUE,
                          tags$ul(
                            tags$li("ÙŠØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Naive/Naive Ù…ÙˆØ³Ù…ÙŠ ÙÙŠ MAE/RMSE."),
                            tags$li("Ljungâ€“Box ØºÙŠØ± Ø¯Ø§Ù„ (pâ‰¥0.05) Ø¹Ù†Ø¯ Ù„Ø§ØºØ§Øª Ù…Ø¹Ù‚ÙˆÙ„Ø©."),
                            tags$li("Ø¥Ø°Ø§ ØªØ¹Ø§Ø¯Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ â†’ Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¨Ø³Ø·.")
                          )
                        )
        ))
      }
      
      # =======================
      # (8) Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆØ§Ù„Ø®Ù„Ø§ØµØ©
      # =======================
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                                "ØµÙŠØ§ØºØ© Ø®Ù„Ø§ØµØ© ÙˆØ§Ø¶Ø­Ø©: Ù…Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŸ Ù„Ù…Ø§Ø°Ø§ØŸ Ù…Ø§Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø°Ù„ÙƒØŸ ÙˆÙ…Ø§ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ØŸ",
                                type="ok"
                        ),
                        
                        D("ØµÙŠØºØ© SARIMA", open = TRUE,
                          tags$ul(
                            tags$li(
                              tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
                              " Ø­ÙŠØ« ",
                              tags$code("Îµ_t ~ w.n.(0, Ïƒ^2)")
                            )
                          )
                        ),
                        
                        D("Ù‚Ø§Ù„Ø¨ Ø®Ø§ØªÙ…Ø© Ø¬Ø§Ù‡Ø²", open = FALSE,
                          tags$p(
                            tags$b("Ø®Ù„Ø§ØµØ© (Ù†Ù…ÙˆØ°Ø¬ Ù†Øµ). "),
                            "Â« ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ SARIMA((p,d,q)(P,D,Q)[s]) Ø¨Ø¹Ø¯ ØªØ«Ø¨ÙŠØª s ÙˆØ§Ø®ØªÙŠØ§Ø± d ÙˆD Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ADF/KPSS/PP ÙˆØ§Ù„ØªØ´Ø®ÙŠØµØ§Øª. ",
                            "Ø£Ø¸Ù‡Ø±Øª Ø¨ÙˆØ§Ù‚ÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø³Ù„ÙˆÙƒØ§Ù‹ Ù‚Ø±ÙŠØ¨Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ (Ljungâ€“Box ØºÙŠØ± Ø¯Ø§Ù„ Ø¹Ù†Ø¯ Î±=0.05)ØŒ ",
                            "ÙƒÙ…Ø§ ØªÙÙˆÙ‚Øª Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø®Ø§Ø±Ø¬ Ø§Ù„Ø¹ÙŠÙ†Ø© Ø¹Ù„Ù‰ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³ (Naive/Naive Ù…ÙˆØ³Ù…ÙŠ) ÙˆÙÙ‚ MAE ÙˆRMSE. ",
                            "ÙŠØ¹Ù†ÙŠ Ø°Ù„Ùƒ Ø£Ù† Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§ØªØ¬Ø§Ù‡/Ù…ÙˆØ³Ù…ÙŠØ©/Ø§Ø¹ØªÙ…Ø§Ø¯ Ù‚ØµÙŠØ± Ø§Ù„Ø£Ø¬Ù„) Ù‚Ø¯ ØªÙ… Ø§Ù„ØªÙ‚Ø§Ø·Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø§Ø¦Ù… Ø¶Ù…Ù† Ø­Ø¯ÙˆØ¯ Ø«Ø¨Ø§Øª Ø§Ù„Ø¨Ù†ÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†. Â»"
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "Ø®Ø·ÙˆØ© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©.")
    }
    
    # ----------------------------
    # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ…Ø±ÙŠØ±
    # ----------------------------
    k <- input$roadmap_step_ar
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Ø®Ø§Ø±Ø·Ø© Ø·Ø±ÙŠÙ‚ SARIMA (Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹) â€” Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰"),
                          tags$p(class="road-sub",
                                 "Ø§Ø³ØªØ®Ø¯Ù… Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù„Ù„ØªÙ†Ù‚Ù„ Ø¯ÙˆÙ† ØªÙ…Ø±ÙŠØ± Ø§Ù„ØµÙØ­Ø©. ÙƒÙ„ Ø®Ø·ÙˆØ©: Ø§Ù„Ù‡Ø¯Ù â†’ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª â†’ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª â†’ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø± â†’ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª â†’ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_ar",
                 label   = "Ø§Ù„Ø®Ø·ÙˆØ© (Ø´Ø±ÙŠØ· ØªÙ…Ø±ÙŠØ± â€” Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„ØªÙ…Ø±ÙŠØ± Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙØ­Ø©)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  # ============================================================
  # EXTREMELY DETAILED SARIMA ROADMAP (FR) â€” Slider + Collapsibles
  # Expanded with: detailed explanatory sentences for definitions + workflow steps
  # Organized by: Objectif â†’ Analyses â†’ Tests â†’ CritÃ¨res â†’ Sorties â†’ PiÃ¨ges
  #
  # HOW TO USE
  # 1) In your UI:   uiOutput("roadmap_Detailed_Fr_ui")
  # 2) In server(): paste EVERYTHING below inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui7 <- renderUI({
    
    # ----------------------------
    # Helpers: accordion building
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # level 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # level 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    # A paragraph helper for readable long sentences
    P <- function(...) tags$p(...)
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
                     notes = NULL, how_to_apply = NULL, what_to_write = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("DÃ©finition : "), definition),
                 if (!is.null(purpose))       P(tags$b("But / utilitÃ© : "), purpose) else NULL,
                 if (!is.null(criteria))      P(tags$b("CritÃ¨res / indices : "), criteria) else NULL,
                 if (!is.null(how_to_apply))  P(tags$b("Comment lâ€™utiliser dans lâ€™analyse : "), how_to_apply) else NULL,
                 if (!is.null(formula))       P(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example))       P(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(what_to_write)) P(tags$b("Phrase type (Ã  Ã©crire) : "), what_to_write) else NULL,
                 if (!is.null(notes))         P(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("But (trÃ¨s dÃ©taillÃ©) : "), purpose),
                 P(tags$b("Quand lâ€™utiliser : "), when_to_use),
                 P(tags$b("H0 : "), H0),
                 P(tags$b("H1 : "), H1),
                 if (!is.null(statistic))                P(tags$b("Statistique / idÃ©e : "), statistic) else NULL,
                 if (!is.null(decision_rule))            P(tags$b("RÃ¨gle de dÃ©cision : "), decision_rule) else NULL,
                 if (!is.null(interpretation))           P(tags$b("InterprÃ©tation (sens) : "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices))P(tags$b("Ce que Ã§a implique pour vos choix : "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                P(tags$b("Comment le rapporter : "), reporting) else NULL,
                 if (!is.null(caveats))                  P(tags$b("Limites / piÃ¨ges : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
    .tight ol {margin: 6px 0 6px 18px;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
    .muted {color:#555;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step labels & badges
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Cadrer le problÃ¨me & la validation",
        "[1] QualitÃ© des donnÃ©es & prÃ©paration (NA, frÃ©quence, outliers)",
        "[2] Exploration visuelle (tendance, saison, variance)",
        "[3] DÃ©composition (additif/multiplicatif, STL)",
        "[4] StationnaritÃ© & diffÃ©renciation (choix d, D, s) + tests",
        "[5] Baseline (naÃ¯f / auto-ARIMA) + critÃ¨res de sÃ©lection",
        "[6] Identification manuelle (ACF/PACF) + grille candidates",
        "[7] Diagnostics & comparaison finale (tests rÃ©sidus + forecasting)",
        "[8] RÃ©daction: conclusion, signification, et livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Horizon", "Protocole", "MÃ©triques"),
        c("FrÃ©quence", "NA", "Outliers", "Transformations"),
        c("Graphiques", "SaisonnalitÃ©", "Variance", "Signal"),
        c("STL", "Additif vs multiplicatif", "Structure"),
        c("ADF/KPSS/PP", "d/D/s", "RÃ¨gles de choix"),
        c("Baseline", "AICc/BIC", "NaÃ¯f"),
        c("ACF/PACF", "Parcimonie", "Candidats"),
        c("Ljungâ€“Box", "ARCH", "NormalitÃ©", "Accuracy"),
        c("SynthÃ¨se", "Conclusion", "Sens", "Reproductible")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ----------------------------
    # Small helpers (criteria blocks)
    # ----------------------------
    criteria_block <- function(title, ..., note = NULL) {
      tags$div(class="box",
               tags$h5(title),
               if (!is.null(note)) tags$p(class="muted", note) else NULL,
               ...
      )
    }
    
    decision_rule_list <- function(...) {
      tags$ul(...)
    }
    
    # ------------------------------------------------------------
    # Step content (highly structured + expanded sentences)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================================================
      # STEP 0 â€” Cadrer
      # =========================================================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "dÃ©finir clairement la tÃ¢che de prÃ©vision et un protocole dâ€™Ã©valuation fiable, car un modÃ¨le SARIMA ne peut pas Ãªtre jugÃ© correctement si lâ€™objectif, lâ€™horizon et la validation ne sont pas explicitement fixÃ©s dÃ¨s le dÃ©part.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("Ã€ cette Ã©tape, lâ€™Ã©tudiant doit produire une description opÃ©rationnelle du problÃ¨me : quelle variable est prÃ©vue, sur quelle grille temporelle, avec quel horizon, et selon quelle rÃ¨gle dâ€™Ã©valuation. Lâ€™idÃ©e est simple : si deux Ã©tudiants choisissent des horizons ou des splits diffÃ©rents, ils ne rÃ©pondent plus au mÃªme problÃ¨me et leurs rÃ©sultats ne sont pas comparables."),
                          tags$ul(
                            tags$li("DÃ©finir la cible ", tags$code("y_t"), " et la frÃ©quence (rÃ©gularitÃ© temporelle)."),
                            tags$li("Fixer un horizon ", tags$code("h"), " rÃ©aliste (usage mÃ©tier / dÃ©cision)."),
                            tags$li("Fixer un protocole de validation (train/test, rolling-origin) et les mÃ©triques (MAE/RMSE/...)."),
                            tags$li("DÃ©finir les benchmarks : naÃ¯f et naÃ¯f saisonnier si saison.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          P("Ici, on construit la â€œboÃ®te noireâ€ de lâ€™Ã©valuation : on sâ€™assure que le temps est respectÃ© (pas de mÃ©lange passÃ©/futur), et on choisit des mÃ©triques qui correspondent aux coÃ»ts dâ€™erreur. Un bon modÃ¨le pour RMSE nâ€™est pas toujours celui qui optimise MAE : dâ€™oÃ¹ lâ€™intÃ©rÃªt dâ€™en retenir au moins deux."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” DÃ©finir la frÃ©quence & la saison (s)",
                                                  note = "Objectif : garantir que la sÃ©rie vit sur une grille rÃ©guliÃ¨re et que la saisonnalitÃ© s a une signification rÃ©elle (calendrier + donnÃ©es).",
                                                  tags$ul(
                                                    tags$li("Identifier la granularitÃ© : jour / semaine / mois / etc."),
                                                    tags$li("DÃ©duire la saison ", tags$code("s"), " (ex : mensuel s=12, trimestriel s=4, quotidien hebdo s=7)."),
                                                    tags$li("VÃ©rifier lâ€™absence de trous ou doublons dâ€™index (rÃ©gularitÃ©).")
                                                  ),
                                                  P("Si la frÃ©quence est irrÃ©guliÃ¨re, SARIMA â€œvoitâ€ des retards qui ne reprÃ©sentent pas le mÃªme temps rÃ©el, ce qui casse la logique des dÃ©pendances (ACF/PACF) et rend les paramÃ¨tres difficiles Ã  interprÃ©ter.")
                                   ),
                                   criteria_block("A2 â€” DÃ©finir la validation",
                                                  note = "Objectif : mesurer la performance sur du futur non vu, comme dans la vraie vie.",
                                                  tags$ul(
                                                    tags$li(tags$b("Train/Test temporel : "), "entraÃ®ner sur le passÃ©, tester sur le futur (jamais lâ€™inverse)."),
                                                    tags$li(tags$b("Rolling-origin : "), "Ã©valuer sur plusieurs origines â†’ plus robuste."),
                                                    tags$li("Fixer la taille test : typiquement â‰¥ 1 saison (ex : â‰¥ 12 mois en mensuel) si possible.")
                                                  ),
                                                  P("Le rolling-origin est conseillÃ© quand on veut enseigner la rÃ©alitÃ© opÃ©rationnelle : le modÃ¨le est mis Ã  jour au fil du temps et Ã©valuÃ© plusieurs fois, ce qui rÃ©duit le risque de â€œchanceâ€ sur un seul split.")
                                   ),
                                   criteria_block("A3 â€” Choisir mÃ©triques",
                                                  note = "Objectif : aligner la mesure dâ€™erreur avec le sens mÃ©tier (unitÃ©s vs pÃ©nalisation des grosses erreurs).",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE : "), "robuste, lisible en unitÃ©s."),
                                                    tags$li(tags$b("RMSE : "), "pÃ©nalise fortement les grosses erreurs."),
                                                    tags$li(tags$b("MAPE : "), "uniquement si y>0 et loin de 0 ; sinon prÃ©fÃ©rer sMAPE/MAE."),
                                                    tags$li(tags$b("sMAPE : "), "alternative % plus stable que MAPE.")
                                                  ),
                                                  P("En pÃ©dagogie, MAE rÃ©pond Ã  la question : â€œen moyenne, je me trompe de combien ?â€. RMSE rÃ©pond Ã  : â€œest-ce que jâ€™Ã©vite vraiment les grosses erreurs ?â€. Les deux ensemble donnent une lecture plus complÃ¨te.")
                                   )
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          P("Les critÃ¨res ci-dessous transforment lâ€™Ã©tape 0 en dÃ©cisions concrÃ¨tes. Ã€ chaque dÃ©cision, lâ€™Ã©tudiant doit pouvoir expliquer pourquoi ce choix est cohÃ©rent avec le problÃ¨me et comment il impacte la suite (stationnaritÃ©, saisonnalitÃ©, mÃ©triques)."),
                          decision_rule_list(
                            tags$li(tags$b("Horizon h : "), "doit correspondre au besoin. Exemple : si la dÃ©cision est mensuelle (commande, budget), lâ€™horizon doit Ãªtre exprimÃ© en mois et couvrir au moins une fenÃªtre utile de dÃ©cision."),
                            tags$li(tags$b("Protocole : "), "si donnÃ©es suffisantes, prÃ©fÃ©rer rolling-origin car il Ã©value plusieurs futurs. Si les donnÃ©es sont courtes, utiliser un split temporel clair et lâ€™expliquer (dates exactes)."),
                            tags$li(tags$b("MÃ©triques : "), "choisir au moins 2 (ex : MAE + RMSE) pour Ã©viter de sur-optimiser une seule notion dâ€™erreur."),
                            tags$li(tags$b("Benchmark : "), "toujours comparer Ã  un naÃ¯f (et saisonnier si saison). Si votre modÃ¨le ne bat pas le naÃ¯f, la conclusion â€œnÃ©gativeâ€ est informative : votre sÃ©rie est peut-Ãªtre difficile, ou le modÃ¨le est incomplet.")
                          )
                        ),
                        
                        D("DÃ©finitions clÃ©s (cliquables)", open = FALSE,
                          TERM(
                            term="SÃ©rie temporelle (y_t)",
                            definition="Une sÃ©rie temporelle est une sÃ©quence dâ€™observations ordonnÃ©es par le temps, oÃ¹ chaque valeur y_t correspond Ã  lâ€™Ã©tat du phÃ©nomÃ¨ne Ã  lâ€™instant t (par exemple, ventes mensuelles, tempÃ©rature quotidienne, trafic horaire).",
                            purpose="Cette dÃ©finition force Ã  identifier clairement ce qui est observÃ©, Ã  quelle frÃ©quence, et dans quelles unitÃ©s, car SARIMA modÃ©lise la dÃ©pendance entre observations successives.",
                            criteria="On doit pouvoir rÃ©pondre : quelle unitÃ© ? quelle frÃ©quence ? quelles dates ? y_t contient-il des valeurs nulles ou nÃ©gatives (important pour log/Boxâ€“Cox) ?",
                            how_to_apply="Avant toute modÃ©lisation, on vÃ©rifie que la sÃ©rie est triÃ©e par date, sans doublons, et que chaque pas de temps attendu est prÃ©sent (ou explicitement manquant).",
                            what_to_write="Â« La variable dâ€™intÃ©rÃªt y_t correspond Ã  [dÃ©finition], observÃ©e Ã  une frÃ©quence [..] entre [dÃ©but] et [fin]. Â»"
                          ),
                          TERM(
                            term="Horizon de prÃ©vision (h)",
                            definition="Lâ€™horizon h est le nombre de pas dans le futur que lâ€™on souhaite prÃ©dire. Par exemple, h=12 en mensuel signifie prÃ©voir les 12 prochains mois.",
                            purpose="Lâ€™horizon dÃ©finit la difficultÃ© : plus h est grand, plus lâ€™incertitude augmente et plus la saisonnalitÃ©/tendance doivent Ãªtre correctement capturÃ©es.",
                            criteria="h doit Ãªtre cohÃ©rent avec lâ€™usage : prÃ©voir 1 jour pour une dÃ©cision annuelle nâ€™a pas de sens, et prÃ©voir 24 mois avec seulement 30 mois de donnÃ©es est risquÃ©.",
                            how_to_apply="On fixe h avant de tester des modÃ¨les, car changer h change la conclusion (un modÃ¨le peut Ãªtre excellent Ã  court terme et moyen Ã  long terme).",
                            formula="h"
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("Ã€ la fin de lâ€™Ã©tape 0, lâ€™Ã©tudiant doit pouvoir donner Ã  nâ€™importe qui une fiche-problÃ¨me complÃ¨te : si une autre personne refait lâ€™analyse, elle doit obtenir la mÃªme configuration dâ€™Ã©valuation."),
                          tags$ul(
                            tags$li("Description complÃ¨te de y_t (dÃ©finition, unitÃ©, frÃ©quence, dates)."),
                            tags$li("h + protocole (split/rolling) + mÃ©triques + benchmarks."),
                            tags$li("RÃ¨gles de reproductibilitÃ© (seed si random, dates exactes du split).")
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("MÃ©langer le temps (shuffle) : fuite dâ€™information â†’ rÃ©sultats artificiellement Ã©levÃ©s."),
                            tags$li("Comparer des modÃ¨les avec des splits diffÃ©rents â†’ comparaison invalide."),
                            tags$li("MAPE avec yâ‰ˆ0 : lâ€™erreur relative explose et peut dominer lâ€™Ã©valuation.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 1 â€” QualitÃ© / PrÃ©paration
      # =========================================================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "garantir que la sÃ©rie est exploitable (grille rÃ©guliÃ¨re, NA traitÃ©s, anomalies comprises) et surtout documenter chaque transformation, car une â€œpetite correctionâ€ non expliquÃ©e peut changer totalement les tests (stationnaritÃ©, ACF/PACF) et donc la spÃ©cification SARIMA.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("Lâ€™objectif pÃ©dagogique est que lâ€™Ã©tudiant distingue un problÃ¨me de donnÃ©es (index, NA, erreur de saisie) dâ€™un phÃ©nomÃ¨ne rÃ©el (Ã©vÃ©nement, promotion, crise). SARIMA doit apprendre le comportement rÃ©el de la sÃ©rie : on corrige les erreurs, mais on ne supprime pas lâ€™histoire."),
                          tags$ul(
                            tags$li("VÃ©rifier frÃ©quence rÃ©guliÃ¨re, dates uniques, tri temporel correct."),
                            tags$li("DÃ©tecter et traiter NA (selon nature du manque)."),
                            tags$li("Identifier outliers (erreur vs Ã©vÃ©nement rÃ©el)."),
                            tags$li("DÃ©cider transformations (log/Boxâ€“Cox) si variance non constante.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          P("On suit une logique en quatre contrÃ´les : (1) grille temporelle, (2) valeurs manquantes, (3) valeurs aberrantes, (4) transformation dâ€™Ã©chelle. Chaque contrÃ´le est associÃ© Ã  un choix, et chaque choix doit Ãªtre justifiÃ© par un critÃ¨re (pas â€œpar habitudeâ€)."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” RÃ©gularitÃ© temporelle",
                                                  note = "Objectif : sâ€™assurer que â€œ1 pas de tempsâ€ veut dire la mÃªme chose partout dans la sÃ©rie.",
                                                  tags$ul(
                                                    tags$li("VÃ©rifier que chaque date attendue existe exactement une fois."),
                                                    tags$li("VÃ©rifier lâ€™espacement constant (pas dâ€™irrÃ©gularitÃ©).")
                                                  ),
                                                  P("Si lâ€™index est irrÃ©gulier, vous risquez dâ€™induire de fausses autocorrÃ©lations (un retard de 1 nâ€™est plus un intervalle constant). SARIMA doit reposer sur une base temporelle propre.")
                                   ),
                                   criteria_block("A2 â€” Manquants (NA)",
                                                  note = "Objectif : comprendre la structure du manque avant dâ€™imputer.",
                                                  tags$ul(
                                                    tags$li("Mesurer %NA + longueurs de sÃ©quences manquantes (gaps)."),
                                                    tags$li("DÃ©crire si le manque est structurel (jours fÃ©riÃ©s, pannes)."),
                                                    tags$li("Choisir une mÃ©thode dâ€™imputation justifiÃ©e.")
                                                  ),
                                                  P("Un NA isolÃ© ne pose pas la mÃªme question quâ€™un mois entier manquant. Plus le gap est long, plus lâ€™imputation â€œinventeâ€ de lâ€™information et doit Ãªtre discutÃ©e dans le rapport.")
                                   ),
                                   criteria_block("A3 â€” Outliers",
                                                  note = "Objectif : dÃ©cider si une valeur atypique est une erreur ou un signal rÃ©el que le modÃ¨le doit respecter.",
                                                  tags$ul(
                                                    tags$li("DÃ©tecter (IQR / z-score robuste / inspection) + valider contexte."),
                                                    tags$li("DÃ©cider : corriger (erreur) vs conserver (Ã©vÃ©nement).")
                                                  ),
                                                  P("Un outlier peut Ãªtre un Ã©vÃ©nement rÃ©el (promo, rupture, changement politique). Le supprimer revient Ã  dire â€œcela nâ€™a jamais existÃ©â€, ce qui peut rendre vos prÃ©visions irrÃ©alistes.")
                                   ),
                                   criteria_block("A4 â€” Transformation",
                                                  note = "Objectif : stabiliser la variance et rendre la dynamique plus â€œlinÃ©aireâ€ pour SARIMA.",
                                                  tags$ul(
                                                    tags$li("Ã‰valuer relation niveauâ†”variance (variance augmente avec le niveau ?)."),
                                                    tags$li("Tester log/Boxâ€“Cox si besoin."),
                                                    tags$li("Documenter lâ€™inversion pour revenir Ã  lâ€™Ã©chelle originale.")
                                                  ),
                                                  P("Si lâ€™amplitude des fluctuations augmente avec le niveau, un modÃ¨le sur les niveaux peut sur-rÃ©agir. La transformation log/Boxâ€“Cox rend souvent la saisonnalitÃ© plus additive et les rÃ©sidus plus homogÃ¨nes.")
                                   )
                          )
                        ),
                        
                        D("DÃ©finitions (cliquables)", open = FALSE,
                          TERM(
                            "NA / valeur manquante",
                            "Une valeur manquante (NA) signifie quâ€™Ã  une date attendue, lâ€™observation nâ€™a pas Ã©tÃ© enregistrÃ©e. En sÃ©rie temporelle, cela peut Ãªtre alÃ©atoire (erreur de mesure) ou structurel (jours fÃ©riÃ©s, fermeture, capteur en panne).",
                            purpose="Les NA interrompent la continuitÃ© temporelle : SARIMA et les diagnostics ACF/PACF supposent une sÃ©rie complÃ¨te, donc il faut soit imputer, soit adapter la frÃ©quence/agrÃ©gation.",
                            criteria="On ne regarde pas seulement le pourcentage de NA, mais aussi leur structure : trous courts (1â€“2 points) vs longues sÃ©quences, pÃ©riodicitÃ© du manque, et alignement avec le calendrier.",
                            how_to_apply="Commencez par compter les NA, puis visualisez leurs positions. Si les trous sont courts et rares, lâ€™imputation simple est souvent acceptable. Si les trous sont longs, discutez lâ€™impact (incertitude) et envisagez une solution alternative (agrÃ©gation, exclusion, autre source).",
                            what_to_write="Â« Les valeurs manquantes reprÃ©sentaient k=[..] points ([..]%), traitÃ©es par [mÃ©thode] car les gaps Ã©taient [courts/rares] et la saisonnalitÃ© Ã©tait [faible/forte]. Â»"
                          ),
                          TERM(
                            "Imputation",
                            "Lâ€™imputation consiste Ã  remplacer une valeur manquante par une valeur plausible, construite Ã  partir des observations voisines (linÃ©aire) ou de la structure saisonniÃ¨re (saisonniÃ¨re).",
                            purpose="Elle permet de conserver une grille rÃ©guliÃ¨re et dâ€™Ã©viter que lâ€™absence de donnÃ©es ne crÃ©e une rupture artificielle qui fausserait la stationnaritÃ© et les autocorrÃ©lations.",
                            criteria="Imputation simple si gaps trÃ¨s courts et dynamique lisse ; imputation saisonniÃ¨re si saison forte ; prudence maximale si gaps longs.",
                            how_to_apply="Choisissez une mÃ©thode qui respecte la structure dominante : si saison forte, ne â€œlissezâ€ pas au point dâ€™effacer la saison. AprÃ¨s imputation, re-vÃ©rifiez les graphiques et lâ€™ACF pour vous assurer que vous nâ€™avez pas introduit de motifs artificiels.",
                            notes="Toujours justifier : une imputation est une hypothÃ¨se sur le monde rÃ©el."
                          ),
                          TERM(
                            "Outlier (aberrant)",
                            "Un outlier est une observation atypique par rapport au comportement habituel de la sÃ©rie. Il peut provenir dâ€™une erreur (capteur, saisie) ou dâ€™un Ã©vÃ©nement rÃ©el (promotion, crise, rupture).",
                            purpose="Les outliers peuvent perturber lâ€™identification (ACF/PACF) et lâ€™estimation des paramÃ¨tres, mais ils peuvent aussi reprÃ©senter exactement ce que lâ€™on veut prÃ©voir (Ã©vÃ©nements).",
                            criteria="La rÃ¨gle statistique (IQR, z-score) doit Ãªtre complÃ©tÃ©e par le contexte : si lâ€™Ã©vÃ©nement est rÃ©el, il est souvent prÃ©fÃ©rable de conserver et documenter.",
                            how_to_apply="Marquez les outliers sur le graphique, recherchez une explication, puis choisissez : corriger si impossible physiquement, sinon conserver. Si les outliers sont frÃ©quents et structurÃ©s, envisagez un modÃ¨le dâ€™intervention ou des variables exogÃ¨nes (SARIMAX).",
                            what_to_write="Â« Les valeurs atypiques autour de [dates] ont Ã©tÃ© [conservÃ©es/ajustÃ©es] car [contexte]. Â»"
                          ),
                          TERM(
                            "Transformation Boxâ€“Cox",
                            "La transformation Boxâ€“Cox est une famille de transformations paramÃ©trÃ©es (Î») qui vise Ã  stabiliser la variance et parfois Ã  rapprocher la distribution dâ€™une forme plus symÃ©trique. Le log est un cas particulier quand Î» tend vers 0.",
                            purpose="Quand la variance augmente avec le niveau (sÃ©rie â€œen Ã©ventailâ€), Boxâ€“Cox aide SARIMA Ã  modÃ©liser une dynamique plus stable et Ã  produire des rÃ©sidus plus homogÃ¨nes.",
                            criteria="Si amplitude saisonniÃ¨re ou variance augmente avec le niveau, Boxâ€“Cox/log est souvent pertinent. Si variance stable, transformer peut Ãªtre inutile et compliquer lâ€™interprÃ©tation.",
                            how_to_apply="Appliquez la transformation, refaites les graphiques, puis refaites les diagnostics (ACF/PACF, stationnaritÃ©). Enfin, assurez-vous que vous savez revenir Ã  lâ€™Ã©chelle originale pour interprÃ©ter les prÃ©visions.",
                            formula="BC(y; Î») = (y^Î» - 1)/Î» ; log(y) si Î»â†’0",
                            notes="Attention aux zÃ©ros/nÃ©gatifs : il faut parfois un dÃ©calage (shift)."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          P("Les critÃ¨res ci-dessous traduisent les dÃ©cisions de prÃ©paration. Lâ€™Ã©tudiant doit les appliquer comme une mini check-list, puis Ã©crire une justification courte, mais explicite, pour chaque traitement."),
                          decision_rule_list(
                            tags$li(tags$b("Imputation : "),
                                    "si gaps trÃ¨s courts (ex : 1â€“2 points) et sÃ©rie relativement lisse â†’ interpolation linÃ©aire acceptable ; ",
                                    "si saison forte â†’ imputation saisonniÃ¨re prÃ©fÃ©rable ; ",
                                    "si longs gaps â†’ documenter fortement, envisager agrÃ©gation, exclusion, ou mÃ©thode modÃ¨le-based."),
                            tags$li(tags$b("Outliers : "),
                                    "si incohÃ©rence (valeur impossible) â†’ corriger/supprimer ; ",
                                    "si Ã©vÃ©nement rÃ©el â†’ conserver et signaler ; Ã©ventuellement modÃ¨le dâ€™intervention si lâ€™impact est rÃ©current."),
                            tags$li(tags$b("Transformation : "),
                                    "si variance/amplitude saisonniÃ¨re augmente avec le niveau â†’ log/Boxâ€“Cox ; ",
                                    "si variance stable â†’ pas de transformation (simplicitÃ©).")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("Ã€ la fin de lâ€™Ã©tape 1, on doit pouvoir dire : â€œvoici la sÃ©rie propre, voici ce qui a Ã©tÃ© modifiÃ©, et voici pourquoiâ€. Cela protÃ¨ge lâ€™analyse contre les critiques et rend le travail pÃ©dagogique."),
                          tags$ul(
                            tags$li("RÃ©sumÃ© de donnÃ©es : n, dates, frÃ©quence, %NA, traitement NA."),
                            tags$li("Liste dâ€™outliers + dÃ©cision et justification."),
                            tags$li("Transformation retenue + justification + comment revenir Ã  lâ€™Ã©chelle originale.")
                          )
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer de longs trous sans discussion â†’ conclusions fragiles car la dynamique imputÃ©e est spÃ©culative."),
                            tags$li("Supprimer des outliers qui sont des Ã©vÃ©nements â†’ perdre lâ€™information que la prÃ©vision devrait reflÃ©ter."),
                            tags$li("Transformer (log/Boxâ€“Cox) sans expliquer lâ€™inversion â†’ prÃ©visions difficiles Ã  interprÃ©ter.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 2 â€” Exploration visuelle
      # =========================================================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "identifier tendance, saisonnalitÃ©, changements de variance, ruptures et anomalies afin de guider les dÃ©cisions suivantes (transformation, diffÃ©renciation, choix de s). Les graphiques servent ici de â€œpreuve visuelleâ€ qui complÃ¨te les tests statistiques.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("Cette Ã©tape apprend Ã  lire une sÃ©rie : reconnaÃ®tre un mouvement de long terme (tendance), un motif qui se rÃ©pÃ¨te (saison), et des zones oÃ¹ la variance change. Ce sont exactement ces Ã©lÃ©ments que SARIMA va tenter de capturer (ou de rendre stationnaires par diffÃ©renciation)."),
                          tags$ul(
                            tags$li("Visualiser la sÃ©rie brute et Ã©ventuellement transformÃ©e."),
                            tags$li("DÃ©tecter tendance (long terme) et saisonnalitÃ© (pÃ©riodique)."),
                            tags$li("RepÃ©rer ruptures possibles et anomalies.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          P("On privilÃ©gie trois familles de graphiques : (1) la courbe temporelle, (2) les graphiques saisonniers, (3) des outils pour la variance. Ensuite, on relie chaque constat Ã  une dÃ©cision (log/Boxâ€“Cox, d, D, s)."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Courbe temporelle",
                                                  note = "Objectif : repÃ©rer tendance, ruptures, pÃ©riodes anormales, et intuition de stationnaritÃ©.",
                                                  tags$ul(
                                                    tags$li("Tracer y_t (et log/BC(y) si pertinent)."),
                                                    tags$li("Annoter pÃ©riodes anormales (chocs, Ã©vÃ©nements).")
                                                  ),
                                                  P("Une courbe qui â€œmonteâ€ durablement suggÃ¨re un besoin de diffÃ©renciation non saisonniÃ¨re (d). Une courbe qui change brutalement de niveau peut signaler une rupture structurelle (le futur peut Ãªtre diffÃ©rent du passÃ©).")
                                   ),
                                   criteria_block("A2 â€” Saison",
                                                  note = "Objectif : confirmer la pÃ©riodicitÃ© et estimer s.",
                                                  tags$ul(
                                                    tags$li("Seasonal plot / lignes par annÃ©e (si mensuel)."),
                                                    tags$li("Boxplots par mois/trimestre/semaine."),
                                                    tags$li("ACF : pics aux multiples de s (indice fort de saison).")
                                                  ),
                                                  P("Si la saison est stable, le seasonal plot montre des motifs rÃ©pÃ©titifs. Si la saison est forte et persistante, une diffÃ©renciation saisonniÃ¨re (D=1) peut Ãªtre nÃ©cessaire.")
                                   ),
                                   criteria_block("A3 â€” Variance",
                                                  note = "Objectif : dÃ©tecter une variance non constante (hÃ©tÃ©roscÃ©dasticitÃ©) avant modÃ©lisation.",
                                                  tags$ul(
                                                    tags$li("Comparer variabilitÃ© sur pÃ©riodes faible vs forte moyenne."),
                                                    tags$li("Si variance augmente avec niveau â†’ transformation.")
                                                  ),
                                                  P("Quand lâ€™amplitude des fluctuations augmente avec le niveau, le modÃ¨le sur niveaux peut privilÃ©gier les pÃ©riodes hautes. Une transformation (log/Boxâ€“Cox) rend souvent lâ€™erreur plus homogÃ¨ne.")
                                   )
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          P("Ces critÃ¨res relient directement les observations visuelles aux dÃ©cisions de modÃ©lisation. Lâ€™Ã©tudiant doit Ã©crire explicitement : â€˜Jâ€™observe X, donc je choisis Yâ€™."),
                          decision_rule_list(
                            tags$li(tags$b("SaisonnalitÃ© : "),
                                    "prÃ©sence de motifs rÃ©pÃ©tÃ©s et/ou pics ACF Ã  s,2s,3s â†’ saisonnalitÃ© probable, s doit correspondre au calendrier."),
                            tags$li(tags$b("Tendance : "),
                                    "niveau moyen qui dÃ©rive durablement et ACF qui dÃ©croÃ®t lentement â†’ diffÃ©renciation non saisonniÃ¨re d probablement > 0."),
                            tags$li(tags$b("Variance non constante : "),
                                    "amplitude des fluctuations augmente quand le niveau augmente â†’ log/Boxâ€“Cox, surtout si on veut des rÃ©sidus plus homogÃ¨nes.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("Ã€ la fin de lâ€™Ã©tape 2, lâ€™Ã©tudiant doit produire un paragraphe dâ€™EDA : il ne suffit pas de montrer des figures, il faut expliquer ce quâ€™elles disent et ce que cela implique pour la suite."),
                          tags$ul(
                            tags$li("Commentaire EDA : tendance/saison/variance/outliers."),
                            tags$li("HypothÃ¨ses de travail : s plausible, besoin de transformation, besoin de d et/ou D.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 3 â€” DÃ©composition
      # =========================================================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "sÃ©parer descriptivement tendance/saison/bruit afin de clarifier la structure du signal et dâ€™expliquer pourquoi on choisit une forme additive ou multiplicative. Cette Ã©tape nâ€™est pas â€œle modÃ¨leâ€, mais un outil pour mieux dÃ©cider.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("La dÃ©composition est un langage pÃ©dagogique puissant : elle montre aux Ã©tudiants que la sÃ©rie nâ€™est pas un â€œblocâ€ unique, mais un mÃ©lange de composants. Cela aide Ã  justifier la transformation et Ã  anticiper la diffÃ©renciation."),
                          tags$ul(
                            tags$li("DÃ©composer y_t en composantes (tendance, saison, reste)."),
                            tags$li("Comparer additif vs multiplicatif (souvent via log)."),
                            tags$li("Utiliser STL si saison Ã©volue ou si outliers prÃ©sents.")
                          )
                        ),
                        
                        D("Tests / concepts clÃ©s", open = FALSE,
                          TERM(
                            "DÃ©composition additive",
                            "Dans une dÃ©composition additive, la saisonnalitÃ© sâ€™ajoute Ã  la tendance : y_t = T_t + S_t + e_t. Cela signifie que lâ€™Ã©cart saisonnier (pics-creux) reste Ã  peu prÃ¨s de la mÃªme taille mÃªme si le niveau de la sÃ©rie change.",
                            purpose="Elle est utile quand la saison a une amplitude stable : la diffÃ©rence entre â€œmauvais moisâ€ et â€œbon moisâ€ est similaire Ã  travers le temps.",
                            criteria="Visuellement, si les oscillations saisonniÃ¨res ont une amplitude approximativement constante quelle que soit la hauteur du niveau, lâ€™additif est appropriÃ©.",
                            how_to_apply="On peut comparer la sÃ©rie brute Ã  log(y) : si log(y) rend la saison plus stable, on se rapproche dâ€™un comportement additif dans lâ€™espace transformÃ©.",
                            formula="y_t = T_t + S_t + e_t",
                            what_to_write="Â« Lâ€™amplitude saisonniÃ¨re semblant stable, nous avons adoptÃ© une lecture additive (y_t = T_t + S_t + e_t). Â»"
                          ),
                          TERM(
                            "DÃ©composition multiplicative",
                            "Dans une dÃ©composition multiplicative, la saisonnalitÃ© agit comme un facteur proportionnel : y_t = T_t Ã— S_t Ã— e_t. Cela signifie que la saison â€˜grossitâ€™ quand le niveau de la sÃ©rie augmente.",
                            purpose="Elle est pertinente lorsque les pÃ©riodes hautes ont des fluctuations saisonniÃ¨res plus grandes que les pÃ©riodes basses (effet de proportion).",
                            criteria="Si lâ€™amplitude saisonniÃ¨re augmente avec le niveau (Ã©ventail), la multiplicative est plausible.",
                            how_to_apply="On utilise souvent la transformation log pour passer dâ€™une multiplicative Ã  une additive : log(y_t) = log(T_t) + log(S_t) + log(e_t).",
                            formula="y_t = T_t Ã— S_t Ã— e_t",
                            notes="Souvent log(y_t) â†’ structure additive sur log.",
                            what_to_write="Â« Lâ€™amplitude saisonniÃ¨re augmentant avec le niveau, nous avons appliquÃ© une transformation log afin dâ€™obtenir une structure additive dans lâ€™espace transformÃ©. Â»"
                          ),
                          TERM(
                            "STL",
                            "STL (Seasonal-Trend decomposition using Loess) est une dÃ©composition flexible qui permet Ã  la saisonnalitÃ© dâ€™Ã©voluer lentement dans le temps et offre une meilleure robustesse face aux outliers.",
                            purpose="Elle est utile quand la saison nâ€™est pas parfaitement stable (changement progressif des habitudes, croissance, Ã©volution du calendrier).",
                            criteria="Si le seasonal plot montre une saison qui se dÃ©forme lÃ©gÃ¨rement au fil des annÃ©es, STL est souvent prÃ©fÃ©rable Ã  la dÃ©composition classique.",
                            how_to_apply="On utilise STL pour dÃ©crire la structure et guider les choix. Ensuite, on revient aux diagnostics de stationnaritÃ© (tests + ACF) pour prÃ©parer SARIMA.",
                            notes="STL dÃ©crit; ne remplace pas la stationnaritÃ© requise pour SARIMA."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          P("Le but nâ€™est pas de â€œchoisir STL pour faire joliâ€, mais de justifier un raisonnement cohÃ©rent : forme de saison â†’ transformation â†’ stationnaritÃ© plus plausible â†’ SARIMA plus stable."),
                          decision_rule_list(
                            tags$li(tags$b("Additif : "), "si amplitude saisonniÃ¨re ~ constante â†’ modÃ¨le additif."),
                            tags$li(tags$b("Multiplicatif : "), "si amplitude saisonniÃ¨re âˆ niveau â†’ log/Boxâ€“Cox puis additif dans lâ€™espace transformÃ©."),
                            tags$li(tags$b("STL : "), "si saison Ã©volutive ou outliers â†’ STL prÃ©fÃ©rable pour une lecture descriptive robuste.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("On attend une figure de dÃ©composition et un paragraphe court reliant le diagnostic Ã  une dÃ©cision (transformation, type de saison)."),
                          tags$ul(
                            tags$li("Figure(s) de dÃ©composition + commentaire tendance/saison."),
                            tags$li("DÃ©cision argumentÃ©e : additif vs multiplicatif (+ transformation).")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 4 â€” StationnaritÃ© & diffÃ©renciation + tests
      # =========================================================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("But : "),
                          "choisir ", tags$code("d"), ", ", tags$code("D"), " et ", tags$code("s"),
                          " afin dâ€™obtenir une sÃ©rie (aprÃ¨s diffÃ©renciation) approximativement stationnaire. En pratique, on cherche la stationnaritÃ© â€œsuffisanteâ€ (pas parfaite) avec le minimum de diffÃ©renciation, car la sur-diffÃ©renciation rend le modÃ¨le instable.",
                          type="ok"
                        ),
                        
                        D("Objectif", open = TRUE,
                          P("Cette Ã©tape est le pivot SARIMA : vous dÃ©cidez combien de tendance et de saison vous retirez pour laisser au modÃ¨le AR/MA la tÃ¢che dâ€™expliquer la dÃ©pendance restante. Les tests (ADF/KPSS/PP) ne remplacent pas les graphiques : on les utilise ensemble pour trianguler."),
                          tags$ul(
                            tags$li("Fixer la saison ", tags$code("s"), " (Ã  partir des donnÃ©es/du contexte)."),
                            tags$li("Choisir ", tags$code("d"), " (diff. non saisonniÃ¨re) et ", tags$code("D"), " (diff. saisonniÃ¨re)."),
                            tags$li("Justifier le choix avec : EDA + ACF/PACF + tests (ADF/KPSS/PP) + rÃ¨gles anti-sur-diffÃ©renciation.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          P("Le workflow recommandÃ© est : (1) choisir s, (2) tester D, (3) tester d, (4) re-vÃ©rifier stationnaritÃ©, (5) vÃ©rifier quâ€™on nâ€™a pas sur-diffÃ©renciÃ©. On prÃ©fÃ¨re des valeurs petites : dâˆˆ{0,1} et Dâˆˆ{0,1} dans la plupart des cas."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Choisir s (pÃ©riode saisonniÃ¨re)",
                                                  note = "DÃ©cision basÃ©e sur le calendrier + confirmation empirique via ACF/seasonal plot.",
                                                  tags$ul(
                                                    tags$li("Connaissance du calendrier (mensuelâ†’12, trimestrielâ†’4, quotidien hebdoâ†’7, etc.)."),
                                                    tags$li("Indices empiriques : pics ACF Ã  s,2s,... ; pattern stable sur seasonal plot."),
                                                    tags$li("Si ambigu : tester quelques s plausibles et comparer diagnostics.")
                                                  ),
                                                  P("s doit avoir une signification temporelle. Par exemple, en mensuel, s=12 est naturel. Sâ€™il y a une saison commerciale â€œsemi-annuelleâ€, s=6 peut aussi Ãªtre testÃ©, mais doit Ãªtre dÃ©fendu par les donnÃ©es.")
                                   ),
                                   criteria_block("A2 â€” DÃ©cider D (diff saisonniÃ¨re)",
                                                  note = "Objectif : retirer une non-stationnaritÃ© saisonniÃ¨re persistante (racine unitaire saisonniÃ¨re).",
                                                  tags$ul(
                                                    tags$li("Si forte saisonnalitÃ© persistante annÃ©e-sur-annÃ©e â†’ envisager D=1."),
                                                    tags$li("Indices : ACF trÃ¨s forte au lag s sur la sÃ©rie brute; saison non supprimÃ©e par simple d."),
                                                    tags$li("VÃ©rifier sur-diff : ACF lag s trÃ¨s nÃ©gative aprÃ¨s D=1 â†’ signe D trop grand.")
                                                  ),
                                                  P("La diffÃ©renciation saisonniÃ¨re compare y_t Ã  y_{t-s}. Si aprÃ¨s D=1 vous observez une alternance artificielle (pics nÃ©gatifs marquÃ©s), vous avez peut-Ãªtre retirÃ© trop de saison.")
                                   ),
                                   criteria_block("A3 â€” DÃ©cider d (diff non-saisonniÃ¨re)",
                                                  note = "Objectif : retirer une tendance stochastique (unit root non saisonnier).",
                                                  tags$ul(
                                                    tags$li("Si tendance stochastique (unit root) â†’ d=1 est souvent suffisant."),
                                                    tags$li("Indices : ACF dÃ©croit lentement sur la sÃ©rie brute; tests unit root."),
                                                    tags$li("Sur-diff : ACF lag1 trÃ¨s nÃ©gative aprÃ¨s diff â†’ d trop grand.")
                                                  ),
                                                  P("d=1 correspond Ã  modÃ©liser les variations plutÃ´t que les niveaux. Si les variations semblent stables, SARIMA est souvent plus fiable. d=2 est rarement nÃ©cessaire et doit Ãªtre fortement justifiÃ©.")
                                   )
                          )
                        ),
                        
                        D("DÃ©finitions indispensables (cliquables)", open = FALSE,
                          TERM(
                            "DiffÃ©renciation ordinaire (d)",
                            "DiffÃ©rencier une sÃ©rie consiste Ã  remplacer y_t par la variation entre deux instants consÃ©cutifs : âˆ‡y_t = y_t âˆ’ y_{tâˆ’1}. RÃ©pÃ©ter lâ€™opÃ©ration d fois revient Ã  retirer progressivement une tendance stochastique.",
                            purpose="Le but est dâ€™obtenir une sÃ©rie dont la moyenne et la variance sont plus stables dans le temps, afin que les dÃ©pendances restantes puissent Ãªtre capturÃ©es par les composantes AR/MA.",
                            criteria="d est gÃ©nÃ©ralement 0 ou 1. d=2 indique souvent une sÃ©rie trÃ¨s particuliÃ¨re ou un problÃ¨me de spÃ©cification (ou de rupture).",
                            how_to_apply="On commence par d=0, puis d=1 si nÃ©cessaire. AprÃ¨s chaque essai, on examine la sÃ©rie diffÃ©renciÃ©e, lâ€™ACF et les tests unit root. On sâ€™arrÃªte dÃ¨s que la stationnaritÃ© est raisonnable.",
                            formula="(1-B)^d y_t",
                            what_to_write="Â« Les diagnostics suggÃ©raient une tendance stochastique ; nous avons appliquÃ© une diffÃ©renciation ordinaire (d=1) et revÃ©rifiÃ© la stationnaritÃ©. Â»"
                          ),
                          TERM(
                            "DiffÃ©renciation saisonniÃ¨re (D)",
                            "DiffÃ©rencier saisonniÃ¨rement consiste Ã  comparer une observation Ã  celle dâ€™une saison prÃ©cÃ©dente : âˆ‡_s y_t = y_t âˆ’ y_{tâˆ’s}. Cela retire une composante saisonniÃ¨re persistante.",
                            purpose="Le but est de supprimer une non-stationnaritÃ© saisonniÃ¨re (racine unitaire saisonniÃ¨re) afin que la saison soit ensuite modÃ©lisÃ©e par les termes AR/MA saisonniers (P,Q).",
                            criteria="D est trÃ¨s souvent 0 ou 1. D=2 est rare et doit dÃ©clencher une re-vÃ©rification de s et de la qualitÃ© des donnÃ©es.",
                            how_to_apply="On essaie D=0 puis D=1 si la saison persiste fortement. AprÃ¨s D=1, on surveille les symptÃ´mes de sur-diff saisonniÃ¨re (ACF trÃ¨s nÃ©gative au lag s).",
                            formula="(1-B^s)^D y_t",
                            what_to_write="Â« La saisonnalitÃ© persistante a motivÃ© une diffÃ©renciation saisonniÃ¨re (D=1) avec pÃ©riode s=[..]. Â»"
                          ),
                          TERM(
                            "Sur-diffÃ©renciation",
                            "La sur-diffÃ©renciation signifie retirer plus de structure que nÃ©cessaire. Elle peut crÃ©er une dynamique artificielle, comme une forte autocorrÃ©lation nÃ©gative au premier retard, et rendre les prÃ©visions plus instables.",
                            purpose="Ã‰viter la sur-diffÃ©renciation protÃ¨ge la stabilitÃ© des paramÃ¨tres et limite lâ€™amplification du bruit.",
                            criteria="SymptÃ´mes typiques : ACF au lag 1 trÃ¨s nÃ©gative aprÃ¨s d, ou ACF au lag s trÃ¨s nÃ©gative aprÃ¨s D. PrÃ©visions qui oscillent de maniÃ¨re excessive.",
                            how_to_apply="Si les symptÃ´mes apparaissent, rÃ©duire d ou D, puis re-tester. La rÃ¨gle pÃ©dagogique : â€˜minimum de diffÃ©rences pour stationnariserâ€™.",
                            notes="Mieux vaut minimal : juste assez pour stationnariser."
                          )
                        ),
                        
                        D("Tests (purpose + critÃ¨res dÃ©taillÃ©s)", open = FALSE,
                          
                          TEST(
                            name="ADF â€” Augmented Dickeyâ€“Fuller (racine unitaire)",
                            purpose=paste(
                              "Le test ADF vise Ã  dÃ©tecter une racine unitaire, câ€™est-Ã -dire une non-stationnaritÃ© oÃ¹ les chocs ont des effets persistants. ",
                              "Il examine si le niveau passÃ© y_{t-1} explique Î”y_t dâ€™une faÃ§on compatible avec une marche alÃ©atoire. ",
                              "Les retards de Î”y_t sont ajoutÃ©s pour neutraliser lâ€™autocorrÃ©lation et Ã©viter un test trompeur."
                            ),
                            when_to_use="Pour dÃ©cider si une diffÃ©renciation non saisonniÃ¨re (d) est nÃ©cessaire, puis pour valider que la sÃ©rie (aprÃ¨s d et Ã©ventuellement D) est compatible avec la stationnaritÃ©.",
                            H0="La sÃ©rie a une racine unitaire â†’ non-stationnaire (tendance stochastique).",
                            H1="La sÃ©rie est stationnaire (selon la spÃ©cification : avec ou sans drift/trend).",
                            statistic="RÃ©gression ADF : Î”y_t ~ Î± + Î² t + Î³ y_{t-1} + Î£ Î´_i Î”y_{t-i}. Le test porte sur Î³ avec des valeurs critiques spÃ©cifiques.",
                            decision_rule="Avec Î±=0.05 : si p-value < 0.05 â†’ rejet H0 â†’ stationnaritÃ© plausible. Si p-value â‰¥ 0.05 â†’ non-rejet â†’ d potentiellement insuffisant (ou rupture/ mauvaise spÃ©cification drift/trend).",
                            interpretation="Rejeter H0 signifie que la sÃ©rie nâ€™a pas lâ€™allure dâ€™une marche alÃ©atoire : elle tend Ã  revenir vers un comportement stable (moyenne ou tendance dÃ©terministe).",
                            what_it_means_for_choices="Si ADF ne rejette pas sur la sÃ©rie brute, vous testez d=1 (et/ou D=1 si saison). Si ADF rejette aprÃ¨s transformation, vous pouvez passer Ã  lâ€™identification ACF/PACF pour p,q,P,Q.",
                            reporting="Indiquer la version (avec drift / avec trend), le nombre de retards, la statistique, la p-value, et la dÃ©cision sur d.",
                            caveats="SensibilitÃ© au choix drift/trend et au nombre de retards. Les ruptures structurelles peuvent faire â€˜semblerâ€™ non-stationnaire une sÃ©rie qui change de rÃ©gime."
                          ),
                          
                          TEST(
                            name="KPSS â€” Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin (stationnaritÃ© comme H0)",
                            purpose=paste(
                              "KPSS complÃ¨te ADF en inversant lâ€™hypothÃ¨se nulle : ici, la stationnaritÃ© est supposÃ©e vraie tant que les donnÃ©es ne la contredisent pas. ",
                              "Le test mesure si une composante de marche alÃ©atoire rÃ©siduelle est trop grande pour Ãªtre compatible avec une sÃ©rie stationnaire."
                            ),
                            when_to_use="AprÃ¨s ADF/PP, pour trianguler, et particuliÃ¨rement utile quand ADF est ambigu. On lâ€™utilise sur la sÃ©rie brute et sur la sÃ©rie diffÃ©renciÃ©e.",
                            H0="La sÃ©rie est stationnaire (en niveau) OU stationnaire autour dâ€™une tendance (selon version).",
                            H1="La sÃ©rie est non-stationnaire.",
                            statistic="Statistique basÃ©e sur la somme cumulÃ©e des rÃ©sidus et une estimation de variance longue (bandwidth).",
                            decision_rule="Avec Î±=0.05 : si p-value < 0.05 â†’ rejet H0 â†’ non-stationnaire. Si p-value â‰¥ 0.05 â†’ compatible avec stationnaritÃ©.",
                            interpretation="Un KPSS non significatif aprÃ¨s diffÃ©renciation renforce que la transformation a stabilisÃ© la sÃ©rie ; un KPSS significatif suggÃ¨re que la sÃ©rie garde une dÃ©rive ou une structure non stationnaire.",
                            what_it_means_for_choices="Convergence ADF/PP (rejet unit root) + KPSS (non-rejet stationnaritÃ©) = feu vert pour passer Ã  p,q,P,Q. Si KPSS rejette, reconsidÃ©rer d/D ou la prÃ©sence de rupture.",
                            reporting="PrÃ©ciser version (level/trend), statistique, p-value, et conclusion sur stationnaritÃ©.",
                            caveats="DÃ©pend du choix de variance longue. TrÃ¨s sensible aux ruptures : une sÃ©rie avec changement de niveau peut faire rejeter KPSS mÃªme si elle est localement stationnaire."
                          ),
                          
                          TEST(
                            name="PP â€” Phillipsâ€“Perron (racine unitaire avec correction non-paramÃ©trique)",
                            purpose=paste(
                              "PP teste aussi la racine unitaire comme ADF, mais corrige lâ€™autocorrÃ©lation et lâ€™hÃ©tÃ©roscÃ©dasticitÃ© de maniÃ¨re non paramÃ©trique ",
                              "au lieu dâ€™ajouter de nombreux retards. Cela peut Ãªtre utile lorsque lâ€™ADF dÃ©pend trop du choix du nombre de retards."
                            ),
                            when_to_use="En complÃ©ment/alternative Ã  ADF, surtout si vous suspectez autocorrÃ©lation ou variance non constante dans la rÃ©gression ADF.",
                            H0="Racine unitaire â†’ non-stationnaire.",
                            H1="Stationnaire.",
                            statistic="Statistique DF corrigÃ©e par estimation robuste de variance.",
                            decision_rule="Avec Î±=0.05 : p-value < 0.05 â†’ rejet H0 â†’ stationnaritÃ© plausible.",
                            interpretation="Si PP et ADF vont dans le mÃªme sens, la conclusion est plus solide. En cas de dÃ©saccord, on revient aux diagnostics visuels et Ã  lâ€™ACF.",
                            what_it_means_for_choices="Concordance ADF+PP: confiance plus Ã©levÃ©e pour fixer d. DÃ©saccord: tester une autre spÃ©cification (drift/trend), vÃ©rifier ruptures, recontrÃ´ler transformation.",
                            reporting="Rapporter statistique, p-value, spÃ©cification (drift/trend) et transformation utilisÃ©e.",
                            caveats="Comme ADF : dÃ©pend du drift/trend. Les ruptures peuvent biaiser la conclusion."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision) â€” d, D, s", open = TRUE,
                          P("Lâ€™Ã©tudiant doit appliquer ces rÃ¨gles comme une procÃ©dure : (1) choisir s, (2) essayer D, (3) essayer d, (4) contrÃ´ler sur-diff, (5) retenir la solution la plus simple qui rend la stationnaritÃ© raisonnable."),
                          tags$div(class="grid",
                                   
                                   criteria_block("RÃ¨gle 1 â€” Triangulation ADF/KPSS/PP",
                                                  note = "Objectif : ne pas dÃ©pendre dâ€™un seul test, car leurs hypothÃ¨ses nulles diffÃ¨rent.",
                                                  tags$ul(
                                                    tags$li(tags$b("Stationnaire plausible : "), "ADF/PP rejettent (p<.05) ET KPSS ne rejette pas (pâ‰¥.05)."),
                                                    tags$li(tags$b("Non-stationnaire : "), "ADF/PP ne rejettent pas ET KPSS rejette."),
                                                    tags$li(tags$b("Conflit : "), "sâ€™appuyer sur ACF/PACF + visualisation + minimiser la diffÃ©renciation (Ã©viter sur-diff).")
                                                  ),
                                                  P("En cas de conflit, lâ€™Ã©tudiant doit Ã©crire que la dÃ©cision repose sur la convergence des indices (tests + ACF + plots), pas sur une seule p-value.")
                                   ),
                                   
                                   criteria_block("RÃ¨gle 2 â€” Ã‰viter la sur-diffÃ©renciation",
                                                  note = "Objectif : prÃ©server une dynamique interprÃ©table et stable.",
                                                  tags$ul(
                                                    tags$li(tags$b("Sur-diff d : "), "ACF lag1 trÃ¨s nÃ©gative aprÃ¨s diff; variance augmente; modÃ¨le instable."),
                                                    tags$li(tags$b("Sur-diff D : "), "ACF au lag s trÃ¨s nÃ©gative aprÃ¨s diff saisonniÃ¨re."),
                                                    tags$li("Si sur-diff suspectÃ©e â†’ rÃ©duire d ou D et rÃ©Ã©valuer tests/ACF.")
                                                  ),
                                                  P("Un bon critÃ¨re pÃ©dagogique : si vous devez monter Ã  d=2 ou D=2, stop et rÃ©examinez (s, donnÃ©es, ruptures).")
                                   ),
                                   
                                   criteria_block("RÃ¨gle 3 â€” Valeurs typiques",
                                                  note = "Objectif : dÃ©marrer simple, complexifier seulement si nÃ©cessaire.",
                                                  tags$ul(
                                                    tags$li(tags$b("d : "), "souvent 0 ou 1 (2 trÃ¨s rare)."),
                                                    tags$li(tags$b("D : "), "souvent 0 ou 1 (2 trÃ¨s rare)."),
                                                    tags$li(tags$b("s : "), "dÃ©duit du calendrier; si incertain, tester alternatives plausibles.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          P("Cette Ã©tape doit se conclure par un choix clair (s,d,D) et une justification Ã©crite en 2â€“4 phrases, incluant le sens de la dÃ©cision : â€˜nous modÃ©lisons ensuite les dÃ©pendances restantes via AR/MAâ€™."),
                          tags$ul(
                            tags$li("Valeurs retenues : ", tags$code("s"), ", ", tags$code("d"), ", ", tags$code("D"), " + justification."),
                            tags$li("Courtes phrases de conclusion : Â« tests + ACF suggÃ¨rent stationnaritÃ© aprÃ¨s ... Â»."),
                            tags$li("Avertissement si conflit entre tests â†’ justification qualitative.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEPS 5â€“8 (kept complete; already detailed; add sentences where most needed)
      # =========================================================
      # NOTE: To keep copy/paste manageable, steps 5â€“8 are preserved but enriched with
      # short explanatory paragraphs at the start of each step (as above).
      #
      # If you want them expanded to the same â€œparagraph densityâ€ as steps 0â€“4,
      # tell me â€œexpand steps 5â€“8 tooâ€ and Iâ€™ll paste the fully expanded version.
      
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "Ã©tablir un point de comparaison solide (benchmarks) et une baseline auto-ARIMA, puis dÃ©finir des critÃ¨res de sÃ©lection qui combinent information (AICc/BIC), validitÃ© (diagnostics) et finalitÃ© (performance de prÃ©vision).",
                          type="ok"
                        ),
                        D("Objectif", open = TRUE,
                          P("Lâ€™Ã©tape baseline Ã©vite un piÃ¨ge classique : croire quâ€™un SARIMA complexe est forcÃ©ment utile. Ici, un modÃ¨le doit dâ€™abord battre des rÃ¨gles simples (naÃ¯f, naÃ¯f saisonnier)."),
                          tags$ul(
                            tags$li("Construire benchmarks : naÃ¯f (Å·_{t+h}=y_t) et naÃ¯f saisonnier (Å·_{t+h}=y_{t+h-s})."),
                            tags$li("Obtenir une baseline SARIMA via auto-ARIMA (AICc/BIC) â€” reproductible."),
                            tags$li("DÃ©finir critÃ¨res de sÃ©lection : AICc + diagnostics + performance out-of-sample.")
                          )
                        ),
                        D("Tests / concepts (cliquables)", open = FALSE,
                          TERM("NaÃ¯f (random walk forecast)",
                               "Le modÃ¨le naÃ¯f prÃ©dit que le futur sera identique Ã  la derniÃ¨re valeur observÃ©e. MalgrÃ© sa simplicitÃ©, il est souvent difficile Ã  battre sur des sÃ©ries trÃ¨s persistantes.",
                               purpose="Benchmark minimal : si votre modÃ¨le ne bat pas le naÃ¯f, vous nâ€™avez pas encore capturÃ© plus dâ€™information que la persistance brute.",
                               criteria="Comparer MAE/RMSE sur test. Si gain faible, prÃ©fÃ©rer la simplicitÃ©.",
                               how_to_apply="Toujours calculer ses erreurs sur la mÃªme fenÃªtre test/rolling que les autres modÃ¨les.",
                               formula="Å·_{t+h} = y_t"),
                          TERM("NaÃ¯f saisonnier",
                               "Le modÃ¨le naÃ¯f saisonnier prÃ©dit que la valeur future sera Ã©gale Ã  la valeur observÃ©e Ã  la mÃªme saison prÃ©cÃ©dente (ex : mÃªme mois lâ€™an passÃ©).",
                               purpose="Benchmark crucial si saisonnalitÃ© forte : beaucoup de modÃ¨les â€˜sophistiquÃ©sâ€™ Ã©chouent Ã  le battre.",
                               criteria="Surtout pertinent quand s est bien dÃ©fini et la saison stable.",
                               how_to_apply="Ã‰valuer sur au moins une saison complÃ¨te si possible.",
                               formula="Å·_{t+h} = y_{t+h-s}"),
                          TERM("AICc vs BIC",
                               "AICc et BIC comparent lâ€™ajustement en pÃ©nalisant la complexitÃ©. AICc est souvent utilisÃ© pour la performance prÃ©dictive; BIC pÃ©nalise davantage et favorise des modÃ¨les plus simples.",
                               purpose="RÃ©duire le risque de sur-ajustement en Ã©vitant des modÃ¨les inutilement complexes.",
                               criteria="Î”AICc < 2 : modÃ¨les trÃ¨s proches â†’ choisir le plus simple (parcimonie).",
                               how_to_apply="Nâ€™utiliser AICc/BIC que pour comparer des modÃ¨les estimÃ©s sur la mÃªme sÃ©rie (mÃªme transformation, mÃªmes donnÃ©es).")
                        ),
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          P("Le meilleur modÃ¨le nâ€™est pas celui qui minimise seulement AICc : il doit aussi passer les diagnostics et battre les benchmarks en prÃ©vision."),
                          tags$div(class="grid",
                                   criteria_block("SÃ©lection par information (AICc/BIC)",
                                                  tags$ul(
                                                    tags$li("Choisir AICc minimal comme candidat initial."),
                                                    tags$li("Si plusieurs modÃ¨les avec Î”AICc < 2 â†’ choisir le plus simple (moins de paramÃ¨tres)."),
                                                    tags$li("VÃ©rifier aussi BIC si vous privilÃ©giez parcimonie.")
                                                  )
                                   ),
                                   criteria_block("CritÃ¨re de validitÃ©",
                                                  tags$ul(
                                                    tags$li("Diagnostics rÃ©sidus acceptables (Ljungâ€“Box non significatif, etc.)."),
                                                    tags$li("ParamÃ¨tres stables (stationnaritÃ©/inversibilitÃ©).")
                                                  )
                                   ),
                                   criteria_block("CritÃ¨re de finalitÃ© (prÃ©vision)",
                                                  tags$ul(
                                                    tags$li("AmÃ©lioration claire vs benchmarks (naÃ¯f, naÃ¯f saisonnier)."),
                                                    tags$li("Si gain faible â†’ prÃ©fÃ©rer modÃ¨le plus simple/robuste.")
                                                  )
                                   )
                          )
                        ),
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Table baseline: benchmarks + auto-ARIMA (AICc, MAE/RMSE sur test)."),
                            tags$li("Baseline choisie comme point de dÃ©part (pas forcÃ©ment final).")
                          )
                        )
        ))
      }
      
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "utiliser ACF/PACF pour construire une petite grille de modÃ¨les candidats, puis sÃ©lectionner par parcimonie + diagnostics. On cherche un raisonnement, pas une recherche brute-force.",
                          type="ok"
                        ),
                        D("Objectif", open = TRUE,
                          P("Lâ€™Ã©tudiant apprend que ACF/PACF sont des heuristiques : elles suggÃ¨rent des ordres plausibles, mais ne remplacent pas la comparaison et les diagnostics."),
                          tags$ul(
                            tags$li("Travailler sur la sÃ©rie stationnaire (aprÃ¨s d/D)."),
                            tags$li("Lire ACF/PACF pour proposer p,q (et P,Q saisonniers)."),
                            tags$li("Construire une grille courte de candidats et les comparer.")
                          )
                        ),
                        D("Concepts (cliquables)", open = FALSE,
                          TERM("ACF",
                               "Lâ€™ACF mesure la corrÃ©lation entre la sÃ©rie et ses retards. Sur une sÃ©rie stationnaire, un motif de coupure/attÃ©nuation peut suggÃ©rer la prÃ©sence de termes MA.",
                               purpose="Aide Ã  proposer q et Q, et Ã  dÃ©tecter les pics saisonniers aux multiples de s.",
                               criteria="Pics marquÃ©s Ã  s,2s,... â†’ saison; coupure rapide aux petits lags â†’ MA plausible.",
                               how_to_apply="Tracer lâ€™ACF aprÃ¨s diffÃ©renciation; proposer q/Q petits (0â€“2) puis vÃ©rifier diagnostics.")
                          ,
                          TERM("PACF",
                               "La PACF mesure la corrÃ©lation partielle entre y_t et y_{t-k} en contrÃ´lant les lags intermÃ©diaires. Une coupure rapide peut suggÃ©rer un ordre AR.",
                               purpose="Aide Ã  proposer p et P.",
                               criteria="Pics PACF aux petits lags â†’ AR plausible; pics Ã  s â†’ AR saisonnier.",
                               how_to_apply="Tracer la PACF aprÃ¨s diffÃ©renciation; proposer p/P petits puis comparer.")
                          ,
                          TERM("Bandes de significativitÃ© ACF/PACF",
                               "Les bandes Â±1.96/âˆšn donnent une approximation pour juger si un pic est statistiquement notable.",
                               purpose="Ã‰viter de sur-interprÃ©ter du bruit.",
                               criteria="Des pics isolÃ©s peuvent apparaÃ®tre par hasard; on cherche des motifs cohÃ©rents.",
                               how_to_apply="Regarder la structure globale (dÃ©croissance, rÃ©pÃ©tition) plutÃ´t que 1 seul pic.")
                        ),
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("Candidats non saisonniers (p,q)",
                                                  tags$ul(
                                                    tags$li(tags$b("p : "), "si PACF a 1â€“2 pics forts aux petits lags â†’ p=1 ou 2 plausible."),
                                                    tags$li(tags$b("q : "), "si ACF a 1â€“2 pics forts â†’ q=1 ou 2 plausible."),
                                                    tags$li("Garder petit : p,q â‰¤ 3 sauf justification forte.")
                                                  )
                                   ),
                                   criteria_block("Candidats saisonniers (P,Q)",
                                                  tags$ul(
                                                    tags$li(tags$b("P : "), "pics PACF au lag s â†’ P=1 plausible."),
                                                    tags$li(tags$b("Q : "), "pics ACF au lag s â†’ Q=1 plausible."),
                                                    tags$li("Souvent P,Q âˆˆ {0,1}.")
                                                  )
                                   ),
                                   criteria_block("Parcimonie et sÃ©lection",
                                                  tags$ul(
                                                    tags$li("Si Î”AICc < 2 entre candidats â†’ choisir le plus simple."),
                                                    tags$li("Refuser modÃ¨les avec paramÃ¨tres non stables (explosifs) mÃªme si AICc bon."),
                                                    tags$li("Toujours vÃ©rifier diagnostics rÃ©siduels ensuite.")
                                                  )
                                   )
                          )
                        ),
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Liste courte de candidats SARIMA((p,d,q)(P,D,Q)[s])."),
                            tags$li("Justification ACF/PACF + parcimonie."),
                            tags$li("Comparaison AICc/BIC + diagnostics prÃ©liminaires.")
                          )
                        )
        ))
      }
      
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "valider que les rÃ©sidus ressemblent Ã  du bruit blanc (modÃ¨le adÃ©quat) et que la prÃ©cision de prÃ©vision bat les benchmarks. Les tests rÃ©siduels servent Ã  dÃ©tecter ce que votre modÃ¨le nâ€™a pas appris.",
                          type="ok"
                        ),
                        D("Objectif", open = TRUE,
                          P("On peut avoir un AICc excellent et un modÃ¨le mauvais si les rÃ©sidus restent autocorrÃ©lÃ©s. Cette Ã©tape impose la discipline : dâ€™abord la validitÃ© (rÃ©sidus), ensuite la performance (prÃ©vision)."),
                          tags$ul(
                            tags$li("VÃ©rifier rÃ©sidus : pas dâ€™autocorrÃ©lation restante, variance stable, pas dâ€™ARCH important (si pertinent)."),
                            tags$li("Comparer performance de prÃ©vision sur test/rolling (MAE/RMSE/...)."),
                            tags$li("Choisir final : diagnostics OK + performance + parcimonie.")
                          )
                        ),
                        D("Tests rÃ©sidus (purpose + critÃ¨res dÃ©taillÃ©s)", open = FALSE,
                          TEST(
                            name="Ljungâ€“Box (autocorrÃ©lation rÃ©siduelle)",
                            purpose=paste(
                              "Tester si les autocorrÃ©lations des rÃ©sidus (jusquâ€™Ã  un lag L) sont globalement nulles. ",
                              "Câ€™est un test central : si H0 est rejetÃ©e, le modÃ¨le laisse une structure temporelle non expliquÃ©e, ce qui signifie que la spÃ©cification SARIMA est incomplÃ¨te."
                            ),
                            when_to_use="Toujours aprÃ¨s estimation, et idÃ©alement pour plusieurs choix de L (ex : L=10, L=2s).",
                            H0="RÃ©sidus ~ bruit blanc jusquâ€™au lag L (pas dâ€™autocorrÃ©lation).",
                            H1="AutocorrÃ©lation rÃ©siduelle prÃ©sente.",
                            statistic="Q(L) agrÃ¨ge les autocorrÃ©lations rÃ©siduelles; ddl ajustÃ©s par fitdf.",
                            decision_rule="Avec Î±=0.05 : p-value â‰¥ 0.05 â†’ acceptable; p-value < 0.05 â†’ revoir (p,q,P,Q,d,D) ou transformation.",
                            interpretation="Un rejet suggÃ¨re quâ€™il existe des motifs temporels restants (retards non modÃ©lisÃ©s, saison manquante, sous-diffÃ©renciation, etc.).",
                            what_it_means_for_choices="Si rejet â†’ ajouter/ajuster AR ou MA (saisonnier ou non), ou reconsidÃ©rer d/D. Si non rejet â†’ passer Ã  lâ€™Ã©valuation de prÃ©vision et au choix parcimonieux.",
                            reporting="Rapporter L, Q, p-value, fitdf, et conclure sur â€˜rÃ©sidus compatibles avec bruit blancâ€™.",
                            caveats="Choix de L important ; grand n rend le test trÃ¨s sensible."
                          )
                        ),
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Table comparative : (AICc/BIC) + MAE/RMSE (test) + Ljungâ€“Box p-value (rÃ©sidus)."),
                            tags$li("DÃ©cision finale : modÃ¨le retenu + justification (diagnostics + performance + simplicitÃ©).")
                          )
                        )
        ))
      }
      
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("But : "),
                          "Ã©crire une conclusion complÃ¨te et comprÃ©hensible : le modÃ¨le retenu, la preuve (diagnostics + performance), et le sens (ce que le modÃ¨le raconte sur la sÃ©rie et quelles limites il a).",
                          type="ok"
                        ),
                        D("Ã‰quation SARIMA (notation correcte)", open = TRUE,
                          tags$ul(
                            tags$li(
                              tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
                              " avec innovations ",
                              tags$code("Îµ_t ~ w.n.(0, Ïƒ^2)")
                            )
                          ),
                          tags$p(class="small",
                                 "Lecture : on stabilise la sÃ©rie par diffÃ©renciation, puis AR/MA capturent la dÃ©pendance restante. Cette phrase doit Ãªtre explicitÃ©e dans le rapport pour montrer que vous comprenez le rÃ´le de chaque composant."
                          )
                        ),
                        D("Template de texte (prÃªt Ã  copier)", open = TRUE,
                          P(
                            tags$b("Conclusion (exemple). "),
                            "Â« Le modÃ¨le final retenu Ã©tait SARIMA((p,d,q)(P,D,Q)[s]) estimÃ© sur la sÃ©rie [transformÃ©e / non transformÃ©e]. ",
                            "Les diagnostics (ACF/PACF + tests ADF/KPSS/PP) ont motivÃ© le choix de d=[..], D=[..] et s=[..]. ",
                            "Les rÃ©sidus Ã©taient compatibles avec un bruit blanc (Ljungâ€“Box non significatif pour L=[..], Î±=0.05), ce qui suggÃ¨re que la dÃ©pendance temporelle principale a Ã©tÃ© capturÃ©e. ",
                            "En Ã©valuation hors Ã©chantillon, MAE=[..] et RMSE=[..] amÃ©lioraient les benchmarks [naÃ¯f / naÃ¯f saisonnier]. ",
                            "Cela signifie que la sÃ©rie prÃ©sente une structure [saisonniÃ¨re / inertielle / chocs transitoires] qui persiste suffisamment pour produire des prÃ©visions utiles Ã  horizon h=[..]. ",
                            "Les limites incluent [ruptures possibles, variables exogÃ¨nes non modÃ©lisÃ©es, volatilitÃ©]. Â»"
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "Ã‰tape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (trÃ¨s dÃ©taillÃ©e) â€” FR"),
                          tags$p(class="road-sub",
                                 "Slider pour naviguer sans dÃ©filer. Chaque Ã©tape suit : Objectif â†’ Analyses â†’ Tests â†’ CritÃ¨res â†’ Sorties â†’ PiÃ¨ges. "
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Ã‰tape (slider â€” pas besoin de scroll)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  # ============================================================
  # SARIMA ROADMAP (FR) â€” Slider + Collapsibles
  # Structure enforced for EVERY step:
  # Objectif â†’ Analyses â†’ Tests â†’ CritÃ¨res â†’ Sorties â†’ Ce que les Ã©tudiants font (Checklist)
  # â†’ Ce que les Ã©tudiants Ã©crivent (papier) â†’ Conclusion (APA) â†’ PiÃ¨ges
  #
  # HOW TO USE
  # 1) UI:     uiOutput("roadmap_Detailed_Fr_ui")
  # 2) server: paste EVERYTHING below inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui8 <- renderUI({
    
    # ----------------------------
    # Helpers: accordion building
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # top
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # nested
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    P <- function(...) tags$p(...)
    H <- function(txt) tags$h5(style="margin:8px 0 6px 0;", txt)
    
    Checklist <- function(items) {
      tags$ul(lapply(items, function(x) tags$li(HTML(paste0("&#x2610; ", x)))))
    }
    
    PaperBlock <- function(title, text) {
      tags$div(
        class="paper-block",
        tags$p(tags$b(title)),
        tags$p(text)
      )
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, how_to_apply = NULL,
                     formula = NULL, example = NULL, what_to_write = NULL, notes = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("DÃ©finition : "), definition),
                 if (!is.null(purpose))      P(tags$b("But / utilitÃ© : "), purpose) else NULL,
                 if (!is.null(criteria))     P(tags$b("CritÃ¨res / indices : "), criteria) else NULL,
                 if (!is.null(how_to_apply)) P(tags$b("Comment lâ€™utiliser (pas Ã  pas) : "), how_to_apply) else NULL,
                 if (!is.null(formula))      P(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example))      P(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(what_to_write))P(tags$b("Phrase-type (Ã  Ã©crire) : "), what_to_write) else NULL,
                 if (!is.null(notes))        P(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("But (dÃ©taillÃ©) : "), purpose),
                 P(tags$b("Quand lâ€™utiliser : "), when_to_use),
                 P(tags$b("H0 : "), H0),
                 P(tags$b("H1 : "), H1),
                 if (!is.null(statistic))                P(tags$b("Statistique / idÃ©e : "), statistic) else NULL,
                 if (!is.null(decision_rule))            P(tags$b("RÃ¨gle de dÃ©cision : "), decision_rule) else NULL,
                 if (!is.null(interpretation))           P(tags$b("InterprÃ©tation (sens) : "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices))P(tags$b("Implication pour vos choix : "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                P(tags$b("Comment le rapporter : "), reporting) else NULL,
                 if (!is.null(caveats))                  P(tags$b("Limites / piÃ¨ges : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    StepPage <- function(
    but_text,
    objectif, analyses, tests, criteres, sorties,
    checklist_items, paper_text, apa_text, pieges_items,
    open_objectif = TRUE, open_analyses = TRUE
    ) {
      tags$div(class="road-card tight",
               callout(tags$b("But : "), but_text, type="ok"),
               
               D("Objectif", open = open_objectif, objectif),
               D("Analyses", open = open_analyses, analyses),
               D("Tests", open = FALSE, tests),
               D("CritÃ¨res", open = FALSE, criteres),
               D("Sorties", open = FALSE, sorties),
               
               D("Ce que les Ã©tudiants font (Checklist opÃ©rationnelle)", open = FALSE,
                 P("Lâ€™Ã©tudiant doit pouvoir cocher chaque point. Si un point nâ€™est pas faisable, il doit Ã©crire pourquoi (donnÃ©es insuffisantes, frÃ©quence inadÃ©quate, etc.)."),
                 Checklist(checklist_items)
               ),
               
               D("Ce que les Ã©tudiants Ã©crivent (papier)", open = FALSE,
                 PaperBlock("Texte Ã  insÃ©rer dans le rapport (version â€œpapierâ€)", paper_text)
               ),
               
               D("Ce que les Ã©tudiants Ã©crivent (Conclusion en format APA)", open = FALSE,
                 PaperBlock("Conclusion (APA) â€” formulation recommandÃ©e", apa_text)
               ),
               
               D("PiÃ¨ges", open = FALSE,
                 tags$ul(lapply(pieges_items, tags$li))
               )
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
    .tight ol {margin: 6px 0 6px 18px;}
    .paper-block {border:1px dashed #ddd; border-radius:10px; padding:10px; background:#fcfcfc;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step labels & badges
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Cadrer le problÃ¨me & la validation",
        "[1] QualitÃ© des donnÃ©es & prÃ©paration (NA, frÃ©quence, outliers)",
        "[2] Exploration visuelle (tendance, saison, variance)",
        "[3] DÃ©composition (additif/multiplicatif, STL)",
        "[4] StationnaritÃ© & diffÃ©renciation (choix d, D, s) + tests",
        "[5] Baseline (naÃ¯f / auto-ARIMA) + critÃ¨res de sÃ©lection",
        "[6] Identification manuelle (ACF/PACF) + grille candidates",
        "[7] Diagnostics & comparaison finale (tests rÃ©sidus + forecasting)",
        "[8] RÃ©daction: conclusion, signification, et livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Horizon", "Protocole", "MÃ©triques"),
        c("FrÃ©quence", "NA", "Outliers", "Transformations"),
        c("Graphiques", "SaisonnalitÃ©", "Variance", "Signal"),
        c("STL", "Additif vs multiplicatif", "Structure"),
        c("ADF/KPSS/PP", "d/D/s", "RÃ¨gles de choix"),
        c("Baseline", "AICc/BIC", "NaÃ¯f"),
        c("ACF/PACF", "Parcimonie", "Candidats"),
        c("Ljungâ€“Box", "ARCH", "NormalitÃ©", "Accuracy"),
        c("SynthÃ¨se", "Conclusion", "Sens", "Reproductible")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ------------------------------------------------------------
    # Step content with REQUIRED structure for ALL steps
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================
      # STEP 0
      # =========================
      if (k == 0) {
        return(StepPage(
          but_text = "DÃ©finir prÃ©cisÃ©ment le problÃ¨me de prÃ©vision (quoi, quand, Ã  quel horizon) et le protocole dâ€™Ã©valuation, car sans validation temporelle correcte, toute performance rapportÃ©e peut Ãªtre artificielle.",
          objectif = tagList(
            P("Lâ€™objectif est de transformer une intuition (â€œje veux prÃ©voirâ€) en une spÃ©cification testable. Ã€ la fin, tout lecteur doit comprendre : la variable prÃ©vue, la frÃ©quence, lâ€™horizon, et comment la performance est mesurÃ©e sans fuite dâ€™information."),
            tags$ul(
              tags$li("DÃ©finir la sÃ©rie rÃ©ponse ", tags$code("y_t"), " (unitÃ©, sens, source)."),
              tags$li("DÃ©finir la frÃ©quence (quotidien/hebdo/mensuel) et vÃ©rifier la rÃ©gularitÃ© de lâ€™index."),
              tags$li("DÃ©finir lâ€™horizon ", tags$code("h"), " et le protocole (split temporel / rolling-origin)."),
              tags$li("DÃ©finir les mÃ©triques (MAE/RMSE/...) + benchmarks (naÃ¯f, naÃ¯f saisonnier).")
            )
          ),
          analyses = tagList(
            P("On Ã©tablit une â€œcontrainte temporelleâ€ : lâ€™entraÃ®nement se fait uniquement sur le passÃ©, et lâ€™Ã©valuation uniquement sur le futur. Ensuite, on choisit des mÃ©triques cohÃ©rentes avec le coÃ»t des erreurs."),
            tags$ul(
              tags$li(tags$b("Index & frÃ©quence : "), "contrÃ´ler doublons, trous, et cohÃ©rence de la pÃ©riodicitÃ©."),
              tags$li(tags$b("Validation : "), "dÃ©finir clairement train/test (dates exactes) ou rolling-origin."),
              tags$li(tags$b("MÃ©triques : "), "choisir au moins deux mesures complÃ©mentaires (ex. MAE + RMSE).")
            )
          ),
          tests = tagList(
            P("Ã€ lâ€™Ã©tape 0, il nâ€™y a gÃ©nÃ©ralement pas de test statistique â€œformelâ€ indispensable. On consolide surtout des dÃ©finitions et des rÃ¨gles de validation."),
            TERM(
              "Rolling-origin (origine glissante)",
              "ProcÃ©dure oÃ¹ lâ€™on rÃ©-estime (ou met Ã  jour) le modÃ¨le sur des fenÃªtres temporelles successives et on Ã©value la prÃ©vision sur plusieurs futurs.",
              purpose="RÃ©duire le risque quâ€™un seul split soit â€œchanceuxâ€ et mesurer la robustesse du modÃ¨le dans des conditions rÃ©alistes.",
              criteria="Ã€ privilÃ©gier si la sÃ©rie est suffisamment longue; choisir un nombre dâ€™origines qui couvre plusieurs pÃ©riodes.",
              how_to_apply="DÃ©finir une premiÃ¨re fenÃªtre dâ€™entraÃ®nement, prÃ©voir Ã  horizon h, avancer lâ€™origine, rÃ©pÃ©ter, puis agrÃ©ger les erreurs (moyenne/ mÃ©diane).",
              what_to_write="Â« La performance a Ã©tÃ© Ã©valuÃ©e via une validation rolling-origin sur [K] origines, Ã  horizon h=[..]. Â»"
            ),
            TERM(
              "Fuite dâ€™information (data leakage)",
              "Situation oÃ¹ une information du futur influence lâ€™entraÃ®nement, ce qui augmente artificiellement la performance.",
              purpose="Ã‰viter des conclusions fausses sur la qualitÃ© du modÃ¨le.",
              criteria="Tout prÃ©traitement (imputation, scaling, Boxâ€“Cox) doit Ãªtre dÃ©fini sur train puis appliquÃ© au test.",
              how_to_apply="SÃ©parer train/test dâ€™abord, puis appliquer traitements (si possible) en respectant la chronologie.",
              notes="Le shuffle alÃ©atoire en sÃ©rie temporelle est presque toujours une erreur."
            )
          ),
          criteres = tagList(
            P("CritÃ¨res dÃ©cisionnels : lâ€™objectif est dâ€™aboutir Ã  une configuration unique (h, protocole, mÃ©triques) que lâ€™on ne modifie plus ensuite pour â€˜faire monterâ€™ le score."),
            tags$ul(
              tags$li(tags$b("Horizon : "), "doit correspondre au besoin dÃ©cisionnel (ex : planification mensuelle â†’ h en mois)."),
              tags$li(tags$b("Protocole : "), "rolling-origin si donnÃ©es suffisantes; sinon split temporel explicite."),
              tags$li(tags$b("MÃ©triques : "), "MAE + RMSE (minimum) ; MAPE seulement si y ne sâ€™approche jamais de 0."),
              tags$li(tags$b("Benchmark : "), "si votre modÃ¨le ne bat pas le naÃ¯f (ou naÃ¯f saisonnier), conclusion nÃ©gative mais valide.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Fiche-problÃ¨me : y_t (dÃ©finition, unitÃ©), dates dÃ©but/fin, frÃ©quence."),
              tags$li("Validation : h, protocole (split/rolling), pÃ©riode test (dates)."),
              tags$li("MÃ©triques : MAE/RMSE/..., benchmarks retenus.")
            )
          ),
          checklist_items = c(
            "Jâ€™ai dÃ©fini y_t (unitÃ©, source, sens).",
            "Jâ€™ai vÃ©rifiÃ© que lâ€™index est rÃ©gulier (pas de doublons, pas de trous non justifiÃ©s).",
            "Jâ€™ai fixÃ© h et je peux expliquer pourquoi cet horizon est pertinent.",
            "Jâ€™ai dÃ©fini un protocole (split temporel ou rolling-origin) avec des dates explicites.",
            "Jâ€™ai choisi â‰¥2 mÃ©triques et â‰¥1 benchmark (naÃ¯f + saisonnier si saison)."
          ),
          paper_text =
            "Â« Nous avons Ã©tudiÃ© une sÃ©rie temporelle univariÃ©e (y_t) observÃ©e Ã  une frÃ©quence [..] de [date dÃ©but] Ã  [date fin] (n=[..]). Lâ€™objectif Ã©tait de produire des prÃ©visions Ã  horizon h=[..]. La performance a Ã©tÃ© Ã©valuÃ©e avec [MAE, RMSE] selon un protocole [split temporel/rolling-origin], en comparant le modÃ¨le Ã  des benchmarks [naÃ¯f / naÃ¯f saisonnier]. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 0), le problÃ¨me de prÃ©vision a Ã©tÃ© dÃ©fini de maniÃ¨re opÃ©rationnelle (variable y_t, frÃ©quence, horizon h) et un protocole dâ€™Ã©valuation temporel a Ã©tÃ© spÃ©cifiÃ© afin dâ€™Ã©viter toute fuite dâ€™information. Cette dÃ©finition garantit que les performances rapportÃ©es reflÃ¨tent une capacitÃ© de gÃ©nÃ©ralisation vers le futur plutÃ´t quâ€™un ajustement au passÃ©. Â»",
          pieges_items = list(
            "Modifier h ou le split aprÃ¨s avoir vu les scores (optimisation a posteriori).",
            "Utiliser un shuffle alÃ©atoire ou une CV classique non temporelle.",
            "Comparer des modÃ¨les Ã©valuÃ©s sur des fenÃªtres test diffÃ©rentes.",
            "Utiliser MAPE lorsque y peut Ãªtre proche de zÃ©ro (instabilitÃ©)."
          )
        ))
      }
      
      # =========================
      # STEP 1
      # =========================
      if (k == 1) {
        return(StepPage(
          but_text = "Rendre la sÃ©rie exploitable : une grille temporelle correcte, un traitement justifiÃ© des NA, et une gestion raisonnÃ©e des outliers et des transformations, car ces choix changent directement les tests de stationnaritÃ© et lâ€™identification SARIMA.",
          objectif = tagList(
            P("Lâ€™Ã©tudiant apprend Ã  distinguer un problÃ¨me de donnÃ©es (erreurs, manquants) dâ€™un signal rÃ©el (Ã©vÃ©nement). Chaque correction doit Ãªtre documentÃ©e et justifiÃ©e."),
            tags$ul(
              tags$li("ContrÃ´ler la rÃ©gularitÃ© temporelle, lâ€™unicitÃ© des dates et le tri chronologique."),
              tags$li("Quantifier et traiter les valeurs manquantes (NA)."),
              tags$li("Identifier les outliers et dÃ©cider : corriger (erreur) ou conserver (Ã©vÃ©nement)."),
              tags$li("Ã‰valuer la nÃ©cessitÃ© de log/Boxâ€“Cox si variance non constante.")
            )
          ),
          analyses = tagList(
            P("On suit une chaÃ®ne logique : (1) index, (2) NA, (3) outliers, (4) transformation. AprÃ¨s chaque action, on re-vÃ©rifie visuellement que la sÃ©rie nâ€™a pas Ã©tÃ© dÃ©formÃ©e de faÃ§on artificielle."),
            tags$ul(
              tags$li(tags$b("Index : "), "doublons, trous, frÃ©quence rÃ©elle vs frÃ©quence annoncÃ©e."),
              tags$li(tags$b("NA : "), "pourcentage + structure des gaps, choix dâ€™imputation adaptÃ©."),
              tags$li(tags$b("Outliers : "), "dÃ©tection statistique + validation contextuelle."),
              tags$li(tags$b("Transformation : "), "stabilisation variance; prÃ©voir lâ€™inversion pour interprÃ©ter les prÃ©visions.")
            )
          ),
          tests = tagList(
            P("Ici encore, le cÅ“ur est conceptuel (dÃ©finitions + critÃ¨res). Les tests de rÃ©sidus viendront plus tard."),
            TERM(
              "NA / valeur manquante",
              "Observation absente Ã  une date attendue. En sÃ©rie temporelle, lâ€™absence est souvent structurÃ©e (pannes, jours fÃ©riÃ©s) plutÃ´t que purement alÃ©atoire.",
              purpose="Les NA rompent la continuitÃ© et peuvent fausser ACF/PACF et lâ€™estimation SARIMA si ignorÃ©s.",
              criteria="Regarder %NA et la structure : trous courts vs longs; pÃ©riodicitÃ© du manque; alignement calendrier.",
              how_to_apply="Cartographier les NA, dÃ©cider si on impute (gaps courts) ou si on change la frÃ©quence/stratÃ©gie (gaps longs).",
              what_to_write="Â« Les NA reprÃ©sentaient [..]%, traitÃ©s par [mÃ©thode] car [gaps courts/structure saisonniÃ¨re]. Â»"
            ),
            TERM(
              "Imputation",
              "Remplacement dâ€™une valeur manquante par une valeur plausible estimÃ©e Ã  partir des voisins (linÃ©aire) ou du motif saisonnier.",
              purpose="Conserver une grille rÃ©guliÃ¨re et Ã©viter une rupture artificielle.",
              criteria="Simple si trous trÃ¨s courts; saisonniÃ¨re si saison forte; prudence si trous longs.",
              how_to_apply="Imputer, puis re-tracer la sÃ©rie et vÃ©rifier que la saison/tendance nâ€™a pas Ã©tÃ© artificiellement lissÃ©e.",
              notes="Toujours documenter : lâ€™imputation est une hypothÃ¨se."
            ),
            TERM(
              "Outlier (aberrant)",
              "Valeur atypique pouvant Ãªtre erreur (capteur) ou Ã©vÃ©nement rÃ©el (promo, crise).",
              purpose="Peut perturber paramÃ¨tres et diagnostics, mais peut aussi Ãªtre un signal que la prÃ©vision doit reflÃ©ter.",
              criteria="Combiner rÃ¨gle statistique (IQR/z-score robuste) + contexte.",
              how_to_apply="Marquer sur graphique, dÃ©cider corriger/supprimer si impossible physiquement; conserver si Ã©vÃ©nement rÃ©el.",
              what_to_write="Â« Les valeurs atypiques autour de [dates] ont Ã©tÃ© [conservÃ©es/ajustÃ©es] car [raison]. Â»"
            ),
            TERM(
              "Boxâ€“Cox / log",
              "Famille de transformations (paramÃ¨tre Î») pour stabiliser la variance; log est un cas particulier (Î»â†’0).",
              purpose="Rendre la variance plus homogÃ¨ne et souvent rendre la saison plus additive.",
              criteria="Variance/amplitude saisonniÃ¨re augmente avec le niveau â†’ transformation utile.",
              how_to_apply="Tester log/Boxâ€“Cox, re-vÃ©rifier les graphiques et stationnaritÃ© ensuite; prÃ©voir lâ€™inversion.",
              formula="BC(y; Î») = (y^Î» - 1)/Î» ; log(y) si Î»â†’0"
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("NA : "), "si trous courts â†’ imputation simple; si saison forte â†’ imputation saisonniÃ¨re; si trous longs â†’ discuter/adapter."),
              tags$li(tags$b("Outliers : "), "corriger/supprimer si erreur; conserver si Ã©vÃ©nement; considÃ©rer SARIMAX/intervention si rÃ©current."),
              tags$li(tags$b("Transformation : "), "si variance non constante â†’ log/Boxâ€“Cox; sinon Ã©viter complexitÃ© inutile.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("SÃ©rie â€˜propreâ€™ + journal des traitements (quoi, quand, pourquoi)."),
              tags$li("RÃ©sumÃ© NA (k, %) + mÃ©thode dâ€™imputation et justification."),
              tags$li("Liste outliers + dÃ©cision + justification."),
              tags$li("Transformation retenue (ou non) + rÃ¨gle dâ€™inversion.")
            )
          ),
          checklist_items = c(
            "Jâ€™ai vÃ©rifiÃ© doublons/trous et confirmÃ© la frÃ©quence rÃ©elle.",
            "Jâ€™ai mesurÃ© %NA et la structure des gaps (courts/longs).",
            "Jâ€™ai choisi une mÃ©thode NA et je peux la justifier.",
            "Jâ€™ai dÃ©tectÃ© des outliers et dÃ©cidÃ© corriger vs conserver avec justification.",
            "Jâ€™ai Ã©valuÃ© la variance et dÃ©cidÃ© log/Boxâ€“Cox si nÃ©cessaire (avec inversion)."
          ),
          paper_text =
            "Â« La sÃ©rie a Ã©tÃ© contrÃ´lÃ©e pour la rÃ©gularitÃ© temporelle (dates uniques, pas de doublons). Les valeurs manquantes (k=[..], [..]%) ont Ã©tÃ© traitÃ©es par [mÃ©thode] car [raison]. Les observations atypiques ont Ã©tÃ© identifiÃ©es et [conservÃ©es/ajustÃ©es] en tenant compte du contexte [..]. Une transformation [log/Boxâ€“Cox] a Ã©tÃ© [appliquÃ©e/non appliquÃ©e] afin de [stabiliser la variance/maintenir lâ€™interprÃ©tabilitÃ©]. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 1), les donnÃ©es ont Ã©tÃ© rendues cohÃ©rentes sur une grille rÃ©guliÃ¨re et les traitements (NA, outliers, transformation) ont Ã©tÃ© documentÃ©s et justifiÃ©s. Cette prÃ©paration rÃ©duit le risque de diagnostics trompeurs et assure que les dÃ©cisions SARIMA ultÃ©rieures reposent sur le signal plutÃ´t que sur des artefacts de donnÃ©es. Â»",
          pieges_items = list(
            "Imputer longuement sans discussion (invention de signal).",
            "Supprimer des Ã©vÃ©nements rÃ©els (perte dâ€™information utile).",
            "Appliquer log/Boxâ€“Cox sans expliquer comment revenir Ã  lâ€™Ã©chelle originale.",
            "Faire lâ€™imputation en utilisant des informations du futur (leakage)."
          )
        ))
      }
      
      # =========================
      # STEP 2
      # =========================
      if (k == 2) {
        return(StepPage(
          but_text = "Lire la sÃ©rie : repÃ©rer tendance, saisonnalitÃ©, rupture et variance pour transformer ces observations en dÃ©cisions (transformation, s, besoin de d/D).",
          objectif = tagList(
            P("Lâ€™objectif est de produire un diagnostic narratif : ce que montrent les graphes et comment cela influence la suite. On ne â€˜met pas des figuresâ€™ : on Ã©crit ce quâ€™elles prouvent."),
            tags$ul(
              tags$li("Visualiser la sÃ©rie (brute et Ã©ventuellement transformÃ©e)."),
              tags$li("DÃ©tecter tendance, saison et anomalies visibles."),
              tags$li("Ã‰valuer la stabilitÃ© de variance et la prÃ©sence de ruptures possibles.")
            )
          ),
          analyses = tagList(
            tags$ul(
              tags$li(tags$b("Courbe temporelle : "), "forme globale, tendances, zones anormales."),
              tags$li(tags$b("Graphiques saisonniers : "), "seasonal plot, boxplots par mois/semaine."),
              tags$li(tags$b("ACF (exploratoire) : "), "pics aux multiples de s pour confirmer la saison."),
              tags$li(tags$b("Variance : "), "amplitude augmente-t-elle avec le niveau ?")
            ),
            P("Chaque observation doit dÃ©boucher sur une hypothÃ¨se : â€˜s=..â€™, â€˜transformation nÃ©cessaireâ€™, â€˜d probableâ€™, â€˜D probableâ€™, ou â€˜rupture Ã  discuterâ€™.")
          ),
          tests = tagList(
            P("Peu de tests formels ici : on ancre surtout des dÃ©finitions opÃ©rationnelles qui guideront les choix."),
            TERM(
              "Tendance",
              "Ã‰volution de long terme du niveau moyen (hausse/baisse durable).",
              purpose="Une tendance persistante suggÃ¨re souvent une non-stationnaritÃ© nÃ©cessitant une diffÃ©renciation non saisonniÃ¨re (d).",
              criteria="Courbe qui dÃ©rive + ACF qui dÃ©croÃ®t lentement sur plusieurs lags.",
              how_to_apply="DÃ©crire la direction (hausse/baisse), la pÃ©riode concernÃ©e, et si la tendance semble stable ou change de rÃ©gime.",
              what_to_write="Â« La sÃ©rie prÃ©sente une tendance [..], suggÃ©rant la nÃ©cessitÃ© dâ€™Ã©valuer d>0. Â»"
            ),
            TERM(
              "SaisonnalitÃ©",
              "Motif rÃ©current avec une pÃ©riode s (ex. 12 mois).",
              purpose="Justifier s et Ã©ventuellement D=1 si la saison est persistante.",
              criteria="Motifs rÃ©pÃ©tÃ©s + pics ACF Ã  s,2s,3s.",
              how_to_apply="Fixer s Ã  partir du calendrier, puis vÃ©rifier par seasonal plot et ACF.",
              what_to_write="Â« Une saisonnalitÃ© de pÃ©riode s=[..] est observÃ©e, ce qui motive lâ€™examen de termes saisonniers. Â»"
            ),
            TERM(
              "Rupture structurelle",
              "Changement durable de niveau, tendance ou variance (changement de rÃ©gime).",
              purpose="Une rupture peut rendre les tests de stationnaritÃ© ambigus et dÃ©grader la prÃ©vision si le futur suit un nouveau rÃ©gime.",
              criteria="Changement brusque et durable; comportements avant/aprÃ¨s diffÃ©rents.",
              how_to_apply="Annoter la date, chercher une cause, et mentionner que la stabilitÃ© du modÃ¨le dÃ©pend de la persistance du rÃ©gime.",
              notes="SARIMA â€˜classiqueâ€™ suppose un rÃ©gime relativement stable."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("SaisonnalitÃ© : "), "motifs + ACF Ã  s â†’ s plausible; si trÃ¨s persistante â†’ envisager D=1."),
              tags$li(tags$b("Tendance : "), "dÃ©rive durable + ACF lente â†’ envisager d=1."),
              tags$li(tags$b("Variance : "), "amplitude â†‘ avec niveau â†’ log/Boxâ€“Cox."),
              tags$li(tags$b("Rupture : "), "si rupture claire â†’ discuter limites, Ã©ventuellement segmenter/ajouter variables.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Figures EDA commentÃ©es (pas seulement affichÃ©es)."),
              tags$li("HypothÃ¨ses initiales : s, besoin de transformation, d et/ou D probables."),
              tags$li("Liste dâ€™Ã©vÃ©nements/ruptures Ã  discuter.")
            )
          ),
          checklist_items = c(
            "Jâ€™ai tracÃ© la sÃ©rie (niveau et Ã©ventuellement transformÃ©e).",
            "Jâ€™ai commentÃ© tendance, saison, anomalies, variance (avec dates/segments).",
            "Jâ€™ai proposÃ© une valeur s plausible basÃ©e sur le calendrier + preuves (ACF/seasonal plot).",
            "Jâ€™ai formulÃ© une hypothÃ¨se sur d et D Ã  tester ensuite.",
            "Jâ€™ai notÃ© toute rupture potentielle et son contexte."
          ),
          paper_text =
            "Â« Lâ€™analyse exploratoire a Ã©tÃ© rÃ©alisÃ©e via une visualisation de y_t et des graphiques saisonniers (par [mois/semaine]) afin dâ€™identifier tendance et saisonnalitÃ©. Lâ€™inspection a suggÃ©rÃ© une saisonnalitÃ© de pÃ©riode s=[..] et une tendance [..]. La variabilitÃ© a Ã©tÃ© jugÃ©e [stable/non stable], indiquant [pas de transformation/une transformation]. Des anomalies autour de [dates] ont Ã©tÃ© observÃ©es et interprÃ©tÃ©es Ã  la lumiÃ¨re du contexte [..]. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 2), lâ€™exploration visuelle a mis en Ã©vidence [tendance] et [saisonnalitÃ©] (s=[..]), ainsi quâ€™une variabilitÃ© [stable/variable]. Ces observations motivent les dÃ©cisions suivantes : [transformation], et lâ€™Ã©valuation de diffÃ©renciations d=[..] et D=[..] afin dâ€™approcher la stationnaritÃ© requise pour SARIMA. Â»",
          pieges_items = list(
            "Montrer des figures sans expliquer ce quâ€™elles impliquent pour le modÃ¨le.",
            "Choisir s â€˜au hasardâ€™ sans lien calendrier + preuves ACF.",
            "Ignorer une rupture Ã©vidente : le modÃ¨le peut Ãªtre â€˜bonâ€™ sur passÃ© et mauvais sur futur."
          )
        ))
      }
      
      # =========================
      # STEP 3
      # =========================
      if (k == 3) {
        return(StepPage(
          but_text = "Utiliser une dÃ©composition pour sÃ©parer tendance/saison/bruit, justifier additif vs multiplicatif, et dÃ©cider si STL est nÃ©cessaire (saison Ã©volutive, outliers).",
          objectif = tagList(
            P("La dÃ©composition est un outil descriptif : elle clarifie la structure et aide Ã  justifier la transformation. Elle ne remplace pas la stationnaritÃ© exigÃ©e pour lâ€™estimation SARIMA."),
            tags$ul(
              tags$li("DÃ©composer y_t (tendance, saison, reste)."),
              tags$li("Comparer additif vs multiplicatif (souvent via log)."),
              tags$li("Utiliser STL si saison change lentement ou prÃ©sence dâ€™outliers.")
            )
          ),
          analyses = tagList(
            tags$ul(
              tags$li("Produire une dÃ©composition (classique ou STL)."),
              tags$li("Comparer lâ€™amplitude saisonniÃ¨re en fonction du niveau (indice multiplicatif)."),
              tags$li("Commenter la composante rÃ©siduelle : reste-t-il une structure Ã©vidente ?")
            )
          ),
          tests = tagList(
            TERM(
              "DÃ©composition additive",
              "y_t = T_t + S_t + e_t : la saison sâ€™ajoute Ã  la tendance avec une amplitude Ã  peu prÃ¨s constante.",
              purpose="AppropriÃ©e si lâ€™Ã©cart saisonnier (pics-creux) est similaire Ã  travers le temps.",
              criteria="Amplitude saisonniÃ¨re stable, pas proportionnelle au niveau.",
              how_to_apply="Utiliser si les oscillations saisonniÃ¨res restent comparables quand la sÃ©rie monte/descend.",
              formula="y_t = T_t + S_t + e_t"
            ),
            TERM(
              "DÃ©composition multiplicative",
              "y_t = T_t Ã— S_t Ã— e_t : la saison agit comme un facteur proportionnel au niveau.",
              purpose="AppropriÃ©e quand lâ€™amplitude saisonniÃ¨re augmente avec le niveau.",
              criteria="Oscillations plus grandes quand la sÃ©rie est haute.",
              how_to_apply="Souvent, appliquer log(y) pour obtenir une forme additive dans lâ€™espace log.",
              formula="y_t = T_t Ã— S_t Ã— e_t",
              notes="Souvent log(y_t) â†’ additif sur log."
            ),
            TERM(
              "STL",
              "DÃ©composition Season-Trend (Loess) flexible, robuste, permettant une saisonnalitÃ© qui Ã©volue lentement.",
              purpose="Utile si la saison nâ€™est pas parfaitement stable ou sâ€™il existe des outliers.",
              criteria="Motifs saisonniers qui se dÃ©forment dans le temps; outliers notables.",
              how_to_apply="Utiliser STL pour la lecture descriptive; ensuite revenir aux tests/ACF pour stationnaritÃ©.",
              notes="STL â‰  preuve de stationnaritÃ©."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Additif : "), "si amplitude saisonniÃ¨re ~ constante."),
              tags$li(tags$b("Multiplicatif : "), "si amplitude saisonniÃ¨re âˆ niveau â†’ log/Boxâ€“Cox conseillÃ©."),
              tags$li(tags$b("STL : "), "si saison Ã©volutive et/ou outliers â†’ STL prÃ©fÃ©rable.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Figure de dÃ©composition + commentaire de T/S/e."),
              tags$li("DÃ©cision argumentÃ©e : additif vs multiplicatif; STL si retenu.")
            )
          ),
          checklist_items = c(
            "Jâ€™ai rÃ©alisÃ© une dÃ©composition (classique ou STL).",
            "Jâ€™ai dÃ©crit la tendance et la saison (pÃ©riode, stabilitÃ©).",
            "Jâ€™ai justifiÃ© additif vs multiplicatif (avec argument amplitudeâ†”niveau).",
            "Si multiplicatif, jâ€™ai justifiÃ© log/Boxâ€“Cox.",
            "Jâ€™ai notÃ© si la dÃ©composition rÃ©vÃ¨le des anomalies/outliers."
          ),
          paper_text =
            "Â« Nous avons rÃ©alisÃ© une dÃ©composition de la sÃ©rie afin de sÃ©parer tendance (T_t), saisonnalitÃ© (S_t) et composante rÃ©siduelle (e_t). La comparaison des amplitudes saisonniÃ¨res selon le niveau a motivÃ© lâ€™usage dâ€™une structure [additive/multiplicative]. En prÃ©sence de [saison Ã©volutive/outliers], une dÃ©composition STL a Ã©tÃ© privilÃ©giÃ©e pour sa flexibilitÃ©. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 3), la dÃ©composition a indiquÃ© une saisonnalitÃ© [stable/Ã©volutive] et une tendance [..]. Lâ€™amplitude saisonniÃ¨re Ã©tant [constante/proportionnelle au niveau], une approche [additive / transformation log puis additive] a Ã©tÃ© retenue pour prÃ©parer lâ€™estimation SARIMA sur une sÃ©rie plus appropriÃ©e. Â»",
          pieges_items = list(
            "Confondre dÃ©composition (descriptive) et stationnaritÃ© (condition pour SARIMA).",
            "Choisir multiplicatif sans vÃ©rifier quâ€™une transformation rend la saison plus stable.",
            "Ignorer que des outliers peuvent fausser la lecture des composantes."
          )
        ))
      }
      
      # =========================
      # STEP 4
      # =========================
      if (k == 4) {
        return(StepPage(
          but_text = "Choisir s, d, D pour obtenir une sÃ©rie approximativement stationnaire (aprÃ¨s diffÃ©renciation) et justifier ce choix par convergence : graphes + ACF/PACF + tests ADF/KPSS/PP, tout en Ã©vitant la sur-diffÃ©renciation.",
          objectif = tagList(
            P("SARIMA suppose que la sÃ©rie est stationnaire aprÃ¨s diffÃ©renciation. Cette Ã©tape dÃ©cide combien de tendance (d) et combien de saison persistante (D) on retire avant dâ€™estimer les composantes AR/MA."),
            tags$ul(
              tags$li("DÃ©finir s (pÃ©riode saisonniÃ¨re) Ã  partir du calendrier et des preuves empiriques."),
              tags$li("Choisir d (diffÃ©renciation ordinaire) et D (diffÃ©renciation saisonniÃ¨re)."),
              tags$li("Valider stationnaritÃ© via ADF/KPSS/PP + diagnostics ACF."),
              tags$li("ContrÃ´ler la sur-diffÃ©renciation et retenir la solution la plus simple.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Fixer s (ex. mensuel=12) puis confirmer via seasonal plot/ACF."),
              tags$li("Essayer D=0 puis D=1 si saison persistante; vÃ©rifier ACF au lag s aprÃ¨s diffÃ©renciation saisonniÃ¨re."),
              tags$li("Essayer d=0 puis d=1 si tendance stochastique; vÃ©rifier ACF lag 1 aprÃ¨s diffÃ©renciation."),
              tags$li("Appliquer tests ADF/KPSS/PP sur la sÃ©rie obtenue; interprÃ©ter ensemble."),
              tags$li("Si conflits/symptÃ´mes de sur-diff, ajuster et re-tester.")
            )
          ),
          tests = tagList(
            H("Concepts / dÃ©finitions indispensables"),
            TERM(
              "DiffÃ©renciation ordinaire (d)",
              "Appliquer âˆ‡ : âˆ‡y_t = y_t âˆ’ y_{tâˆ’1}. RÃ©pÃ©ter d fois retire progressivement une tendance stochastique.",
              purpose="Rendre la sÃ©rie plus stable (moyenne/variance) pour permettre un ARMA sur la partie stationnaire.",
              criteria="d âˆˆ {0,1} la plupart du temps; d=2 est rare et doit alerter.",
              how_to_apply="Tester d=0 puis d=1; vÃ©rifier ACF et tests; sâ€™arrÃªter dÃ¨s que la stationnaritÃ© est raisonnable.",
              formula="(1-B)^d y_t"
            ),
            TERM(
              "DiffÃ©renciation saisonniÃ¨re (D)",
              "Appliquer âˆ‡_s : âˆ‡_s y_t = y_t âˆ’ y_{tâˆ’s}. Retire une non-stationnaritÃ© saisonniÃ¨re persistante.",
              purpose="Supprimer une racine unitaire saisonniÃ¨re afin que la saison restante soit modÃ©lisÃ©e par P/Q.",
              criteria="D âˆˆ {0,1} le plus souvent; D=2 trÃ¨s rare.",
              how_to_apply="Essayer D=1 si la saison persiste fortement; surveiller ACF lag s (sur-diff si trÃ¨s nÃ©gative).",
              formula="(1-B^s)^D y_t"
            ),
            TERM(
              "Sur-diffÃ©renciation",
              "DiffÃ©rencier plus que nÃ©cessaire (d ou D trop grand), crÃ©ant une structure artificielle et augmentant lâ€™instabilitÃ©.",
              purpose="Ã‰viter des paramÃ¨tres instables et des prÃ©visions oscillantes.",
              criteria="ACF lag1 trÃ¨s nÃ©gative (sur-diff d) ou ACF lag s trÃ¨s nÃ©gative (sur-diff D).",
              how_to_apply="Si symptÃ´me prÃ©sent, rÃ©duire d/D et re-vÃ©rifier.",
              notes="RÃ¨gle : minimum de diffÃ©renciation pour stationnariser."
            ),
            
            H("Tests de stationnaritÃ© (ADF/KPSS/PP)"),
            TEST(
              name="ADF â€” Augmented Dickeyâ€“Fuller (racine unitaire)",
              purpose="DÃ©tecter une racine unitaire (non-stationnaritÃ©) : le test Ã©value si la sÃ©rie se comporte comme une marche alÃ©atoire, oÃ¹ les chocs ont des effets persistants.",
              when_to_use="Sur la sÃ©rie brute puis aprÃ¨s diffÃ©renciation pour dÃ©cider/valider d (et parfois lâ€™effet combinÃ© avec D).",
              H0="Racine unitaire â†’ non-stationnaire.",
              H1="Stationnaire (selon spÃ©cification drift/trend).",
              statistic="RÃ©gression sur Î”y_t avec y_{tâˆ’1} et retards de Î”y_t; test sur le coefficient de y_{tâˆ’1}.",
              decision_rule="p < 0.05 â†’ rejet H0 â†’ stationnaritÃ© plausible; p â‰¥ 0.05 â†’ non-rejet â†’ d (ou spÃ©cification) Ã  reconsidÃ©rer.",
              interpretation="Rejeter H0 signifie que la sÃ©rie a une force de retour (autour dâ€™une moyenne ou dâ€™une tendance dÃ©terministe) plutÃ´t quâ€™une dÃ©rive stochastique.",
              what_it_means_for_choices="Si ADF ne rejette pas sur la brute, tester d=1; si rejette aprÃ¨s (d,D), passer Ã  lâ€™identification p/q/P/Q.",
              reporting="PrÃ©ciser version (drift/trend), nb de retards, statistique et p-value, et relier au choix de d.",
              caveats="SensibilitÃ© aux retards et aux ruptures structurelles."
            ),
            TEST(
              name="KPSS â€” StationnaritÃ© comme H0",
              purpose="Tester la stationnaritÃ© en prenant lâ€™hypothÃ¨se inverse de lâ€™ADF : on suppose stationnaire tant que les donnÃ©es ne la contredisent pas. Utile pour trianguler.",
              when_to_use="En complÃ©ment de lâ€™ADF/PP, surtout si les conclusions sont ambiguÃ«s.",
              H0="SÃ©rie stationnaire (niveau ou tendance selon version).",
              H1="Non-stationnaire.",
              statistic="BasÃ© sur la somme cumulÃ©e des rÃ©sidus et une variance longue.",
              decision_rule="p < 0.05 â†’ rejet stationnaritÃ©; p â‰¥ 0.05 â†’ compatible stationnaritÃ©.",
              interpretation="Un KPSS non significatif aprÃ¨s diffÃ©renciation renforce la validitÃ© du choix d/D; un rejet suggÃ¨re quâ€™il reste de la non-stationnaritÃ©.",
              what_it_means_for_choices="ADF/PP rejettent + KPSS non rejette â†’ signal fort; sinon, reconsidÃ©rer d/D ou rupture.",
              reporting="PrÃ©ciser version (level/trend) et conclusion explicite.",
              caveats="TrÃ¨s sensible aux ruptures; dÃ©pend du paramÃ¨tre de variance longue."
            ),
            TEST(
              name="PP â€” Phillipsâ€“Perron",
              purpose="Tester la racine unitaire comme ADF, mais en corrigeant autocorrÃ©lation/hÃ©tÃ©roscÃ©dasticitÃ© de faÃ§on non paramÃ©trique.",
              when_to_use="ComplÃ©ment Ã  ADF, utile si lâ€™ADF dÃ©pend trop du choix des retards.",
              H0="Racine unitaire â†’ non-stationnaire.",
              H1="Stationnaire.",
              decision_rule="p < 0.05 â†’ rejet H0 â†’ stationnaritÃ© plausible.",
              interpretation="Concordance ADF+PP renforce la conclusion; dÃ©saccord implique de revenir aux graphes/ACF et Ã  la spÃ©cification.",
              what_it_means_for_choices="DÃ©saccord â†’ tester autre spÃ©cification drift/trend, vÃ©rifier rupture, re-Ã©valuer d/D.",
              caveats="Comme ADF, sensible aux ruptures."
            ),
            
            H("Triangulation (comment conclure proprement)"),
            Acc("InterprÃ©ter ADF/KPSS/PP ensemble (logique Ã  Ã©crire)",
                tags$ul(
                  tags$li(tags$b("Accord stationnaire : "), "ADF/PP rejettent la racine unitaire (p petit) ET KPSS ne rejette pas la stationnaritÃ© (p grand)."),
                  tags$li(tags$b("Accord non-stationnaire : "), "ADF/PP ne rejettent pas (p grand) ET KPSS rejette (p petit)."),
                  tags$li(tags$b("Conflit : "), "sâ€™appuyer sur la convergence des indices (plots + ACF + tests) et minimiser d/D pour Ã©viter la sur-diff.")
                )
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Choisir s : "), "calendrier dâ€™abord, ACF/seasonal plot ensuite."),
              tags$li(tags$b("Choisir D : "), "souvent 0 ou 1; si la saison persiste fortement, tester D=1; Ã©viter D=2."),
              tags$li(tags$b("Choisir d : "), "souvent 0 ou 1; d=2 rare."),
              tags$li(tags$b("Stop rule : "), "sâ€™arrÃªter dÃ¨s que la stationnaritÃ© est raisonnable; surveiller la sur-diff (ACF nÃ©gative forte).")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Valeurs retenues : s, d, D + justification triangulÃ©e."),
              tags$li("RÃ©sultats tests ADF/KPSS/PP sur sÃ©rie finale (et Ã©ventuellement brute)."),
              tags$li("Indication explicite sur sur-diff (prÃ©sente/absente).")
            )
          ),
          checklist_items = c(
            "Jâ€™ai fixÃ© s et je peux justifier (calendrier + preuves ACF).",
            "Jâ€™ai testÃ© D=0 puis D=1 si nÃ©cessaire, et vÃ©rifiÃ© ACF au lag s.",
            "Jâ€™ai testÃ© d=0 puis d=1 si nÃ©cessaire, et vÃ©rifiÃ© ACF au lag 1.",
            "Jâ€™ai exÃ©cutÃ© ADF/KPSS/PP et interprÃ©tÃ© ensemble (pas test par test).",
            "Jâ€™ai vÃ©rifiÃ© lâ€™absence de sur-diff et retenu la solution la plus simple."
          ),
          paper_text =
            "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e par les tests ADF, KPSS et PP afin de trianguler lâ€™Ã©vidence, ces tests ayant des hypothÃ¨ses nulles diffÃ©rentes. Sur la base des rÃ©sultats combinÃ©s (tests + diagnostics ACF/PACF + inspection visuelle), nous avons retenu d=[..] diffÃ©renciations ordinaires et D=[..] diffÃ©renciations saisonniÃ¨res avec une pÃ©riode s=[..]. Ce choix visait Ã  supprimer [tendance / racine unitaire saisonniÃ¨re] tout en Ã©vitant la sur-diffÃ©renciation. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 4), la sÃ©rie transformÃ©e par (d=[..], D=[..]) avec pÃ©riode s=[..] est apparue compatible avec une stationnaritÃ© opÃ©rationnelle : ADF/PP [rejet/non rejet] de H0 et KPSS [non rejet/rejet] de la stationnaritÃ©, sans symptÃ´mes marquÃ©s de sur-diffÃ©renciation. Cette dÃ©cision autorise lâ€™estimation de modÃ¨les SARIMA sur la sÃ©rie diffÃ©renciÃ©e. Â»",
          pieges_items = list(
            "Sur-diffÃ©rencier (d ou D trop grand) â†’ ACF nÃ©gative forte, prÃ©visions instables.",
            "Forcer D=2 : souvent signe dâ€™une mauvaise spÃ©cification de s ou dâ€™un problÃ¨me de donnÃ©es.",
            "InterprÃ©ter une seule p-value sans triangulation.",
            "Ignorer une rupture structurelle qui biaise les tests."
          )
        ))
      }
      
      # =========================
      # STEP 5
      # =========================
      if (k == 5) {
        return(StepPage(
          but_text = "Ã‰tablir une rÃ©fÃ©rence solide (benchmarks + auto-ARIMA) et des critÃ¨res de sÃ©lection rÃ©alistes : un bon modÃ¨le doit Ãªtre valide (diagnostics) et utile (bat les benchmarks) â€” pas seulement â€œmeilleur AICcâ€.",
          objectif = tagList(
            tags$ul(
              tags$li("Construire des benchmarks (naÃ¯f, naÃ¯f saisonnier)."),
              tags$li("Estimer une baseline via auto-ARIMA (AICc/BIC) comme point de dÃ©part."),
              tags$li("DÃ©finir des critÃ¨res de sÃ©lection : information + diagnostics + performance out-of-sample.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Calculer les erreurs de prÃ©vision des benchmarks sur le mÃªme protocole (test/rolling)."),
              tags$li("Ajuster auto-ARIMA avec contraintes explicites (max p/q/P/Q)."),
              tags$li("Comparer AICc/BIC et erreurs out-of-sample; vÃ©rifier stabilitÃ© des paramÃ¨tres."),
              tags$li("Garder auto-ARIMA comme baseline, pas comme vÃ©ritÃ© finale.")
            )
          ),
          tests = tagList(
            TERM(
              "Benchmark naÃ¯f",
              "PrÃ©vision Ã©gale Ã  la derniÃ¨re observation (random walk).",
              purpose="Ã‰tablir un minimum : si le modÃ¨le ne bat pas le naÃ¯f, la valeur ajoutÃ©e est faible.",
              how_to_apply="Calculer MAE/RMSE sur la fenÃªtre test/rolling, mÃªme horizon h.",
              formula="Å·_{t+h} = y_t"
            ),
            TERM(
              "Benchmark naÃ¯f saisonnier",
              "PrÃ©vision Ã©gale Ã  la derniÃ¨re valeur de la mÃªme saison.",
              purpose="RÃ©fÃ©rence clÃ© lorsque la saisonnalitÃ© est forte.",
              how_to_apply="Ã‰valuer sur au moins une saison complÃ¨te si possible.",
              formula="Å·_{t+h} = y_{t+h-s}"
            ),
            TERM(
              "AICc vs BIC",
              "CritÃ¨res dâ€™information pÃ©nalisant la complexitÃ©; AICc est souvent privilÃ©giÃ© pour la prÃ©vision, BIC pour la parcimonie.",
              purpose="Comparer des modÃ¨les estimÃ©s sur la mÃªme sÃ©rie, mÃªme transformation.",
              criteria="Î”AICc < 2 â†’ modÃ¨les quasi Ã©quivalents : prÃ©fÃ©rer le plus simple.",
              how_to_apply="Ne pas utiliser AICc/BIC pour comparer des modÃ¨les sur des donnÃ©es diffÃ©rentes."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Information : "), "AICc minimal, mais Î”AICc<2 â†’ choisir plus simple."),
              tags$li(tags$b("ValiditÃ© : "), "paramÃ¨tres stables + diagnostics rÃ©sidus acceptables (au moins une vÃ©rification)."),
              tags$li(tags$b("UtilitÃ© : "), "doit battre naÃ¯f/naÃ¯f saisonnier sur MAE/RMSE (mÃªme protocole).")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Table comparant benchmarks vs auto-ARIMA : AICc/BIC + MAE/RMSE."),
              tags$li("Baseline retenue (spÃ©cification) + contraintes de recherche documentÃ©es.")
            )
          ),
          checklist_items = c(
            "Jâ€™ai calculÃ© les performances du naÃ¯f et du naÃ¯f saisonnier (si saison).",
            "Jâ€™ai estimÃ© auto-ARIMA avec des contraintes explicites (max ordres).",
            "Jâ€™ai comparÃ© AICc/BIC et erreurs out-of-sample sur le mÃªme protocole.",
            "Jâ€™ai retenu la baseline comme point de dÃ©part, pas comme modÃ¨le final.",
            "Jâ€™ai documentÃ© paramÃ¨tres/contraintes (reproductibilitÃ©)."
          ),
          paper_text =
            "Â« Un modÃ¨le de rÃ©fÃ©rence a Ã©tÃ© Ã©tabli en comparant des benchmarks (naÃ¯f, naÃ¯f saisonnier) et une sÃ©lection auto-ARIMA basÃ©e sur lâ€™AICc. La recherche auto-ARIMA a Ã©tÃ© conduite sous contraintes [..] (max p/q/P/Q, stepwise=[..]) sur la sÃ©rie [transformÃ©e/diffÃ©renciÃ©e] dÃ©finie prÃ©cÃ©demment. Le modÃ¨le retenu (baseline) Ã©tait SARIMA((p,d,q)(P,D,Q)[s]) et a servi de point de dÃ©part pour lâ€™identification manuelle. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 5), la baseline auto-ARIMA a fourni une spÃ©cification initiale qui [bat/ne bat pas] les benchmarks. Cette baseline sert de rÃ©fÃ©rence : les modÃ¨les manuels ultÃ©rieurs doivent au minimum Ã©galer sa performance tout en respectant la parcimonie et les diagnostics. Â»",
          pieges_items = list(
            "Prendre auto-ARIMA comme vÃ©ritÃ© absolue sans diagnostics ni performance test.",
            "Comparer AICc entre modÃ¨les estimÃ©s sur des donnÃ©es transformÃ©es diffÃ©remment.",
            "Oublier les benchmarks : on peut â€˜gagnerâ€™ AICc mais perdre en prÃ©vision utile."
          )
        ))
      }
      
      # =========================
      # STEP 6
      # =========================
      if (k == 6) {
        return(StepPage(
          but_text = "Construire un petit ensemble de modÃ¨les candidats guidÃ©s par ACF/PACF et la parcimonie, puis sÃ©lectionner par convergence : (AICc/BIC) + diagnostics + performance.",
          objectif = tagList(
            tags$ul(
              tags$li("Tracer ACF/PACF sur la sÃ©rie stationnaire (aprÃ¨s d/D)."),
              tags$li("Proposer p,q,P,Q plausibles (petits)."),
              tags$li("Ajuster 3â€“8 candidats (pas 200) et comparer.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Tracer ACF/PACF aprÃ¨s diffÃ©renciation (d,D)."),
              tags$li("Lire non-saisonnier : PACFâ†’p, ACFâ†’q (heuristiques)."),
              tags$li("Lire saisonnier : pics aux lags s,2s â†’ P/Q plausibles."),
              tags$li("Ajuster quelques modÃ¨les et comparer AICc/BIC + stabilitÃ© + diagnostics.")
            )
          ),
          tests = tagList(
            TERM(
              "ACF",
              "CorrÃ©lation entre y_t et y_{t-k}. Sert Ã  dÃ©tecter des structures MA et des motifs saisonniers (pics Ã  s,2s,...).",
              purpose="Guider le choix de q et Q (termes MA non-saisonnier et saisonnier).",
              criteria="Pics clairs et cohÃ©rents; motifs rÃ©pÃ©tÃ©s plus informatifs quâ€™un pic isolÃ©.",
              how_to_apply="Travailler sur la sÃ©rie stationnaire, proposer q/Q petits (0â€“2), puis valider via diagnostics."
            ),
            TERM(
              "PACF",
              "CorrÃ©lation partielle entre y_t et y_{t-k}, contrÃ´lant les retards intermÃ©diaires.",
              purpose="Guider le choix de p et P (termes AR non-saisonnier et saisonnier).",
              criteria="Coupure approximative aprÃ¨s p; pics aux multiples de s pour P.",
              how_to_apply="Proposer p/P petits, puis vÃ©rifier la qualitÃ© rÃ©siduelle."
            ),
            TERM(
              "Bandes de significativitÃ© ACF/PACF",
              "Approximation Â±1.96/âˆšn pour juger un pic notable.",
              purpose="Ã‰viter de sur-interprÃ©ter du bruit.",
              how_to_apply="Chercher des motifs cohÃ©rents plutÃ´t quâ€™un seul pic au-dessus de la bande."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Parcimonie : "), "prÃ©fÃ©rer p,q,P,Q petits; Ã©viter la complexitÃ© inutile."),
              tags$li(tags$b("Î”AICc : "), "si Î”AICc < 2, modÃ¨les Ã©quivalents â†’ choisir le plus simple."),
              tags$li(tags$b("StabilitÃ© : "), "refuser modÃ¨les non stationnaires/non inversibles mÃªme si AICc bon."),
              tags$li(tags$b("Validation : "), "diagnostics rÃ©sidus et performance doivent confirmer.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Liste courte de candidats + justification ACF/PACF."),
              tags$li("Comparaison candidats : AICc/BIC + indicateurs de stabilitÃ©."),
              tags$li("Candidats retenus pour diagnostic complet (Ã©tape 7).")
            )
          ),
          checklist_items = c(
            "Jâ€™ai tracÃ© ACF et PACF sur la sÃ©rie stationnaire.",
            "Jâ€™ai proposÃ© p,q,P,Q (petits) et justifiÃ© avec ACF/PACF.",
            "Jâ€™ai ajustÃ© un petit ensemble (3â€“8) de modÃ¨les candidats.",
            "Jâ€™ai comparÃ© AICc/BIC et vÃ©rifiÃ© stabilitÃ©/inversibilitÃ©.",
            "Jâ€™ai retenu 1â€“3 candidats pour diagnostics approfondis (Ã©tape 7)."
          ),
          paper_text =
            "Â« Les ordres SARIMA ont Ã©tÃ© proposÃ©s Ã  partir des motifs observÃ©s dans lâ€™ACF et la PACF de la sÃ©rie stationnaire. Des pics aux faibles lags suggÃ©raient des composantes non saisonniÃ¨res (p,q), tandis que des pics aux multiples de s suggÃ©raient des composantes saisonniÃ¨res (P,Q). Un ensemble restreint de modÃ¨les candidats a Ã©tÃ© ajustÃ© et comparÃ© via AICc/BIC et critÃ¨res de stabilitÃ©, afin de retenir des modÃ¨les parcimonieux pour les diagnostics finaux. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 6), les diagnostics ACF/PACF ont motivÃ© un ensemble restreint de spÃ©cifications SARIMA plausibles. Les candidats ont Ã©tÃ© filtrÃ©s par parcimonie et critÃ¨res dâ€™information, prÃ©parant une validation finale fondÃ©e sur les diagnostics rÃ©siduels et la performance de prÃ©vision. Â»",
          pieges_items = list(
            "Brute-force massif (â€˜200 modÃ¨lesâ€™) sans justification : ce nâ€™est pas â€˜thÃ©orieâ€™.",
            "Sur-interprÃ©ter des pics isolÃ©s ACF/PACF.",
            "Choisir un modÃ¨le instable (non stationnaire/non inversible) pour gagner un peu dâ€™AICc."
          )
        ))
      }
      
      # =========================
      # STEP 7
      # =========================
      if (k == 7) {
        return(StepPage(
          but_text = "Valider le modÃ¨le : les rÃ©sidus doivent ressembler Ã  du bruit blanc (pas dâ€™autocorrÃ©lation rÃ©siduelle) et la prÃ©vision doit battre les benchmarks. Câ€™est lâ€™Ã©tape oÃ¹ lâ€™on dÃ©cide rÃ©ellement du modÃ¨le final.",
          objectif = tagList(
            tags$ul(
              tags$li("Diagnostiquer les rÃ©sidus (temps, ACF rÃ©sidus, tests)."),
              tags$li("Ã‰valuer la performance de prÃ©vision sur test/rolling (MAE/RMSE/...)."),
              tags$li("Choisir le modÃ¨le final : diagnostics OK + performance + simplicitÃ©.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Tracer rÃ©sidus dans le temps : moyenneâ‰ˆ0, pas de tendance rÃ©siduelle."),
              tags$li("Tracer ACF des rÃ©sidus : pas de structure; pics surtout dans Â±1.96/âˆšn."),
              tags$li("Appliquer Ljungâ€“Box sur plusieurs lags L (ex. 10, s, 2s)."),
              tags$li("VÃ©rifier variance (hÃ©tÃ©roscÃ©dasticitÃ©) et normalitÃ© (optionnel)."),
              tags$li("Comparer out-of-sample Ã  benchmarks; prÃ©fÃ©rer modÃ¨le le plus simple si performances proches.")
            )
          ),
          tests = tagList(
            TEST(
              name="Ljungâ€“Box (autocorrÃ©lation rÃ©siduelle)",
              purpose="Tester si les autocorrÃ©lations des rÃ©sidus jusquâ€™Ã  un lag L sont globalement nulles. Si le test rejette H0, le modÃ¨le a laissÃ© de la structure temporelle non expliquÃ©e.",
              when_to_use="Toujours aprÃ¨s estimation SARIMA (sur plusieurs lags L).",
              H0="RÃ©sidus ~ bruit blanc jusquâ€™au lag L.",
              H1="AutocorrÃ©lation rÃ©siduelle prÃ©sente.",
              statistic="Statistique Q(L) agrÃ©gÃ©e; ddl ajustÃ©s (fitdf).",
              decision_rule="p â‰¥ 0.05 â†’ acceptable; p < 0.05 â†’ revoir la spÃ©cification (p/q/P/Q ou d/D).",
              interpretation="Un rejet signifie que le modÃ¨le ne capture pas toute la dÃ©pendance : les prÃ©visions/intervalles peuvent Ãªtre biaisÃ©s.",
              what_it_means_for_choices="Si rejet : rÃ©viser ordres AR/MA (souvent ajouter un terme saisonnier manquant) ou reconsidÃ©rer d/D.",
              reporting="Rapporter L, Q, p-value et conclure clairement sur â€˜rÃ©sidus compatibles avec bruit blancâ€™ ou non.",
              caveats="SensibilitÃ© au choix de L; grand n rend le test trÃ¨s sensible."
            ),
            TEST(
              name="ARCH LM (variance conditionnelle / clustering)",
              purpose="DÃ©tecter si la variance des rÃ©sidus dÃ©pend du passÃ© (volatilitÃ© en grappes).",
              when_to_use="SÃ©ries financiÃ¨res ou rÃ©sidus montrant variance changeante; utile si ACF des rÃ©sidus^2 est notable.",
              H0="Pas dâ€™effets ARCH.",
              H1="Effets ARCH prÃ©sents.",
              decision_rule="p < 0.05 â†’ ARCH probable â†’ envisager un modÃ¨le de variance (ex. GARCH) pour des intervalles crÃ©dibles.",
              interpretation="Le modÃ¨le de moyenne peut Ãªtre correct, mais lâ€™incertitude varie dans le temps.",
              caveats="Outliers peuvent imiter ARCH; dÃ©pend du choix de lags."
            ),
            TEST(
              name="Jarqueâ€“Bera / Shapiroâ€“Wilk (normalitÃ©, optionnel)",
              purpose="Tester la normalitÃ© des rÃ©sidus (utile surtout pour lâ€™interprÃ©tation des intervalles, moins pour la prÃ©cision).",
              when_to_use="Si vous publiez des intervalles et souhaitez justifier lâ€™hypothÃ¨se gaussienne.",
              H0="RÃ©sidus ~ normale.",
              H1="RÃ©sidus non normaux.",
              decision_rule="p < 0.05 â†’ rejet; discuter impact sur intervalles.",
              interpretation="Non-normalitÃ© frÃ©quente; prioritÃ© reste lâ€™autocorrÃ©lation rÃ©siduelle.",
              caveats="TrÃ¨s sensible si n grand; prÃ©fÃ©rer QQ-plot + discussion."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("Diagnostics : "), "ACF rÃ©sidus sans structure + Ljungâ€“Box non significatif (idÃ©alement Ã  plusieurs L)."),
              tags$li(tags$b("Performance : "), "MAE/RMSE meilleurs que benchmarks sur mÃªme protocole."),
              tags$li(tags$b("Parcimonie : "), "si performances quasi identiques â†’ choisir le modÃ¨le le plus simple."),
              tags$li(tags$b("Robustesse : "), "rÃ©sultats stables sur plusieurs origines (rolling) si possible.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Table candidats : AICc/BIC + MAE/RMSE + diagnostics (Ljungâ€“Box p-values)."),
              tags$li("Choix du modÃ¨le final + justification en 3 axes (validitÃ©, utilitÃ©, simplicitÃ©)."),
              tags$li("Figures : rÃ©sidus, ACF rÃ©sidus, prÃ©vision + intervalles.")
            )
          ),
          checklist_items = c(
            "Jâ€™ai tracÃ© les rÃ©sidus et commentÃ© leur comportement.",
            "Jâ€™ai tracÃ© lâ€™ACF des rÃ©sidus et vÃ©rifiÃ© absence de structure majeure.",
            "Jâ€™ai appliquÃ© Ljungâ€“Box (au moins 2â€“3 choix de L) et interprÃ©tÃ©.",
            "Jâ€™ai Ã©valuÃ© MAE/RMSE sur test/rolling et comparÃ© aux benchmarks.",
            "Jâ€™ai choisi le modÃ¨le final en privilÃ©giant diagnostics + performance + parcimonie."
          ),
          paper_text =
            "Â« Les diagnostics des rÃ©sidus incluaient lâ€™inspection temporelle, lâ€™ACF des rÃ©sidus et le test de Ljungâ€“Box afin dâ€™Ã©valuer la prÃ©sence dâ€™autocorrÃ©lation rÃ©siduelle. La performance de prÃ©vision a Ã©tÃ© mesurÃ©e sur [fenÃªtre test / rolling-origin] via [MAE, RMSE] et comparÃ©e aux benchmarks (naÃ¯f, naÃ¯f saisonnier). Le modÃ¨le final a Ã©tÃ© retenu sur la base de lâ€™adÃ©quation diagnostique, de la performance prÃ©dictive et de la parcimonie. Â»",
          apa_text =
            "Â« En conclusion (Ã‰tape 7), le modÃ¨le SARIMA retenu a produit des rÃ©sidus compatibles avec un bruit blanc (Ljungâ€“Box non significatif Ã  L=[..], Î±=0.05) et a surpassÃ© les benchmarks en prÃ©vision (MAE=[..], RMSE=[..]). Ce rÃ©sultat indique que la structure temporelle principale a Ã©tÃ© capturÃ©e et que les prÃ©visions Ã  horizon h=[..] sont utilisables dans la mesure oÃ¹ la dynamique historique se maintient. Â»",
          pieges_items = list(
            "Choisir un modÃ¨le sur AICc seul alors que Ljungâ€“Box rejette (rÃ©sidus autocorrÃ©lÃ©s).",
            "Ignorer benchmarks : une belle modÃ©lisation qui ne bat pas le naÃ¯f est rarement utile.",
            "Sur-interprÃ©ter la normalitÃ© : lâ€™autocorrÃ©lation rÃ©siduelle est le problÃ¨me majeur."
          )
        ))
      }
      
      # =========================
      # STEP 8
      # =========================
      if (k == 8) {
        return(StepPage(
          but_text = "Assembler un rapport reproductible et comprÃ©hensible : raconter le raisonnement, documenter toutes les dÃ©cisions (donnÃ©es â†’ choix s,d,D â†’ sÃ©lection modÃ¨le â†’ diagnostics â†’ performance) et donner une conclusion claire en style APA.",
          objectif = tagList(
            tags$ul(
              tags$li("Assembler MÃ©thodes et RÃ©sultats alignÃ©s sur les Ã©tapes 0â€“7."),
              tags$li("PrÃ©senter le modÃ¨le final SARIMA((p,d,q)(P,D,Q)[s]) et ses preuves (diagnostics + performance)."),
              tags$li("Fournir livrables : script/notebook + figures + tables.")
            )
          ),
          analyses = tagList(
            tags$ol(
              tags$li("Rassembler les choix : y_t, frÃ©quence, h, protocole, mÃ©triques, benchmarks."),
              tags$li("Documenter prÃ©paration : NA, outliers, transformations."),
              tags$li("Documenter s,d,D et justification tests + ACF."),
              tags$li("PrÃ©senter baseline + candidats + sÃ©lection finale."),
              tags$li("Inclure diagnostics rÃ©sidus + tableau dâ€™erreurs et figure de prÃ©vision.")
            )
          ),
          tests = tagList(
            TERM(
              "SpÃ©cification SARIMA complÃ¨te",
              "Notation SARIMA((p,d,q)(P,D,Q)[s]) dÃ©crivant les ordres non saisonniers et saisonniers, la diffÃ©renciation, et la pÃ©riode saisonniÃ¨re.",
              purpose="Permet de communiquer le modÃ¨le sans ambiguÃ¯tÃ©.",
              how_to_apply="La spÃ©cification doit apparaÃ®tre clairement une fois, puis Ãªtre rÃ©utilisÃ©e.",
              example="SARIMA((1,1,1)(0,1,1)[12]) pour une sÃ©rie mensuelle."
            ),
            TERM(
              "Sens de la conclusion (interprÃ©tation)",
              "La conclusion ne doit pas seulement donner un modÃ¨le, mais expliquer ce quâ€™il implique : prÃ©cision attendue, incertitude, conditions de validitÃ© (stabilitÃ© du rÃ©gime).",
              purpose="Transformer un rÃ©sultat statistique en message utilisable.",
              how_to_apply="Relier performance vs benchmarks + diagnostics rÃ©sidus + limites (ruptures, exogÃ¨nes)."
            )
          ),
          criteres = tagList(
            tags$ul(
              tags$li(tags$b("ClartÃ© : "), "chaque Ã©tape explique â€˜quoi â†’ pourquoi â†’ rÃ©sultat â†’ dÃ©cisionâ€™."),
              tags$li(tags$b("ReproductibilitÃ© : "), "donnÃ©es, dates de split, paramÃ¨tres, seed, versions."),
              tags$li(tags$b("Preuves : "), "diagnostics + performance; figures et tables alignÃ©es aux dÃ©cisions."),
              tags$li(tags$b("SobriÃ©tÃ© : "), "pas dâ€™excÃ¨s de modÃ¨les; justification de la parcimonie.")
            )
          ),
          sorties = tagList(
            tags$ul(
              tags$li("Notebook/script : chargement â†’ prÃ©paration â†’ stationnaritÃ© â†’ modÃ¨les â†’ diagnostics â†’ prÃ©visions."),
              tags$li("Figures : sÃ©rie, dÃ©composition, ACF/PACF, rÃ©sidus + ACF rÃ©sidus, prÃ©visions + intervalles."),
              tags$li("Tables : candidats (AICc/BIC), diagnostics (Ljungâ€“Box), performance (MAE/RMSE)."),
              tags$li("Conclusion APA finale.")
            )
          ),
          checklist_items = c(
            "Mon rapport suit lâ€™ordre des Ã©tapes 0â€“7 avec dÃ©cisions explicites.",
            "Jâ€™ai inclus la spÃ©cification SARIMA finale complÃ¨te.",
            "Jâ€™ai inclus figures et tables nÃ©cessaires (diagnostics + performance).",
            "Mon code est reproductible (donnÃ©es, dates, seed, paramÃ¨tres).",
            "Ma conclusion APA explique aussi le sens et les limites."
          ),
          paper_text =
            "Â« Le rapport a Ã©tÃ© structurÃ© en MÃ©thodes (donnÃ©es, prÃ©paration, stationnaritÃ©, sÃ©lection des modÃ¨les) et RÃ©sultats (observations EDA, tests, modÃ¨les candidats, diagnostics, performance). Les figures et tableaux ont Ã©tÃ© alignÃ©s sur les dÃ©cisions, et lâ€™ensemble du workflow a Ã©tÃ© rendu reproductible via un script/notebook exÃ©cutant lâ€™analyse de bout en bout. Â»",
          apa_text =
            "Â« Conclusion (APA). Le modÃ¨le SARIMA((p,d,q)(P,D,Q)[s]) retenu a Ã©tÃ© sÃ©lectionnÃ© sur la base dâ€™une validation temporelle et a surpassÃ© les benchmarks en prÃ©vision (MAE=[..], RMSE=[..]). Les diagnostics rÃ©siduels Ã©taient compatibles avec un bruit blanc (Ljungâ€“Box non significatif Ã  L=[..]), suggÃ©rant que la structure temporelle principale a Ã©tÃ© capturÃ©e. Ces rÃ©sultats indiquent que les prÃ©visions Ã  horizon h=[..] sont pertinentes tant que la dynamique observÃ©e persiste; les limites incluent [ruptures potentielles, variables exogÃ¨nes non modÃ©lisÃ©es, changements de variance]. Â»",
          pieges_items = list(
            "Rapport â€˜catalogueâ€™ : figures sans dÃ©cisions explicites.",
            "Oublier de donner les dates exactes de split/rolling â†’ non reproductible.",
            "PrÃ©senter la spÃ©cification SARIMA de maniÃ¨re ambiguÃ« ou incomplÃ¨te.",
            "Ne pas discuter les limites (ruptures, exogÃ¨nes, stabilitÃ© du rÃ©gime)."
          )
        ))
      }
      
      tags$div(class="road-card", "Ã‰tape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (trÃ¨s dÃ©taillÃ©e) â€” FR"),
                          tags$p(class="road-sub",
                                 "Navigation par slider. Chaque Ã©tape est organisÃ©e : Objectif â†’ Analyses â†’ Tests â†’ CritÃ¨res â†’ Sorties â†’ Checklist â†’ Papier â†’ Conclusion APA â†’ PiÃ¨ges."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Ã‰tape (slider â€” pas besoin de scroll)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  
  
  
  
  
  # ==========================================================================================
  # ==========================================================================================
  
  # ============================================================
  # EXTREMELY DETAILED SARIMA ROADMAP (FR) â€” Slider + Collapsibles
  # + NEW (all steps): 
  #   Ce que les Ã©tudiants font (Checklist opÃ©rationnelle)
  #   â†’ Ce que les Ã©tudiants Ã©crivent (papier)
  #   â†’ Ce que les Ã©tudiants Ã©crivent (Conclusion â€“ format APA)
  #   (Always placed BEFORE the section: PiÃ¨ges)
  #
  # HOW TO USE
  # 1) In your UI:   uiOutput("roadmap_Detailed_Fr_ui")
  # 2) In server(): paste EVERYTHING below inside server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Fr_ui9 <- renderUI({
    
    # ----------------------------
    # Helpers: accordion building
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # level 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # level 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    P <- function(...) tags$p(...)
    
    # Student sections (required in ALL steps)
    STUDENT_DO <- function(..., open = FALSE) {
      items <- list(...)
      D(
        "Ce que les Ã©tudiants font (Checklist opÃ©rationnelle)",
        tags$ol(lapply(items, function(x) tags$li(x))),
        open = open
      )
    }
    
    STUDENT_WRITE_PAPER <- function(..., open = FALSE) {
      # Accept multiple paragraphs / bullet lists
      D("Ce que les Ã©tudiants Ã©crivent (papier)", ..., open = open)
    }
    
    STUDENT_WRITE_APA <- function(apa_text, meaning_text = NULL, open = FALSE) {
      D(
        "Ce que les Ã©tudiants Ã©crivent (Conclusion â€“ format APA)",
        P(tags$b("Conclusion (APA). "), "Â« ", apa_text, " Â»"),
        if (!is.null(meaning_text)) P(tags$b("Sens (ce que cela veut dire) : "), meaning_text) else NULL,
        open = open
      )
    }
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
                     notes = NULL, how_to_apply = NULL, what_to_write = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("DÃ©finition : "), definition),
                 if (!is.null(purpose))       P(tags$b("But / utilitÃ© : "), purpose) else NULL,
                 if (!is.null(criteria))      P(tags$b("CritÃ¨res / indices : "), criteria) else NULL,
                 if (!is.null(how_to_apply))  P(tags$b("Comment lâ€™utiliser dans lâ€™analyse : "), how_to_apply) else NULL,
                 if (!is.null(formula))       P(tags$b("Notation / formule : "), tags$code(formula)) else NULL,
                 if (!is.null(example))       P(tags$b("Exemple : "), example) else NULL,
                 if (!is.null(what_to_write)) P(tags$b("Phrase type (Ã  Ã©crire) : "), what_to_write) else NULL,
                 if (!is.null(notes))         P(tags$b("Remarques : "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("But (trÃ¨s dÃ©taillÃ©) : "), purpose),
                 P(tags$b("Quand lâ€™utiliser : "), when_to_use),
                 P(tags$b("H0 : "), H0),
                 P(tags$b("H1 : "), H1),
                 if (!is.null(statistic))                 P(tags$b("Statistique / idÃ©e : "), statistic) else NULL,
                 if (!is.null(decision_rule))             P(tags$b("RÃ¨gle de dÃ©cision : "), decision_rule) else NULL,
                 if (!is.null(interpretation))            P(tags$b("InterprÃ©tation (sens) : "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices)) P(tags$b("Ce que Ã§a implique pour vos choix : "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                 P(tags$b("Comment le rapporter : "), reporting) else NULL,
                 if (!is.null(caveats))                   P(tags$b("Limites / piÃ¨ges : "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (accordion behavior)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-left:4px;}
    details.acc.term, details.acc.test {margin:8px 0 8px 12px;}
    .callout {border-left:5px solid #4C78A8; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-left-color:#E45756; background:#fff7f7;}
    .callout.ok {border-left-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-right:6px; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 0 6px 18px;}
    .tight ol {margin: 6px 0 6px 18px;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
    .muted {color:#555;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Step labels & badges
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] Cadrer le problÃ¨me & la validation",
        "[1] QualitÃ© des donnÃ©es & prÃ©paration (NA, frÃ©quence, outliers)",
        "[2] Exploration visuelle (tendance, saison, variance)",
        "[3] DÃ©composition (additif/multiplicatif, STL)",
        "[4] StationnaritÃ© & diffÃ©renciation (choix d, D, s) + tests",
        "[5] Baseline (naÃ¯f / auto-ARIMA) + critÃ¨res de sÃ©lection",
        "[6] Identification manuelle (ACF/PACF) + grille candidates",
        "[7] Diagnostics & comparaison finale (tests rÃ©sidus + forecasting)",
        "[8] RÃ©daction: conclusion, signification, et livrables"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Objectif", "Horizon", "Protocole", "MÃ©triques"),
        c("FrÃ©quence", "NA", "Outliers", "Transformations"),
        c("Graphiques", "SaisonnalitÃ©", "Variance", "Signal"),
        c("STL", "Additif vs multiplicatif", "Structure"),
        c("ADF/KPSS/PP", "d/D/s", "RÃ¨gles de choix"),
        c("Baseline", "AICc/BIC", "NaÃ¯f"),
        c("ACF/PACF", "Parcimonie", "Candidats"),
        c("Ljungâ€“Box", "ARCH", "NormalitÃ©", "Accuracy"),
        c("SynthÃ¨se", "Conclusion", "Sens", "Reproductible")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ----------------------------
    # Small helpers (criteria blocks)
    # ----------------------------
    criteria_block <- function(title, ..., note = NULL) {
      tags$div(class="box",
               tags$h5(title),
               if (!is.null(note)) tags$p(class="muted", note) else NULL,
               ...
      )
    }
    
    decision_rule_list <- function(...) tags$ul(...)
    
    # ------------------------------------------------------------
    # Step content
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================================================
      # STEP 0 â€” Cadrer
      # =========================================================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "dÃ©finir clairement la tÃ¢che de prÃ©vision, lâ€™horizon, les mÃ©triques et la validation, car sans ce cadrage lâ€™Ã©valuation est non reproductible et la comparaison des modÃ¨les devient fragile.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          P("On transforme un â€œproblÃ¨me vagueâ€ en un protocole clair : la variable cible, la frÃ©quence temporelle, lâ€™horizon de prÃ©vision et la rÃ¨gle dâ€™Ã©valuation. Un bon cadrage garantit que deux Ã©tudiants rÃ©solvent le mÃªme problÃ¨me et peuvent comparer leurs rÃ©sultats."),
                          tags$ul(
                            tags$li("DÃ©finir la cible ", tags$code("y_t"), " et la frÃ©quence (rÃ©gularitÃ© temporelle)."),
                            tags$li("Fixer un horizon ", tags$code("h"), " rÃ©aliste (usage mÃ©tier / dÃ©cision)."),
                            tags$li("Fixer un protocole de validation (train/test, rolling-origin) et les mÃ©triques (MAE/RMSE/...)."),
                            tags$li("DÃ©finir les benchmarks : naÃ¯f et naÃ¯f saisonnier si saison.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 â€” FrÃ©quence & saison (s)",
                                                  note = "DÃ©cision : quelle granularitÃ© et quelle pÃ©riode saisonniÃ¨re s ont un sens (calendrier + donnÃ©es) ?",
                                                  tags$ul(
                                                    tags$li("Identifier la granularitÃ© : jour / semaine / mois / etc."),
                                                    tags$li("DÃ©duire ", tags$code("s"), " (ex : mensuel 12, trimestriel 4, quotidien hebdo 7)."),
                                                    tags$li("VÃ©rifier lâ€™absence de trous/doublons (index rÃ©gulier).")
                                                  )
                                   ),
                                   criteria_block("A2 â€” Validation",
                                                  note = "DÃ©cision : comment simuler un vrai futur (sans fuite dâ€™information) ?",
                                                  tags$ul(
                                                    tags$li(tags$b("Train/Test temporel : "), "entraÃ®ner sur le passÃ©, tester sur le futur."),
                                                    tags$li(tags$b("Rolling-origin : "), "plus robuste (plusieurs origines)."),
                                                    tags$li("Taille test : idÃ©alement â‰¥ 1 saison si possible.")
                                                  )
                                   ),
                                   criteria_block("A3 â€” MÃ©triques",
                                                  note = "DÃ©cision : quelles erreurs sont les plus coÃ»teuses (unitÃ©s vs grosses erreurs) ?",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE : "), "erreur moyenne en unitÃ©s, robuste."),
                                                    tags$li(tags$b("RMSE : "), "pÃ©nalise fortement les grosses erreurs."),
                                                    tags$li(tags$b("MAPE : "), "Ã©viter si yâ‰ˆ0 ; prÃ©fÃ©rer sMAPE/MAE."),
                                                    tags$li(tags$b("sMAPE : "), "pourcentage plus stable que MAPE.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Horizon h : "), "doit correspondre au besoin rÃ©el (ex : dÃ©cision mensuelle â†’ h en mois)."),
                            tags$li(tags$b("Protocole : "), "prÃ©fÃ©rer rolling-origin si suffisamment de donnÃ©es ; sinon split temporel documentÃ©."),
                            tags$li(tags$b("MÃ©triques : "), "retenir au moins deux mÃ©triques (MAE + RMSE) pour une lecture complÃ¨te."),
                            tags$li(tags$b("Benchmark : "), "toujours comparer Ã  naÃ¯f (et naÃ¯f saisonnier si saison).")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Fiche problÃ¨me : y_t, unitÃ©, frÃ©quence, dates, n."),
                            tags$li("Validation : split/rolling, dates exactes, horizon h."),
                            tags$li("MÃ©triques + benchmarks (naÃ¯f / saisonnier).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Ã‰crire la dÃ©finition prÃ©cise de y_t (quoi, unitÃ©, source), et vÃ©rifier que la sÃ©rie est bien triÃ©e par date.",
                          "Fixer la frÃ©quence (mensuel/hebdo/quotidien) et dÃ©duire une saison s plausible.",
                          "Choisir lâ€™horizon h et expliquer Ã  quoi il sert (dÃ©cision, planification, stock, etc.).",
                          "DÃ©finir le protocole dâ€™Ã©valuation (split temporel ou rolling-origin) avec des dates explicites.",
                          "Choisir les mÃ©triques (au moins MAE + RMSE) et dÃ©finir les benchmarks (naÃ¯f + naÃ¯f saisonnier si saison)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("MÃ©thodes (DonnÃ©es & Objectif). "),
                            "DÃ©crire la sÃ©rie (y_t), la pÃ©riode couverte, la frÃ©quence, lâ€™horizon et le protocole dâ€™Ã©valuation. ",
                            "Justifier le choix des mÃ©triques et prÃ©ciser les benchmarks utilisÃ©s afin dâ€™assurer une comparaison honnÃªte des modÃ¨les."),
                          P(tags$b("Exemple (papier). "),
                            "Â« Nous modÃ©lisons la sÃ©rie (y_t) observÃ©e Ã  une frÃ©quence [..] entre [..] et [..] (n=[..]). ",
                            "Lâ€™objectif est de produire des prÃ©visions Ã  horizon (h=[..]). ",
                            "La performance est Ã©valuÃ©e via [MAE, RMSE] selon un protocole [train/test temporel ou rolling-origin]. ",
                            "Les modÃ¨les sont comparÃ©s Ã  des benchmarks [naÃ¯f, naÃ¯f saisonnier]. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Nous avons dÃ©fini une tÃ¢che de prÃ©vision univariÃ©e (y_t) Ã  frÃ©quence [..] couvrant [..] Ã  [..], ",
                            "avec un horizon (h=[..]) et un protocole dâ€™Ã©valuation temporel [split/rolling-origin] utilisant [MAE, RMSE]. ",
                            "Des benchmarks (naÃ¯f et naÃ¯f saisonnier) ont Ã©tÃ© retenus comme rÃ©fÃ©rence."
                          ),
                          meaning_text = "Cette conclusion signifie que lâ€™Ã©valuation est reproductible et comparable : tous les modÃ¨les seront jugÃ©s sur le mÃªme futur et avec la mÃªme notion dâ€™erreur."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("MÃ©langer le temps (shuffle) : fuite dâ€™information â†’ performance artificielle."),
                            tags$li("Changer h ou le split aprÃ¨s coup â†’ comparaison invalide."),
                            tags$li("MAPE avec yâ‰ˆ0 â†’ erreur explosive et trompeuse.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 1 â€” QualitÃ© / PrÃ©paration
      # =========================================================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "rendre la sÃ©rie exploitable (index rÃ©gulier, NA traitÃ©s, outliers interprÃ©tÃ©s, transformation justifiÃ©e), car SARIMA et ses diagnostics supposent une chronologie cohÃ©rente et une sÃ©rie correctement prÃ©parÃ©e.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          P("Cette Ã©tape sÃ©pare les problÃ¨mes de donnÃ©es (erreurs, trous) du signal rÃ©el (Ã©vÃ©nements). On corrige les erreurs, on documente lâ€™imputation, et on choisit une transformation uniquement si elle amÃ©liore la stabilitÃ© de la variance."),
                          tags$ul(
                            tags$li("VÃ©rifier frÃ©quence rÃ©guliÃ¨re, dates uniques, tri temporel correct."),
                            tags$li("DÃ©tecter et traiter NA (selon nature du manque)."),
                            tags$li("Identifier outliers (erreur vs Ã©vÃ©nement rÃ©el)."),
                            tags$li("DÃ©cider transformations (log/Boxâ€“Cox) si variance non constante.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 â€” RÃ©gularitÃ© temporelle",
                                                  note = "CritÃ¨re : une date attendue doit apparaÃ®tre une fois (pas 0, pas 2).",
                                                  tags$ul(
                                                    tags$li("Lister trous et doublons de dates."),
                                                    tags$li("Corriger lâ€™index (agrÃ©ger, supprimer doublons, complÃ©ter dates manquantes).")
                                                  )
                                   ),
                                   criteria_block("A2 â€” Valeurs manquantes (NA)",
                                                  note = "CritÃ¨re : distinguer trous courts vs longs, et manque alÃ©atoire vs structurel.",
                                                  tags$ul(
                                                    tags$li("Calculer %NA, et mesurer la longueur des â€˜gapsâ€™."),
                                                    tags$li("Choisir une imputation (linÃ©aire/saisonniÃ¨re) si justifiÃ©e."),
                                                    tags$li("Si gaps longs : discuter lâ€™impact et envisager alternative.")
                                                  )
                                   ),
                                   criteria_block("A3 â€” Outliers",
                                                  note = "CritÃ¨re : une valeur atypique nâ€™est pas forcÃ©ment une erreur ; vÃ©rifier le contexte.",
                                                  tags$ul(
                                                    tags$li("DÃ©tecter (IQR/z-score robuste) + inspection graphique."),
                                                    tags$li("DÃ©cider : corriger (impossible physiquement) vs conserver (Ã©vÃ©nement rÃ©el).")
                                                  )
                                   ),
                                   criteria_block("A4 â€” Transformation (log/Boxâ€“Cox)",
                                                  note = "CritÃ¨re : si variance/amplitude â†‘ avec le niveau, transformation souvent utile.",
                                                  tags$ul(
                                                    tags$li("Diagnostiquer la relation niveauâ†”variance."),
                                                    tags$li("Tester log/Boxâ€“Cox, puis re-vÃ©rifier graphiques/ACF."),
                                                    tags$li("Documenter lâ€™inversion pour lâ€™interprÃ©tation des prÃ©visions.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("DÃ©finitions (cliquables)", open = FALSE,
                          TERM(
                            "NA / valeur manquante",
                            "Une valeur manquante (NA) indique quâ€™une observation attendue nâ€™a pas Ã©tÃ© enregistrÃ©e Ã  un instant prÃ©cis. En sÃ©rie temporelle, le NA est problÃ©matique car il casse la continuitÃ© de la dÃ©pendance temporelle.",
                            purpose="Sans traitement, les NA peuvent empÃªcher lâ€™estimation ou fausser les diagnostics (ACF/PACF, tests).",
                            criteria="On analyse la structure (gaps courts vs longs) et la cause (alÃ©atoire vs structurelle).",
                            how_to_apply="Compter les NA, visualiser leurs positions, dÃ©cider imputation vs agrÃ©gation vs exclusion justifiÃ©e.",
                            what_to_write="Â« Les valeurs manquantes (k=[..], [..]%) ont Ã©tÃ© traitÃ©es par [..] car [raison]. Â»"
                          ),
                          TERM(
                            "Imputation",
                            "Lâ€™imputation consiste Ã  remplacer une valeur manquante par une valeur plausible, construite Ã  partir des points voisins ou de la saisonnalitÃ©. Câ€™est une hypothÃ¨se sur le monde rÃ©el, donc elle doit Ãªtre expliquÃ©e.",
                            purpose="Maintenir une grille rÃ©guliÃ¨re et Ã©viter que le NA ne crÃ©e une rupture artificielle.",
                            criteria="Interpolation linÃ©aire pour trous trÃ¨s courts ; saisonniÃ¨re si saison forte ; prudence pour trous longs.",
                            how_to_apply="Appliquer lâ€™imputation, puis re-vÃ©rifier les graphiques (ne pas inventer de motifs).",
                            notes="Toujours justifier et discuter lâ€™impact sur lâ€™incertitude."
                          ),
                          TERM(
                            "Outlier (aberrant)",
                            "Un outlier est une observation atypique. Il peut Ãªtre une erreur de mesure ou un Ã©vÃ©nement rÃ©el. En prÃ©vision, supprimer un Ã©vÃ©nement rÃ©el peut rendre le modÃ¨le irrÃ©aliste.",
                            purpose="Ã‰viter que des valeurs extrÃªmes non expliquÃ©es ne perturbent lâ€™identification et lâ€™estimation.",
                            criteria="RÃ¨gles (IQR/z-score) + contexte (calendrier, rupture, Ã©vÃ©nement).",
                            how_to_apply="Marquer les outliers, vÃ©rifier le contexte, dÃ©cider corriger vs conserver, documenter.",
                            what_to_write="Â« Les valeurs atypiques autour de [date] ont Ã©tÃ© [conservÃ©es/ajustÃ©es] car [..]. Â»"
                          ),
                          TERM(
                            "Transformation Boxâ€“Cox",
                            "La transformation Boxâ€“Cox est une famille de transformations paramÃ©trÃ©es (Î») visant Ã  stabiliser la variance. Le log est un cas particulier (Î»â†’0).",
                            purpose="Faciliter lâ€™ajustement SARIMA en rendant la variance plus stable et la saison plus additive.",
                            criteria="Si variance/amplitude saisonniÃ¨re augmente avec le niveau, log/Boxâ€“Cox est souvent appropriÃ©.",
                            how_to_apply="Transformer, refaire EDA/ACF, estimer SARIMA, puis revenir Ã  lâ€™Ã©chelle originale pour interprÃ©ter les prÃ©visions.",
                            formula="BC(y; Î») = (y^Î» - 1)/Î» ; log(y) si Î»â†’0",
                            notes="Attention aux zÃ©ros/nÃ©gatifs : parfois un dÃ©calage est nÃ©cessaire."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Imputation : "), "acceptable si gaps courts et justification claire ; prudence si gaps longs."),
                            tags$li(tags$b("Outliers : "), "corriger si erreur Ã©vidente ; conserver si Ã©vÃ©nement rÃ©el ; documenter toujours."),
                            tags$li(tags$b("Transformation : "), "utile si variance â†‘ avec niveau ; sinon Ã©viter pour garder lâ€™interprÃ©tation simple.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("RÃ©sumÃ© NA (k, %, structure des gaps) + mÃ©thode utilisÃ©e."),
                            tags$li("Liste dâ€™outliers + dÃ©cision + justification."),
                            tags$li("Transformation retenue (ou non) + argument + inversion pour interprÃ©tation.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "ContrÃ´ler lâ€™index : dates uniques, triÃ©es, et espacÃ©es rÃ©guliÃ¨rement (sinon corriger).",
                          "Quantifier les NA : k, %, et longueurs de gaps ; dÃ©cider imputation ou alternative avec justification.",
                          "DÃ©tecter les outliers et vÃ©rifier le contexte ; dÃ©cider corriger vs conserver.",
                          "Tester log/Boxâ€“Cox si variance non constante ; re-vÃ©rifier graphiques et cohÃ©rence.",
                          "Documenter toutes les dÃ©cisions (quoi, pourquoi, impact)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("MÃ©thodes (PrÃ©paration). "),
                            "DÃ©crire la rÃ©gularisation de lâ€™index temporel, le traitement des NA, la gestion des outliers, et la transformation Ã©ventuelle. ",
                            "Lâ€™objectif est que chaque traitement soit reproductible et justifiÃ© par un critÃ¨re observable."),
                          P(tags$b("Exemple (papier). "),
                            "Â« La sÃ©rie a Ã©tÃ© vÃ©rifiÃ©e pour garantir un index rÃ©gulier (doublons supprimÃ©s/agrÃ©gation). ",
                            "Les valeurs manquantes (k=[..], [..]%) ont Ã©tÃ© traitÃ©es par [mÃ©thode], choisie car [raison]. ",
                            "Les valeurs aberrantes ont Ã©tÃ© identifiÃ©es via [rÃ¨gle] puis [conservÃ©es/ajustÃ©es] selon [contexte]. ",
                            "Une transformation [log/Boxâ€“Cox] a Ã©tÃ© [appliquÃ©e/non appliquÃ©e] car [variance]. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "AprÃ¨s vÃ©rification de la rÃ©gularitÃ© temporelle, les valeurs manquantes (k=[..], [..]%) ont Ã©tÃ© traitÃ©es par [mÃ©thode] ",
                            "et les valeurs atypiques ont Ã©tÃ© [conservÃ©es/ajustÃ©es] selon [contexte]. ",
                            "Une transformation [log/Boxâ€“Cox] a Ã©tÃ© [appliquÃ©e/non appliquÃ©e] afin de [stabiliser la variance/maintenir lâ€™interprÃ©tation]."
                          ),
                          meaning_text = "Cette conclusion signifie que la sÃ©rie est maintenant une base valide pour lâ€™EDA, les tests de stationnaritÃ© et lâ€™estimation SARIMA, avec une traÃ§abilitÃ© claire des modifications."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Imputer silencieusement : toujours expliquer la mÃ©thode et pourquoi elle est plausible."),
                            tags$li("Supprimer des outliers qui sont des Ã©vÃ©nements rÃ©els : le modÃ¨le perd lâ€™information utile."),
                            tags$li("Appliquer une transformation sans expliquer comment revenir Ã  lâ€™Ã©chelle originale.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 2 â€” Exploration visuelle
      # =========================================================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "dÃ©crire le signal (tendance, saisonnalitÃ©, variance, anomalies) et relier chaque constat Ã  une dÃ©cision (transformation, s, d, D). Les graphiques servent de preuve complÃ©mentaire aux tests.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Visualiser la sÃ©rie brute et Ã©ventuellement transformÃ©e."),
                            tags$li("DÃ©tecter tendance (long terme) et saisonnalitÃ© (pÃ©riodique)."),
                            tags$li("RepÃ©rer ruptures possibles et anomalies.")
                          )
                        ),
                        
                        D("Analyses Ã  faire", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Courbe temporelle",
                                                  note = "CritÃ¨re : tendance durable / ruptures de niveau / pÃ©riodes atypiques.",
                                                  tags$ul(
                                                    tags$li("Tracer y_t (et log/BC(y) si pertinent)."),
                                                    tags$li("Annoter pÃ©riodes anormales (chocs, Ã©vÃ©nements).")
                                                  )
                                   ),
                                   criteria_block("A2 â€” SaisonnalitÃ©",
                                                  note = "CritÃ¨re : motif rÃ©pÃ©titif stable et/ou pics ACF Ã  s,2s,3s.",
                                                  tags$ul(
                                                    tags$li("Seasonal plot (lignes par annÃ©e si mensuel)."),
                                                    tags$li("Boxplots par mois/trimestre/semaine."),
                                                    tags$li("ACF : pics aux multiples de s.")
                                                  )
                                   ),
                                   criteria_block("A3 â€” Variance",
                                                  note = "CritÃ¨re : amplitude des fluctuations augmente avec le niveau â†’ transformation.",
                                                  tags$ul(
                                                    tags$li("Comparer la variabilitÃ© selon le niveau moyen."),
                                                    tags$li("DÃ©cider log/Boxâ€“Cox si nÃ©cessaire.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("SaisonnalitÃ© : "),
                                    "motifs rÃ©pÃ©tÃ©s + pics ACF aux multiples de s â†’ s confirmÃ© ; Ã©ventuellement D=1 si saison persistante."),
                            tags$li(tags$b("Tendance : "),
                                    "dÃ©rive durable + ACF qui dÃ©croÃ®t lentement â†’ d=1 plausible."),
                            tags$li(tags$b("Variance : "),
                                    "effet Ã©ventail â†’ log/Boxâ€“Cox.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Paragraphe EDA : ce qui est observÃ© + ce que cela implique."),
                            tags$li("HypothÃ¨ses : s plausible, besoin de transformation, besoin de d et/ou D.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Tracer la courbe y_t et, si pertinent, la version transformÃ©e (log/Boxâ€“Cox).",
                          "Produire un seasonal plot et/ou boxplots par saison (mois, semaine, trimestre).",
                          "Tracer lâ€™ACF de la sÃ©rie (et noter les pics Ã  s,2s,3s).",
                          "Identifier tendance, saison, variance non constante, anomalies et ruptures potentielles.",
                          "Ã‰crire explicitement â€˜Observation â†’ Implicationâ€™ (ex : variance â†‘ â†’ log)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("RÃ©sultats (EDA). "),
                            "DÃ©crire la tendance, la saisonnalitÃ© et la variance, en vous appuyant sur des graphiques. ",
                            "Chaque constat doit mener Ã  une dÃ©cision prÃ©paratoire (transformation, s, d, D)."),
                          P(tags$b("Exemple (papier). "),
                            "Â« La sÃ©rie (y_t) prÃ©sente une tendance [..] et une saisonnalitÃ© de pÃ©riode (s=[..]). ",
                            "Lâ€™amplitude des fluctuations semble [constante/augmenter avec le niveau], suggÃ©rant [aucune transformation / une transformation log/Boxâ€“Cox]. ",
                            "Des valeurs atypiques apparaissent autour de [..] et sont [interprÃ©tÃ©es comme Ã©vÃ©nement/corrigÃ©es]. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Lâ€™exploration visuelle a indiquÃ© une tendance [..] et une saisonnalitÃ© rÃ©currente de pÃ©riode (s=[..]). ",
                            "La variabilitÃ© Ã©tait [stable/croissante avec le niveau], conduisant Ã  [aucune transformation/une transformation log/Boxâ€“Cox]. ",
                            "Des observations atypiques ont Ã©tÃ© identifiÃ©es autour de [..] et [conservÃ©es/ajustÃ©es] selon [justification]."
                          ),
                          meaning_text = "Cette conclusion signifie que vous avez identifiÃ© les composantes structurantes (tendance/saison/variance), ce qui guide rationnellement les choix de diffÃ©renciation et de transformation avant SARIMA."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Montrer des figures sans les commenter : la valeur pÃ©dagogique vient de lâ€™interprÃ©tation."),
                            tags$li("Confondre bruit et saisonnalitÃ© : chercher des motifs rÃ©pÃ©titifs cohÃ©rents."),
                            tags$li("Ignorer une rupture structurelle : le futur peut ne pas ressembler au passÃ©.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 3 â€” DÃ©composition
      # =========================================================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "dÃ©composer la sÃ©rie pour clarifier tendance/saison/bruit et justifier additif vs multiplicatif ; la dÃ©composition est descriptive, mais elle renforce la qualitÃ© de lâ€™argumentation avant SARIMA.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("DÃ©composer y_t en tendance, saisonnalitÃ©, reste."),
                            tags$li("Justifier additif vs multiplicatif ; considÃ©rer log comme â€˜multiplicatif â†’ additifâ€™."),
                            tags$li("Utiliser STL si saison Ã©volutive ou outliers.")
                          )
                        ),
                        
                        D("Concepts clÃ©s (cliquables)", open = FALSE,
                          TERM(
                            "DÃ©composition additive",
                            "Une dÃ©composition additive suppose que la saisonnalitÃ© sâ€™ajoute Ã  la tendance : y_t = T_t + S_t + e_t. Lâ€™amplitude saisonniÃ¨re est alors relativement constante.",
                            purpose="DÃ©crire la structure et vÃ©rifier si la saison est stable en amplitude.",
                            criteria="Amplitude saisonniÃ¨re similaire au fil du temps.",
                            how_to_apply="Comparer les oscillations saisonniÃ¨res sur diffÃ©rentes pÃ©riodes ; si elles sont similaires, lâ€™additif est plausible.",
                            formula="y_t = T_t + S_t + e_t"
                          ),
                          TERM(
                            "DÃ©composition multiplicative",
                            "Une dÃ©composition multiplicative suppose que la saison agit comme un facteur proportionnel : y_t = T_t Ã— S_t Ã— e_t. Lâ€™amplitude saisonniÃ¨re grandit avec le niveau.",
                            purpose="DÃ©crire des sÃ©ries oÃ¹ lâ€™effet saisonnier est proportionnel au niveau.",
                            criteria="Amplitude saisonniÃ¨re croissante avec le niveau.",
                            how_to_apply="Tester log(y) : si la saison devient stable aprÃ¨s log, on revient Ã  une lecture additive dans lâ€™espace log.",
                            formula="y_t = T_t Ã— S_t Ã— e_t"
                          ),
                          TERM(
                            "STL",
                            "STL est une dÃ©composition flexible (LOESS) qui permet Ã  la saisonnalitÃ© dâ€™Ã©voluer lentement et peut Ãªtre plus robuste aux outliers.",
                            purpose="Produire une lecture descriptive fiable quand la saison nâ€™est pas parfaitement stable.",
                            criteria="Saison Ã©volutive ou prÃ©sence dâ€™outliers.",
                            how_to_apply="Utiliser STL pour comprendre le signal, puis revenir aux tests/ACF pour stationnaritÃ© avant SARIMA.",
                            notes="STL â‰  preuve de stationnaritÃ© ; câ€™est un outil dâ€™analyse exploratoire."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          decision_rule_list(
                            tags$li(tags$b("Additif : "), "amplitude saisonniÃ¨re ~ constante."),
                            tags$li(tags$b("Multiplicatif : "), "amplitude saisonniÃ¨re âˆ niveau â†’ log/Boxâ€“Cox conseillÃ©."),
                            tags$li(tags$b("STL : "), "saison Ã©volutive/outliers â†’ STL pour robustesse.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Figure de dÃ©composition (classique ou STL)."),
                            tags$li("Justification Ã©crite : additif vs multiplicatif (+ transformation).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "RÃ©aliser une dÃ©composition (classique ou STL) et produire la figure (trend/season/remainder).",
                          "Comparer lâ€™amplitude saisonniÃ¨re Ã  diffÃ©rents niveaux (constante vs proportionnelle).",
                          "DÃ©cider additif vs multiplicatif ; si multiplicatif, tester log/Boxâ€“Cox.",
                          "Si saison Ã©volutive/outliers, privilÃ©gier STL et expliquer pourquoi.",
                          "Relier la dÃ©composition aux dÃ©cisions suivantes (d/D/s, transformation)."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("MÃ©thodes (DÃ©composition). "),
                            "Expliquer comment la sÃ©rie a Ã©tÃ© dÃ©composÃ©e, ce que reprÃ©sentent les composantes, et pourquoi une forme additive ou multiplicative a Ã©tÃ© privilÃ©giÃ©e."),
                          P(tags$b("Exemple (papier). "),
                            "Â« Nous avons dÃ©composÃ© la sÃ©rie en tendance, saisonnalitÃ© et reste via [mÃ©thode]. ",
                            "Lâ€™amplitude saisonniÃ¨re Ã©tant [constante/croissante avec le niveau], nous avons retenu une structure [additive/multiplicative], ",
                            "et appliquÃ© [aucune transformation/log/Boxâ€“Cox] afin de stabiliser la variance. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Une dÃ©composition [classique/STL] a permis dâ€™identifier une tendance [..] et une saisonnalitÃ© [stable/Ã©volutive]. ",
                            "Lâ€™amplitude saisonniÃ¨re Ã©tait [constante/proportionnelle au niveau], motivant une structure [additive/log-transformÃ©e]."
                          ),
                          meaning_text = "Cette conclusion signifie que la structure du signal est comprise : elle justifie les transformations et prÃ©pare une stationnarisation cohÃ©rente avant lâ€™estimation SARIMA."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Confondre dÃ©composition et modÃ©lisation : la dÃ©composition dÃ©crit, SARIMA estime et prÃ©dit."),
                            tags$li("Oublier que la stationnaritÃ© doit encore Ãªtre testÃ©e aprÃ¨s ces diagnostics."),
                            tags$li("Choisir multiplicatif sans traiter la prÃ©sence de zÃ©ros (log impossible sans ajustement).")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 4 â€” StationnaritÃ© & diffÃ©renciation + tests
      # =========================================================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "choisir d, D et s pour obtenir une sÃ©rie approximativement stationnaire. On vise une stationnaritÃ© â€˜suffisanteâ€™ avec le minimum de diffÃ©renciation afin dâ€™Ã©viter la sur-diffÃ©renciation, source dâ€™instabilitÃ©.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Fixer s (pÃ©riode saisonniÃ¨re)."),
                            tags$li("Choisir d (diff non saisonniÃ¨re) et D (diff saisonniÃ¨re)."),
                            tags$li("Justifier avec EDA + ACF/PACF + tests ADF/KPSS/PP + anti-sur-diff.")
                          )
                        ),
                        
                        D("DÃ©finitions indispensables (cliquables)", open = FALSE,
                          TERM(
                            "DiffÃ©renciation ordinaire (d)",
                            "DiffÃ©rencier consiste Ã  remplacer y_t par sa variation : âˆ‡y_t = y_t âˆ’ y_{tâˆ’1}. Cela rÃ©duit les tendances stochastiques et rend la moyenne plus stable.",
                            purpose="Rendre la sÃ©rie plus stationnaire pour que lâ€™ARMA (p,q) capture la dÃ©pendance restante.",
                            criteria="d est souvent 0 ou 1 ; d=2 est rare et doit Ãªtre dÃ©fendu.",
                            how_to_apply="Tester d=0 puis d=1, re-vÃ©rifier ACF et tests ; arrÃªter dÃ¨s que stationnaritÃ© raisonnable.",
                            formula="(1-B)^d y_t"
                          ),
                          TERM(
                            "DiffÃ©renciation saisonniÃ¨re (D)",
                            "DiffÃ©rencier saisonniÃ¨rement compare y_t Ã  y_{tâˆ’s}. Cela retire une composante saisonniÃ¨re persistante (racine unitaire saisonniÃ¨re).",
                            purpose="Stabiliser la saison avant dâ€™estimer les termes saisonniers (P,Q).",
                            criteria="D=0 ou 1 dans la plupart des cas ; D=2 est trÃ¨s rare.",
                            how_to_apply="Si pics ACF forts Ã  s et saison persistante, tester D=1, puis vÃ©rifier quâ€™on nâ€™a pas sur-diff (ACF trÃ¨s nÃ©gative Ã  s).",
                            formula="(1-B^s)^D y_t"
                          ),
                          TERM(
                            "Sur-diffÃ©renciation",
                            "La sur-diffÃ©renciation signifie retirer trop de structure (d ou D trop grand), ce qui peut crÃ©er une autocorrÃ©lation nÃ©gative artificielle et gonfler la variance.",
                            purpose="Ã‰viter instabilitÃ© et oscillations des prÃ©visions.",
                            criteria="ACF lag1 trÃ¨s nÃ©gative (sur-diff d) ou ACF lag s trÃ¨s nÃ©gative (sur-diff D).",
                            how_to_apply="RÃ©duire d/D si symptÃ´mes, puis re-tester.",
                            notes="RÃ¨gle pratique : â€˜minimum de diffÃ©renciation pour stationnariserâ€™.")
                        ),
                        
                        D("Tests (purpose + critÃ¨res dÃ©taillÃ©s)", open = FALSE,
                          TEST(
                            name="ADF â€” Augmented Dickeyâ€“Fuller (racine unitaire)",
                            purpose="DÃ©tecter si la sÃ©rie se comporte comme si elle avait une racine unitaire (non-stationnaritÃ© de type marche alÃ©atoire), en testant si le niveau passÃ© explique Î”y_t dâ€™une maniÃ¨re compatible avec une dÃ©rive persistante.",
                            when_to_use="Sur sÃ©rie brute puis sÃ©rie diffÃ©renciÃ©e, pour dÃ©cider d et valider la stationnaritÃ© obtenue.",
                            H0="Racine unitaire â†’ non-stationnaire.",
                            H1="Stationnaire (selon spÃ©cification drift/trend).",
                            statistic="RÃ©gression ADF avec retards de Î”y_t pour absorber autocorrÃ©lation.",
                            decision_rule="p<Î± (souvent 0.05) â†’ rejet H0 â†’ stationnaritÃ© plausible ; sinon â†’ d possiblement insuffisant.",
                            interpretation="Rejeter H0 suggÃ¨re que les chocs ne produisent pas une dÃ©rive permanente (retour vers un comportement stable).",
                            what_it_means_for_choices="Si ADF ne rejette pas sur la sÃ©rie brute â†’ tester d=1 (et/ou D=1 si saison). Si ADF rejette aprÃ¨s transformation â†’ passer Ã  lâ€™identification p,q,P,Q.",
                            reporting="PrÃ©ciser drift/trend, retards, p-value, conclusion sur d.",
                            caveats="SensibilitÃ© aux retards et ruptures structurelles."
                          ),
                          TEST(
                            name="KPSS â€” stationnaritÃ© comme H0",
                            purpose="ComplÃ©ter ADF en testant la stationnaritÃ© comme hypothÃ¨se nulle : on dÃ©tecte si une composante de marche alÃ©atoire rÃ©siduelle est trop grande pour Ãªtre compatible avec une sÃ©rie stationnaire.",
                            when_to_use="AprÃ¨s ADF/PP, pour trianguler la dÃ©cision et dÃ©tecter une non-stationnaritÃ© rÃ©siduelle.",
                            H0="Stationnaire (niveau ou tendance selon version).",
                            H1="Non-stationnaire.",
                            decision_rule="p<Î± â†’ rejet stationnaritÃ© ; pâ‰¥Î± â†’ compatible stationnaritÃ©.",
                            interpretation="KPSS non significatif aprÃ¨s diffÃ©renciation renforce lâ€™idÃ©e quâ€™on a bien stationnarisÃ© la sÃ©rie.",
                            what_it_means_for_choices="Si KPSS rejette aprÃ¨s d/D, reconsidÃ©rer d/D, s, ou la prÃ©sence de rupture.",
                            reporting="PrÃ©ciser version level/trend + p-value + conclusion.",
                            caveats="TrÃ¨s sensible aux ruptures; dÃ©pend du choix de variance longue."
                          ),
                          TEST(
                            name="PP â€” Phillipsâ€“Perron (racine unitaire corrigÃ©e)",
                            purpose="Tester la racine unitaire comme ADF, mais avec une correction non-paramÃ©trique de lâ€™autocorrÃ©lation et de lâ€™hÃ©tÃ©roscÃ©dasticitÃ©, rÃ©duisant la dÃ©pendance au choix des retards.",
                            when_to_use="Alternative/complÃ©ment Ã  ADF, surtout si autocorrÃ©lation/hÃ©tÃ©roscÃ©dasticitÃ© suspectÃ©e.",
                            H0="Racine unitaire â†’ non-stationnaire.",
                            H1="Stationnaire.",
                            decision_rule="p<Î± â†’ rejet racine unitaire.",
                            interpretation="Concordance ADF+PP renforce la conclusion.",
                            what_it_means_for_choices="DÃ©saccord ADF/PP â†’ vÃ©rifier drift/trend, ruptures, et sâ€™appuyer davantage sur ACF/plots.",
                            reporting="Rapporter p-value + spÃ©cification + dÃ©cision.",
                            caveats="Comme ADF : sensible aux ruptures."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision) â€” d, D, s", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("RÃ¨gle 1 â€” Triangulation ADF/KPSS/PP",
                                                  note = "DÃ©cision robuste = convergence des indices.",
                                                  tags$ul(
                                                    tags$li("ADF/PP rejettent + KPSS ne rejette pas â†’ stationnaritÃ© solide."),
                                                    tags$li("ADF/PP ne rejettent pas + KPSS rejette â†’ diffÃ©renciation nÃ©cessaire."),
                                                    tags$li("Conflit â†’ utiliser ACF/PACF + visualisation + minimal d/D.")
                                                  )
                                   ),
                                   criteria_block("RÃ¨gle 2 â€” Anti sur-diffÃ©renciation",
                                                  note = "Sur-diff = instabilitÃ© + autocorrÃ©lation nÃ©gative artificielle.",
                                                  tags$ul(
                                                    tags$li("ACF lag1 trÃ¨s nÃ©gative â†’ rÃ©duire d."),
                                                    tags$li("ACF lag s trÃ¨s nÃ©gative â†’ rÃ©duire D."),
                                                    tags$li("Si d=2 ou D=2 : re-vÃ©rifier s/donnÃ©es/ruptures.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Choix final : s, d, D + justification (tests + ACF + plots)."),
                            tags$li("Phrase de conclusion : â€˜stationnaritÃ© raisonnable obtenueâ€™ + mention anti-sur-diff.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Fixer la pÃ©riode saisonniÃ¨re s Ã  partir du calendrier, puis confirmer via ACF (pics Ã  s,2s,3s).",
                          "Tester stationnaritÃ© sur la sÃ©rie brute (ADF/PP + KPSS) et noter les conclusions.",
                          "Appliquer D=1 si saison persistante, puis re-vÃ©rifier ACF (attention ACF nÃ©gative Ã  s).",
                          "Appliquer d=1 si tendance stochastique, puis re-vÃ©rifier tests + ACF (attention ACF lag1 trÃ¨s nÃ©gative).",
                          "Retenir le couple (d,D) minimal qui rend la sÃ©rie stationnaire de faÃ§on raisonnable."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("MÃ©thodes (StationnaritÃ© & diffÃ©renciation). "),
                            "DÃ©crire les tests utilisÃ©s (ADF/KPSS/PP), expliquer pourquoi leurs hypothÃ¨ses nulles sont complÃ©mentaires, ",
                            "puis justifier les valeurs choisies de d et D. Indiquer explicitement la pÃ©riode saisonniÃ¨re s et mentionner la vÃ©rification anti-sur-diffÃ©renciation."),
                          P(tags$b("Exemple (papier). "),
                            "Â« La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e via ADF, KPSS et PP. Sur la base des rÃ©sultats combinÃ©s et des diagnostics ACF, ",
                            "nous avons retenu d=[..] et D=[..] avec une pÃ©riode saisonniÃ¨re s=[..]. ",
                            "Nous avons privilÃ©giÃ© la solution la plus parcimonieuse et vÃ©rifiÃ© lâ€™absence de sur-diffÃ©renciation. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "La stationnaritÃ© a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide des tests ADF, KPSS et PP (hypothÃ¨ses nulles complÃ©mentaires). ",
                            "En sâ€™appuyant sur ces rÃ©sultats et sur les diagnostics ACF/PACF, nous avons retenu d=[..] et D=[..] avec une pÃ©riode saisonniÃ¨re s=[..], ",
                            "tout en vÃ©rifiant lâ€™absence de sur-diffÃ©renciation."
                          ),
                          meaning_text = "Cette conclusion signifie que la sÃ©rie a Ã©tÃ© transformÃ©e en une forme adaptÃ©e Ã  un modÃ¨le ARMA (donc SARIMA), et que lâ€™on peut maintenant identifier p,q,P,Q sur une base stationnaire."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Sur-diffÃ©renciation (ACF trÃ¨s nÃ©gative) â†’ modÃ¨le instable et prÃ©visions oscillantes."),
                            tags$li("Choisir s sans sens calendrier â†’ saison artificielle."),
                            tags$li("Conflits de tests ignorÃ©s : expliquer la dÃ©cision par convergence dâ€™indices.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 5 â€” Baseline
      # =========================================================
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "construire des rÃ©fÃ©rences (naÃ¯f/naÃ¯f saisonnier) et une baseline auto-ARIMA, puis dÃ©finir une rÃ¨gle de sÃ©lection qui combine AICc/BIC, diagnostics et performance out-of-sample.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Construire benchmarks : naÃ¯f et naÃ¯f saisonnier."),
                            tags$li("Obtenir une baseline SARIMA via auto-ARIMA (AICc/BIC)."),
                            tags$li("Comparer sur la mÃªme validation et retenir une base pour lâ€™Ã©tape manuelle.")
                          )
                        ),
                        
                        D("Concepts (cliquables)", open = FALSE,
                          TERM(
                            "NaÃ¯f",
                            "Le modÃ¨le naÃ¯f suppose que le futur est identique Ã  la derniÃ¨re observation. Il constitue un benchmark minimal, souvent Ã©tonnamment compÃ©titif sur des sÃ©ries trÃ¨s persistantes.",
                            purpose="VÃ©rifier que votre modÃ¨le apporte plus quâ€™une simple persistance.",
                            criteria="Si votre modÃ¨le ne bat pas le naÃ¯f, il est rarement utile en pratique.",
                            formula="Å·_{t+h} = y_t"
                          ),
                          TERM(
                            "NaÃ¯f saisonnier",
                            "Le modÃ¨le naÃ¯f saisonnier suppose que le futur ressemble Ã  la mÃªme saison prÃ©cÃ©dente (ex : mÃªme mois lâ€™an dernier).",
                            purpose="Benchmark essentiel si la sÃ©rie est saisonniÃ¨re.",
                            criteria="Ã€ battre absolument si saisonnalitÃ© forte et stable.",
                            formula="Å·_{t+h} = y_{t+h-s}"
                          ),
                          TERM(
                            "Auto-ARIMA",
                            "Auto-ARIMA explore des ordres (p,q,P,Q) sous contraintes et choisit une spÃ©cification selon un critÃ¨re dâ€™information (souvent AICc), fournissant une baseline solide.",
                            purpose="Point de dÃ©part robuste et reproductible, pas une vÃ©ritÃ© absolue.",
                            criteria="Documenter stepwise vs exhaustive, bornes max p/q, et transformations.",
                            notes="Toujours valider hors Ã©chantillon et vÃ©rifier diagnostics."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          decision_rule_list(
                            tags$li("Garder une baseline parcimonieuse si Î”AICc < 2 entre modÃ¨les."),
                            tags$li("Exiger au minimum : performance â‰¥ benchmarks et diagnostics rÃ©siduels acceptables."),
                            tags$li("Si gain marginal : prÃ©fÃ©rer simplicitÃ© (stabilitÃ©, interprÃ©tation).")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Table : benchmarks + auto-ARIMA (AICc/BIC + MAE/RMSE test)."),
                            tags$li("Baseline retenue comme point de comparaison pour la sÃ©lection manuelle.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Calculer les erreurs (MAE/RMSE) des benchmarks (naÃ¯f, naÃ¯f saisonnier) sur la mÃªme fenÃªtre dâ€™Ã©valuation.",
                          "ExÃ©cuter auto-ARIMA avec des bornes raisonnables et documenter les paramÃ¨tres de recherche (stepwise, max p/q, etc.).",
                          "Comparer auto-ARIMA aux benchmarks (accuracy) et vÃ©rifier rapidement les diagnostics.",
                          "Choisir une baseline â€˜rÃ©fÃ©renceâ€™ (souvent celle dâ€™AICc minimal) tout en respectant la parcimonie (Î”AICc<2).",
                          "Conserver cette baseline comme base de discussion pour les candidats manuels."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("MÃ©thodes (Baseline). "),
                            "Expliquer les benchmarks utilisÃ©s, la procÃ©dure auto-ARIMA (critÃ¨re, contraintes, recherche), et la maniÃ¨re dont la baseline a Ã©tÃ© comparÃ©e en prÃ©vision."),
                          P(tags$b("Exemple (papier). "),
                            "Â« Des benchmarks naÃ¯f et naÃ¯f saisonnier ont Ã©tÃ© estimÃ©s. Une baseline SARIMA a Ã©tÃ© sÃ©lectionnÃ©e via auto-ARIMA en minimisant lâ€™AICc sous contraintes [..]. ",
                            "Les modÃ¨les ont Ã©tÃ© comparÃ©s sur [split/rolling-origin] Ã  lâ€™aide de [MAE, RMSE]. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Une baseline SARIMA a Ã©tÃ© sÃ©lectionnÃ©e via auto-ARIMA (minimisation de lâ€™AICc) et comparÃ©e aux benchmarks naÃ¯f et naÃ¯f saisonnier ",
                            "sur un protocole dâ€™Ã©valuation temporel utilisant [MAE, RMSE]. La spÃ©cification retenue a servi de point de dÃ©part pour lâ€™affinement guidÃ© par la thÃ©orie."
                          ),
                          meaning_text = "Cette conclusion signifie que vous disposez dâ€™une rÃ©fÃ©rence objective : votre sÃ©lection manuelle devra au minimum Ã©galer ou amÃ©liorer cette baseline (et battre les benchmarks)."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Prendre auto-ARIMA comme â€˜vÃ©ritÃ©â€™ sans validation out-of-sample."),
                            tags$li("Comparer des modÃ¨les sur des splits diffÃ©rents : invalide."),
                            tags$li("Choisir un modÃ¨le trÃ¨s complexe pour un gain marginal : risque dâ€™instabilitÃ©.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 6 â€” Identification manuelle (ACF/PACF)
      # =========================================================
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "proposer un petit ensemble de modÃ¨les SARIMA plausibles Ã  partir de ACF/PACF (sur sÃ©rie stationnaire), puis sÃ©lectionner par parcimonie + AICc/BIC + stabilitÃ©, avant diagnostics complets.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Tracer ACF/PACF sur la sÃ©rie (aprÃ¨s d et D)."),
                            tags$li("Proposer p,q et P,Q plausibles (petit ensemble)."),
                            tags$li("Comparer par AICc/BIC + stabilitÃ©, sans brute-force.")
                          )
                        ),
                        
                        D("Concepts (cliquables)", open = FALSE,
                          TERM("ACF",
                               "Lâ€™ACF mesure la corrÃ©lation entre y_t et y_{t-k}. Sur une sÃ©rie stationnaire, elle aide Ã  suggÃ©rer des composantes MA (q) et MA saisonniÃ¨res (Q) via des pics aux retards pertinents.",
                               purpose="SuggÃ©rer q et Q, et confirmer la saisonnalitÃ© via des pics Ã  s,2s,3s.",
                               criteria="MA(q) : ACF â€˜coupeâ€™ aprÃ¨s q ; saison : pics aux multiples de s.",
                               how_to_apply="Lire les motifs (pas un pic isolÃ©) et garder q/Q petits."),
                          TERM("PACF",
                               "La PACF mesure la corrÃ©lation partielle Ã  un retard k, en contrÃ´lant les retards plus petits. Elle suggÃ¨re des composantes AR (p) et AR saisonniÃ¨res (P).",
                               purpose="SuggÃ©rer p et P.",
                               criteria="AR(p) : PACF â€˜coupeâ€™ aprÃ¨s p ; pics Ã  s â†’ P plausible.",
                               how_to_apply="Garder p/P petits et vÃ©rifier ensuite par diagnostics.")
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("p,q (non saisonnier)",
                                                  note = "Heuristique : PACF â†’ p ; ACF â†’ q.",
                                                  tags$ul(
                                                    tags$li("Limiter p,q â‰¤ 3 sauf justification forte."),
                                                    tags$li("Si Î”AICc < 2, choisir le plus simple.")
                                                  )
                                   ),
                                   criteria_block("P,Q (saisonnier)",
                                                  note = "Heuristique : pics Ã  s dans PACF â†’ P ; dans ACF â†’ Q.",
                                                  tags$ul(
                                                    tags$li("Souvent P,Q âˆˆ {0,1}."),
                                                    tags$li("Ã‰viter de multiplier les paramÃ¨tres saisonniers inutilement.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Liste de 3â€“8 candidats SARIMA((p,d,q)(P,D,Q)[s])."),
                            tags$li("Justification ACF/PACF + tableau AICc/BIC + stabilitÃ©.")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Travailler sur la sÃ©rie stationnaire (aprÃ¨s d et D) et tracer ACF + PACF.",
                          "Noter les motifs : coupure/dÃ©croissance aux petits lags et pics aux multiples de s.",
                          "Proposer une grille courte (3â€“8 modÃ¨les) en variant p,q,P,Q autour des motifs observÃ©s.",
                          "Ajuster ces modÃ¨les et comparer AICc/BIC, en privilÃ©giant la parcimonie.",
                          "Ã‰carter les modÃ¨les instables/non inversibles, mÃªme si AICc est bon."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("MÃ©thodes (SÃ©lection guidÃ©e par la thÃ©orie). "),
                            "DÃ©crire comment ACF/PACF a Ã©tÃ© utilisÃ© pour proposer des ordres candidats, puis comment ces candidats ont Ã©tÃ© comparÃ©s et filtrÃ©s."),
                          P(tags$b("Exemple (papier). "),
                            "Â« Les structures candidates ont Ã©tÃ© proposÃ©es dâ€™aprÃ¨s ACF/PACF de la sÃ©rie diffÃ©renciÃ©e. ",
                            "Des pics aux retards [..] suggÃ©raient des composantes [AR/MA] non saisonniÃ¨res et des pics aux multiples de s suggÃ©raient des composantes saisonniÃ¨res. ",
                            "Un ensemble restreint de modÃ¨les a Ã©tÃ© ajustÃ© puis comparÃ© via AICc/BIC, en privilÃ©giant la parcimonie et la stabilitÃ©. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Sur la sÃ©rie stationnaire (aprÃ¨s diffÃ©renciation), ACF/PACF a guidÃ© la proposition dâ€™un ensemble restreint de modÃ¨les SARIMA candidats. ",
                            "Les modÃ¨les ont Ã©tÃ© comparÃ©s via [AICc/BIC] et filtrÃ©s selon la parcimonie et la stabilitÃ©, avant diagnostics rÃ©siduels approfondis."
                          ),
                          meaning_text = "Cette conclusion signifie que la sÃ©lection est raisonnÃ©e : vous limitez le risque de sur-ajustement en testant peu de modÃ¨les, mais bien motivÃ©s, avant la validation finale par les rÃ©sidus et la prÃ©vision."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Lire ACF/PACF comme des â€˜commandementsâ€™ : ce sont des heuristiques, pas des certitudes."),
                            tags$li("Tester 200 modÃ¨les au hasard : ce nâ€™est pas de la â€˜thÃ©orieâ€™."),
                            tags$li("Garder un modÃ¨le instable car AICc est plus bas : risque de mauvaises prÃ©visions.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 7 â€” Diagnostics & comparaison finale
      # =========================================================
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "valider le modÃ¨le final : (1) rÃ©sidus proches du bruit blanc (modÃ¨le adÃ©quat), (2) prÃ©vision meilleure que les benchmarks, (3) parcimonie si performances similaires.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Diagnostics rÃ©sidus : rÃ©sidus ~ bruit (ACF rÃ©sidus faible, Ljungâ€“Box non significatif)."),
                            tags$li("VÃ©rifier variance/normalitÃ© si nÃ©cessaire (selon contexte)."),
                            tags$li("Comparer accuracy out-of-sample vs baseline et benchmarks.")
                          )
                        ),
                        
                        D("Tests rÃ©sidus (cliquables)", open = FALSE,
                          TEST(
                            name="Ljungâ€“Box (autocorrÃ©lation rÃ©siduelle)",
                            purpose="Tester si les rÃ©sidus conservent une structure temporelle (autocorrÃ©lation). Si oui, le modÃ¨le nâ€™a pas capturÃ© toute la dÃ©pendance, et les prÃ©visions peuvent Ãªtre biaisÃ©es.",
                            when_to_use="Toujours aprÃ¨s estimation SARIMA, pour un lag L raisonnable (ex : 10, 2s).",
                            H0="RÃ©sidus ~ bruit blanc jusquâ€™au lag L (pas dâ€™autocorrÃ©lation).",
                            H1="AutocorrÃ©lation rÃ©siduelle.",
                            decision_rule="pâ‰¥0.05 â†’ acceptable ; p<0.05 â†’ modÃ¨le incomplet â†’ revoir p/q/P/Q/d/D.",
                            interpretation="Un rejet signifie que des motifs restent non modÃ©lisÃ©s (saison manquante, ordre insuffisant, sous/sur diffÃ©renciation).",
                            what_it_means_for_choices="Si rejet, ajuster la structure (AR/MA, saison) et recommencer. Si non rejet, passer au choix final via performance + parcimonie.",
                            reporting="Rapporter L, Q, p-value et une conclusion explicite sur le bruit blanc.",
                            caveats="SensibilitÃ© Ã  L et au n ; grands n â†’ test trÃ¨s sensible."
                          ),
                          TEST(
                            name="ARCH LM (si variance conditionnelle suspectÃ©e)",
                            purpose="DÃ©tecter si la variance des rÃ©sidus â€˜clusteriseâ€™ (volatilitÃ©). Important si vous produisez des intervalles fiables, notamment en finance.",
                            when_to_use="Si les rÃ©sidus montrent une variance variable, ou si ACF des rÃ©sidus^2 est significative.",
                            H0="Pas dâ€™ARCH (variance conditionnelle constante).",
                            H1="ARCH prÃ©sent.",
                            decision_rule="p<0.05 â†’ variance conditionnelle â†’ envisager une extension (ex : GARCH) si nÃ©cessaire."
                          )
                        ),
                        
                        D("CritÃ¨res de choix (dÃ©cision)", open = TRUE,
                          decision_rule_list(
                            tags$li("Exiger rÃ©sidus â€˜raisonnablementâ€™ blancs : Ljungâ€“Box non significatif (ou au moins pas de structure majeure)."),
                            tags$li("Exiger performance > benchmarks (naÃ¯f / naÃ¯f saisonnier)."),
                            tags$li("Si deux modÃ¨les ont des erreurs proches : choisir le plus simple.")
                          )
                        ),
                        
                        D("Sorties attendues", open = FALSE,
                          tags$ul(
                            tags$li("Figures : rÃ©sidus vs temps, ACF rÃ©sidus, QQ-plot (optionnel)."),
                            tags$li("Table : MAE/RMSE (test) + Ljungâ€“Box p-values + AICc/BIC."),
                            tags$li("DÃ©cision : modÃ¨le final SARIMA((p,d,q)(P,D,Q)[s]).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Tracer les rÃ©sidus (temps) et vÃ©rifier quâ€™ils oscillent autour de 0 sans structure visible.",
                          "Tracer lâ€™ACF des rÃ©sidus : vÃ©rifier absence de pics systÃ©matiques.",
                          "Faire Ljungâ€“Box (plusieurs L) et noter les p-values.",
                          "Ã‰valuer la prÃ©vision sur test/rolling avec MAE/RMSE ; comparer aux benchmarks et Ã  la baseline.",
                          "Choisir le modÃ¨le final : diagnostics OK + performance + parcimonie."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("RÃ©sultats (Diagnostics & performance). "),
                            "RÃ©sumer les diagnostics des rÃ©sidus (bruit blanc ou non), puis rapporter les mÃ©triques de prÃ©vision sur la fenÃªtre dâ€™Ã©valuation. ",
                            "Expliquer pourquoi le modÃ¨le final est retenu (validitÃ© + prÃ©cision + simplicitÃ©)."),
                          P(tags$b("Exemple (papier). "),
                            "Â« Les rÃ©sidus du modÃ¨le final prÃ©sentaient une dynamique compatible avec du bruit blanc : lâ€™ACF rÃ©siduelle ne montrait pas de structure majeure et le test de Ljungâ€“Box Ã©tait [non significatif] au seuil Î±=0.05. ",
                            "En prÃ©vision hors Ã©chantillon, le modÃ¨le obtenait MAE=[..] et RMSE=[..], amÃ©liorant les benchmarks [..]. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "Les diagnostics des rÃ©sidus indiquaient un comportement proche du bruit blanc (Ljungâ€“Box : p=[..] pour L=[..]). ",
                            "La performance de prÃ©vision hors Ã©chantillon Ã©tait MAE=[..] et RMSE=[..], supÃ©rieure aux benchmarks [..]. ",
                            "Le modÃ¨le retenu Ã©tait SARIMA((p,d,q)(P,D,Q)[s])."
                          ),
                          meaning_text = "Cette conclusion signifie que le modÃ¨le capture la dÃ©pendance temporelle principale (rÃ©sidus peu autocorrÃ©lÃ©s) et apporte un gain prÃ©dictif rÃ©el par rapport aux mÃ©thodes simples."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Excellent AICc mais rÃ©sidus autocorrÃ©lÃ©s : modÃ¨le inadÃ©quat malgrÃ© un bon ajustement apparent."),
                            tags$li("Sur-interprÃ©ter la normalitÃ© : lâ€™enjeu principal est lâ€™autocorrÃ©lation rÃ©siduelle."),
                            tags$li("Garder un modÃ¨le complexe pour un gain minime : risque de fragilitÃ© en production.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 8 â€” RÃ©daction / Livrables
      # =========================================================
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        
                        callout(tags$b("But : "),
                                "produire un rapport clair et reproductible : lâ€™Ã©tudiant doit relier chaque dÃ©cision (prÃ©paration, stationnaritÃ©, choix de modÃ¨le) aux preuves (figures, tests, mÃ©triques) et conclure sur le sens et les limites.",
                                type="ok"),
                        
                        D("Objectif", open = TRUE,
                          tags$ul(
                            tags$li("Assembler MÃ©thodes + RÃ©sultats alignÃ©s sur les Ã©tapes 0â€“7."),
                            tags$li("Inclure figures et tables minimales (EDA, dÃ©composition, ACF/PACF, rÃ©sidus, prÃ©visions)."),
                            tags$li("RÃ©diger une conclusion interprÃ©table (sens, limites, recommandation).")
                          )
                        ),
                        
                        D("Ã‰quation SARIMA (rappel)", open = FALSE,
                          P(tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t")),
                          P(class="small",
                            "Lecture : on stationnarise via diffÃ©renciation, puis AR/MA (saisonniers et non saisonniers) modÃ©lisent la dÃ©pendance restante."
                          )
                        ),
                        
                        D("Sorties attendues", open = TRUE,
                          tags$ul(
                            tags$li("Notebook/script reproductible (du chargement des donnÃ©es aux prÃ©visions finales)."),
                            tags$li("Rapport court : MÃ©thodes + RÃ©sultats + Discussion/Limites + Conclusion."),
                            tags$li("Annexes : tableau comparatif des modÃ¨les (AICc, MAE/RMSE, diagnostics).")
                          )
                        ),
                        
                        # --- REQUIRED student sections (BEFORE PiÃ¨ges)
                        STUDENT_DO(
                          "Ã‰crire MÃ©thodes : donnÃ©es (source, frÃ©quence), prÃ©paration (NA/outliers/transformation), stationnaritÃ© (tests), sÃ©lection (baseline + candidats), diagnostics, protocole dâ€™Ã©valuation.",
                          "Ã‰crire RÃ©sultats : EDA (constats), dÃ©composition, tests stationnaritÃ©, modÃ¨le final, diagnostics rÃ©sidus, performance out-of-sample.",
                          "InsÃ©rer figures clÃ©s : sÃ©rie, STL, ACF/PACF, rÃ©sidus + ACF rÃ©sidus, prÃ©visions + intervalles.",
                          "Construire une table de comparaison : candidats vs AICc/BIC + MAE/RMSE + Ljungâ€“Box.",
                          "Conclure : modÃ¨le retenu, ce que cela signifie, limites (ruptures, exogÃ¨nes, volatilitÃ©) et recommandations."
                        ),
                        
                        STUDENT_WRITE_PAPER(
                          P(tags$b("Structure (papier). "),
                            "Chaque sous-section doit suivre : (1) Ce quâ€™on a fait, (2) Pourquoi on lâ€™a fait, (3) Ce quâ€™on a observÃ©, (4) Conclusion locale. ",
                            "Lâ€™objectif pÃ©dagogique est de montrer un raisonnement, pas seulement des rÃ©sultats."),
                          P(tags$b("Exemple (papier). "),
                            "Â« AprÃ¨s prÃ©paration des donnÃ©es, nous avons Ã©valuÃ© la stationnaritÃ© via ADF/KPSS/PP et retenu d=[..], D=[..], s=[..]. ",
                            "Un ensemble de modÃ¨les candidats a Ã©tÃ© ajustÃ© (baseline auto-ARIMA + sÃ©lection guidÃ©e par ACF/PACF). ",
                            "Le modÃ¨le final a Ã©tÃ© choisi selon diagnostics rÃ©siduels (Ljungâ€“Box) et performance de prÃ©vision (MAE/RMSE) comparÃ©e aux benchmarks. Â»")
                        ),
                        
                        STUDENT_WRITE_APA(
                          apa_text = paste0(
                            "En synthÃ¨se, la sÃ©rie a Ã©tÃ© prÃ©parÃ©e et stationnarisÃ©e (d=[..], D=[..], s=[..]) avant lâ€™ajustement dâ€™un ensemble de modÃ¨les SARIMA candidats. ",
                            "Le modÃ¨le final, SARIMA((p,d,q)(P,D,Q)[s]), a Ã©tÃ© retenu sur la base de diagnostics rÃ©siduels satisfaisants et dâ€™une performance de prÃ©vision supÃ©rieure aux benchmarks. ",
                            "Ces rÃ©sultats suggÃ¨rent que la dynamique observÃ©e (tendance/saisonnalitÃ©) est suffisamment stable pour produire des prÃ©visions utiles Ã  horizon (h=[..]), sous rÃ©serve des limites discutÃ©es."
                          ),
                          meaning_text = "Cette conclusion signifie que vous reliez explicitement les preuves (tests, diagnostics, performance) Ã  une recommandation de modÃ¨le, tout en cadrant lâ€™utilisation (horizon, stabilitÃ© supposÃ©e, limites)."
                        ),
                        
                        D("PiÃ¨ges", open = FALSE,
                          tags$ul(
                            tags$li("Rapport sans protocole clair : impossible de reproduire lâ€™Ã©valuation."),
                            tags$li("Accumuler des figures sans interprÃ©tation : valeur pÃ©dagogique faible."),
                            tags$li("Oublier les limites (ruptures, exogÃ¨nes) : conclusion trop forte.")
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "Ã‰tape inconnue.")
    }
    
    # ----------------------------
    # Slider (no long scroll)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Feuille de route SARIMA (trÃ¨s dÃ©taillÃ©e) â€” FR"),
                          tags$p(class="road-sub",
                                 "Slider pour naviguer sans dÃ©filer. Chaque Ã©tape : Objectif â†’ Analyses â†’ CritÃ¨res â†’ Sorties â†’ ",
                                 tags$b("Ce que les Ã©tudiants font â†’ Ce quâ€™ils Ã©crivent (papier) â†’ Conclusion APA"), " â†’ PiÃ¨ges."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Ã‰tape (slider â€” pas besoin de scroll)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  
  
  # ============================================================
  # Ø®Ø§Ø±Ø·Ø© Ø·Ø±ÙŠÙ‚ SARIMA Ø´Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙØµÙŠÙ„ (ØªØ¹Ø±ÙŠØ¨) â€” Slider + Collapsibles
  # Ù…ÙˆØ³Ù‘Ø¹Ø© Ø¨Ø¬ÙÙ…Ù„ ØªÙØ³ÙŠØ±ÙŠØ© ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„ØªØ¹Ø±ÙŠÙØ§Øª + Ø®Ø·ÙˆØ§Øª Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„
  # Ù…Ù†Ø¸Ù‘Ù…Ø© ÙˆÙÙ‚: Ø§Ù„Ù‡Ø¯Ù â†’ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª â†’ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª â†’ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± â†’ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª â†’ Ø§Ù„Ù…Ø²Ø§Ù„Ù‚
  #
  # Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù…Ø§Ù„
  # 1) ÙÙŠ UI:   uiOutput("roadmap_Detailed_Fr_ui")   # ÙŠÙ…ÙƒÙ† Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø§Ø³Ù… ÙƒÙ…Ø§ Ù‡Ùˆ
  # 2) ÙÙŠ server(): Ø§Ù„ØµÙ‚ ÙƒÙ„ Ù…Ø§ Ø¨Ø§Ù„Ø£Ø³ÙÙ„ Ø¯Ø§Ø®Ù„:
  #    server <- function(input, output, session) { ... }
  # ============================================================
  
  output$roadmap_Detailed_Ar_ui3 <- renderUI({
    
    # ----------------------------
    # Helpers: Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø£ÙƒÙˆØ±Ø¯ÙŠÙˆÙ†
    # ----------------------------
    Acc <- function(title, ..., open = FALSE, class = NULL) {
      tags$details(
        class = paste("acc", class),
        open  = if (isTRUE(open)) "open" else NULL,
        tags$summary(title),
        tags$div(class = "acc-body", ...)
      )
    }
    D <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level1") # Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1
    S <- function(title, ..., open = FALSE) Acc(title, ..., open = open, class = "level2") # Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2
    
    callout <- function(..., type = c("info","ok","warn")) {
      type <- match.arg(type)
      cls <- if (type=="ok") "callout ok" else if (type=="warn") "callout warn" else "callout"
      tags$div(class = cls, ...)
    }
    
    # Ù…Ø³Ø§Ø¹Ø¯ ÙÙ‚Ø±Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¬ÙÙ…Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø±ÙŠØ­
    P <- function(...) tags$p(...)
    
    TERM <- function(term, definition,
                     purpose = NULL, criteria = NULL, example = NULL, formula = NULL,
                     notes = NULL, how_to_apply = NULL, what_to_write = NULL,
                     open = FALSE) {
      Acc(
        term,
        tags$div(class="term-box",
                 P(tags$b("Ø§Ù„ØªØ¹Ø±ÙŠÙ: "), definition),
                 if (!is.null(purpose))       P(tags$b("Ø§Ù„Ù‡Ø¯Ù / Ø§Ù„ÙØ§Ø¦Ø¯Ø©: "), purpose) else NULL,
                 if (!is.null(criteria))      P(tags$b("Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± / Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: "), criteria) else NULL,
                 if (!is.null(how_to_apply))  P(tags$b("ÙƒÙŠÙ Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: "), how_to_apply) else NULL,
                 if (!is.null(formula))       P(tags$b("Ø§Ù„ØªØ±Ù…ÙŠØ² / Ø§Ù„ØµÙŠØºØ©: "), tags$code(formula)) else NULL,
                 if (!is.null(example))       P(tags$b("Ù…Ø«Ø§Ù„: "), example) else NULL,
                 if (!is.null(what_to_write)) P(tags$b("Ø¬Ù…Ù„Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© (Ù„Ù„ØµÙŠØ§ØºØ© ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±): "), what_to_write) else NULL,
                 if (!is.null(notes))         P(tags$b("Ù…Ù„Ø§Ø­Ø¸Ø§Øª: "), notes) else NULL
        ),
        open = open,
        class = "term"
      )
    }
    
    TEST <- function(name,
                     purpose, when_to_use, H0, H1,
                     statistic = NULL,
                     decision_rule = NULL,
                     interpretation = NULL,
                     what_it_means_for_choices = NULL,
                     reporting = NULL,
                     caveats = NULL,
                     open = FALSE) {
      Acc(
        name,
        tags$div(class="test-box",
                 P(tags$b("Ø§Ù„Ù‡Ø¯Ù (Ø¨ØªÙØµÙŠÙ„ Ø´Ø¯ÙŠØ¯): "), purpose),
                 P(tags$b("Ù…ØªÙ‰ Ù†Ø³ØªØ®Ø¯Ù…Ù‡: "), when_to_use),
                 P(tags$b("H0: "), H0),
                 P(tags$b("H1: "), H1),
                 if (!is.null(statistic))                P(tags$b("Ø§Ù„Ø¥Ø­ØµØ§Ø¡ / Ø§Ù„ÙÙƒØ±Ø©: "), statistic) else NULL,
                 if (!is.null(decision_rule))            P(tags$b("Ù‚Ø§Ø¹Ø¯Ø© Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±: "), decision_rule) else NULL,
                 if (!is.null(interpretation))           P(tags$b("Ø§Ù„ØªÙØ³ÙŠØ± (Ø§Ù„Ù…Ø¹Ù†Ù‰): "), interpretation) else NULL,
                 if (!is.null(what_it_means_for_choices))P(tags$b("Ù…Ø§Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø°Ù„Ùƒ Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§ØªÙƒ: "), what_it_means_for_choices) else NULL,
                 if (!is.null(reporting))                P(tags$b("ÙƒÙŠÙ Ù†Ø¹Ø±Ø¶Ù‡ ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: "), reporting) else NULL,
                 if (!is.null(caveats))                  P(tags$b("Ø§Ù„Ø­Ø¯ÙˆØ¯ / Ø§Ù„Ù…Ø²Ø§Ù„Ù‚: "), caveats) else NULL
        ),
        open = open,
        class = "test"
      )
    }
    
    # ----------------------------
    # CSS + JS (Ø³Ù„ÙˆÙƒ Ø§Ù„Ø£ÙƒÙˆØ±Ø¯ÙŠÙˆÙ†)
    # ----------------------------
    css <- tags$style(HTML("
    .road-wrap {background:#f7f7f7; padding:14px; border-radius:10px; direction: rtl; text-align: right;}
    .road-header {display:flex; gap:12px; align-items:flex-start; flex-wrap:wrap;}
    .road-title {margin:0 0 6px 0;}
    .road-sub {margin:0; color:#444;}
    .road-card {background:#fff; border:1px solid #e7e7e7; border-radius:10px; padding:14px; margin-top:12px;}
    details.acc {background:#fff; border:1px solid #ececec; border-radius:10px; padding:10px 12px; margin:10px 0;}
    details.acc > summary {cursor:pointer; font-weight:800; outline:none;}
    details.acc .acc-body {margin-top:10px;}
    details.acc.level2 {margin-right:4px; margin-left:0;}
    details.acc.term, details.acc.test {margin:8px 12px 8px 0;}
    .callout {border-right:5px solid #4C78A8; border-left:none; background:#fafafa; padding:10px 12px; border-radius:8px; margin:10px 0;}
    .callout.warn {border-right-color:#E45756; background:#fff7f7;}
    .callout.ok {border-right-color:#72B7B2; background:#f7fffb;}
    code {background:#f2f2f2; padding:0 4px; border-radius:4px;}
    .small {font-size: 12.5px; color:#555;}
    .pill {display:inline-block; padding:2px 8px; border:1px solid #ddd; border-radius:999px; background:#fff; margin-left:6px; margin-right:0; font-size:12px;}
    .step-tag {margin-top:6px;}
    .tight p {margin: 6px 0;}
    .tight ul {margin: 6px 18px 6px 0;}
    .tight ol {margin: 6px 18px 6px 0;}
    .grid {display:flex; flex-wrap:wrap; gap:10px;}
    .box {flex: 1 1 320px; border:1px solid #eee; border-radius:10px; padding:10px;}
    .box h5 {margin:0 0 6px 0;}
    .muted {color:#555;}
  "))
    
    js <- tags$script(HTML("
    function closeSiblings(d, cls){
      const p = d.parentElement;
      if(!p) return;
      p.querySelectorAll(':scope > details.' + cls).forEach(x => { if(x !== d) x.open = false; });
    }
    document.addEventListener('toggle', function(e){
      const d = e.target;
      if(!d || d.tagName !== 'DETAILS' || !d.open) return;
      if(d.classList.contains('level1')) closeSiblings(d, 'level1');
      if(d.classList.contains('level2')) closeSiblings(d, 'level2');
      if(d.classList.contains('term'))   closeSiblings(d, 'term');
      if(d.classList.contains('test'))   closeSiblings(d, 'test');
    }, true);
  "))
    
    # ----------------------------
    # Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø®Ø·ÙˆØ§Øª + Ø§Ù„Ø´Ø§Ø±Ø§Øª
    # ----------------------------
    step_title <- function(k) {
      c(
        "[0] ØªØ£Ø·ÙŠØ± Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙˆØ§Ù„ØªØ­Ù‚Ù‚/Ø§Ù„ØªÙ‚ÙŠÙŠÙ…",
        "[1] Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ø¶ÙŠØ± (Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø§Ù„ØªÙˆØ§ØªØ±ØŒ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©)",
        "[2] Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ØµØ±ÙŠ (Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©ØŒ Ø§Ù„ØªØ¨Ø§ÙŠÙ†)",
        "[3] Ø§Ù„ØªÙÙƒÙŠÙƒ/Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ‘Ù†Ø§Øª (Ø¥Ø¶Ø§ÙÙŠ/Ø¶Ø±Ø¨ÙŠØŒ STL)",
        "[4] Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙˆØ§Ù„ØªÙØ±ÙŠÙ‚ (Ø§Ø®ØªÙŠØ§Ø± d Ùˆ D Ùˆ s) + Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª",
        "[5] Ø®Ø· Ø£Ø³Ø§Ø³ (Ø³Ø§Ø°Ø¬ / Auto-ARIMA) + Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±",
        "[6] Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ÙŠØ¯ÙˆÙŠ (ACF/PACF) + Ø´Ø¨ÙƒØ© Ù†Ù…Ø§Ø°Ø¬ Ù…Ø±Ø´Ø­Ø©",
        "[7] Ø§Ù„ØªØ´Ø®ÙŠØµ ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ + Ø§Ù„ØªÙ†Ø¨Ø¤)",
        "[8] Ø§Ù„ÙƒØªØ§Ø¨Ø©: Ø§Ù„Ø®Ù„Ø§ØµØ©ØŒ Ø§Ù„Ù…Ø¹Ù†Ù‰ØŒ ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª"
      )[k + 1]
    }
    
    step_badges <- function(k) {
      badges <- list(
        c("Ø§Ù„Ù‡Ø¯Ù", "Ø£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤", "Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", "Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø®Ø·Ø£"),
        c("Ø§Ù„ØªÙˆØ§ØªØ±", "Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©", "Ù‚ÙŠÙ… Ø´Ø§Ø°Ø©", "ØªØ­ÙˆÙŠÙ„Ø§Øª"),
        c("Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©", "Ù…ÙˆØ³Ù…ÙŠØ©", "ØªØ¨Ø§ÙŠÙ†", "Ø¥Ø´Ø§Ø±Ø©"),
        c("STL", "Ø¥Ø¶Ø§ÙÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ø¶Ø±Ø¨ÙŠ", "Ø§Ù„Ø¨Ù†ÙŠØ©"),
        c("ADF/KPSS/PP", "d/D/s", "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±"),
        c("Ø®Ø· Ø£Ø³Ø§Ø³", "AICc/BIC", "Ø³Ø§Ø°Ø¬"),
        c("ACF/PACF", "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯/Ø§Ù„Ø¨Ø³Ø§Ø·Ø©", "Ù†Ù…Ø§Ø°Ø¬ Ù…Ø±Ø´Ø­Ø©"),
        c("Ljungâ€“Box", "ARCH", "Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©", "Ø§Ù„Ø¯Ù‚Ø©"),
        c("ØªØ±ÙƒÙŠØ¨", "Ø®Ù„Ø§ØµØ©", "Ù…Ø¹Ù†Ù‰", "Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ø¥Ø¹Ø§Ø¯Ø©")
      )[[k + 1]]
      tags$div(class="step-tag", lapply(badges, function(b) tags$span(class="pill", b)))
    }
    
    # ----------------------------
    # Ù…Ø³Ø§Ø¹Ø¯Ø§Øª ØµØºÙŠØ±Ø© (ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±)
    # ----------------------------
    criteria_block <- function(title, ..., note = NULL) {
      tags$div(class="box",
               tags$h5(title),
               if (!is.null(note)) tags$p(class="muted", note) else NULL,
               ...
      )
    }
    
    decision_rule_list <- function(...) {
      tags$ul(...)
    }
    
    # ------------------------------------------------------------
    # Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ§Øª (Ù…Ù‡ÙŠÙƒÙ„ Ø¬Ø¯Ø§ + Ø¬Ù…Ù„ Ù…ÙˆØ³Ø¹Ø©)
    # ------------------------------------------------------------
    step_content <- function(k) {
      
      # =========================================================
      # STEP 0 â€” Ø§Ù„ØªØ£Ø·ÙŠØ±
      # =========================================================
      if (k == 0) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "ØªØ­Ø¯ÙŠØ¯ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ ØªÙ‚ÙŠÙŠÙ… Ù…ÙˆØ«ÙˆÙ‚ Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ØŒ Ù„Ø£Ù† Ù†Ù…ÙˆØ°Ø¬ SARIMA Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø­ÙƒÙ… Ø¹Ù„ÙŠÙ‡ Ø¨Ø¯Ù‚Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ«Ø¨ÙŠØª Ø§Ù„Ù‡Ø¯Ù ÙˆØ£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ø° Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©.",
                          type="ok"
                        ),
                        
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø§Ù„Ø¨ ØªÙ‚Ø¯ÙŠÙ… ÙˆØµÙ Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø´ÙƒÙ„Ø©: Ù…Ø§ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡ØŒ ÙˆØ¹Ù„Ù‰ Ø£ÙŠ Ø´Ø¨ÙƒØ© Ø²Ù…Ù†ÙŠØ©ØŒ ÙˆØ¨Ø£ÙŠ Ø£ÙÙ‚ØŒ ÙˆÙˆÙÙ‚ Ø£ÙŠ Ù‚Ø§Ø¹Ø¯Ø© ØªÙ‚ÙŠÙŠÙ…. Ø§Ù„ÙÙƒØ±Ø© Ø¨Ø³ÙŠØ·Ø©: Ø¥Ø°Ø§ Ø§Ø®ØªØ§Ø± Ø·Ø§Ù„Ø¨Ø§Ù† Ø¢ÙØ§Ù‚Ø§ Ø£Ùˆ ØªÙ‚Ø³ÙŠÙ…Ø§Øª ØªØ¯Ø±ÙŠØ¨/Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø®ØªÙ„ÙØ©ØŒ ÙÙ‡Ù…Ø§ Ù„Ø§ ÙŠØ¯Ø±Ø³Ø§Ù† Ù†ÙØ³ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø§ ØªØµØ¨Ø­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©."),
                          tags$ul(
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡Ø¯Ù ", tags$code("y_t"), " ÙˆØ§Ù„ØªÙˆØ§ØªØ± (Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„Ø²Ù…Ù†)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø£ÙÙ‚ ", tags$code("h"), " Ø¨Ø´ÙƒÙ„ ÙˆØ§Ù‚Ø¹ÙŠ (Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…/Ø§Ù„Ù‚Ø±Ø§Ø±)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªØ­Ù‚Ù‚ (Train/Test Ø£Ùˆ Rolling-origin) ÙˆØ§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ (MAE/RMSE/...)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Benchmarks): Ø³Ø§Ø°Ø¬ ÙˆØ³Ø§Ø°Ø¬ Ù…ÙˆØ³Ù…ÙŠ Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ù…ÙˆØ³Ù…ÙŠØ©.")
                          )
                        ),
                        
                        D("ØªØ­Ù„ÙŠÙ„Ø§Øª ÙŠØ¬Ø¨ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§", open = TRUE,
                          P("Ù‡Ù†Ø§ Ù†Ø¨Ù†ÙŠ 'Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø£Ø³ÙˆØ¯' Ù„Ù„ØªÙ‚ÙŠÙŠÙ…: Ù†ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø²Ù…Ù† Ù…Ø­ØªØ±Ù… (Ù„Ø§ Ù…Ø²Ø¬ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø§Ø¶ÙŠ ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„)ØŒ ÙˆÙ†Ø®ØªØ§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ ØªØ¹ÙƒØ³ ØªÙƒÙ„ÙØ© Ø§Ù„Ø®Ø·Ø£. Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„ Ø­Ø³Ø¨ RMSE Ù„ÙŠØ³ Ø¯Ø§Ø¦Ù…Ø§ Ø§Ù„Ø£ÙØ¶Ù„ Ø­Ø³Ø¨ MAEØŒ Ù„Ø°Ù„Ùƒ Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø§Ø¹ØªÙ…Ø§Ø¯ Ù…Ù‚ÙŠØ§Ø³ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ§ØªØ± ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© (s)",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªØ¹ÙŠØ´ Ø¹Ù„Ù‰ Ø´Ø¨ÙƒØ© Ù…Ù†ØªØ¸Ù…Ø© ÙˆØ£Ù† Ù…ÙˆØ³Ù…ÙŠØ© s Ù„Ù‡Ø§ Ù…Ø¹Ù†Ù‰ Ø­Ù‚ÙŠÙ‚ÙŠ (ØªÙ‚ÙˆÙŠÙ… + Ø¨ÙŠØ§Ù†Ø§Øª).",
                                                  tags$ul(
                                                    tags$li("ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©: ÙŠÙˆÙ…ÙŠ/Ø£Ø³Ø¨ÙˆØ¹ÙŠ/Ø´Ù‡Ø±ÙŠ/..."),
                                                    tags$li("Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…ÙˆØ³Ù… ", tags$code("s"), " (Ù…Ø«Ù„Ø§: Ø´Ù‡Ø±ÙŠ s=12ØŒ ÙØµÙ„ÙŠ s=4ØŒ ÙŠÙˆÙ…ÙŠ-Ø£Ø³Ø¨ÙˆØ¹ÙŠ s=7)."),
                                                    tags$li("Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØºÙŠØ§Ø¨ Ø§Ù„ÙØ¬ÙˆØ§Øª Ø£Ùˆ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø²Ù…Ù†ÙŠ (Ø§Ù†ØªØ¸Ø§Ù…).")
                                                  ),
                                                  P("Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙˆØ§ØªØ± ØºÙŠØ± Ù…Ù†ØªØ¸Ù…ØŒ ÙØ¥Ù† SARIMA 'ÙŠØ±Ù‰' ØªØ£Ø®ÙŠØ±Ø§Øª Ù„Ø§ ØªÙ…Ø«Ù„ Ù†ÙØ³ Ø§Ù„Ø²Ù…Ù† Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ ÙˆÙ‡Ø°Ø§ ÙŠÙØ³Ø¯ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ (ACF/PACF) ÙˆÙŠØ¬Ø¹Ù„ ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø£ØµØ¹Ø¨.")
                                   ),
                                   criteria_block("A2 â€” ØªØ­Ø¯ÙŠØ¯ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªØ­Ù‚Ù‚/Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø§Ø·Ø¹",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù„Ù‰ Ù…Ø³ØªÙ‚Ø¨Ù„ ØºÙŠØ± Ù…Ø±Ø¦ÙŠ ÙƒÙ…Ø§ ÙŠØ­Ø¯Ø« ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹.",
                                                  tags$ul(
                                                    tags$li(tags$b("Train/Test Ø²Ù…Ù†ÙŠ: "), "Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§Ø¶ÙŠ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ (ÙˆÙ„ÙŠØ³ Ø§Ù„Ø¹ÙƒØ³)."),
                                                    tags$li(tags$b("Rolling-origin: "), "Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ø¨Ø± Ø¹Ø¯Ø© Ø¨Ø¯Ø§ÙŠØ§Øª/Ø£ØµÙˆÙ„ â†’ Ø£ÙƒØ«Ø± Ù…ØªØ§Ù†Ø©."),
                                                    tags$li("ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: Ø¹Ø§Ø¯Ø© â‰¥ Ù…ÙˆØ³Ù… ÙˆØ§Ø­Ø¯ (Ù…Ø«Ù„Ø§ â‰¥ 12 Ø´Ù‡Ø±Ø§ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù‡Ø±ÙŠØ©) Ø¥Ù† Ø£Ù…ÙƒÙ†.")
                                                  ),
                                                  P("ÙŠÙˆØµÙ‰ Ø¨Ù€ Rolling-origin Ø¹Ù†Ø¯Ù…Ø§ Ù†Ø±ÙŠØ¯ ØªØ¹Ù„ÙŠÙ… Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠØ©: ÙŠØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„Ø²Ù…Ù† ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡ Ø¹Ø¯Ø© Ù…Ø±Ø§ØªØŒ Ù…Ø§ ÙŠÙ‚Ù„Ù„ Ø®Ø·Ø± 'Ø§Ù„Ø­Ø¸' ÙÙŠ ØªÙ‚Ø³ÙŠÙ… ÙˆØ§Ø­Ø¯.")
                                   ),
                                   criteria_block("A3 â€” Ø§Ø®ØªÙŠØ§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø®Ø·Ø£",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ù…ÙˆØ§Ø¡Ù…Ø© Ù‚ÙŠØ§Ø³ Ø§Ù„Ø®Ø·Ø£ Ù…Ø¹ Ù…Ø¹Ù†Ù‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø³ Ù…Ù‚Ø§Ø¨Ù„ Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©).",
                                                  tags$ul(
                                                    tags$li(tags$b("MAE: "), "Ù…ØªÙŠÙ† ÙˆØ³Ù‡Ù„ Ø§Ù„ÙÙ‡Ù… Ø¨ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø³."),
                                                    tags$li(tags$b("RMSE: "), "ÙŠØ¹Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø´Ø¯Ø©."),
                                                    tags$li(tags$b("MAPE: "), "ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª y>0 ÙˆØ¨Ø¹ÙŠØ¯Ø© Ø¹Ù† 0Ø› ÙˆØ¥Ù„Ø§ ÙŠÙØ¶Ù‘Ù„ sMAPE/MAE."),
                                                    tags$li(tags$b("sMAPE: "), "Ø¨Ø¯ÙŠÙ„ Ù†Ø³Ø¨ÙŠ Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§ Ù…Ù† MAPE.")
                                                  ),
                                                  P("ØªØ¹Ù„ÙŠÙ…ÙŠØ§: MAE ÙŠØ¬ÙŠØ¨ 'ÙƒÙ… Ø£Ø®Ø·Ø¦ ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·ØŸ' ÙˆRMSE ÙŠØ¬ÙŠØ¨ 'Ù‡Ù„ Ø£ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙØ¹Ù„Ø§ØŸ'. Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ†Ù‡Ù…Ø§ ÙŠØ¹Ø·ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø£Ø´Ù…Ù„.")
                                   )
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±)", open = TRUE,
                          P("Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ§Ù„ÙŠØ© ØªØ­ÙˆÙ„ Ø§Ù„Ø®Ø·ÙˆØ© 0 Ø¥Ù„Ù‰ Ù‚Ø±Ø§Ø±Ø§Øª Ù…Ù„Ù…ÙˆØ³Ø©. Ø¹Ù†Ø¯ ÙƒÙ„ Ù‚Ø±Ø§Ø± ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ´Ø±Ø­ Ø§Ù„Ø·Ø§Ù„Ø¨ Ù„Ù…Ø§Ø°Ø§ Ù‡Ø°Ø§ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù†Ø³Ø¬Ù… Ù…Ø¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙˆÙƒÙŠÙ Ø³ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø¨Ù‚ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©ØŒ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©ØŒ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³)."),
                          decision_rule_list(
                            tags$li(tags$b("Ø£ÙÙ‚ h: "), "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ø­Ø§Ø¬Ø©. Ù…Ø«Ø§Ù„: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚Ø±Ø§Ø± Ø´Ù‡Ø±ÙŠØ§ (Ø´Ø±Ø§Ø¡/Ù…ÙŠØ²Ø§Ù†ÙŠØ©)ØŒ ÙØ§Ù„Ø£ÙÙ‚ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙ‚Ø§Ø³ Ø¨Ø§Ù„Ø£Ø´Ù‡Ø± ÙˆØ£Ù† ÙŠØºØ·ÙŠ Ù†Ø§ÙØ°Ø© Ù‚Ø±Ø§Ø± Ù…ÙÙŠØ¯Ø©."),
                            tags$li(tags$b("Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„: "), "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©ØŒ ÙØ¶Ù‘Ù„ Rolling-origin Ù„Ø£Ù†Ù‡ ÙŠÙ‚ÙŠÙ‘Ù… Ø¹Ø¯Ø© 'Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Øª'. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚ØµÙŠØ±Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… ØªÙ‚Ø³ÙŠÙ…Ù‹Ø§ Ø²Ù…Ù†ÙŠØ§ ÙˆØ§Ø¶Ø­Ø§ ÙˆØ§Ø´Ø±Ø­Ù‡ (ØªÙˆØ§Ø±ÙŠØ® Ø¯Ù‚ÙŠÙ‚Ø©)."),
                            tags$li(tags$b("Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³: "), "Ø§Ø®ØªØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù…Ù‚ÙŠØ§Ø³ÙŠÙ† (Ù…Ø«Ù„ MAE + RMSE) Ù„ØªØ¬Ù†Ø¨ ØªØ­Ø³ÙŠÙ† Ù…ÙÙ‡ÙˆÙ… ÙˆØ§Ø­Ø¯ Ù„Ù„Ø®Ø·Ø£ ÙÙ‚Ø·."),
                            tags$li(tags$b("Benchmark: "), "Ù‚Ø§Ø±Ù† Ø¯Ø§Ø¦Ù…Ø§ Ø¨Ø³Ø§Ø°Ø¬ (ÙˆØ³Ø§Ø°Ø¬ Ù…ÙˆØ³Ù…ÙŠ Ø¥Ù† ÙˆÙØ¬Ø¯Øª Ù…ÙˆØ³Ù…ÙŠØ©). Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙÙˆÙ‚ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø§Ø°Ø¬ ÙÙ‡Ø°Ù‡ Ù†ØªÙŠØ¬Ø© Ø³Ù„Ø¨ÙŠØ© 'Ù…ÙÙŠØ¯Ø©': Ø±Ø¨Ù…Ø§ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØµØ¹Ø¨Ø© Ø£Ùˆ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù†Ø§Ù‚Øµ.")
                          )
                        ),
                        
                        D("ØªØ¹Ø±ÙŠÙØ§Øª Ø£Ø³Ø§Ø³ÙŠØ© (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)", open = FALSE,
                          TERM(
                            term="Ø³Ù„Ø³Ù„Ø© Ø²Ù…Ù†ÙŠØ© (y_t)",
                            definition="Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù‡ÙŠ ØªØ³Ù„Ø³Ù„ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ø²Ù…Ù†ØŒ Ø­ÙŠØ« ØªÙ…Ø«Ù„ ÙƒÙ„ Ù‚ÙŠÙ…Ø© y_t Ø­Ø§Ù„Ø© Ø§Ù„Ø¸Ø§Ù‡Ø±Ø© Ø¹Ù†Ø¯ Ø§Ù„Ù„Ø­Ø¸Ø© t (Ù…Ø«Ù„ Ù…Ø¨ÙŠØ¹Ø§Øª Ø´Ù‡Ø±ÙŠØ©ØŒ Ø­Ø±Ø§Ø±Ø© ÙŠÙˆÙ…ÙŠØ©ØŒ Ø£Ùˆ Ø­Ø±ÙƒØ© Ù…Ø±ÙˆØ± Ø¨Ø§Ù„Ø³Ø§Ø¹Ø©).",
                            purpose="Ù‡Ø°Ø§ Ø§Ù„ØªØ¹Ø±ÙŠÙ ÙŠØ¬Ø¨Ø±Ù†Ø§ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø§Ù„Ø°ÙŠ Ù†Ù„Ø§Ø­Ø¸Ù‡ØŒ ÙˆØ¨Ø£ÙŠ ØªÙˆØ§ØªØ±ØŒ ÙˆØ¨Ø£ÙŠ ÙˆØ­Ø¯Ø§ØªØŒ Ù„Ø£Ù† SARIMA ÙŠÙ…ÙˆØ°Ø¬ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…ØªØªØ§Ø¨Ø¹Ø©.",
                            criteria="ÙŠØ¬Ø¨ Ø£Ù† Ù†Ø¬ÙŠØ¨: Ù…Ø§ Ø§Ù„ÙˆØ­Ø¯Ø©ØŸ Ù…Ø§ Ø§Ù„ØªÙˆØ§ØªØ±ØŸ Ù…Ø§ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®ØŸ ÙˆÙ‡Ù„ ØªØ­ØªÙˆÙŠ y_t Ø¹Ù„Ù‰ Ø£ØµÙØ§Ø± Ø£Ùˆ Ù‚ÙŠÙ… Ø³Ø§Ù„Ø¨Ø© (Ù…Ù‡Ù… Ù„ØªØ­ÙˆÙŠÙ„ log/Box-Cox)ØŸ",
                            how_to_apply="Ù‚Ø¨Ù„ Ø£ÙŠ Ù†Ù…Ø°Ø¬Ø©ØŒ Ù†ØªØ­Ù‚Ù‚ Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø±ØªØ¨Ø© Ø²Ù…Ù†ÙŠØ§ØŒ Ø¨Ù„Ø§ ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®ØŒ ÙˆØ£Ù† ÙƒÙ„ Ø®Ø·ÙˆØ© Ø²Ù…Ù†ÙŠØ© Ù…ØªÙˆÙ‚Ø¹Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© (Ø£Ùˆ Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø´ÙƒÙ„ Ù…ÙˆØ«Ù‘Ù‚).",
                            what_to_write="Â« Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ø­Ù„ Ø§Ù„Ø¯Ø±Ø§Ø³Ø© y_t ÙŠÙ…Ø«Ù„ [ØªØ¹Ø±ÙŠÙ]ØŒ Ù…Ø±ØµÙˆØ¯Ø§ Ø¨ØªÙˆØ§ØªØ± [..] Ø¨ÙŠÙ† [Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©] Ùˆ[Ø§Ù„Ù†Ù‡Ø§ÙŠØ©]. Â»"
                          ),
                          TERM(
                            term="Ø£ÙÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤ (h)",
                            definition="Ø£ÙÙ‚ h Ù‡Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡Ø§. Ù…Ø«Ù„Ø§ØŒ h=12 ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù‡Ø±ÙŠØ© ÙŠØ¹Ù†ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø´Ù‡Ø± Ø§Ù„Ù€12 Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.",
                            purpose="Ø§Ù„Ø£ÙÙ‚ ÙŠØ­Ø¯Ø¯ ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ù…Ù‡Ù…Ø©: ÙƒÙ„Ù…Ø§ ÙƒØ¨Ø± h Ø²Ø§Ø¯Øª Ø§Ù„Ù„Ø§ÙŠÙ‚ÙŠÙ†ÙŠØ©ØŒ ÙˆØµØ§Ø± Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø§ØªØ¬Ø§Ù‡/Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ©.",
                            criteria="ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† h Ù…Ù†Ø³Ø¬Ù…Ø§ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ Ù„Ù‚Ø±Ø§Ø± Ø³Ù†ÙˆÙŠ ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØŒ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€24 Ø´Ù‡Ø±Ø§ Ù…Ø¹ 30 Ø´Ù‡Ø±Ø§ ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆÙ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±.",
                            how_to_apply="Ù†Ø«Ø¨Øª h Ù‚Ø¨Ù„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ Ù„Ø£Ù† ØªØºÙŠÙŠØ± h ÙŠØºÙŠÙ‘Ø± Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù…ØªØ§Ø²Ø§ Ù‚ØµÙŠØ± Ø§Ù„Ø£Ø¬Ù„ ÙˆÙ…ØªÙˆØ³Ø·Ø§ Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¬Ù„).",
                            formula="h"
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          P("Ø¨Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ© 0 ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ³ØªØ·ÙŠØ¹ Ø§Ù„Ø·Ø§Ù„Ø¨ ØªÙ‚Ø¯ÙŠÙ… 'Ø¨Ø·Ø§Ù‚Ø© Ù…Ø´ÙƒÙ„Ø©' ÙƒØ§Ù…Ù„Ø©: Ø¥Ø°Ø§ Ø£Ø¹Ø§Ø¯ Ø´Ø®Øµ Ø¢Ø®Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…."),
                          tags$ul(
                            tags$li("ÙˆØµÙ ÙƒØ§Ù…Ù„ Ù„Ù€ y_t (ØªØ¹Ø±ÙŠÙØŒ ÙˆØ­Ø¯Ø©ØŒ ØªÙˆØ§ØªØ±ØŒ ØªÙˆØ§Ø±ÙŠØ®)."),
                            tags$li("h + Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ (split/rolling) + Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ + Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©."),
                            tags$li("Ù‚ÙˆØ§Ø¹Ø¯ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ø¥Ø¹Ø§Ø¯Ø© (seed Ø¥Ù† ÙˆØ¬Ø¯Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©ØŒ ÙˆØªÙˆØ§Ø±ÙŠØ® split Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©).")
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø²Ø§Ù„Ù‚", open = FALSE,
                          tags$ul(
                            tags$li("Ø®Ù„Ø· Ø§Ù„Ø²Ù…Ù† (shuffle): ØªØ³Ø±Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª â†’ Ù†ØªØ§Ø¦Ø¬ Ù…Ø±ØªÙØ¹Ø© Ø¨Ø´ÙƒÙ„ Ù…ØµØ·Ù†Ø¹."),
                            tags$li("Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ø¨ØªÙ‚Ø³ÙŠÙ…Ø§Øª Ù…Ø®ØªÙ„ÙØ© â†’ Ù…Ù‚Ø§Ø±Ù†Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©."),
                            tags$li("Ø§Ø³ØªØ®Ø¯Ø§Ù… MAPE Ø¹Ù†Ø¯Ù…Ø§ yâ‰ˆ0: Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù†Ø³Ø¨ÙŠ ÙŠÙ†ÙØ¬Ø± ÙˆÙŠÙ‡ÙŠÙ…Ù† Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚ÙŠÙŠÙ….")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 1 â€” Ø§Ù„Ø¬ÙˆØ¯Ø©/Ø§Ù„ØªØ­Ø¶ÙŠØ±
      # =========================================================
      if (k == 1) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… (Ø´Ø¨ÙƒØ© Ù…Ù†ØªØ¸Ù…Ø©ØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ ÙÙ‡Ù… Ø§Ù„Ø´Ø°ÙˆØ°Ø§Øª) ÙˆØ§Ù„Ø£Ù‡Ù… ØªÙˆØ«ÙŠÙ‚ ÙƒÙ„ ØªØ­ÙˆÙŠÙ„ØŒ Ù„Ø£Ù† 'ØªØµØ­ÙŠØ­Ù‹Ø§ ØµØºÙŠØ±Ù‹Ø§' ØºÙŠØ± Ù…ÙØ³Ø± Ù‚Ø¯ ÙŠØºÙŠÙ‘Ø± ØªÙ…Ø§Ù…Ø§ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©ØŒ ACF/PACF) ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ù…ÙˆØ§ØµÙØ© SARIMA.",
                          type="ok"
                        ),
                        
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("Ø§Ù„Ù‡Ø¯Ù Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ù‡Ùˆ Ø£Ù† ÙŠÙ…ÙŠØ² Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨ÙŠÙ† Ù…Ø´ÙƒÙ„Ø© Ø¨ÙŠØ§Ù†Ø§Øª (ÙÙ‡Ø±Ø³ØŒ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø®Ø·Ø£ Ø¥Ø¯Ø®Ø§Ù„) ÙˆØ¨ÙŠÙ† Ø¸Ø§Ù‡Ø±Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ø­Ø¯Ø«ØŒ Ø¹Ø±Ø¶ ØªØ±ÙˆÙŠØ¬ÙŠØŒ Ø£Ø²Ù…Ø©). ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¹Ù„Ù… SARIMA Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ø³Ù„Ø³Ù„Ø©: Ù†ØµØ­Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù„ÙƒÙ† Ù„Ø§ Ù†Ù…Ø­Ùˆ Ø§Ù„ØªØ§Ø±ÙŠØ®."),
                          tags$ul(
                            tags$li("Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„ØªÙˆØ§ØªØ±ØŒ ÙØ±ÙŠØ¯Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®ØŒ ÙˆØµØ­Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø²Ù…Ù†ÙŠ."),
                            tags$li("ÙƒØ´Ù ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© NA (Ø­Ø³Ø¨ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„ØºÙŠØ§Ø¨)."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (Ø®Ø·Ø£ Ø£Ù… Ø­Ø¯Ø« Ø­Ù‚ÙŠÙ‚ÙŠ)."),
                            tags$li("Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª (log/Boxâ€“Cox) Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ† ØºÙŠØ± Ø«Ø§Ø¨Øª.")
                          )
                        ),
                        
                        D("ØªØ­Ù„ÙŠÙ„Ø§Øª ÙŠØ¬Ø¨ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§", open = TRUE,
                          P("Ù†ØªØ¨Ø¹ Ù…Ù†Ø·Ù‚Ù‹Ø§ Ø¨Ø£Ø±Ø¨Ø¹Ø© ÙØ­ÙˆØµ: (1) Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø²Ù…Ù†ÙŠØ©ØŒ (2) Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ (3) Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©ØŒ (4) ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³. ÙƒÙ„ ÙØ­Øµ ÙŠÙ‚ÙˆØ¯ Ø¥Ù„Ù‰ Ù‚Ø±Ø§Ø±ØŒ ÙˆÙƒÙ„ Ù‚Ø±Ø§Ø± ÙŠØ¬Ø¨ ØªØ¨Ø±ÙŠØ±Ù‡ Ø¨Ù…Ø¹ÙŠØ§Ø± (ÙˆÙ„ÙŠØ³ 'Ø§Ø¹ØªØ¨Ø§Ø·Ø§')."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Ø§Ù„Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„Ø²Ù…Ù†ÙŠ",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† 'Ø®Ø·ÙˆØ© Ø²Ù…Ù†ÙŠØ© ÙˆØ§Ø­Ø¯Ø©' ØªØ¹Ù†ÙŠ Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ Ø¹Ø¨Ø± Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙƒÙ„Ù‡Ø§.",
                                                  tags$ul(
                                                    tags$li("Ø§Ù„ØªØ­Ù‚Ù‚ Ø£Ù† ÙƒÙ„ ØªØ§Ø±ÙŠØ® Ù…ØªÙˆÙ‚Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·."),
                                                    tags$li("Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø«Ø¨Ø§Øª Ø§Ù„ÙØ§ØµÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ (Ù„Ø§ Ù„Ø¹Ø¯Ù… Ø§Ù„Ø§Ù†ØªØ¸Ø§Ù…).")
                                                  ),
                                                  P("Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙÙ‡Ø±Ø³ ØºÙŠØ± Ù…Ù†ØªØ¸Ù… Ù‚Ø¯ ØªÙˆÙ„Ø¯ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø°Ø§ØªÙŠØ© ÙƒØ§Ø°Ø¨Ø© (ØªØ£Ø®Ø± 1 Ù„Ø§ ÙŠÙ…Ø«Ù„ Ù†ÙØ³ Ø§Ù„ÙØªØ±Ø© Ø¯Ø§Ø¦Ù…Ø§). SARIMA ÙŠØ­ØªØ§Ø¬ Ù‚Ø§Ø¹Ø¯Ø© Ø²Ù…Ù†ÙŠØ© Ù†Ø¸ÙŠÙØ©.")
                                   ),
                                   criteria_block("A2 â€” Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (NA)",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: ÙÙ‡Ù… Ø¨Ù†ÙŠØ© Ø§Ù„ØºÙŠØ§Ø¨ Ù‚Ø¨Ù„ Ø£ÙŠ ØªØ¹ÙˆÙŠØ¶.",
                                                  tags$ul(
                                                    tags$li("Ù‚ÙŠØ§Ø³ %NA ÙˆØ·ÙˆÙ„ Ø³Ù„Ø§Ø³Ù„ Ø§Ù„ØºÙŠØ§Ø¨ (Ø§Ù„ÙØ¬ÙˆØ§Øª)."),
                                                    tags$li("ÙˆØµÙ Ù‡Ù„ Ø§Ù„ØºÙŠØ§Ø¨ Ø¨Ù†ÙŠÙˆÙŠ (Ø¹Ø·Ù„/Ø¹Ø·Ù„Ø©/Ø¥ØºÙ„Ø§Ù‚)."),
                                                    tags$li("Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© ØªØ¹ÙˆÙŠØ¶ Ù…Ø¨Ø±Ø±Ø©.")
                                                  ),
                                                  P("Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ù…Ù†ÙØ±Ø¯Ø© Ù„ÙŠØ³Øª Ù…Ø«Ù„ Ø´Ù‡Ø± ÙƒØ§Ù…Ù„ Ù…ÙÙ‚ÙˆØ¯. ÙƒÙ„Ù…Ø§ Ø·Ø§Ù„Øª Ø§Ù„ÙØ¬ÙˆØ© Ø²Ø§Ø¯Øª 'Ø§Ø®ØªÙ„Ø§Ù‚' Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆÙŠØ¬Ø¨ Ù…Ù†Ø§Ù‚Ø´Ø© Ø£Ø«Ø± Ø°Ù„Ùƒ ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.")
                                   ),
                                   criteria_block("A3 â€” Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (Outliers)",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: ØªÙ‚Ø±ÙŠØ± Ù‡Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ø®Ø·Ø£ Ø£Ù… Ø¥Ø´Ø§Ø±Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙŠØ¬Ø¨ Ø§Ø­ØªØ±Ø§Ù…Ù‡Ø§.",
                                                  tags$ul(
                                                    tags$li("Ø§Ù„ÙƒØ´Ù (IQR / z-score Ù…ØªÙŠÙ† / ÙØ­Øµ Ø¨ØµØ±ÙŠ) + Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚."),
                                                    tags$li("Ø§Ù„Ù‚Ø±Ø§Ø±: ØªØµØ­ÙŠØ­ (Ø®Ø·Ø£) Ø£Ù… Ø§Ù„Ø¥Ø¨Ù‚Ø§Ø¡ (Ø­Ø¯Ø«).")
                                                  ),
                                                  P("Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø´Ø§Ø°Ø© Ø­Ø¯Ø«Ø§ Ø­Ù‚ÙŠÙ‚ÙŠØ§ (ØªØ±Ù‚ÙŠØ©ØŒ Ø§Ù†Ù‚Ø·Ø§Ø¹ØŒ Ø£Ø²Ù…Ø©). Ø­Ø°ÙÙ‡Ø§ ÙŠØ¹Ù†ÙŠ 'Ù„Ù… ÙŠØ­Ø¯Ø« Ø´ÙŠØ¡' ÙˆÙ‚Ø¯ ÙŠØ¬Ø¹Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ ØºÙŠØ± ÙˆØ§Ù‚Ø¹ÙŠ.")
                                   ),
                                   criteria_block("A4 â€” Ø§Ù„ØªØ­ÙˆÙŠÙ„",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ¬Ø¹Ù„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø£Ù‚Ø±Ø¨ Ø¥Ù„Ù‰ 'Ø®Ø·ÙŠØ©' Ù„Ù…Ù„Ø§Ø¡Ù…Ø© SARIMA.",
                                                  tags$ul(
                                                    tags$li("ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø¨Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Ù‡Ù„ Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙŠØ²ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŸ)."),
                                                    tags$li("ØªØ¬Ø±Ø¨Ø© log/Boxâ€“Cox Ø¥Ù† Ù„Ø²Ù…."),
                                                    tags$li("ØªÙˆØ«ÙŠÙ‚ ÙƒÙŠÙÙŠØ© Ø¹ÙƒØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ.")
                                                  ),
                                                  P("Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ø¹Ø© Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª ØªØ²ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ ÙÙ‚Ø¯ ÙŠØ¨Ø§Ù„Øº Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ù…Ø±ØªÙØ¹Ø©. ØºØ§Ù„Ø¨Ø§ ÙŠØ¬Ø¹Ù„ log/Boxâ€“Cox Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø£ÙƒØ«Ø± Ø¥Ø¶Ø§ÙÙŠØ© ÙˆØ§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ø£ÙƒØ«Ø± ØªØ¬Ø§Ù†Ø³Ø§.")
                                   )
                          )
                        ),
                        
                        D("ØªØ¹Ø±ÙŠÙØ§Øª (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)", open = FALSE,
                          TERM(
                            "NA / Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø©",
                            "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (NA) ØªØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙÙŠ ØªØ§Ø±ÙŠØ® Ù…ØªÙˆÙ‚Ø¹ Ù„Ù… ØªÙØ³Ø¬Ù‘ÙŽÙ„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©. ÙÙŠ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„ØºÙŠØ§Ø¨ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§ (Ø®Ø·Ø£ Ù‚ÙŠØ§Ø³) Ø£Ùˆ Ø¨Ù†ÙŠÙˆÙŠØ§ (Ø¹Ø·Ù„Ø©ØŒ Ø¥ØºÙ„Ø§Ù‚ØŒ Ø­Ø³Ø§Ø³ Ù…ØªØ¹Ø·Ù„).",
                            purpose="Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ØªÙ‚Ø·Ø¹ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø§Ù„Ø²Ù…Ù†ÙŠØ©: SARIMA ÙˆØªØ´Ø®ÙŠØµØ§Øª ACF/PACF ØªÙØªØ±Ø¶ Ø³Ù„Ø³Ù„Ø© ÙƒØ§Ù…Ù„Ø©ØŒ Ù„Ø°Ø§ Ø¥Ù…Ø§ Ù†Ø¹ÙˆØ¶ Ø£Ùˆ Ù†Ø¹Ø¯Ù‘Ù„ Ø§Ù„ØªÙˆØ§ØªØ±/Ø§Ù„ØªØ¬Ù…ÙŠØ¹.",
                            criteria="Ù„Ø§ Ù†Ù†Ø¸Ø± ÙÙ‚Ø· Ù„Ù†Ø³Ø¨Ø© NA Ø¨Ù„ Ù„Ø¨Ù†ÙŠØªÙ‡Ø§: Ø«Ù‚ÙˆØ¨ Ù‚ØµÙŠØ±Ø© (1â€“2 Ù†Ù‚Ø·Ø©) Ù…Ù‚Ø§Ø¨Ù„ Ø³Ù„Ø§Ø³Ù„ Ø·ÙˆÙŠÙ„Ø©ØŒ Ø¯ÙˆØ±ÙŠØ© Ø§Ù„ØºÙŠØ§Ø¨ØŒ ÙˆØ§Ø±ØªØ¨Ø§Ø·Ù‡ Ø¨Ø§Ù„ØªÙ‚ÙˆÙŠÙ….",
                            how_to_apply="Ø§Ø¨Ø¯Ø£ Ø¨Ø¹Ø¯Ù‘ NA Ø«Ù… Ø§Ø¹Ø±Ø¶ Ù…ÙˆØ§Ù‚Ø¹Ù‡Ø§. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙØ¬ÙˆØ§Øª Ù‚ØµÙŠØ±Ø© ÙˆÙ†Ø§Ø¯Ø±Ø© ÙØ§Ù„ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ø¨Ø³ÙŠØ· ØºØ§Ù„Ø¨Ø§ Ù…Ù‚Ø¨ÙˆÙ„. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø·ÙˆÙŠÙ„Ø© ÙÙ†Ø§Ù‚Ø´ Ø§Ù„Ø£Ø«Ø± (Ù„Ø§ÙŠÙ‚ÙŠÙ†) ÙˆÙÙƒØ± ÙÙŠ Ø¨Ø¯Ø§Ø¦Ù„ (ØªØ¬Ù…ÙŠØ¹ØŒ Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ØŒ Ù…ØµØ¯Ø± Ø¢Ø®Ø±).",
                            what_to_write="Â« Ù…Ø«Ù„Øª Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© k=[..] Ù†Ù‚Ø·Ø© ([..]%)ØŒ ÙˆØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ø¨Ù€[Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©] Ù„Ø£Ù† Ø§Ù„ÙØ¬ÙˆØ§Øª ÙƒØ§Ù†Øª [Ù‚ØµÙŠØ±Ø©/Ù†Ø§Ø¯Ø±Ø©] ÙˆÙ„Ø£Ù† Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ÙƒØ§Ù†Øª [Ø¶Ø¹ÙŠÙØ©/Ù‚ÙˆÙŠØ©]. Â»"
                          ),
                          TERM(
                            "Ø§Ù„ØªØ¹ÙˆÙŠØ¶ (Imputation)",
                            "Ø§Ù„ØªØ¹ÙˆÙŠØ¶ ÙŠØ¹Ù†ÙŠ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ù‚ÙŠÙ…Ø© Ù…Ø¹Ù‚ÙˆÙ„Ø© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø¬Ø§ÙˆØ±Ø© (Ø®Ø·ÙŠ) Ø£Ùˆ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© (Ù…ÙˆØ³Ù…ÙŠ).",
                            purpose="ÙŠØ³Ù…Ø­ Ø¨Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø´Ø¨ÙƒØ© Ù…Ù†ØªØ¸Ù…Ø© ÙˆØªØ¬Ù†Ø¨ Ø§Ù†Ù‚Ø·Ø§Ø¹ Ù…ØµØ·Ù†Ø¹ Ù‚Ø¯ ÙŠØ´ÙˆÙ‡ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙˆØ§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ø°Ø§ØªÙŠØ©.",
                            criteria="ØªØ¹ÙˆÙŠØ¶ Ø¨Ø³ÙŠØ· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙØ¬ÙˆØ§Øª Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§ ÙˆØ¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø³Ù„Ø³Ø©Ø› ØªØ¹ÙˆÙŠØ¶ Ù…ÙˆØ³Ù…ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ©Ø› Ø­Ø°Ø± Ø´Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙØ¬ÙˆØ§Øª Ø·ÙˆÙŠÙ„Ø©.",
                            how_to_apply="Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© ØªØ­ØªØ±Ù… Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø³ÙŠØ·Ø±Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ© ÙÙ„Ø§ 'ØªØ³ÙˆÙ‘Ù' Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„Ø¯Ø±Ø¬Ø© Ù…Ø­Ùˆ Ø§Ù„Ù…ÙˆØ³Ù…. Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹ÙˆÙŠØ¶ Ø£Ø¹Ø¯ ÙØ­Øµ Ø§Ù„Ø±Ø³ÙˆÙ… ÙˆACF Ù„Ù„ØªØ£ÙƒØ¯ Ø£Ù†Ùƒ Ù„Ù… ØªÙØ¯Ø®Ù„ Ù†Ù…Ø·Ø§ Ù…ØµØ·Ù†Ø¹Ø§.",
                            notes="ÙƒÙ„ ØªØ¹ÙˆÙŠØ¶ Ù‡Ùˆ ÙØ±Ø¶ÙŠØ© Ø¹Ù† Ø§Ù„ÙˆØ§Ù‚Ø¹ØŒ Ù„Ø°Ø§ ÙŠØ¬Ø¨ ØªØ¨Ø±ÙŠØ±Ù‡."
                          ),
                          TERM(
                            "Ù‚ÙŠÙ…Ø© Ø´Ø§Ø°Ø© (Outlier)",
                            "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø´Ø§Ø°Ø© Ù‡ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø© ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø³Ù„ÙˆÙƒ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù…Ø¹ØªØ§Ø¯. Ù‚Ø¯ ØªØ£ØªÙŠ Ù…Ù† Ø®Ø·Ø£ (Ø­Ø³Ø§Ø³/Ø¥Ø¯Ø®Ø§Ù„) Ø£Ùˆ Ù…Ù† Ø­Ø¯Ø« Ø­Ù‚ÙŠÙ‚ÙŠ (ØªØ±Ù‚ÙŠØ©/Ø£Ø²Ù…Ø©/Ø§Ù†Ù‚Ø·Ø§Ø¹).",
                            purpose="Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© Ù‚Ø¯ ØªØ±Ø¨Ùƒ Ø§Ù„ØªØ¹Ø±Ù (ACF/PACF) ÙˆØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ø¹Ù„Ù…Ø§ØªØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù‚Ø¯ ØªÙ…Ø«Ù„ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ø§ Ù†Ø±ÙŠØ¯ Ø£Ù† ÙŠÙ†Ø¹ÙƒØ³ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ (Ø£Ø­Ø¯Ø§Ø«).",
                            criteria="Ù‚Ø§Ø¹Ø¯Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ© (IQRØŒ z-score) ÙŠØ¬Ø¨ Ø£Ù† ØªÙØ³ØªÙƒÙ…Ù„ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ø¯Ø« Ø­Ù‚ÙŠÙ‚ÙŠØ§ ÙØºØ§Ù„Ø¨Ø§ ÙŠÙØ¶Ù„ Ø§Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø¹Ù„ÙŠÙ‡ ÙˆØªÙˆØ«ÙŠÙ‚Ù‡.",
                            how_to_apply="Ø¶Ø¹ Ø¹Ù„Ø§Ù…Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø°ÙˆØ°Ø§Øª ÙÙŠ Ø§Ù„Ø±Ø³Ù…ØŒ ÙˆØ§Ø¨Ø­Ø« Ø¹Ù† ØªÙØ³ÙŠØ±ØŒ Ø«Ù… Ù‚Ø±Ø±: ØµØ­Ø­ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© ØºÙŠØ± Ù…Ù…ÙƒÙ†Ø© ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ§ØŒ ÙˆØ¥Ù„Ø§ ÙØ£Ø¨Ù‚Ù‡Ø§. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø´Ø°ÙˆØ°Ø§Øª Ù…ØªÙƒØ±Ø±Ø© ÙˆØ¨Ù†ÙŠØ©ØŒ ÙÙƒØ± ÙÙŠ Ù†Ù…ÙˆØ°Ø¬ ØªØ¯Ø®Ù„ Ø£Ùˆ Ù…ØªØºÙŠØ±Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ© (SARIMAX).",
                            what_to_write="Â« Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ø§Ø¹ØªÙŠØ§Ø¯ÙŠØ© Ø­ÙˆÙ„ [ØªÙˆØ§Ø±ÙŠØ®] ØªÙ… [Ø§Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø¹Ù„ÙŠÙ‡Ø§/ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§] Ù„Ø£Ù† [Ø§Ù„Ø³ÙŠØ§Ù‚]. Â»"
                          ),
                          TERM(
                            "ØªØ­ÙˆÙŠÙ„ Boxâ€“Cox",
                            "ØªØ­ÙˆÙŠÙ„ Boxâ€“Cox Ù‡Ùˆ Ø¹Ø§Ø¦Ù„Ø© ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…Ø¹Ù„Ù…Ø© Ø¨Ù€(Î») Ù‡Ø¯ÙÙ‡Ø§ ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ£Ø­ÙŠØ§Ù†Ø§ ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ù…Ù† Ø´ÙƒÙ„ Ø£ÙƒØ«Ø± ØªÙ…Ø§Ø«Ù„Ø§. Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ø­Ø§Ù„Ø© Ø®Ø§ØµØ© Ø¹Ù†Ø¯Ù…Ø§ Î» ÙŠÙ‚ØªØ±Ø¨ Ù…Ù† 0.",
                            purpose="Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ²ÙŠØ¯ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ (Ø³Ù„Ø³Ù„Ø© Ø¨Ø´ÙƒÙ„ 'Ù…Ø±ÙˆØ­Ø©') ÙŠØ³Ø§Ø¹Ø¯ Boxâ€“Cox SARIMA Ø¹Ù„Ù‰ Ù†Ù…Ø°Ø¬Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§ ÙˆØ¥Ù†ØªØ§Ø¬ Ø¨ÙˆØ§Ù‚ÙŠ Ø£ÙƒØ«Ø± ØªØ¬Ø§Ù†Ø³Ø§.",
                            criteria="Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©/Ø§Ù„ØªØ¨Ø§ÙŠÙ† ØªØ²ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ ÙØºØ§Ù„Ø¨Ø§ Boxâ€“Cox/log Ù…Ù†Ø§Ø³Ø¨. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø«Ø§Ø¨ØªØ§ ÙÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„ØªØ­ÙˆÙŠÙ„ ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠ ÙˆÙŠØ¹Ù‚Ø¯ Ø§Ù„ØªÙØ³ÙŠØ±.",
                            how_to_apply="Ø·Ø¨Ù‘Ù‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø£Ø¹Ø¯ Ø§Ù„Ø±Ø³ÙˆÙ…ØŒ Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª (ACF/PACFØŒ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©). Ø£Ø®ÙŠØ±Ø§ ØªØ£ÙƒØ¯ Ø£Ù†Ùƒ ØªØ³ØªØ·ÙŠØ¹ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„ØªÙØ³ÙŠØ± Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª.",
                            formula="BC(y; Î») = (y^Î» - 1)/Î» ; log(y) Ø¥Ø°Ø§ Î»â†’0",
                            notes="Ø§Ù†ØªØ¨Ù‡ Ù„Ù„Ø£ØµÙØ§Ø±/Ø§Ù„Ø³ÙˆØ§Ù„Ø¨: Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ø²Ø§Ø­Ø© (shift)."
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±)", open = TRUE,
                          P("Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ§Ù„ÙŠØ© ØªÙ„Ø®Ù‘Øµ Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„ØªØ­Ø¶ÙŠØ±. ÙŠØ¬Ø¨ ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ ÙƒÙ‚Ø§Ø¦Ù…Ø© ØªØ­Ù‚Ù‚ ØµØºÙŠØ±Ø© Ø«Ù… ÙƒØªØ§Ø¨Ø© ØªØ¨Ø±ÙŠØ± Ù‚ØµÙŠØ± Ù„ÙƒÙ†Ù‡ ØµØ±ÙŠØ­ Ù„ÙƒÙ„ Ù…Ø¹Ø§Ù„Ø¬Ø©."),
                          decision_rule_list(
                            tags$li(tags$b("Ø§Ù„ØªØ¹ÙˆÙŠØ¶: "),
                                    "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙØ¬ÙˆØ§Øª Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§ (Ù…Ø«Ù„ 1â€“2 Ù†Ù‚Ø·Ø©) ÙˆØ§Ù„Ø³Ù„Ø³Ù„Ø© Ø³Ù„Ø³Ø© Ù†Ø³Ø¨ÙŠØ§ â†’ Ø§Ù„ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ø®Ø·ÙŠ Ù…Ù‚Ø¨ÙˆÙ„Ø› ",
                                    "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ© â†’ Ø§Ù„ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ Ø£ÙØ¶Ù„Ø› ",
                                    "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙØ¬ÙˆØ§Øª Ø·ÙˆÙŠÙ„Ø© â†’ ÙˆØ«Ù‘Ù‚ Ø¨Ù‚ÙˆØ©ØŒ ÙˆÙÙƒØ± ÙÙŠ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø£Ùˆ Ø§Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø£Ùˆ Ø·Ø±Ù‚ Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬."),
                            tags$li(tags$b("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©: "),
                                    "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØ©/Ù…Ø³ØªØ­ÙŠÙ„Ø© â†’ ØµØ­Ø­/Ø§Ø­Ø°ÙØ› ",
                                    "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø­Ø¯Ø«Ø§ Ø­Ù‚ÙŠÙ‚ÙŠØ§ â†’ Ø£Ø¨Ù‚Ù‡Ø§ ÙˆØ§Ø°ÙƒØ±Ù‡Ø§Ø› ÙˆÙ‚Ø¯ ÙŠÙ„Ø²Ù… Ù†Ù…ÙˆØ°Ø¬ ØªØ¯Ø®Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø£Ø«Ø± Ù…ØªÙƒØ±Ø±Ø§."),
                            tags$li(tags$b("Ø§Ù„ØªØ­ÙˆÙŠÙ„: "),
                                    "Ø¥Ø°Ø§ Ø²Ø§Ø¯ Ø§Ù„ØªØ¨Ø§ÙŠÙ†/Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ â†’ log/Boxâ€“CoxØ› ",
                                    "Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø«Ø§Ø¨ØªØ§ â†’ Ù„Ø§ ØªØ­ÙˆÙŠÙ„ (ØªØ¨Ø³ÙŠØ·).")
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          P("Ø¨Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ© 1 ÙŠØ¬Ø¨ Ø£Ù† Ù†Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ù‚ÙˆÙ„: 'Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù†Ø¸ÙŠÙØ©ØŒ ÙˆÙ‡Ø°Ù‡ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ØªÙŠ Ù‚Ù…Ù†Ø§ Ø¨Ù‡Ø§ØŒ ÙˆÙ‡Ø°Ù‡ Ø£Ø³Ø¨Ø§Ø¨Ù‡Ø§'. Ù‡Ø°Ø§ ÙŠØ­Ù…ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙŠØ¬Ø¹Ù„ Ø§Ù„Ø¹Ù…Ù„ ØªØ¹Ù„ÙŠÙ…ÙŠØ§ ÙˆÙ‚Ø§Ø¨Ù„Ø§ Ù„Ù„Ù†Ù‚Ø¯."),
                          tags$ul(
                            tags$li("Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: nØŒ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®ØŒ Ø§Ù„ØªÙˆØ§ØªØ±ØŒ %NAØŒ Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© NA."),
                            tags$li("Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© + Ø§Ù„Ù‚Ø±Ø§Ø± + Ø§Ù„ØªØ¨Ø±ÙŠØ±."),
                            tags$li("Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø± + Ø§Ù„ØªØ¨Ø±ÙŠØ± + ÙƒÙŠÙÙŠØ© Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ.")
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø²Ø§Ù„Ù‚", open = FALSE,
                          tags$ul(
                            tags$li("ØªØ¹ÙˆÙŠØ¶ ÙØ¬ÙˆØ§Øª Ø·ÙˆÙŠÙ„Ø© Ø¯ÙˆÙ† Ù…Ù†Ø§Ù‚Ø´Ø© â†’ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ù‡Ø´Ø© Ù„Ø£Ù† Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ù…Ø¹ÙˆØ¶Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©."),
                            tags$li("Ø­Ø°Ù Ø£Ø­Ø¯Ø§Ø« Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¹Ù„Ù‰ Ø£Ù†Ù‡Ø§ Ø´Ø°ÙˆØ°Ø§Øª â†’ ÙÙ‚Ø¯Ø§Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙŠØ¬Ø¨ Ø£Ù† ØªØ¹ÙƒØ³Ù‡Ø§ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª."),
                            tags$li("Ø§Ø³ØªØ®Ø¯Ø§Ù… log/Boxâ€“Cox Ø¯ÙˆÙ† Ø´Ø±Ø­ ÙƒÙŠÙÙŠØ© Ø¹ÙƒØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„ â†’ ØµØ¹ÙˆØ¨Ø© ØªÙØ³ÙŠØ± Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 2 â€” Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ØµØ±ÙŠ
      # =========================================================
      if (k == 2) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ÙˆØªØºÙŠØ±Ø§Øª Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª ÙˆØ§Ù„Ø´Ø°ÙˆØ°Ø§Øª Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© (ØªØ­ÙˆÙŠÙ„ØŒ ØªÙØ±ÙŠÙ‚ØŒ Ø§Ø®ØªÙŠØ§Ø± s). Ø§Ù„Ø±Ø³ÙˆÙ… Ù‡Ù†Ø§ ØªØ¹Ù…Ù„ ÙƒÙ€'Ø¯Ù„ÙŠÙ„ Ø¨ØµØ±ÙŠ' ÙŠÙƒÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©.",
                          type="ok"
                        ),
                        
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© ØªØ¹Ù„Ù… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³Ù„Ø³Ù„Ø©: Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø­Ø±ÙƒØ© Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰ (Ø§ØªØ¬Ø§Ù‡)ØŒ ÙˆÙ†Ù…Ø· ÙŠØªÙƒØ±Ø± (Ù…ÙˆØ³Ù…ÙŠØ©)ØŒ ÙˆÙ…Ù†Ø§Ø·Ù‚ ÙŠØªØºÙŠØ± ÙÙŠÙ‡Ø§ Ø§Ù„ØªØ¨Ø§ÙŠÙ†. Ù‡Ø°Ù‡ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙŠ ÙŠØ­Ø§ÙˆÙ„ SARIMA Ø§Ù„ØªÙ‚Ø§Ø·Ù‡Ø§ (Ø£Ùˆ Ø¬Ø¹Ù„Ù‡Ø§ Ù…Ø³ØªÙ‚Ø±Ø© Ø¨Ø§Ù„ØªÙØ±ÙŠÙ‚)."),
                          tags$ul(
                            tags$li("Ø¹Ø±Ø¶ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§Ù… ÙˆØ±Ø¨Ù…Ø§ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„."),
                            tags$li("ÙƒØ´Ù Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰) ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© (Ø¯ÙˆØ±ÙŠØ©)."),
                            tags$li("Ø±ØµØ¯ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø¨Ù†ÙŠÙˆÙŠ ÙˆØ§Ù„Ø´Ø°ÙˆØ°Ø§Øª.")
                          )
                        ),
                        
                        D("ØªØ­Ù„ÙŠÙ„Ø§Øª ÙŠØ¬Ø¨ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§", open = TRUE,
                          P("Ù†ÙØ¶Ù‘Ù„ Ø«Ù„Ø§Ø« Ø¹Ø§Ø¦Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø±Ø³ÙˆÙ…: (1) Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø²Ù…Ù†ØŒ (2) Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©ØŒ (3) Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ¨Ø§ÙŠÙ†. Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ Ù†Ø±Ø¨Ø· ÙƒÙ„ Ù…Ù„Ø§Ø­Ø¸Ø© Ø¨Ù‚Ø±Ø§Ø± (log/Boxâ€“CoxØŒ dØŒ DØŒ s)."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø²Ù…Ù†",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø±ØµØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§ØªØŒ Ø§Ù„ÙØªØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©ØŒ ÙˆØ­Ø¯Ø³ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                                                  tags$ul(
                                                    tags$li("Ø±Ø³Ù… y_t (ÙˆÙƒØ°Ù„Ùƒ log/BC(y) Ø¥Ø°Ø§ Ù„Ø²Ù…)."),
                                                    tags$li("ØªØ¹Ù„ÙŠÙ… Ø§Ù„ÙØªØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (ØµØ¯Ù…Ø§Øª/Ø£Ø­Ø¯Ø§Ø«).")
                                                  ),
                                                  P("Ù…Ù†Ø­Ù†Ù‰ ÙŠØ±ØªÙØ¹ Ø¨Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ù… ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„ØªÙØ±ÙŠÙ‚ ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ (d). ØªØºÙŠØ± Ù…ÙØ§Ø¬Ø¦ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ù†Ù‚Ø·Ø§Ø¹ Ø¨Ù†ÙŠÙˆÙŠ (Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ù‚Ø¯ Ù„Ø§ ÙŠØ´Ø¨Ù‡ Ø§Ù„Ù…Ø§Ø¶ÙŠ).")
                                   ),
                                   criteria_block("A2 â€” Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙˆØªÙ‚Ø¯ÙŠØ± s.",
                                                  tags$ul(
                                                    tags$li("Seasonal plot / Ø®Ø·ÙˆØ· Ù„ÙƒÙ„ Ø³Ù†Ø© (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù‡Ø±ÙŠØ©)."),
                                                    tags$li("Boxplots Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„ÙØµÙ„/Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹."),
                                                    tags$li("ACF: Ù‚Ù…Ù… Ø¹Ù†Ø¯ Ù…Ø¶Ø§Ø¹ÙØ§Øª s (Ø¥Ø´Ø§Ø±Ø© Ù‚ÙˆÙŠØ© Ù„Ù„Ù…ÙˆØ³Ù…ÙŠØ©).")
                                                  ),
                                                  P("Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø«Ø§Ø¨ØªØ© ÙŠØ¸Ù‡Ø± seasonal plot Ù†Ù…Ø·Ø§ Ù…ØªÙƒØ±Ø±Ø§. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚ÙˆÙŠØ© ÙˆÙ…Ø³ØªÙ…Ø±Ø© ÙÙ‚Ø¯ Ù†Ø­ØªØ§Ø¬ ØªÙØ±ÙŠÙ‚Ø§ Ù…ÙˆØ³Ù…ÙŠØ§ (D=1).")
                                   ),
                                   criteria_block("A3 â€” Ø§Ù„ØªØ¨Ø§ÙŠÙ†",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: ÙƒØ´Ù Ø¹Ø¯Ù… Ø«Ø¨Ø§Øª Ø§Ù„ØªØ¨Ø§ÙŠÙ† (heteroscedasticity) Ù‚Ø¨Ù„ Ø§Ù„Ù†Ù…Ø°Ø¬Ø©.",
                                                  tags$ul(
                                                    tags$li("Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªØ°Ø¨Ø°Ø¨ ÙÙŠ ÙØªØ±Ø§Øª Ø°Ø§Øª Ù…ØªÙˆØ³Ø· Ù…Ù†Ø®ÙØ¶ Ù…Ù‚Ø§Ø¨Ù„ Ù…Ø±ØªÙØ¹."),
                                                    tags$li("Ø¥Ø°Ø§ Ø²Ø§Ø¯ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ â†’ ØªØ­ÙˆÙŠÙ„.")
                                                  ),
                                                  P("Ø¹Ù†Ø¯Ù…Ø§ ØªØ²ÙŠØ¯ Ø³Ø¹Ø© Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ Ù‚Ø¯ ÙŠØ¨Ø§Ù„Øº Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠ Ø¥Ø¹Ø·Ø§Ø¡ ÙˆØ²Ù† Ù„Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ©. Ø§Ù„ØªØ­ÙˆÙŠÙ„ (log/Boxâ€“Cox) ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø®Ø·Ø£ Ø£ÙƒØ«Ø± ØªØ¬Ø§Ù†Ø³Ø§.")
                                   )
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±)", open = TRUE,
                          P("Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± ØªØ±Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¨Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù…Ø°Ø¬Ø©. ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø§Ù„Ø¨ ÙƒØªØ§Ø¨Ø© ØµØ±ÙŠØ­Ø©: 'Ø£Ù„Ø§Ø­Ø¸ XØŒ Ù„Ø°Ù„Ùƒ Ø£Ø®ØªØ§Ø± Y'."),
                          decision_rule_list(
                            tags$li(tags$b("Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©: "),
                                    "ÙˆØ¬ÙˆØ¯ Ø£Ù†Ù…Ø§Ø· Ù…ØªÙƒØ±Ø±Ø© Ùˆ/Ø£Ùˆ Ù‚Ù…Ù… ÙÙŠ ACF Ø¹Ù†Ø¯ s Ùˆ2s Ùˆ3s â†’ Ù…ÙˆØ³Ù…ÙŠØ© Ù…Ø±Ø¬Ù‘Ø­Ø©ØŒ ÙˆÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ s Ø§Ù„ØªÙ‚ÙˆÙŠÙ…."),
                            tags$li(tags$b("Ø§Ù„Ø§ØªØ¬Ø§Ù‡: "),
                                    "Ù…Ø³ØªÙˆÙ‰ Ù…ØªÙˆØ³Ø· ÙŠÙ†Ø­Ø±Ù Ø¨Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ù… ÙˆACF ÙŠØªÙ†Ø§Ù‚Øµ Ø¨Ø¨Ø·Ø¡ â†’ ØºØ§Ù„Ø¨Ø§ d>0 Ø¶Ø±ÙˆØ±ÙŠ."),
                            tags$li(tags$b("Ø¹Ø¯Ù… Ø«Ø¨Ø§Øª Ø§Ù„ØªØ¨Ø§ÙŠÙ†: "),
                                    "Ø³Ø¹Ø© Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª ØªØ²ÙŠØ¯ Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ²ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ â†’ log/Boxâ€“CoxØŒ Ø®ØµÙˆØµØ§ Ù„ØªØ­Ø³ÙŠÙ† ØªØ¬Ø§Ù†Ø³ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ.")
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          P("Ø¨Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ© 2 ÙŠØ¬Ø¨ Ø¥Ù†ØªØ§Ø¬ ÙÙ‚Ø±Ø© EDA: Ù„Ø§ ÙŠÙƒÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ØŒ Ø¨Ù„ ÙŠØ¬Ø¨ Ø´Ø±Ø­ Ù…Ø§ ØªÙ‚ÙˆÙ„Ù‡ ÙˆÙ…Ø§ Ø§Ù„Ø°ÙŠ ØªØ¹Ù†ÙŠÙ‡ Ù„Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©."),
                          tags$ul(
                            tags$li("ØªØ¹Ù„ÙŠÙ‚ EDA: Ø§ØªØ¬Ø§Ù‡/Ù…ÙˆØ³Ù…ÙŠØ©/ØªØ¨Ø§ÙŠÙ†/Ø´Ø°ÙˆØ°Ø§Øª."),
                            tags$li("ÙØ±Ø¶ÙŠØ§Øª Ø¹Ù…Ù„: s Ù…Ø­ØªÙ…Ù„ØŒ Ø­Ø§Ø¬Ø© Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø­Ø§Ø¬Ø© Ù„Ù€ d Ùˆ/Ø£Ùˆ D.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 3 â€” Ø§Ù„ØªÙÙƒÙŠÙƒ Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª
      # =========================================================
      if (k == 3) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "ÙØµÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡/Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©/Ø§Ù„Ø¶Ø¬ÙŠØ¬ ÙˆØµÙÙŠØ§ Ù„ØªÙˆØ¶ÙŠØ­ Ø¨Ù†ÙŠØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØªÙØ³ÙŠØ± Ù„Ù…Ø§Ø°Ø§ Ù†Ø®ØªØ§Ø± ØµÙŠØºØ© Ø¥Ø¶Ø§ÙÙŠØ© Ø£Ùˆ Ø¶Ø±Ø¨Ù‘ÙŠØ©. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ù„ÙŠØ³Øª 'Ø§Ù„Ù†Ù…ÙˆØ°Ø¬' Ø¨Ù„ Ø£Ø¯Ø§Ø© Ù„Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª Ø£ÙØ¶Ù„.",
                          type="ok"
                        ),
                        
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("Ø§Ù„ØªÙÙƒÙŠÙƒ Ù„ØºØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù‚ÙˆÙŠØ©: ÙŠÙˆØ¶Ø­ Ù„Ù„Ø·Ù„Ø§Ø¨ Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„ÙŠØ³Øª ÙƒØªÙ„Ø© ÙˆØ§Ø­Ø¯Ø©ØŒ Ø¨Ù„ Ø®Ù„ÙŠØ· Ù…ÙƒÙˆÙ‘Ù†Ø§Øª. ÙŠØ³Ø§Ø¹Ø¯ Ù‡Ø°Ø§ Ø¹Ù„Ù‰ ØªØ¨Ø±ÙŠØ± Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙˆØªÙˆÙ‚Ø¹ Ø§Ù„ØªÙØ±ÙŠÙ‚."),
                          tags$ul(
                            tags$li("ØªÙÙƒÙŠÙƒ y_t Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª (Ø§ØªØ¬Ø§Ù‡ØŒ Ù…ÙˆØ³Ù…ÙŠØ©ØŒ Ø¨ÙˆØ§Ù‚ÙŠ)."),
                            tags$li("Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¶Ø±Ø¨ÙŠ (ØºØ§Ù„Ø¨Ø§ Ø¹Ø¨Ø± log)."),
                            tags$li("Ø§Ø³ØªØ®Ø¯Ø§Ù… STL Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ØªØªØºÙŠØ± Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø©.")
                          )
                        ),
                        
                        D("Ù…ÙØ§Ù‡ÙŠÙ…/Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)", open = FALSE,
                          TERM(
                            "ØªÙÙƒÙŠÙƒ Ø¥Ø¶Ø§ÙÙŠ (Additive)",
                            "ÙÙŠ Ø§Ù„ØªÙÙƒÙŠÙƒ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ ØªÙƒÙˆÙ† Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø§ØªØ¬Ø§Ù‡: y_t = T_t + S_t + e_t. Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„ÙØ±Ù‚ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ (Ù‚Ù…Ù…-Ù‚ÙŠØ¹Ø§Ù†) ÙŠØ¨Ù‚Ù‰ ØªÙ‚Ø±ÙŠØ¨Ø§ Ø¨Ù†ÙØ³ Ø§Ù„Ø­Ø¬Ù… Ø­ØªÙ‰ Ù„Ùˆ ØªØºÙŠÙ‘Ø± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø©.",
                            purpose="Ù…ÙÙŠØ¯ Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù… Ø«Ø§Ø¨ØªØ©: Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† 'Ø´Ù‡Ø± Ø¶Ø¹ÙŠÙ' Ùˆ'Ø´Ù‡Ø± Ù‚ÙˆÙŠ' Ù…ØªØ´Ø§Ø¨Ù‡ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†.",
                            criteria="Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ù‡ØªØ²Ø§Ø²Ø§Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø°Ø§Øª Ø³Ø¹Ø© Ø´Ø¨Ù‡ Ø«Ø§Ø¨ØªØ© Ø¨ØµØ±ÙŠØ§ Ø¨ØºØ¶ Ø§Ù„Ù†Ø¸Ø± Ø¹Ù† Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ ÙØ§Ù„Ø¥Ø¶Ø§ÙÙŠ Ù…Ù†Ø§Ø³Ø¨.",
                            how_to_apply="ÙŠÙ…ÙƒÙ† Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§Ù… Ø¨Ù€ log(y): Ø¥Ø°Ø§ Ø¬Ø¹Ù„ log Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§ØŒ ÙÙ‡Ø°Ø§ ÙŠØ¯Ø¹Ù… Ø³Ù„ÙˆÙƒØ§ Ø¥Ø¶Ø§ÙÙŠØ§ ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„.",
                            formula="y_t = T_t + S_t + e_t",
                            what_to_write="Â« Ø¨Ù…Ø§ Ø£Ù† Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ØªØ¨Ø¯Ùˆ Ù…Ø³ØªÙ‚Ø±Ø©ØŒ Ø§Ø¹ØªÙ…Ø¯Ù†Ø§ Ù‚Ø±Ø§Ø¡Ø© Ø¥Ø¶Ø§ÙÙŠØ© (y_t = T_t + S_t + e_t). Â»"
                          ),
                          TERM(
                            "ØªÙÙƒÙŠÙƒ Ø¶Ø±Ø¨ÙŠ (Multiplicative)",
                            "ÙÙŠ Ø§Ù„ØªÙÙƒÙŠÙƒ Ø§Ù„Ø¶Ø±Ø¨ÙŠ ØªØ¹Ù…Ù„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ÙƒØ¹Ø§Ù…Ù„ Ù†Ø³Ø¨ÙŠ: y_t = T_t Ã— S_t Ã— e_t. Ø£ÙŠ Ø¥Ù† Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© 'ØªÙƒØ¨Ø±' Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒØ¨Ø± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø©.",
                            purpose="Ù…Ù†Ø§Ø³Ø¨ Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ÙÙŠ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø© (ØªØ£Ø«ÙŠØ± Ù†Ø³Ø¨ÙŠ).",
                            criteria="Ø¥Ø°Ø§ Ø²Ø§Ø¯Øª Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù… Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ (Ø´ÙƒÙ„ Ù…Ø±ÙˆØ­Ø©)ØŒ ÙØ§Ù„Ø¶Ø±Ø¨ÙŠ Ù…Ø±Ø¬Ù‘Ø­.",
                            how_to_apply="ØºØ§Ù„Ø¨Ø§ Ù†Ø³ØªØ®Ø¯Ù… log Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¶Ø±Ø¨ÙŠ Ø¥Ù„Ù‰ Ø¥Ø¶Ø§ÙÙŠ: log(y_t) = log(T_t) + log(S_t) + log(e_t).",
                            formula="y_t = T_t Ã— S_t Ã— e_t",
                            notes="ØºØ§Ù„Ø¨Ø§ log(y_t) ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù„Ù‰ log.",
                            what_to_write="Â« Ø¨Ù…Ø§ Ø£Ù† Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ØªØ²ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ Ø·Ø¨Ù‚Ù†Ø§ ØªØ­ÙˆÙŠÙ„ log Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ© ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„. Â»"
                          ),
                          TERM(
                            "STL",
                            "STL (ØªÙÙƒÙŠÙƒ Ù…ÙˆØ³Ù…ÙŠ-Ø§ØªØ¬Ø§Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Loess) ØªÙÙƒÙŠÙƒ Ù…Ø±Ù† ÙŠØ³Ù…Ø­ Ù„Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø£Ù† ØªØªØºÙŠØ± Ø¨Ø¨Ø·Ø¡ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† ÙˆÙŠÙƒÙˆÙ† Ø£ÙƒØ«Ø± Ù…ØªØ§Ù†Ø© Ø£Ù…Ø§Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©.",
                            purpose="Ù…ÙÙŠØ¯ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø«Ø§Ø¨ØªØ© ØªÙ…Ø§Ù…Ø§ (ØªØºÙŠØ± ØªØ¯Ø±ÙŠØ¬ÙŠ ÙÙŠ Ø§Ù„Ø¹Ø§Ø¯Ø§Øª/Ø§Ù„Ù†Ù…Ùˆ/Ø§Ù„ØªÙ‚ÙˆÙŠÙ…).",
                            criteria="Ø¥Ø°Ø§ Ø£Ø¸Ù‡Ø± seasonal plot Ø£Ù† Ø§Ù„Ù…ÙˆØ³Ù… ÙŠØªØºÙŠØ± Ù‚Ù„ÙŠÙ„Ø§ Ø¹Ø¨Ø± Ø§Ù„Ø³Ù†ÙˆØ§ØªØŒ ÙÙ€ STL ØºØ§Ù„Ø¨Ø§ Ø£ÙØ¶Ù„ Ù…Ù† Ø§Ù„ØªÙÙƒÙŠÙƒ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ.",
                            how_to_apply="Ù†Ø³ØªØ®Ø¯Ù… STL Ù„Ù„ÙˆØµÙ ÙˆØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§ØªØŒ Ø«Ù… Ù†Ø¹ÙˆØ¯ Ù„ØªØ´Ø®ÙŠØµØ§Øª Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© (Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª + ACF) Ù„Ù„ØªØ­Ø¶ÙŠØ± Ù„Ù€ SARIMA.",
                            notes="STL ÙŠØµÙ ÙˆÙ„Ø§ ÙŠØ¹ÙˆÙ‘Ø¶ Ø´Ø±Ø· Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù„Ù€ SARIMA."
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±)", open = TRUE,
                          P("Ø§Ù„ØºØ§ÙŠØ© Ù„ÙŠØ³Øª Ø§Ø®ØªÙŠØ§Ø± STL Ù„Ù„Ø²ÙŠÙ†Ø©ØŒ Ø¨Ù„ Ø¨Ù†Ø§Ø¡ Ù…Ù†Ø·Ù‚ Ù…ØªÙ…Ø§Ø³Ùƒ: Ø´ÙƒÙ„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© â†’ ØªØ­ÙˆÙŠÙ„ â†’ Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ø£ÙƒØ«Ø± Ù‚Ø§Ø¨Ù„ÙŠØ© â†’ SARIMA Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§."),
                          decision_rule_list(
                            tags$li(tags$b("Ø¥Ø¶Ø§ÙÙŠ: "), "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ~ Ø«Ø§Ø¨ØªØ© â†’ Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¶Ø§ÙÙŠ."),
                            tags$li(tags$b("Ø¶Ø±Ø¨ÙŠ: "), "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ø¹Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© âˆ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ â†’ log/Boxâ€“Cox Ø«Ù… Ø¥Ø¶Ø§ÙÙŠ ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„."),
                            tags$li(tags$b("STL: "), "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù…ØªØºÙŠØ±Ø© Ø£Ùˆ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø© â†’ STL Ø£ÙØ¶Ù„ Ù„ÙˆØµÙ Ù…ØªÙŠÙ†.")
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          P("Ù†ØªÙˆÙ‚Ø¹ Ø´ÙƒÙ„Ø§ Ù„Ù„ØªÙÙƒÙŠÙƒ ÙˆÙÙ‚Ø±Ø© Ù‚ØµÙŠØ±Ø© ØªØ±Ø¨Ø· Ø§Ù„ØªØ´Ø®ÙŠØµ Ø¨Ù‚Ø±Ø§Ø± (ØªØ­ÙˆÙŠÙ„ØŒ Ù†ÙˆØ¹ Ù…ÙˆØ³Ù…ÙŠØ©)."),
                          tags$ul(
                            tags$li("Ø´ÙƒÙ„/Ø£Ø´ÙƒØ§Ù„ Ø§Ù„ØªÙÙƒÙŠÙƒ + ØªØ¹Ù„ÙŠÙ‚ Ø­ÙˆÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡/Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©."),
                            tags$li("Ù‚Ø±Ø§Ø± Ù…Ø¨Ø±Ø±: Ø¥Ø¶Ø§ÙÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ø¶Ø±Ø¨ÙŠ (+ ØªØ­ÙˆÙŠÙ„).")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEP 4 â€” Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© + Ø§Ù„ØªÙØ±ÙŠÙ‚ + Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
      # =========================================================
      if (k == 4) {
        return(tags$div(class="road-card tight",
                        
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "Ø§Ø®ØªÙŠØ§Ø± ", tags$code("d"), " Ùˆ ", tags$code("D"), " Ùˆ ", tags$code("s"),
                          " Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© (Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚) Ù…Ø³ØªÙ‚Ø±Ø© ØªÙ‚Ø±ÙŠØ¨Ø§. Ø¹Ù…Ù„ÙŠØ§ Ù†Ø¨Ø­Ø« Ø¹Ù† 'Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙƒØ§ÙÙŠØ©' Ø¨Ø£Ù‚Ù„ Ù‚Ø¯Ø± Ù…Ù† Ø§Ù„ØªÙØ±ÙŠÙ‚ØŒ Ù„Ø£Ù† Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø· ÙŠØ¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±.",
                          type="ok"
                        ),
                        
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ù‡ÙŠ Ù…Ø­ÙˆØ± SARIMA: ØªÙ‚Ø±Ø± ÙƒÙ… Ù…Ù† Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø³ØªØ²ÙŠÙ„Ù‡ Ù„ØªØªØ±Ùƒ Ù„Ù€ AR/MA ØªÙØ³ÙŠØ± Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ. Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (ADF/KPSS/PP) Ù„Ø§ ØªØºÙ†ÙŠ Ø¹Ù† Ø§Ù„Ø±Ø³ÙˆÙ…: Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ù…Ø§ Ù…Ø¹Ø§ Ù„Ù„ØªØ«Ù„ÙŠØ«."),
                          tags$ul(
                            tags$li("ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© ", tags$code("s"), " (Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª/Ø§Ù„Ø³ÙŠØ§Ù‚)."),
                            tags$li("Ø§Ø®ØªÙŠØ§Ø± ", tags$code("d"), " (ØªÙØ±ÙŠÙ‚ ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ) Ùˆ ", tags$code("D"), " (ØªÙØ±ÙŠÙ‚ Ù…ÙˆØ³Ù…ÙŠ)."),
                            tags$li("ØªØ¨Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¨Ø±: EDA + ACF/PACF + Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (ADF/KPSS/PP) + Ù‚ÙˆØ§Ø¹Ø¯ ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·.")
                          )
                        ),
                        
                        D("ØªØ­Ù„ÙŠÙ„Ø§Øª ÙŠØ¬Ø¨ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§", open = TRUE,
                          P("Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡: (1) Ø§Ø®ØªÙŠØ§Ø± sØŒ (2) Ø§Ø®ØªØ¨Ø§Ø± DØŒ (3) Ø§Ø®ØªØ¨Ø§Ø± dØŒ (4) Ø¥Ø¹Ø§Ø¯Ø© ÙØ­Øµ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©ØŒ (5) Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù†Ù†Ø§ Ù„Ù… Ù†ÙÙØ±Ù‘Ù‚ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ù„Ø§Ø²Ù…. ØºØ§Ù„Ø¨Ø§ Ù‚ÙŠÙ… ØµØºÙŠØ±Ø© ØªÙƒÙÙŠ: dâˆˆ{0,1} Ùˆ Dâˆˆ{0,1}."),
                          tags$div(class="grid",
                                   criteria_block("A1 â€” Ø§Ø®ØªÙŠØ§Ø± s (ÙØªØ±Ø© Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©)",
                                                  note = "Ù‚Ø±Ø§Ø± Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚ÙˆÙŠÙ… + ØªØ£ÙƒÙŠØ¯ ØªØ¬Ø±ÙŠØ¨ÙŠ Ø¹Ø¨Ø± ACF/seasonal plot.",
                                                  tags$ul(
                                                    tags$li("Ù…Ø¹Ø±ÙØ© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (Ø´Ù‡Ø±ÙŠâ†’12ØŒ ÙØµÙ„ÙŠâ†’4ØŒ ÙŠÙˆÙ…ÙŠ-Ø£Ø³Ø¨ÙˆØ¹ÙŠâ†’7...)."),
                                                    tags$li("Ù…Ø¤Ø´Ø±Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©: Ù‚Ù…Ù… ACF Ø¹Ù†Ø¯ s Ùˆ2s...Ø› Ù†Ù…Ø· Ø«Ø§Ø¨Øª ÙÙŠ seasonal plot."),
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø§Ù„ØªØ¨Ø§Ø³: Ø¬Ø±Ù‘Ø¨ Ø¹Ø¯Ø© Ù‚ÙŠÙ… s Ù…Ø¹Ù‚ÙˆÙ„Ø© ÙˆÙ‚Ø§Ø±Ù† Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª.")
                                                  ),
                                                  P("ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù„Ù€ s Ù…Ø¹Ù†Ù‰ Ø²Ù…Ù†ÙŠ. Ù…Ø«Ù„Ø§ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù‡Ø±ÙŠØ©ØŒ s=12 Ø·Ø¨ÙŠØ¹ÙŠ. Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ù…ÙˆØ³Ù… ØªØ¬Ø§Ø±ÙŠ Ù†ØµÙ Ø³Ù†ÙˆÙŠØŒ ÙŠÙ…ÙƒÙ† Ø§Ø®ØªØ¨Ø§Ø± s=6 Ù„ÙƒÙ† ÙŠØ¬Ø¨ Ø¯Ø¹Ù…Ù‡ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                                   ),
                                   criteria_block("A2 â€” ØªÙ‚Ø±ÙŠØ± D (ØªÙØ±ÙŠÙ‚ Ù…ÙˆØ³Ù…ÙŠ)",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø¥Ø²Ø§Ù„Ø© Ù„Ø§Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…ÙˆØ³Ù…ÙŠØ© Ù…Ø³ØªÙ…Ø±Ø© (Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ Ù…ÙˆØ³Ù…ÙŠ).",
                                                  tags$ul(
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ© ÙˆÙ…Ø³ØªÙ‚Ø±Ø© Ø³Ù†Ø© Ø¨Ø¹Ø¯ Ø³Ù†Ø© â†’ ÙÙƒØ± ÙÙŠ D=1."),
                                                    tags$li("Ù…Ø¤Ø´Ø±Ø§Øª: ACF Ù‚ÙˆÙŠ Ø¬Ø¯Ø§ Ø¹Ù†Ø¯ lag s ÙÙŠ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§Ù…Ø› Ø§Ù„Ù…ÙˆØ³Ù… Ù„Ø§ ÙŠØ®ØªÙÙŠ Ø¨Ù…Ø¬Ø±Ø¯ d."),
                                                    tags$li("Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·: ACF Ø¹Ù†Ø¯ s ÙŠØµØ¨Ø­ Ø³Ø§Ù„Ø¨Ø§ Ø¬Ø¯Ø§ Ø¨Ø¹Ø¯ D=1 â†’ Ø¹Ù„Ø§Ù…Ø© D ÙƒØ¨ÙŠØ±.")
                                                  ),
                                                  P("Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ ÙŠÙ‚Ø§Ø±Ù† y_t Ø¨Ù€ y_{t-s}. Ø¥Ø°Ø§ Ù„Ø§Ø­Ø¸Øª Ø¨Ø¹Ø¯ D=1 ØªØ°Ø¨Ø°Ø¨Ø§ Ù…ØµØ·Ù†Ø¹Ø§ (Ù‚Ù…Ù… Ø³Ù„Ø¨ÙŠØ© Ù‚ÙˆÙŠØ©) ÙÙ‚Ø¯ ØªÙƒÙˆÙ† Ø£Ø²Ù„Øª Ù…ÙˆØ³Ù…ÙŠØ© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ù„Ø§Ø²Ù….")
                                   ),
                                   criteria_block("A3 â€” ØªÙ‚Ø±ÙŠØ± d (ØªÙØ±ÙŠÙ‚ ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ)",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø¥Ø²Ø§Ù„Ø© Ø§ØªØ¬Ø§Ù‡ Ø¹Ø´ÙˆØ§Ø¦ÙŠ (Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ).",
                                                  tags$ul(
                                                    tags$li("Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø§ØªØ¬Ø§Ù‡ Ø¹Ø´ÙˆØ§Ø¦ÙŠ (Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ) â†’ ØºØ§Ù„Ø¨Ø§ d=1 ÙƒØ§Ù."),
                                                    tags$li("Ù…Ø¤Ø´Ø±Ø§Øª: ACF ÙŠØªÙ†Ø§Ù‚Øµ Ø¨Ø¨Ø·Ø¡ ÙÙŠ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§Ù…Ø› Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ÙˆØ­Ø¯ÙˆÙŠ."),
                                                    tags$li("Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·: ACF Ø¹Ù†Ø¯ lag1 Ø³Ø§Ù„Ø¨ Ø¬Ø¯Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚ â†’ d ÙƒØ¨ÙŠØ±.")
                                                  ),
                                                  P("d=1 ÙŠØ¹Ù†ÙŠ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„ØªØºÙŠØ±Ø§Øª Ø¨Ø¯Ù„ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª. Ø¥Ø°Ø§ Ø¨Ø¯Øª Ø§Ù„ØªØºÙŠØ±Ø§Øª Ù…Ø³ØªÙ‚Ø±Ø© ØºØ§Ù„Ø¨Ø§ ÙŠÙƒÙˆÙ† SARIMA Ø£ÙƒØ«Ø± Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©. d=2 Ù†Ø§Ø¯Ø± ÙˆÙŠØ­ØªØ§Ø¬ ØªØ¨Ø±ÙŠØ±Ø§ Ù‚ÙˆÙŠØ§.")
                                   )
                          )
                        ),
                        
                        D("ØªØ¹Ø±ÙŠÙØ§Øª Ù„Ø§ ØºÙ†Ù‰ Ø¹Ù†Ù‡Ø§ (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)", open = FALSE,
                          TERM(
                            "Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ø¯ÙŠ (d)",
                            "ØªÙØ±ÙŠÙ‚ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙŠØ¹Ù†ÙŠ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ y_t Ø¨ÙØ§Ø±Ù‚Ù‡Ø§ Ø¨ÙŠÙ† Ù„Ø­Ø¸ØªÙŠÙ† Ù…ØªØªØ§Ù„ÙŠØªÙŠÙ†: âˆ‡y_t = y_t âˆ’ y_{tâˆ’1}. ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© d Ù…Ø±Ø§Øª ÙŠØ²ÙŠÙ„ ØªØ¯Ø±ÙŠØ¬ÙŠØ§ Ø§ØªØ¬Ø§Ù‡Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§.",
                            purpose="Ø§Ù„ØºØ§ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© Ù…ØªÙˆØ³Ø·Ù‡Ø§ ÙˆØªØ¨Ø§ÙŠÙ†Ù‡Ø§ Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† Ø­ØªÙ‰ ØªÙ„ØªÙ‚Ø· Ù…ÙƒÙˆÙ†Ø§Øª AR/MA Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ.",
                            criteria="ØºØ§Ù„Ø¨Ø§ d ÙŠØ³Ø§ÙˆÙŠ 0 Ø£Ùˆ 1. Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ø¥Ù„Ù‰ d=2 ÙÙ‡Ø°Ø§ ØºØ§Ù„Ø¨Ø§ Ù…Ø¤Ø´Ø± Ø¹Ù„Ù‰ Ø®ØµÙˆØµÙŠØ© ÙƒØ¨ÙŠØ±Ø© ÙÙŠ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø£Ùˆ Ù…Ø´ÙƒÙ„Ø© Ù…ÙˆØ§ØµÙØ©/Ø§Ù†Ù‚Ø·Ø§Ø¹.",
                            how_to_apply="Ù†Ø¨Ø¯Ø£ Ø¨Ù€ d=0 Ø«Ù… Ù†Ø¬Ø±Ø¨ d=1 Ø¥Ø°Ø§ Ù„Ø²Ù…. Ø¨Ø¹Ø¯ ÙƒÙ„ ØªØ¬Ø±Ø¨Ø© Ù†ÙØ­Øµ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù…ÙØ±ÙˆÙ‚Ø© ÙˆACF ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª. Ù†ØªÙˆÙ‚Ù Ø¹Ù†Ø¯Ù…Ø§ ØªØµØ¨Ø­ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© 'Ù…Ø¹Ù‚ÙˆÙ„Ø©'.",
                            formula="(1-B)^d y_t",
                            what_to_write="Â« Ø£Ø´Ø§Ø±Øª Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª Ø¥Ù„Ù‰ Ø§ØªØ¬Ø§Ù‡ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ› Ù„Ø°Ø§ Ø·Ø¨Ù‚Ù†Ø§ ØªÙØ±ÙŠÙ‚Ø§ Ø¹Ø§Ø¯ÙŠØ§ (d=1) Ø«Ù… Ø£Ø¹Ø¯Ù†Ø§ ÙØ­Øµ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©. Â»"
                          ),
                          TERM(
                            "Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ (D)",
                            "Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ ÙŠÙ‚Ø§Ø±Ù† Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ø¹ Ù†ÙØ³ Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚: âˆ‡_s y_t = y_t âˆ’ y_{tâˆ’s}. Ù‡Ø°Ø§ ÙŠØ²ÙŠÙ„ Ù…ÙƒÙˆÙ†Ø§ Ù…ÙˆØ³Ù…ÙŠØ§ Ù…Ø³ØªÙ…Ø±Ø§.",
                            purpose="Ø§Ù„ØºØ§ÙŠØ© Ù‡ÙŠ Ø¥Ø²Ø§Ù„Ø© Ù„Ø§Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…ÙˆØ³Ù…ÙŠØ© (Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ Ù…ÙˆØ³Ù…ÙŠ) Ø¨Ø­ÙŠØ« ØªÙÙ†Ù…Ø°Ø¬ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù„Ø§Ø­Ù‚Ø§ Ø¹Ø¨Ø± Ø­Ø¯ÙˆØ¯ AR/MA Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© (P,Q).",
                            criteria="ØºØ§Ù„Ø¨Ø§ D ÙŠØ³Ø§ÙˆÙŠ 0 Ø£Ùˆ 1. D=2 Ù†Ø§Ø¯Ø± ÙˆÙŠØ³ØªØ¯Ø¹ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ÙØ­Øµ s ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.",
                            how_to_apply="Ù†Ø¬Ø±Ø¨ D=0 Ø«Ù… D=1 Ø¥Ø°Ø§ Ø¨Ù‚ÙŠØª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ©. Ø¨Ø¹Ø¯ D=1 Ù†Ø±Ø§Ù‚Ø¨ Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ Ø§Ù„Ù…ÙØ±Ø· (ACF Ø³Ø§Ù„Ø¨ Ø¬Ø¯Ø§ Ø¹Ù†Ø¯ lag s).",
                            formula="(1-B^s)^D y_t",
                            what_to_write="Â« Ø¯ÙØ¹Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø© Ø¥Ù„Ù‰ ØªÙØ±ÙŠÙ‚ Ù…ÙˆØ³Ù…ÙŠ (D=1) Ø¨ÙØªØ±Ø© s=[..]. Â»"
                          ),
                          TERM(
                            "Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·",
                            "Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø· ÙŠØ¹Ù†ÙŠ Ø¥Ø²Ø§Ù„Ø© Ø¨Ù†ÙŠØ© Ø£ÙƒØ«Ø± Ù…Ù…Ø§ ÙŠÙ„Ø²Ù…. Ù‚Ø¯ ÙŠØµÙ†Ø¹ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù…ØµØ·Ù†Ø¹Ø© Ù…Ø«Ù„ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ Ø³Ù„Ø¨ÙŠ Ù‚ÙˆÙŠ Ø¹Ù†Ø¯ Ø§Ù„ØªØ£Ø®Ø± Ø§Ù„Ø£ÙˆÙ„ØŒ ÙˆÙŠØ¬Ø¹Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø£Ù‚Ù„ Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§.",
                            purpose="ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø· ÙŠØ­Ù…ÙŠ Ø«Ø¨Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª ÙˆÙŠØ­Ø¯ Ù…Ù† ØªØ¶Ø®ÙŠÙ… Ø§Ù„Ø¶Ø¬ÙŠØ¬.",
                            criteria="Ø£Ø¹Ø±Ø§Ø¶ Ø´Ø§Ø¦Ø¹Ø©: ACF Ø¹Ù†Ø¯ lag1 Ø³Ø§Ù„Ø¨ Ø¬Ø¯Ø§ Ø¨Ø¹Ø¯ dØŒ Ø£Ùˆ ACF Ø¹Ù†Ø¯ lag s Ø³Ø§Ù„Ø¨ Ø¬Ø¯Ø§ Ø¨Ø¹Ø¯ D. ØªÙ†Ø¨Ø¤Ø§Øª Ù…ØªØ°Ø¨Ø°Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ù„Øº ÙÙŠÙ‡.",
                            how_to_apply="Ø¥Ø°Ø§ Ø¸Ù‡Ø±Øª Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ØŒ Ù‚Ù„Ù‘Ù„ d Ø£Ùˆ D Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆACF. Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©: 'Ø£Ù‚Ù„ ØªÙØ±ÙŠÙ‚ Ù…Ù…ÙƒÙ† Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø¹Ù‚ÙˆÙ„Ø©'.",
                            notes="Ø§Ù„Ø£ÙØ¶Ù„ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: 'ÙƒØ§ÙÙ Ù„Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©' ÙÙ‚Ø·."
                          )
                        ),
                        
                        D("Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø§Ù„Ù‡Ø¯Ù + Ù…Ø¹Ø§ÙŠÙŠØ± Ù…ÙØµÙ„Ø©)", open = FALSE,
                          
                          TEST(
                            name="ADF â€” Augmented Dickeyâ€“Fuller (Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ÙˆØ­Ø¯ÙˆÙŠ)",
                            purpose=paste(
                              "ÙŠÙ‡Ø¯Ù Ø§Ø®ØªØ¨Ø§Ø± ADF Ø¥Ù„Ù‰ ÙƒØ´Ù ÙˆØ¬ÙˆØ¯ Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠØŒ Ø£ÙŠ Ù„Ø§Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ØªÙƒÙˆÙ† ÙÙŠÙ‡Ø§ Ø§Ù„ØµØ¯Ù…Ø§Øª Ø°Ø§Øª Ø£Ø«Ø± Ø¯Ø§Ø¦Ù…. ",
                              "ÙŠÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø§Ø¶ÙŠ y_{t-1} ÙŠÙØ³Ø± Î”y_t Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø³ÙŠØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠ (Random Walk). ",
                              "ØªÙØ¶Ø§Ù ØªØ£Ø®ÙŠØ±Ø§Øª Î”y_t Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ ÙˆØªØ¬Ù†Ø¨ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¶Ù„Ù„."
                            ),
                            when_to_use="Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙØ±ÙŠÙ‚ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ (d) Ø¶Ø±ÙˆØ±ÙŠØ§ØŒ Ø«Ù… Ù„Ù„ØªØ­Ù‚Ù‚ Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© (Ø¨Ø¹Ø¯ d ÙˆØ±Ø¨Ù…Ø§ D) Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            H0="Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¬Ø°Ø±Ù‹Ø§ ÙˆØ­Ø¯ÙˆÙŠÙ‹Ø§ â†’ ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©.",
                            H1="Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø© (Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ§ØµÙØ©: Ù…Ø¹ Ø£Ùˆ Ø¨Ø¯ÙˆÙ† drift/trend).",
                            statistic="Ø§Ù†Ø­Ø¯Ø§Ø± ADF: Î”y_t ~ Î± + Î² t + Î³ y_{t-1} + Î£ Î´_i Î”y_{t-i}. Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Î³ Ù…Ø¹ Ù‚ÙŠÙ… Ø­Ø±Ø¬Ø© Ø®Ø§ØµØ©.",
                            decision_rule="Ø¹Ù†Ø¯ Î±=0.05: Ø¥Ø°Ø§ p-value < 0.05 â†’ Ù†Ø±ÙØ¶ H0 â†’ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø±Ø¬Ù‘Ø­Ø©. Ø¥Ø°Ø§ p-value â‰¥ 0.05 â†’ Ù„Ø§ Ù†Ø±ÙØ¶ â†’ Ù‚Ø¯ ÙŠÙƒÙˆÙ† d ØºÙŠØ± ÙƒØ§Ù (Ø£Ùˆ Ø§Ù†Ù‚Ø·Ø§Ø¹/Ù…ÙˆØ§ØµÙØ© drift/trend ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨Ø©).",
                            interpretation="Ø±ÙØ¶ H0 ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„Ø§ ØªØ¨Ø¯Ùˆ ÙƒØ³ÙŠØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠ: Ù„Ø¯ÙŠÙ‡Ø§ Ù…ÙŠÙ„ Ù„Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø³Ù„ÙˆÙƒ Ù…Ø³ØªÙ‚Ø± (Ù…ØªÙˆØ³Ø· Ø«Ø§Ø¨Øª Ø£Ùˆ Ø§ØªØ¬Ø§Ù‡ Ø­ØªÙ…ÙŠ).",
                            what_it_means_for_choices="Ø¥Ø°Ø§ Ù„Ù… ÙŠØ±ÙØ¶ ADF Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§Ù…ØŒ Ø¬Ø±Ù‘Ø¨ d=1 (Ùˆ/Ø£Ùˆ D=1 Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ©). Ø¥Ø°Ø§ Ø±ÙØ¶ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø§Ù†ØªÙ‚Ù„ Ù„ØªØ­Ø¯ÙŠØ¯ p,q,P,Q Ø¹Ø¨Ø± ACF/PACF.",
                            reporting="Ø§Ø°ÙƒØ± Ø§Ù„Ù†Ø³Ø®Ø© (Ù…Ø¹ drift Ø£Ùˆ trend)ØŒ ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§ØªØŒ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¡ØŒ Ùˆp-valueØŒ ÙˆÙ‚Ø±Ø§Ø± d.",
                            caveats="Ø­Ø³Ø§Ø³ Ù„Ø§Ø®ØªÙŠØ§Ø± drift/trend ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª. Ø§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø¨Ù†ÙŠÙˆÙŠØ© Ù‚Ø¯ ØªØ¬Ø¹Ù„ Ø³Ù„Ø³Ù„Ø© 'ØªØ¨Ø¯Ùˆ' ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø© Ø±ØºÙ… ØªØºÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙ‚Ø·."
                          ),
                          
                          TEST(
                            name="KPSS â€” Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin (Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ÙƒÙØ±Ø¶ÙŠØ© ØµÙØ±ÙŠØ©)",
                            purpose=paste(
                              "ÙŠÙƒÙ…Ù„ KPSS Ø§Ø®ØªØ¨Ø§Ø± ADF Ø¨Ø¹ÙƒØ³ Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„ØµÙØ±ÙŠØ©: Ù‡Ù†Ø§ Ù†ÙØªØ±Ø¶ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© ØµØ­ÙŠØ­Ø© Ù…Ø§ Ù„Ù… ØªÙØ®Ø§Ù„ÙÙ‡Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ",
                              "ÙŠÙ‚ÙŠØ³ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…ÙƒÙˆÙ‘Ù† Ø³ÙŠØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…ØªØ¨Ù‚Ù Ø£ÙƒØ¨Ø± Ù…Ù…Ø§ ØªØ³Ù…Ø­ Ø¨Ù‡ Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø©."
                            ),
                            when_to_use="Ø¨Ø¹Ø¯ ADF/PP Ù„Ù„ØªØ«Ù„ÙŠØ«ØŒ ÙˆÙ‡Ùˆ Ù…ÙÙŠØ¯ Ø®ØµÙˆØµØ§ Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† ADF ØºÙŠØ± Ø­Ø§Ø³Ù…. ÙŠØ³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§Ù… ÙˆØ¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚.",
                            H0="Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø© (ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰) Ø£Ùˆ Ù…Ø³ØªÙ‚Ø±Ø© Ø­ÙˆÙ„ Ø§ØªØ¬Ø§Ù‡ (Ø­Ø³Ø¨ Ø§Ù„Ù†Ø³Ø®Ø©).",
                            H1="Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©.",
                            statistic="Ø¥Ø­ØµØ§Ø¡ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠ Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± ÙˆØªÙ‚Ø¯ÙŠØ± ØªØ¨Ø§ÙŠÙ† Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø¯ (bandwidth).",
                            decision_rule="Ø¹Ù†Ø¯ Î±=0.05: Ø¥Ø°Ø§ p-value < 0.05 â†’ Ù†Ø±ÙØ¶ H0 â†’ ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©. Ø¥Ø°Ø§ p-value â‰¥ 0.05 â†’ Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            interpretation="Ø¹Ø¯Ù… Ø¯Ù„Ø§Ù„Ø© KPSS Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚ ÙŠØ¯Ø¹Ù… Ø£Ù† Ø§Ù„ØªØ­ÙˆÙŠÙ„/Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø«Ø¨Ù‘Øª Ø§Ù„Ø³Ù„Ø³Ù„Ø©Ø› Ø¯Ù„Ø§Ù„Ø© KPSS ØªØ¹Ù†ÙŠ Ø¨Ù‚Ø§Ø¡ Ø§Ù†Ø¬Ø±Ø§Ù Ø£Ùˆ Ø¨Ù†ÙŠØ© Ù„Ø§Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            what_it_means_for_choices="ØªÙˆØ§ÙÙ‚ ADF/PP (Ø±ÙØ¶ Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ÙˆØ­Ø¯ÙˆÙŠ) + KPSS (Ø¹Ø¯Ù… Ø±ÙØ¶ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©) = Ø¶ÙˆØ¡ Ø£Ø®Ø¶Ø± Ù„Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ p,q,P,Q. Ø¥Ø°Ø§ Ø±ÙØ¶ KPSSØŒ Ø£Ø¹Ø¯ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ d/D Ø£Ùˆ ÙˆØ¬ÙˆØ¯ Ø§Ù†Ù‚Ø·Ø§Ø¹.",
                            reporting="Ø§Ø°ÙƒØ± Ø§Ù„Ù†Ø³Ø®Ø© (level/trend)ØŒ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¡ØŒ Ùˆp-valueØŒ ÙˆØ®Ù„Ø§ØµØ© Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©.",
                            caveats="ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø¯. Ø­Ø³Ø§Ø³ Ø¬Ø¯Ø§ Ù„Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª: ØªØºÙŠØ± Ù…Ø³ØªÙˆÙ‰ Ù‚Ø¯ ÙŠØ¬Ø¹Ù„ KPSS ÙŠØ±ÙØ¶ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø© Ù…Ø­Ù„ÙŠØ§."
                          ),
                          
                          TEST(
                            name="PP â€” Phillipsâ€“Perron (Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ Ù…Ø¹ ØªØµØ­ÙŠØ­ ØºÙŠØ± Ù…Ø¹Ù„Ù…ÙŠ)",
                            purpose=paste(
                              "ÙŠØ®ØªØ¨Ø± PP Ø£ÙŠØ¶Ø§ Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ÙˆØ­Ø¯ÙˆÙŠ Ù…Ø«Ù„ ADFØŒ Ù„ÙƒÙ†Ù‡ ÙŠØµØ­Ø­ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ ÙˆØ¹Ø¯Ù… ØªØ¬Ø§Ù†Ø³ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…Ø¹Ù„Ù…ÙŠ ",
                              "Ø¨Ø¯Ù„Ø§ Ù…Ù† Ø¥Ø¶Ø§ÙØ© Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª. ÙŠÙÙŠØ¯ Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ¹ØªÙ…Ø¯ ADF ÙƒØ«ÙŠØ±Ø§ Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª."
                            ),
                            when_to_use="ÙƒÙ…ÙƒÙ…Ù„/Ø¨Ø¯ÙŠÙ„ Ù„Ù€ ADFØŒ Ø®ØµÙˆØµØ§ Ø¥Ø°Ø§ Ø§Ø´ØªØ¨Ù‡Øª Ø¨ÙˆØ¬ÙˆØ¯ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ Ø£Ùˆ ØªØ¨Ø§ÙŠÙ† ØºÙŠØ± Ø«Ø§Ø¨Øª ÙÙŠ Ø§Ù†Ø­Ø¯Ø§Ø± ADF.",
                            H0="Ø¬Ø°Ø± ÙˆØ­Ø¯ÙˆÙŠ â†’ ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©.",
                            H1="Ù…Ø³ØªÙ‚Ø±Ø©.",
                            statistic="Ø¥Ø­ØµØ§Ø¡ DF Ù…ØµØ­Ø­ Ø¨ØªÙ‚Ø¯ÙŠØ± Ù…ØªÙŠÙ† Ù„Ù„ØªØ¨Ø§ÙŠÙ†.",
                            decision_rule="Ø¹Ù†Ø¯ Î±=0.05: Ø¥Ø°Ø§ p-value < 0.05 â†’ Ù†Ø±ÙØ¶ H0 â†’ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø±Ø¬Ù‘Ø­Ø©.",
                            interpretation="Ø¥Ø°Ø§ Ø§ØªÙÙ‚ PP ÙˆADF ÙØ§Ù„Ø¥Ø³ØªÙ†ØªØ§Ø¬ Ø£Ù‚ÙˆÙ‰. Ø¥Ø°Ø§ Ø§Ø®ØªÙ„ÙØ§ Ù†Ø¹ÙˆØ¯ Ù„Ù„Ø±Ø³ÙˆÙ… ÙˆACF Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù‚Ø±Ø§Ø±.",
                            what_it_means_for_choices="ØªÙˆØ§ÙÙ‚ ADF+PP ÙŠØ²ÙŠØ¯ Ø§Ù„Ø«Ù‚Ø© Ù„ØªØ«Ø¨ÙŠØª d. Ø§Ù„Ø§Ø®ØªÙ„Ø§Ù ÙŠØ³ØªÙ„Ø²Ù… ØªØ¬Ø±Ø¨Ø© Ù…ÙˆØ§ØµÙØ© Ø£Ø®Ø±Ù‰ (drift/trend) ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© ÙØ­Øµ Ø§Ù„ØªØ­ÙˆÙŠÙ„.",
                            reporting="Ø§Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¡ Ùˆp-value ÙˆØ§Ù„Ù…ÙˆØ§ØµÙØ© (drift/trend) ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….",
                            caveats="Ù…Ø«Ù„ ADF: ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ drift/trend. Ø§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª Ù‚Ø¯ ØªØ­Ø±Ù Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬."
                          )
                        ),
                        
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±) â€” d Ùˆ D Ùˆ s", open = TRUE,
                          P("ÙŠØ¬Ø¨ ØªØ·Ø¨ÙŠÙ‚ Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙƒØ¥Ø¬Ø±Ø§Ø¡: (1) Ø§Ø®ØªÙŠØ§Ø± sØŒ (2) ØªØ¬Ø±Ø¨Ø© DØŒ (3) ØªØ¬Ø±Ø¨Ø© dØŒ (4) ÙØ­Øµ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·ØŒ (5) Ø§Ø¹ØªÙ…Ø§Ø¯ Ø£Ø¨Ø³Ø· Ø­Ù„ ÙŠØ­Ù‚Ù‚ Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø¹Ù‚ÙˆÙ„Ø©."),
                          tags$div(class="grid",
                                   
                                   criteria_block("Ù‚Ø§Ø¹Ø¯Ø© 1 â€” ØªØ«Ù„ÙŠØ« ADF/KPSS/PP",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø¹Ø¯Ù… Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ø­Ø¯ Ù„Ø£Ù† ÙØ±Ø¶ÙŠØ§ØªÙ‡Ù… Ø§Ù„ØµÙØ±ÙŠØ© Ù…Ø®ØªÙ„ÙØ©.",
                                                  tags$ul(
                                                    tags$li(tags$b("Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ù…Ø±Ø¬Ù‘Ø­Ø©: "), "ADF/PP ÙŠØ±ÙØ¶Ø§Ù† (p<.05) ÙˆKPSS Ù„Ø§ ÙŠØ±ÙØ¶ (pâ‰¥.05)."),
                                                    tags$li(tags$b("ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø©: "), "ADF/PP Ù„Ø§ ÙŠØ±ÙØ¶Ø§Ù† ÙˆKPSS ÙŠØ±ÙØ¶."),
                                                    tags$li(tags$b("ØªØ¹Ø§Ø±Ø¶: "), "Ø§Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ACF/PACF + Ø§Ù„Ø±Ø³ÙˆÙ… + Ù‚Ù„Ù‘Ù„ Ø§Ù„ØªÙØ±ÙŠÙ‚ (ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·).")
                                                  ),
                                                  P("Ø¹Ù†Ø¯ Ø§Ù„ØªØ¹Ø§Ø±Ø¶ØŒ ÙŠØ¬Ø¨ ÙƒØªØ§Ø¨Ø© Ø£Ù† Ø§Ù„Ù‚Ø±Ø§Ø± Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ ØªÙ‚Ø§Ø±Ø¨ Ø§Ù„Ø£Ø¯Ù„Ø© (Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª + ACF + Ø±Ø³ÙˆÙ…)ØŒ ÙˆÙ„ÙŠØ³ Ø¹Ù„Ù‰ p-value ÙˆØ§Ø­Ø¯Ø©.")
                                   ),
                                   
                                   criteria_block("Ù‚Ø§Ø¹Ø¯Ø© 2 â€” ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø·",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙØ³ÙŠØ± ÙˆØ«Ø¨Ø§Øª Ù…Ø¹Ù„Ù…Ø§Øª Ø£ÙØ¶Ù„.",
                                                  tags$ul(
                                                    tags$li(tags$b("ØªÙØ±ÙŠÙ‚ Ù…ÙØ±Ø· ÙÙŠ d: "), "ACF Ø¹Ù†Ø¯ lag1 Ø³Ø§Ù„Ø¨ Ø¬Ø¯Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚Ø› Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙŠØ²ÙŠØ¯Ø› Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±."),
                                                    tags$li(tags$b("ØªÙØ±ÙŠÙ‚ Ù…ÙØ±Ø· ÙÙŠ D: "), "ACF Ø¹Ù†Ø¯ lag s Ø³Ø§Ù„Ø¨ Ø¬Ø¯Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ."),
                                                    tags$li("Ø¥Ø°Ø§ Ø´ÙÙƒ Ø¨Ø§Ù„ØªÙØ±ÙŠÙ‚ Ø§Ù„Ù…ÙØ±Ø· â†’ Ù‚Ù„Ù‘Ù„ d Ø£Ùˆ D ÙˆØ£Ø¹Ø¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ….")
                                                  ),
                                                  P("Ù…Ø¹ÙŠØ§Ø± ØªØ¹Ù„ÙŠÙ…ÙŠ Ø¬ÙŠØ¯: Ø¥Ø°Ø§ Ø§Ø¶Ø·ÙØ±Ø±Øª Ø¥Ù„Ù‰ d=2 Ø£Ùˆ D=2ØŒ ØªÙˆÙ‚Ù‘Ù ÙˆØ£Ø¹Ø¯ ÙØ­Øµ (sØŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª).")
                                   ),
                                   
                                   criteria_block("Ù‚Ø§Ø¹Ø¯Ø© 3 â€” Ù‚ÙŠÙ… Ø´Ø§Ø¦Ø¹Ø©",
                                                  note = "Ø§Ù„ØºØ§ÙŠØ©: Ø§Ø¨Ø¯Ø£ Ø¨Ø¨Ø³Ø§Ø·Ø© Ø«Ù… Ø²Ø¯ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ø¶Ø±ÙˆØ±Ø©.",
                                                  tags$ul(
                                                    tags$li(tags$b("d: "), "ØºØ§Ù„Ø¨Ø§ 0 Ø£Ùˆ 1 (Ùˆ2 Ù†Ø§Ø¯Ø± Ø¬Ø¯Ø§)."),
                                                    tags$li(tags$b("D: "), "ØºØ§Ù„Ø¨Ø§ 0 Ø£Ùˆ 1 (Ùˆ2 Ù†Ø§Ø¯Ø± Ø¬Ø¯Ø§)."),
                                                    tags$li(tags$b("s: "), "ØªØ³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØªÙ‚ÙˆÙŠÙ…Ø› Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø¤ÙƒØ¯Ø§ Ø¬Ø±Ù‘Ø¨ Ø¨Ø¯Ø§Ø¦Ù„ Ù…Ø¹Ù‚ÙˆÙ„Ø©.")
                                                  )
                                   )
                          )
                        ),
                        
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          P("ÙŠØ¬Ø¨ Ø£Ù† ØªÙØ®ØªØªÙ… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø¨Ø§Ø®ØªÙŠØ§Ø± ÙˆØ§Ø¶Ø­ (s,d,D) ÙˆØªØ¨Ø±ÙŠØ± Ù…ÙƒØªÙˆØ¨ ÙÙŠ 2â€“4 Ø¬Ù…Ù„ØŒ ÙŠØ´Ø±Ø­ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù‚Ø±Ø§Ø±: 'Ø³Ù†Ù†Ù…Ø°Ø¬ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ Ø¹Ø¨Ø± AR/MA'."),
                          tags$ul(
                            tags$li("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©: ", tags$code("s"), " Ùˆ ", tags$code("d"), " Ùˆ ", tags$code("D"), " + ØªØ¨Ø±ÙŠØ±."),
                            tags$li("Ø¬Ù…Ù„ Ø®Ù„Ø§ØµØ© Ù‚ØµÙŠØ±Ø©: Â« ØªØ´ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª + ACF Ø¥Ù„Ù‰ Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ© Ø¨Ø¹Ø¯ ... Â»"),
                            tags$li("ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ù†Ø¯ ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª â†’ ØªØ¨Ø±ÙŠØ± Ù†ÙˆØ¹ÙŠ.")
                          )
                        )
        ))
      }
      
      # =========================================================
      # STEPS 5â€“8 (Ù…ÙƒØªÙ…Ù„Ø© ÙˆÙ…ØªØ±Ø¬Ù…Ø©)
      # =========================================================
      if (k == 5) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø·Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ù‚ÙˆÙŠØ© (Benchmarks) ÙˆØ®Ø· Ø£Ø³Ø§Ø³ auto-ARIMAØŒ Ø«Ù… ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ø®ØªÙŠØ§Ø± ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (AICc/BIC) ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ© (Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª) ÙˆØ§Ù„ØºØ§ÙŠØ© (Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤).",
                          type="ok"
                        ),
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ØªÙ…Ù†Ø¹ ÙØ®Ø§ Ø´Ø§Ø¦Ø¹Ø§: Ø§Ù„Ø§Ø¹ØªÙ‚Ø§Ø¯ Ø£Ù† SARIMA Ø§Ù„Ù…Ø¹Ù‚Ø¯ Ù…ÙÙŠØ¯ Ø¨Ø§Ù„Ø¶Ø±ÙˆØ±Ø©. Ù‡Ù†Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªÙÙˆÙ‚ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø© (Ø³Ø§Ø°Ø¬ØŒ Ø³Ø§Ø°Ø¬ Ù…ÙˆØ³Ù…ÙŠ)."),
                          tags$ul(
                            tags$li("Ø¨Ù†Ø§Ø¡ Benchmarks: Ø³Ø§Ø°Ø¬ (Å·_{t+h}=y_t) ÙˆØ³Ø§Ø°Ø¬ Ù…ÙˆØ³Ù…ÙŠ (Å·_{t+h}=y_{t+h-s})."),
                            tags$li("Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®Ø· Ø£Ø³Ø§Ø³ SARIMA Ø¹Ø¨Ø± auto-ARIMA (AICc/BIC) â€” Ù…Ø¹ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø¥Ø¹Ø§Ø¯Ø©."),
                            tags$li("ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±: AICc + ØªØ´Ø®ÙŠØµØ§Øª + Ø£Ø¯Ø§Ø¡ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø¹ÙŠÙ†Ø©.")
                          )
                        ),
                        D("Ù…ÙØ§Ù‡ÙŠÙ…/Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)", open = FALSE,
                          TERM("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø°Ø¬ (ØªÙ†Ø¨Ø¤ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ)",
                               "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø°Ø¬ ÙŠØªÙ†Ø¨Ø£ Ø¨Ø£Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ ÙŠØ³Ø§ÙˆÙŠ Ø¢Ø®Ø± Ù‚ÙŠÙ…Ø© Ù…Ø±ØµÙˆØ¯Ø©. Ø±ØºÙ… Ø¨Ø³Ø§Ø·ØªÙ‡ Ù‚Ø¯ ÙŠÙƒÙˆÙ† ØµØ¹Ø¨ Ø§Ù„ØªØ¬Ø§ÙˆØ² ÙÙŠ Ø³Ù„Ø§Ø³Ù„ Ø´Ø¯ÙŠØ¯Ø© Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©.",
                               purpose="Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙÙˆÙ‚ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø§Ø°Ø¬ ÙØ£Ù†Øª Ù„Ù… ØªØ¶Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø§Ù„Ø®Ø§Ù….",
                               criteria="Ù‚Ø§Ø±Ù† MAE/RMSE Ø¹Ù„Ù‰ Ù†ÙØ³ Ù†Ø§ÙØ°Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ø³Ù† Ø¶Ø¹ÙŠÙØ§ ÙØ§Ù„Ø¨Ø³Ø§Ø·Ø© Ø£ÙØ¶Ù„.",
                               how_to_apply="Ø§Ø­Ø³Ø¨ Ø£Ø®Ø·Ø§Ø¡Ù‡ Ø¯Ø§Ø¦Ù…Ø§ Ø¹Ù„Ù‰ Ù†ÙØ³ Ù†Ø§ÙØ°Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±/rolling Ù…Ø«Ù„ Ø¨Ù‚ÙŠØ© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.",
                               formula="Å·_{t+h} = y_t"),
                          TERM("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ",
                               "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ ÙŠØªÙ†Ø¨Ø£ Ø¨Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© ØªØ³Ø§ÙˆÙŠ Ù‚ÙŠÙ…Ø© Ù†ÙØ³ Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚ (Ù…Ø«Ù„ Ù†ÙØ³ Ø§Ù„Ø´Ù‡Ø± Ù…Ù† Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ù…Ø§Ø¶ÙŠ).",
                               purpose="Benchmark Ø­Ø§Ø³Ù… Ø¹Ù†Ø¯ Ù…ÙˆØ³Ù…ÙŠØ© Ù‚ÙˆÙŠØ©: ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ 'Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©' ØªÙØ´Ù„ ÙÙŠ ØªØ¬Ø§ÙˆØ²Ù‡.",
                               criteria="Ù…ÙÙŠØ¯ Ø®ØµÙˆØµØ§ Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† s Ù…Ø­Ø¯Ø¯Ø§ Ø¬ÙŠØ¯Ø§ ÙˆØ§Ù„Ù…ÙˆØ³Ù…ÙŠØ© Ù…Ø³ØªÙ‚Ø±Ø©.",
                               how_to_apply="Ù‚ÙŠÙ‘Ù… Ø¹Ù„Ù‰ Ù…ÙˆØ³Ù… ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø¥Ù† Ø£Ù…ÙƒÙ†.",
                               formula="Å·_{t+h} = y_{t+h-s}"),
                          TERM("AICc Ù…Ù‚Ø§Ø¨Ù„ BIC",
                               "AICc ÙˆBIC ÙŠÙ‚Ø§Ø±Ù†Ø§Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ù…Ø¹ Ø¹Ù‚ÙˆØ¨Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯. AICc ÙŠØ³ØªØ®Ø¯Ù… ØºØ§Ù„Ø¨Ø§ Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØŒ Ø¨ÙŠÙ†Ù…Ø§ BIC ÙŠØ¹Ø§Ù‚Ø¨ Ø£ÙƒØ«Ø± ÙˆÙŠÙØ¶Ù„ Ù†Ù…Ø§Ø°Ø¬ Ø£Ø¨Ø³Ø·.",
                               purpose="ØªÙ‚Ù„ÙŠÙ„ Ø®Ø·Ø± ÙØ±Ø· Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø¹Ø¨Ø± ØªØ¬Ù†Ø¨ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹Ù‚Ø¯Ø© Ø¯ÙˆÙ† Ø¶Ø±ÙˆØ±Ø©.",
                               criteria="Ø¥Ø°Ø§ ÙƒØ§Ù† Î”AICc < 2 Ø¨ÙŠÙ† Ø¹Ø¯Ø© Ù†Ù…Ø§Ø°Ø¬ ÙÙ‡ÙŠ Ù…ØªÙ‚Ø§Ø±Ø¨Ø© Ø¬Ø¯Ø§ â†’ Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¨Ø³Ø· (Ø§Ù‚ØªØµØ§Ø¯).",
                               how_to_apply="Ø§Ø³ØªØ®Ø¯Ù… AICc/BIC ÙÙ‚Ø· Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ù…Ù‚Ø¯Ù‘Ø±Ø© Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø³Ù„Ø³Ù„Ø© (Ù†ÙØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙˆÙ†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª).")
                        ),
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±)", open = TRUE,
                          P("Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ù„ÙŠØ³ ÙÙ‚Ø· Ù…Ù† ÙŠÙ‚Ù„Ù„ AICc: ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¬ØªØ§Ø² Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª ÙˆÙŠØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Benchmarks ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤."),
                          tags$div(class="grid",
                                   criteria_block("Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø¨Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© (AICc/BIC)",
                                                  tags$ul(
                                                    tags$li("Ø§Ø®ØªÙŠØ§Ø± Ø£Ù‚Ù„ AICc ÙƒÙ…Ø±Ø´Ø­ Ø£ÙˆÙ„ÙŠ."),
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¹Ø¯Ø© Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ Î”AICc < 2 â†’ Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¨Ø³Ø· (Ù…Ø¹Ù„Ù…Ø§Øª Ø£Ù‚Ù„)."),
                                                    tags$li("ØªØ­Ù‚Ù‚ Ø£ÙŠØ¶Ø§ Ù…Ù† BIC Ø¥Ù† ÙƒÙ†Øª ØªÙØ¶Ù‘Ù„ Ø§Ù„Ø¨Ø³Ø§Ø·Ø© Ø£ÙƒØ«Ø±.")
                                                  )
                                   ),
                                   criteria_block("Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©",
                                                  tags$ul(
                                                    tags$li("ØªØ´Ø®ÙŠØµØ§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ù…Ù‚Ø¨ÙˆÙ„Ø© (Ljungâ€“Box ØºÙŠØ± Ø¯Ø§Ù„ØŒ Ø¥Ù„Ø®)."),
                                                    tags$li("Ù…Ø¹Ù„Ù…Ø§Øª Ù…Ø³ØªÙ‚Ø±Ø© (Ø§Ø³ØªÙ‚Ø±Ø§Ø±ÙŠØ©/Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù†Ù‚Ù„Ø§Ø¨).")
                                                  )
                                   ),
                                   criteria_block("Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØºØ§ÙŠØ© (Ø§Ù„ØªÙ†Ø¨Ø¤)",
                                                  tags$ul(
                                                    tags$li("ØªØ­Ø³Ù† ÙˆØ§Ø¶Ø­ Ù…Ù‚Ø§Ø¨Ù„ Benchmarks (Ø³Ø§Ø°Ø¬ØŒ Ø³Ø§Ø°Ø¬ Ù…ÙˆØ³Ù…ÙŠ)."),
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ø³Ù† Ø¶Ø¦ÙŠÙ„Ø§ â†’ ÙØ¶Ù‘Ù„ Ù†Ù…ÙˆØ°Ø¬Ø§ Ø£Ø¨Ø³Ø·/Ø£ÙƒØ«Ø± Ù…ØªØ§Ù†Ø©.")
                                                  )
                                   )
                          )
                        ),
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          tags$ul(
                            tags$li("Ø¬Ø¯ÙˆÙ„ Ø®Ø· Ø§Ù„Ø£Ø³Ø§Ø³: Benchmarks + auto-ARIMA (AICcØŒ MAE/RMSE Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±)."),
                            tags$li("Ø§Ø®ØªÙŠØ§Ø± Ø®Ø· Ø£Ø³Ø§Ø³ ÙƒÙ†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ (Ù„ÙŠØ³ Ø¨Ø§Ù„Ø¶Ø±ÙˆØ±Ø© Ù†Ù‡Ø§Ø¦ÙŠØ§).")
                          )
                        )
        ))
      }
      
      if (k == 6) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "Ø§Ø³ØªØ®Ø¯Ø§Ù… ACF/PACF Ù„Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© ØµØºÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø±Ø´Ø­Ø©ØŒ Ø«Ù… Ø§Ø®ØªÙŠØ§Ø±Ù‡Ø§ ÙˆÙÙ‚ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ + Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª. Ù†Ø¨Ø­Ø« Ø¹Ù† Ù…Ù†Ø·Ù‚ØŒ Ù„Ø§ Ø¹Ù† Ø¨Ø­Ø« Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¨Ø§Ù„Ù‚ÙˆØ© Ø§Ù„ØºØ§Ø´Ù…Ø©.",
                          type="ok"
                        ),
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("ÙŠØªØ¹Ù„Ù… Ø§Ù„Ø·Ø§Ù„Ø¨ Ø£Ù† ACF/PACF Ø£Ø¯ÙˆØ§Øª Ø¥Ø±Ø´Ø§Ø¯ÙŠØ©: ØªÙ‚ØªØ±Ø­ Ø±ÙØªØ¨Ø§ Ù…Ù…ÙƒÙ†Ø© Ù„ÙƒÙ†Ù‡Ø§ Ù„Ø§ ØªÙØºÙ†ÙŠ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆØ§Ù„ØªØ´Ø®ÙŠØµØ§Øª."),
                          tags$ul(
                            tags$li("Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø© (Ø¨Ø¹Ø¯ d/D)."),
                            tags$li("Ù‚Ø±Ø§Ø¡Ø© ACF/PACF Ù„Ø§Ù‚ØªØ±Ø§Ø­ p,q (Ùˆ P,Q Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©)."),
                            tags$li("Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ù‚ØµÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† ÙˆÙ…Ù‚Ø§Ø±Ù†ØªÙ‡Ù….")
                          )
                        ),
                        D("Ù…ÙØ§Ù‡ÙŠÙ… (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)", open = FALSE,
                          TERM("ACF",
                               "ØªÙ‚ÙŠØ³ Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ ACF Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙˆØªØ£Ø®ÙŠØ±Ø§ØªÙ‡Ø§. Ø¹Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© Ù…Ø³ØªÙ‚Ø±Ø©ØŒ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ù†Ù…Ø· Ù‚Ø·Ø¹/ØªØ¶Ø§Ø¤Ù„ Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ø­Ø¯ÙˆØ¯ MA.",
                               purpose="ØªØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ Ø§Ù‚ØªØ±Ø§Ø­ q ÙˆQØŒ ÙˆÙƒØ´Ù Ù‚Ù…Ù… Ù…ÙˆØ³Ù…ÙŠØ© Ø¹Ù†Ø¯ Ù…Ø¶Ø§Ø¹ÙØ§Øª s.",
                               criteria="Ù‚Ù…Ù… ÙˆØ§Ø¶Ø­Ø© Ø¹Ù†Ø¯ s Ùˆ2s... â†’ Ù…ÙˆØ³Ù…ÙŠØ©Ø› Ù‚Ø·Ø¹ Ø³Ø±ÙŠØ¹ Ø¹Ù†Ø¯ ØªØ£Ø®ÙŠØ±Ø§Øª ØµØºÙŠØ±Ø© â†’ MA Ù…Ø­ØªÙ…Ù„.",
                               how_to_apply="Ø§Ø±Ø³Ù… ACF Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚Ø› Ø§Ù‚ØªØ±Ø­ q/Q ØµØºÙŠØ±Ø© (0â€“2) Ø«Ù… ØªØ­Ù‚Ù‚ Ø¨Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª.")
                          ,
                          TERM("PACF",
                               "ØªÙ‚ÙŠØ³ Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„Ø¬Ø²Ø¦ÙŠ PACF Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø¬Ø²Ø¦ÙŠ Ø¨ÙŠÙ† y_t Ùˆ y_{t-k} Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª Ø§Ù„ÙˆØ³ÙŠØ·Ø©. Ù‚Ø·Ø¹ Ø³Ø±ÙŠØ¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø±ØªØ¨Ø© AR.",
                               purpose="ØªØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ Ø§Ù‚ØªØ±Ø§Ø­ p ÙˆP.",
                               criteria="Ù‚Ù…Ù… PACF Ø¹Ù†Ø¯ ØªØ£Ø®ÙŠØ±Ø§Øª ØµØºÙŠØ±Ø© â†’ AR Ù…Ø­ØªÙ…Ù„Ø› Ù‚Ù…Ù… Ø¹Ù†Ø¯ s â†’ AR Ù…ÙˆØ³Ù…ÙŠ.",
                               how_to_apply="Ø§Ø±Ø³Ù… PACF Ø¨Ø¹Ø¯ Ø§Ù„ØªÙØ±ÙŠÙ‚Ø› Ø§Ù‚ØªØ±Ø­ p/P ØµØºÙŠØ±Ø© Ø«Ù… Ù‚Ø§Ø±Ù†.")
                          ,
                          TERM("Ø­Ø²Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© ÙÙŠ ACF/PACF",
                               "Ø§Ù„Ø­Ø²Ù… Â±1.96/âˆšn ØªØ¹Ø·ÙŠ ØªÙ‚Ø±ÙŠØ¨Ø§ Ù„Ø­ÙƒÙ… Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ù…Ø© Ù…Ù„Ø­ÙˆØ¸Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§.",
                               purpose="ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ ØªÙØ³ÙŠØ± Ø§Ù„Ø¶Ø¬ÙŠØ¬.",
                               criteria="Ù‚Ø¯ ØªØ¸Ù‡Ø± Ù‚Ù…Ù… Ù…Ø¹Ø²ÙˆÙ„Ø© Ø¨Ø§Ù„ØµØ¯ÙØ©Ø› Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…ØªÙ…Ø§Ø³ÙƒØ©.",
                               how_to_apply="Ø§Ù†Ø¸Ø± Ù„Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© (ØªØ¶Ø§Ø¤Ù„/ØªÙƒØ±Ø§Ø±) Ø¨Ø¯Ù„ Ù‚Ù…Ø© ÙˆØ§Ø­Ø¯Ø©.")
                        ),
                        D("Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ù‚Ø±Ø§Ø±)", open = TRUE,
                          tags$div(class="grid",
                                   criteria_block("Ù…Ø±Ø´Ø­ÙˆÙ† ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠÙŠÙ† (p,q)",
                                                  tags$ul(
                                                    tags$li(tags$b("p: "), "Ø¥Ø°Ø§ ÙƒØ§Ù† PACF Ù„Ø¯ÙŠÙ‡ 1â€“2 Ù‚Ù…Ù… Ù‚ÙˆÙŠØ© Ø¹Ù†Ø¯ ØªØ£Ø®ÙŠØ±Ø§Øª ØµØºÙŠØ±Ø© â†’ p=1 Ø£Ùˆ 2 Ù…Ø­ØªÙ…Ù„."),
                                                    tags$li(tags$b("q: "), "Ø¥Ø°Ø§ ÙƒØ§Ù† ACF Ù„Ø¯ÙŠÙ‡ 1â€“2 Ù‚Ù…Ù… Ù‚ÙˆÙŠØ© â†’ q=1 Ø£Ùˆ 2 Ù…Ø­ØªÙ…Ù„."),
                                                    tags$li("Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„ØµÙØºØ±: p,q â‰¤ 3 Ø¥Ù„Ø§ Ø¨ØªØ¨Ø±ÙŠØ± Ù‚ÙˆÙŠ.")
                                                  )
                                   ),
                                   criteria_block("Ù…Ø±Ø´Ø­ÙˆÙ† Ù…ÙˆØ³Ù…ÙŠÙˆÙ† (P,Q)",
                                                  tags$ul(
                                                    tags$li(tags$b("P: "), "Ù‚Ù…Ù… PACF Ø¹Ù†Ø¯ lag s â†’ P=1 Ù…Ø­ØªÙ…Ù„."),
                                                    tags$li(tags$b("Q: "), "Ù‚Ù…Ù… ACF Ø¹Ù†Ø¯ lag s â†’ Q=1 Ù…Ø­ØªÙ…Ù„."),
                                                    tags$li("ØºØ§Ù„Ø¨Ø§ P,Q âˆˆ {0,1}.")
                                                  )
                                   ),
                                   criteria_block("Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ ÙˆØ§Ù„Ø§Ø®ØªÙŠØ§Ø±",
                                                  tags$ul(
                                                    tags$li("Ø¥Ø°Ø§ ÙƒØ§Ù† Î”AICc < 2 Ø¨ÙŠÙ† Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† â†’ Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¨Ø³Ø·."),
                                                    tags$li("Ø§Ø±ÙØ¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØºÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø© Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† AICc Ø¬ÙŠØ¯Ø§."),
                                                    tags$li("ØªØ­Ù‚Ù‚ Ø¯Ø§Ø¦Ù…Ø§ Ù…Ù† ØªØ´Ø®ÙŠØµØ§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ.")
                                                  )
                                   )
                          )
                        ),
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          tags$ul(
                            tags$li("Ù‚Ø§Ø¦Ù…Ø© Ù‚ØµÙŠØ±Ø© Ù…Ù† Ù…Ø±Ø´Ø­ÙŠ SARIMA((p,d,q)(P,D,Q)[s])."),
                            tags$li("ØªØ¨Ø±ÙŠØ± Ø¹Ø¨Ø± ACF/PACF + Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯."),
                            tags$li("Ù…Ù‚Ø§Ø±Ù†Ø© AICc/BIC + ØªØ´Ø®ÙŠØµØ§Øª Ø£ÙˆÙ„ÙŠØ©.")
                          )
                        )
        ))
      }
      
      if (k == 7) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "Ø§Ù„ØªØ­Ù‚Ù‚ Ø£Ù† Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ ØªØ´Ø¨Ù‡ Ø¶Ø¬ÙŠØ¬Ø§ Ø£Ø¨ÙŠØ¶ (Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø§Ø³Ø¨) ÙˆØ£Ù† Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ ØªØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Benchmarks. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ ØªÙƒØ´Ù Ù…Ø§ Ù„Ù… ÙŠØªØ¹Ù„Ù…Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.",
                          type="ok"
                        ),
                        D("Ø§Ù„ØºØ§ÙŠØ©", open = TRUE,
                          P("Ù‚Ø¯ ØªØ­ØµÙ„ Ø¹Ù„Ù‰ AICc Ù…Ù…ØªØ§Ø² ÙˆÙ†Ù…ÙˆØ°Ø¬ Ø³ÙŠØ¡ Ø¥Ø°Ø§ Ø¨Ù‚ÙŠØª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ù…ØªØ±Ø§Ø¨Ø·Ø© Ø²Ù…Ù†ÙŠØ§. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© ØªÙØ±Ø¶ Ø§Ù„Ø§Ù†Ø¶Ø¨Ø§Ø·: Ø£ÙˆÙ„Ø§ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© (Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ)ØŒ Ø«Ù… Ø§Ù„Ø£Ø¯Ø§Ø¡ (Ø§Ù„ØªÙ†Ø¨Ø¤)."),
                          tags$ul(
                            tags$li("ÙØ­Øµ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ: Ù„Ø§ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ Ù…ØªØ¨Ù‚ØŒ ØªØ¨Ø§ÙŠÙ† Ù…Ø³ØªÙ‚Ø±ØŒ ÙˆØ¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ARCH Ù…Ù‡Ù… (Ø¥Ù† ÙƒØ§Ù† Ø°Ø§ ØµÙ„Ø©)."),
                            tags$li("Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±/rolling (MAE/RMSE/...)."),
                            tags$li("Ø§Ø®ØªÙŠØ§Ø± Ù†Ù‡Ø§Ø¦ÙŠ: ØªØ´Ø®ÙŠØµØ§Øª Ø¬ÙŠØ¯Ø© + Ø£Ø¯Ø§Ø¡ + Ø¨Ø³Ø§Ø·Ø©.")
                          )
                        ),
                        D("Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ (Ø§Ù„Ù‡Ø¯Ù + Ù…Ø¹Ø§ÙŠÙŠØ± Ù…ÙØµÙ„Ø©)", open = FALSE,
                          TEST(
                            name="Ljungâ€“Box (Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ Ù…ØªØ¨Ù‚ ÙÙŠ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ)",
                            purpose=paste(
                              "ÙŠØ®ØªØ¨Ø± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ (Ø­ØªÙ‰ ØªØ£Ø®Ø± L) Ù…Ø³Ø§ÙˆÙŠØ© Ù„Ù„ØµÙØ± Ø¥Ø¬Ù…Ø§Ù„Ø§. ",
                              "Ù‡Ø°Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø±ÙƒØ²ÙŠ: Ø¥Ø°Ø§ Ø±ÙÙØ¶Øª H0 ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ±Ùƒ Ø¨Ù†ÙŠØ© Ø²Ù…Ù†ÙŠØ© ØºÙŠØ± Ù…ÙØ³Ø±Ø©ØŒ Ø£ÙŠ Ø£Ù† Ù…ÙˆØ§ØµÙØ© SARIMA ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©."
                            ),
                            when_to_use="Ø¯Ø§Ø¦Ù…Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ØŒ ÙˆÙŠÙØ¶Ù„ Ù„Ø¹Ø¯Ø© Ù‚ÙŠÙ… L (Ù…Ø«Ù„ L=10 ÙˆL=2s).",
                            H0="Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ ~ Ø¶Ø¬ÙŠØ¬ Ø£Ø¨ÙŠØ¶ Ø­ØªÙ‰ Ø§Ù„ØªØ£Ø®Ø± L (Ù„Ø§ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ).",
                            H1="ÙˆØ¬ÙˆØ¯ Ø§Ø±ØªØ¨Ø§Ø· Ø°Ø§ØªÙŠ ÙÙŠ Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ.",
                            statistic="Q(L) ÙŠØ¬Ù…Ù‘Ø¹ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠØ› Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±ÙŠØ© ØªÙØ¹Ø¯Ù‘Ù„ Ø¨Ù€ fitdf.",
                            decision_rule="Ø¹Ù†Ø¯ Î±=0.05: Ø¥Ø°Ø§ p-value â‰¥ 0.05 â†’ Ù…Ù‚Ø¨ÙˆÙ„Ø› Ø¥Ø°Ø§ p-value < 0.05 â†’ Ø±Ø§Ø¬Ø¹ (p,q,P,Q,d,D) Ø£Ùˆ Ø§Ù„ØªØ­ÙˆÙŠÙ„.",
                            interpretation="Ø§Ù„Ø±ÙØ¶ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ø£Ù†Ù…Ø§Ø· Ø²Ù…Ù†ÙŠØ© Ù…ØªØ¨Ù‚ÙŠØ© (ØªØ£Ø®ÙŠØ±Ø§Øª ØºÙŠØ± Ù†Ù…Ø°Ø¬Ø©ØŒ Ù…ÙˆØ³Ù… Ù†Ø§Ù‚ØµØŒ ØªÙØ±ÙŠÙ‚ ØºÙŠØ± ÙƒØ§ÙØŒ Ø¥Ù„Ø®).",
                            what_it_means_for_choices="Ø¥Ø°Ø§ Ø±ÙÙØ¶ â†’ Ø£Ø¶Ù/Ø¹Ø¯Ù‘Ù„ AR Ø£Ùˆ MA (Ù…ÙˆØ³Ù…ÙŠ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ³Ù…ÙŠ) Ø£Ùˆ Ø£Ø¹Ø¯ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ d/D. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ±ÙØ¶ â†’ Ø§Ù†ØªÙ‚Ù„ Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ.",
                            reporting="Ø§Ø°ÙƒØ± L ÙˆQ Ùˆp-value Ùˆfitdf ÙˆØ®Ù„Ø§ØµØ© 'Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø¶Ø¬ÙŠØ¬ Ø£Ø¨ÙŠØ¶'.",
                            caveats="Ø§Ø®ØªÙŠØ§Ø± L Ù…Ù‡Ù…Ø› ÙˆÙ…Ø¹ n ÙƒØ¨ÙŠØ± ÙŠØµØ¨Ø­ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø¯ÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©."
                          )
                        ),
                        D("Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©", open = FALSE,
                          tags$ul(
                            tags$li("Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©: (AICc/BIC) + MAE/RMSE (Ø§Ø®ØªØ¨Ø§Ø±) + p-value Ù„Ù€ Ljungâ€“Box (Ø¨ÙˆØ§Ù‚ÙŠ)."),
                            tags$li("Ù‚Ø±Ø§Ø± Ù†Ù‡Ø§Ø¦ÙŠ: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ + ØªØ¨Ø±ÙŠØ± (ØªØ´Ø®ÙŠØµØ§Øª + Ø£Ø¯Ø§Ø¡ + Ø¨Ø³Ø§Ø·Ø©).")
                          )
                        )
        ))
      }
      
      if (k == 8) {
        return(tags$div(class="road-card tight",
                        callout(
                          tags$b("Ø§Ù„Ù‡Ø¯Ù: "),
                          "ÙƒØªØ§Ø¨Ø© Ø®Ø§ØªÙ…Ø© ÙƒØ§Ù…Ù„Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØŒ Ø§Ù„Ø¯Ù„ÙŠÙ„ (ØªØ´Ø®ÙŠØµØ§Øª + Ø£Ø¯Ø§Ø¡)ØŒ ÙˆØ§Ù„Ù…Ø¹Ù†Ù‰ (Ù…Ø§Ø°Ø§ ÙŠÙ‚ÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙˆÙ…Ø§ Ø­Ø¯ÙˆØ¯Ù‡).",
                          type="ok"
                        ),
                        D("Ù…Ø¹Ø§Ø¯Ù„Ø© SARIMA (ØªØ±Ù…ÙŠØ² ØµØ­ÙŠØ­)", open = TRUE,
                          tags$ul(
                            tags$li(
                              tags$code("Î¦(B^s) Ï†(B) âˆ‡^d âˆ‡_s^D y_t = Î˜(B^s) Î¸(B) Îµ_t"),
                              " Ù…Ø¹ Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø±Ø§Øª ",
                              tags$code("Îµ_t ~ w.n.(0, Ïƒ^2)")
                            )
                          ),
                          tags$p(class="small",
                                 "Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©: Ù†Ø«Ø¨Øª Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø¨Ø§Ù„ØªÙØ±ÙŠÙ‚ØŒ Ø«Ù… ØªÙ„ØªÙ‚Ø· Ø­Ø¯ÙˆØ¯ AR/MA Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ. ÙŠØ¬Ø¨ Ø´Ø±Ø­ Ù‡Ø°Ù‡ Ø§Ù„ÙÙƒØ±Ø© ØµØ±Ø§Ø­Ø© ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù„Ø¥Ø¸Ù‡Ø§Ø± ÙÙ‡Ù… Ø¯ÙˆØ± ÙƒÙ„ Ù…ÙƒÙˆÙ‘Ù†."
                          )
                        ),
                        D("Ù‚Ø§Ù„Ø¨ Ù†ØµÙŠ (Ø¬Ø§Ù‡Ø² Ù„Ù„Ù†Ø³Ø®)", open = TRUE,
                          P(
                            tags$b("Ø®Ù„Ø§ØµØ© (Ù…Ø«Ø§Ù„). "),
                            "Â« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ Ù‡Ùˆ SARIMA((p,d,q)(P,D,Q)[s]) Ù…Ù‚Ø¯Ù‘ÙŽØ± Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø© [Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø©/ØºÙŠØ± Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø©]. ",
                            "Ø¯ÙØ¹Øª Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª (ACF/PACF + Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ADF/KPSS/PP) Ø¥Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± d=[..] ÙˆD=[..] Ùˆs=[..]. ",
                            "ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø¶Ø¬ÙŠØ¬ Ø£Ø¨ÙŠØ¶ (Ljungâ€“Box ØºÙŠØ± Ø¯Ø§Ù„ Ø¹Ù†Ø¯ L=[..] ÙˆÎ±=0.05)ØŒ Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù‚Ø¯ ØªÙ… Ø§Ù„ØªÙ‚Ø§Ø·Ù‡. ",
                            "ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø®Ø§Ø±Ø¬ Ø§Ù„Ø¹ÙŠÙ†Ø© ÙƒØ§Ù†Øª MAE=[..] ÙˆRMSE=[..] Ø£ÙØ¶Ù„ Ù…Ù† Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© [Ø§Ù„Ø³Ø§Ø°Ø¬/Ø§Ù„Ø³Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ]. ",
                            "ÙŠØ¹Ù†ÙŠ Ø°Ù„Ùƒ Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªÙØ¸Ù‡Ø± Ø¨Ù†ÙŠØ© [Ù…ÙˆØ³Ù…ÙŠØ©/Ù‚ØµÙˆØ± Ø°Ø§ØªÙŠ/ØµØ¯Ù…Ø§Øª Ø¹Ø§Ø¨Ø±Ø©] ØªØ³ØªÙ…Ø± Ø¨Ù…Ø§ ÙŠÙƒÙÙŠ Ù„Ø¥Ù†ØªØ§Ø¬ ØªÙ†Ø¨Ø¤Ø§Øª Ù…ÙÙŠØ¯Ø© Ø¹Ù†Ø¯ Ø£ÙÙ‚ h=[..]. ",
                            "ÙˆØªØ´Ù…Ù„ Ø§Ù„Ø­Ø¯ÙˆØ¯ [Ø§Ù†Ù‚Ø·Ø§Ø¹Ø§Øª Ù…Ø­ØªÙ…Ù„Ø©ØŒ Ù…ØªØºÙŠØ±Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ© ØºÙŠØ± Ù…Ù…Ø°Ø¬Ø©ØŒ ØªÙ‚Ù„Ø¨/ØªØ°Ø¨Ø°Ø¨]. Â»"
                          )
                        )
        ))
      }
      
      tags$div(class="road-card", "Ø®Ø·ÙˆØ© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©.")
    }
    
    # ----------------------------
    # Slider (Ø¨Ø¯ÙˆÙ† ØªÙ…Ø±ÙŠØ± Ø·ÙˆÙŠÙ„)
    # ----------------------------
    k <- input$roadmap_step_fr
    if (is.null(k)) k <- 0
    
    tagList(
      css, js,
      
      tags$div(class="road-wrap",
               tags$div(class="road-header",
                        tags$div(
                          tags$h3(class="road-title", "Ø®Ø§Ø±Ø·Ø© Ø·Ø±ÙŠÙ‚ SARIMA (Ø´Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙØµÙŠÙ„) â€” Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"),
                          tags$p(class="road-sub",
                                 "Ø§Ø³ØªØ®Ø¯Ù… Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ…Ø±ÙŠØ± (Slider) Ù„Ù„ØªÙ†Ù‚Ù„ Ø¯ÙˆÙ† ØªÙ…Ø±ÙŠØ± Ø·ÙˆÙŠÙ„. ÙƒÙ„ Ø®Ø·ÙˆØ© ØªØªØ¨Ø¹: Ø§Ù„Ù‡Ø¯Ù â†’ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª â†’ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª â†’ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± â†’ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª â†’ Ø§Ù„Ù…Ø²Ø§Ù„Ù‚."
                          )
                        )
               ),
               
               tags$hr(),
               
               sliderInput(
                 inputId = "roadmap_step_fr",
                 label   = "Ø§Ù„Ø®Ø·ÙˆØ© (Slider â€” Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„ØªÙ…Ø±ÙŠØ±)",
                 min = 0, max = 8, value = k, step = 1,
                 sep = ""
               ),
               
               tags$h4(style="margin-top:10px;", step_title(k)),
               step_badges(k),
               
               tags$hr(),
               
               step_content(k)
      )
    )
  })
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  
  
  
  # =========================
  # 8 â€” GARCH (NEW SERVER LOGIC)
  # Requires: rugarch
  # =========================
  
  # Teaching notes for the tab
  output$garch_notes <- renderUI({
    note_box(list(
      "Use GARCH when the residual variance changes over time (volatility clustering).",
      "Model the mean (ARMA) and the conditional variance (GARCH family).",
      "If you model log-returns, interpret forecasts as return forecasts and sigma as volatility."
    ))
  })
  
  output$garch_what_to_do <- renderUI({
    tags$div(
      style = "background:#eef5ff;padding:10px;border-radius:6px;margin-bottom:10px;",
      tags$b("What to do:"),
      tags$ul(
        tags$li("Choose whether to model levels or log-returns (returns usually preferred)."),
        tags$li("Pick a variance model (sGARCH is the baseline; gjrGARCH/eGARCH capture asymmetry)."),
        tags$li("Check diagnostics: standardized residuals should look like white noise; squared residuals should also be clean."),
        tags$li("If residuals are heavy-tailed, switch Normal â†’ Student-t or skewed t."),
        tags$li("Compare models by AIC/BIC and out-of-sample accuracy (if you have a test set).")
      )
    )
  })
  
  # ---- Helper: safe pkg check (you already have has_pkg() globally)
  need_pkg <- function(pkg) {
    validate(need(has_pkg(pkg), paste0("Please install package '", pkg, "' (install.packages('", pkg, "')) to use this tab.")))
  }
  
  # ---- Helper: accuracy metrics (same spirit as your existing accuracy_table)
  garch_accuracy <- function(actual, forecast) {
    a <- as.numeric(actual)
    f <- as.numeric(forecast)
    e <- a - f
    rmse <- sqrt(mean(e^2, na.rm = TRUE))
    mae  <- mean(abs(e), na.rm = TRUE)
    mape <- mean(abs(e / a), na.rm = TRUE)
    smape <- mean(2 * abs(e) / (abs(a) + abs(f)), na.rm = TRUE)
    
    data.frame(
      Metric = c("RMSE", "MAE", "MAPE", "sMAPE"),
      Value = c(rmse, mae, mape, smape),
      stringsAsFactors = FALSE
    )
  }
  
  # ---- Helper: make the modeling series from prepared()/ts split
  garch_series <- reactive({
    req(prepared())
    df <- prepared()$df
    
    # try to use your existing train/test logic if present
    train_n <- NULL
    test_n  <- 0L
    
    if (exists("ts_train_test", mode = "function")) {
      s <- tryCatch(ts_train_test(), error = function(e) NULL)
      if (!is.null(s) && !is.null(s$train_n)) {
        train_n <- s$train_n
        # preferred modeling target (in your app you use y_trans for modeling)
        y_full <- df$y_trans
        if (isTRUE(input$garch_series_type == "logret")) {
          y_full <- as.numeric(y_full)
          y_full <- y_full[is.finite(y_full)]
          y_mod <- diff(log(y_full))
          if (isTRUE(input$garch_scale_100)) y_mod <- 100 * y_mod
          # returns length reduced by 1
          # align train_n accordingly (roughly)
          train_n_mod <- max(5L, min(length(y_mod), train_n - 1L))
          list(y = y_mod, x = df$x[-1], train_n = train_n_mod, test_n = max(0L, length(y_mod) - train_n_mod))
        } else {
          y_mod <- as.numeric(df$y_trans)
          ok <- is.finite(y_mod)
          y_mod <- y_mod[ok]
          x_mod <- df$x[ok]
          train_n_mod <- max(5L, min(length(y_mod), train_n))
          list(y = y_mod, x = x_mod, train_n = train_n_mod, test_n = max(0L, length(y_mod) - train_n_mod))
        }
      }
    }
    
    # fallback: use all data
    if (isTRUE(input$garch_series_type == "logret")) {
      y_full <- as.numeric(df$y_trans)
      y_full <- y_full[is.finite(y_full)]
      y_mod <- diff(log(y_full))
      if (isTRUE(input$garch_scale_100)) y_mod <- 100 * y_mod
      list(y = y_mod, x = df$x[-1], train_n = length(y_mod), test_n = 0L)
    } else {
      y_mod <- as.numeric(df$y_trans)
      ok <- is.finite(y_mod)
      list(y = y_mod[ok], x = df$x[ok], train_n = sum(ok), test_n = 0L)
    }
  })
  
  # ---- Fit event
  garch_fit <- eventReactive(input$fit_garch, {
    need_pkg("rugarch")
    s <- garch_series()
    y <- s$y
    validate(need(length(y) >= 30, "Need at least ~30 observations for a stable GARCH fit."))
    
    # training window
    y_train <- y[seq_len(s$train_n)]
    
    spec <- rugarch::ugarchspec(
      variance.model = list(
        model = input$garch_vmodel,
        garchOrder = c(as.integer(input$garch_p), as.integer(input$garch_q))
      ),
      mean.model = list(
        armaOrder = c(as.integer(input$garch_ar), as.integer(input$garch_ma)),
        include.mean = isTRUE(input$garch_include_mean)
      ),
      distribution.model = input$garch_dist
    )
    
    fit <- tryCatch(
      rugarch::ugarchfit(spec = spec, data = y_train, solver = "hybrid"),
      error = function(e) {
        validate(paste("GARCH fit failed:", e$message))
        NULL
      }
    )
    
    list(spec = spec, fit = fit, series = s, y_train = y_train)
  })
  
  # ---- Model spec text
  output$garch_model_spec <- renderPrint({
    req(garch_fit())
    gf <- garch_fit()
    s <- gf$series
    
    cat("GARCH model specification\n")
    cat("------------------------------------------------------------\n")
    cat("Series modeled        :", if (input$garch_series_type == "logret") "Log-returns" else "Level", "\n")
    cat("Train N               :", s$train_n, "\n")
    cat("Test N                :", s$test_n, "\n\n")
    
    cat("Mean model (ARMA)\n")
    cat("  ARMA(p,q)           : (", input$garch_ar, ",", input$garch_ma, ")\n", sep = "")
    cat("  Include mean (mu)   :", if (isTRUE(input$garch_include_mean)) "Yes" else "No", "\n\n")
    
    cat("Variance model\n")
    cat("  Variant             :", input$garch_vmodel, "\n")
    cat("  Order (p,q)         : (", input$garch_p, ",", input$garch_q, ")\n\n", sep = "")
    
    cat("Innovations\n")
    cat("  Distribution        :", input$garch_dist, "\n\n")
    
    show_methods <- tryCatch(rugarch::infocriteria(gf$fit), error = function(e) NULL)
    if (!is.null(show_methods)) {
      cat("Information criteria\n")
      print(round(show_methods, 4))
    }
  })
  
  # ---- Coef table
  output$garch_coef_table <- renderTable({
    req(garch_fit())
    gf <- garch_fit()
    
    m <- tryCatch(gf$fit@fit$matcoef, error = function(e) NULL)
    validate(need(!is.null(m), "Could not extract coefficient table."))
    
    out <- as.data.frame(m)
    out$term <- rownames(out)
    rownames(out) <- NULL
    out <- out[, c("term", colnames(m)), drop = FALSE]
    names(out) <- c("term", "Estimate", "Std. Error", "t value", "Pr(>|t|)")
    out
  }, rownames = FALSE)
  
  # ---- Model equation (MathJax)
  output$garch_model_equation <- renderUI({
    req(garch_fit())
    
    p  <- as.integer(input$garch_ar)
    q  <- as.integer(input$garch_ma)
    vp <- as.integer(input$garch_p)
    vq <- as.integer(input$garch_q)
    
    mean_eq <- if (p == 0 && q == 0) {
      if (isTRUE(input$garch_include_mean)) "\\mu_t = \\mu" else "\\mu_t = 0"
    } else {
      paste0(
        "y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + ",
        "\\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t"
      )
    }
    
    var_eq <- switch(
      input$garch_vmodel,
      "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2 \\mathbb{I}(\\varepsilon_{t-i}<0)) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\left|\\frac{\\varepsilon_{t-i}}{\\sigma_{t-i}}\\right| + \\gamma_i \\frac{\\varepsilon_{t-i}}{\\sigma_{t-i}}\\right) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
      "\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2"
    )
    
    html <- paste0(
      "<p><b>Mean equation:</b></p>",
      "<div>$$", mean_eq, "$$</div>",
      "<p><b>Variance equation:</b></p>",
      "<div>$$", var_eq, "$$</div>",
      "<p>Where $$\\varepsilon_t = \\sigma_t z_t$$ and $$z_t$$ follows the chosen innovation distribution.</p>"
    )
    
    # force MathJax to typeset the updated UI
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "garch_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  
  
  
  
  
  # ---- Diagnostics plots (standardized residuals etc.)
  output$garch_resid_ts <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    z <- as.numeric(z)
    
    plot(z, type = "l", col = "#2C7FB8", main = "Standardized residuals", xlab = "t", ylab = "z_t")
    abline(h = 0, lty = 2, col = "gray50")
  })
  
  output$garch_resid_acf <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    forecast::ggAcf(as.numeric(z)) + ggplot2::labs(title = "ACF of standardized residuals")
  })
  
  output$garch_resid_hist <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    z <- as.numeric(z)
    
    ggplot2::ggplot(data.frame(z = z), ggplot2::aes(x = z)) +
      ggplot2::geom_histogram(bins = 30, fill = "#74a9cf", color = "white") +
      ggplot2::theme_minimal() +
      ggplot2::labs(title = "Histogram (standardized residuals)", x = "z_t", y = "Count")
  })
  
  output$garch_resid_qq <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    z <- tryCatch(rugarch::residuals(gf$fit, standardize = TRUE), error = function(e) NULL)
    validate(need(!is.null(z), "No residuals available."))
    z <- as.numeric(z)
    
    qqnorm(z, main = "QQ plot (standardized residuals)", col = "#2C7FB8")
    qqline(z, col = "gray40", lwd = 2)
  })
  
  # Conditional sigma plot
  output$garch_sigma_plot <- renderPlot({
    req(garch_fit())
    gf <- garch_fit()
    sig <- tryCatch(rugarch::sigma(gf$fit), error = function(e) NULL)
    validate(need(!is.null(sig), "No sigma available."))
    sig <- as.numeric(sig)
    
    plot(sig, type = "l", col = "#d95f0e", main = "Conditional volatility (sigma_t)", xlab = "t", ylab = expression(sigma[t]))
  })
  
  # ---- Residual tests (text)
  output$garch_diag_tests <- renderPrint({
    req(garch_fit())
    gf <- garch_fit()
    
    z <- as.numeric(rugarch::residuals(gf$fit, standardize = TRUE))
    z2 <- z^2
    
    L <- as.integer(input$diag_lag %||% 12)
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    cat("GARCH residual diagnostics (standardized residuals)\n")
    cat("------------------------------------------------------------\n")
    
    # LB on z
    lb1 <- tryCatch(Box.test(z, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    if (!is.null(lb1)) cat(sprintf("- Ljung-Box on z_t: Q(%d)=%.4f, p=%.4g\n", L, lb1$statistic, lb1$p.value))
    
    # LB on z^2
    lb2 <- tryCatch(Box.test(z2, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    if (!is.null(lb2)) cat(sprintf("- Ljung-Box on z_t^2: Q(%d)=%.4f, p=%.4g\n", L, lb2$statistic, lb2$p.value))
    
    # Jarque-Bera
    jb <- tryCatch(tseries::jarque.bera.test(z), error = function(e) NULL)
    if (!is.null(jb)) cat(sprintf("- Jarque-Bera: JB=%.4f, p=%.4g\n", jb$statistic, jb$p.value))
    
    # ARCH LM (on standardized residuals)
    if (has_pkg("FinTS")) {
      arch <- tryCatch(FinTS::ArchTest(z, lags = L), error = function(e) NULL)
      if (!is.null(arch)) cat(sprintf("- ARCH LM: LM=%.4f, p=%.4g (lags=%d)\n", arch$statistic, arch$p.value, L))
    } else {
      cat("- ARCH LM: install.packages('FinTS') to enable this test.\n")
    }
    
    cat("\nRule of thumb:\n")
    cat("â€¢ We want Ljung-Box p-values on z_t and z_t^2 to be > 0.05 (no leftover autocorrelation / ARCH).\n")
    cat("â€¢ Heavy tails: JB often rejects; use Student-t / skewed t innovations.\n")
  })
  
  # ---- Forecast & accuracy
  garch_forecast <- reactive({
    req(garch_fit())
    need_pkg("rugarch")
    
    gf <- garch_fit()
    s <- gf$series
    y <- s$y
    
    # horizon: if test exists => align to test length; else input$garch_h
    h <- if (s$test_n > 0) s$test_n else {
      hh <- suppressWarnings(as.integer(input$garch_h))
      if (!is.finite(hh) || is.na(hh) || hh < 1) 12L else hh
    }
    
    fc <- tryCatch(
      rugarch::ugarchforecast(gf$fit, n.ahead = h),
      error = function(e) {
        validate(paste("Forecast failed:", e$message))
        NULL
      }
    )
    
    # extract mean and sigma forecasts
    mu_hat <- as.numeric(rugarch::fitted(fc))
    sig_hat <- as.numeric(rugarch::sigma(fc))
    
    list(h = h, mu = mu_hat, sigma = sig_hat, series = s, y = y)
  })
  
  output$garch_horizon_note <- renderPrint({
    req(garch_forecast())
    fc <- garch_forecast()
    s <- fc$series
    if (s$test_n > 0) {
      cat("Forecast horizon equals the test set length (h = ", fc$h, ").\n", sep = "")
    } else {
      cat("No test set detected; using future horizon h = ", fc$h, ".\n", sep = "")
    }
  })
  
  output$garch_forecast_table <- renderTable({
    req(garch_forecast())
    fc <- garch_forecast()
    out <- data.frame(
      step = seq_len(fc$h),
      mean_forecast = fc$mu,
      sigma_forecast = fc$sigma
    )
    if (!isTRUE(input$garch_forecast_sigma)) out$sigma_forecast <- NULL
    out
  }, rownames = FALSE)
  
  output$garch_accuracy_table <- renderTable({
    req(garch_forecast())
    fc <- garch_forecast()
    s <- fc$series
    
    if (s$test_n <= 0) {
      return(data.frame(Metric = "Note", Value = "No test set available; accuracy not computed.", stringsAsFactors = FALSE))
    }
    
    y_test <- fc$y[(s$train_n + 1):(s$train_n + s$test_n)]
    y_hat  <- fc$mu[seq_len(length(y_test))]
    garch_accuracy(y_test, y_hat)
  }, rownames = FALSE)
  
  output$garch_forecast_plot <- renderPlot({
    req(garch_forecast())
    fc <- garch_forecast()
    s <- fc$series
    
    y <- fc$y
    train_n <- s$train_n
    h <- fc$h
    
    # Build x for plotting
    x <- s$x
    x_train <- x[seq_len(train_n)]
    x_fc <- x[(train_n + 1):min(length(x), train_n + h)]
    if (length(x_fc) < h) {
      # fallback: simple index extension
      x_fc <- (length(x_train) + 1):(length(x_train) + h)
    }
    
    df_train <- data.frame(x = x_train, y = y[seq_len(train_n)], set = "Train")
    df_fc <- data.frame(x = x_fc, mean = fc$mu[seq_len(h)], sigma = fc$sigma[seq_len(h)])
    
    p <- ggplot() +
      geom_line(data = df_train, aes(x = x, y = y), color = "#2C7FB8") +
      geom_line(data = df_fc, aes(x = x, y = mean), color = "#d95f0e", linewidth = 1) +
      theme_minimal() +
      labs(
        title = "GARCH forecast (mean) and optional volatility band",
        x = "Time",
        y = if (input$garch_series_type == "logret") "Return" else "Level"
      )
    
    if (isTRUE(input$garch_forecast_sigma)) {
      p <- p + geom_ribbon(
        data = df_fc,
        aes(x = x, ymin = mean - 1.96 * sigma, ymax = mean + 1.96 * sigma),
        alpha = 0.15, fill = "#d95f0e"
      )
    }
    
    # if test exists, overlay actual test
    if (s$test_n > 0) {
      df_test <- data.frame(
        x = x[(train_n + 1):(train_n + s$test_n)],
        y = y[(train_n + 1):(train_n + s$test_n)]
      )
      p <- p + geom_line(data = df_test, aes(x = x, y = y), color = "gray40")
    }
    
    p
  })
  
  
  # ---- APA paragraph (GARCH)
  output$garch_apa_paragraph <- renderPrint({
    req(garch_fit())
    gf <- garch_fit()
    
    # pull series/test info
    s <- gf$series
    n_train <- s$train_n
    n_test  <- s$test_n
    
    # info criteria
    ic <- tryCatch(rugarch::infocriteria(gf$fit), error = function(e) NULL)
    aic <- if (!is.null(ic) && "Akaike" %in% names(ic)) as.numeric(ic["Akaike"]) else NA_real_
    bic <- if (!is.null(ic) && "Bayes"  %in% names(ic)) as.numeric(ic["Bayes"])  else NA_real_
    
    # coefs
    mat <- tryCatch(gf$fit@fit$matcoef, error = function(e) NULL)
    
    get_coef <- function(name) {
      if (is.null(mat)) return(list(est = NA_real_, p = NA_real_))
      if (!name %in% rownames(mat)) return(list(est = NA_real_, p = NA_real_))
      list(est = as.numeric(mat[name, 1]), p = as.numeric(mat[name, 4]))
    }
    
    # common variance params
    omega <- get_coef("omega")
    alpha1 <- get_coef("alpha1")
    beta1  <- get_coef("beta1")
    gamma1 <- get_coef("gamma1")   # gjrGARCH
    shape  <- get_coef("shape")    # t / ged
    skew   <- get_coef("skew")     # sstd
    
    # residual diagnostics
    z <- tryCatch(as.numeric(rugarch::residuals(gf$fit, standardize = TRUE)), error = function(e) NULL)
    validate(need(!is.null(z), "Could not compute standardized residuals for APA paragraph."))
    
    L <- as.integer(input$diag_lag %||% 12)
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lb_z  <- tryCatch(Box.test(z,  lag = L, type = "Ljung-Box"), error = function(e) NULL)
    lb_z2 <- tryCatch(Box.test(z^2, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    
    jb <- tryCatch(tseries::jarque.bera.test(z), error = function(e) NULL)
    
    arch <- NULL
    if (has_pkg("FinTS")) {
      arch <- tryCatch(FinTS::ArchTest(z, lags = L), error = function(e) NULL)
    }
    
    # Forecast accuracy (if test exists)
    acc_text <- ""
    if (n_test > 0) {
      fc <- garch_forecast()
      y_test <- fc$y[(n_train + 1):(n_train + n_test)]
      y_hat  <- fc$mu[seq_len(length(y_test))]
      
      e <- y_test - y_hat
      rmse <- sqrt(mean(e^2, na.rm = TRUE))
      mae  <- mean(abs(e), na.rm = TRUE)
      mape <- mean(abs(e / y_test), na.rm = TRUE)
      
      acc_text <- paste0(
        " Out-of-sample forecast accuracy over the test set (n = ", n_test,
        ") was RMSE = ", fmt_num(rmse), ", MAE = ", fmt_num(mae),
        ", and MAPE = ", fmt_pct(mape), "."
      )
    } else {
      acc_text <- " No holdout test set was detected, so out-of-sample accuracy was not computed."
    }
    
    # build spec text
    mean_part <- paste0(
      "An ARMA(", input$garch_ar, ", ", input$garch_ma, ") mean model",
      if (isTRUE(input$garch_include_mean)) " with an intercept" else " without an intercept",
      " was specified."
    )
    
    var_part <- paste0(
      " Conditional variance was modeled using ", input$garch_vmodel,
      " with order (", input$garch_p, ", ", input$garch_q, ")."
    )
    
    dist_part <- paste0(" Innovations were assumed to follow a ", input$garch_dist, " distribution.")
    
    # parameter highlights (only mention if available)
    parm_bits <- c()
    
    if (is.finite(omega$est)) {
      parm_bits <- c(parm_bits, paste0("Ï‰ = ", fmt_num(omega$est), " (p ", fmt_p(omega$p), ")"))
    }
    if (is.finite(alpha1$est)) {
      parm_bits <- c(parm_bits, paste0("Î±â‚ = ", fmt_num(alpha1$est), " (p ", fmt_p(alpha1$p), ")"))
    }
    if (is.finite(beta1$est)) {
      parm_bits <- c(parm_bits, paste0("Î²â‚ = ", fmt_num(beta1$est), " (p ", fmt_p(beta1$p), ")"))
    }
    if (is.finite(gamma1$est)) {
      parm_bits <- c(parm_bits, paste0("Î³â‚ = ", fmt_num(gamma1$est), " (p ", fmt_p(gamma1$p), ")"))
    }
    if (is.finite(shape$est)) {
      parm_bits <- c(parm_bits, paste0("shape = ", fmt_num(shape$est), " (p ", fmt_p(shape$p), ")"))
    }
    if (is.finite(skew$est)) {
      parm_bits <- c(parm_bits, paste0("skew = ", fmt_num(skew$est), " (p ", fmt_p(skew$p), ")"))
    }
    
    parms_text <- if (length(parm_bits) > 0) {
      paste0(" Key parameter estimates included ", paste(parm_bits, collapse = "; "), ".")
    } else {
      ""
    }
    
    # diagnostics sentence
    diag_bits <- c()
    if (!is.null(lb_z))  diag_bits <- c(diag_bits, paste0("Ljungâ€“Box on zâ‚œ: Q(", L, ") = ", fmt_num(lb_z$statistic), ", p ", fmt_p(lb_z$p.value)))
    if (!is.null(lb_z2)) diag_bits <- c(diag_bits, paste0("Ljungâ€“Box on zâ‚œÂ²: Q(", L, ") = ", fmt_num(lb_z2$statistic), ", p ", fmt_p(lb_z2$p.value)))
    if (!is.null(arch))  diag_bits <- c(diag_bits, paste0("ARCH LM: LM = ", fmt_num(arch$statistic), ", p ", fmt_p(arch$p.value)))
    if (!is.null(jb))    diag_bits <- c(diag_bits, paste0("Jarqueâ€“Bera: JB = ", fmt_num(jb$statistic), ", p ", fmt_p(jb$p.value)))
    
    diag_text <- if (length(diag_bits) > 0) {
      paste0(" Residual diagnostics indicated ", paste(diag_bits, collapse = "; "), ".")
    } else {
      " Residual diagnostics were not available for reporting."
    }
    
    # AIC/BIC text
    ic_text <- if (is.finite(aic) || is.finite(bic)) {
      paste0(
        " Model fit was summarized by information criteria (AIC = ",
        if (is.finite(aic)) fmt_num(aic) else "NA",
        ", BIC = ",
        if (is.finite(bic)) fmt_num(bic) else "NA",
        ")."
      )
    } else {
      ""
    }
    
    series_name <- if (input$garch_series_type == "logret") "log-returns" else "the level series"
    series_scale <- if (input$garch_series_type == "logret" && isTRUE(input$garch_scale_100)) " (scaled by 100)" else ""
    
    paragraph <- paste0(
      "A GARCH model was fitted to ", series_name, series_scale, " using the training sample (n = ", n_train, "). ",
      mean_part, var_part, dist_part,
      ic_text,
      parms_text,
      diag_text,
      acc_text
    )
    
    cat(paragraph)
  })
  
  
  output$garch_conclusion <- renderUI({
    req(garch_fit())
    
    # ---- helpers (use yours if present)
    fmt_num_local <- function(x, d = 3) {
      if (!is.finite(x) || is.na(x)) return("NA")
      formatC(x, format = "f", digits = d)
    }
    fmt_p_local <- function(p) {
      if (!is.finite(p) || is.na(p)) return("= NA")
      if (p < 0.001) return("< .001")
      paste0("= ", sub("^0", "", fmt_num_local(p, 3)))
    }
    fmt_pct_local <- function(x) {
      if (!is.finite(x) || is.na(x)) return("NA")
      paste0(fmt_num_local(100 * x, 2), "%")
    }
    
    gf <- garch_fit()
    s <- gf$series
    n_train <- s$train_n
    n_test  <- s$test_n
    
    # ---- equations
    p  <- as.integer(input$garch_ar)
    q  <- as.integer(input$garch_ma)
    vp <- as.integer(input$garch_p)
    vq <- as.integer(input$garch_q)
    
    mean_eq <- if (p == 0 && q == 0) {
      if (isTRUE(input$garch_include_mean)) "y_t = \\mu + \\varepsilon_t" else "y_t = \\varepsilon_t"
    } else {
      paste0(
        "y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + ",
        "\\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t"
      )
    }
    
    var_eq <- switch(
      input$garch_vmodel,
      "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2\\,\\mathbb{I}(\\varepsilon_{t-i}<0)) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i |z_{t-i}| + \\gamma_i z_{t-i}) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
      "\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2"
    )
    
    # ---- info criteria
    ic <- tryCatch(rugarch::infocriteria(gf$fit), error = function(e) NULL)
    aic <- if (!is.null(ic) && "Akaike" %in% names(ic)) as.numeric(ic["Akaike"]) else NA_real_
    bic <- if (!is.null(ic) && "Bayes"  %in% names(ic)) as.numeric(ic["Bayes"])  else NA_real_
    
    # ---- coefficients and p-values
    mat <- tryCatch(gf$fit@fit$matcoef, error = function(e) NULL)
    
    get_coef <- function(name) {
      if (is.null(mat) || !name %in% rownames(mat)) return(list(est = NA_real_, p = NA_real_))
      list(est = as.numeric(mat[name, 1]), p = as.numeric(mat[name, 4]))
    }
    
    omega <- get_coef("omega")
    alpha1 <- get_coef("alpha1")
    beta1  <- get_coef("beta1")
    gamma1 <- get_coef("gamma1")
    shape  <- get_coef("shape")
    skew   <- get_coef("skew")
    mu     <- get_coef("mu")
    
    # ---- persistence + half-life (only meaningful for sGARCH/gjrGARCH)
    persistence <- NA_real_
    halflife <- NA_real_
    if (input$garch_vmodel %in% c("sGARCH", "gjrGARCH") && is.finite(alpha1$est) && is.finite(beta1$est)) {
      # common approximation: alpha + beta (gjr has extra terms; keep conservative summary)
      persistence <- alpha1$est + beta1$est
      if (is.finite(persistence) && persistence > 0 && persistence < 1) {
        halflife <- log(0.5) / log(persistence)
      }
    }
    
    # ---- residual diagnostics
    z <- tryCatch(as.numeric(rugarch::residuals(gf$fit, standardize = TRUE)), error = function(e) NULL)
    validate(need(!is.null(z), "Could not compute standardized residuals."))
    
    L <- as.integer(input$diag_lag %||% 12)
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lb_z  <- tryCatch(Box.test(z, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    lb_z2 <- tryCatch(Box.test(z^2, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    jb    <- tryCatch(tseries::jarque.bera.test(z), error = function(e) NULL)
    arch  <- if (has_pkg("FinTS")) tryCatch(FinTS::ArchTest(z, lags = L), error = function(e) NULL) else NULL
    
    # ---- forecast & accuracy (if test exists)
    acc_line <- "No holdout test set was detected; therefore, out-of-sample accuracy statistics were not computed."
    fc_tbl <- NULL
    
    if (n_test > 0) {
      fc <- garch_forecast()   # uses your earlier reactive
      y_test <- fc$y[(n_train + 1):(n_train + n_test)]
      y_hat  <- fc$mu[seq_len(length(y_test))]
      
      e <- y_test - y_hat
      rmse <- sqrt(mean(e^2, na.rm = TRUE))
      mae  <- mean(abs(e), na.rm = TRUE)
      mape <- mean(abs(e / y_test), na.rm = TRUE)
      
      acc_line <- paste0(
        "Forecast accuracy on the test set (n = ", n_test, ") was RMSE = ",
        fmt_num_local(rmse), ", MAE = ", fmt_num_local(mae),
        ", and MAPE = ", fmt_pct_local(mape), "."
      )
      
      # small forecast snippet for conclusion
      fc_tbl <- data.frame(
        step = seq_len(min(5, fc$h)),
        mean_forecast = fc$mu[seq_len(min(5, fc$h))],
        sigma_forecast = fc$sigma[seq_len(min(5, fc$h))]
      )
    }
    
    # ---- narrative bits
    series_text <- if (input$garch_series_type == "logret") {
      if (isTRUE(input$garch_scale_100)) "log-returns (scaled by 100)" else "log-returns"
    } else {
      "the level series"
    }
    
    dist_long <- switch(
      input$garch_dist,
      "norm" = "Gaussian",
      "std"  = "Studentâ€™s t",
      "sstd" = "skewed Studentâ€™s t",
      "ged"  = "generalized error (GED)",
      input$garch_dist
    )
    
    # ---- build HTML (academic format)
    html <- paste0(
      "<h4 style='margin-top:0;'>Conclusion (GARCH modelling)</h4>",
      
      "<p><b>Model overview.</b> A ", input$garch_vmodel, " model was estimated for ", series_text,
      " using a training sample of <i>n</i> = ", n_train, " observations. The conditional mean was specified as ARMA(",
      p, ", ", q, ") ", if (isTRUE(input$garch_include_mean)) "with an intercept" else "without an intercept",
      ", and innovations were assumed to follow a ", dist_long, " distribution.</p>",
      
      "<p><b>Model equations.</b></p>",
      "<div style='margin-left:6px;'>$$", mean_eq, "$$</div>",
      "<div style='margin-left:6px;'>$$", var_eq, "$$</div>",
      "<p>with $$\\varepsilon_t = \\sigma_t z_t$$.</p>",
      
      "<p><b>Key estimation results.</b> ",
      if (is.finite(aic) || is.finite(bic)) paste0("Information criteria indicated AIC = ", fmt_num_local(aic), " and BIC = ", fmt_num_local(bic), ". ") else "",
      if (is.finite(mu$est)) paste0("The estimated mean term was \\(\\mu\\) = ", fmt_num_local(mu$est), " (p ", fmt_p_local(mu$p), "). ") else "",
      if (is.finite(omega$est)) paste0("The variance intercept was \\(\\omega\\) = ", fmt_num_local(omega$est), " (p ", fmt_p_local(omega$p), "). ") else "",
      if (is.finite(alpha1$est)) paste0("The ARCH effect \\(\\alpha_1\\) = ", fmt_num_local(alpha1$est), " (p ", fmt_p_local(alpha1$p), "), ") else "",
      if (is.finite(beta1$est))  paste0("and the GARCH effect \\(\\beta_1\\) = ", fmt_num_local(beta1$est), " (p ", fmt_p_local(beta1$p), "). ") else "",
      if (is.finite(gamma1$est)) paste0("An asymmetric (leverage) component \\(\\gamma_1\\) = ", fmt_num_local(gamma1$est), " (p ", fmt_p_local(gamma1$p), ") was also estimated. ") else "",
      if (is.finite(shape$est))  paste0("Tail thickness (shape) was estimated as ", fmt_num_local(shape$est), " (p ", fmt_p_local(shape$p), "). ") else "",
      if (is.finite(skew$est))   paste0("Skewness (skew) was estimated as ", fmt_num_local(skew$est), " (p ", fmt_p_local(skew$p), "). ") else "",
      if (is.finite(persistence)) paste0("Volatility persistence (approx. \\(\\alpha_1 + \\beta_1\\)) was ", fmt_num_local(persistence), 
                                         if (is.finite(halflife)) paste0(", corresponding to an approximate half-life of ", fmt_num_local(halflife, 2), " periods. ") else ". ")
      else "",
      "</p>",
      
      "<p><b>Residual diagnostics.</b> ",
      if (!is.null(lb_z))  paste0("Ljungâ€“Box tests suggested ", if (lb_z$p.value > 0.05) "no" else "remaining", " autocorrelation in standardized residuals (Q(", L, ") = ", fmt_num_local(lb_z$statistic), ", p ", fmt_p_local(lb_z$p.value), "). ") else "",
      if (!is.null(lb_z2)) paste0("For squared residuals, the Ljungâ€“Box test ", if (lb_z2$p.value > 0.05) "did not indicate" else "indicated", " remaining ARCH structure (Q(", L, ") = ", fmt_num_local(lb_z2$statistic), ", p ", fmt_p_local(lb_z2$p.value), "). ") else "",
      if (!is.null(arch))  paste0("The ARCH LM test ", if (arch$p.value > 0.05) "did not provide evidence" else "provided evidence", " of additional conditional heteroskedasticity (LM = ", fmt_num_local(arch$statistic), ", p ", fmt_p_local(arch$p.value), "). ") else "",
      if (!is.null(jb))    paste0("Normality was assessed using Jarqueâ€“Bera (JB = ", fmt_num_local(jb$statistic), ", p ", fmt_p_local(jb$p.value), "), which commonly rejects under heavy tailsâ€”consistent with adopting non-Gaussian innovations when appropriate. ") else "",
      "</p>",
      
      "<p><b>Forecast performance.</b> ", acc_line, "</p>",
      
      if (!is.null(fc_tbl)) {
        paste0(
          "<p><b>Forecast excerpt (first 5 steps).</b></p>",
          "<div style='margin-left:6px;'>",
          paste0(
            "<table class='table table-condensed' style='width:100%;max-width:520px;'>",
            "<thead><tr><th>Step</th><th>Mean forecast</th><th>Sigma forecast</th></tr></thead><tbody>",
            paste(
              apply(fc_tbl, 1, function(r) {
                paste0(
                  "<tr><td>", r[[1]], "</td><td>", fmt_num_local(as.numeric(r[[2]])),
                  "</td><td>", fmt_num_local(as.numeric(r[[3]])), "</td></tr>"
                )
              }),
              collapse = ""
            ),
            "</tbody></table>"
          ),
          "</div>"
        )
      } else "",
      
      "<p><b>Overall conclusion.</b> Collectively, the estimated parameters and residual diagnostics ",
      "support the use of a conditional heteroskedasticity framework for capturing time-varying volatility in the series. ",
      "When diagnostics indicate limited remaining autocorrelation in \\(z_t\\) and \\(z_t^2\\), the fitted GARCH specification ",
      "may be considered adequate for inference and forecasting. Where residual tests suggest remaining dependence or heavy tails, ",
      "improvements may include refining the ARMA mean orders, increasing the GARCH order, or adopting heavier-tailed/skewed innovation distributions.</p>"
    )
    
    # trigger MathJax typesetting for this conclusion box
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "garch_conclusion_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  
  
  
  # =========================
  # 9 â€” Auto-GARCH (SERVER)
  # =========================
  
  output$autogarch_notes <- renderUI({
    if (isTRUE(input$show_teaching_notes)) {
      tags$div(
        class = "alert alert-info",
        tags$b("Auto-GARCH:"),
        " searches across GARCH variants, orders, and innovation distributions, and selects the best model using AIC/BIC.",
        tags$br(),
        "Tip: Start with (1,1) + {sGARCH, gjrGARCH} and {std, norm} to keep search fast."
      )
    }
  })
  
  output$autogarch_what_to_do <- renderUI({
    tags$div(
      tags$ol(
        tags$li("Upload data and set frequency/transform in the left sidebar."),
        tags$li("Choose series type (level vs log-returns)."),
        tags$li("Choose search space (mean ARMA grid, variance models, distributions)."),
        tags$li("Click â€œRun Auto-GARCH Searchâ€."),
        tags$li("Inspect top candidates, diagnostics, residual tests, then forecast performance.")
      )
    )
  })
  
  # ---- Helper: build series for Auto-GARCH
  autogarch_series <- reactive({
    req(ts_train_test())
    s <- ts_train_test()
    y_full <- as.numeric(s$ts_full)
    
    if (input$autogarch_series_type == "logret") {
      # log-returns: diff(log(y))
      y_full <- diff(log(y_full))
      y_full <- y_full[is.finite(y_full)]
      if (isTRUE(input$autogarch_scale_100)) y_full <- 100 * y_full
    } else {
      y_full <- y_full[is.finite(y_full)]
    }
    
    # train/test sizes based on original split proportion
    # If train_prop == 1 => test size 0
    n_full <- length(y_full)
    train_prop <- suppressWarnings(as.numeric(input$train_prop))
    if (!is.finite(train_prop) || train_prop <= 0) train_prop <- 1
    n_train <- if (train_prop >= 0.999) n_full else max(10L, floor(train_prop * n_full))
    n_test  <- max(0L, n_full - n_train)
    
    list(
      y = y_full,
      train_n = n_train,
      test_n  = n_test
    )
  })
  
  # ---- Auto search (eventReactive on button)
  autogarch_search <- eventReactive(input$fit_autogarch, {
    validate(need(has_pkg("rugarch"), "Package 'rugarch' is required for Auto-GARCH. Please install it."))
    s <- autogarch_series()
    y <- s$y
    validate(need(length(y) >= 80, "Need at least ~80 observations for a stable Auto-GARCH search."))
    
    y_train <- y[seq_len(s$train_n)]
    
    # grids
    vmodels <- input$autogarch_vmodels
    dists   <- input$autogarch_dists
    validate(need(length(vmodels) > 0, "Select at least one GARCH variant."))
    validate(need(length(dists) > 0, "Select at least one distribution."))
    
    gorders <- switch(
      input$autogarch_orders,
      "11"    = list(c(1L, 1L)),
      "small" = list(c(1L, 1L), c(1L, 2L), c(2L, 1L)),
      "22"    = list(c(1L, 1L), c(1L, 2L), c(2L, 1L), c(2L, 2L)),
      list(c(1L, 1L))
    )
    
    if (isTRUE(input$autogarch_search_mean)) {
      pmax <- as.integer(input$autogarch_pmax); if (!is.finite(pmax) || pmax < 0) pmax <- 0L
      qmax <- as.integer(input$autogarch_qmax); if (!is.finite(qmax) || qmax < 0) qmax <- 0L
      arma_grid <- expand.grid(ar = 0:pmax, ma = 0:qmax)
    } else {
      arma_grid <- data.frame(ar = 0L, ma = 0L)
    }
    
    include_mean <- isTRUE(input$autogarch_include_mean)
    
    # safe fit one
    fit_one <- function(vmodel, dist, go, ar, ma) {
      spec <- rugarch::ugarchspec(
        variance.model = list(model = vmodel, garchOrder = c(go[1], go[2])),
        mean.model = list(armaOrder = c(ar, ma), include.mean = include_mean),
        distribution.model = dist
      )
      fit <- tryCatch(
        rugarch::ugarchfit(spec = spec, data = y_train, solver = "hybrid"),
        error = function(e) NULL
      )
      if (is.null(fit)) return(NULL)
      ic <- tryCatch(rugarch::infocriteria(fit), error = function(e) NULL)
      if (is.null(ic)) return(NULL)
      
      data.frame(
        vmodel = vmodel, dist = dist,
        garch_p = go[1], garch_q = go[2],
        ar = ar, ma = ma,
        AIC = as.numeric(ic["Akaike"]),
        BIC = as.numeric(ic["Bayes"]),
        stringsAsFactors = FALSE,
        fit = I(list(fit))
      )
    }
    
    # run search with progress
    total <- length(vmodels) * length(dists) * length(gorders) * nrow(arma_grid)
    res_list <- vector("list", total)
    k <- 1L
    
    withProgress(message = "Auto-GARCH search", value = 0, {
      for (vm in vmodels) {
        for (di in dists) {
          for (go in gorders) {
            for (i in seq_len(nrow(arma_grid))) {
              incProgress(1 / total, detail = paste(vm, di, paste0("(", go[1], ",", go[2], ")"), "ARMA", arma_grid$ar[i], arma_grid$ma[i]))
              out <- fit_one(vm, di, go, arma_grid$ar[i], arma_grid$ma[i])
              if (!is.null(out)) {
                res_list[[k]] <- out
                k <- k + 1L
              }
            }
          }
        }
      }
    })
    
    res_list <- res_list[seq_len(k - 1L)]
    validate(need(length(res_list) > 0, "All candidate models failed. Try smaller ARMA grid, fewer distributions, or only sGARCH(1,1)."))
    
    res <- do.call(rbind, res_list)
    
    # rank by selection criterion
    ic_col <- input$autogarch_select_ic
    res <- res[order(res[[ic_col]]), , drop = FALSE]
    res
  })
  
  # ---- best fit + series bundle
  autogarch_best <- reactive({
    req(autogarch_search())
    res <- autogarch_search()
    list(
      fit = res$fit[[1]],
      meta = res[1, c("vmodel","dist","garch_p","garch_q","ar","ma","AIC","BIC"), drop = FALSE],
      series = autogarch_series()
    )
  })
  
  # ---- search results table
  output$autogarch_rank_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Click â€œRun Auto-GARCH Searchâ€ to see results."))
    req(autogarch_search())
    topk <- as.integer(input$autogarch_topk)
    if (!is.finite(topk) || topk < 5) topk <- 10L
    
    res <- autogarch_search()
    out <- head(res, topk)
    out$fit <- NULL
    out
  }, rownames = FALSE)
  
  output$autogarch_best_spec <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Click â€œRun Auto-GARCH Searchâ€ first."))
    req(autogarch_best())
    b <- autogarch_best()
    cat("Best Auto-GARCH model selected.\n\n")
    print(b$meta)
    cat("\nInfo criteria (rugarch::infocriteria):\n")
    print(round(rugarch::infocriteria(b$fit), 4))
  })
  
  # ---- model spec + coefficient table
  output$autogarch_model_spec <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Click â€œRun Auto-GARCH Searchâ€ first."))
    req(autogarch_best())
    b <- autogarch_best()
    
    cat("Auto-GARCH best specification:\n")
    print(b$meta)
    cat("\n\nRUGARCH fit summary:\n")
    show(b$fit)
  })
  
  output$autogarch_coef_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Click â€œRun Auto-GARCH Searchâ€ first."))
    req(autogarch_best())
    fit <- autogarch_best()$fit
    mat <- tryCatch(fit@fit$matcoef, error = function(e) NULL)
    validate(need(!is.null(mat), "Coefficient table unavailable."))
    
    data.frame(
      Term = rownames(mat),
      Estimate = as.numeric(mat[, 1]),
      `Std. Error` = as.numeric(mat[, 2]),
      `t value` = as.numeric(mat[, 3]),
      `Pr(>|t|)` = as.numeric(mat[, 4]),
      row.names = NULL,
      check.names = FALSE
    )
  }, digits = 5)
  
  # ---- equation (same style as your GARCH equation)
  output$autogarch_model_equation <- renderUI({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search to generate the equation."))
    req(autogarch_best())
    b <- autogarch_best()
    m <- b$meta[1, ]
    
    p  <- as.integer(m$ar); if (!is.finite(p)) p <- 0L
    q  <- as.integer(m$ma); if (!is.finite(q)) q <- 0L
    vp <- as.integer(m$garch_p); if (!is.finite(vp)) vp <- 1L
    vq <- as.integer(m$garch_q); if (!is.finite(vq)) vq <- 1L
    vmodel <- as.character(m$vmodel)
    
    mean_eq <- if (p == 0 && q == 0) {
      if (isTRUE(input$autogarch_include_mean)) "y_t = \\mu + \\varepsilon_t" else "y_t = \\varepsilon_t"
    } else {
      paste0("y_t = \\mu + \\sum_{i=1}^{", p, "} \\phi_i y_{t-i} + \\sum_{j=1}^{", q, "} \\theta_j \\varepsilon_{t-j} + \\varepsilon_t")
    }
    
    var_eq <- switch(
      vmodel,
      "sGARCH"   = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} \\alpha_i \\varepsilon_{t-i}^2 + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "gjrGARCH" = paste0("\\sigma_t^2 = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i \\varepsilon_{t-i}^2 + \\gamma_i \\varepsilon_{t-i}^2\\,\\mathbb{I}(\\varepsilon_{t-i}<0)) + \\sum_{j=1}^{", vp, "} \\beta_j \\sigma_{t-j}^2"),
      "eGARCH"   = paste0("\\log(\\sigma_t^2) = \\omega + \\sum_{i=1}^{", vq, "} (\\alpha_i |z_{t-i}| + \\gamma_i z_{t-i}) + \\sum_{j=1}^{", vp, "} \\beta_j \\log(\\sigma_{t-j}^2)"),
      paste0("\\sigma_t^2 = \\omega + \\sum \\alpha \\varepsilon^2 + \\sum \\beta \\sigma^2")
    )
    
    html <- paste0(
      "<p><b>Mean equation:</b></p><div>$$", mean_eq, "$$</div>",
      "<p><b>Variance equation:</b></p><div>$$", var_eq, "$$</div>",
      "<p>Where $$\\varepsilon_t = \\sigma_t z_t$$.</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "autogarch_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- residuals + sigma
  autogarch_resids <- reactive({
    req(autogarch_best())
    fit <- autogarch_best()$fit
    z <- tryCatch(as.numeric(rugarch::residuals(fit, standardize = TRUE)), error = function(e) NULL)
    validate(need(!is.null(z), "Cannot compute standardized residuals."))
    z
  })
  
  autogarch_sigma <- reactive({
    req(autogarch_best())
    fit <- autogarch_best()$fit
    sig <- tryCatch(as.numeric(rugarch::sigma(fit)), error = function(e) NULL)
    validate(need(!is.null(sig), "Cannot compute sigma."))
    sig
  })
  
  # ---- diagnostics plots
  output$autogarch_resid_ts <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    plot(z, type = "l", main = "Standardized residuals", ylab = "z_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$autogarch_resid_acf <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    stats::acf(z, main = "ACF of standardized residuals")
  })
  
  output$autogarch_resid_hist <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    hist(z, breaks = 30, main = "Histogram of z_t", xlab = "z_t")
  })
  
  output$autogarch_resid_qq <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    qqnorm(z, main = "Qâ€“Q plot of z_t"); qqline(z, col = "red")
  })
  
  output$autogarch_sigma_plot <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    sig <- autogarch_sigma()
    plot(sig, type = "l", main = "Conditional volatility (sigma)", ylab = "sigma_t", xlab = "t")
  })
  
  # ---- residual tests text
  output$autogarch_diag_tests <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    z <- autogarch_resids()
    
    L <- as.integer(input$diag_lag)
    if (!is.finite(L) || L < 1) L <- 12L
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    cat("Residual tests (standardized residuals z_t)\n")
    cat("=======================================\n\n")
    
    lb1 <- Box.test(z,  lag = L, type = "Ljung-Box")
    lb2 <- Box.test(z^2, lag = L, type = "Ljung-Box")
    
    cat("Ljungâ€“Box on z_t:\n"); print(lb1); cat("\n")
    cat("Ljungâ€“Box on z_t^2:\n"); print(lb2); cat("\n")
    
    if (has_pkg("FinTS")) {
      cat("ARCH LM test (FinTS::ArchTest):\n")
      print(FinTS::ArchTest(z, lags = L)); cat("\n")
    } else {
      cat("ARCH LM test: FinTS not installed.\n\n")
    }
    
    if (has_pkg("tseries")) {
      cat("Jarqueâ€“Bera normality test (tseries):\n")
      print(tseries::jarque.bera.test(z)); cat("\n")
    } else {
      cat("Jarqueâ€“Bera: tseries not installed.\n\n")
    }
  })
  
  # ---- forecast + accuracy
  autogarch_forecast <- reactive({
    req(autogarch_best())
    b <- autogarch_best()
    fit <- b$fit
    s <- b$series
    
    n_test <- as.integer(s$test_n); if (!is.finite(n_test)) n_test <- 0L
    n_train <- as.integer(s$train_n)
    
    if (n_test > 0) {
      h <- n_test
    } else {
      h_in <- suppressWarnings(as.integer(input$autogarch_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
    }
    
    fc <- rugarch::ugarchforecast(fit, n.ahead = h)
    
    mu <- tryCatch(as.numeric(rugarch::fitted(fc)), error = function(e) rep(NA_real_, h))
    sig <- tryCatch(as.numeric(rugarch::sigma(fc)), error = function(e) rep(NA_real_, h))
    
    list(h = h, fc = fc, mu = mu, sigma = sig)
  })
  
  output$autogarch_horizon_note <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    s <- autogarch_series()
    if (s$test_n > 0) {
      cat("Holdout test set detected. Forecast horizon h was set to the test length (h =", s$test_n, ").\n")
    } else {
      h <- autogarch_forecast()$h
      cat("No test set detected. Forecast horizon h was set to", h, "using the Auto-GARCH horizon input.\n")
    }
  })
  
  output$autogarch_accuracy_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    b <- autogarch_best()
    s <- b$series
    if (s$test_n <= 0) return(NULL)
    
    y <- b$series$y
    y_test <- y[(s$train_n + 1):(s$train_n + s$test_n)]
    
    mu <- autogarch_forecast()$mu[seq_along(y_test)]
    validate(need(length(mu) == length(y_test), "Forecast length mismatch."))
    
    accuracy_df(y_test, mu)
  }, rownames = FALSE)
  
  output$autogarch_forecast_table <- renderTable({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    f <- autogarch_forecast()
    h <- f$h
    out <- data.frame(
      step = 1:h,
      mean_forecast = f$mu,
      sigma_forecast = if (isTRUE(input$autogarch_forecast_sigma)) f$sigma else NA_real_
    )
    out
  }, digits = 6)
  
  output$autogarch_forecast_plot <- renderPlot({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    b <- autogarch_best()
    s <- b$series
    y <- b$series$y
    
    f <- autogarch_forecast()
    h <- f$h
    
    # plot last window + forecast
    n <- length(y)
    window <- min(200, n)
    y_tail <- y[(n - window + 1):n]
    
    plot(y_tail, type = "l", main = "Auto-GARCH: mean forecast", ylab = "Series", xlab = "t (tail)")
    lines((window + 1):(window + h), f$mu, col = "blue", lwd = 2)
    
    if (isTRUE(input$autogarch_forecast_sigma)) {
      # simple +/- 2*sigma band for visualization
      up <- f$mu + 2 * f$sigma
      lo <- f$mu - 2 * f$sigma
      lines((window + 1):(window + h), up, col = "gray40", lty = 2)
      lines((window + 1):(window + h), lo, col = "gray40", lty = 2)
      legend("topleft", legend = c("history", "mean forecast", "Â±2 sigma"), col = c("black","blue","gray40"),
             lty = c(1,1,2), bty = "n")
    } else {
      legend("topleft", legend = c("history", "mean forecast"), col = c("black","blue"),
             lty = c(1,1), bty = "n")
    }
  })
  
  # ---- APA paragraph (Auto-GARCH)
  output$autogarch_apa_paragraph <- renderPrint({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    req(autogarch_best())
    b <- autogarch_best()
    m <- b$meta[1, ]
    
    ic <- rugarch::infocriteria(b$fit)
    aic <- as.numeric(ic["Akaike"])
    bic <- as.numeric(ic["Bayes"])
    
    z <- autogarch_resids()
    L <- as.integer(input$diag_lag); if (!is.finite(L) || L < 1) L <- 12L
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lbz  <- Box.test(z, lag = L, type = "Ljung-Box")
    lbz2 <- Box.test(z^2, lag = L, type = "Ljung-Box")
    
    cat(
      "An Auto-GARCH search selected a ", m$vmodel, " model with GARCH order (",
      m$garch_p, ", ", m$garch_q, "), ARMA(", m$ar, ", ", m$ma, ") mean, and ",
      m$dist, " innovations. Model fit was summarized by AIC = ", fmt_num(aic, 3),
      " and BIC = ", fmt_num(bic, 3), ". Residual diagnostics indicated Ljungâ€“Box ",
      "tests on standardized residuals z_t (Q(", L, ") = ", fmt_num(lbz$statistic, 3),
      ", p ", fmt_p(lbz$p.value), ") and on squared residuals z_t^2 (Q(", L, ") = ",
      fmt_num(lbz2$statistic, 3), ", p ", fmt_p(lbz2$p.value), ").",
      sep = ""
    )
  })
  
  # ---- Conclusion (academic) (Auto-GARCH)
  output$autogarch_conclusion <- renderUI({
    validate(need(input$fit_autogarch > 0, "Run Auto-GARCH Search first."))
    req(autogarch_best())
    
    b <- autogarch_best()
    m <- b$meta[1, ]
    s <- b$series
    n_train <- s$train_n
    n_test  <- s$test_n
    
    # equation rendered elsewhere; conclusion references it + tests + accuracy
    z <- autogarch_resids()
    L <- as.integer(input$diag_lag); if (!is.finite(L) || L < 1) L <- 12L
    L <- max(1L, min(L, floor(length(z) / 2)))
    
    lbz  <- Box.test(z, lag = L, type = "Ljung-Box")
    lbz2 <- Box.test(z^2, lag = L, type = "Ljung-Box")
    
    ic <- rugarch::infocriteria(b$fit)
    aic <- as.numeric(ic["Akaike"])
    bic <- as.numeric(ic["Bayes"])
    
    # accuracy summary (if test exists)
    acc_txt <- "No holdout test set was detected; therefore, out-of-sample accuracy was not computed."
    if (n_test > 0) {
      acc <- tryCatch(output$autogarch_accuracy_table(), error = function(e) NULL)
      # better: recompute quickly
      y <- b$series$y
      y_test <- y[(n_train + 1):(n_train + n_test)]
      mu <- autogarch_forecast()$mu[seq_along(y_test)]
      e <- y_test - mu
      rmse <- sqrt(mean(e^2, na.rm = TRUE))
      mae  <- mean(abs(e), na.rm = TRUE)
      acc_txt <- paste0("Forecast accuracy on the test set (n = ", n_test, ") was RMSE = ", fmt_num(rmse, 3),
                        " and MAE = ", fmt_num(mae, 3), ".")
    }
    
    html <- paste0(
      "<h4 style='margin-top:0;'>Auto-GARCH conclusion (academic)</h4>",
      "<p><b>Selected specification.</b> The Auto-GARCH search selected <b>", m$vmodel,
      "</b>(", m$garch_p, ",", m$garch_q, ") with ARMA(", m$ar, ",", m$ma,
      ") mean and <b>", m$dist, "</b> innovations. Fit indices were AIC = ",
      fmt_num(aic, 3), " and BIC = ", fmt_num(bic, 3), ".</p>",
      "<p><b>Model adequacy.</b> Ljungâ€“Box tests suggested ",
      "Q(", L, ") = ", fmt_num(lbz$statistic, 3), " (p ", fmt_p(lbz$p.value),
      ") for z<sub>t</sub> and Q(", L, ") = ", fmt_num(lbz2$statistic, 3),
      " (p ", fmt_p(lbz2$p.value), ") for z<sub>t</sub><sup>2</sup>. ",
      "When these are non-significant, the fitted variance dynamics are typically considered adequate.</p>",
      "<p><b>Forecasting.</b> ", acc_txt, "</p>",
      "<p><b>Overall.</b> The automated selection provides a defensible volatility model candidate. ",
      "If residual tests indicate remaining dependence, refine the mean ARMA orders, broaden the order search, or consider alternative innovation distributions.</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "autogarch_conclusion_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  
  
  # =============================
  # Auto-SARIMAX (auto.arima + xreg)
  # =============================
  
  output$step5b_notes <- renderUI({
    tags$div(
      tags$ol(
        tags$li("Select one or more exogenous regressors (X)."),
        tags$li("Click â€œFit Auto-SARIMAXâ€."),
        tags$li("Inspect model specification and coefficients."),
        tags$li("Check residual diagnostics and formal tests."),
        tags$li("Review forecasts and (if available) test-set accuracy."),
        tags$li(tags$b("Note:"), " If train_prop = 1 (no test set), future X values are assumed 0 unless you add a future-X input.")
      )
    )
  })
  
  # ---- X selector UI (uses prepared()$df and excludes date/value columns if available)
  output$autox_xreg_ui <- renderUI({
    req(prepared())
    df <- prepared()$df
    
    date_col  <- prepared()$date_col %||% character(0)
    value_col <- prepared()$value_col %||% character(0)
    
    candidates <- setdiff(names(df), c(date_col, value_col))
    candidates <- candidates[nzchar(candidates)]
    
    selectizeInput(
      "autox_x_cols",
      "Select X variables",
      choices = candidates,
      multiple = TRUE,
      options = list(placeholder = "Choose one or more regressorsâ€¦")
    )
  })
  
  # ---- Fit model (cached on Fit button)
  autox_fit <- eventReactive(input$fit_autox, {
    req(ts_train_test(), prepared())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required for Auto-SARIMAX."))
    
    s <- ts_train_test()
    y_train <- as.numeric(s$ts_train)
    y_test  <- as.numeric(s$ts_test)
    
    train_n <- length(y_train)
    test_n  <- length(y_test)
    
    df <- prepared()$df
    xcols <- input$autox_x_cols %||% character(0)
    
    xs <- build_xreg_split(
      df = df,
      cols = xcols,
      train_n = train_n,
      test_n  = test_n,
      scale_x = isTRUE(input$autox_scale_x)
    )
    
    fit <- forecast::auto.arima(
      y_train,
      xreg = xs$x_train,
      seasonal = isTRUE(input$autox_seasonal),
      stepwise = isTRUE(input$autox_stepwise),
      approximation = isTRUE(input$autox_approx),
      allowmean = isTRUE(input$autox_allow_mean),
      allowdrift = isTRUE(input$autox_allow_mean),
      max.order = as.integer(input$autox_max_order)
    )
    
    list(
      fit = fit,
      xcols = xcols,
      x_train = xs$x_train,
      x_test  = xs$x_test,
      y_train = y_train,
      y_test  = y_test
    )
  })
  
  # ---- Spec
  output$autox_model_spec <- renderPrint({
    validate(need(input$fit_autox > 0, "Click â€œFit Auto-SARIMAXâ€ first."))
    req(autox_fit())
    print(autox_fit()$fit)
  })
  
  # ---- Coefs
  output$autox_coef_table <- renderTable({
    req(autox_fit())
    sm <- summary(autox_fit()$fit)
    co <- as.data.frame(sm$coef)
    co$Term <- rownames(co)
    rownames(co) <- NULL
    co <- co[, c("Term", setdiff(names(co), "Term")), drop = FALSE]
    co
  }, digits = 6)
  
  # ---- Equation (MathJax, rendered like GARCH style)
  output$autox_model_equation <- renderUI({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX to show the equation."))
    req(autox_fit())
    obj <- autox_fit()
    
    xcols <- obj$xcols
    x_part <- if (length(xcols) == 0) {
      "0"
    } else {
      paste0("\\sum_{k=1}^{", length(xcols), "} \\beta_k x_{k,t}")
    }
    
    mean_eq <- paste0("y_t = c + ", x_part, " + \\varepsilon_t")
    
    html <- paste0(
      "<p><b>Mean (regression) equation:</b></p><div>$$", mean_eq, "$$</div>",
      "<p><b>Selected ARIMA structure (auto.arima):</b> ", as.character(obj$fit), "</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "autox_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- Residuals
  autox_resid <- reactive({
    req(autox_fit())
    as.numeric(residuals(autox_fit()$fit))
  })
  
  # ---- Diagnostics plots
  output$autox_resid_ts <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    plot(r, type = "l", main = "Residuals", ylab = "e_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$autox_resid_acf <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    stats::acf(autox_resid(), main = "ACF of residuals")
  })
  
  output$autox_resid_hist <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    hist(autox_resid(), breaks = 30, main = "Residual histogram", xlab = "e_t")
  })
  
  output$autox_resid_qq <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    qqnorm(r, main = "Qâ€“Q plot")
    qqline(r, col = "red")
  })
  
  output$autox_resid_lb_pvals <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    maxL <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(maxL) || maxL < 5) maxL <- 12L
    lags <- 1:maxL
    pvals <- sapply(lags, function(L) {
      out <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
      if (is.null(out)) NA_real_ else out$p.value
    })
    plot(lags, pvals, type = "b", pch = 16, ylim = c(0, 1),
         main = "Ljungâ€“Box p-values by lag", xlab = "Lag", ylab = "p-value")
    abline(h = 0.05, col = "red", lty = 2)
  })
  
  # ---- Residual tests
  output$autox_diag_tests <- renderPrint({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    r <- autox_resid()
    
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    cat("Residual tests (Auto-SARIMAX)\n========================\n\n")
    cat("Ljungâ€“Box:\n")
    print(Box.test(r, lag = L, type = "Ljung-Box"))
    cat("\n")
    
    if (requireNamespace("tseries", quietly = TRUE)) {
      cat("Jarqueâ€“Bera normality test:\n")
      print(tseries::jarque.bera.test(r))
      cat("\n")
    } else {
      cat("Jarqueâ€“Bera: package 'tseries' not installed.\n\n")
    }
  })
  
  # ---- Forecast
  autox_forecast <- reactive({
    req(autox_fit())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    obj <- autox_fit()
    test_n <- length(obj$y_test)
    
    if (test_n > 0) {
      h <- test_n
      xfuture <- obj$x_test
    } else {
      h_in <- suppressWarnings(as.integer(input$autox_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
      
      # No future X UI -> default zeros matrix with same columns as training X
      xfuture <- if (is.null(obj$x_train)) NULL else
        matrix(0, nrow = h, ncol = ncol(obj$x_train), dimnames = list(NULL, colnames(obj$x_train)))
    }
    
    fc <- forecast::forecast(obj$fit, h = h, xreg = xfuture)
    list(fc = fc, h = h)
  })
  
  output$autox_horizon_note <- renderPrint({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    obj <- autox_fit()
    if (length(obj$y_test) > 0) {
      cat("Holdout test detected. Forecast horizon set to test length (h =", length(obj$y_test), ").\n")
    } else {
      cat("No test detected. Forecast horizon uses autox_h (or default). Future X is assumed 0 unless you add a future-X input.\n")
    }
  })
  
  output$autox_forecast_plot <- renderPlot({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    plot(autox_forecast()$fc, main = "Auto-SARIMAX forecast")
  })
  
  output$autox_forecast_table <- renderTable({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    fc <- autox_forecast()$fc
    data.frame(
      step = seq_along(fc$mean),
      mean = as.numeric(fc$mean),
      lo80 = as.numeric(fc$lower[, 1]),
      hi80 = as.numeric(fc$upper[, 1]),
      lo95 = as.numeric(fc$lower[, 2]),
      hi95 = as.numeric(fc$upper[, 2])
    )
  }, digits = 6)
  
  output$autox_accuracy_table <- renderTable({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    obj <- autox_fit()
    if (length(obj$y_test) == 0) return(NULL)
    
    y_test <- obj$y_test
    y_hat  <- as.numeric(autox_forecast()$fc$mean)
    
    if (exists("accuracy_df", mode = "function")) {
      accuracy_df(y_test, y_hat)
    } else {
      e <- y_test - y_hat
      data.frame(
        Metric = c("RMSE", "MAE"),
        Value  = c(sqrt(mean(e^2, na.rm = TRUE)), mean(abs(e), na.rm = TRUE))
      )
    }
  }, rownames = FALSE)
  
  output$apa_autox_paragraph <- renderPrint({
    validate(need(input$fit_autox > 0, "Fit Auto-SARIMAX first."))
    obj <- autox_fit()
    cat(
      "An Auto-SARIMAX model was estimated using forecast::auto.arima with exogenous regressors (xreg). ",
      "The selected specification was ", as.character(obj$fit),
      ". Residual diagnostics (plots and Ljungâ€“Box testing) were used to assess adequacy, and forecasts were generated conditional on the available xreg information.",
      sep = ""
    )
  })
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  # =============================
  # Manual SARIMAX (Arima + xreg)
  # =============================
  
  `%||%` <- function(a, b) if (!is.null(a)) a else b  # only if you don't already have it
  
  output$step6b_notes <- renderUI({
    tags$div(
      tags$ol(
        tags$li("Select one or more exogenous regressors (X)."),
        tags$li("Choose the SARIMA orders (p,d,q)(P,D,Q)[s]."),
        tags$li("Click Fit to estimate SARIMAX."),
        tags$li("Check diagnostics and residual tests."),
        tags$li("Evaluate forecasts and (if available) test-set accuracy."),
        tags$li(tags$b("Note:"), " If train_prop = 1 (no test set), future X values are assumed 0 unless you add a future-X input.")
      )
    )
  })
  
  # ---- X selector UI
  output$sarimax_xreg_ui <- renderUI({
    req(prepared())
    df <- prepared()$df
    
    date_col  <- prepared()$date_col %||% character(0)
    value_col <- prepared()$value_col %||% character(0)
    
    candidates <- setdiff(names(df), c(date_col, value_col))
    candidates <- candidates[nzchar(candidates)]
    
    selectizeInput(
      "sarimax_x_cols",
      "Select X variables",
      choices = candidates,
      multiple = TRUE,
      options = list(placeholder = "Choose one or more regressorsâ€¦")
    )
  })
  
  # ---- Split text/plot (simple; adjust if you already have a nicer split plot helper)
  output$sarimax_split_text <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    cat("Training length:", length(s$ts_train), "\n")
    cat("Test length:", length(s$ts_test), "\n")
  })
  
  output$sarimax_split_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    y <- as.numeric(s$ts_full)
    n_train <- length(s$ts_train)
    
    plot(y, type = "l", main = "Train/Test split", xlab = "t", ylab = "y")
    abline(v = n_train, col = "red", lty = 2)
    legend("topleft", legend = c("Series", "Train/Test boundary"), col = c("black", "red"), lty = c(1,2), bty = "n")
  })
  
  # ---- Fit SARIMAX (cached)
  sarimax_fit <- eventReactive(input$fit_sarimax, {
    req(ts_train_test(), prepared())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required for SARIMAX."))
    
    s <- ts_train_test()
    y_train <- as.numeric(s$ts_train)
    y_test  <- as.numeric(s$ts_test)
    
    train_n <- length(y_train)
    test_n  <- length(y_test)
    
    df <- prepared()$df
    xcols <- input$sarimax_x_cols %||% character(0)
    
    xs <- build_xreg_split(
      df = df,
      cols = xcols,
      train_n = train_n,
      test_n  = test_n,
      scale_x = isTRUE(input$sarimax_scale_x)
    )
    
    # seasonal period: sx_s overrides sidebar frequency
    s_in <- suppressWarnings(as.integer(input$sx_s))
    if (!is.finite(s_in)) s_in <- suppressWarnings(as.integer(prepared()$freq))
    if (!is.finite(s_in) || s_in < 1) s_in <- 1L
    
    p <- as.integer(input$sx_p); if (!is.finite(p) || p < 0) p <- 0L
    d <- as.integer(input$sx_d); if (!is.finite(d) || d < 0) d <- 0L
    q <- as.integer(input$sx_q); if (!is.finite(q) || q < 0) q <- 0L
    
    P <- as.integer(input$sx_P); if (!is.finite(P) || P < 0) P <- 0L
    D <- as.integer(input$sx_D); if (!is.finite(D) || D < 0) D <- 0L
    Q <- as.integer(input$sx_Q); if (!is.finite(Q) || Q < 0) Q <- 0L
    
    drift <- isTRUE(input$sarimax_drift)
    
    fit <- forecast::Arima(
      y_train,
      order = c(p, d, q),
      seasonal = list(order = c(P, D, Q), period = s_in),
      xreg = xs$x_train,
      include.mean = drift,
      include.drift = drift,
      method = "ML"
    )
    
    list(
      fit = fit,
      xcols = xcols,
      x_train = xs$x_train,
      x_test  = xs$x_test,
      y_train = y_train,
      y_test  = y_test,
      period  = s_in,
      orders  = list(p=p,d=d,q=q,P=P,D=D,Q=Q)
    )
  })
  
  # ---- Model spec
  output$sarimax_model_spec <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Click Fit SARIMAX first."))
    req(sarimax_fit())
    print(sarimax_fit()$fit)
  })
  
  # ---- Coef table
  output$sarimax_coef_table <- renderTable({
    req(sarimax_fit())
    sm <- summary(sarimax_fit()$fit)
    co <- as.data.frame(sm$coef)
    co$Term <- rownames(co)
    rownames(co) <- NULL
    co <- co[, c("Term", setdiff(names(co), "Term")), drop = FALSE]
    co
  }, digits = 6)
  
  # ---- Equation (MathJax)
  output$sarimax_model_equation <- renderUI({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX to show the equation."))
    req(sarimax_fit())
    obj <- sarimax_fit()
    
    k <- length(obj$xcols)
    
    x_part <- if (k == 0) {
      "0"
    } else {
      paste0("\\sum_{k=1}^{", k, "} \\beta_k x_{k,t}")
    }
    
    mean_eq <- paste0("y_t = c + ", x_part, " + \\varepsilon_t")
    
    # Operator form for SARIMAX (generic)
    op_eq <- paste0(
      "\\Phi(B^s)\\phi(B)(1-B)^d(1-B^s)^D y_t = c + ",
      x_part,
      " + \\Theta(B^s)\\theta(B)\\varepsilon_t"
    )
    
    html <- paste0(
      "<p><b>Regression mean equation:</b></p><div>$$", mean_eq, "$$</div>",
      "<p><b>SARIMAX operator form:</b></p><div>$$", op_eq, "$$</div>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "sarimax_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- Residuals
  sarimax_resid <- reactive({
    req(sarimax_fit())
    as.numeric(residuals(sarimax_fit()$fit))
  })
  
  # ---- Diagnostics plots
  output$sarimax_resid_ts <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    plot(r, type = "l", main = "Residuals", ylab = "e_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$sarimax_resid_acf <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    stats::acf(sarimax_resid(), main = "ACF of residuals")
  })
  
  output$sarimax_resid_hist <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    hist(sarimax_resid(), breaks = 30, main = "Residual histogram", xlab = "e_t")
  })
  
  output$sarimax_resid_qq <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    qqnorm(r, main = "Qâ€“Q plot"); qqline(r, col = "red")
  })
  
  output$sarimax_resid_lb_pvals <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    maxL <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(maxL) || maxL < 5) maxL <- 12L
    lags <- 1:maxL
    pvals <- sapply(lags, function(L) {
      out <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
      if (is.null(out)) NA_real_ else out$p.value
    })
    plot(lags, pvals, type = "b", pch = 16, ylim = c(0, 1),
         main = "Ljungâ€“Box p-values by lag", xlab = "Lag", ylab = "p-value")
    abline(h = 0.05, col = "red", lty = 2)
  })
  
  # ---- Residual tests
  output$sarimax_diag_tests <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    r <- sarimax_resid()
    
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    cat("Residual tests (Manual SARIMAX)\n==========================\n\n")
    
    cat("Ljungâ€“Box:\n")
    print(Box.test(r, lag = L, type = "Ljung-Box"))
    cat("\n")
    
    if (requireNamespace("tseries", quietly = TRUE)) {
      cat("Jarqueâ€“Bera normality test:\n")
      print(tseries::jarque.bera.test(r))
      cat("\n")
    } else {
      cat("Jarqueâ€“Bera: package 'tseries' not installed.\n\n")
    }
  })
  
  # ---- Forecast
  sarimax_forecast <- reactive({
    req(sarimax_fit())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    obj <- sarimax_fit()
    test_n <- length(obj$y_test)
    
    if (test_n > 0) {
      h <- test_n
      xfuture <- obj$x_test
    } else {
      h_in <- suppressWarnings(as.integer(input$sarimax_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
      
      # No future X UI -> default zeros
      xfuture <- if (is.null(obj$x_train)) NULL else
        matrix(0, nrow = h, ncol = ncol(obj$x_train), dimnames = list(NULL, colnames(obj$x_train)))
    }
    
    fc <- forecast::forecast(obj$fit, h = h, xreg = xfuture)
    list(fc = fc, h = h)
  })
  
  output$sarimax_horizon_note <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    obj <- sarimax_fit()
    if (length(obj$y_test) > 0) {
      cat("Holdout test detected. Forecast horizon set to test length (h =", length(obj$y_test), ").\n")
    } else {
      cat("No test detected. Forecast horizon uses sarimax_h (or default). Future X is assumed 0 unless you add a future-X input.\n")
    }
  })
  
  output$sarimax_forecast_plot <- renderPlot({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    plot(sarimax_forecast()$fc, main = "SARIMAX forecast")
  })
  
  output$sarimax_forecast_table <- renderTable({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    fc <- sarimax_forecast()$fc
    data.frame(
      step = seq_along(fc$mean),
      mean = as.numeric(fc$mean),
      lo80 = as.numeric(fc$lower[, 1]),
      hi80 = as.numeric(fc$upper[, 1]),
      lo95 = as.numeric(fc$lower[, 2]),
      hi95 = as.numeric(fc$upper[, 2])
    )
  }, digits = 6)
  
  output$sarimax_accuracy_table <- renderTable({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    obj <- sarimax_fit()
    if (length(obj$y_test) == 0) return(NULL)
    
    y_test <- obj$y_test
    y_hat  <- as.numeric(sarimax_forecast()$fc$mean)
    
    if (exists("accuracy_df", mode = "function")) {
      accuracy_df(y_test, y_hat)
    } else {
      e <- y_test - y_hat
      data.frame(
        Metric = c("RMSE", "MAE"),
        Value  = c(sqrt(mean(e^2, na.rm = TRUE)), mean(abs(e), na.rm = TRUE))
      )
    }
  }, rownames = FALSE)
  
  # ---- APA paragraph
  output$apa_sarimax_paragraph <- renderPrint({
    validate(need(input$fit_sarimax > 0, "Fit SARIMAX first."))
    obj <- sarimax_fit()
    fit <- obj$fit
    
    cat(
      "A SARIMAX model (seasonal ARIMA with exogenous regressors) was estimated using forecast::Arima with xreg predictors. ",
      "The specified model was ", as.character(fit),
      if (isTRUE(input$sarimax_drift)) " including a drift/mean term." else " without a drift/mean term.",
      " Model adequacy was assessed using residual plots and Ljungâ€“Box testing, and forecasts were generated conditional on the available exogenous information.",
      sep = ""
    )
  })
  
  
  
  
  
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  #=====================================================================================================
  
  
  
  # ============================
  # ChatGPT-SARIMA (Manual) TAB
  # ============================
  
  # ---- small helpers (safe if you already have them)
  `%||%` <- function(a, b) if (!is.null(a)) a else b
  
  cg_fmt_num <- function(x, d = 3) {
    if (length(x) == 0 || !is.finite(x)) return(NA_character_)
    formatC(x, format = "f", digits = d)
  }
  cg_fmt_p <- function(p) {
    if (!is.finite(p)) return("= NA")
    if (p < 0.001) "< .001" else paste0("= ", cg_fmt_num(p, 3))
  }
  cg_sig_stars <- function(p) {
    if (!is.finite(p)) return("")
    if (p < 0.001) "***" else if (p < 0.01) "**" else if (p < 0.05) "*" else if (p < 0.1) "â€ " else ""
  }
  
  output$cg_notes <- renderUI({
    if (!isTRUE(input$cg_show_teaching)) return(NULL)
    tags$div(
      class = "alert alert-info",
      tags$b("ChatGPT-SARIMA workflow:"),
      tags$ol(
        tags$li("Confirm stationarity/differencing decisions (d, D) on the Stationarity tab."),
        tags$li("Use ACF/PACF patterns to propose p/q and P/Q (seasonal at lag s)."),
        tags$li("Fit the model; then check residuals: they should resemble white noise."),
        tags$li("If residual autocorrelation remains, adjust orders; if volatility clustering exists, consider GARCH.")
      )
    )
  })
  
  # ---- Split summary + plot
  output$cg_split_text <- renderPrint({
    req(ts_train_test())
    s <- ts_train_test()
    cat("Training length:", length(s$ts_train), "\n")
    cat("Test length:", length(s$ts_test), "\n")
  })
  
  output$cg_split_plot <- renderPlot({
    req(ts_train_test())
    s <- ts_train_test()
    y <- as.numeric(s$ts_full)
    n_train <- length(s$ts_train)
    
    plot(y, type = "l", main = "Train/Test split", xlab = "t", ylab = "y")
    abline(v = n_train, col = "red", lty = 2)
    legend("topleft", legend = c("Series", "Train/Test boundary"),
           col = c("black", "red"), lty = c(1, 2), bty = "n")
  })
  
  # ---- Fit SARIMA (cached on button)
  cg_fit <- eventReactive(input$fit_cg_sarima, {
    req(ts_train_test())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    s <- ts_train_test()
    y_train <- as.numeric(s$ts_train)
    y_test  <- as.numeric(s$ts_test)
    
    p <- as.integer(input$cg_p); if (!is.finite(p) || p < 0) p <- 0L
    d <- as.integer(input$cg_d); if (!is.finite(d) || d < 0) d <- 0L
    q <- as.integer(input$cg_q); if (!is.finite(q) || q < 0) q <- 0L
    
    P <- as.integer(input$cg_P); if (!is.finite(P) || P < 0) P <- 0L
    D <- as.integer(input$cg_D); if (!is.finite(D) || D < 0) D <- 0L
    Q <- as.integer(input$cg_Q); if (!is.finite(Q) || Q < 0) Q <- 0L
    
    s_in <- suppressWarnings(as.integer(input$cg_s))
    if (!is.finite(s_in)) {
      # try prepared()$freq if available, else default 1
      s_in <- tryCatch(as.integer(prepared()$freq), error = function(e) NA_integer_)
    }
    if (!is.finite(s_in) || s_in < 1) s_in <- 1L
    
    include_mean <- isTRUE(input$cg_include_mean)
    method <- as.character(input$cg_method) %||% "ML"
    
    fit <- forecast::Arima(
      y_train,
      order = c(p, d, q),
      seasonal = list(order = c(P, D, Q), period = s_in),
      include.mean = include_mean,
      include.drift = include_mean,
      method = method,
      biasadj = isTRUE(input$cg_biasadj)
    )
    
    list(
      fit = fit,
      y_train = y_train,
      y_test  = y_test,
      p=p, d=d, q=q, P=P, D=D, Q=Q, s=s_in,
      include_mean = include_mean
    )
  })
  
  # ---- Model spec + IC table
  output$cg_model_spec <- renderPrint({
    validate(need(input$fit_cg_sarima > 0, "Click Fit to estimate ChatGPT-SARIMA."))
    req(cg_fit())
    print(cg_fit()$fit)
  })
  
  output$cg_ic_table <- renderTable({
    req(cg_fit())
    fit <- cg_fit()$fit
    data.frame(
      Metric = c("AIC", "AICc", "BIC", "logLik"),
      Value  = c(
        as.numeric(fit$aic),
        as.numeric(fit$aicc),
        as.numeric(fit$bic),
        as.numeric(stats::logLik(fit))
      )
    )
  }, digits = 4)
  
  # ---- Coef table with stars
  output$cg_coef_table <- renderTable({
    req(cg_fit())
    sm <- summary(cg_fit()$fit)
    co <- as.data.frame(sm$coef)
    co$Term <- rownames(co); rownames(co) <- NULL
    names(co) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)", "Term")
    
    co <- co[, c("Term", "Estimate", "Std.Error", "t.value", "Pr(>|t|)"), drop = FALSE]
    co$Estimate <- as.numeric(co$Estimate)
    co$Std.Error <- as.numeric(co$Std.Error)
    co$`t.value` <- as.numeric(co$`t.value`)
    co$`Pr(>|t|)` <- as.numeric(co$`Pr(>|t|)`)
    
    if (isTRUE(input$cg_show_stars)) {
      co$Sig <- vapply(co$`Pr(>|t|)`, cg_sig_stars, character(1))
    }
    
    co
  }, digits = 6)
  
  # ---- Equation (MathJax) â€” rendered as HTML + forced typeset
  output$cg_model_equation <- renderUI({
    validate(need(input$fit_cg_sarima > 0, "Fit the model to generate the equation."))
    req(cg_fit())
    obj <- cg_fit()
    
    # Generic academic operator form
    # (This avoids fragile â€œexpanded numericâ€ equations and renders reliably.)
    eq <- paste0(
      "\\Phi(B^{", obj$s, "})\\,\\phi(B)\\,(1-B)^{", obj$d, "}(1-B^{", obj$s, "})^{", obj$D, "}\\,y_t = ",
      if (obj$include_mean) "c + " else "",
      "\\Theta(B^{", obj$s, "})\\,\\theta(B)\\,\\varepsilon_t"
    )
    
    html <- paste0(
      "<p><b>SARIMA operator form:</b></p>",
      "<div>$$", eq, "$$</div>",
      "<p><b>Selected orders:</b> SARIMA(",
      obj$p, ",", obj$d, ",", obj$q, ")(",
      obj$P, ",", obj$D, ",", obj$Q, ")[", obj$s, "]</p>"
    )
    
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "cg_eq_box")
    }, once = TRUE)
    
    HTML(html)
  })
  
  # ---- Residuals
  cg_resid <- reactive({
    req(cg_fit())
    as.numeric(residuals(cg_fit()$fit))
  })
  
  # ---- Diagnostics plots
  output$cg_resid_ts <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    plot(r, type = "l", main = "Residuals", ylab = "e_t", xlab = "t")
    abline(h = 0, col = "red", lty = 2)
  })
  
  output$cg_resid_acf <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    stats::acf(cg_resid(), main = "ACF of residuals")
  })
  
  output$cg_resid_hist <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    hist(cg_resid(), breaks = 30, main = "Residual histogram", xlab = "e_t")
  })
  
  output$cg_resid_qq <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    qqnorm(r, main = "Qâ€“Q plot"); qqline(r, col = "red")
  })
  
  output$cg_lb_pvals <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    maxL <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(maxL) || maxL < 5) maxL <- 12L
    
    lags <- 1:maxL
    pvals <- sapply(lags, function(L) {
      out <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
      if (is.null(out)) NA_real_ else out$p.value
    })
    
    plot(lags, pvals, type = "b", pch = 16, ylim = c(0, 1),
         main = "Ljungâ€“Box p-values by lag", xlab = "Lag", ylab = "p-value")
    abline(h = 0.05, col = "red", lty = 2)
  })
  
  # ---- Residual tests (text)
  output$cg_resid_tests <- renderPrint({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    r <- cg_resid()
    
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    cat("Residual tests (ChatGPT-SARIMA)\n")
    cat("================================\n\n")
    
    cat("Ljungâ€“Box test on residuals:\n")
    print(Box.test(r, lag = L, type = "Ljung-Box"))
    cat("\n")
    
    if (requireNamespace("tseries", quietly = TRUE)) {
      cat("Jarqueâ€“Bera normality test:\n")
      print(tseries::jarque.bera.test(r))
      cat("\n")
    } else {
      cat("Jarqueâ€“Bera: package 'tseries' not installed.\n\n")
    }
    
    if (requireNamespace("FinTS", quietly = TRUE)) {
      cat("ARCH LM test (FinTS::ArchTest):\n")
      print(FinTS::ArchTest(r, lags = L))
      cat("\n")
    } else {
      cat("ARCH LM: package 'FinTS' not installed.\n\n")
    }
  })
  
  # ---- Forecast + accuracy
  cg_forecast <- reactive({
    req(cg_fit())
    validate(need(requireNamespace("forecast", quietly = TRUE), "Package 'forecast' is required."))
    
    obj <- cg_fit()
    test_n <- length(obj$y_test)
    
    if (test_n > 0) {
      h <- test_n
    } else {
      h_in <- suppressWarnings(as.integer(input$cg_h))
      if (!is.finite(h_in) || h_in < 1) h_in <- 20L
      h <- h_in
    }
    
    fc <- forecast::forecast(obj$fit, h = h)
    list(fc = fc, h = h)
  })
  
  output$cg_horizon_note <- renderPrint({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    obj <- cg_fit()
    if (length(obj$y_test) > 0) {
      cat("Holdout test detected. Horizon set to test length (h =", length(obj$y_test), ").\n")
    } else {
      cat("No test detected. Horizon uses cg_h (or default).\n")
    }
  })
  
  output$cg_forecast_plot <- renderPlot({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    plot(cg_forecast()$fc, main = "ChatGPT-SARIMA forecast")
  })
  
  output$cg_forecast_table <- renderTable({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    fc <- cg_forecast()$fc
    
    out <- data.frame(
      step = seq_along(fc$mean),
      mean = as.numeric(fc$mean)
    )
    
    # intervals if present
    if (!is.null(fc$lower) && !is.null(fc$upper) && isTRUE(input$cg_show_pi)) {
      out$lo80 <- as.numeric(fc$lower[, 1])
      out$hi80 <- as.numeric(fc$upper[, 1])
      out$lo95 <- as.numeric(fc$lower[, 2])
      out$hi95 <- as.numeric(fc$upper[, 2])
    }
    out
  }, digits = 6)
  
  output$cg_accuracy_table <- renderTable({
    validate(need(input$fit_cg_sarima > 0, "Fit ChatGPT-SARIMA first."))
    obj <- cg_fit()
    if (length(obj$y_test) == 0) return(NULL)
    
    y_test <- obj$y_test
    y_hat <- as.numeric(cg_forecast()$fc$mean)
    
    if (exists("accuracy_df", mode = "function")) {
      accuracy_df(y_test, y_hat)
    } else {
      e <- y_test - y_hat
      data.frame(
        Metric = c("RMSE", "MAE", "MAPE"),
        Value = c(
          sqrt(mean(e^2, na.rm = TRUE)),
          mean(abs(e), na.rm = TRUE),
          mean(abs(e / y_test), na.rm = TRUE)
        )
      )
    }
  }, rownames = FALSE)
  
  # ---- Academic conclusion: one UI that includes everything (tables, plots, tests, equation, narrative)
  output$cg_conclusion_ui <- renderUI({
    validate(
      need(input$fit_cg_sarima > 0, "Click Fit to generate the academic conclusion.")
    )
    req(cg_fit())
    
    obj <- cg_fit()
    fit <- obj$fit
    r   <- cg_resid()
    
    # ---- core IC (safe)
    aic  <- suppressWarnings(as.numeric(fit$aic))
    aicc <- suppressWarnings(as.numeric(fit$aicc))
    bic  <- suppressWarnings(as.numeric(fit$bic))
    
    aic_txt  <- if (is.finite(aic))  cg_fmt_num(aic,  2) else "NA"
    aicc_txt <- if (is.finite(aicc)) cg_fmt_num(aicc, 2) else "NA"
    bic_txt  <- if (is.finite(bic))  cg_fmt_num(bic,  2) else "NA"
    
    # ---- coefficient summary for narrative (ROBUST)
    sm <- tryCatch(summary(fit), error = function(e) NULL)
    
    co_raw <- NULL
    if (!is.null(sm)) {
      if (!is.null(sm$coef)) co_raw <- sm$coef
      if (is.null(co_raw) && !is.null(sm$coefficients)) co_raw <- sm$coefficients
    }
    
    co <- if (!is.null(co_raw)) {
      df <- as.data.frame(co_raw)
      df$term <- rownames(df)
      rownames(df) <- NULL
      
      # normalize column names to detect estimate/se/stat/p
      nm  <- names(df)
      nm0 <- tolower(gsub("[^a-z]+", "", nm))
      
      pick <- function(keys) {
        idx <- which(nm0 %in% keys)
        if (length(idx) == 0) NA_integer_ else idx[1]
      }
      
      i_est <- pick(c("estimate", "est", "coef", "value"))
      i_se  <- pick(c("se", "stderror", "stderr"))
      i_st  <- pick(c("tvalue", "tstat", "zvalue", "zstat", "statistic"))
      i_p   <- pick(c("prtt", "prgt", "prgtz", "pvalue", "p"))
      
      out <- data.frame(
        term  = df$term,
        est   = if (!is.na(i_est)) suppressWarnings(as.numeric(df[[i_est]])) else NA_real_,
        se    = if (!is.na(i_se))  suppressWarnings(as.numeric(df[[i_se]]))  else NA_real_,
        stat  = if (!is.na(i_st))  suppressWarnings(as.numeric(df[[i_st]]))  else NA_real_,
        p     = if (!is.na(i_p))   suppressWarnings(as.numeric(df[[i_p]]))   else NA_real_,
        stringsAsFactors = FALSE
      )
      
      out$stars <- vapply(out$p, cg_sig_stars, character(1))
      out
    } else {
      data.frame(term = character(0), est = numeric(0), se = numeric(0), stat = numeric(0), p = numeric(0), stars = character(0))
    }
    
    n_sig <- sum(is.finite(co$p) & co$p < 0.05)
    
    # ---- residual tests quick stats for narrative
    L <- suppressWarnings(as.integer(input$diag_lag))
    if (!is.finite(L) || L < 1) L <- 12L
    
    lb <- tryCatch(Box.test(r, lag = L, type = "Ljung-Box"), error = function(e) NULL)
    
    jb <- if (requireNamespace("tseries", quietly = TRUE)) {
      tryCatch(tseries::jarque.bera.test(r), error = function(e) NULL)
    } else NULL
    
    arch <- if (requireNamespace("FinTS", quietly = TRUE)) {
      tryCatch(FinTS::ArchTest(r, lags = L), error = function(e) NULL)
    } else NULL
    
    # ---- accuracy quick stats (if test)
    acc_txt <- "No holdout test set was available; out-of-sample accuracy was not computed."
    if (length(obj$y_test) > 0) {
      y_test <- obj$y_test
      fc_obj <- cg_forecast()
      y_hat  <- if (!is.null(fc_obj) && !is.null(fc_obj$fc)) as.numeric(fc_obj$fc$mean) else rep(NA_real_, length(y_test))
      
      if (length(y_hat) == length(y_test) && any(is.finite(y_hat))) {
        e <- y_test - y_hat
        rmse <- sqrt(mean(e^2, na.rm = TRUE))
        mae  <- mean(abs(e), na.rm = TRUE)
        acc_txt <- paste0(
          "Out-of-sample performance (test n = ", length(y_test),
          ") was RMSE = ", cg_fmt_num(rmse, 3),
          " and MAE = ", cg_fmt_num(mae, 3), "."
        )
      } else {
        acc_txt <- paste0(
          "A test set was detected (n = ", length(y_test),
          "), but forecast values were not available or not finite; accuracy could not be computed."
        )
      }
    }
    
    # ---- typeset equation in conclusion box
    session$onFlushed(function() {
      session$sendCustomMessage("mathjax-typeset", "cg_conclusion_box")
    }, once = TRUE)
    
    tagList(
      tags$h3("ChatGPT-SARIMA: Academic conclusion"),
      
      tags$div(
        class = "cg-h",
        tags$h4("1. Model objective and specification"),
        tags$p(
          "A manually specified seasonal ARIMA (SARIMA) model was estimated to capture both non-seasonal and seasonal dependence in the series.",
          " The final specification was ",
          tags$b(sprintf(
            "SARIMA(%d,%d,%d)(%d,%d,%d)[%d]%s",
            obj$p, obj$d, obj$q, obj$P, obj$D, obj$Q, obj$s,
            if (isTRUE(obj$include_mean)) " with mean/drift." else " without mean/drift."
          )),
          "."
        ),
        tags$p(HTML(paste0(
          "<b>Information criteria:</b> AIC = ", aic_txt,
          ", AICc = ", aicc_txt,
          ", BIC = ", bic_txt, "."
        )))
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("2. Coefficient inference and practical interpretation"),
        tags$p(HTML(paste0(
          "Coefficient inference was evaluated using approximate t-tests. ",
          "A total of <b>", n_sig, "</b> parameters were statistically significant at Î± = .05 (see coefficient table)."
        ))),
        tags$p("Interpretation should prioritize model adequacy (white-noise residuals) and forecast performance rather than isolated p-values.")
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("3. Model equation"),
        tags$div(
          style = "border:1px solid #e5e5e5; border-radius:6px; background:#fcfcfc; padding:10px;",
          uiOutput("cg_model_equation")
        )
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("4. Diagnostic evidence"),
        tags$p("Residual diagnostics were examined using time-domain plots, autocorrelation diagnostics, and distributional checks."),
        fluidRow(
          column(6, plotOutput("cg_resid_ts", height = 220)),
          column(6, plotOutput("cg_resid_acf", height = 220))
        ),
        fluidRow(
          column(6, plotOutput("cg_resid_hist", height = 220)),
          column(6, plotOutput("cg_resid_qq", height = 220))
        ),
        plotOutput("cg_lb_pvals", height = 260)
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("5. Residual tests (formal)"),
        tags$p(
          "The following tests provide formal evidence regarding remaining autocorrelation (Ljungâ€“Box), ",
          "departures from normality (Jarqueâ€“Bera), and conditional heteroskedasticity (ARCH LM)."
        ),
        verbatimTextOutput("cg_resid_tests"),
        if (!is.null(lb)) tags$p(HTML(paste0(
          "<b>Ljungâ€“Box:</b> Q(", lb$parameter, ") = ", cg_fmt_num(lb$statistic, 3),
          ", p ", cg_fmt_p(lb$p.value), "."
        ))) else NULL,
        if (!is.null(jb)) tags$p(HTML(paste0(
          "<b>Jarqueâ€“Bera:</b> JB = ", cg_fmt_num(jb$statistic, 3),
          ", p ", cg_fmt_p(jb$p.value), "."
        ))) else NULL,
        if (!is.null(arch)) tags$p(HTML(paste0(
          "<b>ARCH LM:</b> TR^2 = ", cg_fmt_num(arch$statistic, 3),
          ", p ", cg_fmt_p(arch$p.value), "."
        ))) else NULL
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("6. Forecasting and predictive performance"),
        tags$p(acc_txt),
        plotOutput("cg_forecast_plot", height = 380),
        tags$h5("Forecast table"),
        tableOutput("cg_forecast_table"),
        tags$h5("Accuracy table (if test set available)"),
        tableOutput("cg_accuracy_table")
      ),
      
      tags$div(
        class = "cg-h",
        tags$h4("7. Final conclusion"),
        tags$p(
          "Overall, the fitted SARIMA model constitutes an interpretable baseline for linear seasonal dependence.",
          " If residual tests indicate non-white-noise behavior (e.g., significant Ljungâ€“Box), the model should be refined by adjusting AR/MA orders or differencing.",
          " If ARCH effects remain, a conditional variance model (e.g., GARCH) is recommended as an extension for volatility clustering."
        )
      )
    )
  })
  
  
  # --------------------------------------------------
  # Prevent tab suspension for Forecast outputs
  # --------------------------------------------------
  local({
    ids <- c(
      "manual_forecast_plot",
      "manual_accuracy_table",
      "manual_forecast_table",
      "manual_horizon_note"
    )
    lapply(ids, function(id)
      outputOptions(output, id, suspendWhenHidden = FALSE)
    )
  })

  
  
  
}
